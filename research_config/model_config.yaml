# LLM Model Configuration
# This file defines which LLM models to use for each processing stage.
# Each model can be configured with provider, model_name, temperature, and max_tokens.

# Layer 0: Fetch and score
# Used for relevance scoring of papers (0-10 scale) with researcher context
layer0:
  relevance_scorer:
    provider: "openai"  # Options: "openai", "gemini", "anthropic"
    model_name: "gpt-5-nano"
    temperature: 0.0
    max_tokens: 100  # Short structured output (just a score)
    structured_output: true  # Use structured output for reliable JSON parsing

# Layer 1: Deep paper analysis
# Multi-agent pipeline for extracting detailed understanding from PDFs
layer1:
  reader:
    provider: "gemini"
    model_name: "gemini-2.5-flash"
    temperature: 0.0
    max_tokens: 0  # 0 = no limit, let model decide

  methods_extractor:
    provider: "gemini"
    model_name: "gemini-2.5-flash"
    temperature: 0.0
    max_tokens: 0

  positioning:
    provider: "gemini"
    model_name: "gemini-3-pro-preview"
    temperature: 0.0
    max_tokens: 0

# Layer 2: Bibliometric front detection
# Used for summarizing research fronts detected through citation analysis
layer2:
  front_summarizer:
    provider: "gemini"
    model_name: "gemini-2.5-flash"
    temperature: 0.3  # Slightly creative for trend descriptions
    max_tokens: 0

# Layer 3: Living reviews and email generation
# Used for maintaining living literature reviews with daily/weekly/monthly cycles
layer3:
  daily_updater:
    provider: "gemini"
    model_name: "gemini-3-flash-preview"
    temperature: 0.3
    max_tokens: 8000

  weekly_revisor:
    provider: "gemini"
    model_name: "gemini-3-flash-preview"
    temperature: 0.3
    max_tokens: 8000

  monthly_rewriter:
    provider: "gemini"
    model_name: "gemini-3-flash-preview"
    temperature: 0.5  # More creative for major restructuring
    max_tokens: 8000

  email_generator:
    provider: "gemini"
    model_name: "gemini-2.5-flash"
    temperature: 0.5
    max_tokens: 0

# Cost estimates (per 1M tokens, as of 2026-02)
# Used for budgeting and cost tracking
cost_per_million_tokens:
  # Gemini
  "gemini-3-flash-preview":
    input: 0.5
    output: 3.0
  "gemini-2.5-flash":
    input: 0.3
    output: 2.5
  "gemini-2.5-flash-lite":
    input: 0.1
    output: 0.40
  "gemini-2.5-pro":
    input: 1.25
    output: 10.00
  "gemini-3-pro-preview":
    input: 2.0
    output: 12.00

  # Anthropic Claude
  "claude-sonnet-4-5-20250929":
    input: 3.00
    output: 15.00
  "claude-haiku-4-5-20251001":
    input: 0.80
    output: 4.00

  # OpenAI
  "gpt-5-nano":
    input: 0.10
    output: 0.30
  "gpt-4o":
    input: 2.50
    output: 10.00
  "gpt-4o-mini":
    input: 0.15
    output: 0.60
