## Updated on 2026.02.10
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#llms-for-algorithm-design>LLMs for Algorithm Design</a></li>
    <li><a href=#or-for-generative-ai>OR for Generative AI</a></li>
    <li><a href=#generative-ai-for-or>Generative AI for OR</a></li>
  </ol>
</details>

## LLMs for Algorithm Design

|Publish Date|Title|Authors|Venue|PDF|Code|
|---|---|---|---|---|---|
|**2026-02-04**|**Landscape-aware Automated Algorithm Design: An Efficient Framework for Real-world Optimization**|Haoran Yin et.al.||[2602.04529](http://arxiv.org/abs/2602.04529)|null|
|**2026-02-04**|**ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas**|Wenjun Peng et.al.||[2602.04296](http://arxiv.org/abs/2602.04296)|**[link](https://github.com/xinke-wang/ProxyWar)**|
|**2026-02-03**|**Contrastive Concept-Tree Search for LLM-Assisted Algorithm Discovery**|Timothee Leleu et.al.||[2602.03132](http://arxiv.org/abs/2602.03132)|null|
|**2026-02-01**|**Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization**|Junhao Qiu et.al.||[2601.17899](http://arxiv.org/abs/2601.17899)|null|
|**2026-01-29**|**READY: Reward Discovery for Meta-Black-Box Optimization**|Zechuan Huang et.al.||[2601.21847](http://arxiv.org/abs/2601.21847)|null|
|**2026-01-29**|**LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from Explainable AI**|Niki van Stein et.al.||[2601.21511](http://arxiv.org/abs/2601.21511)|null|
|**2026-01-29**|**TIDE: Tuning-Integrated Dynamic Evolution for LLM-Based Automated Heuristic Design**|Chentong Chen et.al.||[2601.21239](http://arxiv.org/abs/2601.21239)|null|
|**2026-01-29**|**PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs**|Oguzhan Gungordu et.al.||[2601.20539](http://arxiv.org/abs/2601.20539)|null|
|**2026-01-27**|**Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search**|Thomas Bömer et.al.|EvoStar conference; Code: https://github|[2601.19622](http://arxiv.org/abs/2601.19622)|null|
|**2026-01-22**|**LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling**|Junhao Qiu et.al.||[2601.15738](http://arxiv.org/abs/2601.15738)|null|
|**2026-01-15**|**Global Optimization for Combinatorial Geometry Problems Revisited in the Era of LLMs**|Timo Berthold et.al.||[2601.05943](http://arxiv.org/abs/2601.05943)|null|
|**2026-01-09**|**Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer**|Yifan Zhang et.al.||[2601.05770](http://arxiv.org/abs/2601.05770)|null|
|**2026-01-06**|**CodeEvolve: an open source evolutionary coding agent for algorithm discovery and optimization**|Henrique Assumpção et.al.||[2510.14150](http://arxiv.org/abs/2510.14150)|null|
|**2025-12-30**|**LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm**|Chunhui Wan et.al.||[2512.24077](http://arxiv.org/abs/2512.24077)|null|
|**2025-12-10**|**Beyond Algorithm Evolution: An LLM-Driven Framework for the Co-Evolution of Swarm Intelligence Optimization Algorithms and Prompts**|Shipeng Cen et.al.||[2512.09209](http://arxiv.org/abs/2512.09209)|null|
|**2025-11-16**|**Automated Algorithmic Discovery for Scientific Computing through LLM-Guided Evolutionary Search: A Case Study in Gravitational-Wave Detection**|He Wang et.al.||[2508.03661](http://arxiv.org/abs/2508.03661)|null|
|**2025-11-16**|**From Euler to AI: Unifying Formulas for Mathematical Constants**|Tomer Raz et.al.|NeurIPS|[2502.17533](http://arxiv.org/abs/2502.17533)|null|
|**2025-11-11**|**AlphaResearch: Accelerating New Algorithm Discovery with Language Models**|Zhaojian Yu et.al.||[2511.08522](http://arxiv.org/abs/2511.08522)|null|
|**2025-11-10**|**Extending QAOA-GPT to Higher-Order Quantum Optimization Problems**|Leanto Sunny et.al.||[2511.07391](http://arxiv.org/abs/2511.07391)|null|
|**2025-10-13**|**Refining Hybrid Genetic Search for CVRP via Reinforcement Learning-Finetuned LLM**|Rongjie Zhu et.al.||[2510.11121](http://arxiv.org/abs/2510.11121)|null|
|**2025-10-10**|**Barbarians at the Gate: How AI is Upending Systems Research**|Audrey Cheng et.al.||[2510.06189](http://arxiv.org/abs/2510.06189)|null|
|**2025-10-07**|**Scientific Algorithm Discovery by Augmenting AlphaEvolve with Deep Research**|Gang Liu et.al.||[2510.06056](http://arxiv.org/abs/2510.06056)|null|
|**2025-09-30**|**Experience-Guided Reflective Co-Evolution of Prompts and Heuristics for Automatic Algorithm Design**|Yihong Liu et.al.||[2509.24509](http://arxiv.org/abs/2509.24509)|null|
|**2025-09-25**|**GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models**|Peng Luo et.al.||[2509.21593](http://arxiv.org/abs/2509.21593)|null|
|**2025-09-02**|**Re-evaluating LLM-based Heuristic Search: A Case Study on the 3D Packing Problem**|Guorui Quan et.al.||[2509.02297](http://arxiv.org/abs/2509.02297)|null|
|**2025-08-25**|**Data-Driven Discovery of Interpretable Kalman Filter Variants through Large Language Models and Genetic Programming**|Vasileios Saketos et.al.||[2508.11703](http://arxiv.org/abs/2508.11703)|null|
|**2025-08-20**|**EoH-S: Evolution of Heuristic Set using LLMs for Automated Heuristic Design**|Fei Liu et.al.||[2508.03082](http://arxiv.org/abs/2508.03082)|null|
|**2025-08-08**|**LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression**|Hengzhe Zhang et.al.||[2505.18602](http://arxiv.org/abs/2505.18602)|null|
|**2025-08-04**|**Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning**|Anja Surina et.al.||[2504.05108](http://arxiv.org/abs/2504.05108)|null|
|**2025-08-03**|**EvoVLMA: Evolutionary Vision-Language Model Adaptation**|Kun Ding et.al.|ACM Multimedia 2025 (ACM MM 2025)|[2508.01558](http://arxiv.org/abs/2508.01558)|null|
|**2025-07-04**|**Behaviour Space Analysis of LLM-driven Meta-heuristic Discovery**|Niki van Stein et.al.||[2507.03605](http://arxiv.org/abs/2507.03605)|null|
|**2025-06-16**|**AlphaEvolve: A coding agent for scientific and algorithmic discovery**|Alexander Novikov et.al.||[2506.13131](http://arxiv.org/abs/2506.13131)|null|
|**2025-06-14**|**Automated Heuristic Design for Unit Commitment Using Large Language Models**|Junjin Lv et.al.||[2506.12495](http://arxiv.org/abs/2506.12495)|null|
|**2025-06-10**|**Can Large Language Models Invent Algorithms to Improve Themselves?: Algorithm Discovery for Recursive Self-Improvement through Reinforcement Learning**|Yoichi Ishibashi et.al.|NAACL 2025 (main)|[2410.15639](http://arxiv.org/abs/2410.15639)|null|
|**2025-06-03**|**LLM-Driven Instance-Specific Heuristic Generation and Selection**|Shaofeng Zhang et.al.||[2506.00490](http://arxiv.org/abs/2506.00490)|null|
|**2025-05-22**|**STRCMP: Integrating Graph Structural Priors with Language Models for Combinatorial Optimization**|Xijun Li et.al.||[2506.11057](http://arxiv.org/abs/2506.11057)|null|
|**2025-05-18**|**CALM: Co-evolution of Algorithms and Language Model for Automatic Heuristic Design**|Ziyao Huang et.al.||[2505.12285](http://arxiv.org/abs/2505.12285)|null|
|**2025-04-28**|**BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics**|Niki van Stein et.al.|GECCO Workshop 2025|[2504.20183](http://arxiv.org/abs/2504.20183)|null|
|**2025-03-25**|**Optimizing Photonic Structures with Large Language Model Driven Algorithm Discovery**|Haoran Yin et.al.||[2503.19742](http://arxiv.org/abs/2503.19742)|null|
|**2025-03-05**|**Leveraging Large Language Models to Develop Heuristics for Emerging Optimization Problems**|Thomas Bömer et.al.||[2503.03350](http://arxiv.org/abs/2503.03350)|null|
|**2025-02-04**|**Multi-objective Evolution of Heuristic Using Large Language Model**|Shunyu Yao et.al.||[2409.16867](http://arxiv.org/abs/2409.16867)|null|
|**2025-01-11**|**AlgoPilot: Fully Autonomous Program Synthesis Without Human-Written Programs**|Xiaoxin Yin et.al.||[2501.06423](http://arxiv.org/abs/2501.06423)|null|
|**2024-12-09**|**LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments**|Prakash Aryan et.al.||[2412.06229](http://arxiv.org/abs/2412.06229)|null|
|**2024-10-30**|**Automatic programming via large language models with population self-evolution for dynamic job shop scheduling problem**|Jin Huang et.al.||[2410.22657](http://arxiv.org/abs/2410.22657)|null|
|**2024-07-15**|**Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models**|Rui Zhang et.al.|the 18th International Conference on Parallel Problem Solving From Nature (PPSN 2024)|[2407.10873](http://arxiv.org/abs/2407.10873)|null|
|**2024-06-01**|**tnGPS: Discovering Unknown Tensor Network Structure Search Algorithms via Large Language Models (LLMs)**|Junhua Zeng et.al.|ICML2024|[2402.02456](http://arxiv.org/abs/2402.02456)|null|
|**2024-06-01**|**Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model**|Fei Liu et.al.||[2401.02051](http://arxiv.org/abs/2401.02051)|null|
|**2024-02-05**|**Open-Universe Indoor Scene Generation using LLM Program Synthesis and Uncurated Object Databases**|Rio Aguina-Kang et.al.||[2403.09675](http://arxiv.org/abs/2403.09675)|null|
|**2024-01-22**|**Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis**|Richard Roberson et.al.||[2401.12379](http://arxiv.org/abs/2401.12379)|null|

<p align=right>(<a href=#updated-on-20260210>back to top</a>)</p>

## OR for Generative AI

|Publish Date|Title|Authors|Venue|PDF|Code|
|---|---|---|---|---|---|
|**2026-02-05**|**Opt4GPTQ: Co-Optimizing Memory and Computation for 4-bit GPTQ Quantized LLM Inference on Heterogeneous Platforms**|Yaozheng Zhang et.al.||[2511.19438](http://arxiv.org/abs/2511.19438)|null|
|**2026-02-03**|**NLI:Non-uniform Linear Interpolation Approximation of Nonlinear Operations for Efficient LLMs Inference**|Jiangyong Yu et.al.||[2602.02988](http://arxiv.org/abs/2602.02988)|null|
|**2026-01-30**|**Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV Cache Time-to-Live**|Hanchen Li et.al.||[2511.02230](http://arxiv.org/abs/2511.02230)|null|
|**2026-01-19**|**SmallKV: Small Model Assisted Compensation of KV Cache Compression for Efficient LLM Inference**|Yi Zhao et.al.||[2508.02751](http://arxiv.org/abs/2508.02751)|null|
|**2026-01-12**|**AdaSpec: Adaptive Speculative Decoding for Fast, SLO-Aware Large Language Model Serving**|Kaiyu Huang et.al.|In ACM Symposium on Cloud Computing (SoCC '25), November 19-21, 2025, Online, USA|[2503.05096](http://arxiv.org/abs/2503.05096)|null|
|**2026-01-07**|**Hummingbird: SLO-Oriented GPU Preemption at Microsecond-scale**|Tiancheng Hu et.al.||[2601.04071](http://arxiv.org/abs/2601.04071)|null|
|**2026-01-05**|**LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference**|Hossein Rajabzadeh et.al.||[2601.02569](http://arxiv.org/abs/2601.02569)|null|
|**2026-01-05**|**Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints**|Ruicheng Ao et.al.||[2504.11320](http://arxiv.org/abs/2504.11320)|null|
|**2025-12-28**|**Argus: Token Aware Distributed LLM Inference Optimization**|Panlong Wu et.al.||[2512.22925](http://arxiv.org/abs/2512.22925)|null|
|**2025-12-18**|**Staggered Batch Scheduling: Co-optimizing Time-to-First-Token and Throughput for High-Efficiency LLM Inference**|Jian Tian et.al.||[2512.16134](http://arxiv.org/abs/2512.16134)|null|
|**2025-12-16**|**SemShareKV: Efficient KVCache Sharing for Semantically Similar Prompts via Token-Level LSH Matching**|Xinye Zhao et.al.||[2509.24832](http://arxiv.org/abs/2509.24832)|null|
|**2025-12-16**|**FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference**|Guangda Liu et.al.||[2505.13109](http://arxiv.org/abs/2505.13109)|null|
|**2025-12-12**|**Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery: Sublinear Memory Growth for Efficient LLM Inference**|Adilet Metinov et.al.||[2512.11221](http://arxiv.org/abs/2512.11221)|null|
|**2025-12-11**|**Hybrid Learning and Optimization-Based Dynamic Scheduling for DL Workloads on Heterogeneous GPU Clusters**|Shruti Dongare et.al.||[2512.10271](http://arxiv.org/abs/2512.10271)|null|
|**2025-12-08**|**H2EAL: Hybrid-Bonding Architecture with Hybrid Sparse Attention for Efficient Long-Context LLM Inference**|Zizhuo Fu et.al.||[2508.16653](http://arxiv.org/abs/2508.16653)|null|
|**2025-12-07**|**KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models**|Sourjya Roy et.al.||[2512.06727](http://arxiv.org/abs/2512.06727)|null|
|**2025-12-01**|**KV Pareto: Systems-Level Optimization of KV Cache and Model Compression for Long Context Inference**|Sai Gokhale et.al.||[2512.01953](http://arxiv.org/abs/2512.01953)|null|
|**2025-12-01**|**Optimal Scheduling Algorithms for LLM Inference: Theory and Practice**|Agrim Bari et.al.||[2508.01002](http://arxiv.org/abs/2508.01002)|null|
|**2025-11-27**|**OmniInfer: System-Wide Acceleration Techniques for Optimizing LLM Serving Throughput and Latency**|Jun Wang et.al.||[2511.22481](http://arxiv.org/abs/2511.22481)|null|
|**2025-11-27**|**KeepKV: Achieving Periodic Lossless KV Cache Compression for Efficient LLM Inference**|Yuxuan Tian et.al.||[2504.09936](http://arxiv.org/abs/2504.09936)|null|
|**2025-11-24**|**An Online Fragmentation-Aware GPU Scheduler for Multi-Tenant MIG-based Clouds**|Marco Zambianco et.al.||[2511.18906](http://arxiv.org/abs/2511.18906)|null|
|**2025-11-18**|**CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design**|Jiawei Yi et.al.||[2511.14510](http://arxiv.org/abs/2511.14510)|null|
|**2025-11-17**|**T-SAR: A Full-Stack Co-design for CPU-Only Ternary LLM Inference via In-Place SIMD ALU Reorganization**|Hyunwoo Oh et.al.||[2511.13676](http://arxiv.org/abs/2511.13676)|null|
|**2025-11-14**|**AccKV: Towards Efficient Audio-Video LLMs Inference via Adaptive-Focusing and Cross-Calibration KV Cache Optimization**|Zhonghua Jiang et.al.||[2511.11106](http://arxiv.org/abs/2511.11106)|null|
|**2025-11-04**|**Optimal Singular Damage: Efficient LLM Inference in Low Storage Regimes**|Mohammadsajad Alipour et.al.||[2511.02681](http://arxiv.org/abs/2511.02681)|null|
|**2025-11-03**|**Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with Efficient LLM Serving**|Chengying Huan et.al.||[2511.01633](http://arxiv.org/abs/2511.01633)|null|
|**2025-10-31**|**HELIOS: Adaptive Model And Early-Exit Selection for Efficient LLM Inference Serving**|Avinash Kumar et.al.||[2504.10724](http://arxiv.org/abs/2504.10724)|null|
|**2025-10-30**|**PureKV: Plug-and-Play KV Cache Optimization with Spatial-Temporal Sparse Attention for Vision-Language Large Models**|Zhonghua Jiang et.al.||[2510.25600](http://arxiv.org/abs/2510.25600)|null|
|**2025-10-30**|**DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference**|Xiang Liu et.al.||[2510.19669](http://arxiv.org/abs/2510.19669)|null|
|**2025-10-29**|**Oneiros: KV Cache Optimization through Parameter Remapping for Multi-tenant LLM Serving**|Ruihao Li et.al.||[2507.11507](http://arxiv.org/abs/2507.11507)|null|
|**2025-10-19**|**Justitia: Fair and Efficient Scheduling for LLM Applications**|Mingyan Yang et.al.||[2510.17015](http://arxiv.org/abs/2510.17015)|null|
|**2025-10-16**|**MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving**|Jungi Lee et.al.|the 58th International Symposium on Microarchitecture (MICRO 2025)|[2510.14557](http://arxiv.org/abs/2510.14557)|null|
|**2025-10-13**|**Efficient LLM Inference over Heterogeneous Edge Networks with Speculative Decoding**|Bingjie Zhu et.al.||[2510.11331](http://arxiv.org/abs/2510.11331)|null|
|**2025-10-10**|**FLRC: Fine-grained Low-Rank Compressor for Efficient LLM Inference**|Yu-Chen Lu et.al.|EMNLP 2025|[2510.09332](http://arxiv.org/abs/2510.09332)|null|
|**2025-10-07**|**VecInfer: Efficient LLM Inference with Low-Bit KV Cache via Outlier-Suppressed Vector Quantization**|Dingyu Yao et.al.||[2510.06175](http://arxiv.org/abs/2510.06175)|null|
|**2025-10-05**|**ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient Long-Context LLMs**|Xin Liu et.al.||[2503.10714](http://arxiv.org/abs/2503.10714)|null|
|**2025-09-30**|**Parallax: Efficient LLM Inference Service over Decentralized Environment**|Chris Tong et.al.||[2509.26182](http://arxiv.org/abs/2509.26182)|null|
|**2025-09-29**|**Speculative Verification: Exploiting Information Gain to Refine Speculative Decoding**|Sungkyun Kim et.al.||[2509.24328](http://arxiv.org/abs/2509.24328)|null|
|**2025-09-29**|**METok: Multi-Stage Event-based Token Compression for Efficient Long Video Understanding**|Mengyue Wang et.al.|EMNLP|[2506.02850](http://arxiv.org/abs/2506.02850)|null|
|**2025-09-29**|**SentenceKV: Efficient LLM Inference via Sentence-Level Semantic KV Caching**|Yuxuan Zhu et.al.||[2504.00970](http://arxiv.org/abs/2504.00970)|null|
|**2025-09-27**|**READER: Retrieval-Assisted Drafter for Efficient LLM Inference**|Maxim Divilkovskiy et.al.||[2508.09072](http://arxiv.org/abs/2508.09072)|null|
|**2025-09-26**|**Bridging Draft Policy Misalignment: Group Tree Optimization for Speculative Decoding**|Shijing Hu et.al.||[2509.22134](http://arxiv.org/abs/2509.22134)|null|
|**2025-09-24**|**Gyges: Dynamic Cross-Instance Parallelism Transformation for Efficient LLM Inference**|Haoyu Chen et.al.||[2509.19729](http://arxiv.org/abs/2509.19729)|null|
|**2025-09-22**|**Cronus: Efficient LLM inference on Heterogeneous GPU Clusters via Partially Disaggregated Prefill**|Yunzhao Liu et.al.||[2509.17357](http://arxiv.org/abs/2509.17357)|null|
|**2025-09-16**|**InferLog: Accelerating LLM Inference for Online Log Parsing via ICL-oriented Prefix Caching**|Yilun Wang et.al.|ICSE '26 (The 48th IEEE/ACM International Conference on Software Engineering)|[2507.08523](http://arxiv.org/abs/2507.08523)|null|
|**2025-09-12**|**MCBP: A Memory-Compute Efficient LLM Inference Accelerator Leveraging Bit-Slice-enabled Sparsity and Repetitiveness**|Huizheng Wang et.al.||[2509.10372](http://arxiv.org/abs/2509.10372)|null|
|**2025-09-11**|**Towards Confidential and Efficient LLM Inference with Dual Privacy Protection**|Honglan Yu et.al.|DASFAA2025|[2509.09091](http://arxiv.org/abs/2509.09091)|null|
|**2025-09-10**|**BitROM: Weight Reload-Free CiROM Architecture Towards Billion-Parameter 1.58-bit LLM Inference**|Wenlun Zhang et.al.||[2509.08542](http://arxiv.org/abs/2509.08542)|null|
|**2025-09-01**|**Adaptively Robust LLM Inference Optimization under Prediction Uncertainty**|Zixi Chen et.al.||[2508.14544](http://arxiv.org/abs/2508.14544)|null|
|**2025-08-31**|**LLM Serving Optimization with Variable Prefill and Decode Lengths**|Meixuan Wang et.al.||[2508.06133](http://arxiv.org/abs/2508.06133)|null|
|**2025-08-16**|**OrthoRank: Token Selection via Sink Token Orthogonality for Efficient LLM inference**|Seungjun Shin et.al.|ICML|[2507.03865](http://arxiv.org/abs/2507.03865)|null|
|**2025-08-08**|**KV Cache Compression for Inference Efficiency in LLMs: A Review**|Yanyu Liu et.al.||[2508.06297](http://arxiv.org/abs/2508.06297)|null|
|**2025-08-06**|**EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices**|Jiyu Chen et.al.||[2508.00370](http://arxiv.org/abs/2508.00370)|null|
|**2025-08-04**|**Prefill-Decode Aggregation or Disaggregation? Unifying Both for Goodput-Optimized LLM Serving**|Chao Wang et.al.||[2508.01989](http://arxiv.org/abs/2508.01989)|null|
|**2025-08-03**|**AGFT: An Adaptive GPU Frequency Tuner for Real-Time LLM Inference Optimization**|Zicong Ye et.al.||[2508.01744](http://arxiv.org/abs/2508.01744)|null|
|**2025-07-25**|**DeltaLLM: A Training-Free Framework Exploiting Temporal Sparsity for Efficient Edge LLM Inference**|Jiawen Qi et.al.||[2507.19608](http://arxiv.org/abs/2507.19608)|null|
|**2025-07-23**|**BucketServe: Bucket-Based Dynamic Batching for Smart and Efficient LLM Inference Serving**|Wanyi Zheng et.al.|IEEE SmartData 2025|[2507.17120](http://arxiv.org/abs/2507.17120)|null|
|**2025-07-16**|**IAM: Efficient Inference through Attention Mapping between Different-scale LLMs**|Yi Zhao et.al.|ACL|[2507.11953](http://arxiv.org/abs/2507.11953)|null|
|**2025-07-14**|**LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models**|Dachuan Shi et.al.|ICML|[2507.14204](http://arxiv.org/abs/2507.14204)|**[link](https://github.com/GATECH-EIC/LaCache)**|
|**2025-07-09**|**Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration**|Xinyuan Song et.al.||[2507.06520](http://arxiv.org/abs/2507.06520)|null|
|**2025-07-05**|**SparseMM: Head Sparsity Emerges from Visual Concept Responses in MLLMs**|Jiahui Wang et.al.|ICCV|[2506.05344](http://arxiv.org/abs/2506.05344)|null|
|**2025-06-20**|**Towards AI Search Paradigm**|Yuchen Li et.al.||[2506.17188](http://arxiv.org/abs/2506.17188)|null|
|**2025-06-12**|**Understanding the Performance and Power of LLM Inferencing on Edge Accelerators**|Mayank Arya et.al.|PAISE 2025: Mayank Arya and Yogesh Simmhan|[2506.09554](http://arxiv.org/abs/2506.09554)|null|
|**2025-06-07**|**Robustifying Vision-Language Models via Dynamic Token Reweighting**|Tanqiu Jiang et.al.||[2505.17132](http://arxiv.org/abs/2505.17132)|null|
|**2025-06-06**|**Towards Efficient Multi-LLM Inference: Characterization and Analysis of LLM Routing and Hierarchical Techniques**|Adarsh Prasad Behera et.al.||[2506.06579](http://arxiv.org/abs/2506.06579)|null|
|**2025-05-29**|**Sustainable Carbon-Aware and Water-Efficient LLM Scheduling in Geo-Distributed Cloud Datacenters**|Hayden Moore et.al.||[2505.23554](http://arxiv.org/abs/2505.23554)|null|
|**2025-05-27**|**TailorKV: A Hybrid Framework for Long-Context Inference via Tailored KV Cache Optimization**|Dingyu Yao et.al.||[2505.19586](http://arxiv.org/abs/2505.19586)|null|
|**2025-05-23**|**DASH: Input-Aware Dynamic Layer Skipping for Efficient LLM Inference with Markov Decision Policies**|Ning Yang et.al.||[2505.17420](http://arxiv.org/abs/2505.17420)|null|
|**2025-05-21**|**SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices**|Xiangwen Zhuge et.al.||[2505.10259](http://arxiv.org/abs/2505.10259)|null|
|**2025-05-15**|**Collaborative Speculative Inference for Efficient LLM Inference Serving**|Luyao Gao et.al.||[2503.10325](http://arxiv.org/abs/2503.10325)|null|
|**2025-05-14**|**ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor**|Seungbeom Choi et.al.||[2505.09142](http://arxiv.org/abs/2505.09142)|null|
|**2025-05-08**|**Scaling Laws for Speculative Decoding**|Siyuan Yan et.al.||[2505.07858](http://arxiv.org/abs/2505.07858)|null|
|**2025-04-28**|**Taming the Titans: A Survey of Efficient LLM Inference Serving**|Ranran Zhen et.al.||[2504.19720](http://arxiv.org/abs/2504.19720)|null|
|**2025-04-28**|**R-Sparse: Rank-Aware Activation Sparsity for Efficient LLM Inference**|Zhenyu Zhang et.al.|ICLR|[2504.19449](http://arxiv.org/abs/2504.19449)|null|
|**2025-04-24**|**On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration**|Maoyang Xiang et.al.||[2504.17376](http://arxiv.org/abs/2504.17376)|null|
|**2025-04-24**|**Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents**|Yueying Li et.al.||[2504.07347](http://arxiv.org/abs/2504.07347)|null|
|**2025-04-13**|**LoopLynx: A Scalable Dataflow Architecture for Efficient LLM Inference**|Jianing Zheng et.al.||[2504.09561](http://arxiv.org/abs/2504.09561)|null|
|**2025-04-08**|**HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient MoE Inference**|Shuzhang Zhong et.al.|DAC 25|[2504.05897](http://arxiv.org/abs/2504.05897)|null|
|**2025-03-28**|**EdgeInfinite: A Memory-Efficient Infinite-Context Transformer for Edge Devices**|Jiyu Chen et.al.||[2503.22196](http://arxiv.org/abs/2503.22196)|null|
|**2025-03-27**|**WindowKV: Task-Adaptive Group-Wise KV Cache Window Selection for Efficient LLM Inference**|Youhui Zuo et.al.||[2503.17922](http://arxiv.org/abs/2503.17922)|null|
|**2025-03-20**|**SPIN: Accelerating Large Language Model Inference with Heterogeneous Speculative Models**|Fahao Chen et.al.|INFOCOM 2025|[2503.15921](http://arxiv.org/abs/2503.15921)|null|
|**2025-03-01**|**Tutorial Proposal: Speculative Decoding for Efficient LLM Inference**|Heming Xia et.al.|COLING|[2503.00491](http://arxiv.org/abs/2503.00491)|null|
|**2025-02-24**|**Make LLM Inference Affordable to Everyone: Augmenting GPU Memory with NDP-DIMM**|Lian Liu et.al.|HPCA 2025|[2502.16963](http://arxiv.org/abs/2502.16963)|null|

<p align=right>(<a href=#updated-on-20260210>back to top</a>)</p>

## Generative AI for OR

|Publish Date|Title|Authors|Venue|PDF|Code|
|---|---|---|---|---|---|
|**2026-02-06**|**Evaluating LLM-persona Generated Distributions for Decision-making**|Jackie Baek et.al.||[2602.06357](http://arxiv.org/abs/2602.06357)|null|
|**2026-02-03**|**MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research**|Yifan Shi et.al.||[2602.03318](http://arxiv.org/abs/2602.03318)|null|
|**2026-02-03**|**ProOPF: Benchmarking and Improving LLMs for Professional-Grade Power Systems Optimization Modeling**|Chao Shen et.al.||[2602.03070](http://arxiv.org/abs/2602.03070)|null|
|**2026-02-03**|**LLM-Inspired Pretrain-Then-Finetune for Small-Data, Large-Scale Optimization**|Zishi Zhang et.al.||[2602.03690](http://arxiv.org/abs/2602.03690)|null|
|**2026-02-02**|**Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation**|Zhongyuan Lyu et.al.||[2602.02029](http://arxiv.org/abs/2602.02029)|null|
|**2026-02-01**|**EvoOpt-LLM: Evolving industrial optimization models with large language models**|Yiliu He et.al.||[2602.01082](http://arxiv.org/abs/2602.01082)|null|
|**2026-01-29**|**NEMO: Execution-Aware Optimization Modeling via Autonomous Coding Agents**|Yang Song et.al.||[2601.21372](http://arxiv.org/abs/2601.21372)|null|
|**2026-01-25**|**Grammar-Aware Literate Generative Mathematical Programming with Compiler-in-the-Loop**|Roberto Rossi et.al.||[2601.17670](http://arxiv.org/abs/2601.17670)|null|
|**2026-01-10**|**SimLLM: Fine-Tuning Code LLMs for SimPy-Based Queueing System Simulation**|Jun-Qi Chen et.al.||[2601.06543](http://arxiv.org/abs/2601.06543)|null|
|**2026-01-09**|**OPT-Engine: Benchmarking the Limits of LLMs in Optimization Modeling via Complexity Scaling**|Yitian Chen et.al.||[2601.19924](http://arxiv.org/abs/2601.19924)|null|
|**2026-01-09**|**Global Optimization for Combinatorial Geometry Problems Revisited in the Era of LLMs**|Timo Berthold et.al.||[2601.05943](http://arxiv.org/abs/2601.05943)|null|
|**2026-01-08**|**NC2C: Automated Convexification of Generic Non-Convex Optimization Problems**|Xinyue Peng et.al.||[2601.04789](http://arxiv.org/abs/2601.04789)|null|
|**2026-01-02**|**LLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization**|Simon Paquette-Greenbaum et.al.||[2601.00770](http://arxiv.org/abs/2601.00770)|null|
|**2025-12-21**|**Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design**|Yuchen Li et.al.|arXiv.org|[2512.18682](http://arxiv.org/abs/2512.18682)|null|
|**2025-12-15**|**Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection**|Francesca Da Ros et.al.|arXiv.org|[2512.13374](http://arxiv.org/abs/2512.13374)|null|
|**2025-12-12**|**A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation**|Hong Je-Gal et.al.|arXiv.org|[2512.11270](http://arxiv.org/abs/2512.11270)|null|
|**2025-11-20**|**An Agent-Based Framework for the Automatic Validation of Mathematical Optimization Models**|Alexander Zadorojniy et.al.|arXiv.org|[2511.16383](http://arxiv.org/abs/2511.16383)|null|
|**2025-11-13**|**LM4Opt-RA: A Multi-Candidate LLM Framework with Structured Ranking for Automating Network Resource Allocation**|Tasnim Ahmed et.al.|arXiv.org|[2512.00039](http://arxiv.org/abs/2512.00039)|null|
|**2025-11-04**|**An LLM-powered MILP modelling engine for workforce scheduling guided by expert knowledge**|Qingyang Li et.al.||[2511.02364](http://arxiv.org/abs/2511.02364)|null|
|**2025-11-01**|**SOCRATES: Simulation Optimization with Correlated Replicas and Adaptive Trajectory Evaluations**|Haoting Zhang et.al.|arXiv.org|[2511.00685](http://arxiv.org/abs/2511.00685)|null|
|**2025-10-31**|**ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling**|Zhuohan Wang et.al.|arXiv.org|[2510.27610](http://arxiv.org/abs/2510.27610)|null|
|**2025-10-21**|**AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library**|Minwei Kong et.al.|arXiv.org|[2510.18428](http://arxiv.org/abs/2510.18428)|null|
|**2025-10-19**|**SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search**|Dong Li et.al.|arXiv.org|[2510.16916](http://arxiv.org/abs/2510.16916)|null|
|**2025-10-12**|**LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems**|Paul-Niklas Ken Kandora et.al.|arXiv.org|[2510.15969](http://arxiv.org/abs/2510.15969)|null|
|**2025-10-05**|**CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling**|Zhengyang Tang et.al.|arXiv.org|[2510.04204](http://arxiv.org/abs/2510.04204)|null|
|**2025-10-03**|**Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation**|Yu-Zhe Shi et.al.|IEEE Transactions on Automation Science and Engineering|[2510.02679](http://arxiv.org/abs/2510.02679)|null|
|**2025-09-29**|**Graph Foundation Models: Bridging Language Model Paradigms and Graph Optimization**|Yunhao Liang et.al.|arXiv.org|[2509.24256](http://arxiv.org/abs/2509.24256)|null|
|**2025-09-28**|**SAC-Opt: Semantic Anchors for Iterative Correction in Optimization Modeling**|Yansen Zhang et.al.||[2510.05115](http://arxiv.org/abs/2510.05115)|null|
|**2025-09-26**|**StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models**|Chenyu Zhou et.al.|arXiv.org|[2509.22558](http://arxiv.org/abs/2509.22558)|null|
|**2025-09-26**|**OptiMind: Teaching LLMs to Think Like Optimization Experts**|Zeyi Chen et.al.|arXiv.org|[2509.22979](http://arxiv.org/abs/2509.22979)|null|
|**2025-09-24**|**OR-Toolformer: Modeling and Solving Operations Research Problems with Tool Augmented Large Language Models**|Jianzhang Zhang et.al.|arXiv.org|[2510.01253](http://arxiv.org/abs/2510.01253)|null|
|**2025-09-24**|**DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs**|WenZhuo Zhu et.al.|arXiv.org|[2511.11576](http://arxiv.org/abs/2511.11576)|null|
|**2025-09-21**|**Large Language Models as End-to-end Combinatorial Optimization Solvers**|Xia Jiang et.al.|arXiv.org|[2509.16865](http://arxiv.org/abs/2509.16865)|null|
|**2025-09-19**|**"It Was a Magical Box": Understanding Practitioner Workflows and Needs in Optimization**|Connor Lawless et.al.|arXiv.org|[2509.16402](http://arxiv.org/abs/2509.16402)|null|
|**2025-09-18**|**Large Language Models in Operations Research: Methods, Applications, and Challenges**|Yang Wang et.al.||[2509.18180](http://arxiv.org/abs/2509.18180)|null|
|**2025-09-10**|**A Systematic Survey on Large Language Models for Evolutionary Optimization: From Modeling to Solving**|Yisong Zhang et.al.|arXiv.org|[2509.08269](http://arxiv.org/abs/2509.08269)|null|
|**2025-09-10**|**Gala: Global LLM Agents for Text-to-Model Translation**|Junyang Cai et.al.||[2509.08970](http://arxiv.org/abs/2509.08970)|null|
|**2025-09-09**|**PersonaFuse: A Personality Activation-Driven Framework for Enhancing Human-LLM Interactions**|Yixuan Tang et.al.|arXiv.org|[2509.07370](http://arxiv.org/abs/2509.07370)|null|
|**2025-08-27**|**LLM-QUBO: An End-to-End Framework for Automated QUBO Transformation from Natural Language Problem Descriptions**|Huixiang Zhang et.al.|Proceedings of the AAAI Symposium Series|[2509.00099](http://arxiv.org/abs/2509.00099)|null|
|**2025-08-25**|**Teaching LLMs to Think Mathematically: A Critical Study of Decision-Making via Optimization**|Mohammad J. Abdel-Rahman et.al.|arXiv.org|[2508.18091](http://arxiv.org/abs/2508.18091)|null|
|**2025-08-24**|**Large Language Model-Based Automatic Formulation for Stochastic Optimization Models**|Amirreza Talebi et.al.|arXiv.org|[2508.17200](http://arxiv.org/abs/2508.17200)|null|
|**2025-08-22**|**Cooperative Design Optimization through Natural Language Interaction**|Ryogo Niwa et.al.|ACM Symposium on User Interface Software and Technology|[2508.16077](http://arxiv.org/abs/2508.16077)|null|
|**2025-08-21**|**R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling**|Raj Jain et.al.|arXiv.org|[2508.15204](http://arxiv.org/abs/2508.15204)|null|
|**2025-08-20**|**Adaptively Robust LLM Inference Optimization under Prediction Uncertainty**|Zixi Chen et.al.|arXiv.org|[2508.14544](http://arxiv.org/abs/2508.14544)|null|
|**2025-08-20**|**Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning**|Beinuo Yang et.al.|arXiv.org|[2508.14410](http://arxiv.org/abs/2508.14410)|null|
|**2025-08-16**|**EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models**|M. Yazdani et.al.|arXiv.org|[2508.11850](http://arxiv.org/abs/2508.11850)|null|
|**2025-08-10**|**CP-Agent: Agentic Constraint Programming**|Stefan Szeider et.al.|arXiv.org|[2508.07468](http://arxiv.org/abs/2508.07468)|null|
|**2025-08-05**|**Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation**|Vinicius Lima et.al.|arXiv.org|[2508.03117](http://arxiv.org/abs/2508.03117)|null|
|**2025-07-23**|**SMARTAPS: Tool-augmented LLMs for Operations Management**|Timothy T. L. Yu et.al.|arXiv.org|[2507.17927](http://arxiv.org/abs/2507.17927)|null|
|**2025-07-20**|**LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading**|C. Lou et.al.|arXiv.org|[2507.14995](http://arxiv.org/abs/2507.14995)|null|
|**2025-07-15**|**Auto-Formulating Dynamic Programming Problems with Large Language Models**|Chenyu Zhou et.al.|arXiv.org|[2507.11737](http://arxiv.org/abs/2507.11737)|null|
|**2025-07-13**|**Fine-tuning Large Language Model for Automated Algorithm Design**|Fei Liu et.al.|arXiv.org|[2507.10614](http://arxiv.org/abs/2507.10614)|null|
|**2025-06-30**|**Performance of LLMS on Stochastic Modeling Operations Research Problems: From Theory to Practice**|Akshit Kumar et.al.|Online World Conference on Soft Computing in Industrial Applications|[2506.23924](http://arxiv.org/abs/2506.23924)|null|
|**2025-06-09**|**REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models**|Diego Forni'es-Tabuenca et.al.|arXiv.org|[2506.07759](http://arxiv.org/abs/2506.07759)|null|
|**2025-06-09**|**HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization**|Hongzheng Chen et.al.|arXiv.org|[2506.07972](http://arxiv.org/abs/2506.07972)|null|
|**2025-06-06**|**DCP-Bench-Open: Evaluating LLMs for Constraint Modelling of Discrete Combinatorial Problems**|Kostis Michailidis et.al.||[2506.06052](http://arxiv.org/abs/2506.06052)|null|
|**2025-06-02**|**ORMind: A Cognitive-Inspired End-to-End Reasoning Framework for Operations Research**|Zhiyuan Wang et.al.|Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 6: Industry Track)|[2506.01326](http://arxiv.org/abs/2506.01326)|**[link](https://github.com/XiaoAI1989/ORMind)**|
|**2025-05-27**|**DualSchool: How Reliable are LLMs for Optimization Education?**|Michael Klamkin et.al.|arXiv.org|[2505.21775](http://arxiv.org/abs/2505.21775)|null|
|**2025-05-21**|**Collaborative Problem-Solving in an Optimization Game**|Isidora Jeknic et.al.|arXiv.org|[2505.15490](http://arxiv.org/abs/2505.15490)|null|
|**2025-05-17**|**Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling**|Yitian Chen et.al.|arXiv.org|[2505.11792](http://arxiv.org/abs/2505.11792)|null|
|**2025-05-15**|**Learning Virtual Machine Scheduling in Cloud Computing through Language Agents**|Jiehao Wu et.al.|arXiv.org|[2505.10117](http://arxiv.org/abs/2505.10117)|null|
|**2025-05-10**|**RideAgent: An LLM-Enhanced Optimization Framework for Automated Taxi Fleet Operations**|Xinyu Jiang et.al.||[2505.06608](http://arxiv.org/abs/2505.06608)|null|
|**2025-05-07**|**Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows**|Wenhao Li et.al.|arXiv.org|[2505.04354](http://arxiv.org/abs/2505.04354)|null|
|**2025-05-04**|**LLM-OptiRA: LLM-Driven Optimization of Resource Allocation for Non-Convex Problems in Wireless Communications**|Xinyue Peng et.al.|arXiv.org|[2505.02091](http://arxiv.org/abs/2505.02091)|null|
|**2025-05-02**|**CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code**|Tasnim Ahmed et.al.|Learning and Intelligent Optimization|[2505.01485](http://arxiv.org/abs/2505.01485)|null|
|**2025-04-23**|**OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents**|Raghav Thind et.al.|arXiv.org|[2504.16918](http://arxiv.org/abs/2504.16918)|null|
|**2025-04-06**|**CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization**|Weiwei Sun et.al.|arXiv.org|[2504.04310](http://arxiv.org/abs/2504.04310)|null|
|**2025-03-27**|**From User Preferences to Optimization Constraints Using Large Language Models**|Manuela Sanguinetti et.al.|arXiv.org|[2503.21360](http://arxiv.org/abs/2503.21360)|null|
|**2025-03-18**|**Fully Automated Generation of Combinatorial Optimisation Systems Using Large Language Models**|Daniel Karapetyan et.al.|arXiv.org|[2503.15556](http://arxiv.org/abs/2503.15556)|null|
|**2025-03-13**|**OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problems with Reasoning LLM**|Bowen Zhang et.al.||[2503.10009](http://arxiv.org/abs/2503.10009)|null|
|**2025-02-22**|**Text2Zinc: A Cross-Domain Dataset for Modeling Optimization and Satisfaction Problems in MiniZinc**|Akash Singirikonda et.al.|arXiv.org|[2503.10642](http://arxiv.org/abs/2503.10642)|null|
|**2025-02-20**|**EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations**|Haotian Zhai et.al.|International Conference on Machine Learning|[2502.14760](http://arxiv.org/abs/2502.14760)|null|
|**2025-02-16**|**OptMATH: A Scalable Bidirectional Data Synthesis Framework for Optimization Modeling**|Hongliang Lu et.al.|International Conference on Machine Learning|[2502.11102](http://arxiv.org/abs/2502.11102)|null|
|**2025-02-14**|**Decision Information Meets Large Language Models: The Future of Explainable Operations Research**|Yansen Zhang et.al.|International Conference on Learning Representations|[2502.09994](http://arxiv.org/abs/2502.09994)|null|
|**2025-01-30**|**Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG Based Approach**|Tianpeng Pan et.al.|Cybersecurity and Cyberforensics Conference|[2501.18320](http://arxiv.org/abs/2501.18320)|null|
|**2025-01-14**|**OptiChat: Bridging Optimization Models and Practitioners with Large Language Models**|Hao Chen et.al.|INFORMS Journal on Data Science|[2501.08406](http://arxiv.org/abs/2501.08406)|null|
|**2024-12-22**|**Evaluating LLM Reasoning in the Operations Research Domain with ORQA**|Mahdi Mostajabdaveh et.al.|arXiv.org|[2412.17874](http://arxiv.org/abs/2412.17874)|null|
|**2024-11-26**|**BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving**|Teng Wang et.al.|Annual Meeting of the Association for Computational Linguistics|[2411.17404](http://arxiv.org/abs/2411.17404)|null|
|**2024-11-03**|**Autoformulation of Mathematical Optimization Models Using LLMs**|Nicolás Astorga et.al.|International Conference on Machine Learning|[2411.01679](http://arxiv.org/abs/2411.01679)|null|
|**2024-10-29**|**Generalists vs. Specialists: Evaluating LLMs on Highly-Constrained Biophysical Sequence Optimization Tasks**|Angelica Chen et.al.|International Conference on Machine Learning|[2410.22296](http://arxiv.org/abs/2410.22296)|null|
|**2024-10-28**|**Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms**|He Yu et.al.|arXiv.org|[2410.20848](http://arxiv.org/abs/2410.20848)|null|
|**2024-10-23**|**AutoRNet: Automatically Optimizing Heuristics for Robust Network Design via Large Language Models**|He Yu et.al.|arXiv.org|[2410.17656](http://arxiv.org/abs/2410.17656)|null|
|**2024-10-17**|**LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch**|Caigao Jiang et.al.|International Conference on Learning Representations|[2410.13213](http://arxiv.org/abs/2410.13213)|null|
|**2024-10-11**|**A Systematic Survey on Large Language Models for Algorithm Design**|Fei Liu et.al.|ACM Computing Surveys|[2410.14716](http://arxiv.org/abs/2410.14716)|null|
|**2024-09-03**|**Leveraging Large Language Models for Solving Rare MIP Challenges**|Teng Wang et.al.|arXiv.org|[2409.04464](http://arxiv.org/abs/2409.04464)|null|
|**2024-08-01**|**A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions**|Ziyang Xiao et.al.|International Joint Conference on Artificial Intelligence|[2508.10047](http://arxiv.org/abs/2508.10047)|null|
|**2024-07-29**|**OptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale**|Ali AhmadiTeshnizi et.al.|arXiv.org|[2407.19633](http://arxiv.org/abs/2407.19633)|null|
|**2024-07-13**|**OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling**|Zhicheng YANG et.al.|International Conference on Learning Representations|[2407.09887](http://arxiv.org/abs/2407.09887)|null|
|**2024-07-09**|**Solving General Natural-Language-Description Optimization Problems with Large Language Models**|Jihai Zhang et.al.|North American Chapter of the Association for Computational Linguistics|[2407.07924](http://arxiv.org/abs/2407.07924)|null|
|**2024-06-23**|**Efficient Evolutionary Search Over Chemical Space with Large Language Models**|Haorui Wang et.al.|International Conference on Learning Representations|[2406.16976](http://arxiv.org/abs/2406.16976)|null|
|**2024-06-16**|**City-LEO: Toward Transparent City Management Using LLM with End-to-End Optimization**|Zihao Jiao et.al.|arXiv.org|[2406.10958](http://arxiv.org/abs/2406.10958)|null|
|**2024-06-15**|**Large Language Models as Surrogate Models in Evolutionary Algorithms: A Preliminary Study**|Hao Hao et.al.|Swarm and Evolutionary Computation|[2406.10675](http://arxiv.org/abs/2406.10675)|null|
|**2024-05-21**|**LLMs for Mathematical Modeling: Towards Bridging the Gap between Natural and Mathematical Languages**|Xuhan Huang et.al.|North American Chapter of the Association for Computational Linguistics|[2405.13144](http://arxiv.org/abs/2405.13144)|null|
|**2024-05-17**|**Large Language Model (LLM) for Telecommunications: A Comprehensive Survey on Principles, Key Techniques, and Opportunities**|Hao Zhou et.al.|IEEE Communications Surveys and Tutorials|[2405.10825](http://arxiv.org/abs/2405.10825)|null|
|**2024-05-16**|**When Large Language Model Meets Optimization**|Sen Huang et.al.|Swarm and Evolutionary Computation|[2405.10098](http://arxiv.org/abs/2405.10098)|null|
|**2024-05-08**|**Automated Conversion of Static to Dynamic Scheduler via Natural Language**|Paul Mingzheng Tang et.al.|arXiv.org|[2405.06697](http://arxiv.org/abs/2405.06697)|null|
|**2024-03-04**|**Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism**|Shuvayan Brahmachary et.al.|Neurocomputing|[2403.02054](http://arxiv.org/abs/2403.02054)|null|
|**2024-03-02**|**LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation**|Zeyuan Ma et.al.|IEEE Transactions on Evolutionary Computation|[2403.01131](http://arxiv.org/abs/2403.01131)|null|
|**2024-03-02**|**LM4OPT: Unveiling the potential of Large Language Models in formulating mathematical optimization problems**|Tasnim Ahmed et.al.|INFOR. Information systems and operational research|[2403.01342](http://arxiv.org/abs/2403.01342)|null|
|**2024-02-26**|**From Large Language Models and Optimization to Decision Optimization CoPilot: A Research Manifesto**|S. Wasserkrug et.al.|arXiv.org|[2402.16269](http://arxiv.org/abs/2402.16269)|null|
|**2024-02-15**|**OptiMUS: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models**|Ali AhmadiTeshnizi et.al.|International Conference on Machine Learning|[2402.10172](http://arxiv.org/abs/2402.10172)|null|
|**2024-01-30**|**Synthetic Dialogue Dataset Generation using LLM Agents**|Yelaman Abdullin et.al.|IEEE Games Entertainment Media Conference|[2401.17461](http://arxiv.org/abs/2401.17461)|null|
|**2024-01-18**|**Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap**|Xingyu Wu et.al.|IEEE Transactions on Evolutionary Computation|[2401.10034](http://arxiv.org/abs/2401.10034)|null|
|**2024-01-06**|**Artificial Intelligence for Operations Research: Revolutionizing the Operations Research Process**|Zhenan Fan et.al.|arXiv.org|[2401.03244](http://arxiv.org/abs/2401.03244)|null|

<p align=right>(<a href=#updated-on-20260210>back to top</a>)</p>

