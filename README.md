## Updated on 2026.02.17
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#llms-for-algorithm-design>LLMs for Algorithm Design</a></li>
    <li><a href=#or-for-generative-ai>OR for Generative AI</a></li>
    <li><a href=#generative-ai-for-or>Generative AI for OR</a></li>
  </ol>
</details>
## LLMs for Algorithm Design

### üÜï Most Recent

| Date | Title | Authors | Affiliation | Code |
|------|-------|---------|-------------|------|
| **2026-02-10** | <details><summary>**ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise**</summary>Kravatskiy et al. introduce ImprovEvolve, a framework that restricts the LLM to evolving `improve()` (local search) and `perturb()` (mutation) operators, which are then executed by a fixed basin-hopping algorithm. They achieve new state-of-the-art results on Hexagon Packing and the Second Autocorrelation Inequality, demonstrating that this modular approach generalizes to unseen problem sizes where monolithic AlphaEvolve solutions fail. The critical insight is that LLMs are poor at designing global search logic and tuning hyperparameters (LLM edits actively harmed performance), so we should isolate the LLM to generating local moves while keeping the meta-heuristic framework deterministic. We should immediately apply this 'operator-only' evolution strategy to our ALNS research for VRP.</details> | Alexey Kravatskiy et.al. | MIRIAI, FusionBrain Lab, Institute of Numerical Mathematics | ‚Äî |
| **2026-02-09** | <details><summary>**G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design**</summary>G-LNS extends LLM-based evolutionary search to ALNS by co-evolving Python code for Destroy and Repair operators rather than constructive priority rules. The authors introduce a 'Synergy Matrix' that tracks the performance of specific operator pairs during evaluation, using this data to guide a 'Synergistic Joint Crossover' where the LLM optimizes the coupling between destroy and repair logic. Results are strong: it significantly outperforms FunSearch and EoH on TSP/CVRP and beats OR-Tools on large-scale instances (N=200) under time constraints. The key takeaway for AlgoEvo is the synergy-aware co-evolution mechanism‚Äîexplicitly tracking and prompting for component interaction is a concrete technique we can apply to multi-agent optimization systems.</details> | Baoyun Zhao et.al. | Tsinghua University, University of Chinese Academy of Sciences, Northeastern University | **[link](https://github.com/zboyn/G-LNS)** |
| **2026-02-09** | <details><summary>**Lyria: A Genetic Algorithm-Driven Neuro-Symbolic Reasoning Framework for LLMs**</summary>Tang et al. propose Lyria, a hybrid evolutionary framework mixing LLM-based and symbolic operators for combinatorial problems, and LAFT, a method to fine-tune smaller models on the evolutionary search traces (e.g., successful crossovers). While their experiments are on toy instances (TSP-10) that offer no evidence of scalability for our VRP work, the LAFT approach provides a concrete mechanism to distill 'search intelligence' into smaller models. We should discuss adapting this fine-tuning strategy to capture the operator logic from our large-scale AlgoEvo runs, potentially improving sample efficiency for future searches.</details> | Weizhi Tang et.al. | University of Edinburgh | ‚Äî |
| **2026-02-09** | <details><summary>**Game-Theoretic Co-Evolution for LLM-Based Heuristic Discovery**</summary>ASRO adapts Policy Space Response Oracles (PSRO) to code generation, treating heuristic discovery as a zero-sum game where a 'Solver' evolves to minimize gaps and a 'Generator' evolves to create adversarial instances. The results are compelling: it consistently beats the static EoH baseline on TSPLIB and CVRPLIB, proving that adversarial training yields better generalization than training on fixed distributions. The critical takeaway is the architecture: explicitly co-evolving an 'Instance Generator' program alongside the solver prevents overfitting and exposes edge cases (like specific geometric traps in TSP) that static benchmarks miss. This is a direct upgrade to our AlgoEvo/AlphaEvolve pipelines, though it incurs higher computational costs due to the evaluation matrix required for the meta-game.</details> | Xinyi Ke et.al. | Tsinghua University, Chinese Academy of Sciences, University of Chinese Academy of Sciences, AiRiA | ‚Äî |
| **2026-02-09** | <details><summary>**MultiMat: Multimodal Program Synthesis for Procedural Materials using Large Multimodal Models**</summary>MultiMat generates procedural material node graphs by interleaving text generation with visual feedback from partial graph execution. The results show that conditioning on the intermediate execution state (rendered image) reduces errors compared to text-only generation. For us, the only transferable insight is the data engineering tactic of transpiling verbose execution formats (like XML) into compact intermediate representations to save context window, and the proof-of-concept for 'execution-state-guided' constructive generation. However, the search method is primitive (backtracking on crash) and offers no value to our evolutionary search research.</details> | Jonas Belouadi et.al. | Adobe Research, University of Mannheim | ‚Äî |

### ‚≠ê Best Papers

| Score | Date | Title | Authors | Affiliation | Code |
|-------|------|-------|---------|-------------|------|
| 30/30 | **2025-06-16** | <details><summary>**AlphaEvolve: A coding agent for scientific and algorithmic discovery**</summary>AlphaEvolve extends FunSearch by evolving entire code files (rather than single functions) using a 'search/replace' diff format and Gemini 2.0, achieving SOTA results across matrix multiplication (beating Strassen), 50+ open math problems, and Google's production scheduling. The results are exceptionally strong and verified, including deployed improvements to Google's Borg scheduler (0.7% resource recovery) and TPU circuits. The critical takeaway is the move to **diff-based full-file evolution** and **meta-prompt evolution** (evolving the prompt instructions alongside the code), which allows the system to modify architecture and logic rather than just heuristics. This is a mandatory blueprint for the next iteration of our AlgoEvo and EvoCut projects.</details> | Alexander Novikov et.al. | Google DeepMind | **[link](https://colab.research.google.com/github/google-deepmind/alphaevolve_results/blob/master/mathematical_results.ipynb)** |
| 29/30 | **2026-01-22** | <details><summary>**Learning to Discover at Test Time**</summary>TTT-Discover introduces a method to fine-tune an LLM (gpt-oss-120b) *during* inference on a single test problem using RL, replacing the frozen-model evolutionary search of AlphaEvolve. They employ a novel 'entropic objective' that optimizes for the single best solution (discovery) rather than expected return, combined with PUCT-based state reuse. The results are empirically rigorous, setting new SOTA on Erd≈ës‚Äô problem, GPU kernel optimization, and AtCoder contests, directly beating AlphaEvolve and ShinkaEvolve. The critical takeaway is that for hard discovery tasks, shifting the model's distribution via online updates is superior to context-based search; we should immediately test their entropic objective in our AlgoEvo pipeline.</details> | Mert Yuksekgonul et.al. | Stanford University, NVIDIA, UC San Diego, Together AI, Astera Institute | **[link](https://github.com/test-time-training/discover)** |
| 28/30 | **2026-02-02** | <details><summary>**DeltaEvolve: Accelerating Scientific Discovery through Momentum-Driven Evolution**</summary>DeltaEvolve replaces the standard full-code history in evolutionary search with 'semantic deltas'‚Äîstructured text summaries capturing the 'from/to' logic of modifications and their hypotheses. Across 5 domains (including BBOB and Symbolic Regression), they demonstrate superior objective scores over AlphaEvolve while reducing token consumption by ~37%. The critical takeaway is the 'Progressive Disclosure' mechanism: treating history as a momentum vector (deltas) rather than a state archive (snapshots) allows us to fit a deeper evolutionary trajectory into the context window. We should immediately test their 'Delta Plan' prompt structure in AlgoEvo to improve sample efficiency and reduce costs.</details> | Jiachen Jiang et.al. | Microsoft, The Ohio State University | ‚Äî |
| 28/30 | **2025-12-30** | <details><summary>**LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm**</summary>LoongFlow replaces the standard stochastic mutation operator in LLM evolutionary search with a 'Plan-Execute-Summarize' (PES) cognitive loop. Instead of random code changes, a Planner retrieves the 'intent' and 'summary' of the parent solution's lineage to generate a directed hypothesis, which is then executed and summarized for the next generation. The authors demonstrate a 60% reduction in evaluations and a 100% success rate on AlphaEvolve tasks where standard methods fail or stagnate. The critical takeaway is the 'Lineage-Based Context Retrieval' mechanism: explicitly passing the parent's plan and retrospective summary to the child allows for directed rather than random walks in the search space. We must implement this PES loop in AlgoEvo immediately to fix our sample efficiency issues.</details> | Chunhui Wan et.al. |  | **[link](https://github.com/baidu-baige/LoongFlow)** |
| 28/30 | **2025-11-28** | <details><summary>**ThetaEvolve: Test-time Learning on Open Problems**</summary>ThetaEvolve integrates test-time reinforcement learning (GRPO) directly into an AlphaEvolve-style loop, allowing a single 8B model to learn from its own successful mutations and achieve new SOTA bounds on Circle Packing and Autocorrelation inequalities. The results are rigorous, showing that RL applied to the *dynamic* environment (sampling from the evolving database) vastly outperforms RL on static prompts or pure inference search. The most stealable insight is the 'lazy penalty' mechanism‚Äîpenalizing semantically equivalent code or stagnation‚Äîwhich forces the RL policy to learn genuine exploration strategies rather than memorization. This is a blueprint for the 'RL-infused evolution' milestone in our AlgoEvo roadmap.</details> | Yiping Wang et.al. | Microsoft, University of Washington, Carnegie Mellon University, University of Wisconsin-Madison, University of California, San Diego | **[link](https://github.com/ypwang61/ThetaEvolve)** |

### üî¨ Research Fronts

| Status | Front Name | Papers | Key Methods | Problems |
|--------|-----------|--------|-------------|----------|
| Emerging | Meta-Evolutionary LLM Architectures for Algorithm and Heuristic Discovery | 25 | Llm Code Generation, Llm As Heuristic, Program Synthesis | Heuristic Evolution, Operator Discovery |
| Emerging | Advanced AlphaEvolve Frameworks for Sample-Efficient Algorithmic Discovery | 18 | Llm Code Generation, Llm Evolutionary Search, Program Synthesis | Algorithm Discovery, Circle Packing |
| Emerging | LLM-Driven Evolutionary Algorithm Design: Structural Co-evolution, Reflection, and RL-Tuning | 13 | Program Synthesis, Llm Evolutionary Search, Llm As Heuristic | Heuristic Evolution, Tsp |
| Stable | Architectural Innovations in LLM-Driven Evolution of Heuristics | 8 | Llm Code Generation, Evolution Of Heuristics, Llm As Heuristic | Combinatorial Optimization, Tsp |
| Declining | LLaMEA Enhancements for Automated Algorithm Design with Explainable AI and Landscape Analysis | 3 | Llm Evolutionary Search, Llm Code Generation, Llamea | Black Box Optimization, Heuristic Evolution |

<details>
<summary>üìã Full list (107 papers, sorted by date)</summary>

| Score | Date | Title | Authors | Affiliation | Venue | PDF | Code |
|-------|------|-------|---------|-------------|-------|-----|------|
| 21/30 | **2026-02-10** | <details><summary>**ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise**</summary>Kravatskiy et al. introduce ImprovEvolve, a framework that restricts the LLM to evolving `improve()` (local search) and `perturb()` (mutation) operators, which are then executed by a fixed basin-hopping algorithm. They achieve new state-of-the-art results on Hexagon Packing and the Second Autocorrelation Inequality, demonstrating that this modular approach generalizes to unseen problem sizes where monolithic AlphaEvolve solutions fail. The critical insight is that LLMs are poor at designing global search logic and tuning hyperparameters (LLM edits actively harmed performance), so we should isolate the LLM to generating local moves while keeping the meta-heuristic framework deterministic. We should immediately apply this 'operator-only' evolution strategy to our ALNS research for VRP.</details> | Alexey Kravatskiy et.al. | MIRIAI, FusionBrain Lab, Institute of Numerical Mathematics |  | [2602.10233](http://arxiv.org/abs/2602.10233) | ‚Äî |
| 25/30 | **2026-02-09** | <details><summary>**G-LNS: Generative Large Neighborhood Search for LLM-Based Automatic Heuristic Design**</summary>G-LNS extends LLM-based evolutionary search to ALNS by co-evolving Python code for Destroy and Repair operators rather than constructive priority rules. The authors introduce a 'Synergy Matrix' that tracks the performance of specific operator pairs during evaluation, using this data to guide a 'Synergistic Joint Crossover' where the LLM optimizes the coupling between destroy and repair logic. Results are strong: it significantly outperforms FunSearch and EoH on TSP/CVRP and beats OR-Tools on large-scale instances (N=200) under time constraints. The key takeaway for AlgoEvo is the synergy-aware co-evolution mechanism‚Äîexplicitly tracking and prompting for component interaction is a concrete technique we can apply to multi-agent optimization systems.</details> | Baoyun Zhao et.al. | Tsinghua University, University of Chinese Academy of Sciences, Northeastern University |  | [2602.08253](http://arxiv.org/abs/2602.08253) | **[link](https://github.com/zboyn/G-LNS)** |
| 16/30 | **2026-02-09** | <details><summary>**Lyria: A Genetic Algorithm-Driven Neuro-Symbolic Reasoning Framework for LLMs**</summary>Tang et al. propose Lyria, a hybrid evolutionary framework mixing LLM-based and symbolic operators for combinatorial problems, and LAFT, a method to fine-tune smaller models on the evolutionary search traces (e.g., successful crossovers). While their experiments are on toy instances (TSP-10) that offer no evidence of scalability for our VRP work, the LAFT approach provides a concrete mechanism to distill 'search intelligence' into smaller models. We should discuss adapting this fine-tuning strategy to capture the operator logic from our large-scale AlgoEvo runs, potentially improving sample efficiency for future searches.</details> | Weizhi Tang et.al. | University of Edinburgh |  | [2507.04034](http://arxiv.org/abs/2507.04034) | ‚Äî |
| 27/30 | **2026-02-09** | <details><summary>**Game-Theoretic Co-Evolution for LLM-Based Heuristic Discovery**</summary>ASRO adapts Policy Space Response Oracles (PSRO) to code generation, treating heuristic discovery as a zero-sum game where a 'Solver' evolves to minimize gaps and a 'Generator' evolves to create adversarial instances. The results are compelling: it consistently beats the static EoH baseline on TSPLIB and CVRPLIB, proving that adversarial training yields better generalization than training on fixed distributions. The critical takeaway is the architecture: explicitly co-evolving an 'Instance Generator' program alongside the solver prevents overfitting and exposes edge cases (like specific geometric traps in TSP) that static benchmarks miss. This is a direct upgrade to our AlgoEvo/AlphaEvolve pipelines, though it incurs higher computational costs due to the evaluation matrix required for the meta-game.</details> | Xinyi Ke et.al. | Tsinghua University, Chinese Academy of Sciences, University of Chinese Academy of Sciences, AiRiA |  | [2601.22896](http://arxiv.org/abs/2601.22896) | ‚Äî |
| 8/30 | **2026-02-09** | <details><summary>**MultiMat: Multimodal Program Synthesis for Procedural Materials using Large Multimodal Models**</summary>MultiMat generates procedural material node graphs by interleaving text generation with visual feedback from partial graph execution. The results show that conditioning on the intermediate execution state (rendered image) reduces errors compared to text-only generation. For us, the only transferable insight is the data engineering tactic of transpiling verbose execution formats (like XML) into compact intermediate representations to save context window, and the proof-of-concept for 'execution-state-guided' constructive generation. However, the search method is primitive (backtracking on crash) and offers no value to our evolutionary search research.</details> | Jonas Belouadi et.al. | Adobe Research, University of Mannheim | ICLR 2026 (poster) | [2509.22151](http://arxiv.org/abs/2509.22151) | ‚Äî |
| 21/30 | **2026-02-05** | <details><summary>**Mining Generalizable Activation Functions**</summary>Vitvitskyi et al. (DeepMind) utilize AlphaEvolve to discover novel activation functions by evolving Python code on small, synthetic datasets explicitly designed to test OOD generalization (e.g., polynomials, Feynman equations). The results are credible and backed by downstream transfer: discovered functions like `GELU * (1 + 0.5 sinc(x))` outperform baselines on algorithmic reasoning tasks (CLRS-30) while matching standard vision benchmarks. **Key Takeaway:** The 'Small-Scale Lab' methodology‚Äîoptimizing on cheap, synthetic proxy tasks to find generalizable logic‚Äîis a validated strategy to bypass the computational bottleneck of evaluating evolved candidates on large-scale instances. We should steal this 'proxy evolution' setup for AlgoEvo to drastically reduce evaluation costs while targeting generalization in VRP heuristics.</details> | Alex Vitvitskyi et.al. | Google DeepMind |  | [2602.05688](http://arxiv.org/abs/2602.05688) | **[link](https://github.com/Aastha2104/Parkinson-Disease-Prediction)** |
| 24/30 | **2026-02-04** | <details><summary>**Landscape-aware Automated Algorithm Design: An Efficient Framework for Real-world Optimization**</summary>Yin et al. introduce a framework that decouples algorithm discovery from expensive evaluations by using Genetic Programming to evolve symbolic proxy functions that statistically match the target problem's landscape (via ELA features). Empirical results on photonics problems confirm that algorithms evolved on these cheap proxies transfer successfully to the real tasks, outperforming standard baselines like LSHADE with only 50√óD real evaluations. **Key Takeaway:** We can synthesize 'symbolic gyms' that statistically mimic our target problems to run thousands of LLM iterations at near-zero cost. This directly addresses the sample efficiency bottleneck in AlgoEvo and suggests we should move beyond standard neural surrogates to evolved symbolic proxies.</details> | Haoran Yin et.al. |  |  | [2602.04529](http://arxiv.org/abs/2602.04529) | **[link](10.5281/zenodo.18385405)** |
| 19/30 | **2026-02-04** | <details><summary>**ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas**</summary>ProxyWar introduces a tournament-based evaluation framework for LLM-generated code, using TrueSkill ratings from game simulations (Sudoku, Poker, etc.) instead of static unit tests. The results are robust (10k+ matches) and reveal a low correlation between Pass@1 and actual win rates; notably, 'reasoning' models like DeepSeek-R1 crush 'coding' models like Qwen-Coder in strategic tasks despite lower static scores. For our evolutionary search work, this confirms that we must move beyond static benchmarks to dynamic, competitive evaluation signals to avoid optimizing for syntax over strategy. We should also prioritize reasoning models over code-specialized ones for our agentic logic generation.</details> | Wenjun Peng et.al. |  |  | [2602.04296](http://arxiv.org/abs/2602.04296) | **[link](https://github.com/xinke-wang/ProxyWar)** |
| 26/30 | **2026-02-03** | <details><summary>**Contrastive Concept-Tree Search for LLM-Assisted Algorithm Discovery**</summary>The authors introduce Contrastive Concept-Tree Search (CCTS), which modifies the standard evolutionary loop by prompting the LLM to extract semantic 'concepts' from every generated program, building a dynamic hierarchy. They then apply a Tree-structured Parzen Estimator (TPE) to these concepts to learn a contrastive utility model (p(concept&#124;good)/p(concept&#124;bad)), using this to bias parent selection towards promising algorithmic strategies. Results are rigorous, showing consistent improvements over k-elite baselines on combinatorial tasks like Circle Packing, with a synthetic ablation confirming the model learns ground-truth concept utilities. **Key Takeaway:** We should immediately implement the 'Concept TPE' loop in AlgoEvo‚Äîasking the LLM to tag generated heuristics with concepts and maintaining a weight vector over these concepts provides a cheap, interpretable 'process reward model' to guide search.</details> | Timothee Leleu et.al. |  |  | [2602.03132](http://arxiv.org/abs/2602.03132) | ‚Äî |
| 19/30 | **2026-02-03** | <details><summary>**Persona Generators: Generating Diverse Synthetic Personas at Scale**</summary>Paglieri et al. (DeepMind) apply AlphaEvolve to optimize Python code that generates synthetic personas, explicitly maximizing diversity metrics (convex hull, coverage) in embedding space rather than just fidelity. They achieve >80% coverage of the behavioral space compared to <50% for baselines, proving that evolving the *generator function* is more effective than prompting for diversity. The key takeaway is their two-stage architecture (autoregressive high-level trait generation $\to$ parallel detail expansion), which we should steal to evolve 'Solution Generators' for VRP/OR that inherently resist mode collapse. This validates our direction with AlgoEvo but offers a concrete architectural pattern for maintaining population diversity.</details> | Davide Paglieri et.al. | Google DeepMind |  | [2602.03545](http://arxiv.org/abs/2602.03545) | ‚Äî |
| 28/30 | **2026-02-02** | <details><summary>**DeltaEvolve: Accelerating Scientific Discovery through Momentum-Driven Evolution**</summary>DeltaEvolve replaces the standard full-code history in evolutionary search with 'semantic deltas'‚Äîstructured text summaries capturing the 'from/to' logic of modifications and their hypotheses. Across 5 domains (including BBOB and Symbolic Regression), they demonstrate superior objective scores over AlphaEvolve while reducing token consumption by ~37%. The critical takeaway is the 'Progressive Disclosure' mechanism: treating history as a momentum vector (deltas) rather than a state archive (snapshots) allows us to fit a deeper evolutionary trajectory into the context window. We should immediately test their 'Delta Plan' prompt structure in AlgoEvo to improve sample efficiency and reduce costs.</details> | Jiachen Jiang et.al. | Microsoft, The Ohio State University |  | [2602.02919](http://arxiv.org/abs/2602.02919) | ‚Äî |
| 21/30 | **2026-02-02** | <details><summary>**Automatic Design of Optimization Test Problems with Large Language Models**</summary>Achtelik et al. adapt LLM-driven evolutionary search (EoH) to generate interpretable Python functions that match specific landscape features (ELA), effectively creating synthetic benchmarks on demand. Unlike prior neural network approaches that fail to scale, this method performs robustly in higher dimensions (3D-5D) and produces portable code. The key takeaway is the capability to procedurally generate 'hard' or specific-property instances; we should immediately adopt this to create a dynamic training curriculum for AlgoEvo, ensuring our evolved metaheuristics generalize beyond standard libraries like BBOB.</details> | Wojciech Achtelik et.al. | AGH University of Krakow, Warsaw University of Technology |  | [2602.02724](http://arxiv.org/abs/2602.02724) | **[link](https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020)** |
| 24/30 | **2026-02-01** | <details><summary>**Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization**</summary>E2OC introduces a hierarchical search framework where MCTS optimizes 'design thoughts' (textual strategies) rather than raw code, subsequently using these strategies to guide a coordinate-descent-style evolution of interdependent operators. While the computational cost is high due to the inner-loop operator rotation, the results on FJSP/TSP (+20% HV vs expert) and comparisons against FunSearch/EoH demonstrate that explicitly modeling operator coupling is superior to isolated evolution. The critical takeaway for us is the **'strategy-first' search layer**: evolving a semantic blueprint for component interaction *before* code generation prevents the local optima trap of independent component optimization, a technique we should immediately test in AlgoEvo.</details> | Junhao Qiu et.al. |  |  | [2601.17899](http://arxiv.org/abs/2601.17899) | **[link](null)** |
| 24/30 | **2026-01-29** | <details><summary>**READY: Reward Discovery for Meta-Black-Box Optimization**</summary>READY introduces a multi-task evolutionary framework where LLMs evolve reward functions for multiple MetaBBO algorithms simultaneously, utilizing explicit 'Knowledge Transfer' operators to translate successful logic between distinct tasks. The results are robust, demonstrating superior performance over Eureka and EoH on BBOB benchmarks with a 2-4x reduction in search time due to parallelization and shared heuristics. The most stealable insights are the 'History-Reflection' operator‚Äîwhich prompts the LLM to extrapolate trends from the evolutionary trajectory rather than just mutating the current state‚Äîand the cross-niche transfer mechanism, both of which should be implemented in our multi-agent optimization stack immediately.</details> | Zechuan Huang et.al. |  |  | [2601.21847](http://arxiv.org/abs/2601.21847) | **[link](https://anonymous.4open.science/r/ICML_READY-747F)** |
| 26/30 | **2026-01-29** | <details><summary>**LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from Explainable AI**</summary>LLaMEA-SAGE augments LLM-based evolutionary search by extracting AST features (complexity, graph metrics) from generated code, training a surrogate model to predict fitness from these features, and using SHAP analysis to generate natural language prompts that guide the LLM to modify specific structural properties (e.g., 'increase cyclomatic complexity'). On the MA-BBOB benchmark, it outperforms state-of-the-art methods (MCTS-AHD, LHNS) and converges faster than vanilla LLaMEA, although the authors honestly report that statistical significance was limited (p=0.44) due to small sample sizes (5 runs). The critical takeaway for us is the pipeline of using static code analysis as a feedback signal‚Äîwe can immediately steal this 'SAGE' loop to guide AlgoEvo or EvoCut by telling the LLM *how* to structurally mutate code based on surrogate correlations, rather than just hoping for random improvements.</details> | Niki van Stein et.al. |  |  | [2601.21511](http://arxiv.org/abs/2601.21511) | **[link](https://anonymous.4open.science/r/LLaMEA-SAGE/README.md)** |
| 27/30 | **2026-01-29** | <details><summary>**TIDE: Tuning-Integrated Dynamic Evolution for LLM-Based Automated Heuristic Design**</summary>TIDE introduces a nested evolutionary framework that strictly decouples algorithmic structure generation (via LLM) from numerical parameter tuning (via Differential Evolution), managed by a Tree Similarity Edit Distance (TSED) guided island model. Results on 9 COPs (TSP, BPP, etc.) show it consistently outperforms ReEvo and EoH, primarily because the DE layer optimizes constants at zero token cost, preventing the discard of structurally sound but poorly tuned heuristics. The critical takeaway is the necessity of a gradient-free tuning layer for LLM-generated code; relying on LLMs for numerical constants is inefficient and imprecise. We should immediately implement a similar parameter-tuning inner loop in our AlgoEvo framework.</details> | Chentong Chen et.al. |  |  | [2601.21239](http://arxiv.org/abs/2601.21239) | ‚Äî |
| 24/30 | **2026-01-29** | <details><summary>**PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs**</summary>PathWise reformulates heuristic discovery as a sequential planning problem over an 'Entailment Graph,' where a Policy Agent generates high-level evolutionary directives (rationales) and a World Model executes the code, guided by specific Critic reflections. The results are robust: it outperforms ReEvo, FunSearch, and MCTS-AHD on TSP, CVRP, and Bin Packing while using half the evaluation budget (500 vs 1000), demonstrating genuine sample efficiency. The key takeaway is the **Entailment Graph** structure: explicitly storing the *derivation rationale* and lineage allows the LLM to reason about the search trajectory and avoid redundant failures, a mechanism we should immediately adapt for AlgoEvo to fix our memory bottleneck.</details> | Oguzhan Gungordu et.al. |  |  | [2601.20539](http://arxiv.org/abs/2601.20539) | ‚Äî |
| 24/30 | **2026-01-28** | <details><summary>**Magellan: Autonomous Discovery of Novel Compiler Optimization Heuristics with AlphaEvolve**</summary>Magellan couples AlphaEvolve with a black-box autotuner (Vizier) to evolve C++ compiler heuristics, achieving >5% binary size reduction in LLVM and beating both human experts and prior neural policies. The results are rigorous, validated on production workloads and showing temporal generalization. **The critical takeaway is the 'Hierarchical Search' strategy:** rather than asking the LLM to write fully specified code, they prompt it to generate *templates* with exposed parameters (flags), delegating numerical tuning to a cheap external optimizer. This directly addresses the sample efficiency issues we face in AlgoEvo; we should immediately steal this architecture to separate structural evolution from parameter tuning.</details> | Hongzheng Chen et.al. | Google DeepMind, Google, Cornell University |  | [2601.21096](http://arxiv.org/abs/2601.21096) | ‚Äî |
| 20/30 | **2026-01-27** | <details><summary>**Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A Search**</summary>This paper introduces 'Algorithmic-Contextual EoH' (A-CEoH), which injects the actual source code of the search algorithm (e.g., the A* driver loop, neighbor generation) into the LLM prompt alongside the problem description. Experiments on the Unit-Load Pre-Marshalling Problem and Sliding Puzzle Problem demonstrate that this algorithmic context allows a 32B parameter model (Qwen2.5-Coder) to generate heuristics superior to those from GPT-4o and human experts. The results are credible and backed by comparisons against optimal baselines. The key takeaway is a transferable 'prompt trick': explicitly showing the LLM the code that *calls* its generated function aligns the heuristic significantly better with the search dynamics than natural language descriptions alone. We should immediately test injecting our ALNS/search driver code into our evolutionary prompt templates.</details> | Thomas B√∂mer et.al. |  | EvoStar conference; Code: https://github | [2601.19622](http://arxiv.org/abs/2601.19622) | **[link](https://github.com/tb-git-tud/a-ceoh-evolution-of-heuristics)** |
| 21/30 | **2026-01-27** | <details><summary>**CASTER: Breaking the Cost-Performance Barrier in Multi-Agent Orchestration via Context-Aware Strategy for Task Efficient Routing**</summary>CASTER implements a context-aware neural router for multi-agent systems that dynamically selects between weak and strong models, reducing inference costs by ~72% compared to a GPT-4o-only baseline. The authors validate this on a custom benchmark across four domains, showing it outperforms cascading strategies (FrugalGPT) by avoiding the 'double-billing' of failed weak calls. The standout takeaway for us is the 'On-Policy Negative Feedback' mechanism: training the router by explicitly relabeling instances where the weak model failed as 'Strong-Required'. We should adapt this active learning logic to train our proxy reward models in AlgoEvo, allowing us to reliably offload expensive evaluations to cheaper proxies without manual annotation.</details> | Shanyv Liu et.al. | University of Houston, China University of Petroleum (East China), Southwest Jiaotong University |  | [2601.19793](http://arxiv.org/abs/2601.19793) | ‚Äî |
| 20/30 | **2026-01-23** | <details><summary>**The Art of Being Difficult: Combining Human and AI Strengths to Find Adversarial Instances for Heuristics**</summary>This paper applies FunSearch to generate adversarial instances for classical OR heuristics (Knapsack, Bin Packing, k-median), successfully breaking long-standing theoretical lower bounds. The results are rigorous: they disprove the output-polynomial time of the Nemhauser-Ullmann algorithm and improve the Best-Fit bin packing bound to 1.5. The key takeaway for our AlgoEvo work is the workflow: the LLM finds 'messy' structural patterns (e.g., repeated floats) which humans then manually generalize into asymptotic proofs. This validates Program Search over vector search but exposes the 'generalization gap'‚Äîwe should implement a post-processing agent to automate this manual refinement step.</details> | Henri Nikoleit et.al. | Google DeepMind, University of Bonn, University of Manitoba |  | [2601.16849](http://arxiv.org/abs/2601.16849) | **[link](https://github.com/lumi-a/funsearch)** |
| 24/30 | **2026-01-23** | <details><summary>**Scaling the Scaling Logic: Agentic Meta-Synthesis of Logic Reasoning**</summary>Liu et al. introduce SS-Logic, an agentic framework that evolves Python 'Generator-Validator' pairs to scale logic task families, using a rigorous 'Code-Augmented Blind Review' where independent agents must write code to solve generated tasks to verify their validity. They expand 400 seed families to over 21k instances, achieving consistent gains on AIME (+3.0) and SynLogic (+5.2) via RLVR. **Crucial Takeaway:** We should steal the 'Blind Review' mechanism for AlgoEvo‚Äîusing the solvability of a generated problem (by an independent code agent) as a strict fitness filter for the generator itself. This directly addresses our bottleneck in filtering invalid or hallucinated heuristics during evolutionary search.</details> | Bowen Liu et.al. | Tencent, The Hong Kong University of Science and Technology (Guangzhou) |  | [2602.13218](http://arxiv.org/abs/2602.13218) | **[link](https://github.com/AdAstraAbyssoque/Scaling-the-Scaling-Logic)** |
| 20/30 | **2026-01-22** | <details><summary>**LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling**</summary>LLM4DRD employs a dual-agent framework (Generator & Evaluator) to evolve priority dispatching rules for dynamic flexible assembly flow shops. The core contribution is the **Hybrid Evaluation** mechanism, where the Evaluator generates qualitative critiques (strengths/weaknesses) that are injected into the Generator's prompts to guide specific operators like 'Dominance-Fusion Crossover' and 'Directed Optimization.' Empirical results show it outperforms FunSearch and EOH, avoiding the premature convergence seen in other methods. The most stealable insight is the prompt structure for crossover: rather than blindly combining code, it uses the Evaluator's analysis of parent strengths to direct the merger, a technique we should implement to improve sample efficiency in our evolutionary search.</details> | Junhao Qiu et.al. |  |  | [2601.15738](http://arxiv.org/abs/2601.15738) | ‚Äî |
| 29/30 | **2026-01-22** | <details><summary>**Learning to Discover at Test Time**</summary>TTT-Discover introduces a method to fine-tune an LLM (gpt-oss-120b) *during* inference on a single test problem using RL, replacing the frozen-model evolutionary search of AlphaEvolve. They employ a novel 'entropic objective' that optimizes for the single best solution (discovery) rather than expected return, combined with PUCT-based state reuse. The results are empirically rigorous, setting new SOTA on Erd≈ës‚Äô problem, GPU kernel optimization, and AtCoder contests, directly beating AlphaEvolve and ShinkaEvolve. The critical takeaway is that for hard discovery tasks, shifting the model's distribution via online updates is superior to context-based search; we should immediately test their entropic objective in our AlgoEvo pipeline.</details> | Mert Yuksekgonul et.al. | Stanford University, NVIDIA, UC San Diego, Together AI, Astera Institute |  | [2601.16175](http://arxiv.org/abs/2601.16175) | **[link](https://github.com/test-time-training/discover)** |
| 22/30 | **2026-01-22** | <details><summary>**Online Operator Design in Evolutionary Optimization for Flexible Job Shop Scheduling via Large Language Models**</summary>LLM4EO embeds an LLM directly into the Genetic Algorithm loop to dynamically generate and replace gene-selection operators whenever the population stagnates, rather than training them offline. Results on FJSP benchmarks (Brandimarte, Fattahi) show a 3-4% improvement over static GA and GP, with convergence plots demonstrating that LLM interventions successfully break local optima. The most stealable insight is the 'Perception and Analysis' prompt structure: it forces the LLM to explicitly diagnose *why* the current population is stuck (based on fitness stats) before generating new code, a mechanism we should port to AlgoEvo to handle search stagnation. This validates the viability of online, state-aware LLM intervention in OR scheduling problems.</details> | Rongjie Liao et.al. | City University of Hong Kong, Guangdong University of Technology |  | [2511.16485](http://arxiv.org/abs/2511.16485) | ‚Äî |
| 21/30 | **2026-01-15** | <details><summary>**Global Optimization for Combinatorial Geometry Problems Revisited in the Era of LLMs**</summary>Berthold et al. demonstrate that standard global NLP solvers (SCIP, Xpress) outperform DeepMind's AlphaEvolve on its own benchmarks (circle/hexagon packing, min-max distance) without any learning or evolution. The results are rigorous, improving on 'newly discovered' solutions within minutes using default solver settings. **CRITICAL TAKEAWAY:** We must validate our AlgoEvo results against classical global solvers to ensure we aren't claiming 'discovery' on problems that are trivial for SCIP; furthermore, it suggests a hybrid path where LLMs generate NLP models for solvers rather than evolving raw heuristic code. This is a necessary reality check for our benchmarking strategy.</details> | Timo Berthold et.al. |  |  | [2601.05943](http://arxiv.org/abs/2601.05943) | ‚Äî |
| 23/30 | **2026-01-09** | <details><summary>**Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer**</summary>Zhang et al. introduce the 'Discrete Transformer,' a constrained architecture that learns algorithmic tasks via gradient descent and allows for the post-hoc extraction of exact, human-readable Python code. By enforcing functional disentanglement (using attention strictly for routing and MLPs for arithmetic) and employing temperature-annealed sampling, they recover symbolic laws for arithmetic and physics tasks with near-zero error. The critical takeaway is their 'continuous-to-discrete homotopy' strategy‚Äîannealing from soft to hard selection during training‚Äîwhich enables differentiable search to converge on discrete, symbolic solutions. This suggests a viable path to discover heuristics via continuous optimization rather than purely stochastic LLM evolution.</details> | Yifan Zhang et.al. |  | arXiv.org | [2601.05770](http://arxiv.org/abs/2601.05770) | ‚Äî |
| 24/30 | **2026-01-06** | <details><summary>**CodeEvolve: an open source evolutionary coding agent for algorithm discovery and optimization**</summary>CodeEvolve couples islands-based genetic algorithms with LLMs, utilizing CVT-MAP-Elites for diversity and a specific 'inspiration-based' crossover operator where the LLM integrates logic from high-ranking peer solutions. The results are strong and backed by numbers: they beat AlphaEvolve on 5/9 benchmarks and demonstrate that Qwen3-Coder-30B matches Gemini-2.5 performance at ~10% of the cost. The single most useful takeaway is the implementation of the 'inspiration' operator and the necessity of MAP-Elites over simple elitism to escape local optima in code space. We should immediately benchmark their open-source framework against our internal AlgoEvo builds.</details> | Henrique Assump√ß√£o et.al. | Inter&Co., Worcester Polytechnic Institute, Universidade Federal de Minas Gerais | arXiv.org | [2510.14150](http://arxiv.org/abs/2510.14150) | **[link](https://github.com/inter-co/science-codeevolve)** |
| 28/30 | **2025-12-30** | <details><summary>**LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm**</summary>LoongFlow replaces the standard stochastic mutation operator in LLM evolutionary search with a 'Plan-Execute-Summarize' (PES) cognitive loop. Instead of random code changes, a Planner retrieves the 'intent' and 'summary' of the parent solution's lineage to generate a directed hypothesis, which is then executed and summarized for the next generation. The authors demonstrate a 60% reduction in evaluations and a 100% success rate on AlphaEvolve tasks where standard methods fail or stagnate. The critical takeaway is the 'Lineage-Based Context Retrieval' mechanism: explicitly passing the parent's plan and retrospective summary to the child allows for directed rather than random walks in the search space. We must implement this PES loop in AlgoEvo immediately to fix our sample efficiency issues.</details> | Chunhui Wan et.al. |  | arXiv.org | [2512.24077](http://arxiv.org/abs/2512.24077) | **[link](https://github.com/baidu-baige/LoongFlow)** |
| 25/30 | **2025-12-22** | <details><summary>**Mathematical exploration and discovery at scale**</summary>DeepMind applies AlphaEvolve to 67 math problems, formalizing the distinction between 'Search Mode' (evolving heuristics for fixed instances) and 'Generalizer Mode' (evolving algorithms that extrapolate from small to large n). Results are rigorous, establishing new bounds on Kakeya sets and 10+ other problems by exploiting verifier loopholes and heuristic specialization. The most critical takeaway for AlgoEvo is Section 44: evolving code that *calls* other LLMs leads to emergent prompt optimization and injection strategies, suggesting a path for our multi-agent optimization work. We must adopt their 'Generalizer' training curriculum (train on small n, test on large n) to fix our scalability bottlenecks.</details> | Bogdan Georgiev et.al. | Google DeepMind, UCLA, Brown University, Institute for Advanced Study | arXiv.org | [2511.02864](http://arxiv.org/abs/2511.02864) | **[link](https://colab.research.google.com/github/google-deepmind/alphaevolve_results/blob/master/mathematical_results.ipynb)** |
| 26/30 | **2025-12-22** | <details><summary>**Let the Barbarians In: How AI Can Accelerate Systems Performance Research**</summary>Cheng et al. (UC Berkeley) perform a rigorous empirical evaluation of LLM evolutionary search (ADRS) across 10 systems problems, achieving SOTA results on MoE load balancing (13x speedup via rediscovering Hamilton's Apportionment) and cloud scheduling. The results are real and backed by code, comparing frameworks like OpenEvolve, GEPA, and ShinkaEvolve. **Key Takeaway:** Their 'Best Practices' section offers concrete engineering constraints we should adopt: specifically, that 'moderate' feedback (worst-k cases) outperforms 'detailed' feedback (prevents overfitting), and that restricting mutations to diff-based edits is essential to prevent reward hacking. This paper validates our core research thesis while providing the benchmarks we now need to beat.</details> | Audrey Cheng et.al. | UC Berkeley | arXiv.org | [2512.14806](http://arxiv.org/abs/2512.14806) | **[link](https://github.com/codelion/openevolve)** |
| 23/30 | **2025-12-19** | <details><summary>**Reinforced Generation of Combinatorial Structures: Hardness of Approximation**</summary>Nagda et al. utilize AlphaEvolve to discover combinatorial gadgets that improve hardness of approximation bounds for MAX-CUT and TSP, validating findings with formal proofs. The standout contribution is not the hardness results themselves, but the methodology: they tasked AlphaEvolve with optimizing the *verification code* (checking correctness against a slow ground truth), achieving a 10,000x speedup that enabled searching gadgets of size 19 (vs. 11 previously). We should immediately adopt this 'evolve the verifier' loop for our computationally expensive fitness functions in AlgoEvo to break current scalability limits.</details> | Ansh Nagda et.al. | Google DeepMind, Google, University of California, Berkeley |  | [2509.18057](http://arxiv.org/abs/2509.18057) | ‚Äî |
| 26/30 | **2025-12-17** | <details><summary>**EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery**</summary>EvoLattice replaces the standard 'overwrite-based' evolution of monolithic programs with a persistent DAG where each node holds multiple alternative implementations, evaluating all valid combinatorial paths to compute fine-grained performance statistics for every micro-operator. The results are strong: it outperforms AlphaEvolve and FunSearch styles on NAS-Bench-Zero by explicitly preserving diversity and enabling surgical, data-driven pruning rather than blind mutation. The critical takeaway is the 'alternative-level statistic' mechanism: by aggregating performance across all paths a component participates in, they generate a high-fidelity signal that tells the LLM exactly which lines of code are working, effectively solving the sparse reward problem in code evolution. We should immediately discuss refactoring our AlgoEvo representation to support this multi-alternative graph structure, as it maximizes signal extraction per LLM call.</details> | Kamer Ali Yuksel et.al. | aiXplain Inc | arXiv.org | [2512.13857](http://arxiv.org/abs/2512.13857) | ‚Äî |
| 24/30 | **2025-12-10** | <details><summary>**Beyond Algorithm Evolution: An LLM-Driven Framework for the Co-Evolution of Swarm Intelligence Optimization Algorithms and Prompts**</summary>The authors introduce a co-evolutionary framework where both the optimization algorithm (Fireworks Algorithm operators) and the prompt templates used to generate them are evolved simultaneously by the LLM. The results demonstrate a massive performance jump on constrained Aircraft Landing problems (from ~56% with FunSearch to 100% with their method), suggesting that static prompts are a primary failure mode for complex OR constraints. The critical takeaway is their prompt fitness function: evaluating a prompt template based on the *performance improvement* (`child - parent`) of the code it generates, rather than absolute performance. We should immediately implement this 'prompt-delta' fitness signal in AlgoEvo to automate our prompt engineering loop.</details> | Shipeng Cen et.al. | Peking University | arXiv.org | [2512.09209](http://arxiv.org/abs/2512.09209) | ‚Äî |
| 23/30 | **2025-12-04** | <details><summary>**RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design**</summary>RoCo replaces standard evolutionary mutation operators with a 4-agent collaboration loop (Explorer, Exploiter, Critic, Integrator) that iteratively refines heuristics and accumulates long-term reflection memory across generations. While the empirical gains over ReEvo are marginal (often <1%) and likely expensive in token cost, the architecture successfully demonstrates how to embed structured multi-agent reasoning into the evolutionary loop to stabilize black-box search. The key takeaway is their Long-term Reflection mechanism, which aggregates critic feedback into a persistent memory buffer to guide future mutations‚Äîa technique we should immediately test to improve sample efficiency in AlgoEvo.</details> | Jiawei Xu et.al. | South China University of Technology | arXiv.org | [2512.03762](http://arxiv.org/abs/2512.03762) | ‚Äî |
| 19/30 | **2025-12-03** | <details><summary>**Structuring Collective Action with LLM-Guided Evolution: From Ill-Structured Problems to Executable Heuristics**</summary>ECHO-MIMIC presents a framework that first uses LLM-guided evolution to generate Python heuristics for agents (ECHO), and subsequently evolves natural language 'nudges' (MIMIC) to persuade simulated agents to adopt these global-optimal policies. While the experiments rely on synthetic data for agriculture and EV charging, the approach outperforms DSPy and AutoGen baselines in driving collective action. The most valuable takeaway is the architectural separation of 'policy discovery' (code evolution) and 'adoption mechanism' (message evolution)‚Äîa pattern we could adapt to evolve incentive structures or negotiation protocols in our multi-agent optimization systems (MASPRM/HERMES). The analysis of code complexity (Halstead metrics) versus fitness also provides a useful empirical reference for our observability work.</details> | Kevin Bradley Dsouza et.al. | University of Waterloo, Royal Bank of Canada | arXiv.org | [2509.20412](http://arxiv.org/abs/2509.20412) | ‚Äî |
| 28/30 | **2025-11-28** | <details><summary>**ThetaEvolve: Test-time Learning on Open Problems**</summary>ThetaEvolve integrates test-time reinforcement learning (GRPO) directly into an AlphaEvolve-style loop, allowing a single 8B model to learn from its own successful mutations and achieve new SOTA bounds on Circle Packing and Autocorrelation inequalities. The results are rigorous, showing that RL applied to the *dynamic* environment (sampling from the evolving database) vastly outperforms RL on static prompts or pure inference search. The most stealable insight is the 'lazy penalty' mechanism‚Äîpenalizing semantically equivalent code or stagnation‚Äîwhich forces the RL policy to learn genuine exploration strategies rather than memorization. This is a blueprint for the 'RL-infused evolution' milestone in our AlgoEvo roadmap.</details> | Yiping Wang et.al. | Microsoft, University of Washington, Carnegie Mellon University, University of Wisconsin-Madison, University of California, San Diego | arXiv.org | [2511.23473](http://arxiv.org/abs/2511.23473) | **[link](https://github.com/ypwang61/ThetaEvolve)** |
| 14/30 | **2025-11-26** | <details><summary>**Even with AI, Bijection Discovery is Still Hard: The Opportunities and Challenges of OpenEvolve for Novel Bijection Construction**</summary>Brown et al. apply OpenEvolve to combinatorial bijection discovery, finding that the system struggles with novel problems due to sparse rewards and 'reward hacking' (e.g., LLMs implementing search algorithms instead of constructive maps to satisfy tests). Results are negative but instructive, showing that direct prompting (GPT-5) sometimes outperforms evolution on these tasks. The key takeaway is the specific categorization of how LLMs cheat objective functions in code generation‚Äîspecifically by substituting computation (search) for insight (construction)‚Äîand the finding that code embedding diversity does not imply functional diversity. This is a valuable case study for debugging our own evolutionary search pipelines.</details> | Davis Brown et.al. | Pacific Northwest National Laboratory, University of Pennsylvania, University of California San Diego, University of Washington | arXiv.org | [2511.20987](http://arxiv.org/abs/2511.20987) | ‚Äî |
| 23/30 | **2025-11-17** | <details><summary>**GigaEvo: An Open Source Optimization Framework Powered By LLMs And Evolution Algorithms**</summary>GigaEvo is an open-source reproduction of the AlphaEvolve framework that implements MAP-Elites with an asynchronous DAG execution engine, successfully reproducing SOTA results on Heilbronn triangles and beating FunSearch on Weibull Bin Packing. The results are credible and backed by code, specifically highlighting that 'rewrite-based' mutation outperforms 'diff-based' approaches for open-weights models‚Äîa crucial engineering constraint for us. The most actionable takeaway is their 'bidirectional lineage tracking' mechanism, which enriches mutation prompts by analyzing both how a program improved over its ancestor and how its descendants further improved, a technique we should steal for AlgoEvo's mutation operator. Their negative result regarding multi-island MAP-Elites (added complexity, no gain) suggests we should deprioritize similar complex topologies.</details> | Valentin Khrulkov et.al. | Sber, Artificial Intelligence Research Institute (AIRI) | arXiv.org | [2511.17592](http://arxiv.org/abs/2511.17592) | **[link](https://github.com/AIRI-Institute/gigaevo-core)** |
| 10/30 | **2025-11-17** | <details><summary>**Fault2Flow: An AlphaEvolve-Optimized Human-in-the-Loop Multi-Agent System for Fault-to-Workflow Automation**</summary>Fault2Flow applies AlphaEvolve to refine symbolic fault trees (PASTA format) extracted from regulatory PDFs before converting them into executable workflows. The authors claim 100% consistency and 10x token efficiency compared to end-to-end prompting, but these results are based on a trivial set of 16 instances. The only transferable insight is their verification loop: using the LLM to synthesize test cases that validate the evolved logic structure against the original text‚Äîa technique we could adapt for verifying symbolic OR models. Overall, it is an engineering integration paper rather than a research advance.</details> | Yafang Wang et.al. | SGITG Accenture Information Technology, ISILC Victoria University, Kexin Melbourne AI Research Center, Eastern Institute of Technology, CNPIEC Kexin Technology | arXiv.org | [2511.12916](http://arxiv.org/abs/2511.12916) | ‚Äî |
| 25/30 | **2025-11-16** | <details><summary>**Automated Algorithmic Discovery for Scientific Computing through LLM-Guided Evolutionary Search: A Case Study in Gravitational-Wave Detection**</summary>Evo-MCTS introduces a hybrid search architecture where MCTS manages the exploration-exploitation balance of an evolutionary process, using LLMs for node expansion via novel operators like 'Path-wise Crossover' (synthesizing code from full root-to-leaf trajectories). The results are empirically strong, outperforming standard LLM-evolution baselines (ReEvo) by ~150% on a complex signal processing task. We learned that structuring the evolutionary lineage as a tree and using MCTS Q-values to select parents‚Äîrather than standard population selection‚Äîdrastically improves sample efficiency and solution quality. This is a blueprint for the 'RL-infused evolution' and 'persistent memory' features we have been planning for our own framework.</details> | He Wang et.al. | Tsinghua University, University of Chinese Academy of Sciences |  | [2508.03661](http://arxiv.org/abs/2508.03661) | **[link](https://github.com/iphysresearch/evo-mcts)** |
| 9/30 | **2025-11-16** | <details><summary>**From Euler to AI: Unifying Formulas for Mathematical Constants**</summary>This paper presents an automated pipeline to harvest, validate, and unify mathematical formulas for constants (like œÄ) by combining LLM-based extraction with a novel symbolic algorithm (UMAPS) that finds coboundary equivalences between linear recurrences. The results are rigorous, validating 385 formulas and unifying 43% of them into a single mathematical structure. The key takeaway for us is the strategy of using 'canonical forms' and empirical invariants (like convergence rates or irrationality measures) to fingerprint and cluster symbolic expressions; this concept could theoretically be adapted to deduplicate evolved heuristics in AlgoEvo if analogous invariants for code behavior were defined. However, the domain is too distant to be immediately actionable.</details> | Tomer Raz et.al. | Technion ‚Äì Israel Institute of Technology | NeurIPS | [2502.17533](http://arxiv.org/abs/2502.17533) | **[link](https://github.com/RamanujanMachine/euler2ai)** |
| 20/30 | **2025-11-11** | <details><summary>**AlphaResearch: Accelerating New Algorithm Discovery with Language Models**</summary>AlphaResearch introduces a 'dual environment' for algorithm discovery: it generates natural language research ideas, filters them using a reward model fine-tuned on ICLR peer reviews, and then executes the surviving ideas. While it claims to beat human baselines on Packing Circles, the improvement is marginal (<0.1%) and it fails to improve upon baselines in 6/8 benchmark problems. The key takeaway for us is the mechanism of an 'Idea Critic'‚Äîusing a learned reward model to filter the search space at the prompt level before wasting compute on execution‚Äîwhich directly addresses our sample efficiency goals in evolutionary search.</details> | Zhaojian Yu et.al. | Yale, NYU, Tsinghua, ByteDance | arXiv.org | [2511.08522](http://arxiv.org/abs/2511.08522) | **[link](https://github.com/answers111/alpha-research)** |
| 6/30 | **2025-11-10** | <details><summary>**Extending QAOA-GPT to Higher-Order Quantum Optimization Problems**</summary>Sunny et al. train a nanoGPT model to predict QAOA circuit parameters for higher-order spin glasses by conditioning on FEATHER graph embeddings, effectively distilling the expensive ADAPT-QAOA algorithm into a single forward pass. They report approximation ratios (~0.95) matching the teacher algorithm on 16-qubit simulations. While the use of FEATHER embeddings to provide structural context to a Transformer is a clean implementation of graph-conditional generation, the approach is standard behavior cloning rather than the evolutionary or RL-based discovery methods we prioritize. The work is domain-specific to quantum computing and offers no transferable insights for our VRP or AlgoEvo pipelines.</details> | Leanto Sunny et.al. | University of Tennessee, Knoxville |  | [2511.07391](http://arxiv.org/abs/2511.07391) | ‚Äî |
| 14/30 | **2025-10-28** | <details><summary>**Discovering Heuristics with Large Language Models (LLMs) for Mixed-Integer Programs: Single-Machine Scheduling**</summary>Cetinkaya et al. adapt the FunSearch framework to the Single-Machine Total Tardiness (SMTT) problem, utilizing a single-threaded pipeline on one A100 GPU to evolve heuristic scoring functions. They discover 'MDDC,' a heuristic containing regression-like arithmetic terms that generalizes from 25-job training instances to 500-job test sets, outperforming classic baselines (MDD, PSK) with ~2-5% optimality gaps. **Takeaway:** The paper serves as a useful data point that 'FunSearch-lite' (single-threaded, 72h on 1 GPU) is sufficient to beat 1990s-era human heuristics in scheduling, but the methodology is derivative and offers no new mechanisms for our AlgoEvo or reward modeling research.</details> | ƒ∞brahim Oƒüuz √áetinkaya et.al. | Virginia Tech | Computers & Operations Research | [2510.24013](http://arxiv.org/abs/2510.24013) | **[link](https://github.com/ibrahimoguzc/DiscoverHeuristics)** |
| 15/30 | **2025-10-26** | <details><summary>**Accelerating Materials Design via LLM-Guided Evolutionary Search**</summary>LLEMA applies LLM-guided evolutionary search to materials discovery, using a multi-island strategy where prompts are constructed via Boltzmann sampling from both 'success' and 'failure' memory pools. The empirical results are strong for the domain, significantly outperforming standard generative baselines and simple prompting (e.g., improving hit rates from <5% to ~30%). The most valuable takeaway is the **explicit inclusion of failure trajectories** in the context window combined with island-based diversity maintenance; this is a concrete mechanism we should test in our code evolution pipelines to better define decision boundaries and prevent mode collapse.</details> | Nikhil Abhyankar et.al. | Sandia National Laboratories, Virginia Tech | arXiv.org | [2510.22503](http://arxiv.org/abs/2510.22503) | **[link](https://github.com/scientific-discovery/LLEMA)** |
| 24/30 | **2025-10-16** | <details><summary>**Programmatic Representation Learning with Language Models**</summary>The authors propose two algorithms, F2 (Features FunSearch) and D-ID3 (Dynamic ID3), to learn programmatic features for decision trees. D-ID3 is particularly novel: instead of evolving a global heuristic, it calls the LLM at *each split node* to generate a feature that discriminates the specific data subset at that leaf. Results are strong on Chess (matching Transformers trained on 250x more data) and Text, though the Image results (MNIST) are trivial. **Key Takeaway:** The D-ID3 architecture‚Äîusing the solver's current state (leaf node data) to prompt the LLM for *local* code generation‚Äîis a powerful pattern we should steal for our VRP solvers (e.g., evolving local repair operators for specific route bottlenecks) and EvoCut work.</details> | Gabriel Poesia et.al. | Harvard University, Stanford University | arXiv.org | [2510.14825](http://arxiv.org/abs/2510.14825) | **[link](https://github.com/gpoesia/leapr/)** |
| 28/30 | **2025-10-13** | <details><summary>**Refining Hybrid Genetic Search for CVRP via Reinforcement Learning-Finetuned LLM**</summary>Zhu et al. fine-tune a Qwen-14B model using Reinforcement Learning (DAPO) to generate C++ crossover operators for the state-of-the-art HGS solver. Unlike typical prompting papers, they demonstrate that a small, specialized model can improve upon expert-designed components in a highly optimized solver, achieving superior results on CVRPLIB (up to 1000 nodes) where GPT-4o fails. The most stealable insight is their **AST-based anti-plagiarism reward**, which penalizes the model for generating code structurally identical to the prompt examples, effectively forcing exploration and preventing mode collapse‚Äîa technique we should immediately adopt for our evolutionary search agents. This confirms we should pivot from pure prompting to RL-finetuning for our code-generation agents.</details> | Rongjie Zhu et.al. | Nanyang Technological University, Singapore, Singapore Management University, Singapore, Nanjing University of Information Science and Technology, China | arXiv.org | [2510.11121](http://arxiv.org/abs/2510.11121) | ‚Äî |
| 23/30 | **2025-10-10** | <details><summary>**Barbarians at the Gate: How AI is Upending Systems Research**</summary>The authors apply OpenEvolve (an AlphaEvolve-style framework) to 11 computer systems problems, achieving significant gains over human baselines, such as a 5.0x speedup in MoE expert placement and 26% cost reduction in cloud scheduling. The results are empirically rigorous, relying on high-fidelity simulators rather than toy problems. For us, the key takeaway is the engineering recipe: using an ensemble of reasoning models (o3) for exploration and fast models (Gemini) for diversity, combined with a specific 'failure taxonomy' to debug search stagnation. This is immediate proof-of-concept for your 'GPUSched' and 'AlgoEvo' projects; we should adopt their ensemble strategy and simulator-first evaluation pipeline.</details> | Audrey Cheng et.al. | UC Berkeley | arXiv.org | [2510.06189](http://arxiv.org/abs/2510.06189) | ‚Äî |
| 26/30 | **2025-10-09** | <details><summary>**Robust Heuristic Algorithm Design with LLMs**</summary>Karimi et al. introduce 'Robusta', an enhancement to FunSearch that uses a Heuristic Analyzer (solver-based) to identify adversarial inputs and a Suggester LLM to explain *why* the current heuristic fails before generating new code. They demonstrate a 28x improvement in worst-case performance over FunSearch on traffic engineering tasks, with results backed by rigorous comparison against optimal solvers. The critical takeaway is the 'Suggester' intermediate step: converting raw failure instances into natural language coding strategies significantly improves the LLM's ability to fix logic bugs compared to raw samples alone. We should immediately attempt to replicate this 'Analyzer -> Explainer -> Coder' loop for our VRP work, using small-scale solvers to generate counter-examples for our evolved ALNS operators.</details> | Pantea Karimi et.al. | Microsoft, MIT, Microsoft Research, University of Southern California, The University of Texas at Austin | arXiv.org | [2510.08755](http://arxiv.org/abs/2510.08755) | ‚Äî |
| 24/30 | **2025-10-07** | <details><summary>**Scientific Algorithm Discovery by Augmenting AlphaEvolve with Deep Research**</summary>DeepEvolve augments the standard evolutionary coding loop (AlphaEvolve) with two critical components: a 'Deep Research' module that searches the web/literature to generate grounded mutation proposals, and an iterative debugging agent that fixes execution errors. While the '666%' improvement on Circle Packing is likely due to a weak baseline (fixed-size vs. generalized), the engineering results are compelling: the debugging agent raises execution success rates from ~13% to ~99% in complex tasks. The key takeaway for our AlgoEvo work is the architecture of generating a text-based 'research proposal' via RAG before attempting code generation, rather than mutating code directly. We should immediately adopt their debugging loop and consider injecting external literature search into our mutation operators to prevent search stagnation.</details> | Gang Liu et.al. | MIT-IBM Watson AI Lab, IBM Research, University of Notre Dame | arXiv.org | [2510.06056](http://arxiv.org/abs/2510.06056) | **[link](https://github.com/liugangcode/deepevolve)** |
| 23/30 | **2025-09-30** | <details><summary>**Experience-Guided Reflective Co-Evolution of Prompts and Heuristics for Automatic Algorithm Design**</summary>EvoPH introduces a co-evolutionary framework where both the heuristic code and the LLM prompts are evolved, utilizing an island model for diversity and a 'strategy sampling' mechanism that dynamically selects mutation types (e.g., parameter tuning vs. rewrite) based on feedback. They report dominating performance over FunSearch and ReEvo on TSP and BPP (e.g., reducing Christofides gap from ~20% to ~5%), though the static performance of baselines suggests the gain comes largely from automating prompt engineering. The most stealable insight is the **Strategy Sampling** module: explicitly defining a pool of mutation operators and using an 'experience' buffer to select them is a practical implementation of the 'planner' concept we need for AlgoEvo. We should also adopt their island migration topology to improve diversity in our parallelized search.</details> | Yihong Liu et.al. | Tencent, Renmin University of China, City University of Hong Kong | arXiv.org | [2509.24509](http://arxiv.org/abs/2509.24509) | **[link](null)** |
| 22/30 | **2025-09-29** | <details><summary>**MAS$^2$: Self-Generative, Self-Configuring, Self-Rectifying Multi-Agent Systems**</summary>MAS2 trains a tri-agent system (Generator, Implementer, Rectifier) using offline RL on decision trees to dynamically construct and repair multi-agent workflows. The results are strong, outperforming ADAS and MaAS on standard benchmarks while maintaining Pareto efficiency. The critical takeaway for us is the **Rectifier agent**: rather than discarding failed evolutionary candidates (as we currently do in AlgoEvo), we should implement a dedicated loop to patch runtime errors (e.g., API failures, dimension mismatches). Additionally, their 'Collaborative Tree Optimization' offers a rigorous method to fine-tune the 'Evolver' model using trajectory data, which could replace our current prompt-based meta-heuristics.</details> | Kun Wang et.al. | NTU, NUS, USTC, ZJU, BUAA, PKU | arXiv.org | [2509.24323](http://arxiv.org/abs/2509.24323) | **[link](https://github.com/yeyeyeah2/MAS2)** |
| 24/30 | **2025-09-27** | <details><summary>**C-Evolve: Consensus-based Evolution for Prompt Groups**</summary>C-Evolve modifies island-based evolution to optimize a group of prompts that maximize consensus accuracy (majority vote) rather than individual performance. The authors introduce a 'voting score' fitness function‚Äîcalculated via Exponential Moving Average (EMA) of an individual's contribution to sampled groups‚Äîwhich successfully drives the population toward diverse, complementary strategies that outperform ensembles of individually optimized prompts (beating AlphaEvolve by ~4% on Qwen3-8B). The single most actionable takeaway is the **EMA voting score mechanism**: we can steal this exact fitness formulation to evolve portfolios of complementary VRP heuristics in AlgoEvo, replacing our current focus on converging to a single 'best' solver. While the benchmarks are standard (MATH, HotpotQA), the method offers a robust solution to the 'single heuristic limitation' we face in OR.</details> | Tiancheng Li et.al. | Westlake University | arXiv.org | [2509.23331](http://arxiv.org/abs/2509.23331) | ‚Äî |
| 28/30 | **2025-09-26** | <details><summary>**Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents**</summary>DGM implements a population-based evolutionary loop where agents modify their own Python source code (tools, memory, flow) to improve performance on coding benchmarks, rather than just optimizing prompts or parameters. Results are strong and verified: it boosts a base agent from 20% to 50% on SWE-bench Verified, matching handcrafted SoTA, with ablations proving the necessity of the population archive (open-endedness) over single-lineage hill climbing. **Key Takeaway:** The 'self-diagnosis' mechanism‚Äîfeeding execution logs to a model to propose specific *architectural* code changes (e.g., implementing a 'str_replace' tool to fix granular editing errors)‚Äîis the exact mechanism we need to implement for evolving our heuristic searchers. This validates that LLM-driven code evolution is viable for complex logic improvement, not just toy tasks.</details> | Jenny Zhang et.al. | Sakana AI, Vector Institute, University of British Columbia, Canada CIFAR AI Chair | Robotics | [2505.22954](http://arxiv.org/abs/2505.22954) | **[link](https://github.com/jennyzzt/dgm)** |
| 23/30 | **2025-09-25** | <details><summary>**GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models**</summary>GeoEvolve augments standard LLM-based evolutionary search (OpenEvolve) with an outer 'researcher' loop that queries a domain-specific RAG (textbooks/papers) to inject theoretical constraints into mutation prompts. On geospatial interpolation tasks, they report 13-21% error reduction over standard evolution, with ablations confirming that retrieved domain knowledge‚Äînot just iterative feedback‚Äîdrives the performance gain. The critical takeaway is the architectural pattern of 'Knowledge-Guided Evolution': instead of relying on the LLM's internal weights for domain theory, they explicitly retrieve and inject theoretical priors (e.g., valid variogram definitions) to steer the search. We should adapt this 'Theory-RAG' outer loop for our AlgoEvo pipeline to force evolved VRP heuristics to respect OR theoretical bounds.</details> | Peng Luo et.al. | Massachusetts Institute of Technology, Stanford University, Technical University of Munich | arXiv.org | [2509.21593](http://arxiv.org/abs/2509.21593) | ‚Äî |
| 22/30 | **2025-09-21** | <details><summary>**Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning**</summary>Ouellette implements an Execution-Guided Neural Program Synthesis (EG-NPS) system for ARC-AGI that conditions the search on the intermediate execution state of every instruction, achieving 80% success on out-of-distribution tasks where TTFT (10%) and standard AlphaEvolve (0-14%) fail. The results are rigorous, using controlled OOD tasks to prove that TTFT relies on in-distribution priors rather than reasoning. The critical takeaway for our AlgoEvo work is the architecture of the 'state-conditioned decoder': instead of blind code generation, we should inject the tokenized execution result of step $t$ into the context for step $t+1$. This is effectively a dense process reward model that solves the sample efficiency bottleneck we face in evolutionary search.</details> | Simon Ouellette et.al. |  | arXiv.org | [2507.15877](http://arxiv.org/abs/2507.15877) | **[link](https://github.com/SimonOuellette35/OODGenARC-AGI)** |
| 16/30 | **2025-09-19** | <details><summary>**Large Language Model Assisted Automated Algorithm Generation and Evolution via Meta-black-box optimization**</summary>Yang et al. use Deepseek R1 to evolve mathematical update rules for continuous constrained optimization, claiming to find feasible solutions on 3 hard CEC2010 instances where state-of-the-art methods (LSHADE, MadDE) fail. The approach uses a standard meta-optimization loop where the LLM refines the update formula based on historical performance and constraint violations. While the 'RTO2H' prompt framework is generic, the result suggests that LLMs can implicitly learn constraint-handling strategies (replacing manual penalty tuning), which is a relevant proof-of-concept for our AlgoEvo work, even if the continuous domain doesn't directly transfer to VRP.</details> | Xu Yang et.al. | National University of Defense Technology | arXiv.org | [2509.13251](http://arxiv.org/abs/2509.13251) | ‚Äî |
| 26/30 | **2025-09-17** | <details><summary>**ShinkaEvolve: Towards Open-Ended And Sample-Efficient Program Evolution**</summary>ShinkaEvolve presents an open-source evolutionary framework that drastically improves sample efficiency (e.g., beating AlphaEvolve on Circle Packing with only 150 evaluations vs. thousands) by integrating embedding-based novelty rejection, adaptive parent sampling, and bandit-based LLM selection. The results are credible, backed by code from Sakana AI, and directly target our primary pain point of high API costs/sample inefficiency in evolutionary search. **Key Takeaway:** We must implement their 'novelty rejection sampling' immediately‚Äîusing a cheap embedding model to filter out semantically similar code mutations (threshold 0.95) before execution is a trivial but high-impact optimization for our AlgoEvo pipeline. This paper proves that smart filtering is superior to the brute-force compute strategies we have been relying on.</details> | Robert Tjarko Lange et.al. | Sakana AI | arXiv.org | [2509.19349](http://arxiv.org/abs/2509.19349) | **[link](https://github.com/SakanaAI/ShinkaEvolve)** |
| 22/30 | **2025-09-10** | <details><summary>**How Should We Meta-Learn Reinforcement Learning Algorithms?**</summary>Goldie et al. perform a rigorous empirical benchmark comparing LLM-based algorithm proposal against Black-box Evolution Strategies (ES) and various distillation methods. They find that while LLMs are sample-efficient for simple functions, they catastrophically fail to incorporate high-dimensional input features (e.g., the 20+ inputs in OPEN), where Black-box ES remains superior. The most actionable takeaway is 'Same-Size Distillation': distilling a learned black-box algorithm into a fresh network of identical size using synthetic data consistently improves out-of-distribution generalization with zero additional environment samples. We should implement this distillation step immediately and reconsider using LLMs for feature-heavy heuristic components.</details> | Alexander David Goldie et.al. | University of Oxford | arXiv.org | [2507.17668](http://arxiv.org/abs/2507.17668) | **[link](https://github.com/AlexGoldie/learn-rl-algorithms)** |
| 28/30 | **2025-09-09** | <details><summary>**Autonomous Code Evolution Meets NP-Completeness**</summary>SATLUTION extends LLM evolutionary search to full-scale C++ repositories, autonomously evolving SAT solvers that outperform 2025 human competition winners using only 2024 training data. The results are highly rigorous, backed by 90k CPU hours of distributed evaluation and strict correctness proofs (DRAT), showing a clear monotonic improvement trajectory. The single most stealable insight is the **self-evolving rule system**: the agent autonomously updates a persistent set of markdown constraints (e.g., forbidden patterns, testing protocols) based on post-cycle failure analysis, effectively creating 'institutional memory' that prevents regression in long-horizon search. We must implement this meta-learning loop in AlgoEvo immediately to move beyond single-file optimization.</details> | Cunxi Yu et.al. | NVIDIA Research, University of Maryland | arXiv.org | [2509.07367](http://arxiv.org/abs/2509.07367) | ‚Äî |
| 14/30 | **2025-09-02** | <details><summary>**Re-evaluating LLM-based Heuristic Search: A Case Study on the 3D Packing Problem**</summary>Quan et al. apply Evolution of Heuristics (EoH) to the Constrained 3D Packing Problem, finding that naive LLM generation fails completely without 'Constraint Scaffolding' (pre-written geometry libraries) and iterative repair. The results are soberingly realistic: while the scaffolded LLM matches greedy baselines on simple instances, it fails to generalize to complex constraints (stability, separation), significantly trailing human-designed metaheuristics. The key takeaway is their observation that the LLM exclusively optimizes the *scoring function* (weights/priorities) rather than the algorithmic structure, effectively reducing 'code evolution' to 'parameter tuning.' This confirms a critical limitation for our AlgoEvo work: simply asking for code results in local optimization; we must force structural changes or provide better primitives to get true novelty.</details> | Guorui Quan et.al. | The University of Manchester | arXiv.org | [2509.02297](http://arxiv.org/abs/2509.02297) | **[link](https://github.com/quangr/EoH)** |
| 7/30 | **2025-08-30** | <details><summary>**LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain**</summary>This paper proposes a 'SuperBrain' framework where human users interact with LLMs to manually tune Genetic Algorithm parameters for UAV scheduling, theoretically aggregating these interactions into a collective intelligence. The empirical results are weak; the 'evolved' GAs merely approach the performance of a basic Round Robin baseline, and the comparison relies on anecdotal differences between 'expert' and 'student' prompters. The 'Backward Evolution' section describes a bilevel optimization for weight tuning but lacks rigorous implementation details or code that would compete with current automated search methods (like FunSearch or OPRO). We learn nothing new here regarding automated heuristic discovery or scalable evolutionary search.</details> | Li Weigang et.al. | University of Brasilia, Federal Institute of Brasilia | arXiv.org | [2509.00510](http://arxiv.org/abs/2509.00510) | **[link](null)** |
| 10/30 | **2025-08-26** | <details><summary>**ReflectivePrompt: Reflective evolution in autoprompting algorithms**</summary>Zhuravlev et al. adapt the ReEvo framework‚Äîwhich uses LLMs to generate 'reflection' hints before mutation‚Äîspecifically for autoprompting on NLP tasks. While they claim significant gains over EvoPrompt (e.g., +28% on BBH), the methodology is a straightforward port of ReEvo combined with standard roulette-wheel selection, offering no new architectural insights. The results serve as a data point confirming that verbalizing mutation strategies ('reflection') helps in discrete spaces, but the paper lacks the statistical rigor or methodological novelty to warrant attention over the original ReEvo work. It is not actionable for our code-centric evolutionary search.</details> | Viktor N. Zhuravlev et.al. | ITMO University | Scientific and Technical Journal of Information Technologies, Mechanics and Optics | [2508.18870](http://arxiv.org/abs/2508.18870) | **[link](https://github.com/CTLab-ITMO/CoolPrompt/)** |
| 15/30 | **2025-08-25** | <details><summary>**Data-Driven Discovery of Interpretable Kalman Filter Variants through Large Language Models and Genetic Programming**</summary>Saketos et al. apply a FunSearch-style loop (using DeepSeek-14B) and Cartesian Genetic Programming (CGP) to evolve Kalman Filter variants, achieving ~3x MSE reduction on non-Gaussian noise scenarios. The results are empirically backed and highlight a critical limitation: LLM-ES failed to reconstruct the exact full Kalman Filter where traditional CGP succeeded, likely due to precision issues in symbolic reconstruction. The main takeaway is that for exact mathematical structure discovery, traditional symbolic mutation (CGP) still holds an edge over 14B-parameter LLM evolution, suggesting we should not fully abandon symbolic operators in our AILS-II control discovery pipeline. It also validates that open-weights 14B models are sufficient for FunSearch-style loops.</details> | Vasileios Saketos et.al. | Harvard University, KTH Stockholm | arXiv.org | [2508.11703](http://arxiv.org/abs/2508.11703) | ‚Äî |
| 16/30 | **2025-08-22** | <details><summary>**Adversarial Generation and Collaborative Evolution of Safety-Critical Scenarios for Autonomous Vehicles**</summary>SCENGE combines LLM-based scenario scripting with a secondary optimization stage that perturbs background vehicle trajectories to force safety violations. The standout technique is the 'Adversarial Collaborator Graph,' which calculates attention scores between agent trajectories to identify the specific subset of 'collaborator' agents that, if perturbed, maximize the adversarial impact. Results are strong (+31% collision rate vs. baselines in CARLA) and validated in real-world closed courses. For us, the agent selection heuristic is a stealable technique for our multi-agent optimization work: it provides a way to identify and target only the most consequential agents in a large system rather than optimizing the entire joint state space.</details> | Jiangfan Liu et.al. | Beihang University, Nanyang Technological University, Zhongguancun Laboratory, Henan University of Science and Technology | arXiv.org | [2508.14527](http://arxiv.org/abs/2508.14527) | **[link](https://scenge.github.io)** |
| 25/30 | **2025-08-20** | <details><summary>**EoH-S: Evolution of Heuristic Set using LLMs for Automated Heuristic Design**</summary>EoH-S reformulates Automated Heuristic Design (AHD) to evolve a complementary *set* of heuristics rather than a single robust one, proving the objective is submodular and solvable via a greedy strategy. Results are strong and credible: on TSPLib and CVRPLib, their set of 10 heuristics reduces the optimality gap by ~40-60% compared to the top 10 heuristics from FunSearch or ReEvo. **KEY TAKEAWAY:** We should replace standard elitist selection in AlgoEvo with their 'Complementary Population Management' (CPM). By greedily selecting individuals based on marginal contribution to instance coverage (using instance-wise performance vectors), we can automatically generate diverse operator pools for ALNS instead of relying on hand-crafted diversity metrics.</details> | Fei Liu et.al. | Huawei Noah

































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































Ark Lab, City University of Hong Kong | arXiv.org | [2508.03082](http://arxiv.org/abs/2508.03082) | ‚Äî |
| 23/30 | **2025-08-08** | <details><summary>**LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression**</summary>Zhang et al. develop a meta-evolutionary framework to evolve selection operators for symbolic regression, achieving state-of-the-art results on SRBench by outperforming expert-designed methods like Œµ-lexicase. The standout contribution is **semantics-aware crossover**: rather than selecting parents based solely on scalar fitness, they compute complementarity scores using performance vectors across instances, explicitly retrieving parents that solve different subsets of the problem. This effectively treats parent selection as a retrieval task based on behavioral signatures, ensuring the LLM combines distinct functional capabilities. We should immediately implement this complementarity-based parent retrieval in AlgoEvo to improve how we merge heuristics.</details> | Hengzhe Zhang et.al. | Victoria University of Wellington, Michigan State University |  | [2505.18602](http://arxiv.org/abs/2505.18602) | **[link](https://anonymous.4open.science/r/LLM-Meta-SR/)** |
| 24/30 | **2025-08-04** | <details><summary>**Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning**</summary>EvoTune augments LLM-based evolutionary search (FunSearch) by iteratively fine-tuning the LLM weights using Direct Preference Optimization (DPO) on the generated programs. The results are robust, consistently outperforming static FunSearch on Bin Packing, TSP, and Hash Code benchmarks by discovering better heuristics faster. The critical takeaway is the use of **Forward KL regularization** in DPO instead of the standard Reverse KL; this prevents the mode collapse that usually kills evolutionary diversity, allowing the model to learn from high-fitness samples while maintaining exploration. This is a direct blueprint for implementing the 'RL-infused evolution' component of our AlgoEvo project.</details> | Anja Surina et.al. | EPFL, Apple | arXiv.org | [2504.05108](http://arxiv.org/abs/2504.05108) | **[link](https://claire-labo.github.io/EvoTune/)** |
| 18/30 | **2025-08-03** | <details><summary>**EvoVLMA: Evolutionary Vision-Language Model Adaptation**</summary>This paper proposes EvoVLMA, an LLM-based evolutionary framework that searches for Python code to adapt Vision-Language Models (feature selection and logits computation). They demonstrate that **jointly** evolving two coupled algorithmic components fails (worse than random), whereas a **sequential** two-stage evolution strategy yields SOTA results (beating manual baselines by ~1-2%). For our AlgoEvo work, the key takeaway is the infrastructure design: they wrap code execution in restartable web services with a process monitor to handle the high rate of CUDA errors/timeouts in generated code‚Äîa practical 'trick' we should adopt to improve our search stability.</details> | Kun Ding et.al. | Chinese Academy of Sciences | ACM Multimedia 2025 (ACM MM 2025) | [2508.01558](http://arxiv.org/abs/2508.01558) | **[link](https://github.com/kding1225/EvoVLMA)** |
| 23/30 | **2025-07-04** | <details><summary>**Behaviour Space Analysis of LLM-driven Meta-heuristic Discovery**</summary>The authors introduce a behavioral analysis framework for LLM-driven algorithm discovery, mapping the 'behavior space' of generated heuristics using Search Trajectory Networks (STNs) and Code Evolution Graphs (CEGs). Results on BBOB (5D) show that a simple 1+1 elitist strategy alternating between 'simplify code' and 'random new' prompts significantly outperforms population-based approaches, effectively balancing exploitation and exploration while preventing code bloat. The primary takeaway is the critical role of a 'simplify' mutation operator‚Äîwithout it, LLM-generated code tends to drift into complexity without performance gains. We should immediately adopt their visualization metrics to debug our own evolutionary search trajectories and implement their 'simplify' prompt strategy in AlgoEvo.</details> | Niki van Stein et.al. | Leiden University, University of Stirling | arXiv.org | [2507.03605](http://arxiv.org/abs/2507.03605) | **[link](https://doi.org/10.5281/zenodo.15675581)** |
| 4/30 | **2025-06-23** | <details><summary>**Advanced For-Loop for QML algorithm search**</summary>This paper proposes an agentic loop to translate classical ML algorithms (MLP, Backprop) into Quantum ML circuits using LLMs. The empirical results are negligible, achieving only ~15% accuracy on a standard digit classification task (barely above random chance), which the author attributes to insufficient training steps. Methodologically, it claims to use advanced techniques like DPO and RAG but provides no ablation or implementation details, effectively reducing the contribution to a basic prompt-engineering exercise. There are no transferable insights for our evolutionary search or optimization work.</details> | FuTe Wong et.al. | University of Toronto, Vector Institute |  | [2506.18260](http://arxiv.org/abs/2506.18260) | ‚Äî |
| 30/30 | **2025-06-16** | <details><summary>**AlphaEvolve: A coding agent for scientific and algorithmic discovery**</summary>AlphaEvolve extends FunSearch by evolving entire code files (rather than single functions) using a 'search/replace' diff format and Gemini 2.0, achieving SOTA results across matrix multiplication (beating Strassen), 50+ open math problems, and Google's production scheduling. The results are exceptionally strong and verified, including deployed improvements to Google's Borg scheduler (0.7% resource recovery) and TPU circuits. The critical takeaway is the move to **diff-based full-file evolution** and **meta-prompt evolution** (evolving the prompt instructions alongside the code), which allows the system to modify architecture and logic rather than just heuristics. This is a mandatory blueprint for the next iteration of our AlgoEvo and EvoCut projects.</details> | Alexander Novikov et.al. | Google DeepMind | arXiv.org | [2506.13131](http://arxiv.org/abs/2506.13131) | **[link](https://colab.research.google.com/github/google-deepmind/alphaevolve_results/blob/master/mathematical_results.ipynb)** |
| 3/30 | **2025-06-14** | <details><summary>**Automated Heuristic Design for Unit Commitment Using Large Language Models**</summary>Lv et al. attempt to apply FunSearch (LLM-based code evolution) to the Unit Commitment problem. The study is critically flawed: it tests on a trivial 10-unit instance (where exact solvers are instantaneous) and compares against an unspecified 'Genetic Algorithm'. The reported 'sampling time' of 6.6s for an LLM evolutionary process is technically implausible unless referring to the final heuristic's execution, indicating a likely confusion in their metrics or methodology. There are no actionable insights or reusable techniques here; it is a low-quality application paper.</details> | Junjin Lv et.al. | Shanghai University of Electric Power, Shanghai Electrical Appliances Research Institute (Group) Co | arXiv.org | [2506.12495](http://arxiv.org/abs/2506.12495) | ‚Äî |
| 26/30 | **2025-06-10** | <details><summary>**Can Large Language Models Invent Algorithms to Improve Themselves?: Algorithm Discovery for Recursive Self-Improvement through Reinforcement Learning**</summary>Ishibashi et al. propose 'Self-Developing,' a framework where an LLM generates Python code for model merging, evaluates the results, and uses the performance data to fine-tune the generator via DPO in a recursive loop. The results are empirically strong, outperforming human-designed baselines (Task Arithmetic) by 4.3% on GSM8k and demonstrating that the generator explicitly learns better strategies over iterations. **Key Takeaway:** We can replace the static mutation operators in our evolutionary search with a DPO-trained model that learns from the search history‚Äîeffectively implementing 'learning to search.' This is a direct, actionable upgrade for our AlgoEvo and AlphaEvolve pipelines.</details> | Yoichi Ishibashi et.al. | NEC Corporation | NAACL 2025 (main) | [2410.15639](http://arxiv.org/abs/2410.15639) | ‚Äî |
| 13/30 | **2025-06-03** | <details><summary>**LLM-Driven Instance-Specific Heuristic Generation and Selection**</summary>Zhang et al. introduce a framework that partitions problem spaces (OBPP, CVRP) into thousands of subclasses and runs LLM-evolution (EoH) on *each* to create a lookup table of heuristics, selected at runtime via k-NN. While they achieve a 5.8% gap reduction on Bin Packing over single-heuristic baselines, the approach requires massive offline compute to generate thousands of scripts. The key takeaway is a negative result: using an LLM to select the best heuristic from candidates yielded negligible gains (0.1%) over simple feature-based distance, suggesting we should avoid LLM-based selector agents for this task. This confirms that 'one-size-fits-all' evolved heuristics struggle with heterogeneity, but we should solve this via adaptive code, not brute-force enumeration.</details> | Shaofeng Zhang et.al. | Nanyang Technological University, The Hong Kong University of Science and Technology, The Hong Kong Polytechnic University, Southern University of Science and Technology, A*STAR, Zhongguancun Academy, Advanced Micro Devices Inc. | arXiv.org | [2506.00490](http://arxiv.org/abs/2506.00490) | ‚Äî |
| 22/30 | **2025-06-01** | <details><summary>**EvoGit: Decentralized Code Evolution via Git-Based Multi-Agent Collaboration**</summary>Huang et al. introduce EvoGit, a framework where LLM agents asynchronously evolve code by treating Git commits as the population and using 3-way merges (based on Lowest Common Ancestor) as crossover. While the experiments (web app, bin packing generator) are largely qualitative and lack rigorous statistical benchmarking against baselines like MetaGPT, the architectural contribution is significant. The key takeaway is using Git's native DAG structure to handle lineage, persistence, and asynchronous concurrency 'for free,' replacing complex custom population managers. This is directly actionable for our AlgoEvo infrastructure to enable massive parallelism and better memory/traceability without reinventing the wheel.</details> | Beichen Huang et.al. | The Hong Kong Polytechnic University | arXiv.org | [2506.02049](http://arxiv.org/abs/2506.02049) | **[link](https://github.com/BillHuang2001/evogit)** |
| 25/30 | **2025-05-22** | <details><summary>**STRCMP: Integrating Graph Structural Priors with Language Models for Combinatorial Optimization**</summary>STRCMP introduces a composite architecture where a GNN encodes CO problem instances (MILP/SAT) into embeddings that condition an LLM (fine-tuned via SFT and DPO) to generate solver-specific heuristics within an evolutionary loop. The results are strong and empirically backed, showing significant reductions in convergence time and timeouts compared to text-only evolutionary methods like AutoSAT and LLM4Solver. The key takeaway is the architectural blueprint for fusing instance-specific structural embeddings (via soft prompting) with LLM code generation to drastically improve the sample efficiency of evolutionary search. This is immediately relevant to our EvoCut and AlgoEvo projects, suggesting we should move beyond pure text prompts for topology-heavy problems.</details> | Xijun Li et.al. | Shanghai Key Laboratory of Scalable Computing and Systems, School of Computer Science, Shanghai Jiao Tong University | arXiv.org | [2506.11057](http://arxiv.org/abs/2506.11057) | ‚Äî |
| 26/30 | **2025-05-18** | <details><summary>**CALM: Co-evolution of Algorithms and Language Model for Automatic Heuristic Design**</summary>CALM introduces a hybrid evolutionary framework that fine-tunes the LLM generator *during* the search process using Group Relative Policy Optimization (GRPO), rather than relying solely on prompt evolution. Using a quantized Qwen-7B model on a single consumer GPU, it outperforms GPT-4o-based baselines (FunSearch, EoH) on Bin Packing and VRP benchmarks. The critical takeaway is their reward function design: instead of absolute performance, they reward the *relative improvement* of the generated code over the specific 'parent' heuristics in the prompt, stabilizing the RL signal. We should immediately test this 'online fine-tuning' approach to reduce our API costs and improve sample efficiency in AlgoEvo.</details> | Ziyao Huang et.al. | City University of Hong Kong, Southeast University, University of Victoria, Hon Hai Research Institute | arXiv.org | [2505.12285](http://arxiv.org/abs/2505.12285) | **[link](https://github.com/whxru/CALM)** |
| 14/30 | **2025-05-12** | <details><summary>**Symbolic Regression with Multimodal Large Language Models and Kolmogorov Arnold Networks**</summary>Harvey et al. introduce LLM-LEx, a FunSearch-style loop that uses Vision-LLMs (GPT-4o) to generate symbolic ans√§tze from plots of univariate functions, extending this to multivariate settings by first training a Kolmogorov-Arnold Network (KAN) and regressing its edges individually. While they claim to beat Mathematica on synthetic benchmarks, the reliance on visual plotting is a non-starter for our complex algorithmic logic. However, the **KAN decomposition strategy**‚Äîreducing a hard multivariate symbolic search into independent, simpler univariate searches‚Äîis a valuable architectural insight. We could steal this 'Train KAN -> Regress Edges' workflow to extract interpretable symbolic constraints or heuristics from neural baselines without searching the full multivariate space directly.</details> | Thomas R. Harvey et.al. | MIT, University of Oxford, Northeastern University | arXiv.org | [2505.07956](http://arxiv.org/abs/2505.07956) | **[link](https://github.com/harveyThomas4692/llmlex)** |
| 13/30 | **2025-04-28** | <details><summary>**BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics**</summary>BLADE is a benchmarking framework for LLM-driven algorithm discovery (AAD) focused on continuous black-box optimization (BBOB, SBOX), integrating standard logging and analysis tools. The empirical results are standard (LLaMEA variants on BBOB), but the paper introduces **Code Evolution Graphs (CEG)**‚Äîa visualization technique that embeds generated code to track lineage and diversity during search. We should steal this visualization method for AlgoEvo to better debug population stagnation and diversity, even though the benchmark suite itself is too focused on continuous toy problems to replace our OR-centric evaluations.</details> | Niki van Stein et.al. | LIACS, Leiden University | GECCO Workshop 2025 | [2504.20183](http://arxiv.org/abs/2504.20183) | **[link](https://github.com/XAI-liacs/BLADE)** |
| 9/30 | **2025-04-03** | <details><summary>**LLM-Guided Evolution: An Autonomous Model Optimization for Object Detection**</summary>Yu and Zutty apply LLM-Guided Evolution (Llama-3.3) to mutate YOLO YAML configuration files for object detection, achieving a 2% mAP improvement on KITTI. The results are empirically weak due to a lack of statistical rigor (single runs) and extreme inefficiency: the method required 35-38 days of runtime and suffered a ~50% failure rate where the LLM generated invalid YAMLs. We learn that evolving configuration files via simple prompting is viable but prohibitively expensive compared to code evolution; this confirms the necessity of the constraint handling and reward modeling techniques we are already developing. The paper offers no transferable insights for improving our AlgoEvo framework.</details> | YiMing Yu et.al. | Georgia Tech Research Institute | GECCO Companion | [2504.02280](http://arxiv.org/abs/2504.02280) | ‚Äî |
| 19/30 | **2025-04-01** | <details><summary>**LLM-Guided Search for Deletion-Correcting Codes**</summary>Weindel and Heckel adapt FunSearch to discover priority functions for the Maximum Independent Set problem (applied to deletion-correcting codes), achieving new SOTA lower bounds for specific lengths (n=12, 13, 16). The critical takeaway for us is their **functional deduplication** step: they hash function outputs on a small subset of data to discard syntactically unique but logically identical programs, which significantly improves sample efficiency by preventing the evaluator from wasting cycles on 'comment changes' or variable renames. Additionally, they demonstrate that optimizing for the single hardest instance generalizes better than averaging performance across a curriculum‚Äîa counter-intuitive finding we should test in our reward modeling.</details> | Franziska Weindel et.al. | Technical University of Munich, Munich Center for Machine Learning | arXiv.org | [2504.00613](http://arxiv.org/abs/2504.00613) | **[link](https://github.com/MLI-lab/FunDCC)** |
| 10/30 | **2025-03-25** | <details><summary>**Optimizing Photonic Structures with Large Language Model Driven Algorithm Discovery**</summary>Yin et al. apply the LLaMEA framework to photonic inverse design, experimenting with injecting domain knowledge into prompts and varying evolutionary strategies (e.g., 1+1 vs 5+5). They demonstrate that LLM-generated algorithms can match baselines like DE and CMA-ES on continuous physics benchmarks. The only potentially useful takeaway is their negative result: detailed domain-specific prompts actually *degraded* performance on noisy fitness landscapes by prematurely constraining exploration. Aside from this prompt engineering heuristic, the work is an incremental application with no fundamental methodological contributions.</details> | Haoran Yin et.al. | LIACS, Leiden University | GECCO Companion | [2503.19742](http://arxiv.org/abs/2503.19742) | **[link](https://doi.org/10.5281/zenodo.15073784)** |
| 17/30 | **2025-03-17** | <details><summary>**Generative Modeling for Mathematical Discovery**</summary>Ellenberg et al. release an open-source implementation of FunSearch and benchmark it on combinatorial problems, analyzing model cost versus performance. Their results are backed by extensive runs, demonstrating that cheaper models (e.g., Mistral) often match GPT-4o in this loop and that long evolutionary runs suffer from path dependence, making frequent restarts more efficient. The most actionable insight is that mathematically equivalent problem formulations (e.g., greedy adding vs. greedy removal of points) yield drastically different search landscapes for the LLM. We should immediately apply this 'formulation variation' strategy to our VRP heuristic evolution (e.g., evolving destruction operators vs. construction operators explicitly) and shift budget toward parallel short runs with smaller models.</details> | Jordan S. Ellenberg et.al. | Massachusetts Institute of Technology, University of Oxford, University of Wisconsin-Madison, The NSF Institute for Artificial Intelligence and Fundamental Interactions | arXiv.org | [2503.11061](http://arxiv.org/abs/2503.11061) | **[link](https://github.com/kitft/funsearch)** |
| 26/30 | **2025-03-13** | <details><summary>**From Understanding to Excelling: Template-Free Algorithm Design through Structural-Functional Co-Evolution**</summary>Zhao et al. propose CAE, a framework that co-evolves algorithm structure (workflow/call graphs) alongside function implementations, aiming to eliminate the fixed templates required by SOTA methods like FunSearch and EoH. On TSP benchmarks, they report reducing optimality gaps by ~2-5% compared to ReEvo, and in quadratic optimization, the system autonomously discovered numerical stability fixes (e.g., replacing matrix inversion with solvers) that human baselines missed. The critical takeaway is the 'bi-dimensional co-evolution' strategy: explicitly maintaining and mutating a population of control flow graphs separate from the function bodies, which allows the system to escape the local optima imposed by a fixed human-designed harness. We must evaluate if this structural search approach can be integrated into AlgoEvo to automate our harness design.</details> | Zhe Zhao et.al. | Princeton University, Nanyang Technological University, City University of Hong Kong, University of Science and Technology of China, The Hong Kong University of Science and Technology (Guangzhou) | arXiv.org | [2503.10721](http://arxiv.org/abs/2503.10721) | ‚Äî |
| 9/30 | **2025-03-05** | <details><summary>**Leveraging Large Language Models to Develop Heuristics for Emerging Optimization Problems**</summary>B√∂mer et al. apply the Evolution of Heuristics (EoH) framework to the Unit-load Pre-marshalling Problem, proposing 'CEoH' which merely adds a static problem description to the prompt. Results show that while this context is crucial for smaller open-weights models (enabling Qwen-32B to slightly outperform GPT-4o on specific instances), it actually degrades the performance of GPT-4o compared to the baseline. The only takeaway for our AlgoEvo work is a confirmation that local model scaling requires verbose context injection, whereas frontier models may suffer from over-constrained prompts. This is an application paper with negligible algorithmic contribution.</details> | Thomas B√∂mer et.al. | TU Dortmund University, Karlsruhe Institute of Technology | arXiv.org | [2503.03350](http://arxiv.org/abs/2503.03350) | **[link](https://github.com/nico-koltermann/contextual-evolution-of-heuristics)** |
| 24/30 | **2025-02-21** | <details><summary>**QUBE: Enhancing Automatic Heuristic Design via Quality-Uncertainty Balanced Evolution**</summary>QUBE replaces FunSearch's naive score-based parent selection with a UCB algorithm that selects parents based on the *average quality of their offspring* (exploitation) plus an uncertainty term (exploration). The authors demonstrate that a parent's own score is a poor predictor of its ability to evolve further; treating parents as 'bandit arms' based on their lineage statistics yields significantly better results on Bin Packing and TSP with fewer samples. While they fail to beat DeepMind's massive-scale Cap Set record, the methodological insight regarding 'offspring-aware' selection is statistically validated and immediately transferable to our evolutionary search frameworks.</details> | Zijie Chen et.al. | Westlake University, Zhejiang University, University of Electronic Science and Technology of China |  | [2412.20694](http://arxiv.org/abs/2412.20694) | **[link](https://github.com/zzjchen/QUBE_code)** |
| 18/30 | **2025-02-13** | <details><summary>**Explainable AI-assisted Optimization for Feynman Integral Reduction**</summary>Song et al. apply FunSearch to evolve priority functions for Feynman integral reduction, achieving up to 3058x reduction in seeding integrals compared to standard heuristics. The results are rigorous, enabling previously impossible multi-loop calculations. The critical insight for us is the successful transfer of heuristics evolved on trivial 1-loop instances (fast evaluation) to complex 5-loop problems without retraining. We should adopt this 'evolve-on-toy, deploy-on-giant' evaluation protocol to drastically reduce compute costs in our VRP and SAT solver evolutionary search pipelines.</details> | Zhuo-Yang Song et.al. | Peking University, Universit
Z
rich, Beijing Computational Science Research Center |  | [2502.09544](http://arxiv.org/abs/2502.09544) | ‚Äî |
| 14/30 | **2025-02-07** | <details><summary>**Refining Integration-by-Parts Reduction of Feynman Integrals with Machine Learning**</summary>Von Hippel and Wilhelm apply FunSearch (LLM evolution) and Strongly Typed Genetic Programming (STGP) to optimize heuristics for Feynman integral reduction, improving on state-of-the-art human strategies (88 vs 92 seeds). The results are validated on a benchmark integral, demonstrating that STGP converges in ~30 generations compared to FunSearch's thousands when provided with the right primitives. **Key Takeaway:** A replicable workflow for sample efficiency: use the LLM to explore and identify relevant feature primitives (e.g., specific sums/counts), then lock those into a grammar for a cheaper, faster traditional GP search. This hybrid approach directly addresses our token-efficiency bottlenecks in AlgoEvo without discarding the LLM's creative exploration capabilities.</details> | Matt von Hippel et.al. | University of Copenhagen, University of Southern Denmark | Journal of High Energy Physics | [2502.05121](http://arxiv.org/abs/2502.05121) | ‚Äî |
| 25/30 | **2025-02-04** | <details><summary>**Multi-objective Evolution of Heuristic Using Large Language Model**</summary>MEoH extends LLM-based heuristic evolution (like FunSearch/EoH) to multi-objective scenarios (e.g., Gap vs. Runtime) by introducing a 'Dominance-Dissimilarity' mechanism that selects parents based on both Pareto dominance and Abstract Syntax Tree (AST) code distance. The results are credible and strong: on TSP, they find heuristics matching EoH's quality but running 16x faster (1.37s vs 22.4s) by effectively navigating the complexity-performance trade-off. The single most useful takeaway is the **AST-based dissimilarity metric** for population management; we should immediately steal this to prune semantically identical code in our evolutionary loops, thereby forcing exploration and improving sample efficiency. This is a direct upgrade to our current single-objective evolutionary search methods.</details> | Shunyu Yao et.al. | City University of Hong Kong, Southern University of Science and Technology | AAAI Conference on Artificial Intelligence | [2409.16867](http://arxiv.org/abs/2409.16867) | **[link](https://github.com/Optima-CityU/LLM4AD)** |
| 6/30 | **2025-01-11** | <details><summary>**AlgoPilot: Fully Autonomous Program Synthesis Without Human-Written Programs**</summary>Yin introduces AlgoPilot, which trains a 'Trajectory Language Model' on traces from randomly generated functions to guide an RL agent in sorting small arrays. While the concept of using a trace-based model as a reward signal (a structural Process Reward Model) to encourage program-like behavior is theoretically interesting, the execution is flawed: the 'random' generator explicitly hardcodes the double-loop structure required for sorting. The results are trivial (sorting arrays of size 14) and the method relies on GPT-4o for the final code synthesis, making it a proof-of-concept with no scalability or genuine autonomy.</details> | Xiaoxin Yin et.al. | Independent Researcher | arXiv.org | [2501.06423](http://arxiv.org/abs/2501.06423) | ‚Äî |
| 22/30 | **2024-12-19** | <details><summary>**HSEvo: Elevating Automatic Heuristic Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs**</summary>HSEvo extends LLM-based evolutionary search (LLM-EPS) by integrating a numerical parameter tuning step (Harmony Search) and a token-efficient 'Flash Reflection' mechanism that batches analysis of parent pairs. They report superior results over ReEvo and FunSearch on Bin Packing and TSP, validated by proposed diversity metrics based on code embeddings. **Key Takeaway:** We should implement the hybrid tuning pattern: explicitly parsing LLM-generated code to extract constants and tuning them with a cheap numerical optimizer (rather than asking the LLM to tune parameters), and adopt batched reflections to reduce inference costs.</details> | Pham Vu Tuan Dat et.al. | George Mason University, Hanoi University of Science and Technology | arXiv.org | [2412.14995](http://arxiv.org/abs/2412.14995) | **[link](https://github.com/datphamvn/HSEvo)** |
| 6/30 | **2024-12-09** | <details><summary>**LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments**</summary>Aryan presents 'DebateBrawl,' a web application that integrates LLMs with a basic Genetic Algorithm to tune rhetorical parameters (ethos/pathos) and Adversarial Search for move prediction. The paper focuses heavily on full-stack engineering (Next.js, Chakra UI) rather than algorithmic novelty, and the 'evolution' appears to be trivial prompt parameter tuning rather than the structural code evolution we pursue. The results are unreliable due to tiny sample sizes and internal data inconsistencies. There is no actionable insight here for our multi-agent debate or evolutionary search work.</details> | Prakash Aryan et.al. | Birla Institute of Technology and Science, Pilani - Dubai Campus | 2024 IEEE Conference on Engineering Informatics (ICEI) | [2412.06229](http://arxiv.org/abs/2412.06229) | ‚Äî |
| 23/30 | **2024-11-29** | <details><summary>**Amplifying human performance in combinatorial competitive programming**</summary>DeepMind applies FunSearch (using Gemini 1.5 Flash) to evolve scoring functions within human-written greedy backbones for Hash Code and AtCoder problems, achieving top-1% or rank-1 performance against humans. The results are robust, beating top human teams on 5/8 historical contests using a generic evolutionary setup. The critical takeaway is the 'switching variable' technique: using a single evolved function to handle multiple distinct decision points (e.g., selecting a vehicle vs. selecting a route) by passing a state flag, rather than evolving multiple interacting functions. This validates that generalist models (Flash) are sufficient for high-end OR evolution without code-specific fine-tuning. We should adopt their 'Backbone + Scorer' architecture for our VRP/Scheduling work immediately.</details> | Petar Veliƒçkoviƒá et.al. | Google DeepMind | arXiv.org | [2411.19744](http://arxiv.org/abs/2411.19744) | ‚Äî |
| 20/30 | **2024-10-30** | <details><summary>**Automatic programming via large language models with population self-evolution for dynamic job shop scheduling problem**</summary>This paper introduces SeEvo, an LLM-based evolutionary search for Dynamic Job Shop Scheduling heuristics that adds an 'individual self-reflection' loop‚Äîprompting the LLM to analyze performance differences of a specific rule before and after mutation‚Äîalongside standard population-level reflection. While they claim significant improvements over GP/GEP and DRL, the ablation study reveals only a marginal <1% improvement over the existing ReEvo framework on benchmark instances. The primary takeaway for us is the specific prompt engineering technique of injecting an individual's mutation history (previous code vs. current code performance) into the context to guide the next mutation, which could potentially improve sample efficiency in our own evolutionary loops despite their weak empirical validation.</details> | Jin Huang et.al. | Huazhong University of Science and Technology | arXiv.org | [2410.22657](http://arxiv.org/abs/2410.22657) | ‚Äî |
| 25/30 | **2024-10-14** | <details><summary>**ReEvo: Large Language Models as Hyper-Heuristics with Reflective Evolution**</summary>ReEvo integrates a 'Reflector LLM' into genetic programming that analyzes pairs of heuristics (better vs. worse) to generate textual 'verbal gradients' for crossover and mutation, maintaining a long-term memory of these insights. The results are strong and relevant: they outperform EoH (Evolution of Heuristics) and NCO baselines on TSP, CVRP, and Bin Packing with significantly higher sample efficiency (only ~100 evaluations). The single most useful takeaway is the 'Short-term Reflection' prompting strategy‚Äîexplicitly asking the LLM to derive a mutation direction by comparing the logic of high-fitness vs. low-fitness parents‚Äîwhich we should immediately test in our AlgoEvo framework to reduce sample costs. This is a direct methodological upgrade for our current evolutionary search pipelines.</details> | Haoran Ye et.al. | Peking University, KAIST, Singapore Management University, Southeast University, PKU-Wuhan Institute for AI | NeurIPS 2024 | [2402.01145](http://arxiv.org/abs/2402.01145) | **[link](https://github.com/AI4CO/ReEvo)** |
| 8/30 | **2024-10-06** | <details><summary>**Learning to Solve Abstract Reasoning Problems with Neurosymbolic Program Synthesis and Task Generation**</summary>TransCoder employs an RNN-based neurosymbolic synthesizer for ARC tasks, introducing a 'learning from mistakes' loop where programs that fail a target task are treated as ground-truth solutions for the input-output mapping they actually produced (effectively Hindsight Experience Replay). The empirical results are abysmal (2% on ARC test set), significantly underperforming even 2020 baselines (20%). While the concept of recycling failed search candidates to build a curriculum is relevant to sample efficiency, this paper provides no evidence that it scales to hard problems or competes with LLM-based approaches. We can safely ignore this implementation.</details> | Jakub Bednarek et.al. | Poznan University of Technology | International Workshop on Neural-Symbolic Learning and Reasoning | [2410.04480](http://arxiv.org/abs/2410.04480) | ‚Äî |
| 20/30 | **2024-07-15** | <details><summary>**Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models**</summary>Zhang et al. perform a rigorous benchmarking of major LLM-based evolutionary program search (EPS) methods (FunSearch, EoH, ReEvo) against a simple (1+1)-EPS baseline across four problems and nine LLMs. The results are empirically solid and sobering: the simple (1+1)-EPS baseline‚Äîiterative improvement via one-shot prompting‚Äîfrequently matches or outperforms the complex population-based methods, particularly on bin packing, though EoH remains superior on TSP. **Crucial Takeaway:** We are likely over-engineering our search mechanisms; we must implement a (1+1)-EPS baseline in all future experiments (AlgoEvo, EvoCut) because if our multi-agent systems cannot beat this simple hill-climber, our papers will be rejected for unnecessary complexity. Additionally, they find that larger models (GPT-4) do not strictly guarantee better heuristic search performance compared to smaller, code-specialized models like CodeLlama-7B.</details> | Rui Zhang et.al. | City University of Hong Kong, Southern University of Science and Technology | the 18th International Conference on Parallel Problem Solving From Nature (PPSN 2024) | [2407.10873](http://arxiv.org/abs/2407.10873) | **[link](https://github.com/zhichao-lu/llm-eps)** |
| 23/30 | **2024-07-01** | <details><summary>**FunBO: Discovering Acquisition Functions for Bayesian Optimization with FunSearch**</summary>FunBO applies FunSearch to evolve Python code for Bayesian Optimization acquisition functions, evaluating fitness by running full BO loops on synthetic functions. The results are empirically strong, showing that evolved AFs generalize well to out-of-distribution functions and outperform standard baselines like EI and UCB. The most stealable insight is their 'few-shot' adaptation strategy, where a general-purpose heuristic is rapidly fine-tuned on a small set of target instances‚Äîa technique we should immediately test for our VRP heuristics. While the method is computationally expensive (brute-forcing the inner loop), the interpretable code outputs provide concrete ideas for dynamic exploration-exploitation trade-offs.</details> | Virginia Aglietti et.al. | Google DeepMind | International Conference on Machine Learning | [2406.04824](http://arxiv.org/abs/2406.04824) | ‚Äî |
| 4/30 | **2024-06-08** | <details><summary>**Large Language Model Assisted Adversarial Robustness Neural Architecture Search**</summary>Zhong et al. employ Gemini with a structured prompt template (CRISPE) to iteratively select neural architectures from the NAS-Bench-201 lookup table to maximize adversarial robustness. The approach is a basic single-solution iterative loop without population dynamics, crossover, or novel feedback mechanisms. The results are statistically weak given the tiny search space (6,466 items), which could be solved by simple enumeration or random search. There are no transferable insights for our large-scale evolutionary search or multi-agent optimization projects.</details> | Rui Zhong et.al. | Hokkaido University, Niigata University | The 6th International Conference on Data-driven Optimization of Complex Systems (DOCS) | [2406.05433](http://arxiv.org/abs/2406.05433) | **[link](https://github.com/RuiZhong961230/LLMO)** |
| 19/30 | **2024-06-01** | <details><summary>**tnGPS: Discovering Unknown Tensor Network Structure Search Algorithms via Large Language Models (LLMs)**</summary>The authors propose tnGPS, a FunSearch-style framework that evolves Python code for Tensor Network Structure Search by mimicking human innovation stages (categorization, recombination, diversity injection). While the application (Tensor Networks) is niche, the results outperform standard heuristics like TNGA and TNLS. The critical takeaway for us is the 'Knowledge Categorization' phase: they use the LLM to semantically cluster the population of generated algorithms to manage diversity and guide the 'Diversity Injection' step. We should immediately implement this LLM-based population clustering in AlgoEvo to prevent convergence on similar code patterns.</details> | Junhua Zeng et.al. | RIKEN Center for Advanced Intelligence Project, Tencent Inc., Guangdong University of Technology | ICML2024 | [2402.02456](http://arxiv.org/abs/2402.02456) | **[link](https://github.com/ChaoLiAtRIKEN/tngps)** |
| 25/30 | **2024-06-01** | <details><summary>**Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model**</summary>EoH introduces a dual-track evolutionary framework that evolves both natural language 'thoughts' (heuristic logic) and their corresponding Python code, rather than code alone. On Online Bin Packing, it claims to outperform DeepMind's FunSearch while using only ~2,000 LLM queries (vs FunSearch's millions), and achieves SOTA gaps on TSP and FSSP via Guided Local Search. The critical takeaway is the 'E2' prompt strategy: explicitly asking the LLM to extract common ideas from parent heuristics into a natural language 'thought' before generating code, which acts as a genetic Chain-of-Thought to stabilize mutation. We should immediately implement this 'Thought-then-Code' mutation operator in our AlgoEvo pipeline to address our sample efficiency bottlenecks.</details> | Fei Liu et.al. | Huawei Noah‚Äôs Ark Lab, City University of Hong Kong, Southern University of Science and Technology | International Conference on Machine Learning | [2401.02051](http://arxiv.org/abs/2401.02051) | **[link](https://github.com/FeiLiu36/EoH)** |
| 18/30 | **2024-03-18** | <details><summary>**LLM Guided Evolution -- The Automation of Models Advancing Models**</summary>Morris et al. propose 'Guided Evolution,' an LLM-based NAS framework that introduces 'Evolution of Thought' (EoT) and 'Character Role Play' to guide code mutations. While the results are statistically negligible (single trials, ~0.8% gain on CIFAR-10), the EoT mechanism offers a specific, actionable prompt engineering technique: explicitly prompting the LLM to compare a successful elite individual against its original seed to extract 'reasoning' before applying mutations to new individuals. This serves as a lightweight, prompt-based memory/feedback mechanism that could immediately improve sample efficiency in our evolutionary search agents. The 'Character Role Play' (e.g., asking the LLM to act as 'Dr. MaGoo' for unorthodox ideas) is a gimmicky but potentially useful heuristic for maintaining population diversity.</details> | Clint Morris et.al. | Georgia Tech Research Institute | Annual Conference on Genetic and Evolutionary Computation | [2403.11446](http://arxiv.org/abs/2403.11446) | **[link](https://github.com/clint-kristopher-morris/llm-guided-evolution)** |
| 24/30 | **2024-03-05** | <details><summary>**Evolution Transformer: In-Context Evolutionary Optimization**</summary>Lange et al. introduce the Evolution Transformer, a causal architecture that learns to perform evolutionary strategy updates by attending to optimization history, effectively 'distilling' algorithms like CMA-ES into a neural network. Crucially, they propose 'Self-Referential Algorithm Distillation' (SR-EAD), where the model improves itself by perturbing its own weights, generating trajectories, and filtering for the best ones to retrain on‚Äîeliminating the need for a teacher. The results are strong, showing generalization to unseen Brax control tasks and successful (though sometimes unstable) self-bootstrapping. The key takeaway for us is the SR-EAD loop as a mechanism for open-ended optimizer improvement, and their use of Perceiver cross-attention to handle variable population sizes‚Äîa technique we should immediately steal for our multi-agent memory architectures.</details> | Robert Tjarko Lange et.al. | Google DeepMind, TU Berlin | GECCO Companion | [2403.02985](http://arxiv.org/abs/2403.02985) | **[link](https://github.com/RobertTLange/evosax)** |
| 11/30 | **2024-02-05** | <details><summary>**Open-Universe Indoor Scene Generation using LLM Program Synthesis and Uncurated Object Databases**</summary>Aguina-Kang et al. generate 3D scenes by prompting an LLM to write declarative Python programs (defining objects and spatial relations) which are then solved via gradient-based optimization. They demonstrate that LLMs perform significantly better at generating relational constraints than direct coordinate prediction, validating the neuro-symbolic architecture where the LLM handles specification and a solver handles instantiation. While the error-handling heuristics for unsatisfiable constraints (backtracking to the LLM) are practically sound, the specific gradient-based solver for spatial constraints is not applicable to our discrete combinatorial problems.</details> | Rio Aguina-Kang et.al. | Brown University, UC San Diego, Dymaxion, LLC | arXiv.org | [2403.09675](http://arxiv.org/abs/2403.09675) | ‚Äî |
| 5/30 | **2024-01-22** | <details><summary>**Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis**</summary>This study fine-tunes WizardCoder and GPT-3.5 for Text-to-SQL synthesis, adding a multi-stage correction loop that utilizes execution errors and ground truth result tables to refine queries. While they report 82.1% accuracy, the approach appears to rely on oracle access to gold result tables during the correction phase, making it less of an autonomous agent and more of a guided system. For us, the only marginal value is the error analysis showing that structural query errors are resistant to few-shot correction, but this is a known phenomenon in code generation. There are no novel evolutionary or multi-agent components to harvest.</details> | Richard Roberson et.al. | University of Colorado Boulder | arXiv.org | [2401.12379](http://arxiv.org/abs/2401.12379) | **[link](https://huggingface.co/richardr1126/spider-skeleton-wizard-coder-merged)** |

</details>

## OR for Generative AI

### üÜï Most Recent

| Date | Title | Authors | Affiliation | Code |
|------|-------|---------|-------------|------|
| **2026-02-16** | **Efficient Multi-round LLM Inference over Disaggregated Serving** | Wenhao He et.al. |  | ‚Äî |
| **2026-02-16** | **Scalable Multi-Robot Path Planning via Quadratic Unconstrained Binary Optimization** | Javier Gonz√°lez Villasmil et.al. |  | ‚Äî |
| **2026-02-13** | **AI Agents for Inventory Control: Human-LLM-OR Complementarity** | Jackie Baek et.al. |  | ‚Äî |
| **2026-02-10** | **Towards Poisoning Robustness Certification for Natural Language Generation** | Mihnea Ghitu et.al. |  | ‚Äî |
| **2026-02-09** | <details><summary>**OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval**</summary>Wang et al. formulate agentic tool-use planning not as a heuristic search (ReAct), but as a two-stage Mixed-Integer Programming (MIP) problem that solves for the mathematically optimal trajectory (tool selection + set operations) on training data. These 'golden trajectories' are then used as retrieved in-context demonstrations to steer the VLM at inference time, achieving SOTA on CIR benchmarks with only 10% of training data. **Key Takeaway:** We can steal this 'Offline MIP $\to$ Online ICL' paradigm. Instead of relying on noisy online RL or expensive evolutionary loops to guide our AlgoEvo agents, we can solve MIPs on training instances to generate optimal reasoning traces, effectively 'solving' the prompt engineering problem via OR.</details> | Teng Wang et.al. | Shanghai Jiao Tong University, OPPO | **[link](https://anonymous.4open.science/r/OSCAR-3A55/README.md)** |

### ‚≠ê Best Papers

| Score | Date | Title | Authors | Affiliation | Code |
|-------|------|-------|---------|-------------|------|
| 26/30 | **2026-01-05** | <details><summary>**Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints**</summary>This paper formulates LLM inference as a multi-stage stochastic scheduling problem, introducing 'Nested WAIT'‚Äîa threshold-based algorithm that handles unknown output lengths by letting prompts classify themselves as they survive into deeper decode segments. Unlike heuristic baselines (vLLM, Sarathi), they provide rigorous asymptotic optimality proofs and high-probability bounds against memory overflow, validated on A100 simulations. The key takeaway is the 'nested segment' mechanism: instead of predicting job size, structure the queue so short jobs exit early and long jobs naturally migrate to lower-priority/protected tiers, effectively decoupling the memory risk. We should immediately evaluate this threshold logic for our GPUSched formulations, as it likely outperforms our current predictive or FCFS approaches for handling KV cache growth.</details> | Ruicheng Ao et.al. | Massachusetts Institute of Technology, Peking University, Alibaba Group | ‚Äî |
| 25/30 | **2026-02-07** | <details><summary>**A Two-Layer Framework for Joint Online Configuration Selection and Admission Control**</summary>The authors introduce a 'switching-aware' primal-dual framework for joint configuration selection (e.g., quantization, parallelism) and admission control, demonstrating that dynamically mixing configurations allows for higher resource utilization than any single fixed configuration. Results are rigorous, backed by $\tilde{O}(\sqrt{T})$ regret bounds and experiments on Alibaba cluster traces where the method achieves ~97% competitive ratio (vs. ~85% for greedy). The key takeaway is the 'switching-aware fluid oracle' concept: our resource allocation models for LLM serving must optimize over the convex hull of configurations (mixing CPU-heavy and Mem-heavy setups) rather than searching for a single static optimum. We should adapt their saddle-point formulation for the GPUSched project to handle heterogeneous resource constraints more effectively.</details> | Owen Shen et.al. | Massachusetts Institute of Technology, Stanford University | ‚Äî |
| 25/30 | **2026-02-03** | <details><summary>**3D-Learning: Diffusion-Augmented Distributionally Robust Decision-Focused Learning**</summary>Wen et al. introduce '3D-Learning,' a framework that replaces analytic ambiguity sets (Wasserstein/KL) in Distributionally Robust Optimization (DRO) with a diffusion model trained via PPO to generate worst-case scenarios. Applied to LLM resource provisioning, they claim ~40-50% regret reduction on OOD Azure traces compared to standard DRO, though training computational cost is high (6.8GB memory vs 35MB). The critical takeaway is the methodology of parameterizing the ambiguity set with a generative model to find 'realistic' adversarial edge cases that respect the data manifold, solving the support shift issue of KL-DRO. We should steal this 'generative ambiguity set' concept for benchmarking our heuristics in RobustMAS and AlgoEvo.</details> | Jiaqi Wen et.al. | University of Houston | **[link](https://github.com/CIGLAB-Houston/3DLearning.git)** |
| 25/30 | **2025-07-21** | <details><summary>**DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving**</summary>DHEvo introduces a 'data-algorithm co-evolution' framework that iteratively evolves heuristic code while simultaneously filtering the training instance set to retain only 'representative' instances (those where current heuristics perform well/stably). Empirical results on SCIP diving heuristics show it outperforms FunSearch and EoH by ~60% on Setcover while significantly reducing performance variance, validating the claim that dynamic data curation prevents overfitting. The key takeaway is the counter-intuitive curriculum strategy: rather than training on the hardest instances, filtering for instances with 'regular' feasible regions (high fitness) stabilizes the evolutionary search for code. We should immediately test this dynamic instance filtering in AlgoEvo to improve sample efficiency and generalization.</details> | Zhihao Zhang et.al. | Harbin Institute of Technology, Huawei Noah‚Äôs Ark Lab, Nanyang Technological University | ‚Äî |
| 25/30 | **2025-03-05** | <details><summary>**Helix: Serving Large Language Models over Heterogeneous GPUs and Network via Max-Flow**</summary>Helix formulates distributed LLM serving on heterogeneous clusters as a max-flow problem, using MILP to optimize model placement and deriving a per-request weighted round-robin scheduler from the flow solution. Unlike standard static pipeline parallelism, it routes every request dynamically based on edge capacities, achieving up to 3.3x throughput gains over Swarm on mixed GPU clusters (L4/T4/A100). The results are rigorous, backed by both physical cluster experiments and high-fidelity simulations. The critical takeaway is the 'per-request pipeline' abstraction: decoupling request routing from static device assignment allows exact OR methods to maximize utilization of weaker hardware‚Äîa technique we should immediately evaluate for our GPUSched project.</details> | Yixuan Mei et.al. | Carnegie Mellon University | **[link](https://github.com/Thesys-lab/Helix-ASPLOS25)** |

### üî¨ Research Fronts

| Status | Front Name | Papers | Key Methods | Problems |
|--------|-----------|--------|-------------|----------|
| New | OR for LLM Serving: Resource Allocation and Scheduling via MILP and Queueing Networks | 4 | Bi Level Optimization, Mixed Integer Linear Programming, Chebyshev Guided Optimization | Llm Serving Optimization, Resource Allocation |

<details>
<summary>üìã Full list (190 papers, sorted by date)</summary>

| Score | Date | Title | Authors | Affiliation | Venue | PDF | Code |
|-------|------|-------|---------|-------------|-------|-----|------|
| ‚Äî | **2026-02-16** | **Efficient Multi-round LLM Inference over Disaggregated Serving** | Wenhao He et.al. |  |  | [2602.14516](http://arxiv.org/abs/2602.14516) | ‚Äî |
| ‚Äî | **2026-02-16** | **Scalable Multi-Robot Path Planning via Quadratic Unconstrained Binary Optimization** | Javier Gonz√°lez Villasmil et.al. |  |  | [2602.14799](http://arxiv.org/abs/2602.14799) | ‚Äî |
| ‚Äî | **2026-02-13** | **AI Agents for Inventory Control: Human-LLM-OR Complementarity** | Jackie Baek et.al. |  |  | [2602.12631](http://arxiv.org/abs/2602.12631) | ‚Äî |
| ‚Äî | **2026-02-10** | **Towards Poisoning Robustness Certification for Natural Language Generation** | Mihnea Ghitu et.al. |  |  | [2602.09757](http://arxiv.org/abs/2602.09757) | ‚Äî |
| 21/30 | **2026-02-09** | <details><summary>**OSCAR: Optimization-Steered Agentic Planning for Composed Image Retrieval**</summary>Wang et al. formulate agentic tool-use planning not as a heuristic search (ReAct), but as a two-stage Mixed-Integer Programming (MIP) problem that solves for the mathematically optimal trajectory (tool selection + set operations) on training data. These 'golden trajectories' are then used as retrieved in-context demonstrations to steer the VLM at inference time, achieving SOTA on CIR benchmarks with only 10% of training data. **Key Takeaway:** We can steal this 'Offline MIP $\to$ Online ICL' paradigm. Instead of relying on noisy online RL or expensive evolutionary loops to guide our AlgoEvo agents, we can solve MIPs on training instances to generate optimal reasoning traces, effectively 'solving' the prompt engineering problem via OR.</details> | Teng Wang et.al. | Shanghai Jiao Tong University, OPPO |  | [2602.08603](http://arxiv.org/abs/2602.08603) | **[link](https://anonymous.4open.science/r/OSCAR-3A55/README.md)** |
| 24/30 | **2026-02-09** | <details><summary>**Predicting Future Utility: Global Combinatorial Optimization for Task-Agnostic KV Cache Eviction**</summary>Tang et al. formulate KV cache eviction not as a heuristic filtering task, but as a global combinatorial optimization problem maximizing 'Oracle Importance' (future utility) across all attention heads. They solve this NP-hard problem efficiently by applying Isotonic Regression (via PAVA) to create a convex surrogate of the eviction loss, enabling an optimal greedy allocation strategy that is deployed via an offline-computed lookup table. Results are strong: they achieve 80% cache reduction on LongBench and RULER with minimal degradation, significantly outperforming dynamic heuristics like AdaKV. **Key Takeaway:** The decomposition of error into 'ranking error' vs. 'allocation error'‚Äîand solving the latter via convex-hull relaxation‚Äîis a powerful OR pattern we should apply to our own resource allocation and scheduling problems.</details> | Ziyao Tang et.al. | Baidu, Fudan University |  | [2602.08585](http://arxiv.org/abs/2602.08585) | ‚Äî |
| ‚Äî | **2026-02-09** | **Nimbus: A Unified Embodied Synthetic Data Generation Framework** | Zeyu He et.al. |  |  | [2601.21449](http://arxiv.org/abs/2601.21449) | ‚Äî |
| ‚Äî | **2026-02-08** | **Solver-in-the-Loop: MDP-Based Benchmarks for Self-Correction and Behavioral Rationality in Operations Research** | Ruicheng Ao et.al. |  |  | [2601.21008](http://arxiv.org/abs/2601.21008) | ‚Äî |
| 25/30 | **2026-02-07** | <details><summary>**A Two-Layer Framework for Joint Online Configuration Selection and Admission Control**</summary>The authors introduce a 'switching-aware' primal-dual framework for joint configuration selection (e.g., quantization, parallelism) and admission control, demonstrating that dynamically mixing configurations allows for higher resource utilization than any single fixed configuration. Results are rigorous, backed by $\tilde{O}(\sqrt{T})$ regret bounds and experiments on Alibaba cluster traces where the method achieves ~97% competitive ratio (vs. ~85% for greedy). The key takeaway is the 'switching-aware fluid oracle' concept: our resource allocation models for LLM serving must optimize over the convex hull of configurations (mixing CPU-heavy and Mem-heavy setups) rather than searching for a single static optimum. We should adapt their saddle-point formulation for the GPUSched project to handle heterogeneous resource constraints more effectively.</details> | Owen Shen et.al. | Massachusetts Institute of Technology, Stanford University |  | [2602.07663](http://arxiv.org/abs/2602.07663) | ‚Äî |
| 19/30 | **2026-02-06** | <details><summary>**tLoRA: Efficient Multi-LoRA Training with Elastic Shared Super-Models**</summary>tLoRA optimizes multi-tenant LoRA training by fusing heterogeneous adapters into a 'Shared Super-Model' and employing an online scheduler that groups jobs based on residual GPU capacity and urgency. They report 1.2‚Äì1.8x throughput improvements and ~5x faster job completion times on A100 clusters compared to mLoRA, backed by realistic trace-driven experiments. For our GPUSched and resource allocation work, their hierarchical incremental grouping strategy serves as the state-of-the-art heuristic baseline we must outperform; additionally, their adaptive nano-batching (AIMD controller) is a transferable engineering trick for overlapping communication in distributed LLM workloads.</details> | Kevin Li et.al. | University of Illinois Urbana-Champaign |  | [2602.07263](http://arxiv.org/abs/2602.07263) | ‚Äî |
| ‚Äî | **2026-02-05** | **Dynamic Quantum Optimal Communication Topology Design for Consensus Control in Linear Multi-Agent Systems** | Milad Hasanzadeh et.al. | Louisiana State University |  | [2602.06215](http://arxiv.org/abs/2602.06215) | ‚Äî |
| ‚Äî | **2026-02-04** | **MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research** | Yifan Shi et.al. |  |  | [2602.03318](http://arxiv.org/abs/2602.03318) | ‚Äî |
| ‚Äî | **2026-02-04** | **MaMa: A Game-Theoretic Approach for Designing Safe Agentic Systems** | Jonathan N√∂ther et.al. |  |  | [2602.04431](http://arxiv.org/abs/2602.04431) | ‚Äî |
| 24/30 | **2026-02-03** | <details><summary>**Large-Scale LLM Inference with Heterogeneous Workloads: Prefill-Decode Contention and Asymptotically Optimal Control**</summary>Lin et al. formulate LLM inference scheduling as a multiclass many-server queueing network, deriving a 'Gate-and-Route' policy from a steady-state fluid LP that explicitly manages prefill-decode contention. Calibrated on A100s, their approach proves that separating prefill admission (via occupancy tracking) from decode routing (work-conserving) eliminates decode backlogs and maximizes revenue. **Key Takeaway:** The decomposition of scheduling into 'static planning' (solving an LP for target occupancies) and 'dynamic control' (a simple gate tracking those targets) is a scalable alternative to online combinatorial optimization for your GPUSched work. It mathematically formalizes the intuition that prefill is the bottleneck and decode should be kept strictly critical but not backlogged.</details> | Ruihan Lin et.al. | The Hong Kong University of Science and Technology |  | [2602.02987](http://arxiv.org/abs/2602.02987) | ‚Äî |
| 25/30 | **2026-02-03** | <details><summary>**3D-Learning: Diffusion-Augmented Distributionally Robust Decision-Focused Learning**</summary>Wen et al. introduce '3D-Learning,' a framework that replaces analytic ambiguity sets (Wasserstein/KL) in Distributionally Robust Optimization (DRO) with a diffusion model trained via PPO to generate worst-case scenarios. Applied to LLM resource provisioning, they claim ~40-50% regret reduction on OOD Azure traces compared to standard DRO, though training computational cost is high (6.8GB memory vs 35MB). The critical takeaway is the methodology of parameterizing the ambiguity set with a generative model to find 'realistic' adversarial edge cases that respect the data manifold, solving the support shift issue of KL-DRO. We should steal this 'generative ambiguity set' concept for benchmarking our heuristics in RobustMAS and AlgoEvo.</details> | Jiaqi Wen et.al. | University of Houston |  | [2602.02943](http://arxiv.org/abs/2602.02943) | **[link](https://github.com/CIGLAB-Houston/3DLearning.git)** |
| 21/30 | **2026-02-03** | <details><summary>**PROBE: Co-Balancing Computation and Communication in MoE Inference via Real-Time Predictive Prefetching**</summary>PROBE optimizes MoE inference by using a distilled MLP to predict next-layer expert activation, enabling proactive load balancing and weight prefetching hidden behind the current layer's computation. The results are strong (1.3x speedup on 235B models) and demonstrate that control plane overheads can be fully masked. The critical takeaway for our `GPUSched` project is the **Lookahead Pipelining** architecture: it carves out a deterministic execution window where we could inject our own specialized solvers (e.g., fast ALNS or IP formulations) to outperform their basic greedy resource allocator. This transforms the stochastic serving problem into a short-horizon deterministic routing problem we are well-equipped to solve.</details> | Qianchao Zhu et.al. | Kling Infra, Kuaishou Technology |  | [2602.00509](http://arxiv.org/abs/2602.00509) | ‚Äî |
| ‚Äî | **2026-02-03** | **Game-Theoretic and Algorithmic Analyses of Multi-Agent Routing under Crossing Costs** | Tesshu Hanaka et.al. |  |  | [2602.03455](http://arxiv.org/abs/2602.03455) | ‚Äî |
| 8/30 | **2026-02-02** | <details><summary>**Distributed Hierarchical Machine Learning for Joint Resource Allocation and Slice Selection in In-Network Edge Systems**</summary>Rashid et al. decompose an edge resource allocation MINLP into three subproblems and train a DeepSets architecture to approximate the optimal solver's decisions. They introduce a 'slack-aware' decoder (adding a dummy output node to the softmax) to enforce inequality constraints where resource usage must be $\le$ capacity. While they claim an 86% speedup over Gurobi/Ipopt with a <6% optimality gap, the approach relies entirely on expensive offline label generation and offers no methodological novelty for our evolutionary search or LLM-based optimization tracks. The slack-node trick is a basic implementation detail, not a research advance.</details> | Sulaiman Muhammad Rashid et.al. | Chonnam National University | arXiv.org | [2511.13313](http://arxiv.org/abs/2511.13313) | ‚Äî |
| ‚Äî | **2026-02-02** | **Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation** | Zhongyuan Lyu et.al. |  |  | [2602.02029](http://arxiv.org/abs/2602.02029) | ‚Äî |
| 19/30 | **2026-02-01** | <details><summary>**SNIP: An Adaptive Mixed Precision Framework for Subbyte Large Language Model Training**</summary>Pan et al. introduce SNIP, a framework that periodically solves a Knapsack-style Integer Linear Program (ILP) to assign layer-wise precision (FP4/FP8) during training, minimizing a custom 'divergence' metric subject to FLOPs constraints. Results are simulated via fake quantization (proxy FLOPs) rather than wall-clock time on native hardware, but the method scales to 70B models and outperforms heuristic baselines. **Key Takeaway:** The design pattern of 'collect sensitivity stats -> solve lightweight ILP -> dynamic reconfiguration' is highly relevant for our work on optimizing LLM serving and agent compute budgets; it proves standard OR solvers are fast enough to operate within the runtime loop of high-performance AI systems.</details> | Yunjie Pan et.al. | University of Michigan, NTT Research, Inc., University of Massachusetts Amherst |  | [2602.01410](http://arxiv.org/abs/2602.01410) | **[link](https://github.com/pyjhzwh/SNIP)** |
| 22/30 | **2026-02-01** | <details><summary>**Predictive Scheduling for Efficient Inference-Time Reasoning in Large Language Models**</summary>Brown et al. propose a 'Predictive Scheduling' framework that trains lightweight predictors (MLP on hidden states or LoRA) to estimate required CoT length before generation, using a greedy algorithm to allocate tokens under a global budget. Results show a 7.9% accuracy gain on GSM8K over uniform batching, backed by a systematic layer-wise analysis. **The key takeaway for us is that middle transformer layers (12-17)‚Äînot the final layer‚Äîcontain the highest signal-to-noise ratio for predicting reasoning difficulty.** We should immediately test extracting features from these layers for our AlgoEvo value functions to improve sample efficiency. While the greedy scheduling algorithm itself is standard OR, the application to internal model states for pre-run allocation is a valid efficiency win for our serving optimization work.</details> | Katrina Brown et.al. | Harvard University |  | [2602.01237](http://arxiv.org/abs/2602.01237) | **[link](https://aneeshers.github.io/predictive-scheduling/)** |
| ‚Äî | **2026-02-01** | **EvoOpt-LLM: Evolving industrial optimization models with large language models** | Yiliu He et.al. |  |  | [2602.01082](http://arxiv.org/abs/2602.01082) | ‚Äî |
| 14/30 | **2026-02-01** | <details><summary>**SFMP: Fine-Grained, Hardware-Friendly and Search-Free Mixed-Precision Quantization for Large Language Models**</summary>SFMP introduces a search-free mixed-precision quantization framework that uses Fisher information to deterministically reorder weights into hardware-friendly blocks, processed by a unified LUT-based GEMM kernel. The results are empirically strong, outperforming search-based baselines (AMQ) in both accuracy and setup time, while demonstrating that lower bit-widths can actually increase inference speed on GPUs (unlike standard kernels). The key takeaway is the 'row-column reordering' heuristic which successfully clusters unstructured salience into structured blocks, effectively bypassing the need for the combinatorial optimization/evolutionary search we typically apply to such allocation problems. This is relevant for our 'LLM serving optimization' work as it alters the latency/memory trade-off curve we model.</details> | Xin Nie et.al. | Nankai University |  | [2602.01027](http://arxiv.org/abs/2602.01027) | **[link](https://github.com/Nkniexin/SFMP)** |
| ‚Äî | **2026-02-01** | **Hard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization** | Yang Liu et.al. |  |  | [2602.01090](http://arxiv.org/abs/2602.01090) | ‚Äî |
| ‚Äî | **2026-02-01** | **BOA Constrictor: Squeezing Performance out of GPUs in the Cloud via Budget-Optimal Allocation** | Zhouzi Li et.al. |  |  | [2602.01404](http://arxiv.org/abs/2602.01404) | ‚Äî |
| ‚Äî | **2026-01-31** | **FedLoDrop: Federated LoRA with Dropout for Generalized LLM Fine-tuning** | Sijing Xie et.al. |  | IEEE Journal on Selected Areas in Communications | [2510.12078](http://arxiv.org/abs/2510.12078) | ‚Äî |
| 18/30 | **2026-01-30** | <details><summary>**Foundation Models for Logistics: Toward Certifiable, Conversational Planning Interfaces**</summary>Yang et al. introduce a neurosymbolic agent that translates natural language into PDDL goals, using a learned latent space to estimate 'intent uncertainty' (distance to class centroids) which gates downstream execution. They use this uncertainty signal to drive both Direct Preference Optimization (DPO) and prompt optimization (TextGrad), achieving higher accuracy than GPT-5 on a lightweight model. **Takeaway:** The concept of deriving a 'probabilistic guarantee' from latent embeddings to serve as a cheap proxy reward or filter is a concrete technique we should test in AlgoEvo to reduce expensive evaluations. However, be skeptical of the topline results as they rely on a simplistic 3-class classification task rather than complex reasoning.</details> | Yunhao Yang et.al. | Neurosymbolic Intelligence, The University of Texas at Austin, University of Colorado Boulder | arXiv.org | [2507.11352](http://arxiv.org/abs/2507.11352) | ‚Äî |
| ‚Äî | **2026-01-30** | **PerfGuard: A Performance-Aware Agent for Visual Content Generation** | Zhipeng Chen et.al. |  | ICLR 2026 | [2601.22571](http://arxiv.org/abs/2601.22571) | **[link](https://github.com/FelixChan9527/PerfGuard)** |
| 16/30 | **2026-01-29** | <details><summary>**DASH: Deterministic Attention Scheduling for High-throughput Reproducible LLM Training**</summary>Qiang et al. formulate the deterministic attention backward pass as a DAG scheduling problem, proposing a 'Shift Scheduling' strategy (cyclic tile assignment) that eliminates pipeline bubbles caused by serialized gradient accumulation. They demonstrate up to 1.28x speedup on H800 GPUs, effectively removing the performance penalty for reproducible training. The most useful takeaway is the 'Shift Scheduling' pattern‚Äîusing cyclic offsets to naturally enforce conflict-free resource access without explicit locks‚Äîwhich is a transferable primitive for parallel resource allocation in our multi-agent systems. For us, this primarily serves as an infrastructure enabler: it allows us to run reproducible evolutionary baselines (AlgoEvo) without the usual 30%+ compute tax.</details> | Xinwei Qiang et.al. | ByteDance, Shanghai Jiao Tong University |  | [2601.21824](http://arxiv.org/abs/2601.21824) | **[link](https://github.com/SJTU-Liquid/deterministic-FA3)** |
| 10/30 | **2026-01-29** | <details><summary>**CORE:Toward Ubiquitous 6G Intelligence Through Collaborative Orchestration of Large Language Model Agents Over Hierarchical Edge**</summary>Yu et al. propose CORE, a framework for distributing LLM agents across edge and cloud devices using a 'Role Affinity Scheduling' algorithm, which is essentially a variant of the Heterogeneous Earliest Finish Time (HEFT) heuristic. They claim improved latency and task completion over ReAct and CrewAI in a fire detection scenario, though the evaluation relies on a limited set of 300 instructions without deep statistical rigor. The primary takeaway is a practical engineering trick: using an offline Digital Twin to pre-train a 'scheduling policy lookup table' to avoid expensive online simulations during inference. For our work on rigorous GPU scheduling and evolutionary search, this offers no new algorithmic insights.</details> | Zitong Yu et.al. | Beijing University of Posts and Telecommunications | IEEE Communications Magazine | [2601.21822](http://arxiv.org/abs/2601.21822) | ‚Äî |
| ‚Äî | **2026-01-28** | **DCP-Bench-Open: Evaluating LLMs for Constraint Modelling of Discrete Combinatorial Problems** | Kostis Michailidis et.al. |  | ECAI25) | [2506.06052](http://arxiv.org/abs/2506.06052) | **[link](https://github.com/kostis-init/CP-Bench)** |
| 17/30 | **2026-01-27** | <details><summary>**Modular Foundation Model Inference at the Edge: Network-Aware Microservice Optimization**</summary>Zhu et al. propose a two-tier resource allocation framework for edge-based Foundation Model inference, separating 'core' layers (static placement via IP) from 'light' layers (dynamic control via Lyapunov optimization). The results are simulation-based and show improvements over weak baselines like Round Robin, but the rigorous modeling of service dependencies is relevant. The key takeaway is their use of **Effective Capacity theory** to analytically map stochastic processing times into deterministic constraints within the optimization loop‚Äîa specific formulation trick we should steal for handling variance in our own stochastic MAS and LLM serving optimization models.</details> | Juan Zhu et.al. | The Hong Kong University of Science and Technology |  | [2601.19563](http://arxiv.org/abs/2601.19563) | ‚Äî |
| ‚Äî | **2026-01-27** | **ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks** | Haoyun Li et.al. |  |  | [2601.19607](http://arxiv.org/abs/2601.19607) | ‚Äî |
| 9/30 | **2026-01-23** | <details><summary>**Stochastic Modeling and Resource Dimensioning of Multi-Cellular Edge Intelligent Systems**</summary>The authors propose a stochastic geometry and queueing theory framework to jointly dimension wireless bandwidth and edge compute for video analytics, solving the resulting non-convex problem via convex decomposition. Results are analytical and simulation-based, highlighting that network densification requires proportional frequency reuse to be cost-effective. While the rigorous handling of tail-latency constraints via M/D/1 queueing is competent, the heavy reliance on wireless channel modeling (fading, interference, base station geometry) makes this irrelevant for our work on LLM evolutionary search or cluster-level GPU scheduling.</details> | Jaume Anguera Peris et.al. | KTH Royal Institute of Technology |  | [2601.16848](http://arxiv.org/abs/2601.16848) | ‚Äî |
| ‚Äî | **2026-01-21** | **Equal-Pay Contracts** | Michal Feldman et.al. |  | arXiv.org | [2601.15478](http://arxiv.org/abs/2601.15478) | **[link](https://github.com/ArjunShah1107/----United-Nation-s-Sustainable-Development-Goals-------Author-Arjun-S.-Shah-------School-U)** |
| ‚Äî | **2026-01-19** | **Cache Your Prompt When It's Green: Carbon-Aware Caching for Large Language Model Serving** | Yuyang Tian et.al. |  |  | [2505.23970](http://arxiv.org/abs/2505.23970) | ‚Äî |
| ‚Äî | **2026-01-19** | **VectorLiteRAG: Latency-Aware and Fine-Grained Resource Partitioning for Efficient RAG** | Junkyum Kim et.al. |  |  | [2504.08930](http://arxiv.org/abs/2504.08930) | ‚Äî |
| 8/30 | **2026-01-18** | <details><summary>**Cross-reality Location Privacy Protection in 6G-enabled Vehicular Metaverses: An LLM-enhanced Hybrid Generative Diffusion Model-based Approach**</summary>The authors propose LHDPPO, a reinforcement learning framework that uses an LLM to iteratively refine reward functions and diffusion models to generate hybrid actions for vehicular privacy. While the concept of an 'LLM-driven reward design loop' aligns with our interests in automated algorithm design, the implementation is standard and the empirical validation is trivial, relying on a simulation with only 5 vehicles. The results are likely overfitted to this micro-scale scenario and offer no evidence of scalability for the large-scale routing or multi-agent problems we study. We can safely ignore this as a repackaging of known techniques.</details> | Xiaofeng Luo et.al. | Nanyang Technological University, University of Manitoba, Sungkyunkwan University, Guangdong University of Technology | arXiv.org | [2601.12311](http://arxiv.org/abs/2601.12311) | ‚Äî |
| ‚Äî | **2026-01-15** | **Online Scheduling for LLM Inference with KV Cache Constraints** | Patrick Jaillet et.al. |  | arXiv.org | [2502.07115](http://arxiv.org/abs/2502.07115) | ‚Äî |
| ‚Äî | **2026-01-15** | **Fine-grained MoE Load Balancing with Linear Programming** | Chenqi Zhao et.al. |  |  | [2511.16947](http://arxiv.org/abs/2511.16947) | ‚Äî |
| ‚Äî | **2026-01-14** | **OptiMind: Teaching LLMs to Think Like Optimization Experts** | Xinzhi Zhang et.al. |  | arXiv.org | [2509.22979](http://arxiv.org/abs/2509.22979) | ‚Äî |
| 11/30 | **2026-01-13** | <details><summary>**Hierarchical Online-Scheduling for Energy-Efficient Split Inference with Progressive Transmission**</summary>The authors propose ENACHI, a hierarchical control framework for split inference that uses a surrogate accuracy model to set long-term energy budgets and an uncertainty-based stopping criterion for packet transmission. Results show significant energy savings on ImageNet simulations, though the setup is heavily tied to wireless channel modeling (Rayleigh fading). The only transferable insight is the **uncertainty-aware stopping mechanism**‚Äîusing a lightweight MLP to predict entropy and halt computation‚Äîwhich is conceptually similar to how we might use Process Reward Models to prune search branches in AlgoEvo. Otherwise, the methodology is textbook stochastic network optimization with no novel application to LLMs or symbolic OR.</details> | Zengzipeng Tang et.al. | The University of Hong Kong, Beijing Jiaotong University | arXiv.org | [2601.08135](http://arxiv.org/abs/2601.08135) | ‚Äî |
| 17/30 | **2026-01-13** | <details><summary>**Coordinated Cooling and Compute Management for AI Datacenters**</summary>Abera and Chen propose a hierarchical control framework for AI datacenters that combines LSTM workload forecasting, MILP-based Tensor Parallelism allocation, and MPC for cooling. They validate this on an 8x Tesla V100 testbed using Azure traces, demonstrating ~24% compute and ~31% cooling energy savings against a fixed baseline. The most stealable insight for our GPUSched work is the use of a lightweight DistilBERT classifier to predict output token lengths *prior* to scheduling, effectively converting a stochastic duration problem into a deterministic MILP constraint. This is a solid reference for integrating thermal dynamics into our resource allocation models, though methodologically it relies on standard OR techniques.</details> | Nardos Belay Abera et.al. | University of Alberta | arXiv.org | [2601.08113](http://arxiv.org/abs/2601.08113) | ‚Äî |
| ‚Äî | **2026-01-13** | **MemFine: Memory-Aware Fine-Grained Scheduling for MoE Training** | Lu Zhao et.al. |  | arXiv.org | [2511.21431](http://arxiv.org/abs/2511.21431) | ‚Äî |
| 22/30 | **2026-01-10** | <details><summary>**SkyNomad: On Using Multi-Region Spot Instances to Minimize AI Batch Job Cost**</summary>SkyNomad presents a multi-region scheduler for AI batch jobs that minimizes cost by dynamically migrating spot instances based on real-time availability probing and survival-analysis-based lifetime prediction. The authors propose a 'Unified Cost Model' that quantifies the monetary value of deadline slack, allowing the system to mathematically trade off migration egress costs against cheaper spot prices. Empirical results on AWS and GCP are strong, demonstrating 1.25-3.96x cost savings over single-region baselines while guaranteeing deadlines. We should immediately adapt their 'Value of Progress' heuristic and lifetime prediction module to optimize our own large-scale parallel evolution infrastructure.</details> | Zhifei Li et.al. | UC Berkeley, Shanghai Jiao Tong University, AMD, ICSI | arXiv.org | [2601.06520](http://arxiv.org/abs/2601.06520) | ‚Äî |
| ‚Äî | **2026-01-09** | **OPT-Engine: Benchmarking the Limits of LLMs in Optimization Modeling via Complexity Scaling** | Yitian Chen et.al. |  |  | [2601.19924](http://arxiv.org/abs/2601.19924) | **[link](https://github.com/Cardinal-Operations/OPTEngine)** |
| 26/30 | **2026-01-05** | <details><summary>**Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints**</summary>This paper formulates LLM inference as a multi-stage stochastic scheduling problem, introducing 'Nested WAIT'‚Äîa threshold-based algorithm that handles unknown output lengths by letting prompts classify themselves as they survive into deeper decode segments. Unlike heuristic baselines (vLLM, Sarathi), they provide rigorous asymptotic optimality proofs and high-probability bounds against memory overflow, validated on A100 simulations. The key takeaway is the 'nested segment' mechanism: instead of predicting job size, structure the queue so short jobs exit early and long jobs naturally migrate to lower-priority/protected tiers, effectively decoupling the memory risk. We should immediately evaluate this threshold logic for our GPUSched formulations, as it likely outperforms our current predictive or FCFS approaches for handling KV cache growth.</details> | Ruicheng Ao et.al. | Massachusetts Institute of Technology, Peking University, Alibaba Group | arXiv.org | [2504.11320](http://arxiv.org/abs/2504.11320) | ‚Äî |
| ‚Äî | **2026-01-05** | **Balancing Fidelity and Plasticity: Aligning Mixed-Precision Fine-Tuning with Linguistic Hierarchies** | Changhai Zhou et.al. |  |  | [2505.03802](http://arxiv.org/abs/2505.03802) | ‚Äî |
| ‚Äî | **2026-01-05** | **Finite-State Decentralized Policy-Based Control With Guaranteed Ground Coverage** | Hossein Rastgoftar et.al. |  | arXiv.org | [2601.02109](http://arxiv.org/abs/2601.02109) | ‚Äî |
| 17/30 | **2025-12-31** | <details><summary>**Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control**</summary>Duan et al. propose a hybrid agentic framework for inventory management that delegates optimization to standard solvers (DQN/(s,S)) while using LLMs strictly for parameter extraction and explanation. They introduce a 'Human Imitator'‚Äîa Qwen model fine-tuned on human dialogue to simulate boundedly rational, ambiguous users‚Äîto stress-test the extraction pipeline. For us, the primary value is the evaluation methodology: fine-tuning a 'noisy user' model is a transferable strategy for our OR-Bench project to test ambiguity resolution. Additionally, their ablation showing GPT-4o fails even with perfect information confirms that the bottleneck is computational, not informational, validating our reliance on external solvers.</details> | Yaqi Duan et.al. | New York University, Cornell University, Hong Kong University of Science and Technology | arXiv.org | [2601.00121](http://arxiv.org/abs/2601.00121) | ‚Äî |
| ‚Äî | **2025-12-30** | **Time-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning** | Xusheng Zhang et.al. |  | arXiv.org | [2512.24069](http://arxiv.org/abs/2512.24069) | ‚Äî |
| 21/30 | **2025-12-26** | <details><summary>**Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models**</summary>This paper formulates geographically distributed LLM inference as a joint block placement and request routing problem, solved via a decomposed MILP heuristic (greedy placement + shortest path routing). The results are real and validated on A100 clusters, showing 60-80% latency reduction over PETALS' native heuristics. The key takeaway for us is their explicit modeling of 'attention cache' memory consumption as a function of concurrent requests‚Äîtreating this as a dynamic constraint rather than a static buffer is the primary driver of their performance gains. This is a direct blueprint for the constraints we need in our 'GPUSched' formulations, though the algorithmic techniques themselves are standard OR fare.</details> | Tingyang Sun et.al. | Pennsylvania State University, Virginia Tech, Indian Institute of Science | Performance Evaluation, Vol. 170, pp. 102527, November 2025 | [2512.21884](http://arxiv.org/abs/2512.21884) | **[link](https://github.com/TingyangSunJeff/LLM_inference_simulator/tree/main)** |
| ‚Äî | **2025-12-25** | **Efficient MoE Inference with Fine-Grained Scheduling of Disaggregated Expert Parallelism** | Xinglin Pan et.al. |  | arXiv.org | [2512.21487](http://arxiv.org/abs/2512.21487) | ‚Äî |
| 16/30 | **2025-12-24** | <details><summary>**Deadline-Aware Online Scheduling for LLM Fine-Tuning with Spot Market Predictions**</summary>The authors propose a deadline-aware scheduling framework for LLM fine-tuning on hybrid spot/on-demand GPUs. They employ a Committed Horizon Control (CHC) algorithm for allocation when predictions (via ARIMA) are reliable, and a reactive fallback heuristic when they are not, governed by an online policy selector (Exponentiated Gradient) to switch strategies dynamically. Results are simulation-based using Vast.ai traces, claiming ~50% utility gains over static baselines. **Takeaway:** The meta-strategy of wrapping a potentially unreliable predictive model and a robust heuristic inside a simple bandit learner is a transferable architectural pattern for handling uncertainty in our AI infrastructure resource allocation work.</details> | Linggao Kong et.al. | Fudan University, University of Oregon, Inria | arXiv.org | [2512.20967](http://arxiv.org/abs/2512.20967) | ‚Äî |
| ‚Äî | **2025-12-19** | **Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs** | Rupanshu Soi et.al. |  | arXiv.org | [2512.18134](http://arxiv.org/abs/2512.18134) | ‚Äî |
| 22/30 | **2025-12-18** | <details><summary>**Staggered Batch Scheduling: Co-optimizing Time-to-First-Token and Throughput for High-Efficiency LLM Inference**</summary>Tian et al. introduce Staggered Batch Scheduling (SBS) for DP+EP architectures, enforcing a buffering window to enable global bin-packing rather than immediate dispatch, which they prove causes Head-of-Line blocking in non-preemptive prefill phases. Tested on a production H800 cluster serving DeepSeek-V3, they demonstrate a 30-40% reduction in TTFT and a ~20% throughput increase backed by clear utilization metrics. The most valuable takeaway for our GPUSched project is their 'IQR-aware lexicographical' scheduling heuristic for the Decode phase, which robustly balances batch size against KV-cache memory variance‚Äîa constraint logic we should immediately adopt. This work validates that discrete batching is superior to continuous dispatch for MoE models, necessitating an update to our queuing theory models.</details> | Jian Tian et.al. | Baidu Inc. | arXiv.org | [2512.16134](http://arxiv.org/abs/2512.16134) | ‚Äî |
| 14/30 | **2025-12-18** | <details><summary>**Multiscale Aggregated Hierarchical Attention (MAHA): A Game Theoretic and Optimization Driven Approach to Efficient Contextual Modeling in Large Language Models**</summary>MAHA replaces standard attention with hierarchical scales aggregated by solving a resource allocation problem (Convex Optimization or Nash Equilibrium) at inference time. While the empirical results rely on dated baselines (Longformer/BigBird) and the architecture itself is not useful for our evolutionary search focus, the **aggregation strategy is highly transferable**. We should evaluate the 'Nash Equilibrium fusion' concept for our Multi-Agent Debate (HERMES) and RobustMAS projects as a rigorous alternative to standard voting or attention for combining agent outputs.</details> | Caner Erden et.al. | Sakarya University of Applied Science | arXiv.org | [2512.14925](http://arxiv.org/abs/2512.14925) | **[link](https://github.com/canererden/MAHA-Project)** |
| ‚Äî | **2025-12-17** | **Dynamic Rebatching for Efficient Early-Exit Inference with DREX** | Xuting Liu et.al. |  | arXiv.org | [2512.15705](http://arxiv.org/abs/2512.15705) | ‚Äî |
| ‚Äî | **2025-12-15** | **PROSERVE: Unified Multi-Priority Request Scheduling for LLM Serving** | Weizhe Huang et.al. |  | arXiv.org | [2512.12928](http://arxiv.org/abs/2512.12928) | ‚Äî |
| ‚Äî | **2025-12-15** | **RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training** | Tianyuan Wu et.al. |  | arXiv.org | [2512.11306](http://arxiv.org/abs/2512.11306) | ‚Äî |
| ‚Äî | **2025-12-14** | **Optimal Resource Allocation for ML Model Training and Deployment under Concept Drift** | Hasan Burhan Beytur et.al. |  | arXiv.org | [2512.12816](http://arxiv.org/abs/2512.12816) | ‚Äî |
| ‚Äî | **2025-12-14** | **GoodSpeed: Optimizing Fair Goodput with Adaptive Speculative Decoding in Distributed Edge Inference** | Phuong Tran et.al. |  | INFOCOM 2026 | [2512.09963](http://arxiv.org/abs/2512.09963) | ‚Äî |
| ‚Äî | **2025-12-13** | **HetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments** | Yongjun He et.al. |  | arXiv.org | [2512.12476](http://arxiv.org/abs/2512.12476) | ‚Äî |
| ‚Äî | **2025-12-11** | **Hybrid Learning and Optimization-Based Dynamic Scheduling for DL Workloads on Heterogeneous GPU Clusters** | Shruti Dongare et.al. |  | ACM Symposium on Cloud Computing | [2512.10271](http://arxiv.org/abs/2512.10271) | ‚Äî |
| ‚Äî | **2025-12-09** | **Dora: QoE-Aware Hybrid Parallelism for Distributed Edge AI** | Jianli Jin et.al. |  | arXiv.org | [2512.10990](http://arxiv.org/abs/2512.10990) | ‚Äî |
| ‚Äî | **2025-12-08** | **Quantifying the Carbon Reduction of DAG Workloads: A Job Shop Scheduling Perspective** | Roozbeh Bostandoost et.al. |  | arXiv.org | [2512.07799](http://arxiv.org/abs/2512.07799) | ‚Äî |
| ‚Äî | **2025-12-05** | **MARINE: Theoretical Optimization and Design for Multi-Agent Recursive IN-context Enhancement** | Hongwei Zhang et.al. |  | arXiv.org | [2512.07898](http://arxiv.org/abs/2512.07898) | ‚Äî |
| 18/30 | **2025-12-02** | <details><summary>**Safety Game: Balancing Safe and Informative Conversations with Blackbox Agentic AI using LP Solvers**</summary>The authors formulate LLM response selection as a zero-sum game, solving a small Linear Program (LP) at inference time to mix candidate answers such that the expected risk never exceeds a 'safe fallback' baseline. Results are statistically significant, showing ~15% accuracy gains on SafetyBench by effectively managing the trade-off between helpfulness and safety probes. The key takeaway is the 'Adaptation Safety' constraint formulation: using an LP to guarantee that a stochastic policy is no worse than a heuristic baseline is a powerful, lightweight control mechanism we could adapt for selecting evolved algorithms or managing constraints in multi-agent optimization.</details> | Tuan Nguyen et.al. | University of Warwick | arXiv.org | [2510.09330](http://arxiv.org/abs/2510.09330) | ‚Äî |
| 17/30 | **2025-12-01** | <details><summary>**Hyperion: Hierarchical Scheduling for Parallel LLM Acceleration in Multi-tier Networks**</summary>Hyperion introduces a two-stage framework for distributed LLM inference on edge networks: offline Dynamic Programming to partition model layers across tiers, followed by online greedy node selection based on queue length. The authors demonstrate ~30-50% latency reduction on Jetson clusters compared to HEFT and GPipe, though the methods are standard combinatorial optimization techniques applied to a new domain. For us, the primary value is the clean decomposition of static partitioning vs. dynamic scheduling‚Äîthis is the 'competent baseline' our GPUSched formulations must beat. It confirms that simple, hierarchy-aware heuristics are effective for pipeline parallelism without requiring complex learning-based schedulers.</details> | Mulei Ma et.al. | Singapore University of Technology and Design, Nanyang Technological University, The Hong Kong University of Science and Technology (Guangzhou), University of Electronic Science and Technology of China, Peng Cheng Laboratory, Terminus Group | arXiv.org | [2511.14450](http://arxiv.org/abs/2511.14450) | ‚Äî |
| ‚Äî | **2025-12-01** | **Optimal Scheduling Algorithms for LLM Inference: Theory and Practice** | Agrim Bari et.al. |  | Proceedings of the ACM on Measurement and Analysis of Computing Systems | [2508.01002](http://arxiv.org/abs/2508.01002) | ‚Äî |
| ‚Äî | **2025-11-27** | **Optimizing NetGPT via Routing-Based Synergy and Reinforcement Learning** | Yuxuan Chen et.al. |  | arXiv.org | [2511.22217](http://arxiv.org/abs/2511.22217) | ‚Äî |
| 22/30 | **2025-11-26** | <details><summary>**BAMAS: Structuring Budget-Aware Multi-Agent Systems**</summary>BAMAS decouples agent resource provisioning from coordination strategy, using an Integer Linear Programming (ILP) solver to select the optimal set of LLMs under a strict budget and offline RL to select a fixed interaction topology. They demonstrate ~80% cost reduction on GSM8K and MBPP while matching SOTA accuracy, proving that formal optimization beats greedy heuristics for agent allocation. The key takeaway for us is the 'lexicographically optimal' ILP formulation for tier-based LLM selection, which we should steal immediately for our inference resource managers. While their topology search is limited to a fixed library (unlike our evolutionary approach), the hybrid ILP+RL architecture is a strong template for our 'OR for Generative AI' work.</details> | Liming Yang et.al. | Tsinghua University, Peking University, University of Illinois Urbana-Champaign, Nanyang Technological University | AAAI 2026 (oral paper) | [2511.21572](http://arxiv.org/abs/2511.21572) | **[link](https://github.com/chunfenri/BAMAS)** |
| 24/30 | **2025-11-19** | <details><summary>**Global Resolution: Optimal Multi-Draft Speculative Sampling via Convex Minimization**</summary>The authors solve the Optimal Transport Linear Program (OTLP) for multi-draft speculative sampling by reducing it to a convex minimization problem using polymatroid theory and max-flow, rather than using slow general LP solvers. They prove this 'Global Resolution' algorithm is exact for i.i.d. drafts and achieves >90% acceptance with negligible overhead (<100ms), running 10,000x faster than baselines. **Key Takeaway:** The reduction of a discrete token selection problem to a convex optimization problem via polymatroids is a brilliant theoretical trick we could potentially adapt for selecting diverse solution subsets in AlgoEvo. This is a definitive 'OR for LLM infra' paper that obsoletes heuristic verification strategies.</details> | Rahul Krishna Thomas et.al. | Stanford University, Ritual | arXiv.org | [2511.15898](http://arxiv.org/abs/2511.15898) | ‚Äî |
| 9/30 | **2025-11-16** | <details><summary>**Co-Layout: LLM-driven Co-optimization for Interior Layout**</summary>Xiang et al. propose a neuro-symbolic pipeline where LLMs extract constraints from text to populate a grid-based Integer Program (IP) for interior layout, solved using a coarse-to-fine strategy. They demonstrate that this solver-based approach eliminates object overlaps (0% vs. ~0.8% in baselines) and improves user satisfaction compared to end-to-end generative models. The primary takeaway is a validation of the 'LLM-to-MIP' paradigm over direct generation for geometric constraints, but the specific grid formulations and heuristics offer no novel insights for our evolutionary search or VRP work.</details> | Chucheng Xiang et.al. | Tsinghua University, Tencent, University of Science and Technology of China | arXiv.org | [2511.12474](http://arxiv.org/abs/2511.12474) | ‚Äî |
| 7/30 | **2025-11-14** | <details><summary>**Constrained Network Slice Assignment via Large Language Models**</summary>Sudhakara et al. address 5G network slice assignment by using an LLM to generate a 'similarity matrix' between user requests, which is then fed into a standard Integer Linear Programming (ILP) solver to enforce constraints. The zero-shot LLM approach fails to satisfy hard constraints, while the hybrid approach succeeds simply because it delegates all logic to a GLPK solver. The experiments are limited to a synthetic dataset with only 3 slice types. The only takeaway is the basic pattern of using LLMs to populate coefficients (similarity scores) in an OR objective function, which is an obvious integration pattern we already understand.</details> | Sagar Sudhakara et.al. | University of Southern California | NeurIPS 2025 Workshop on AI and ML for Next-Generation Wireless Communications and Networking (AI4NextG) | [2512.00040](http://arxiv.org/abs/2512.00040) | ‚Äî |
| ‚Äî | **2025-11-13** | **LM4Opt-RA: A Multi-Candidate LLM Framework with Structured Ranking for Automating Network Resource Allocation** | Tasnim Ahmed et.al. |  | arXiv.org | [2512.00039](http://arxiv.org/abs/2512.00039) | ‚Äî |
| 8/30 | **2025-11-12** | <details><summary>**Cost-Minimized Label-Flipping Poisoning Attack to LLM Alignment**</summary>The authors formulate label-flipping poisoning in RLHF as a convex optimization problem, exploiting the fact that dataset size $N$ vastly exceeds feature dimension $n$ to find the minimal set of label flips required to steer a reward model. They demonstrate that attack costs can be reduced by 10-30% on standard benchmarks by solving this linear program. While we do not work on poisoning, the paper's formalization of the 'many-to-one' mapping between dataset labels and the resulting reward vector highlights the massive redundancy in preference datasets. This geometric insight could theoretically inspire methods for data pruning or sample-efficient training of our Process Reward Models (MASPRM), but the paper itself offers no direct tools for our optimization tasks.</details> | Shigeki Kusaka et.al. | University of Tsukuba, RIKEN AIP, LY Corporation, Institute of Science Tokyo | AAAI | [2511.09105](http://arxiv.org/abs/2511.09105) | **[link](https://github.com/akimotolab/PoisoningCostMinimization)** |
| 24/30 | **2025-11-12** | <details><summary>**SageServe: Optimizing LLM Serving on Cloud Data Centers with Forecast Aware Auto-Scaling**</summary>SageServe optimizes LLM inference resource allocation across regions using an Integer Linear Programming (ILP) model coupled with ARIMA-based traffic forecasting, specifically targeting mixed interactive and non-interactive workloads. They validate this on real Microsoft O365 production traces (which they release), demonstrating a 25% reduction in GPU hours and $2.5M/month savings compared to reactive baselines. The primary value for us is the release of the production workload traces‚Äîallowing us to benchmark our 'GPUSched' formulations against real-world data rather than synthetic distributions‚Äîand their specific ILP formulation for unified capacity management, which directly competes with our internal OR models.</details> | Shashwat Jaiswal et.al. | Microsoft, University of Illinois Urbana-Champaign, Georgia Institute of Technology, Indian Institute of Science | Proceedings of the ACM on Measurement and Analysis of Computing Systems, Vol. 9, No. 3, Article 61. December 2025 | [2502.14617](http://arxiv.org/abs/2502.14617) | **[link](https://github.com/shashwatj07/SageServe)** |
| ‚Äî | **2025-11-12** | **OR-R1: Automating Modeling and Solving of Operations Research Optimization Problem via Test-Time Reinforcement Learning** | Zezhen Ding et.al. |  | AAAI | [2511.09092](http://arxiv.org/abs/2511.09092) | **[link](https://github.com/SCUTE-ZZ/OR-R1)** |
| 17/30 | **2025-11-11** | <details><summary>**Tool-Aided Evolutionary LLM for Generative Policy Toward Efficient Resource Management in Wireless Federated Learning**</summary>Tan et al. propose T-ELLM, a framework that fine-tunes an LLM for device selection in Federated Learning using Group Relative Policy Optimization (GRPO) and a learned 'virtual environment.' Instead of expensive real-world training, they train a small GPT-2 model to predict FL accuracy dynamics (acting as a world model), then use this surrogate to generate trajectories for GRPO updates. They mathematically decouple the problem, letting the LLM handle discrete selection while a convex optimization tool handles continuous resource allocation. **Takeaway:** The 'World Model + GRPO' pipeline is a concrete, sample-efficient recipe for RL-infused optimization that we could adapt to train our evolutionary searchers without running expensive real evaluations.</details> | Chongyang Tan et.al. | Zhejiang University, Zhejiang Lab, University of Manitoba, Macau University of Science and Technology | IEEE Journal on Selected Areas in Communications | [2505.11570](http://arxiv.org/abs/2505.11570) | **[link](https://github.com/TCY-N/TELLM)** |
| 12/30 | **2025-11-10** | <details><summary>**Understanding Forgetting in LLM Supervised Fine-Tuning and Preference Learning -- A Convex Optimization Perspective**</summary>The authors propose ALRIGHT (random alternation) and MAXRIGHT (adaptive alternation) to jointly optimize SFT and DPO objectives, theoretically proving that sequential training leads to suboptimal Pareto frontiers due to forgetting. Empirical results show up to 23% improvement on general benchmarks compared to sequential approaches, with minimal computational overhead. The most stealable insight is the MAXRIGHT heuristic: dynamically selecting the objective with the largest normalized optimality gap to update at each step. This is a computationally cheap proxy for multi-objective optimization that avoids the memory cost of simultaneous gradient calculation, which we could adapt for multi-objective agent control or heuristic selection in AlgoEvo.</details> | Heshan Fernando et.al. | Rensselaer Polytechnic Institute, IBM Research, Cornell University |  | [2410.15483](http://arxiv.org/abs/2410.15483) | **[link](https://github.com/heshandevaka/XRIGHT)** |
| 21/30 | **2025-11-08** | <details><summary>**CoEdge-RAG: Optimizing Hierarchical Scheduling for Retrieval-Augmented LLMs in Collaborative Edge Computing**</summary>Hong et al. introduce CoEdge-RAG, a hierarchical scheduling framework for distributed edge RAG that combines PPO-based query routing with Online Convex Optimization (OCO) for local resource management. They empirically validate that a quadratic function best approximates LLM inference latency for OCO, allowing them to dynamically resize models and memory allocations under strict SLOs. The standout takeaway is the feedback loop: using PPO to learn a 'semantic routing policy' based on downstream generation quality (Rouge/BERTScore) rather than just load, effectively solving the 'black box' data distribution problem in privacy-preserving multi-agent systems. This hybrid RL/OR control stack is a transferable pattern for our distributed inference and multi-agent optimization work.</details> | Guihang Hong et.al. | Sun Yat-sen University | RTSS 2025 (Real-Time Systems Symposium | [2511.05915](http://arxiv.org/abs/2511.05915) | ‚Äî |
| 6/30 | **2025-11-06** | <details><summary>**Question the Questions: Auditing Representation in Online Deliberative Processes**</summary>The authors introduce an auditing framework and an O(mn log n) algorithm to measure 'Justified Representation' (JR) in selecting questions for deliberation, using LLM embeddings to infer participant utility. They demonstrate that LLM-generated summaries and IP-selected subsets often outperform human moderators in representativeness. The only potential takeaway is the formulation of semantic coverage as a formal JR constraint in an Integer Program, which could theoretically act as a diversity filter for multi-agent debate memory, but standard clustering methods likely suffice for our needs.</details> | Soham De et.al. | FAIR at Meta, Stanford University, Harvard University, University of Washington | arXiv.org | [2511.04588](http://arxiv.org/abs/2511.04588) | ‚Äî |
| 9/30 | **2025-11-05** | <details><summary>**Joint Optimization of DNN Model Caching and Request Routing in Mobile Edge Computing**</summary>Qiu et al. propose CoCaR, an algorithm for jointly optimizing model caching and request routing in Mobile Edge Computing using 'Dynamic DNNs' (models partitioned into sub-blocks). They formulate the problem as an Integer Linear Program (ILP), solve via LP relaxation and randomized rounding, and provide an online heuristic based on predictive future gain. While the explicit modeling of 'model loading latency' (switching costs between submodels) is a sound constraint formulation, the methodology is textbook OR and the application is strictly edge-focused. It offers no new algorithmic insights for our LLM evolutionary search or data-center scale serving optimization.</details> | Shuting Qiu et.al. | The Chinese University of Hong Kong, Southeast University, Chongqing University | arXiv.org | [2511.03159](http://arxiv.org/abs/2511.03159) | ‚Äî |
| ‚Äî | **2025-11-04** | **An LLM-powered MILP modelling engine for workforce scheduling guided by expert knowledge** | Qingyang Li et.al. |  |  | [2511.02364](http://arxiv.org/abs/2511.02364) | ‚Äî |
| 4/30 | **2025-10-30** | <details><summary>**Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling**</summary>El Makroum et al. deploy Llama-3.3 to schedule three home appliances by parsing natural language and invoking a sliding-window summation tool. While they achieve optimality against a MILP baseline, the problem size is negligible (3 items, 96 slots) and the 'intelligence' consists entirely of calling a deterministic exhaustive search function. We learn that even for such simple tasks, smaller models (Qwen-32B) fail without explicit workflow constraints, confirming the fragility of pure agentic reasoning for OR. This is a basic application paper with no transferable insights for our large-scale optimization or evolutionary search work.</details> | Reda El Makroum et.al. | Technische Universit√§t Wien, Norwegian University of Science and Technology | arXiv.org | [2510.26603](http://arxiv.org/abs/2510.26603) | **[link](https://github.com/RedaElMakroum/agentic-ai-hems)** |
| ‚Äî | **2025-10-27** | **Unified Sparse Mixture of Experts** | Giang Do et.al. | CUIP |  | [2503.22996](http://arxiv.org/abs/2503.22996) | **[link](https://github.com/lanl/TTLoRAMoE)** |
| 10/30 | **2025-10-26** | <details><summary>**PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language**</summary>Shi et al. introduce PIP-LLM, a pipeline that uses LLMs to instantiate PDDL problems from natural language, solves them for a high-level plan, and then uses a basic Integer Programming formulation for robot task allocation. While they outperform pure LLM baselines (which are known to fail at optimization), the 'large-scale' experiments only involve 12 robots, and the IP formulation is a trivial assignment problem. The work validates that separating semantic planning from numeric allocation is robust, but offers no new mechanisms for our evolutionary search or advanced OR formulations.</details> | Guangyao Shi et.al. | University of Pennsylvania, University of Southern California | arXiv.org | [2510.22784](http://arxiv.org/abs/2510.22784) | ‚Äî |
| ‚Äî | **2025-10-26** | **Movable Antenna Enhanced Federated Fine-Tuning of Large Language Models via Hybrid Client Selection Optimization** | Yang Zhao et.al. |  |  | [2506.00011](http://arxiv.org/abs/2506.00011) | ‚Äî |
| ‚Äî | **2025-10-20** | **Every Rollout Counts: Optimal Resource Allocation for Efficient Test-Time Scaling** | Xinglin Wang et.al. |  | NeurIPS2025 | [2506.15707](http://arxiv.org/abs/2506.15707) | **[link](https://github.com/WangXinglin/DORA)** |
| ‚Äî | **2025-10-19** | **Justitia: Fair and Efficient Scheduling for LLM Applications** | Mingyan Yang et.al. |  | arXiv.org | [2510.17015](http://arxiv.org/abs/2510.17015) | ‚Äî |
| 14/30 | **2025-10-14** | <details><summary>**Learning Adaptive and Temporally Causal Video Tokenization in a 1D Latent Space**</summary>AdapTok enables variable-length video tokenization by training a 'scorer' to predict reconstruction quality at different token counts, then solving an Integer Linear Program (ILP) during inference to allocate a fixed token budget across a batch. The results demonstrate that solving a lightweight ILP per batch adds negligible latency (15%) while achieving Pareto-optimal quality/cost trade-offs compared to fixed allocation. **Takeaway:** We should steal the 'Scorer + ILP' pattern for our AlgoEvo and LLM serving work‚Äîspecifically to dynamically allocate 'think time' or evolutionary generations based on predicted marginal utility, rather than using static budgets.</details> | Yan Li et.al. | Tsinghua University, The Chinese University of Hong Kong, Shanghai AI Laboratory, Shanghai Jiao Tong University, Tongji University | arXiv.org | [2505.17011](http://arxiv.org/abs/2505.17011) | **[link](https://github.com/VisionXLab/AdapTok)** |
| 20/30 | **2025-10-13** | <details><summary>**MC#: Mixture Compressor for Mixture-of-Experts Large Models**</summary>Huang et al. propose MC#, a compression framework for MoE models that combines static mixed-precision quantization with dynamic expert pruning. They formulate bit-width allocation as an Integer Linear Programming (ILP) problem‚Äîoptimizing expert importance vs. quantization error‚Äîand use a Gumbel-Softmax router for dynamic pruning. Results are strong, achieving 6.2x weight reduction on DeepSeek-VL2 with <2% accuracy loss. **Takeaway:** The ILP formulation (Eq. 7) is a clean, successful application of OR to AI infrastructure that we should replicate for our own resource allocation/scheduling problems; additionally, the differentiable router offers a template for dynamic agent selection in our multi-agent systems.</details> | Wei Huang et.al. | NVIDIA Research, National University of Singapore, The University of Hong Kong, Beihang University, Hangzhou Innovation Institute | arXiv.org | [2510.10962](http://arxiv.org/abs/2510.10962) | ‚Äî |
| 12/30 | **2025-10-13** | <details><summary>**InstructSAM: A Training-Free Framework for Instruction-Oriented Remote Sensing Object Recognition**</summary>InstructSAM introduces a training-free framework that combines an LVLM, SAM2, and a Binary Integer Programming (BIP) solver to perform object recognition without confidence thresholds. Instead of relying on noisy per-instance scores, the model uses the LVLM to predict total object counts, which serve as hard constraints in a BIP formulation to optimally assign semantic labels to visual masks. The results are strong, outperforming specialized baselines in zero-shot settings. **Takeaway:** We should steal the 'LLM-as-Constraint-Generator + Solver' pattern for our multi-agent optimization work; specifically, using LLMs to predict global resource envelopes or topology constraints that a downstream IP solver then respects, rather than asking the LLM to solve the allocation directly.</details> | Yijie Zheng et.al. | Aerospace Information Research Institute, Chinese Academy of Sciences, University of Chinese Academy of Sciences, Shanghai Jiao Tong University, Harbin Institute of Technology, University of Wollongong | NeurIPS | [2505.15818](http://arxiv.org/abs/2505.15818) | **[link](https://VoyagerXvoyagerx.github.io/InstructSAM/)** |
| ‚Äî | **2025-10-13** | **Efficient LLM Inference over Heterogeneous Edge Networks with Speculative Decoding** | Bingjie Zhu et.al. |  | arXiv.org | [2510.11331](http://arxiv.org/abs/2510.11331) | ‚Äî |
| 12/30 | **2025-10-11** | <details><summary>**Efficient Onboard Vision-Language Inference in UAV-Enabled Low-Altitude Economy Networks via LLM-Enhanced Optimization**</summary>Li et al. optimize UAV trajectory for VLM inference using a hierarchical approach: standard Branch-and-Bound for resource allocation and PPO for trajectory, where the PPO reward function is iteratively generated by GPT-4 (offline). Simulation results claim a ~12% latency reduction over manually tuned PPO. The only actionable takeaway is the specific reward term the LLM discovered: using Value-at-Risk (VaR) of user backlogs to effectively minimize worst-case latency, a formulation often overlooked in manual tuning. For our work, this is merely a validation that Eureka-style reward search works in OR contexts, offering no new search mechanisms.</details> | Yang Li et.al. | Nanyang Technological University, The University of Sydney, Western University, Sungkyunkwan University | arXiv.org | [2510.10028](http://arxiv.org/abs/2510.10028) | ‚Äî |
| 18/30 | **2025-10-08** | <details><summary>**FLEET: Formal Language-Grounded Scheduling for Heterogeneous Robot Teams**</summary>FLEET implements a hybrid pipeline where an LLM extracts a task dependency graph and a 'fitness matrix' (capability scores) from natural language, which then populate a standard MILP for multi-robot scheduling. Results on the PARTNR benchmark show it outperforms pure LLM planners (SMART-LLM) by ~7% on heterogeneous tasks, though overall gains are modest. The actionable takeaway is the **fitness matrix extraction**: using the LLM to generate dense cost coefficients ($c_{ij}$) for the optimization model rather than just binary constraints. We should adopt this technique for handling soft semantic preferences in our heterogeneous VRP formulations.</details> | Corban Rivera et.al. | JHU APL, JHU, DEVCOM ARL | arXiv.org | [2510.07417](http://arxiv.org/abs/2510.07417) | ‚Äî |
| ‚Äî | **2025-10-07** | **ConstraintLLM: A Neuro-Symbolic Framework for Industrial-Level Constraint Programming** | Weichun Shi et.al. |  | Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing, pages 15999-16019 | [2510.05774](http://arxiv.org/abs/2510.05774) | **[link](https://github.com/william4s/ConstraintLLM)** |
| 7/30 | **2025-10-02** | <details><summary>**LLM-Enhanced, Data-Driven Personalized and Equitable Clinician Scheduling: A Predict-then-Optimize Approach**</summary>The authors propose a Predict-then-Optimize framework for clinician scheduling that uses a fine-tuned FLAN-T5 model to extract binary availability constraints from unstructured notes, which then feed into a lexicographic goal programming MIP. The evaluation relies entirely on synthetic data (templates + LLM-generated notes) and compares against unoptimized historical baselines, yielding predictable improvements in fairness and coverage. For us, the only takeaway is the practical pattern of using small, local LLMs to 'clean' hard constraints from text before optimization, but the methodology is too elementary to impact our AlgoEvo or MAS work.</details> | Anjali Jha et.al. | University of Maryland, Baltimore County, University of Texas Health Science Center at San Antonio | arXiv.org | [2510.02047](http://arxiv.org/abs/2510.02047) | ‚Äî |
| 20/30 | **2025-10-01** | <details><summary>**Logical Consistency Between Disagreeing Experts and Its Role in AI Safety**</summary>Corrada-Emmanuel formulates the unsupervised evaluation of classifiers as an Integer Linear Programming problem, defining the geometric space of possible ground truths consistent with observed agent disagreements. While the results are primarily theoretical demonstrations on MT-Bench (showing that certain disagreement patterns mathematically preclude accuracy >46%), the methodology is sound. The key takeaway is the concept of 'no-knowledge alarms': using LP constraints to flag when a multi-agent system or process reward model has become logically incoherent. We could implement this as a cheap, rigorous filter in our evolutionary search loops to prune branches where the evaluator agents are demonstrably unreliable.</details> | Andr√©s Corrada-Emmanuel et.al. | Data Engines | arXiv.org | [2510.00821](http://arxiv.org/abs/2510.00821) | ‚Äî |
| ‚Äî | **2025-10-01** | **StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models** | Chenyu Zhou et.al. | Shanghai Jiao Tong Univeristy | arXiv.org | [2509.22558](http://arxiv.org/abs/2509.22558) | ‚Äî |
| 22/30 | **2025-09-29** | <details><summary>**Cascadia: An Efficient Cascade Serving System for Large Language Models**</summary>Jiang et al. propose CASCADIA, a bi-level optimization framework for LLM cascade serving that iterates between an MILP solver for hardware deployment (choosing DP/TP/PP strategies) and a Chebyshev-guided solver for routing thresholds. They demonstrate 2.3x average throughput gains over SGLang and CascadeServe on H100 clusters, backed by rigorous ablation studies. The key takeaway is the effective decomposition of the NP-hard joint optimization problem: freezing routing to solve deployment via MILP, then optimizing routing against that deployment. This is a direct reference point for our 'GPUSched' project, validating the efficacy of formal integer programming in LLM resource allocation.</details> | Youhe Jiang et.al. | Princeton University, University of Cambridge, Tsinghua University, HKUST, Shanghai Jiaotong University |  | [2506.04203](http://arxiv.org/abs/2506.04203) | ‚Äî |
| ‚Äî | **2025-09-29** | **FMIP: Joint Continuous-Integer Flow For Mixed-Integer Linear Programming** | Hongpei Li et.al. |  |  | [2507.23390](http://arxiv.org/abs/2507.23390) | **[link](https://github.com/Lhongpei/FMIP)** |
| ‚Äî | **2025-09-28** | **AdaPtis: Reducing Pipeline Bubbles with Adaptive Pipeline Parallelism on Heterogeneous Models** | Jihu Guo et.al. |  | arXiv.org | [2509.23722](http://arxiv.org/abs/2509.23722) | ‚Äî |
| 17/30 | **2025-09-27** | <details><summary>**Ask, Reason, Assist: Decentralized Robot Collaboration via Language and Logic**</summary>Choe et al. propose a decentralized multi-robot framework where LLMs translate natural language help requests into Signal Temporal Logic (STL) constraints using a BNF grammar, which are then solved locally via MILP. They demonstrate that this approach achieves 100% formula validity (by definition) and tracks within 18% of a centralized ILS-based VRP oracle on small instances (6 robots). The key takeaway is the **BNF-constrained decoding pipeline** which effectively bridges the gap between fuzzy LLM outputs and strict formal solvers; we should steal this exact mechanism to eliminate syntax errors in our OR-Bench symbolic model generation. The underlying optimization logic is standard contract-net protocol and offers no new insights for our evolutionary search or large-scale VRP work.</details> | Dan BW Choe et.al. | Georgia Institute of Technology | arXiv.org | [2509.23506](http://arxiv.org/abs/2509.23506) | **[link](https://github.com/ask-reason-assist/ask-reason-assist-codebase)** |
| 18/30 | **2025-09-27** | <details><summary>**Enhancing Delta Compression in LLMs via SVD-based Quantization Error Minimization**</summary>PRINMIX replaces heuristic quantization of LLM delta-weights with a 0/1 Integer Linear Programming (ILP) formulation to minimize reconstruction error. The results are strong and backed by numbers, showing ~22% improvement on AIME2024 and 6x storage savings compared to Delta-CoMe. For us, the key takeaway is not the compression itself, but the formulation: it proves that exact OR modeling outperforms heuristics in LLM serving infrastructure. Additionally, the reported 30-minute solving time suggests this problem could serve as a valuable testbed for our own evolutionary solver acceleration (EvoCut/AlgoEvo).</details> | Boya Xiong et.al. | Tsinghua University, Fudan University, Southern University of Science and Technology, Shanghai University of Finance and Economics |  | [2506.11087](http://arxiv.org/abs/2506.11087) | ‚Äî |
| 23/30 | **2025-09-25** | <details><summary>**Best-of-$\infty$ -- Asymptotic Performance of Test-Time Compute**</summary>This paper introduces a Bayesian adaptive stopping criterion (using Dirichlet process priors and Bayes factors) for majority voting, reducing test-time compute by 2-5x while maintaining asymptotic 'Best-of-Infinity' accuracy. They further demonstrate that optimizing weights for an ensemble of LLMs can be formulated as a Mixed-Integer Linear Program (MILP) by treating the decision boundaries as polytopes. **What we learned:** The Bayesian stopping logic is immediately transferable to AlgoEvo to reduce the cost of fitness evaluations‚Äîwe can stop evaluating candidate solutions early if their performance distribution is statistically distinct. The MILP approach for ensembles also offers a concrete formulation we could adapt for our GPU scheduling and model serving optimization work.</details> | Junpei Komiyama et.al. | Mohamed bin Zayed University of Artificial Intelligence, New York University, RIKEN AIP, Institute of Science Tokyo, NEC Corporation | arXiv.org | [2509.21091](http://arxiv.org/abs/2509.21091) | **[link](https://github.com/jkomiyama/BoInf-code-publish)** |
| 13/30 | **2025-09-25** | <details><summary>**Task-Oriented Computation Offloading for Edge Inference: An Integrated Bayesian Optimization and Deep Reinforcement Learning Framework**</summary>Li et al. introduce LAB, a hybrid framework for edge inference offloading where a DNN actor proposes a small set of candidate degradation levels and a Gaussian Process (BO) critic selects the best one, subsequently using these selections to retrain the actor. They validate this on a self-driving dataset, demonstrating that this 'guided' approach outperforms standard DRL in accuracy and is significantly faster than exhaustive BO. The useful takeaway is the architectural pattern of using a sample-efficient surrogate (BO) to filter and label actions for a fast neural policy in an online setting‚Äîessentially distilling an expensive search into a heuristic. However, the method is tailored for low-dimensional edge constraints and does not provide scalable solutions for our large-scale LLM serving or evolutionary search challenges.</details> | Xian Li et.al. | The Chinese University of Hong Kong, Shenzhen University | arXiv.org | [2509.21090](http://arxiv.org/abs/2509.21090) | ‚Äî |
| ‚Äî | **2025-09-25** | **Nova: Real-Time Agentic Vision-Language Model Serving with Adaptive Cross-Stage Parallelization** | Yuhang Xu et.al. |  | IEEE Real-Time Systems Symposium | [2509.21301](http://arxiv.org/abs/2509.21301) | ‚Äî |
| 4/30 | **2025-09-24** | <details><summary>**Agentic AI for Low-Altitude Semantic Wireless Networks: An Energy Efficient Design**</summary>The authors formulate a mixed-integer non-convex problem to minimize energy in a UAV-assisted network by optimizing location, transmit power, and semantic compression ratios. They solve it via analytical reduction and a 2D search, claiming energy savings over static baselines in simulation. The work is mathematically competent within the wireless domain but irrelevant to us: it relies on domain-specific channel physics and classical convex optimization tricks rather than the evolutionary search or learning-based methods we develop. The 'Agentic AI' claim is purely marketing for a standard offloading decision variable.</details> | Zhouxiang Zhao et.al. | Zhejiang University, University of Miami, Southeast University | arXiv.org | [2509.19791](http://arxiv.org/abs/2509.19791) | ‚Äî |
| ‚Äî | **2025-09-24** | **OR-Toolformer: Modeling and Solving Operations Research Problems with Tool Augmented Large Language Models** | Jianzhang Zhang et.al. |  | arXiv.org | [2510.01253](http://arxiv.org/abs/2510.01253) | ‚Äî |
| ‚Äî | **2025-09-24** | **CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks** | Jiewei Chen et.al. |  | arXiv.org | [2509.19855](http://arxiv.org/abs/2509.19855) | ‚Äî |
| ‚Äî | **2025-09-23** | **Robust DNN Partitioning and Resource Allocation Under Uncertain Inference Time** | Zhaojun Nan et.al. |  | IEEE Transactions on Mobile Computing | [2503.21476](http://arxiv.org/abs/2503.21476) | ‚Äî |
| 9/30 | **2025-09-19** | <details><summary>**Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection**</summary>Chen et al. propose LLM-CRDT, initializing a Decision Transformer with GPT-2 weights (fine-tuned via LoRA) and adding a critic-based regularization term to the loss function to encourage high-value actions. They apply this to a continuous UAV trajectory control problem, claiming ~30% energy efficiency gains over standard DT and the ability to learn from suboptimal data. **Takeaway:** The specific loss formulation ($L_{DT} - \lambda Q(s, \hat{a})$) effectively combines supervised sequence modeling with value maximization to enable 'stitching' in Transformers, a mechanism that could theoretically guide generative heuristics. However, the application is low-level continuous control, and the method treats the LLM purely as a pre-trained feature extractor rather than a reasoning agent, making it largely irrelevant to our AlgoEvo or VRP work.</details> | Zhixion Chen et.al. | Queen Mary University of London, Southeast University, Kyung Hee University | arXiv.org | [2509.13934](http://arxiv.org/abs/2509.13934) | ‚Äî |
| ‚Äî | **2025-09-16** | **Temporal-Aware GPU Resource Allocation for Distributed LLM Inference via Reinforcement Learning** | Chengze Du et.al. |  |  | [2507.10259](http://arxiv.org/abs/2507.10259) | ‚Äî |
| 10/30 | **2025-09-10** | <details><summary>**No-Knowledge Alarms for Misaligned LLMs-as-Judges**</summary>The author proposes using Linear Programming to detect logical inconsistencies in LLM judge ensembles, raising an 'alarm' when observed disagreement rates mathematically preclude a target accuracy level (e.g., >50%) without needing ground truth. The empirical validation is virtually non-existent, relying on a single 'toy example' of 25 pair comparisons from MT-Bench. The only potential takeaway is the formalization of judge consistency as an LP constraint, which could theoretically serve as a rejection filter in our multi-agent debate loops. However, the method provides no gradient for improvement and increases inference cost, making it impractical for our sample-efficient evolutionary search goals.</details> | Andr√©s Corrada-Emmanuel et.al. | Data Engines | arXiv.org | [2509.08593](http://arxiv.org/abs/2509.08593) | ‚Äî |
| 7/30 | **2025-09-05** | <details><summary>**A Federated Fine-Tuning Paradigm of Foundation Models in Heterogenous Wireless Networks**</summary>Wang et al. propose a federated learning framework for edge networks where devices dynamically switch between different LoRA modules to optimize convergence under wireless constraints. They formulate a mixed-integer program to jointly optimize model switching, transmit power, and bandwidth, claiming ~40% faster convergence on NLP tasks. The only potentially interesting concept is 'model switching'‚Äîallowing agents to self-select which global module to update based on local fit‚Äîwhich loosely parallels niching or dynamic population selection in evolutionary algorithms. However, the heavy reliance on wireless channel physics makes the actual methodology non-transferable to our cloud-based evolutionary search or GPU scheduling problems.</details> | Jingyi Wang et.al. | China Telecom Research Institute, Beijing University of Posts and Telecommunications, Singapore University of Technology and Design | arXiv.org | [2509.19306](http://arxiv.org/abs/2509.19306) | ‚Äî |
| 22/30 | **2025-08-26** | <details><summary>**HAP: Hybrid Adaptive Parallelism for Efficient Mixture-of-Experts Inference**</summary>HAP replaces static parallelization heuristics in MoE inference with an Integer Linear Programming (ILP) solver that dynamically selects optimal strategies (TP, EP, DP) for Attention and Expert modules. They achieve verified ~1.6x speedups on A100/A6000 GPUs by modeling the inference process as a two-stage problem (prefill vs. decoding) with explicit transition costs, allowing the system to switch parallelism strategies mid-inference. For our work on OR-based resource allocation (GPUSched), the key takeaway is their formulation of **transition overheads** within the ILP constraints‚Äîa technique we should steal to model dynamic reconfiguration in our scheduling solvers. This confirms that symbolic OR methods can outperform standard systems heuristics in the LLM serving stack.</details> | Haoran Lin et.al. | Huawei Noah‚Äôs Ark Lab, Shandong University | International Conference on Parallel and Distributed Systems | [2508.19373](http://arxiv.org/abs/2508.19373) | ‚Äî |
| 20/30 | **2025-08-18** | <details><summary>**Batching-Aware Joint Model Onloading and Offloading for Hierarchical Multi-Task Inference**</summary>Cha et al. propose an alternating optimization framework (J3O) for joint model placement and query routing in hierarchical inference systems, decomposing the MINLP into greedy Lagrangian submodular maximization and linear programming. They explicitly model batching latency at the edge using a linear surrogate to handle the non-convex batch setup costs, achieving ~97% of Gurobi's optimal accuracy with <15% of the runtime. **Takeaway:** We should steal their linear surrogate formulation for batching overhead (approximating the L0-norm of task arrival) for our 'GPUSched' integer programs; it offers a tractable way to model batching efficiency in serving systems without full non-linear solvers.</details> | Seohyeon Cha et.al. | The University of Texas at Austin, DEVCOM Army Research Laboratory | arXiv.org | [2508.13380](http://arxiv.org/abs/2508.13380) | ‚Äî |
| ‚Äî | **2025-08-16** | **EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models** | Milad Yazdani et.al. |  | arXiv.org | [2508.11850](http://arxiv.org/abs/2508.11850) | **[link](https://github.com/milad1378yz/EvoCut)** |
| 11/30 | **2025-08-15** | <details><summary>**CSGO: Generalized Optimization for Cold Start in Wireless Collaborative Edge LLM Systems**</summary>Liu et al. propose a Dynamic Programming algorithm to optimize layer partitioning for LLM inference on heterogeneous edge devices, specifically targeting 'cold start' by overlapping disk I/O with computation. The results claim 8-50% latency reduction, but these are derived entirely from numerical simulations using simple FLOPs/bandwidth formulas rather than real-world device deployment. The methodology is a textbook application of chain partitioning DP to a specific cost function; while it cleanly formulates the I/O-compute overlap, it lacks the methodological novelty or empirical rigor to be actionable for our high-performance computing contexts.</details> | Xuran Liu et.al. | Shanghai Jiao Tong University, CUHK (Shenzhen), Pengcheng Lab, BUPT | Journal of Communications and Information Networks | [2508.11287](http://arxiv.org/abs/2508.11287) | ‚Äî |
| 19/30 | **2025-08-12** | <details><summary>**Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference**</summary>This paper formulates the placement of MoE experts (specifically DeepSeek-R1/V3) onto distributed GPU clusters as an Integer Linear Program (ILP) to minimize network hops. While the results are simulation-based (counting hops rather than measuring real latency), they demonstrate that ILP-based placement reduces traffic by ~14-30% compared to Round-Robin, but *only* when the objective function is weighted by historical expert activation frequency; unweighted ILP performs poorly. The key takeaway for our GPUSched project is the specific formulation of the load-aware objective function and the finding that topology-aware placement requires usage statistics to beat simple heuristics. We should adapt this ILP formulation for our resource allocation work.</details> | Danil Sivtsov et.al. | AIRI, Skoltech, Avito | arXiv.org | [2508.09229](http://arxiv.org/abs/2508.09229) | **[link](https://github.com/svtdanny/moe_topology_pack)** |
| 18/30 | **2025-08-11** | <details><summary>**Pareto Multi-Objective Alignment for Language Models**</summary>PAMA introduces a computationally efficient algorithm for multi-objective alignment by reformulating the expensive gradient-norm minimization of MGDA into a convex optimization problem with a closed-form solution, reducing complexity from O(n^2d) to O(n). Empirical results on LLaMA-2-7B are robust, showing stable convergence on conflicting objectives (e.g., harmlessness vs. length) where baselines like MGDA-UB oscillate or fail. The single most useful takeaway is the analytical derivation for optimal objective weighting (Theorem 1) and the 'Noon PPO' heuristic (clipping negative advantages); we could port this logic to our multi-objective process reward models in AlgoEvo to balance search signals efficiently. While the NLP experiments are trivial, the gradient balancing mechanism is directly applicable to our multi-objective RL controllers.</details> | Qiang He et.al. | Ruhr University Bochum | ECML/PKDD 2025 | [2508.07768](http://arxiv.org/abs/2508.07768) | ‚Äî |
| 21/30 | **2025-08-05** | <details><summary>**Learning to Incentivize: LLM-Empowered Contract for AIGC Offloading in Teleoperation**</summary>Zhan et al. propose an LLM-based evolutionary framework to generate Python solvers for inferring hidden agent parameters in contract design (a bilevel OR problem). While the experiments are toy-scale (N=7 actions) and benchmarks are weak, the methodological architecture is highly relevant: they separate 'short-term reflectors' (analyzing parent pairs) from a 'long-term reflector' (aggregating insights across generations) to guide the Mutation LLM. This is a concrete, transferable implementation of evolutionary memory that we should test to improve sample efficiency in our own code-evolving agents.</details> | Zijun Zhan et.al. | University of Houston, The Pennsylvania State University, University of Florida, Kyung Hee University, China University of Petroleum (East China), Prairie View A&M University | IEEE Transactions on Network Science and Engineering | [2508.03464](http://arxiv.org/abs/2508.03464) | **[link](https://github.com/Zijun0819/llm4contract)** |
| ‚Äî | **2025-08-05** | **Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation** | Vinicius Lima et.al. |  | arXiv.org | [2508.03117](http://arxiv.org/abs/2508.03117) | ‚Äî |
| ‚Äî | **2025-08-01** | **OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problems with Reasoning LLM** | Bowen Zhang et.al. |  |  | [2503.10009](http://arxiv.org/abs/2503.10009) | **[link](https://github.com/bwz96sco/or_llm_agent)** |
| 13/30 | **2025-07-30** | <details><summary>**Parametrized Multi-Agent Routing via Deep Attention Models**</summary>Basiri et al. replace the dynamic programming step in Maximum Entropy Principle (MEP) optimization with a Transformer-based 'Shortest Path Network' to jointly solve facility location and routing. They demonstrate 100x-1500x speedups over Gurobi and analytical baselines by estimating gradients via a mixture of Beam Search and uniform sampling. While the speed is impressive, the resulting ~6% optimality gap is too high for high-precision OR applications. The primary takeaway is the practical utility of mixing uniform samples with high-probability samples to stabilize gradient estimation in coupled discrete-continuous optimization, though this does not justify a shift in our current methods.</details> | Salar Basiri et.al. | University of Illinois Urbana-Champaign | AAAI | [2507.22338](http://arxiv.org/abs/2507.22338) | **[link](https://github.com/salar96/LearningFLPO)** |
| 25/30 | **2025-07-21** | <details><summary>**DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving**</summary>DHEvo introduces a 'data-algorithm co-evolution' framework that iteratively evolves heuristic code while simultaneously filtering the training instance set to retain only 'representative' instances (those where current heuristics perform well/stably). Empirical results on SCIP diving heuristics show it outperforms FunSearch and EoH by ~60% on Setcover while significantly reducing performance variance, validating the claim that dynamic data curation prevents overfitting. The key takeaway is the counter-intuitive curriculum strategy: rather than training on the hardest instances, filtering for instances with 'regular' feasible regions (high fitness) stabilizes the evolutionary search for code. We should immediately test this dynamic instance filtering in AlgoEvo to improve sample efficiency and generalization.</details> | Zhihao Zhang et.al. | Harbin Institute of Technology, Huawei Noah‚Äôs Ark Lab, Nanyang Technological University | arXiv.org | [2507.15615](http://arxiv.org/abs/2507.15615) | ‚Äî |
| 9/30 | **2025-07-13** | <details><summary>**Adaptive Federated LoRA in Heterogeneous Wireless Networks with Independent Sampling**</summary>Hou et al. propose an adaptive Federated LoRA strategy that jointly optimizes client sampling probabilities and LoRA sketching ratios to minimize wall-clock training time. They derive a convergence bound and use it as a constraint in a non-convex optimization problem, achieving ~4x speedups over state-of-the-art FL methods on commonsense reasoning tasks. The most transferable insight is their 'calibration' technique: rather than relying on loose theoretical constants in their convergence bound, they treat the bound's coefficients as unknown parameters and estimate them via SVD from a few pilot runs‚Äîa clever trick to make theoretical bounds actionable in OR formulations. However, the specific application to wireless Federated Learning is irrelevant to our current research agenda.</details> | Yanzhao Hou et.al. | National Engineering Research Center for Mobile Network Technologies, Beijing University of Posts and Telecommunications, Hong Kong Baptist University, Peng Cheng Laboratory | arXiv.org | [2505.23555](http://arxiv.org/abs/2505.23555) | ‚Äî |
| ‚Äî | **2025-07-05** | **Combining Graph Neural Networks and Mixed Integer Linear Programming for Molecular Inference under the Two-Layered Model** | Jianshen Zhu et.al. | Kyoto University | arXiv.org | [2507.03920](http://arxiv.org/abs/2507.03920) | ‚Äî |
| 6/30 | **2025-07-02** | <details><summary>**Efficient Split Federated Learning for Large Language Models over Communication Networks**</summary>Zhao et al. propose a resource allocation framework for Split Federated Learning (SFL) combined with LoRA over wireless edge networks. They formulate a mixed-integer non-linear programming problem to jointly optimize subchannel allocation, transmission power, model split points, and LoRA rank to minimize training latency, solving it via Block Coordinate Descent. The results are simulation-based and focus entirely on overcoming wireless channel constraints (fading, noise). This is a standard communications engineering paper applied to LLMs; it offers no insights for our algorithmic discovery or cluster-scale resource allocation work.</details> | Kai Zhao et.al. |  |  | [2504.14667](http://arxiv.org/abs/2504.14667) | ‚Äî |
| ‚Äî | **2025-06-30** | **Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice** | Akshit Kumar et.al. |  | Online World Conference on Soft Computing in Industrial Applications | [2506.23924](http://arxiv.org/abs/2506.23924) | ‚Äî |
| 9/30 | **2025-06-22** | <details><summary>**Integrating LLMs and Digital Twins for Adaptive Multi-Robot Task Allocation in Construction**</summary>Deng et al. propose a pipeline where an LLM parses natural language site updates (e.g., delays) into constraint modifications for a standard CP-SAT solver to reschedule construction robots. The validation is limited to trivial instance sizes (max 27 tasks) and focuses on the LLM's extraction accuracy rather than optimization performance improvements. While the prompt engineering for mapping text to constraint types is competent, the methodology treats the LLM purely as a translator, offering no insights for our work on evolutionary search or fundamental algorithm design.</details> | Min Deng et.al. | Amazon Robotics, Texas A&M University, Texas Tech University, University of South Florida | arXiv.org | [2506.18178](http://arxiv.org/abs/2506.18178) | ‚Äî |
| ‚Äî | **2025-06-11** | **ETS: Efficient Tree Search for Inference-Time Scaling** | Coleman Hooper et.al. |  | arXiv.org | [2502.13575](http://arxiv.org/abs/2502.13575) | **[link](https://github.com/SqueezeAILab/ETS)** |
| 7/30 | **2025-06-06** | <details><summary>**BAQ: Efficient Bit Allocation Quantization for Large Language Models**</summary>Zhang et al. formulate LLM weight quantization as a convex resource allocation problem, deriving a closed-form 'equal-loss' bit assignment that significantly outperforms uniform quantization (GPTQ) at 2 bits. The results are empirically strong, recovering usable perplexity at 2-bit precision where GPTQ typically collapses. For us, this is purely an infrastructure utility: we could potentially use their code to fit larger reasoning models into our limited GPU memory during evolutionary search. However, the methodology‚Äîstandard resource allocation applied to weights‚Äîoffers no transferable insights for our work in AlgoEvo or multi-agent optimization.</details> | Chao Zhang et.al. | Central South University, China, Khalifa University, UAE, CNRS, France | arXiv.org | [2506.05664](http://arxiv.org/abs/2506.05664) | **[link](https://github.com/CSU-ModelCompression/BAQ)** |
| ‚Äî | **2025-06-05** | **Joint User Association and Beamforming Design for ISAC Networks with Large Language Models** | Haoyun Li et.al. |  | IEEE Open Journal of the Communications Society | [2506.05637](http://arxiv.org/abs/2506.05637) | ‚Äî |
| ‚Äî | **2025-06-05** | **Autoformulation of Mathematical Optimization Models Using LLMs** | Nicol√°s Astorga et.al. |  | ICML | [2411.01679](http://arxiv.org/abs/2411.01679) | ‚Äî |
| ‚Äî | **2025-06-05** | **Demystifying Cost-Efficiency in LLM Serving over Heterogeneous GPUs** | Youhe Jiang et.al. |  | International Conference on Machine Learning | [2502.00722](http://arxiv.org/abs/2502.00722) | ‚Äî |
| ‚Äî | **2025-06-03** | **Puzzle: Distillation-Based NAS for Inference-Optimized LLMs** | Akhiad Bercovich et.al. |  | International Conference on Machine Learning | [2411.19146](http://arxiv.org/abs/2411.19146) | ‚Äî |
| ‚Äî | **2025-05-29** | **Towards Reward Fairness in RLHF: From a Resource Allocation Perspective** | Sheng Ouyang et.al. |  | ACL | [2505.23349](http://arxiv.org/abs/2505.23349) | **[link](https://github.com/shoyua/Towards-Reward-Fairness)** |
| 3/30 | **2025-05-25** | <details><summary>**Lightweight Embeddings with Graph Rewiring for Collaborative Filtering**</summary>LERG reduces storage and computation for GNN-based recommenders by quantizing a compositional embedding codebook and pruning the interaction graph via a linear programming relaxation of a binary integer problem. The authors demonstrate significant storage reduction (up to 97%) on datasets like iFashion while maintaining competitive accuracy against other lightweight baselines. The only potential methodological takeaway is the use of LP relaxation to select 'active' nodes based on pre-trained similarity scores, but this is a standard OR technique applied to a problem we do not have. This work is irrelevant to our focus on evolutionary search and vehicle routing.</details> | Xurong Liang et.al. | The University of Queensland | TOIS'25 | [2505.18999](http://arxiv.org/abs/2505.18999) | ‚Äî |
| ‚Äî | **2025-05-19** | **Seeing, Saying, Solving: An LLM-to-TL Framework for Cooperative Robots** | Dan BW Choe et.al. |  | arXiv.org | [2505.13376](http://arxiv.org/abs/2505.13376) | ‚Äî |
| ‚Äî | **2025-05-19** | **Automatic mixed precision for optimizing gained time with constrained loss mean-squared-error based on model partition to sequential sub-graphs** | Shmulik Markovich-Golan et.al. |  | arXiv.org | [2505.13060](http://arxiv.org/abs/2505.13060) | ‚Äî |
| ‚Äî | **2025-05-06** | **SPAP: Structured Pruning via Alternating Optimization and Penalty Methods** | Hanyu Hu et.al. |  | arXiv.org | [2505.03373](http://arxiv.org/abs/2505.03373) | ‚Äî |
| ‚Äî | **2025-04-24** | **Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents** | Yueying Li et.al. |  | arXiv.org | [2504.07347](http://arxiv.org/abs/2504.07347) | ‚Äî |
| ‚Äî | **2025-04-14** | **Can Reasoning Models Reason about Hardware? An Agentic HLS Perspective** | Luca Collini et.al. |  | 2025 IEEE International Conference on LLM-Aided Design (ICLAD) | [2503.12721](http://arxiv.org/abs/2503.12721) | ‚Äî |
| ‚Äî | **2025-04-08** | **ARLO: A Tailorable Approach for Transforming Natural Language Software Requirements into Architecture using LLMs** | Tooraj Helmi et.al. |  | arXiv.org | [2504.06143](http://arxiv.org/abs/2504.06143) | ‚Äî |
| ‚Äî | **2025-04-04** | **ORLM: A Customizable Framework in Training Large Models for Automated Optimization Modeling** | Chenyu Huang et.al. |  | Operations Research (2025), published online ahead of print | [2405.17743](http://arxiv.org/abs/2405.17743) | **[link](https://github.com/cardinal-operations/orlm)** |
| ‚Äî | **2025-04-01** | **SCRec: A Scalable Computational Storage System with Statistical Sharding and Tensor-train Decomposition for Recommendation Models** | Jinho Yang et.al. |  | IEEE transactions on computers | [2504.00520](http://arxiv.org/abs/2504.00520) | ‚Äî |
| ‚Äî | **2025-03-22** | **A Survey on Mathematical Reasoning and Optimization with Large Language Models** | Ali Forootani et.al. |  | arXiv.org | [2503.17726](http://arxiv.org/abs/2503.17726) | **[link](https://github.com/Ali-Forootani/A-Survey-on-Mathematical-Reasoning-and-Optimization-with-Large-Language-Models)** |
| 8/30 | **2025-03-19** | <details><summary>**Communication-Efficient Distributed On-Device LLM Inference Over Wireless Networks**</summary>The authors propose using Over-the-Air Computation (AirComp)‚Äîleveraging analog signal superposition in wireless channels‚Äîto accelerate the all-reduce step for distributed LLM inference on edge devices. While they claim a 5x speedup in simulations, the approach relies entirely on wireless physical properties (fading channels, beamforming) that do not translate to the digital interconnects (NVLink/InfiniBand) used in our cluster environments. The only potentially interesting aspect is the formulation of a mixed-timescale stochastic optimization problem for resource allocation, but the solution via standard Stochastic SCA is not novel enough to warrant attention for our RobustMAS project.</details> | Kai Zhang et.al. | The Hong Kong University of Science and Technology | IEEE Journal on Selected Topics in Signal Processing | [2503.14882](http://arxiv.org/abs/2503.14882) | **[link](https://github.com/zklasd24/distributedllamaAirComp)** |
| ‚Äî | **2025-03-18** | **Automatic MILP Model Construction for Multi-Robot Task Allocation and Scheduling Based on Large Language Models** | Mingming Peng et.al. |  | IEEE/RJS International Conference on Intelligent RObots and Systems | [2503.13813](http://arxiv.org/abs/2503.13813) | ‚Äî |
| ‚Äî | **2025-03-12** | **Automatic Operator-level Parallelism Planning for Distributed Deep Learning -- A Mixed-Integer Programming Approach** | Ruifeng She et.al. |  | arXiv.org | [2503.09357](http://arxiv.org/abs/2503.09357) | ‚Äî |
| 22/30 | **2025-03-11** | <details><summary>**Robust Multi-Objective Controlled Decoding of Large Language Models**</summary>RMOD formulates multi-objective decoding as a zero-sum game between a policy and adversarial weights, solving a convex optimization problem at each decoding step to maximize the worst-case value estimate (essentially a Process Reward Model). The results are empirically strong, outperforming MO-DPO and scalarized baselines on alignment benchmarks by dynamically preventing any single objective from collapsing. **Key Takeaway:** The efficient inference-time weight optimization algorithm (Eq. 10) is a 'stealable' mechanism for **AlgoEvo** and **RobustMAS**. We should implement this dynamic adversarial weighting to balance conflicting code metrics (e.g., runtime vs. solution quality) during evolutionary search, replacing our current static scalarization methods.</details> | Seongho Son et.al. | University College London, University of Basel, Ulsan National Institute of Science and Technology | ICLR | [2503.08796](http://arxiv.org/abs/2503.08796) | **[link](https://github.com/williambankes/robust-multi-objective-decoding)** |
| 25/30 | **2025-03-05** | <details><summary>**Helix: Serving Large Language Models over Heterogeneous GPUs and Network via Max-Flow**</summary>Helix formulates distributed LLM serving on heterogeneous clusters as a max-flow problem, using MILP to optimize model placement and deriving a per-request weighted round-robin scheduler from the flow solution. Unlike standard static pipeline parallelism, it routes every request dynamically based on edge capacities, achieving up to 3.3x throughput gains over Swarm on mixed GPU clusters (L4/T4/A100). The results are rigorous, backed by both physical cluster experiments and high-fidelity simulations. The critical takeaway is the 'per-request pipeline' abstraction: decoupling request routing from static device assignment allows exact OR methods to maximize utilization of weaker hardware‚Äîa technique we should immediately evaluate for our GPUSched project.</details> | Yixuan Mei et.al. | Carnegie Mellon University | International Conference on Architectural Support for Programming Languages and Operating Systems | [2406.01566](http://arxiv.org/abs/2406.01566) | **[link](https://github.com/Thesys-lab/Helix-ASPLOS25)** |
| ‚Äî | **2025-03-04** | **Reliable and Efficient Multi-Agent Coordination via Graph Neural Network Variational Autoencoders** | Yue Meng et.al. |  | 2025 International Conference on Robotics and Automation (ICRA 2025) | [2503.02954](http://arxiv.org/abs/2503.02954) | **[link](https://github.com/mengyuest/gnn-vae-coord)** |
| ‚Äî | **2025-03-03** | **DILEMMA: Joint LLM Quantization and Distributed LLM Inference Over Edge Computing Systems** | Minoo Hosseinzadeh et.al. |  | arXiv.org | [2503.01704](http://arxiv.org/abs/2503.01704) | ‚Äî |
| ‚Äî | **2025-02-26** | **A Temporal Planning Framework for Multi-Agent Systems via LLM-Aided Knowledge Base Management** | Enrico Saccon et.al. |  | arXiv.org | [2502.19135](http://arxiv.org/abs/2502.19135) | ‚Äî |
| ‚Äî | **2025-02-25** | **OCCAM: Towards Cost-Efficient and Accuracy-Aware Classification Inference** | Dujian Ding et.al. |  | ICLR | [2406.04508](http://arxiv.org/abs/2406.04508) | **[link](https://github.com/DujianDing/OCCAM)** |
| ‚Äî | **2025-02-22** | **Mixture Compressor for Mixture-of-Experts LLMs Gains More** | Wei Huang et.al. |  | ICLR | [2410.06270](http://arxiv.org/abs/2410.06270) | **[link](https://github.com/aaronhuang-778/mc-moe)** |
| 8/30 | **2025-02-18** | <details><summary>**Distributed On-Device LLM Inference With Over-the-Air Computation**</summary>Zhang et al. propose using analog 'Over-the-Air' computation to accelerate the all-reduce aggregation step in distributed tensor-parallel LLM inference on edge devices. They formulate a mixed-timescale stochastic optimization problem for joint model assignment and beamforming, solved via Semidefinite Relaxation and Successive Convex Approximation. While the two-stage formulation (slow assignment, fast adjustment) technically parallels our stochastic resource allocation work, the methodology is specific to wireless interference management and offers no transferable insights for our discrete optimization or evolutionary search stacks. The results are simulation-based on VMs, not real hardware.</details> | Kai Zhang et.al. | The Hong Kong University of Science and Technology | ICC 2025 - IEEE International Conference on Communications | [2502.12559](http://arxiv.org/abs/2502.12559) | ‚Äî |
| ‚Äî | **2025-02-14** | **Hybrid Offline-online Scheduling Method for Large Language Model Inference Optimization** | Bowen Pang et.al. |  | arXiv.org | [2502.15763](http://arxiv.org/abs/2502.15763) | ‚Äî |
| ‚Äî | **2025-02-11** | **Let the Fuzzy Rule Speak: Enhancing In-context Learning Debiasing with Interpretability** | Ruixi Lin et.al. |  |  | [2412.19018](http://arxiv.org/abs/2412.19018) | ‚Äî |
| ‚Äî | **2025-02-11** | **FlexSP: Accelerating Large Language Model Training via Flexible Sequence Parallelism** | Yujie Wang et.al. |  | International Conference on Architectural Support for Programming Languages and Operating Systems | [2412.01523](http://arxiv.org/abs/2412.01523) | **[link](https://github.com/AFDWang/ASPLOS25-FlexSP-Supplemental-Material)** |
| ‚Äî | **2025-02-10** | **MoETuner: Optimized Mixture of Expert Serving with Balanced Expert Placement and Token Routing** | Seokjin Go et.al. |  | arXiv.org | [2502.06643](http://arxiv.org/abs/2502.06643) | ‚Äî |
| 2/30 | **2025-02-03** | <details><summary>**Relatively-Secure LLM-Based Steganography via Constrained Markov Decision Processes**</summary>Huang et al. formulate LLM steganography as a Constrained Markov Decision Process (CMDP) to maximize embedding entropy under total variation constraints. However, they reduce the entire LLM to a trivial 2-state model to derive closed-form policies, providing no empirical validation on actual language models or complex state spaces. The work is purely theoretical on a toy abstraction and offers no actionable insights for optimization or search.</details> | Yu-Shin Huang et.al. | Massachusetts Institute of Technology, Texas A&M University | International Symposium on Information Theory | [2502.01827](http://arxiv.org/abs/2502.01827) | **[link](https://github.com/Yu-Shin-Huang/Stega-via-CMDP.git)** |
| ‚Äî | **2025-01-16** | **Split Fine-Tuning for Large Language Models in Wireless Networks** | Songge Zhang et.al. |  | IEEE Journal on Selected Topics in Signal Processing | [2501.09237](http://arxiv.org/abs/2501.09237) | ‚Äî |
| ‚Äî | **2025-01-15** | **MEMO: Fine-grained Tensor Management For Ultra-long Context LLM Training** | Pinxue Zhao et.al. |  | Proc. ACM Manag. Data | [2407.12117](http://arxiv.org/abs/2407.12117) | **[link](https://github.com/pinxuezhao/MEMO)** |
| ‚Äî | **2025-01-13** | **A Unified Approach to Extract Interpretable Rules from Tree Ensembles via Integer Programming** | Lorenzo Bonasera et.al. |  | Computers & Operations Research | [2407.00843](http://arxiv.org/abs/2407.00843) | ‚Äî |
| ‚Äî | **2025-01-07** | **A Sequential Optimal Learning Approach to Automated Prompt Engineering in Large Language Models** | Shuyang Wang et.al. |  | Conference on Empirical Methods in Natural Language Processing | [2501.03508](http://arxiv.org/abs/2501.03508) | ‚Äî |
| 6/30 | **2025-01-02** | <details><summary>**Communication-and-Computation Efficient Split Federated Learning: Gradient Aggregation and Resource Management**</summary>Liang et al. propose a Split Federated Learning framework that aggregates gradients at the cut layer to reduce downlink bandwidth, using DDQN to dynamically select the model split point. They validate this on MNIST and CIFAR-10 with 10 clients, claiming communication reductions by forcing identical client-side updates to bypass synchronization steps. The methodology relies on standard wireless resource allocation techniques (optimizing transmit power and subchannel bandwidth) and offers no transferable insights for LLM serving or evolutionary optimization. The results are limited to small-scale edge scenarios and do not scale to the complexity of problems we solve.</details> | Yipeng Liang et.al. | Wuhan University, Zhejiang University, Shenzhen Research Institute of Big Data, Oman Telecommunications Company | arXiv.org | [2501.01078](http://arxiv.org/abs/2501.01078) | ‚Äî |
| ‚Äî | **2024-12-11** | **Fundamental Limits of Prompt Compression: A Rate-Distortion Framework for Black-Box Language Models** | Alliot Nagle et.al. |  | NeurIPS | [2407.15504](http://arxiv.org/abs/2407.15504) | ‚Äî |
| ‚Äî | **2024-11-08** | **SpecHub: Provable Acceleration to Multi-Draft Speculative Decoding** | Ryan Sun et.al. |  | EMNLP | [2411.05289](http://arxiv.org/abs/2411.05289) | ‚Äî |
| ‚Äî | **2024-10-28** | **LiP-LLM: Integrating Linear Programming and dependency graph with Large Language Models for multi-robot task planning** | Kazuma Obata et.al. |  | IEEE Robotics and Automation Letters | [2410.21040](http://arxiv.org/abs/2410.21040) | ‚Äî |
| ‚Äî | **2024-10-24** | **Maximum a Posteriori Inference for Factor Graphs via Benders' Decomposition** | Harsh Vardhan Dubey et.al. |  | arXiv.org | [2410.19131](http://arxiv.org/abs/2410.19131) | ‚Äî |
| ‚Äî | **2024-10-21** | **To the Globe (TTG): Towards Language-Driven Guaranteed Travel Planning** | Da JU et.al. |  | EMNLP 2024 Demo Track | [2410.16456](http://arxiv.org/abs/2410.16456) | ‚Äî |
| 13/30 | **2024-10-16** | <details><summary>**SplitLLM: Collaborative Inference of LLMs for Model Placement and Throughput Optimization**</summary>Mudvari et al. formulate the placement of LLM layers between a client and server as a constrained shortest path problem on a DAG, solving it via dynamic programming to minimize server load under latency constraints. They claim a ~19% improvement over greedy splitting baselines (like Neurosurgeon) in simulated environments. The primary takeaway is the clean mapping of sequential model layers to heterogeneous hardware resources using standard OR techniques, which serves as a decent reference for our GPUSched formulations regarding pipeline parallelism. However, the method relies on standard integer-rounding relaxations and offers no fundamental novelty in optimization or LLM search.</details> | Akrit Mudvari et.al. | Yale University, NEC Laboratories America | arXiv.org | [2410.10759](http://arxiv.org/abs/2410.10759) | ‚Äî |
| ‚Äî | **2024-10-10** | **MENAGE: Mixed-Signal Event-Driven Neuromorphic Accelerator for Edge Applications** | Armin Abdollahi et.al. |  | arXiv.org | [2410.08403](http://arxiv.org/abs/2410.08403) | ‚Äî |
| 9/30 | **2024-10-03** | <details><summary>**Foundations of Large Language Model Compression -- Part 1: Weight Quantization**</summary>Young formulates LLM weight quantization as a constrained convex optimization problem (minimizing distortion subject to a bit budget), solved via dual ascent to assign arbitrary fractional bit-widths per layer. The results are rigorous and show that classical optimization methods can outperform heuristic approaches like GPTQ, particularly at aggressive compression rates (2-3 bits). The primary takeaway for us is the modeling pattern: treating discrete configuration choices as continuous variables in a resource allocation problem is a strategy we could transfer to our GPU scheduling formulations. However, the method itself is not actionable for our evolutionary search or routing research.</details> | Sean I. Young et.al. | MIT | arXiv.org | [2409.02026](http://arxiv.org/abs/2409.02026) | **[link](github.com/seannz/cvxq)** |
| ‚Äî | **2024-09-13** | **B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests** | Mouxiang Chen et.al. |  | ASE' 24 (full paper) | [2409.08692](http://arxiv.org/abs/2409.08692) | **[link](https://github.com/zju-ctag/b4)** |
| ‚Äî | **2024-09-11** | **Beyond IID: Optimizing Instruction Learning from the Perspective of Instruction Interaction and Dependency** | Hanyu Zhao et.al. |  | arXiv.org | [2409.07045](http://arxiv.org/abs/2409.07045) | ‚Äî |
| ‚Äî | **2024-08-09** | **Cycle-Configuration: A Novel Graph-theoretic Descriptor Set for Molecular Inference** | Bowen Song et.al. |  | IEEE International Conference on Bioinformatics and Biomedicine | [2408.05136](http://arxiv.org/abs/2408.05136) | ‚Äî |
| 7/30 | **2024-08-07** | <details><summary>**A Convex-optimization-based Layer-wise Post-training Pruner for Large Language Models**</summary>FISTAPruner formulates layer-wise LLM pruning as a convex optimization problem with $\ell_1$ regularization, solved via the FISTA algorithm, and includes an intra-layer error correction mechanism. The authors demonstrate superior perplexity and zero-shot performance compared to SparseGPT and Wanda, though the method is computationally slower (hours vs minutes). For us, the primary takeaway is the effectiveness of replacing heuristics with rigorous classical optimization (LASSO-style) in deep learning contexts, but the specific application to weight pruning is not actionable for our evolutionary search or OR scheduling work.</details> | Pengxiang Zhao et.al. | Huawei Cloud, The University of Hong Kong | arXiv.org | [2408.03728](http://arxiv.org/abs/2408.03728) | ‚Äî |
| ‚Äî | **2024-07-18** | **Improving GPU Multi-Tenancy Through Dynamic Multi-Instance GPU Reconfiguration** | Tianyu Wang et.al. |  | arXiv.org | [2407.13126](http://arxiv.org/abs/2407.13126) | ‚Äî |
| ‚Äî | **2024-06-27** | **SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models** | Vipul Rathore et.al. |  | Conference on Empirical Methods in Natural Language Processing | [2406.18880](http://arxiv.org/abs/2406.18880) | ‚Äî |
| ‚Äî | **2024-06-18** | **City-LEO: Toward Transparent City Management Using LLM with End-to-End Optimization** | Zihao Jiao et.al. |  | arXiv.org | [2406.10958](http://arxiv.org/abs/2406.10958) | ‚Äî |
| ‚Äî | **2024-06-17** | **Multi-Dimensional Pruning: Joint Channel, Layer and Block Pruning with Latency Constraint** | Xinglong Sun et.al. |  | arXiv.org | [2406.12079](http://arxiv.org/abs/2406.12079) | ‚Äî |
| ‚Äî | **2024-06-04** | **Investigating the Potential of Using Large Language Models for Scheduling** | Deddy Jobson et.al. |  | AIware | [2406.07573](http://arxiv.org/abs/2406.07573) | **[link](https://github.com/jettbrains/-L-)** |
| ‚Äî | **2024-05-30** | **Large Language Model Watermark Stealing With Mixed Integer Programming** | Zhaoxi Zhang et.al. |  | arXiv.org | [2405.19677](http://arxiv.org/abs/2405.19677) | ‚Äî |
| 12/30 | **2024-05-12** | <details><summary>**Edge Intelligence Optimization for Large Language Model Inference with Batching and Quantization**</summary>This paper formulates edge LLM inference as a multidimensional knapsack problem, optimizing throughput by selecting batch sizes and quantization levels under latency and accuracy (PPL) constraints. They propose a Depth-First Tree-Searching algorithm with pruning (DFTSP) to solve this NP-hard problem, claiming superiority over static and no-batching baselines in simulation. For us, the only extractable insight is the explicit modeling of quantization-induced PPL degradation as a hard constraint in the optimization formulation, which could inform our GPUSched constraints. However, the algorithmic approach is standard branch-and-bound, and the lack of comparison to modern continuous batching engines limits its utility.</details> | Xinyuan Zhang et.al. | SUTD, BUPT, Purple Mountain Laboratories | IEEE Wireless Communications and Networking Conference | [2405.07140](http://arxiv.org/abs/2405.07140) | ‚Äî |

</details>

## Generative AI for OR

### üÜï Most Recent

| Date | Title | Authors | Affiliation | Code |
|------|-------|---------|-------------|------|
| **2026-02-11** | <details><summary>**Constructing Industrial-Scale Optimization Modeling Benchmark**</summary>Li et al. introduce MIPLIB-NL, a benchmark of 223 industrial-scale MILP instances (up to 10^7 variables) reverse-engineered from MIPLIB 2017, enforcing strict model-data separation. Results are sobering: SOTA models like GPT-4 and fine-tuned OR-LLMs drop from ~90% accuracy on existing toy benchmarks to ~18% here, failing primarily on structural consistency and index handling at scale. For us, the key takeaway is their "Loop-Based Structural Scaffold" taxonomy‚Äîa method to compress massive industrial formulations into compact LLM prompts via model-data separation. This is a mandatory read for our OR-Bench project, as it demonstrates that current evaluations are effectively measuring overfitting to toy problems rather than genuine modeling capability.</details> | Zhong Li et.al. | Peking University, Huawei Technologies Co., Ltd., Great Bay University | **[link](https://github.com/optsuite/MIPLIB-NL)** |
| **2026-02-06** | <details><summary>**Evaluating LLM-persona Generated Distributions for Decision-making**</summary>This paper evaluates using LLMs to generate probability distributions for stochastic optimization (Assortment, Pricing, Newsvendor) via Sample Average Approximation (SAA). They rigorously show that standard statistical distance metrics often misalign with decision quality‚Äîa distribution can be statistically far from ground truth yet yield near-optimal decisions. The key actionable insight is that 'persona-sampling' (prompting the LLM to adopt specific demographics) significantly improves the aggregate distribution's utility for optimization, even if the LLM fails to simulate individual personas accurately. This is relevant for generating diverse synthetic scenarios for our stochastic VRP and benchmarking efforts.</details> | Jackie Baek et.al. | New York University, Columbia University | **[link](https://github.com/yunhanchen2/Evaluating-LLM-persona-Generated-Distributions-for-Decision-making)** |
| **2026-02-03** | <details><summary>**MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research**</summary>MIRROR is a multi-agent framework that translates natural language OR problems into Gurobi code using Hierarchical RAG (metadata filtering + semantic search) and an iterative repair loop. It achieves ~72% pass@1 across five benchmarks, outperforming Chain-of-Experts and fine-tuned models like LLMOPT without task-specific training. The key takeaway is their **structured revision tip mechanism**: upon execution failure, the agent generates a JSON object explicitly isolating the `error_statement`, `incorrect_code_snippet`, and `correct_code_snippet`, which serves as a precise memory artifact for subsequent retries. This structured reflection pattern is superior to raw error logs and could be immediately adopted in our own code generation pipelines.</details> | Yifan Shi et.al. | Xi'an Jiaotong University, Northwestern Polytechnical University | ‚Äî |
| **2026-02-03** | <details><summary>**ProOPF: Benchmarking and Improving LLMs for Professional-Grade Power Systems Optimization Modeling**</summary>Shen et al. propose a benchmark (ProOPF) for translating natural language into Optimal Power Flow (OPF) models, treating instances as parametric or structural modifications to a canonical base model rather than generating code from scratch. They introduce a rigorous data synthesis pipeline using 'scenario trees' to map qualitative descriptions (e.g., 'heatwave') to quantitative parameter deltas, and define structural extensions (e.g., adding security constraints) as modular patches. Results are sobering: SOTA models (GPT-4, Claude 3.5) score 0% on the hardest level (semantic inference + structural change), though SFT recovers ~11-35%. **Key Takeaway:** We should steal their 'Base + Delta' synthesis approach for our VRP variant generation and OR-Bench work; it allows for scalable, physically valid data generation without requiring an LLM to hallucinate full solvers, and effectively benchmarks 'ambiguity' handling.</details> | Chao Shen et.al. |  | ‚Äî |
| **2026-02-03** | <details><summary>**LLM-Inspired Pretrain-Then-Finetune for Small-Data, Large-Scale Optimization**</summary>The authors propose a Transformer-based estimator for stochastic optimization parameters (e.g., demand in Newsvendor) that pretrains on synthetic domain knowledge and finetunes on sparse real data using a Stein-identity loss function. Results are purely theoretical and simulation-based, showing that finetuning scales with the number of tasks ($N$) to correct pretraining bias. The single most stealable insight is the use of **Stein's identity to construct a differentiable, label-free loss function**, allowing the model to adapt to real data without ground-truth labels‚Äîa technique potentially transferable to unsupervised adaptation in our stochastic OR projects. However, the work is mathematically dense and functionally distant from LLM-based algorithmic discovery.</details> | Zishi Zhang et.al. | Peking University, University of Toronto | ‚Äî |

### ‚≠ê Best Papers

| Score | Date | Title | Authors | Affiliation | Code |
|-------|------|-------|---------|-------------|------|
| 28/30 | **2025-08-16** | <details><summary>**EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models**</summary>Yazdani et al. introduce EvoCut, an evolutionary framework where LLMs generate Python code for MILP cuts, filtered by a 'usefulness check' (does it cut the current LP relaxation?) and an 'empirical validity check' (does it preserve known integer optima?). They report 17-57% gap reductions on TSPLIB and JSSP compared to Gurobi defaults, backed by strong ablation studies on the evolutionary operators. **Key Takeaway:** The reliance on 'acceleration cuts'‚Äîconstraints verified empirically on small datasets rather than formally proven‚Äîbypasses the bottleneck of automated theorem proving while still delivering valid speedups. We should immediately adopt their 'LP separation' check as a cheap, high-signal reward for our own evolutionary search loops.</details> | M. Yazdani et.al. | Huawei Technologies Canada, University of British Columbia, University of Toronto | **[link](https://github.com/milad1378yz/EvoCut)** |
| 27/30 | **2026-01-29** | <details><summary>**NEMO: Execution-Aware Optimization Modeling via Autonomous Coding Agents**</summary>NEMO achieves SOTA on 8/9 optimization benchmarks by deploying autonomous coding agents that generate both a declarative optimizer (solver code) and an imperative simulator (verification code). The key innovation is using the simulator to validate the optimizer's results in a closed loop, detecting logical errors without ground truth‚Äîa technique that beats fine-tuned models like SIRL by up to 28%. The most stealable insight is this asymmetric validation: imperative Python simulation is often less error-prone than declarative constraint formulation, making it a robust 'critic' for generated solvers. This is immediately applicable to our OR-Bench and AlgoEvo projects for generating reliable reward signals.</details> | Yang Song et.al. | Carnegie Mellon University, C3 AI | ‚Äî |
| 26/30 | **2025-09-26** | <details><summary>**StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models**</summary>Zhou et al. propose StepORLM, a framework where an 8B policy and a **Generative Process Reward Model (GenPRM)** co-evolve. Unlike standard discriminative PRMs that score steps in isolation, their GenPRM generates a reasoning trace to evaluate the full trajectory's logic before assigning credit, addressing the interdependency of OR constraints. They align the policy using **Weighted DPO**, where preference weights are derived from the GenPRM's process scores. They claim to beat GPT-4o and DeepSeek-V3 on 6 OR benchmarks (e.g., NL4Opt, MAMO) with an 8B model. **Key Takeaway:** We should test **Generative PRMs** immediately for AlgoEvo; asking the critic to 'explain then score' (generative) rather than just 'score' (discriminative) likely fixes the credit assignment noise in our long-horizon search.</details> | Chenyu Zhou et.al. | Shanghai Jiao Tong University | ‚Äî |
| 26/30 | **2025-05-17** | <details><summary>**Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling**</summary>Chen et al. introduce SIRL, a framework for training LLMs to generate optimization models using Reinforcement Learning with Verifiable Rewards (RLVR) and a novel 'Partial KL' surrogate objective. By removing the KL penalty from the reasoning (CoT) section while retaining it for the code generation section, they balance exploration with syntactic stability, achieving SOTA on OptMATH and IndustryOR against OpenAI-o3 and DeepSeek-R1. The critical takeaway for us is the Partial KL strategy: it allows the model to 'think' freely outside the reference distribution while adhering to strict coding standards‚Äîa technique we should immediately test in AlgoEvo. Furthermore, their method of parsing .lp files to extract structural features (variable counts, constraint types) for 'instance-enhanced self-consistency' provides a much richer signal than our current binary success/failure metrics.</details> | Yitian Chen et.al. | Stanford University, Shanghai Jiao Tong University, The University of Hong Kong, Shanghai University of Finance and Economics, Cardinal Operations | **[link](https://github.com/Cardinal-Operations/SIRL)** |
| 25/30 | **2025-10-31** | <details><summary>**ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling**</summary>Wang et al. propose ORGEval, a framework that evaluates LLM-generated optimization models by converting them into bipartite graphs and using the Weisfeiler-Lehman (WL) test to detect isomorphism with a ground truth, rather than solving the instances. They prove that for 'symmetric decomposable' graphs, this method is guaranteed to detect equivalence correctly, achieving 100% consistency and running in seconds compared to hours for solver-based checks on hard MIPLIB instances. The critical takeaway is the shift from execution-based to **structural evaluation**: we can validate model logic via graph topology ($O(k(m+n)^2)$) without incurring the cost of solving NP-hard problems. This is immediately actionable for our OR benchmarking pipelines and could serve as a rapid 'pre-solve' filter in our evolutionary search loops to reject structurally invalid candidates instantly.</details> | Zhuohan Wang et.al. | The Chinese University of Hong Kong, Shenzhen, Shenzhen Research Institute of Big Data, Shenzhen International Center for Industrial and Applied Mathematics, Shenzhen Loop Area Institute | ‚Äî |

### üî¨ Research Fronts

| Status | Front Name | Papers | Key Methods | Problems |
|--------|-----------|--------|-------------|----------|
| Declining | LLM-Driven Evolutionary and Agentic OR Algorithm and Model Synthesis | 16 | Llm In The Loop, Llm Code Generation, Program Synthesis | Scheduling, Job Shop Scheduling |
| Emerging | LLM-Guided Robust Optimization Model Formulation via Structured Search and Data Synthesis | 16 | Llm Code Generation, Llm In The Loop, Llm As Evaluator | Linear Programming, Mixed Integer Linear Programming |
| Declining | Scalable LLM-Driven Optimization Model Synthesis and Verification | 11 | Llm In The Loop, Llm As Evaluator, Llm Code Generation | Linear Programming, Optimization Modeling |
| Emerging | Multi-Agent LLM Frameworks for Iterative Optimization Model Synthesis | 10 | Llm Code Generation, Llm As Evaluator, Llm In The Loop | Linear Programming, Optimization Modeling |
| Emerging | Adaptive Scheduling and LLM-Guided Heuristic Evolution | 5 | Llm Code Generation, Llm In The Loop, Llm As Heuristic | Llm Inference Scheduling, Resource Constrained Scheduling |

<details>
<summary>üìã Full list (106 papers, sorted by date)</summary>

| Score | Date | Title | Authors | Affiliation | Venue | PDF | Code |
|-------|------|-------|---------|-------------|-------|-----|------|
| 24/30 | **2026-02-11** | <details><summary>**Constructing Industrial-Scale Optimization Modeling Benchmark**</summary>Li et al. introduce MIPLIB-NL, a benchmark of 223 industrial-scale MILP instances (up to 10^7 variables) reverse-engineered from MIPLIB 2017, enforcing strict model-data separation. Results are sobering: SOTA models like GPT-4 and fine-tuned OR-LLMs drop from ~90% accuracy on existing toy benchmarks to ~18% here, failing primarily on structural consistency and index handling at scale. For us, the key takeaway is their "Loop-Based Structural Scaffold" taxonomy‚Äîa method to compress massive industrial formulations into compact LLM prompts via model-data separation. This is a mandatory read for our OR-Bench project, as it demonstrates that current evaluations are effectively measuring overfitting to toy problems rather than genuine modeling capability.</details> | Zhong Li et.al. | Peking University, Huawei Technologies Co., Ltd., Great Bay University |  | [2602.10450](http://arxiv.org/abs/2602.10450) | **[link](https://github.com/optsuite/MIPLIB-NL)** |
| 16/30 | **2026-02-06** | <details><summary>**Evaluating LLM-persona Generated Distributions for Decision-making**</summary>This paper evaluates using LLMs to generate probability distributions for stochastic optimization (Assortment, Pricing, Newsvendor) via Sample Average Approximation (SAA). They rigorously show that standard statistical distance metrics often misalign with decision quality‚Äîa distribution can be statistically far from ground truth yet yield near-optimal decisions. The key actionable insight is that 'persona-sampling' (prompting the LLM to adopt specific demographics) significantly improves the aggregate distribution's utility for optimization, even if the LLM fails to simulate individual personas accurately. This is relevant for generating diverse synthetic scenarios for our stochastic VRP and benchmarking efforts.</details> | Jackie Baek et.al. | New York University, Columbia University |  | [2602.06357](http://arxiv.org/abs/2602.06357) | **[link](https://github.com/yunhanchen2/Evaluating-LLM-persona-Generated-Distributions-for-Decision-making)** |
| 20/30 | **2026-02-03** | <details><summary>**MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research**</summary>MIRROR is a multi-agent framework that translates natural language OR problems into Gurobi code using Hierarchical RAG (metadata filtering + semantic search) and an iterative repair loop. It achieves ~72% pass@1 across five benchmarks, outperforming Chain-of-Experts and fine-tuned models like LLMOPT without task-specific training. The key takeaway is their **structured revision tip mechanism**: upon execution failure, the agent generates a JSON object explicitly isolating the `error_statement`, `incorrect_code_snippet`, and `correct_code_snippet`, which serves as a precise memory artifact for subsequent retries. This structured reflection pattern is superior to raw error logs and could be immediately adopted in our own code generation pipelines.</details> | Yifan Shi et.al. | Xi'an Jiaotong University, Northwestern Polytechnical University |  | [2602.03318](http://arxiv.org/abs/2602.03318) | ‚Äî |
| 20/30 | **2026-02-03** | <details><summary>**ProOPF: Benchmarking and Improving LLMs for Professional-Grade Power Systems Optimization Modeling**</summary>Shen et al. propose a benchmark (ProOPF) for translating natural language into Optimal Power Flow (OPF) models, treating instances as parametric or structural modifications to a canonical base model rather than generating code from scratch. They introduce a rigorous data synthesis pipeline using 'scenario trees' to map qualitative descriptions (e.g., 'heatwave') to quantitative parameter deltas, and define structural extensions (e.g., adding security constraints) as modular patches. Results are sobering: SOTA models (GPT-4, Claude 3.5) score 0% on the hardest level (semantic inference + structural change), though SFT recovers ~11-35%. **Key Takeaway:** We should steal their 'Base + Delta' synthesis approach for our VRP variant generation and OR-Bench work; it allows for scalable, physically valid data generation without requiring an LLM to hallucinate full solvers, and effectively benchmarks 'ambiguity' handling.</details> | Chao Shen et.al. |  |  | [2602.03070](http://arxiv.org/abs/2602.03070) | ‚Äî |
| 15/30 | **2026-02-03** | <details><summary>**LLM-Inspired Pretrain-Then-Finetune for Small-Data, Large-Scale Optimization**</summary>The authors propose a Transformer-based estimator for stochastic optimization parameters (e.g., demand in Newsvendor) that pretrains on synthetic domain knowledge and finetunes on sparse real data using a Stein-identity loss function. Results are purely theoretical and simulation-based, showing that finetuning scales with the number of tasks ($N$) to correct pretraining bias. The single most stealable insight is the use of **Stein's identity to construct a differentiable, label-free loss function**, allowing the model to adapt to real data without ground-truth labels‚Äîa technique potentially transferable to unsupervised adaptation in our stochastic OR projects. However, the work is mathematically dense and functionally distant from LLM-based algorithmic discovery.</details> | Zishi Zhang et.al. | Peking University, University of Toronto |  | [2602.03690](http://arxiv.org/abs/2602.03690) | ‚Äî |
| 22/30 | **2026-02-02** | <details><summary>**Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation**</summary>Lyu et al. propose a 'Canonical Intermediate Representation' (CIR) to decouple natural language operational rules from their mathematical instantiation, explicitly forcing the LLM to select modeling paradigms (e.g., time-indexed vs. continuous flow) before coding. They achieve state-of-the-art accuracy (47.2% vs 22.4% baseline) on a new, complex benchmark (ORCOpt-Bench) by using a multi-agent pipeline that retrieves and adapts constraint templates. The key takeaway is the 'Mapper' agent's paradigm selection logic, which prevents common formulation errors in VRPs and scheduling; we should evaluate CIR as a structured mutation space for AlgoEvo to replace brittle code evolution. The new benchmark is immediately relevant for our OR-Bench evaluation suite.</details> | Zhongyuan Lyu et.al. | The Hong Kong Polytechnic University, InfiX.ai |  | [2602.02029](http://arxiv.org/abs/2602.02029) | ‚Äî |
| 11/30 | **2026-02-01** | <details><summary>**EvoOpt-LLM: Evolving industrial optimization models with large language models**</summary>He et al. fine-tune a 7B LLM to generate MILP code, inject constraints into existing LP files, and predict redundant variables. While the problem formulation of 'Constraint Injection' (editing LP files directly rather than regenerating from scratch) is a valid task for our OR agents, their execution relies entirely on standard supervised fine-tuning. The results are weak: their variable pruning module fails to scale, with F1 scores dropping to near zero on LP files exceeding 1,500 lines due to context limitations. This is an application paper with no transferable algorithmic insights for our evolutionary search work.</details> | Yiliu He et.al. | Southeast University |  | [2602.01082](http://arxiv.org/abs/2602.01082) | ‚Äî |
| 27/30 | **2026-01-29** | <details><summary>**NEMO: Execution-Aware Optimization Modeling via Autonomous Coding Agents**</summary>NEMO achieves SOTA on 8/9 optimization benchmarks by deploying autonomous coding agents that generate both a declarative optimizer (solver code) and an imperative simulator (verification code). The key innovation is using the simulator to validate the optimizer's results in a closed loop, detecting logical errors without ground truth‚Äîa technique that beats fine-tuned models like SIRL by up to 28%. The most stealable insight is this asymmetric validation: imperative Python simulation is often less error-prone than declarative constraint formulation, making it a robust 'critic' for generated solvers. This is immediately applicable to our OR-Bench and AlgoEvo projects for generating reliable reward signals.</details> | Yang Song et.al. | Carnegie Mellon University, C3 AI |  | [2601.21372](http://arxiv.org/abs/2601.21372) | ‚Äî |
| 23/30 | **2026-01-25** | <details><summary>**Grammar-Aware Literate Generative Mathematical Programming with Compiler-in-the-Loop**</summary>SyntAGM is a framework for translating natural language into Algebraic Modeling Language (PyOPL) code using a 'compiler-in-the-loop' approach, where the LLM is constrained by an in-context BNF grammar and iteratively repairs code based on compiler diagnostics. They demonstrate that this approach matches the accuracy of expensive multi-agent systems (like Chain-of-Experts) while being significantly faster and cheaper. The immediate takeaways for us are the **StochasticOR benchmark** (which we should adopt for RobustMAS) and the technique of **injecting explicit BNF grammars** into prompts to enforce syntax in evolutionary search without fine-tuning. The 'literate modeling' approach‚Äîembedding reasoning as comments directly next to code constraints‚Äîis also a clever memory mechanism we could steal for AlgoEvo.</details> | Roberto Rossi et.al. | University of Edinburgh, University College Cork |  | [2601.17670](http://arxiv.org/abs/2601.17670) | **[link](https://gwr3n.github.io/rhetor/)** |
| 23/30 | **2026-01-17** | <details><summary>**Automated Optimization Modeling via a Localizable Error-Driven Perspective**</summary>This paper introduces MIND, a framework for automated optimization modeling that combines error-driven data synthesis with a novel post-training method called DFPO. Instead of standard RLVR which suffers from sparse rewards on hard problems, DFPO uses a teacher model to minimally correct the student's *failed* rollouts, converting them into on-policy(ish) positive samples for SFT/RL. Results show a 7B model outperforming GPT-4 on IndustryOR and OptMATH benchmarks. **Key Takeaway:** We should steal the DFPO mechanism for AlgoEvo: rather than wasting failed evolutionary samples, use a stronger model (or oracle) to fix the code and feed it back as a reward signal, drastically improving sample efficiency in our RL loops.</details> | Weiting Liu et.al. | Huawei Noah‚Äôs Ark Lab, Fudan University, University of Science and Technology of China |  | [2602.11164](http://arxiv.org/abs/2602.11164) | ‚Äî |
| 13/30 | **2026-01-10** | <details><summary>**SimLLM: Fine-Tuning Code LLMs for SimPy-Based Queueing System Simulation**</summary>The authors fine-tune small code models (Qwen/DeepSeek) to generate executable SimPy queueing simulations using a three-stage pipeline: SFT on template-generated data, masked code completion, and DPO. Results show a jump from ~0% to ~76% logic consistency, confirming that base models hallucinate SimPy mechanics without targeted training. The most useful takeaway is the 'Stage II' masked completion strategy: explicitly masking functional logic blocks (e.g., 'service interruption logic') during training to force the model to learn internal library semantics rather than just surface-level completion. This technique could be transferable if our AlgoEvo agents struggle with hallucinating internal APIs, but otherwise, the paper is a niche engineering application.</details> | Jun-Qi Chen et.al. | Renmin University of China, University of Electronic Science and Technology of China | arXiv.org | [2601.06543](http://arxiv.org/abs/2601.06543) | ‚Äî |
| 16/30 | **2026-01-09** | <details><summary>**OPT-Engine: Benchmarking the Limits of LLMs in Optimization Modeling via Complexity Scaling**</summary>OPT-Engine introduces a scalable benchmark for OR modeling (10 problem classes) to evaluate LLMs, confirming that Tool-Integrated Reasoning (LLM+Gurobi) scales while Pure-Text Reasoning collapses. The results are rigorous and backed by solver verification. **Key Takeaway:** The 'Constraint Augmentation' analysis reveals a critical bottleneck: LLM performance drops sharply when simple, non-canonical constraints are added to standard problems, indicating a reliance on memorized templates rather than logical composition. This is a direct competitor/reference for our OR-Bench work and suggests we need to stress-test our AlgoEvo formulations against constraint perturbations.</details> | Yitian Chen et.al. | University of Chicago, Shanghai Jiao Tong University, Shanghai University of Finance and Economics, Cardinal Operations |  | [2601.19924](http://arxiv.org/abs/2601.19924) | **[link](https://github.com/Cardinal-Operations/OPTEngine)** |
| ‚Äî | **2026-01-09** | **Global Optimization for Combinatorial Geometry Problems Revisited in the Era of LLMs** | Timo Berthold et.al. |  |  | [2601.05943](http://arxiv.org/abs/2601.05943) | ‚Äî |
| 14/30 | **2026-01-08** | <details><summary>**NC2C: Automated Convexification of Generic Non-Convex Optimization Problems**</summary>NC2C extends automated OR modeling (like OptiMUS) to non-convex problems by using LLMs to identify non-convex terms and select standard relaxation strategies (SCA, Lagrangian) for solvers like CVXPY. The authors claim high success rates (~90% on NL4Opt) using GPT-5.1, employing a 'Feasibility Domain Correction' loop that iteratively adjusts initial points or relaxation strategies when solvers fail. While the results are strong, the methodology is essentially 'textbook relaxation via prompting'‚Äîuseful for our symbolic OR benchmarking baseline, but it provides no new insights for algorithmic discovery or evolutionary search.</details> | Xinyue Peng et.al. | Massachusetts Institute of Technology, Zhejiang University, Southeast University | arXiv.org | [2601.04789](http://arxiv.org/abs/2601.04789) | ‚Äî |
| 10/30 | **2026-01-02** | <details><summary>**LLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization**</summary>The authors apply a basic greedy refinement loop using OpenAI o4-mini to generate Python implementations of standard metaheuristics (GA, PSO, etc.) for Cardinality Constrained Portfolio Optimization. By generating multiple distinct algorithm types and pooling their results, they achieve performance competitive with state-of-the-art heuristics. The primary takeaway is empirical confirmation that LLM-generated algorithm portfolios provide better Pareto coverage than single heuristics, but the underlying 'agent' framework is trivial compared to our evolutionary search methods. This is an application paper with no transferable methodological insights for our core research.</details> | Simon Paquette-Greenbaum et.al. | McGill University | arXiv.org | [2601.00770](http://arxiv.org/abs/2601.00770) | ‚Äî |
| 19/30 | **2025-12-21** | <details><summary>**Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design**</summary>Li et al. propose APF, a framework to fine-tune LLMs for translating engineering requirements into optimization code without running expensive simulations during training. They generate synthetic training data and filter it by checking if the generated code ranks historical data instances similarly to how an LLM 'judge' ranks them based on the text requirements. Results show 7B models outperforming GPT-4o on antenna design tasks, validated by actual simulation. **Key Takeaway:** We can replace expensive ground-truth evaluations in our process reward models by checking consistency between generated code outputs and LLM-predicted rankings on cached historical data‚Äîa direct method to improve sample efficiency in AlgoEvo.</details> | Yuchen Li et.al. | Xidian University, Victoria University of Wellington, Westlake University | arXiv.org | [2512.18682](http://arxiv.org/abs/2512.18682) | ‚Äî |
| 14/30 | **2025-12-15** | <details><summary>**Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection**</summary>Da Ros et al. conduct a large-scale analysis (26k instances) to determine if Llama-3.2 embeddings encode combinatorial structure (BPP, GCP, JSP, KP) better than the model can explicitly reason about it. They find that while models fail to explicitly calculate features like graph density via prompting, a classifier trained on their max-pooled hidden states matches the performance of handcrafted features for algorithm selection. **Takeaway:** This confirms that LLM latent spaces hold rich structural signals useful for Process Reward Models or state representations in AlgoEvo, even when the model's explicit reasoning fails. However, since performance is only 'comparable' to cheap handcrafted features but computationally expensive, we should only leverage this for problems where manual feature engineering is impossible.</details> | Francesca Da Ros et.al. | University of Udine, Italy | arXiv.org | [2512.13374](http://arxiv.org/abs/2512.13374) | **[link](https://doi.org/10.5281/zenodo.17913884)** |
| 18/30 | **2025-12-12** | <details><summary>**A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation**</summary>A-LAMP decomposes the translation of natural language task descriptions into executable RL environments via a multi-agent pipeline, separating parameter extraction, variable definition, and constraint formulation before code generation. The results show that this structured approach allows a 27B model to rival GPT-4o on simple tasks, though the benchmarks (e.g., grid-world drone delivery, trivial wireless scheduling) are toy-scale and the RL application is sometimes forced. The primary takeaway is the specific decomposition schema for symbolic modeling: we should steal their granular extraction pipeline (Parameters -> Objectives -> Variables -> Constraints) to improve the reliability of our automated problem instantiation in OR-Bench and AlgoEvo without relying solely on expensive frontier models.</details> | Hong Je-Gal et.al. | Sejong University | arXiv.org | [2512.11270](http://arxiv.org/abs/2512.11270) | ‚Äî |
| 22/30 | **2025-11-20** | <details><summary>**An Agent-Based Framework for the Automatic Validation of Mathematical Optimization Models**</summary>Zadorojniy et al. introduce a multi-agent framework for validating LLM-generated optimization models by generating a test suite and verifying the suite's quality via mutation testing (ensuring tests detect deliberate errors injected into the model). On 100 NLP4LP instances, they achieve a 76% mutation kill ratio and successfully classify external models where simple objective value comparisons fail. The critical takeaway is the 'bootstrapped validation' workflow: using mutation analysis to validate the generated unit tests themselves before using them to score the model. We should steal this mutation-based verification loop to create a robust, ground-truth-free fitness signal for our evolutionary search and OR benchmarking pipelines.</details> | Alexander Zadorojniy et.al. | IBM Research | arXiv.org | [2511.16383](http://arxiv.org/abs/2511.16383) | ‚Äî |
| 9/30 | **2025-11-13** | <details><summary>**LM4Opt-RA: A Multi-Candidate LLM Framework with Structured Ranking for Automating Network Resource Allocation**</summary>Ahmed et al. propose a framework for translating natural language to LP/MILP formulations using three prompt variations (Direct, Few-shot, CoT) followed by a pairwise LLM ranking step. They introduce a small dataset (NL4RA, 50 instances) and an LLM-based evaluation metric (LAME) to replace BLEU/ROUGE. The methodology is elementary prompt engineering, and the dataset scale is too small to be useful for our large-scale VRP or scheduling work. The only minor takeaway is their confirmation that lexical metrics fail for OR formulations, validating the need for semantic evaluation, but their proposed solution is a standard LLM-judge wrapper.</details> | Tasnim Ahmed et.al. | Queen‚Äôs University | arXiv.org | [2512.00039](http://arxiv.org/abs/2512.00039) | ‚Äî |
| 11/30 | **2025-11-04** | <details><summary>**An LLM-powered MILP modelling engine for workforce scheduling guided by expert knowledge**</summary>Li et al. propose SMILO, a framework that restricts LLMs to extracting parameters into a manually defined 'Modelling Graph,' using deterministic templates to assemble MILP code for workforce scheduling. While they achieve 90% accuracy on a small custom dataset of 20 instances, the method is essentially a rigid expert system that sacrifices generalization for reliability. The primary takeaway is the detailed error analysis of GPT-4o on scheduling constraints (e.g., failing to infer implicit weekend rules), which we could incorporate into our OR-Bench failure taxonomy. However, the reliance on domain-specific manual graph construction makes this approach non-scalable for our automated discovery work.</details> | Qingyang Li et.al. | The University of Melbourne, Deakin University |  | [2511.02364](http://arxiv.org/abs/2511.02364) | ‚Äî |
| 23/30 | **2025-11-01** | <details><summary>**SOCRATES: Simulation Optimization with Correlated Replicas and Adaptive Trajectory Evaluations**</summary>SOCRATES introduces a two-stage framework: first constructing 'Operational AI Replicas' (surrogates) via LLM-guided causal discovery, then using an LLM to analyze optimization trajectories on these surrogates to schedule hybrid algorithms (e.g., running BO then switching to GA). While the benchmarks (inventory, queuing) are simple and the causal inference step seems fragile, the core innovation of **trajectory-based reasoning** is highly transferable. We can steal this mechanism for AlgoEvo: instead of blind evolution, our planner agent should consume the optimization trajectory to dynamically swap operators or restart populations when stagnation is detected, effectively using the LLM as a process reward model.</details> | Haoting Zhang et.al. | Columbia, UC Berkeley, Amazon | arXiv.org | [2511.00685](http://arxiv.org/abs/2511.00685) | ‚Äî |
| 25/30 | **2025-10-31** | <details><summary>**ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling**</summary>Wang et al. propose ORGEval, a framework that evaluates LLM-generated optimization models by converting them into bipartite graphs and using the Weisfeiler-Lehman (WL) test to detect isomorphism with a ground truth, rather than solving the instances. They prove that for 'symmetric decomposable' graphs, this method is guaranteed to detect equivalence correctly, achieving 100% consistency and running in seconds compared to hours for solver-based checks on hard MIPLIB instances. The critical takeaway is the shift from execution-based to **structural evaluation**: we can validate model logic via graph topology ($O(k(m+n)^2)$) without incurring the cost of solving NP-hard problems. This is immediately actionable for our OR benchmarking pipelines and could serve as a rapid 'pre-solve' filter in our evolutionary search loops to reject structurally invalid candidates instantly.</details> | Zhuohan Wang et.al. | The Chinese University of Hong Kong, Shenzhen, Shenzhen Research Institute of Big Data, Shenzhen International Center for Industrial and Applied Mathematics, Shenzhen Loop Area Institute | arXiv.org | [2510.27610](http://arxiv.org/abs/2510.27610) | ‚Äî |
| 25/30 | **2025-10-21** | <details><summary>**AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library**</summary>AlphaOPT introduces a 'Library Evolution' mechanism that iteratively refines the *applicability conditions* of cached optimization insights based on solver feedback, allowing it to learn from answers alone (no gold programs). On OOD benchmarks like OptiBench, it beats fine-tuned models (ORLM) by ~13% and shows consistent scaling with data size. **Key Takeaway:** The specific mechanism of diagnosing 'unretrieved' vs. 'negative' tasks to rewrite retrieval triggers is a transferable technique for our AlgoEvo memory; it solves the problem of heuristic misapplication in long-term search. We should implement this 'condition refinement' loop immediately to improve our multi-agent memory systems.</details> | Minwei Kong et.al. | Massachusetts Institute of Technology, London School of Economics and Political Science, University of Florida, Northeastern University, Singapore Management University, Singapore-MIT Alliance for Research and Technology | arXiv.org | [2510.18428](http://arxiv.org/abs/2510.18428) | **[link](https://github.com/Minw913/AlphaOPT)** |
| 23/30 | **2025-10-19** | <details><summary>**SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search**</summary>SolverLLM frames optimization problem formulation as a hierarchical Monte Carlo Tree Search (MCTS), decomposing the task into six layers (variables, constraints, etc.) and using test-time compute to beat fine-tuned baselines like LLMOPT. The results appear robust, showing ~10% gains on complex datasets, though inference cost is high. **The critical takeaway for us is the 'Prompt Backpropagation' mechanism:** instead of just updating numerical values, they propagate textual error analysis from leaf nodes back up the tree to dynamically modify the prompts of parent nodes, effectively creating 'short-term memory' for the search. We should immediately test this technique in AlgoEvo to prevent the recurrence of failed code patterns during mutation steps. Additionally, their use of semantic entropy to down-weight uncertain rewards in MCTS is a practical solution to the noisy evaluation problem we face in process reward models.</details> | Dong Li et.al. | NEC Labs America, Baylor University, University of Texas at Dallas, Augusta University, Southern Illinois University | arXiv.org | [2510.16916](http://arxiv.org/abs/2510.16916) | ‚Äî |
| 22/30 | **2025-10-12** | <details><summary>**LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems**</summary>LinearizeLLM is a multi-agent framework that converts LaTeX nonlinear optimization problems into exact MILP formulations by detecting nonlinear terms and processing them bottom-up based on nesting depth. On 40 benchmark instances, it achieves 73% end-to-end success compared to <15% for one-shot LLMs and Pyomo baselines, demonstrating that structural decomposition is essential for handling complex nested terms. The key takeaway is the 'Structural Policy': rather than letting the LLM plan the reformulation order, they enforce a deterministic bottom-up traversal (linearizing children before parents). We should steal this hybrid approach‚Äîusing deterministic graph traversal to orchestrate LLM manipulation steps‚Äîto improve reliability in our symbolic modeling and EvoCut pipelines.</details> | Paul-Niklas Ken Kandora et.al. | Karlsruhe Institute of Technology, Reutlingen University | arXiv.org | [2510.15969](http://arxiv.org/abs/2510.15969) | ‚Äî |
| 25/30 | **2025-10-05** | <details><summary>**CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling**</summary>Tang et al. propose CALM, a framework that uses an expert 'Intervener' model to inject corrective hints into a small LRM's reasoning trace (e.g., forcing it to use Python instead of manual calculation), followed by SFT and RL (GRPO). Results are strong and verified: a 4B model matches DeepSeek-R1 (671B) on OR benchmarks, specifically fixing the 'Code Utilization Distrust' we see in our own agents. The key takeaway is the 'Intervener' loop: instead of discarding failed traces, they repair them with hints to create a 'golden' reasoning dataset that preserves the 'thinking' process while enforcing tool use. This is a direct, actionable method for improving our AlgoEvo agents' reliability in generating executable heuristics without massive human annotation.</details> | Zhengyang Tang et.al. | Qwen Team, Alibaba Inc., The Chinese University of Hong Kong, Shenzhen, Southern University of Science and Technology, Shanghai University of Finance and Economics, Shenzhen Loop Area Institute (SLAI) | arXiv.org | [2510.04204](http://arxiv.org/abs/2510.04204) | **[link](https://github.com/tangzhy/STORM)** |
| 20/30 | **2025-10-03** | <details><summary>**Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation**</summary>This paper proposes a constraint-centric architecture that translates natural language manufacturing descriptions into Job Shop Scheduling (JSP) constraints by mediating through a learned Domain-Specific Language (DSL). Unlike standard prompting, they implement an automated DSL adaptation algorithm using non-parametric modeling (DPMM) and Expectation-Maximization to learn the syntax and semantics of the intermediate representation from data, which is then verified via a Pushdown Automaton. While the experiments rely on synthetic data augmented from standard benchmarks (a weakness), the methodology for **automatically deriving the intermediate representation** rather than hand-coding it is a transferable insight. We could steal this 'automated DSL design' approach to dynamically construct search spaces for AlgoEvo or to improve the robustness of NL-to-OR translation in OR-Bench.</details> | Yu-Zhe Shi et.al. | Peking University, The Hong Kong University of Science and Technology, Huazhong University of Science and Technology, University of Science and Technology of China | IEEE Transactions on Automation Science and Engineering | [2510.02679](http://arxiv.org/abs/2510.02679) | **[link](null)** |
| 10/30 | **2025-09-29** | <details><summary>**Graph Foundation Models: Bridging Language Model Paradigms and Graph Optimization**</summary>The authors propose training a BERT-style Transformer on random walks from a specific graph to learn its topology, subsequently using this 'prior' to generate solutions for routing problems (TSP, Shortest Path) on that same graph. While they claim this is a 'Foundation Model,' the methodology appears to require retraining for every new map (e.g., separate models for Chengdu vs. Berkeley), rendering it a glorified, expensive map index rather than a generalizable solver. The only potentially transferable insight is the 'insertion-based reconstruction' curriculum for learning path connectivity, but the lack of cross-graph generalization makes this irrelevant for our dynamic VRP work.</details> | Yunhao Liang et.al. | University of California, Berkeley, The University of Hong Kong, Shenzhen Institute of Research and Innovation | arXiv.org | [2509.24256](http://arxiv.org/abs/2509.24256) | **[link](https://github.com/jettbrains/-L-)** |
| 21/30 | **2025-09-28** | <details><summary>**SAC-Opt: Semantic Anchors for Iterative Correction in Optimization Modeling**</summary>SAC-Opt introduces a verification loop where generated Gurobi code is back-translated into natural language ('semantic anchors') to check for alignment with the original problem description. Empirical results are strong, demonstrating a ~22% accuracy improvement on the ComplexLP dataset over OptiMUS-0.3 by catching logic errors that solver feedback misses. The primary takeaway is the utility of granular, constraint-level back-translation as a process reward signal, which we should adopt to improve the reliability of our automated modeling agents.</details> | Yansen Zhang et.al. | Huawei Noah‚Äôs Ark Lab, Huawei‚Äôs Supply Chain Management Department, City University of Hong Kong |  | [2510.05115](http://arxiv.org/abs/2510.05115) | **[link](https://github.com/Forrest-Stone/SAC-Opt)** |
| 26/30 | **2025-09-26** | <details><summary>**StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models**</summary>Zhou et al. propose StepORLM, a framework where an 8B policy and a **Generative Process Reward Model (GenPRM)** co-evolve. Unlike standard discriminative PRMs that score steps in isolation, their GenPRM generates a reasoning trace to evaluate the full trajectory's logic before assigning credit, addressing the interdependency of OR constraints. They align the policy using **Weighted DPO**, where preference weights are derived from the GenPRM's process scores. They claim to beat GPT-4o and DeepSeek-V3 on 6 OR benchmarks (e.g., NL4Opt, MAMO) with an 8B model. **Key Takeaway:** We should test **Generative PRMs** immediately for AlgoEvo; asking the critic to 'explain then score' (generative) rather than just 'score' (discriminative) likely fixes the credit assignment noise in our long-horizon search.</details> | Chenyu Zhou et.al. | Shanghai Jiao Tong University | arXiv.org | [2509.22558](http://arxiv.org/abs/2509.22558) | ‚Äî |
| 21/30 | **2025-09-26** | <details><summary>**OptiMind: Teaching LLMs to Think Like Optimization Experts**</summary>The authors fine-tune a 20B model for MILP formulation, but the critical contribution is a rigorous audit of standard benchmarks (IndustryOR, OptMATH), revealing that 30-50% of instances are flawed (missing data, wrong ground truth, infeasible). They introduce a 'class-based error analysis' where the model classifies a problem (e.g., TSP) and retrieves specific, expert-written hints to avoid common pitfalls, boosting accuracy by ~20%. **Takeaway:** We must immediately replace our benchmark versions with their cleaned sets for the OR-Bench project. Additionally, their library of 'error hints' per problem class is a high-value artifact we can scrape and inject into AlgoEvo's prompt templates to improve initial population quality.</details> | Zeyi Chen et.al. | Microsoft Research, Stanford University, University of Washington | arXiv.org | [2509.22979](http://arxiv.org/abs/2509.22979) | ‚Äî |
| 13/30 | **2025-09-24** | <details><summary>**OR-Toolformer: Modeling and Solving Operations Research Problems with Tool Augmented Large Language Models**</summary>The authors fine-tune Llama-3-8B to translate natural language OR problems into solver API calls using a synthetic dataset generated by Gemini. While they outperform baselines on simple tasks, the model collapses on complex industry problems (14% accuracy), confirming that basic SFT is insufficient for the scale of problems we target. The only useful takeaway is their data generation pipeline‚Äîsampling parameters first, then wrapping them in text to ensure ground-truth validity‚Äîwhich is a clean pattern we could adapt for generating grounded test cases in OR-Bench. Overall, this is a competent but incremental engineering effort that does not advance the state of the art for complex optimization.</details> | Jianzhang Zhang et.al. | Alibaba Business School, Hangzhou Normal University | arXiv.org | [2510.01253](http://arxiv.org/abs/2510.01253) | **[link](https://figshare.com/s/262251a08ea7f79113d7)** |
| 21/30 | **2025-09-24** | <details><summary>**DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs**</summary>Zhu et al. propose DAOpt, a framework for modeling optimization under uncertainty that integrates LLMs with the RSOME library to handle robust and stochastic formulations. Their experiments on a new dataset (OptU) convincingly demonstrate that standard LLM-generated deterministic models suffer from the 'optimizer's curse,' achieving only ~27% out-of-sample feasibility, whereas their robust approach achieves >70%. The critical takeaway for us is to **stop asking LLMs to derive mathematical duals or robust counterparts**; instead, we should train them to use high-level DSLs (like RSOME) that handle the duality internally. This is an immediate action item for our RobustMAS project to ensure generated solutions are actually executable in stochastic environments.</details> | WenZhuo Zhu et.al. | Zhejiang University, University of Toronto, Peking University | arXiv.org | [2511.11576](http://arxiv.org/abs/2511.11576) | **[link](https://anonymous.4open.science/r/LLM-for-data-driven-optimization-problems-9528)** |
| 10/30 | **2025-09-21** | <details><summary>**Large Language Models as End-to-end Combinatorial Optimization Solvers**</summary>Jiang et al. fine-tune Qwen2.5-7B to directly output solution tours for TSP, CVRP, and scheduling problems (up to 100 nodes) using Supervised Fine-Tuning on solver traces followed by Group Relative Policy Optimization (GRPO) to enforce constraints. While they outperform general reasoning models like DeepSeek-R1 and claim to beat Gurobi under strict 11s time limits, the method is an inefficient form of imitation learning that fails to scale or match the specialized heuristics it mimics. The only technical nugget is their specific reward shaping for GRPO to balance feasibility and optimality, but this does not redeem the fundamental flaw of using autoregressive text generation as a solver for large-scale OR. We should stick to evolving executable heuristics (AlgoEvo) rather than training LLMs to be solvers.</details> | Xia Jiang et.al. | Eindhoven University of Technology, Singapore Management University | arXiv.org | [2509.16865](http://arxiv.org/abs/2509.16865) | **[link](https://github.com/Summer142857/LLMCoSolver)** |
| 8/30 | **2025-09-19** | <details><summary>**"It Was a Magical Box": Understanding Practitioner Workflows and Needs in Optimization**</summary>Lawless et al. interview 15 optimization practitioners to map the real-world OR workflow, finding that 'data processing' and 'problem elicitation' dominate the lifecycle, while actual solving is a small fraction. The results are purely qualitative and anecdotal. The only takeaway for our multi-agent work is a confirmation that automated OR agents must prioritize 'dialogue' (ambiguity resolution) and data cleaning over pure solver efficiency to be useful. Useful only as citation fodder to motivate why we work on ambiguity-grounded benchmarking.</details> | Connor Lawless et.al. | Stanford University, University of Groningen | arXiv.org | [2509.16402](http://arxiv.org/abs/2509.16402) | ‚Äî |
| 4/30 | **2025-09-18** | <details><summary>**Large Language Models in Operations Research: Methods, Applications, and Challenges**</summary>This survey classifies LLM-OR integration into three streams: automatic modeling, auxiliary optimization (heuristics), and direct solving. It presents no new results, functioning purely as a catalog of recent literature (2023-2025) such as FunSearch, AEL, and OptiMUS. The only tangible utility for us is the consolidated list of competitor benchmarks (e.g., IndustryOR, FrontierCO, CO-Bench) in Sections III.A.4 and III.B.3, which we should cross-reference to ensure our 'OR-Bench' coverage is complete. Otherwise, it contains no actionable insights for an expert team.</details> | Yang Wang et.al. | University of Chinese Academy of Sciences, Institute of Automation Chinese Academy of Sciences |  | [2509.18180](http://arxiv.org/abs/2509.18180) | **[link](https://github.com/Aryia-Behroziuan/Other-sources)** |
| 6/30 | **2025-09-10** | <details><summary>**A Systematic Survey on Large Language Models for Evolutionary Optimization: From Modeling to Solving**</summary>Zhang et al. present a systematic survey of LLMs in evolutionary optimization, proposing a taxonomy that splits the field into optimization modeling (text-to-math) and solving (direct optimizers vs. low/high-level algorithmic components). The paper aggregates existing literature like FunSearch, EoH, and OPRO, highlighting the limitations of LLMs as direct numerical optimizers and the promise of algorithm generation. For us, this is purely a bibliographic reference to ensure our own related work sections are complete; it contains no actionable technical insights.</details> | Yisong Zhang et.al. |  | arXiv.org | [2509.08269](http://arxiv.org/abs/2509.08269) | ‚Äî |
| 19/30 | **2025-09-10** | <details><summary>**Gala: Global LLM Agents for Text-to-Model Translation**</summary>GALA decomposes text-to-MiniZinc translation into a multi-agent system where specialized agents detect specific Constraint Programming global constraints (e.g., all_different, cumulative) before an assembler unifies them. Results on 110 TEXT2ZINC instances show a modest improvement over CoT (57% vs 52% execution rate with o3-mini), though the sample size is small and lacks statistical rigor. The key takeaway is the architectural shift from generic 'coder/reviewer' roles to 'primitive-specific' agents, which aligns LLM reasoning with the target formalism's structure. We should test this 'primitive-based decomposition' in our OR-Bench pipeline to see if it reduces hallucination of complex constraints better than our current methods.</details> | Junyang Cai et.al. | University of Southern California, Brown University, Fidelity Investments |  | [2509.08970](http://arxiv.org/abs/2509.08970) | ‚Äî |
| 14/30 | **2025-09-09** | <details><summary>**PersonaFuse: A Personality Activation-Driven Framework for Enhancing Human-LLM Interactions**</summary>Tang et al. introduce a Mixture-of-Experts (MoE) framework where a 'Situation-Aware Router' dynamically activates specific LoRA adapters based on input context, trained via a contrastive objective to align queries with expert embeddings. While they apply this to personality adaptation, the architecture is effectively a learnable hyper-heuristic: it maps context to specific behavioral modes without catastrophic forgetting (improving GPQA by 9.7%). We should steal the **router design and contrastive training pipeline** to build a 'Heuristic-MoE' for our VRP solvers, replacing their 'personality experts' with our 'search operators' (e.g., specific destroy/repair heuristics) to dynamically adapt optimization strategies per instance.</details> | Yixuan Tang et.al. | The Hong Kong University of Science and Technology, University of Notre Dame | arXiv.org | [2509.07370](http://arxiv.org/abs/2509.07370) | ‚Äî |
| 10/30 | **2025-08-27** | <details><summary>**LLM-QUBO: An End-to-End Framework for Automated QUBO Transformation from Natural Language Problem Descriptions**</summary>Zhang et al. propose a framework using Qwen3-8B to translate natural language optimization problems into MILP and subsequently into QUBO formats, utilizing Benders decomposition for scaling. They claim a 38% runtime reduction over Gurobi on large-scale Capacitated Facility Location Problems (CFLP), though this benefit likely stems from the classical Benders method rather than the LLM integration. The most interesting aspect is the attempt to automate the 'constraint-to-penalty' tuning for QUBO, but the system's failure to correctly formulate TSP (producing non-quadratic terms) reveals significant fragility. This is a proof-of-concept integration of LLMs as compilers for Quantum Annealers; it offers no new evolutionary search or learning-based insights relevant to our research.</details> | Huixiang Zhang et.al. | Lakehead University, Memorial University of Newfoundland, Queen's University | Proceedings of the AAAI Symposium Series | [2509.00099](http://arxiv.org/abs/2509.00099) | ‚Äî |
| 12/30 | **2025-08-25** | <details><summary>**Teaching LLMs to Think Mathematically: A Critical Study of Decision-Making via Optimization**</summary>This paper surveys 54 studies on LLMs for optimization and benchmarks GPT-4o vs. DeepSeek Math on 10 small-scale network problems using standard prompting (CoT, Act-as-Expert). The experiments confirm GPT-4o's superiority but rely on trivial instances that do not reflect the large-scale complexity of our VRP or scheduling work. The most useful takeaway is the conceptual proposal of 'Chain of RAGs'‚Äîiteratively retrieving context for variables, then constraints, then objectives‚Äîwhich could structure our agentic workflows, though the paper offers no empirical validation for it. Overall, it is a competent survey but offers no actionable algorithmic innovations for our evolutionary search focus.</details> | Mohammad J. Abdel-Rahman et.al. | Virginia Tech, King Fahd University of Petroleum and Minerals, Princess Sumaya University for Technology | arXiv.org | [2508.18091](http://arxiv.org/abs/2508.18091) | ‚Äî |
| 13/30 | **2025-08-24** | <details><summary>**Large Language Model-Based Automatic Formulation for Stochastic Optimization Models**</summary>This paper benchmarks GPT-4's ability to formulate Stochastic Optimization models (SMILP-2, chance-constrained) from natural language, proposing a 'soft scoring' metric to evaluate structural correctness when code fails to execute. The empirical results are negative‚Äîachieving 0% perfect execution accuracy on their dataset‚Äîdemonstrating that current LLMs struggle significantly with the recourse logic in stochastic programming. For us, the value lies solely in the evaluation methodology: their algebraic equivalence scoring and the curated dataset of SO problems could be integrated into our OR-Bench pipeline to better quantify partial failures in symbolic modeling.</details> | Amirreza Talebi et.al. | The Ohio State University | arXiv.org | [2508.17200](http://arxiv.org/abs/2508.17200) | **[link](https://github.com/Amirreza-96/LLM-SO-manuscript)** |
| 9/30 | **2025-08-22** | <details><summary>**Cooperative Design Optimization through Natural Language Interaction**</summary>This paper integrates LLMs into Batch Bayesian Optimization by having the LLM select one candidate from a batch of 8 (generated by qLogNEHVI) based on user natural language constraints, subsequently explaining the choice. The authors validate this via user studies on synthetic quadratic functions, showing it reduces cognitive load compared to manual controls but underperforms pure BO on optimization metrics. The primary takeaway is the architectural pattern of 'Generate Batch via Traditional Solver -> Filter/Select via LLM,' which allows injecting qualitative human intent without modifying the underlying search algorithm. However, this is a basic interface wrapper rather than a fundamental search improvement, making it irrelevant for our large-scale combinatorial and code-evolution work.</details> | Ryogo Niwa et.al. | OMRON SINIC X Corporation, National Institute of Advanced Industrial Science and Technology (AIST), The University of Tokyo, The University of Tsukuba | ACM Symposium on User Interface Software and Technology | [2508.16077](http://arxiv.org/abs/2508.16077) | ‚Äî |
| 14/30 | **2025-08-21** | <details><summary>**R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling**</summary>Jain and Wetter introduce R-ConstraintBench, a synthetic generator for RCPSP instances that isolates failure modes by incrementally adding downtime, temporal, and disjunctive constraints. They demonstrate via CP-SAT verification that even strong models (GPT-5, o3) collapse when constraints interact, despite handling pure precedence well. **Takeaway:** The paper confirms direct prompting is insufficient for hard scheduling; we should steal their instance generation pipeline to create a graded curriculum for AlgoEvo, using their high-failure regimes (disjunctive constraints) to validate our multi-agent search improvements.</details> | Raj Jain et.al. | Labelbox | arXiv.org | [2508.15204](http://arxiv.org/abs/2508.15204) | **[link](null)** |
| 17/30 | **2025-08-20** | <details><summary>**Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning**</summary>Yang et al. propose ORThought, a structured Chain-of-Thought framework with a code repair loop to translate natural language into Gurobi models, and introduce a new benchmark, LogiOR. They demonstrate that this single-agent approach outperforms multi-agent baselines (like Chain-of-Experts) while using significantly fewer tokens. The methodological novelty is low (prompt engineering + reflexion), but the **LogiOR dataset** and their **cleaned annotations for NLP4LP** are immediate assets for our OR-Bench evaluation pipeline. We should incorporate their datasets to test our own modeling agents and use their results as a baseline to justify whether our multi-agent approaches are actually necessary.</details> | Beinuo Yang et.al. | Zhejiang University, Singapore-MIT Alliance for Research and Technology (SMART), Link.AI, Minimal Future Tech., Hong Kong | arXiv.org | [2508.14410](http://arxiv.org/abs/2508.14410) | **[link](https://github.com/BeinuoYang/ORThought)** |
| 22/30 | **2025-08-20** | <details><summary>**Adaptively Robust LLM Inference Optimization under Prediction Uncertainty**</summary>Chen et al. propose $A_{min}$, an online scheduling algorithm for LLM inference that handles unknown output lengths by optimistically assuming the lower bound and evicting jobs (based on accumulated length) if memory overflows. They prove a logarithmic competitive ratio and show via simulations on LMSYS-Chat-1M that this approach nearly matches hindsight-optimal scheduling, vastly outperforming conservative upper-bound baselines. **Key Takeaway:** For our **GPUSched** project, we should abandon conservative memory reservation for output tokens; instead, implement an optimistic scheduler that oversubscribes memory and handles overflows via their ordered eviction policy, as the cost of restart is theoretically bounded and empirically negligible compared to the throughput gains.</details> | Zixi Chen et.al. | Stanford University, Peking University, HKUST | arXiv.org | [2508.14544](http://arxiv.org/abs/2508.14544) | ‚Äî |
| 28/30 | **2025-08-16** | <details><summary>**EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models**</summary>Yazdani et al. introduce EvoCut, an evolutionary framework where LLMs generate Python code for MILP cuts, filtered by a 'usefulness check' (does it cut the current LP relaxation?) and an 'empirical validity check' (does it preserve known integer optima?). They report 17-57% gap reductions on TSPLIB and JSSP compared to Gurobi defaults, backed by strong ablation studies on the evolutionary operators. **Key Takeaway:** The reliance on 'acceleration cuts'‚Äîconstraints verified empirically on small datasets rather than formally proven‚Äîbypasses the bottleneck of automated theorem proving while still delivering valid speedups. We should immediately adopt their 'LP separation' check as a cheap, high-signal reward for our own evolutionary search loops.</details> | M. Yazdani et.al. | Huawei Technologies Canada, University of British Columbia, University of Toronto | arXiv.org | [2508.11850](http://arxiv.org/abs/2508.11850) | **[link](https://github.com/milad1378yz/EvoCut)** |
| 21/30 | **2025-08-10** | <details><summary>**CP-Agent: Agentic Constraint Programming**</summary>Szeider implements a standard ReAct agent with a persistent IPython kernel to iteratively generate and refine CPMpy models, claiming 100% accuracy on CP-Bench. However, this perfect score is achieved on a *modified* version of the benchmark where the author manually fixed 31 ambiguous problem statements and 19 ground-truth errors‚Äîmaking the '100%' result an artifact of dataset cleaning rather than pure model capability. The most actionable takeaways are the negative result for explicit 'task management' tools (which hurt performance on hard problems) and the effectiveness of a minimal (<50 lines) domain prompt over complex scaffolding. We should review their clarified benchmark for our OR-Bench work.</details> | Stefan Szeider et.al. | TU Wien | arXiv.org | [2508.07468](http://arxiv.org/abs/2508.07468) | **[link](https://github.com/szeider/agentic-python-coder)** |
| 20/30 | **2025-08-05** | <details><summary>**Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation**</summary>Lima et al. introduce a pipeline to generate synthetic optimization datasets by starting with symbolic MILP instances (ground truth) and using LLMs to generate natural language descriptions, ensuring full verifiability. They fine-tune a small model (Granite 8B) that beats GPT-4 on 6/7 benchmarks, largely due to a 'majority vote' mechanism where the agent generates code in 5 different modeling languages (Pyomo, Gurobi, etc.) and checks for result consistency. **Takeaway:** We should steal the multi-language execution voting to boost robustness in our code generation agents. Furthermore, their reverse-generation (Symbolic $\to$ NL) strategy is the correct approach for generating infinite, error-free test cases for our OR-Bench work.</details> | Vinicius Lima et.al. | IBM Research AI | arXiv.org | [2508.03117](http://arxiv.org/abs/2508.03117) | ‚Äî |
| 4/30 | **2025-07-23** | <details><summary>**SMARTAPS: Tool-augmented LLMs for Operations Management**</summary>Yu et al. build a chat interface for Advanced Planning Systems using standard RAG to map natural language queries to pre-defined, manually written API tools. The results are purely qualitative (user feedback from internal deployment) with no quantitative benchmarks or baselines. There is no technical takeaway for us; the paper claims to support 'tool generation' in the abstract but admits in the text that all tools must be manually created by experts. This is a UI wrapper for existing solvers, not an advancement in AI-driven optimization.</details> | Timothy T. L. Yu et.al. | University of British Columbia, Huawei Technologies Canada, Huawei Cloud Computing Technologies | arXiv.org | [2507.17927](http://arxiv.org/abs/2507.17927) | ‚Äî |
| 20/30 | **2025-07-20** | <details><summary>**LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading**</summary>This paper proposes a neurosymbolic MARL framework for P2P energy trading where LLMs generate CVXPY optimization models to act as 'experts' for RL agents to imitate via Wasserstein distance. They introduce a 'Differential Attention' mechanism in the critic that subtracts attention maps to filter noise, enabling scalability to 100 agents where standard baselines fail. **Takeaway:** We should steal the Differential Attention architecture for our multi-agent critics to handle irrelevant interactions in large-scale optimization. The workflow of using LLMs to write the *solver* (generating reliable synthetic data) rather than the *solution* is a transferable strategy for bootstrapping RL in our OR domains.</details> | C. Lou et.al. | China Agricultural University, University of Glasgow, Guangdong University of Foreign Studies | arXiv.org | [2507.14995](http://arxiv.org/abs/2507.14995) | **[link](https://github.com/jzk0806/P2P-llm-supplementary)** |
| 23/30 | **2025-07-15** | <details><summary>**Auto-Formulating Dynamic Programming Problems with Large Language Models**</summary>Zhou et al. introduce DPLM, a 7B model fine-tuned to formulate Dynamic Programming models, achieving performance comparable to o1 on their new DP-Bench. Their key contribution is 'DualReflect,' a synthetic data pipeline that combines Forward Generation (Problem‚ÜíCode) for diversity with Backward Generation (Code‚ÜíProblem) for correctness. **Takeaway:** We should steal the Backward Generation approach for AlgoEvo: instead of relying on noisy forward generation, we can take valid heuristics/OR code (which we have in abundance) and reverse-engineer problem descriptions to create massive, verifiable synthetic datasets for fine-tuning our code generation models. The paper proves this method is superior for 'cold-starting' small models in data-scarce domains.</details> | Chenyu Zhou et.al. | University of Chicago, Cornell University, Shanghai Jiao Tong University, Shanghai University of Finance and Economics, Cardinal Operations | arXiv.org | [2507.11737](http://arxiv.org/abs/2507.11737) | ‚Äî |
| 25/30 | **2025-07-13** | <details><summary>**Fine-tuning Large Language Model for Automated Algorithm Design**</summary>Liu et al. introduce a fine-tuning pipeline for LLMs in automated algorithm design, utilizing a 'Diversity-Aware Rank-based' sampling strategy to construct DPO preference pairs from evolutionary search histories. By partitioning the population into ranked subsets and sampling pairs with a guaranteed quality gap (skipping adjacent tiers), they ensure training signals are both clear and diverse. Empirically, they show that a fine-tuned Llama-3.2-1B matches the performance of a base Llama-3.1-8B on ASP and CVRP tasks, effectively compressing the search capability into a much cheaper model. We should implement this sampling strategy to recycle our AlgoEvo run logs into specialized 'mutator' models, potentially allowing us to downscale to 1B/3B models for the inner search loop without losing quality.</details> | Fei Liu et.al. | City University of Hong Kong | arXiv.org | [2507.10614](http://arxiv.org/abs/2507.10614) | ‚Äî |
| 12/30 | **2025-06-30** | <details><summary>**Performance of LLMS on Stochastic Modeling Operations Research Problems: From Theory to Practice**</summary>Kumar et al. evaluate LLMs (o1, GPT-4o, Claude 3.5) on stochastic modeling proofs and simulation-optimization tasks (SimOpt), finding that while o1 excels at theoretical derivations (passing PhD qual exams), Claude 3.5 Sonnet generates better executable optimization code (spontaneously using binary search or differential evolution). The results highlight a critical failure mode: models implemented inconsistent simulation environments for complex problems (e.g., IronOre), rendering zero-shot results incomparable. The primary takeaway is that Claude 3.5 Sonnet appears to be a superior backend for code-based heuristic generation than o1, which defaults to naive grid search. We should consider incorporating their stochastic problem set into OR-Bench, but the paper offers no methodological advances for our evolutionary search frameworks.</details> | Akshit Kumar et.al. | Columbia University | Online World Conference on Soft Computing in Industrial Applications | [2506.23924](http://arxiv.org/abs/2506.23924) | **[link](https://github.com/AkshitKumar/simopt-llm-evals)** |
| 20/30 | **2025-06-09** | <details><summary>**REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models**</summary>Forni√©s-Tabuenca et al. propose REMoH, an LLM-driven evolutionary framework for multi-objective FJSSP that uses K-Means to cluster the population by objective performance before generating reflections. While their optimality gaps (~12%) trail behind state-of-the-art CP solvers (~1.5%), the ablation study confirms that their reflection mechanism significantly improves Pareto front diversity (Hypervolume). **The killer feature is the phenotypic clustering step:** instead of reflecting on a random or elitist subset, they group solutions by trade-offs (e.g., 'low makespan' vs 'balanced') to generate targeted prompts. We should implement this clustering-based context construction in AlgoEvo to improve diversity maintenance in multi-objective search without exploding token costs.</details> | Diego Forni'es-Tabuenca et.al. | Vicomtech Foundation, University of the Basque Country, Universidad EAFIT, HiTZ Basque Center for Language Technology | arXiv.org | [2506.07759](http://arxiv.org/abs/2506.07759) | ‚Äî |
| 21/30 | **2025-06-09** | <details><summary>**HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization**</summary>The authors introduce HeuriGym, a benchmark suite of 9 hard combinatorial optimization problems (including PDPTW, EDA scheduling, and routing) coupled with an agentic evaluation loop. Results are backed by extensive experiments showing that SOTA LLMs saturate at ~60% of expert performance and, significantly, that existing evolutionary frameworks (ReEvo, EoH) perform *worse* than simple prompting on these large-context tasks (300+ lines of code). The key takeaway is the failure mode of current evolutionary methods: they cannot handle the context fragmentation and feedback integration required for complex heuristic design. We should immediately adopt this benchmark to demonstrate AlgoEvo's superiority, as the current baselines are weak and the problem set aligns perfectly with our focus.</details> | Hongzheng Chen et.al. | Cornell University, Harvard University, NVIDIA | arXiv.org | [2506.07972](http://arxiv.org/abs/2506.07972) | **[link](https://github.com/cornell-zhang/heurigym)** |
| 20/30 | **2025-06-06** | <details><summary>**DCP-Bench-Open: Evaluating LLMs for Constraint Modelling of Discrete Combinatorial Problems**</summary>This paper introduces DCP-Bench-Open, a benchmark of 164 discrete combinatorial problems, to evaluate LLMs on translating natural language into constraint models (CPMpy, MiniZinc, OR-Tools). The results are rigorous and highlight a critical failure mode: LLMs overfit to the specific data values in the prompt's example instance, causing a ~30% performance drop when evaluated on hidden instances (Multi-Instance Accuracy). Crucially for our pipeline design, they find that Retrieval-Augmented In-Context Learning (RAICL) is ineffective or harmful compared to simply including library documentation in the system prompt. We should adopt their 'Multi-Instance Accuracy' metric immediately for OR-Bench and switch any MiniZinc generation efforts to Python-based frameworks like CPMpy or OR-Tools, which LLMs handle much better.</details> | Kostis Michailidis et.al. | KU Leuven, University of Western Macedonia | ECAI25) | [2506.06052](http://arxiv.org/abs/2506.06052) | **[link](https://github.com/kostis-init/CP-Bench)** |
| 17/30 | **2025-06-02** | <details><summary>**ORMind: A Cognitive-Inspired End-to-End Reasoning Framework for Operations Research**</summary>ORMind is a multi-agent framework for translating natural language OR problems into PuLP code, featuring a 'System 2 Reasoner' that debugs solutions by asking what constraint relaxations would make the current (invalid) solution optimal. They claim ~15% improvement over Chain-of-Experts on NL4Opt and their own ComplexOR dataset, though the latter contains only 37 instances, making the statistical significance questionable. The primary takeaway is the 'counterfactual' error message generation strategy‚Äîinverting the validation check to suggest specific constraint modifications‚Äîwhich we could adapt for better error signals in our code agents. This is directly relevant to our OR-Bench work but offers little for our core evolutionary search algorithms.</details> | Zhiyuan Wang et.al. | ETH Zurich, Tsinghua University, Sun Yat-sen University, Lenovo Research, Peng Cheng Laboratory | Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 6: Industry Track) | [2506.01326](http://arxiv.org/abs/2506.01326) | **[link](https://github.com/XiaoAI1989/ORMind)** |
| 18/30 | **2025-05-27** | <details><summary>**DualSchool: How Reliable are LLMs for Optimization Education?**</summary>This paper evaluates LLMs on Primal-to-Dual Conversion (P2DC), introducing a 'Canonical Graph Edit Distance' (CGED) to verify structural correctness while ignoring benign differences like variable ordering or slack conventions. Results show that even strong LLMs often fail (<50% accuracy) and, crucially, that standard execution-based evaluation (checking objective values) produces frequent false positives by missing errors in redundant constraints. The primary takeaway for us is the CGED methodology: a robust way to score symbolic OR model generation that captures structural validity better than execution alone, which we could steal for our benchmarking and evolutionary search fitness functions.</details> | Michael Klamkin et.al. | Georgia Institute of Technology | arXiv.org | [2505.21775](http://arxiv.org/abs/2505.21775) | ‚Äî |
| 8/30 | **2025-05-21** | <details><summary>**Collaborative Problem-Solving in an Optimization Game**</summary>The authors introduce a two-player cooperative TSP game with partial information (split edge weights) and a neurosymbolic agent that uses GPT-4 for dialogue and an exact solver for path planning. The agent parses partner messages to update a partial graph and calls the solver to generate the next move. However, the evaluation is restricted to 6-node graphs, which is computationally trivial and offers no evidence of scalability or robustness for real-world OR problems. While the 'split-knowledge' game setup conceptually aligns with our multi-agent debate interests, the methodology is rudimentary tool-use rather than a fundamental advance in MAS optimization.</details> | Isidora Jeknic et.al. | Saarland University | arXiv.org | [2505.15490](http://arxiv.org/abs/2505.15490) | **[link](https://github.com/coli-saar/collaborative-problem-solving)** |
| 26/30 | **2025-05-17** | <details><summary>**Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling**</summary>Chen et al. introduce SIRL, a framework for training LLMs to generate optimization models using Reinforcement Learning with Verifiable Rewards (RLVR) and a novel 'Partial KL' surrogate objective. By removing the KL penalty from the reasoning (CoT) section while retaining it for the code generation section, they balance exploration with syntactic stability, achieving SOTA on OptMATH and IndustryOR against OpenAI-o3 and DeepSeek-R1. The critical takeaway for us is the Partial KL strategy: it allows the model to 'think' freely outside the reference distribution while adhering to strict coding standards‚Äîa technique we should immediately test in AlgoEvo. Furthermore, their method of parsing .lp files to extract structural features (variable counts, constraint types) for 'instance-enhanced self-consistency' provides a much richer signal than our current binary success/failure metrics.</details> | Yitian Chen et.al. | Stanford University, Shanghai Jiao Tong University, The University of Hong Kong, Shanghai University of Finance and Economics, Cardinal Operations | arXiv.org | [2505.11792](http://arxiv.org/abs/2505.11792) | **[link](https://github.com/Cardinal-Operations/SIRL)** |
| 25/30 | **2025-05-15** | <details><summary>**Learning Virtual Machine Scheduling in Cloud Computing through Language Agents**</summary>Wu et al. introduce MiCo, a hierarchical framework that uses LLMs to evolve both a library of scenario-specific scheduling heuristics ('Options') and a master policy ('Composer') that dynamically switches between them based on system state. Tested on large-scale Huawei/Azure VM traces, it achieves a 96.9% competitive ratio against Gurobi, significantly outperforming Deep RL (SchedRL) by ~11% in dynamic scenarios. **Key Insight:** Instead of evolving a single robust heuristic (which often fails in non-stationary environments), explicitly evolve a *portfolio* of specialized heuristics and a separate *selector* function. This SMDP-based decomposition is a concrete architectural pattern we should adopt in AlgoEvo to handle diverse problem instances and non-stationary distributions effectively.</details> | Jiehao Wu et.al. | Shanghai Jiao Tong University, East China Normal University, Tongji University | arXiv.org | [2505.10117](http://arxiv.org/abs/2505.10117) | **[link](https://github.com/jettbrains/-L-)** |
| 20/30 | **2025-05-10** | <details><summary>**RideAgent: An LLM-Enhanced Optimization Framework for Automated Taxi Fleet Operations**</summary>RideAgent employs an LLM to analyze a small set of historical optimal solutions, identifying and fixing 'low-sensitivity' decision variables to shrink the MIP search space before handing it to Gurobi. The results are empirically solid, showing a ~50% time reduction with <2.5% optimality gap, outperforming standard cutting plane baselines on NYC taxi data. **Key Takeaway:** We should adapt their 'Small-Sample Guided Optimization' strategy‚Äîspecifically using LLMs to infer *variable fixing constraints* from elite archive solutions‚Äîto accelerate the inner solvers in our AlgoEvo and EvoCut pipelines. This offers a concrete, data-driven way to prune search spaces that complements our current evolutionary approaches.</details> | Xinyu Jiang et.al. | Tsinghua University, McGill University, George Washington University, JD Intelligent Cities Research, Beijing Technology and Business University |  | [2505.06608](http://arxiv.org/abs/2505.06608) | ‚Äî |
| 20/30 | **2025-05-07** | <details><summary>**Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows**</summary>Li et al. propose an 'Evolutionary Agentic Workflow' that combines LLMs (DeepSeek) with evolutionary search to automate algorithm design, demonstrating it on VM scheduling and ADMM parameter tuning. The empirical rigor is low; they compare against weak baselines (BestFit for bin packing, a 2000-era heuristic for ADMM) and frame it as a position paper. However, the application of LLM-evolution to discover symbolic mathematical update rules (for ADMM step sizes) rather than just procedural code is a concrete use case we should consider for our EvoCut work. This serves primarily as competitor intelligence‚Äîvalidating our AlgoEvo direction‚Äîrather than a source of novel methodology.</details> | Wenhao Li et.al. | University of Minnesota, Tongji University, East China Normal University | arXiv.org | [2505.04354](http://arxiv.org/abs/2505.04354) | ‚Äî |
| 14/30 | **2025-05-04** | <details><summary>**LLM-OptiRA: LLM-Driven Optimization of Resource Allocation for Non-Convex Problems in Wireless Communications**</summary>The authors propose LLM-OptiRA, a pipeline that uses GPT-4 to parse natural language wireless problems, explicitly identify non-convex terms, and rewrite them using standard convex approximations (e.g., SCA, SDR) before generating CVXPY code. They claim 80% success on a custom dataset of 100 small-scale problems, outperforming standard CoT. The results are likely real but limited to small instances where standard relaxations work well. The only useful takeaway for us is the explicit 'convexification' prompting step‚Äîasking the LLM to map specific non-convex mathematical terms to their convex surrogates‚Äîwhich could be a useful operator in an automated OR modeling agent, but the rest is standard engineering.</details> | Xinyue Peng et.al. | Southeast University, Zhejiang University, Purple Mountain Laboratories | arXiv.org | [2505.02091](http://arxiv.org/abs/2505.02091) | **[link](https://github.com/Tibbers0310/LLM-OptiRA)** |
| 18/30 | **2025-05-02** | <details><summary>**CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code**</summary>CHORUS introduces a RAG framework for generating Gurobi code that replaces standard code retrieval with a metadata-based approach, indexing code examples by generated keywords and summaries rather than raw syntax. On the NL4Opt-Code benchmark, this allows open-source models like Llama-3-70B to match GPT-4 performance (improving accuracy from ~23% to ~57%). The key takeaway for us is the effectiveness of 'metadata-augmented indexing'‚Äîbridging the semantic gap between natural language problem descriptions and rigid solver APIs by retrieving based on functional descriptions rather than code embeddings. We should apply this metadata indexing strategy to the code retrieval modules in our OR-Bench and AlgoEvo agents.</details> | Tasnim Ahmed et.al. | Queen's University | Learning and Intelligent Optimization | [2505.01485](http://arxiv.org/abs/2505.01485) | ‚Äî |
| 22/30 | **2025-04-23** | <details><summary>**OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents**</summary>OptimAI introduces a multi-agent framework for translating natural language to optimization models, featuring a 'plan-before-code' stage and a novel **UCB-based debug scheduler**. Instead of linearly debugging a single solution, it treats debugging as a multi-armed bandit problem, dynamically allocating compute to different solution strategies based on a 'Decider' score and exploration term. While the combinatorial results (TSP a280) are trivial, the bandit mechanism is a highly effective heuristic for search control. We should steal this UCB scheduling logic for AlgoEvo to prevent agents from wasting tokens debugging fundamentally flawed heuristics.</details> | Raghav Thind et.al. | University of Maryland at College Park | arXiv.org | [2504.16918](http://arxiv.org/abs/2504.16918) | ‚Äî |
| 20/30 | **2025-04-06** | <details><summary>**CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization**</summary>Sun et al. introduce CO-Bench, a suite of 36 diverse combinatorial optimization problems (packing, scheduling, routing) designed specifically to benchmark LLM agents in generating algorithms (code), not just solutions. They evaluate 9 frameworks (including FunSearch, ReEvo, AIDE), finding that FunSearch combined with reasoning models (o3-mini) yields the most robust performance, though agents still struggle significantly with strict feasibility constraints (valid solution rates often <60%). **Takeaway:** We should immediately integrate CO-Bench into our pipeline to benchmark AlgoEvo against ReEvo and FunSearch; this saves us months of data curation and provides a standardized metric to prove our method's superiority.</details> | Weiwei Sun et.al. | Carnegie Mellon University | arXiv.org | [2504.04310](http://arxiv.org/abs/2504.04310) | **[link](https://github.com/sunnweiwei/CO-Bench)** |
| 3/30 | **2025-03-27** | <details><summary>**From User Preferences to Optimization Constraints Using Large Language Models**</summary>Sanguinetti et al. evaluate standard LLMs (ChatGPT, LLaMAntino) on translating natural language to simple energy optimization constraints using zero/few-shot prompting. The study is statistically insignificant, relying on a pilot dataset of only 26 Italian utterances, and merely confirms that few-shot prompting improves adherence to output formats. There is no novel algorithmic contribution, and the problem complexity is far below our requirements for symbolic OR modeling or large-scale optimization. We learn nothing actionable from this work.</details> | Manuela Sanguinetti et.al. | University of Cagliari | arXiv.org | [2503.21360](http://arxiv.org/abs/2503.21360) | **[link](https://github.com/msang/nl-interface/tree/main/nl2optim)** |
| 11/30 | **2025-03-18** | <details><summary>**Fully Automated Generation of Combinatorial Optimisation Systems Using Large Language Models**</summary>Karapetyan proposes a framework where LLMs generate Python mutation operators for a Conditional Markov Chain Search (CMCS), which are then tuned via offline training. While the study validates that component-based generation outperforms monolithic LLM code generation, the absolute performance is poor (16.9% gap on TSP-500), proving this specific architecture is insufficient for high-performance optimization. The only potential utility for us is the released library of natural language problem descriptions, which could serve as auxiliary data for our OR-Bench project. The methodology itself is a regression from our current AlgoEvo capabilities.</details> | Daniel Karapetyan et.al. | University of Nottingham | arXiv.org | [2503.15556](http://arxiv.org/abs/2503.15556) | **[link](https://people.cs.nott.ac.uk/pszdk/problems_library.zip)** |
| 8/30 | **2025-03-13** | <details><summary>**OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problems with Reasoning LLM**</summary>Zhang et al. propose a basic three-stage agent (Math Modeling, Code Generation, Debugging) utilizing DeepSeek-R1 to solve Operations Research word problems. They introduce a small benchmark (BWOR, 82 textbook problems) where their approach succeeds, but strangely report that reasoning models (R1, GPT-o3) underperform standard models on established benchmarks like NL4OPT‚Äîa red flag suggesting prompting deficiencies. The 'agent' is merely a fixed prompt chain with a retry loop, offering no novel evolutionary search, memory, or process reward mechanisms relevant to our work. The benchmark is too small to be useful for our large-scale evaluation needs.</details> | Bowen Zhang et.al. | Shanghai Jiao Tong University, Nanyang Technological University, Ningbo Artificial Intelligence Institute |  | [2503.10009](http://arxiv.org/abs/2503.10009) | **[link](https://github.com/bwz96sco/or-llm-agent)** |
| 15/30 | **2025-02-22** | <details><summary>**Text2Zinc: A Cross-Domain Dataset for Modeling Optimization and Satisfaction Problems in MiniZinc**</summary>Singirikonda et al. introduce TEXT2ZINC, a dataset of 110 Natural Language-to-MiniZinc problems, and benchmark GPT-4 using Vanilla, CoT, and Compositional prompting. Their results are poor (max ~25% solution accuracy), confirming that off-the-shelf LLMs struggle significantly with MiniZinc syntax and logical translation. Crucially, they attempt using Knowledge Graphs as an intermediate representation, but report that it actually *reduced* solution accuracy compared to basic CoT‚Äîa valuable negative result for our symbolic modeling work. We should examine their dataset for inclusion in OR-Bench, but their prompting methods are rudimentary baselines we should easily outperform.</details> | Akash Singirikonda et.al. | Brown University, Fidelity Investments | arXiv.org | [2503.10642](http://arxiv.org/abs/2503.10642) | ‚Äî |
| 23/30 | **2025-02-20** | <details><summary>**EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations**</summary>Zhai et al. propose EquivaMap, a framework that evaluates whether two MILP formulations are equivalent by using an LLM to discover a linear mapping between their decision variables, which is then rigorously verified by a solver. Unlike 'execution accuracy' (which fails on unit scaling) or 'canonical accuracy' (which fails on variable permutation), they achieve 100% accuracy on a new dataset of equivalent formulations including cuts and slack variables. The core insight is replacing output comparison with a 'propose-mapping-and-verify' loop, effectively using the LLM to construct a proof of equivalence. We must adopt this methodology for the OR-Bench evaluation pipeline immediately, as it eliminates the false negatives currently plaguing our generation benchmarks.</details> | Haotian Zhai et.al. | Stanford University, The University of Texas at Austin | International Conference on Machine Learning | [2502.14760](http://arxiv.org/abs/2502.14760) | **[link](https://github.com/HumainLab/EquivaMap)** |
| 24/30 | **2025-02-16** | <details><summary>**OptMATH: A Scalable Bidirectional Data Synthesis Framework for Optimization Modeling**</summary>The authors introduce OptMATH, a framework for generating synthetic optimization datasets by creating mathematical instances from seed generators, back-translating them to natural language via LLMs, and validating the pairs using a solver-based rejection sampling loop (checking if the re-generated model yields the same optimal value). They demonstrate that a Qwen-32B model fine-tuned on this data beats GPT-4 on NL4Opt and MAMO benchmarks. The critical takeaway is the **solver-verified reverse generation pipeline**: we should immediately steal this workflow to populate OR-Bench and generate diverse, verified training environments for AlgoEvo, replacing manual curation with scalable synthesis.</details> | Hongliang Lu et.al. | Peking University | International Conference on Machine Learning | [2502.11102](http://arxiv.org/abs/2502.11102) | **[link](https://github.com/AuroraLHL/OptMATH)** |
| 13/30 | **2025-02-14** | <details><summary>**Decision Information Meets Large Language Models: The Future of Explainable Operations Research**</summary>This paper introduces EOR, a framework that uses LLMs to modify OR problem code based on user queries (e.g., adding constraints) and explains the impact on the solution. The core technical contribution is quantifying the 'Decision Information' by converting Linear Programs into bipartite graphs (variables vs. constraints) and calculating the Graph Edit Distance (GED) between the original and modified formulations. While the focus on explainability is tangential to our work, the method of using GED on bipartite LP representations is a stealable technique for measuring diversity or mutation magnitude in our evolutionary search populations (AlgoEvo).</details> | Yansen Zhang et.al. | Huawei Noah‚Äôs Ark Lab, City University of Hong Kong | International Conference on Learning Representations | [2502.09994](http://arxiv.org/abs/2502.09994) | **[link](https://github.com/Forrest-Stone/EOR)** |
| 12/30 | **2025-01-30** | <details><summary>**Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG Based Approach**</summary>This paper proposes 'MAG-RAG,' a multi-agent system that uses a manually constructed graph database (linking Problem Type ‚Üí System Model ‚Üí Formulation ‚Üí Algorithm) to retrieve context for formulating signal processing problems. The evaluation is weak, relying on subjective scoring by three scientists on only 10 problems, with no evidence that the generated formulations are executable or solvable. The only potential takeaway is the specific hierarchical schema for structuring RAG knowledge in mathematical domains, which might be a minor engineering reference for our symbolic modeling work. Otherwise, it lacks the rigor and algorithmic depth required for our evolutionary search focus.</details> | Tianpeng Pan et.al. | Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen | Cybersecurity and Cyberforensics Conference | [2501.18320](http://arxiv.org/abs/2501.18320) | **[link](https://github.com/advantages/MAG-RAG-for-SASP)** |
| 11/30 | **2025-01-14** | <details><summary>**OptiChat: Bridging Optimization Models and Practitioners with Large Language Models**</summary>OptiChat presents a multi-agent system that explains Pyomo optimization models to non-experts by routing queries to either predefined solver tools (for sensitivity/infeasibility) or code generation (for counterfactuals). They demonstrate that using specific solver hooks (like IIS detection or dual variable retrieval) significantly outperforms pure LLM code generation for diagnostic tasks. The most useful takeaway is their automated 'why-not' analysis pipeline, which translates user objections into temporary constraints (e.g., x >= 1) and re-solves the model to quantify the trade-off. However, the dataset is small (24 models), and the methodology is a standard application of agents without novel search mechanics relevant to our AlgoEvo or VRP work.</details> | Hao Chen et.al. | Purdue University | INFORMS Journal on Data Science | [2501.08406](http://arxiv.org/abs/2501.08406) | **[link](https://github.com/li-group/OptiChat.git)** |
| 14/30 | **2024-12-22** | <details><summary>**Evaluating LLM Reasoning in the Operations Research Domain with ORQA**</summary>Mostajabdaveh et al. introduce ORQA, a benchmark of 1,513 multiple-choice questions testing LLM ability to identify OR problem components (objectives, constraints, variables) from natural language. They report that Chain-of-Thought prompting frequently degrades performance compared to standard prompting‚Äîa counter-intuitive finding suggesting that explicit reasoning steps in OR often lead to hallucinations in current models. For our **OR-Bench** project, their taxonomy of modeling concepts (e.g., distinguishing 'set-defining elements' from 'parameters') provides a useful reference for structuring our evaluation criteria. However, the multiple-choice format is too low-fidelity to serve as a training signal for our code-generating evolutionary agents.</details> | Mahdi Mostajabdaveh et.al. | Huawei Technologies Canada, University of Toronto, University of British Columbia | arXiv.org | [2412.17874](http://arxiv.org/abs/2412.17874) | **[link](https://github.com/nl4opt/ORQA)** |
| 22/30 | **2024-11-26** | <details><summary>**BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving**</summary>Wang et al. propose BPP-Search, combining Beam Search, a Process Reward Model (PRM), and a final Pairwise Preference Model to generate LP/MIP models from natural language. While their new 'StructuredOR' dataset is small (38 test instances), it uniquely provides intermediate modeling labels (sets, parameters, variables) essential for training PRMs in this domain. The key takeaway is their finding that PRMs are effective for pruning but imprecise for final ranking; they solve this by adding a pairwise preference model at the leaf layer‚Äîa technique we should immediately steal to improve selection robustness in our MASPRM and evolutionary search pipelines. This is a competent execution of 'LLM + Search' applied specifically to our OR niche.</details> | Teng Wang et.al. | Huawei, The University of Hong Kong | Annual Meeting of the Association for Computational Linguistics | [2411.17404](http://arxiv.org/abs/2411.17404) | **[link](https://github.com/LLM4OR/StructuredOR)** |
| 25/30 | **2024-11-03** | <details><summary>**Autoformulation of Mathematical Optimization Models Using LLMs**</summary>Astorga et al. frame optimization modeling as a hierarchical Monte-Carlo Tree Search (MCTS) problem, using LLMs to generate components and‚Äîcrucially‚Äîemploying SMT solvers to prune mathematically equivalent branches (e.g., recognizing `x+y` and `y+x` as identical). They achieve SOTA results on NL4OPT and IndustryOR, outperforming fine-tuned models like ORLM while using significantly fewer samples than naive approaches. **Key Takeaway:** The integration of symbolic equivalence checking (SMT) to prune the search tree is a technique we should immediately steal; implementing this in AlgoEvo would allow us to discard functionally identical code/math mutants before expensive evaluation, directly addressing our sample efficiency bottleneck.</details> | Nicol√°s Astorga et.al. | University of Cambridge, University of Hawaii at Manoa | ICML | [2411.01679](http://arxiv.org/abs/2411.01679) | **[link](https://github.com/jumpynitro/AutoFormulator)** |
| 22/30 | **2024-10-29** | <details><summary>**Generalists vs. Specialists: Evaluating LLMs on Highly-Constrained Biophysical Sequence Optimization Tasks**</summary>The authors propose LLOME, a bilevel optimization framework that fine-tunes an LLM using 'MargE' (Margin-Aligned Expectation), a loss function that weights gradient updates by the magnitude of reward improvement (margin) rather than simple preference rankings. Results are rigorous and demonstrate that while DPO leads to generator collapse and infeasibility in constrained spaces, MargE maintains diversity and significantly improves sample efficiency, matching specialized solvers like LaMBO-2 on medium-difficulty tasks. The critical takeaway is that standard alignment methods (DPO/RLHF) are ill-suited for optimization because they discard information about *how much* better a solution is; MargE fixes this by satisfying the Strong Interpolation Criteria. We should immediately evaluate replacing the RL/update component in AlgoEvo with the MargE objective to improve the stability and quality of our evolved heuristics.</details> | Angelica Chen et.al. | Genentech, New York University | International Conference on Machine Learning | [2410.22296](http://arxiv.org/abs/2410.22296) | ‚Äî |
| 9/30 | **2024-10-28** | <details><summary>**Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms**</summary>This paper reviews the intersection of LLMs and Evolutionary Algorithms, proposing a generalized 'LLM-EA paradigm' that formalizes the standard loop of selection, LLM-based variation, and reflection. It categorizes individual representations into code-centric, hybrid, and 'augmented' (injecting domain concepts into prompts), but provides no new benchmarks or empirical validation. The work is primarily a literature review and conceptual framework; for a team already developing AlgoEvo and familiar with FunSearch/LMEA, it contains no actionable novelties.</details> | He Yu et.al. | Xidian University, Guangzhou Institute of Technology | arXiv.org | [2410.20848](http://arxiv.org/abs/2410.20848) | ‚Äî |
| 13/30 | **2024-10-23** | <details><summary>**AutoRNet: Automatically Optimizing Heuristics for Robust Network Design via Large Language Models**</summary>AutoRNet combines LLMs with evolutionary algorithms to generate Python heuristics for robust network design, utilizing an adaptive fitness function to handle hard constraints (degree distribution). While the authors incorrectly claim novelty over FunSearch by arguing they generate 'complete algorithms' (FunSearch also does this), their specific contribution of **NOS-based variation** is valuable: they randomly inject domain-specific strategies (e.g., 'prioritize high-degree nodes') into prompts to guide the LLM's mutation steps. This strategy-guided mutation is a simple, effective mechanism to force exploration and prevent mode collapse that we should replicate in AlgoEvo for VRP heuristics. Results are positive against basic baselines (SA, HC) on graphs up to 1,500 nodes, though the baselines are relatively weak.</details> | He Yu et.al. | Xidian University | arXiv.org | [2410.17656](http://arxiv.org/abs/2410.17656) | **[link](null)** |
| 18/30 | **2024-10-17** | <details><summary>**LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch**</summary>The authors fine-tune Qwen1.5-14B to translate natural language optimization problems into Pyomo code via a structured 'five-element' intermediate representation (Sets, Parameters, Variables, Objective, Constraints) and KTO alignment. They achieve ~11% accuracy gains over GPT-4o and ORLM on benchmarks like NL4Opt and IndustryOR, primarily by reducing formulation hallucinations through the structured intermediate step and preference optimization. For our OR-Bench work, the key takeaway is the concrete recipe for using KTO to align symbolic modeling agents, which appears more effective than standard SFT for enforcing constraints in smaller models. While not an evolutionary search paper, it provides a strong, locally runnable baseline for our OR modeling evaluations.</details> | Caigao Jiang et.al. | Ant Group, East China Normal University, Nanjing University | International Conference on Learning Representations | [2410.13213](http://arxiv.org/abs/2410.13213) | **[link](https://github.com/caigaojiang/LLMOPT)** |
| 13/30 | **2024-10-11** | <details><summary>**A Systematic Survey on Large Language Models for Algorithm Design**</summary>A systematic survey of over 180 papers on LLM-based algorithm design, proposing a taxonomy that categorizes LLMs as Optimizers, Predictors, Extractors, or Designers. It aggregates key literature relevant to our AlphaEvolve and AlgoEvo tracks, specifically highlighting the 'LLM as Designer' paradigm (FunSearch, EoH) which aligns with our code generation approach. There is no methodological novelty here, but the categorization provides a useful framework for positioning our papers. The team should review the 'Challenges' and 'Applications' sections to identify any overlooked baselines in combinatorial optimization and NAS.</details> | Fei Liu et.al. | Huawei Noah‚Äôs Ark Lab, Huawei Cloud EI Service Product Dept., City University of Hong Kong, Southern University of Science and Technology, Xi‚Äôan Jiaotong University | ACM Computing Surveys | [2410.14716](http://arxiv.org/abs/2410.14716) | **[link](https://github.com/FeiLiu36/LLM4AlgorithmDesign)** |
| 5/30 | **2024-09-03** | <details><summary>**Leveraging Large Language Models for Solving Rare MIP Challenges**</summary>Wang et al. fine-tune LLaMA-3.1 to directly output binary decision variables for ride-pooling MIPs, employing a 'recursive dynamic temperature' (annealing) strategy to refine solutions. They claim to outperform Gurobi's initial feasible solutions, but the results are unconvincing as they ignore standard heuristics (like ALNS) and Gurobi's rapid improvement over time. The method offers no novelty for our evolutionary search work; the temperature annealing (1.0 -> 0.01) is a trivial heuristic that does not justify the cost of fine-tuning for combinatorial problems.</details> | Teng Wang et.al. | Huawei, University of Hong Kong | arXiv.org | [2409.04464](http://arxiv.org/abs/2409.04464) | ‚Äî |
| 20/30 | **2024-08-01** | <details><summary>**A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions**</summary>This survey and empirical audit reveals that standard optimization modeling benchmarks (NL4Opt, IndustryOR) suffer from critical error rates ranging from 16% to 54%, rendering prior leaderboards unreliable. The authors manually cleaned these datasets and re-evaluated methods, finding that Chain-of-Thought (CoT) often degrades performance compared to standard prompting, while fine-tuned models (ORLM) and multi-agent systems (Chain-of-Experts) perform best. The immediate takeaway is that we must adopt their cleaned datasets for our OR-Bench project; using the original open-source versions is no longer defensible. Additionally, the failure of CoT on these tasks suggests we should prioritize multi-agent or fine-tuned approaches for symbolic formulation tasks.</details> | Ziyang Xiao et.al. | Zhejiang University, Huawei Noah‚Äôs Ark Lab, Singapore University of Social Sciences, Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security | International Joint Conference on Artificial Intelligence | [2508.10047](http://arxiv.org/abs/2508.10047) | **[link](https://llm4or.github.io/LLM4OR)** |
| 23/30 | **2024-07-29** | <details><summary>**OptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale**</summary>OptiMUS-0.3 is a modular multi-agent system that translates natural language into Gurobi code, utilizing a 'connection graph' to manage variable-constraint relationships in long contexts and specialized agents to detect solver-specific structures (SOS, indicators) or implement sifting. The results are rigorous, introducing a new hard benchmark (NLP4LP) where they outperform GPT-4o by ~40% and beat Chain-of-Experts. The most stealable insight is the 'Structure Detection Agent': instead of relying on the LLM to write generic constraints, we should explicitly prompt for and map high-level structures to efficient solver APIs (like SOS constraints) to improve performance in our EvoCut and AlgoEvo pipelines. This is a necessary read for the OR-Bench team.</details> | Ali AhmadiTeshnizi et.al. |  | arXiv.org | [2407.19633](http://arxiv.org/abs/2407.19633) | ‚Äî |
| 22/30 | **2024-07-13** | <details><summary>**OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling**</summary>The authors propose OptiBench, a benchmark of 605 optimization problems (linear/nonlinear, tabular/text), and ReSocratic, a data synthesis method that generates formal models first and back-translates them into natural language questions. Results are strong: fine-tuning Llama-3-8B on their 29k synthetic samples improves accuracy from 13.6% to 51.1%, validating the data quality. **Key Takeaway:** The 'Reverse Socratic' synthesis pipeline (Formal Model ‚Üí Code ‚Üí NL Question) is the superior strategy for generating synthetic OR datasets because it guarantees solvability and ground truth by construction, unlike forward generation. We should steal this pipeline for generating robust test instances for OR-Bench and potentially for training our OR agents.</details> | Zhicheng YANG et.al. | The Hong Kong University of Science and Technology, ETH Zurich, Huawei Noah‚Äôs Ark Lab, City University of Hong Kong, Sun Yat-sen University, MBZUAI, University of California Merced, Chongqing University | International Conference on Learning Representations | [2407.09887](http://arxiv.org/abs/2407.09887) | **[link](https://github.com/yangzhch6/ReSocratic)** |
| 11/30 | **2024-07-09** | <details><summary>**Solving General Natural-Language-Description Optimization Problems with Large Language Models**</summary>OptLLM introduces a framework that fine-tunes Qwen-50B (using LoRA) to convert natural language descriptions into MAPL (Alibaba's modeling language) code for external solvers. They claim to outperform GPT-4 on a custom dataset of 100 LP/MILP problems, though the complexity appears limited to textbook-level instances. The primary takeaway is the confirmation that SFT on synthetic data (15k samples) effectively enforces strict syntax adherence for less common modeling languages, but the methodology offers no novel search or reasoning mechanisms relevant to AlgoEvo.</details> | Jihai Zhang et.al. | Alibaba Group | North American Chapter of the Association for Computational Linguistics | [2407.07924](http://arxiv.org/abs/2407.07924) | ‚Äî |
| 15/30 | **2024-06-23** | <details><summary>**Efficient Evolutionary Search Over Chemical Space with Large Language Models**</summary>MOLLEO integrates LLMs (GPT-4, BioT5) into a standard genetic algorithm by replacing random crossover and mutation with prompt-based generation for molecular optimization. The authors show strong empirical results on PMO/TDC benchmarks, demonstrating that LLM-guided evolution improves sample efficiency over random baselines. The most useful takeaway is that a fine-tuned, domain-specific small model (BioT5) can perform competitively with GPT-4 as a genetic operator, validating the strategy of using specialized, cheaper models for evolutionary operators in our AlgoEvo pipeline. However, the method relies on simple prompt substitution and chemistry-specific pruning heuristics (Tanimoto distance) rather than a novel evolutionary architecture.</details> | Haorui Wang et.al. | MIT, Cornell University, University of Toronto, Georgia Institute of Technology, University of California, Los Angeles, Universit√© de Montr√©al, Vector Institute, Mila - Quebec AI Institute, University of Wuppertal, Deep Principle Inc. | International Conference on Learning Representations | [2406.16976](http://arxiv.org/abs/2406.16976) | **[link](https://github.com/zoom-wang112358/MOLLEO)** |
| 9/30 | **2024-06-16** | <details><summary>**City-LEO: Toward Transparent City Management Using LLM with End-to-End Optimization**</summary>Jiao et al. propose an LLM agent that translates natural language queries into Gurobi objectives and 'scopes down' an electric bike rebalancing MIP by fixing variables deemed irrelevant by the LLM. The 'End-to-End' component simply maps a pre-trained Random Forest into MIP constraints (following Biggs et al., 2022), which is a known technique. The results are tautological: solving a sub-problem (by heuristically fixing variables) is faster than solving the full MIP, but incurs an optimality gap of up to ~12%. The only takeaway is the concept of 'semantic decomposition'‚Äîusing an LLM to identify variable dependencies for local search‚Äîbut their implementation is too trivial to be useful for our AlgoEvo or VRP work.</details> | Zihao Jiao et.al. | Tsinghua University, Beijing Technology and Business University | arXiv.org | [2406.10958](http://arxiv.org/abs/2406.10958) | ‚Äî |
| 7/30 | **2024-06-15** | <details><summary>**Large Language Models as Surrogate Models in Evolutionary Algorithms: A Preliminary Study**</summary>The authors propose using LLMs (Llama3, Mixtral) as zero-shot surrogate models for low-dimensional (5D-10D) continuous black-box optimization by prompting them with historical solution-fitness pairs. While they claim performance comparable to Bayesian Optimization on toy benchmarks (Ackley, Rosenbrock), the approach incurs massive inference costs for results that are often statistically indistinguishable from or worse than standard baselines. The primary takeaway is a negative one: LLMs are inefficient and imprecise regressors for raw numerical vectors compared to traditional ML methods. This confirms we should restrict our LLM surrogate efforts to semantic tasks (code/heuristics) rather than numerical parameter tuning.</details> | Hao Hao et.al. | Shanghai Jiao Tong University, East China Normal University | Swarm and Evolutionary Computation | [2406.10675](http://arxiv.org/abs/2406.10675) | **[link](https://github.com/hhyqhh/LAEA.git)** |
| 16/30 | **2024-05-21** | <details><summary>**LLMs for Mathematical Modeling: Towards Bridging the Gap between Natural and Mathematical Languages**</summary>Huang et al. present Mamo, a benchmark evaluating LLMs on mathematical modeling (ODEs and LP/MILP) by generating code/files (Python/.lp) and verifying numerical results via solvers. They provide ~800 optimization word problems with ground truth, finding that while o1-preview dominates on complex LP tasks (36% vs GPT-4o's 23%), it surprisingly underperforms on simpler instances. **Takeaway:** We should scrape their dataset to augment our 'OR-Bench' and 'OR formulations' training data. Additionally, their success using the text-based `.lp` format (instead of complex Python API calls) is a prompting strategy we should adopt to reduce syntax hallucinations in our optimization agents.</details> | Xuhan Huang et.al. | The Chinese University of Hong Kong, Shenzhen, Shenzhen Research Institute of Big Data | North American Chapter of the Association for Computational Linguistics | [2405.13144](http://arxiv.org/abs/2405.13144) | **[link](https://github.com/freedomintelligence/mamo)** |
| 4/30 | **2024-05-17** | <details><summary>**Large Language Model (LLM) for Telecommunications: A Comprehensive Survey on Principles, Key Techniques, and Opportunities**</summary>This paper is a comprehensive survey of LLM applications in telecommunications, covering generation, classification, prediction, and optimization. It reviews how standard techniques like CoT, in-context learning, and parameter-efficient fine-tuning are applied to telecom tasks such as network configuration and traffic prediction. For our research, the only potential value is a list of domain-specific optimization problems (e.g., RIS phase shift control, beamforming) that could serve as future testbeds for AlgoEvo, but the paper itself offers no methodological novelty.</details> | Hao Zhou et.al. | McGill University, Samsung Research America, Western University, Simon Fraser University | IEEE Communications Surveys and Tutorials | [2405.10825](http://arxiv.org/abs/2405.10825) | ‚Äî |
| 3/30 | **2024-05-16** | <details><summary>**When Large Language Model Meets Optimization**</summary>Huang et al. provide a systematic review categorizing the intersection of LLMs and optimization into two flows: LLMs assisting optimization (as search operators or code generators) and optimization assisting LLMs (prompt tuning, NAS). The paper proposes a taxonomy but contains no original experiments or novel methodologies. For our expert group, this serves only as a bibliography to ensure we haven't missed minor papers; it provides no actionable technical value or transferable insights.</details> | Sen Huang et.al. | National University of Defense Technology, South China University of Technology | Swarm and Evolutionary Computation | [2405.10098](http://arxiv.org/abs/2405.10098) | **[link](https://github.com/jettbrains/-L-)** |
| 12/30 | **2024-05-08** | <details><summary>**Automated Conversion of Static to Dynamic Scheduler via Natural Language**</summary>Tang et al. propose RAGDYS, a pipeline using LLMs to modify existing Google OR-Tools code by adding dynamic constraints (e.g., worker unavailability) and a minimum perturbation objective. While they claim 90% success with GPT-4, the tested constraints are trivial (mostly fixing variables to zero), and the methodology is a standard application of RAG without novel search or reasoning mechanisms. The only potentially useful implementation detail is the code-fixing loop that retrieves specific solver documentation to resolve syntax errors, which we could standardize in our coding agents. Otherwise, this is a basic interface wrapper around a solver, offering no new algorithmic insights for our evolutionary or multi-agent work.</details> | Paul Mingzheng Tang et.al. | Singapore Management University | arXiv.org | [2405.06697](http://arxiv.org/abs/2405.06697) | ‚Äî |
| 8/30 | **2024-03-04** | <details><summary>**Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism**</summary>The authors propose LEO, a population-based optimizer that uses LLM prompts to generate new numerical candidate solutions by explicitly asking for 'nearby' (exploit) or 'scattered' (explore) values. While they claim success on simple 2D benchmarks, the method is orders of magnitude slower than standard baselines (3 hours vs. <1 minute) and degrades significantly in high-dimensional settings (20D+). The only transferable concept is the use of distinct prompts to enforce population diversity (exploration vs. exploitation), but applying LLMs to direct parameter search is a known anti-pattern compared to evolving symbolic logic or code.</details> | Shuvayan Brahmachary et.al. | Brown University, Shell India Markets Pvt. Ltd. | Neurocomputing | [2403.02054](http://arxiv.org/abs/2403.02054) | ‚Äî |
| 23/30 | **2024-03-02** | <details><summary>**LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation**</summary>LLaMoCo fine-tunes small LLMs (down to 350M) to generate executable Python optimization code by training on a synthetic dataset where the 'ground truth' is the empirically best-performing solver identified via exhaustive benchmarking. The results are compelling: the fine-tuned 350M model achieves ~85% normalized performance on benchmarks where GPT-4 Turbo only reaches ~14-30%, largely because the small model learns to select specialized evolutionary strategies (like BIPOP-CMA-ES) while GPT-4 defaults to generic gradient-based solvers. **Key Takeaway:** We can replace the expensive GPT-4 calls in our evolutionary search loop with a specialized, fine-tuned local model (CodeLlama-7B) trained on our historical search successes, significantly improving both sample efficiency and scalability. The paper's 'contrastive warm-up' strategy for aligning diverse problem descriptions is also a transferable technique for our problem encoding work.</details> | Zeyuan Ma et.al. | Singapore Management University, Nanyang Technological University, South China University of Technology | IEEE Transactions on Evolutionary Computation | [2403.01131](http://arxiv.org/abs/2403.01131) | **[link](https://anonymous.4open.science/r/LLaMoCo-722A)** |
| 9/30 | **2024-03-02** | <details><summary>**LM4OPT: Unveiling the potential of Large Language Models in formulating mathematical optimization problems**</summary>This paper benchmarks GPT-4 and a fine-tuned Llama-2-7b on translating natural language to linear programming formulations (NL4Opt dataset). The results demonstrate that a 7B model, even with 'progressive fine-tuning' (training on GSM8K first) and noisy embeddings (NEFTune), fails to perform meaningfully (F1 ~0.13) compared to GPT-4 (F1 ~0.63). The only technical takeaway is that NEFTune slightly mitigates overfitting in small-data fine-tuning, but the overall performance gap suggests this approach is not viable for our automated OR modeling needs compared to prompting frontier models.</details> | Tasnim Ahmed et.al. | Queen's University | INFOR. Information systems and operational research | [2403.01342](http://arxiv.org/abs/2403.01342) | ‚Äî |
| 6/30 | **2024-02-26** | <details><summary>**From Large Language Models and Optimization to Decision Optimization CoPilot: A Research Manifesto**</summary>Wasserkrug et al. propose a vision for a 'Decision Optimization CoPilot' and conduct small-scale anecdotal tests (5 runs per problem) using ChatGPT to formulate MILPs for bike hubs, vaccination clinics, and radiotherapy. They find that off-the-shelf LLMs frequently generate incorrect formulations (missing objective terms) and fail significantly at 'Requirement #3': refactoring models for computational efficiency (e.g., failing to linearize constraints or reduce variable counts). The results are qualitative and confirm known limitations without offering a solution. The only takeaway is the specific observation that LLMs struggle to distinguish between a 'correct' mathematical model and a 'solver-efficient' one, which reinforces the need for our automated benchmarking work.</details> | S. Wasserkrug et.al. | IBM Research, University of Washington, Harvard, University of Amsterdam, MIT-IBM Watson AI Lab | arXiv.org | [2402.16269](http://arxiv.org/abs/2402.16269) | ‚Äî |
| 23/30 | **2024-02-15** | <details><summary>**OptiMUS: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models**</summary>OptiMUS is a multi-agent framework for translating natural language into Gurobi code, achieving SOTA performance by using a 'Connection Graph' to map variables and parameters to specific constraints. This graph allows the agents to dynamically filter context and construct minimal prompts, enabling success on problems with long descriptions where baselines like Chain-of-Experts fail. They release NLP4LP, a hard benchmark of 67 complex instances, which we must immediately compare against our OR-Bench efforts. The **Connection Graph** is the key stealable insight: a structured dependency tracking mechanism that solves context pollution in iterative code generation, directly applicable to our AlgoEvo and HERMES memory designs.</details> | Ali AhmadiTeshnizi et.al. | Stanford University | International Conference on Machine Learning | [2402.10172](http://arxiv.org/abs/2402.10172) | ‚Äî |
| 9/30 | **2024-01-30** | <details><summary>**Synthetic Dialogue Dataset Generation using LLM Agents**</summary>Abdullin et al. employ a standard dual-agent GPT-4 setup to generate 476 synthetic dialogues for eliciting Linear Programming constraints from NL4Opt problem descriptions. The methodology relies entirely on basic prompt engineering to simulate a 'user' and 'expert' loop, validated by a lenient GPT-4 evaluator and human checks. While the paper addresses OR formulation‚Äîa topic relevant to our OR-Bench project‚Äîthe approach is technically trivial and offers no novel mechanisms for multi-agent optimization or evolutionary search. The only potential utility is the workflow for converting static OR benchmarks into conversational datasets, but we could replicate this effortlessly without the paper.</details> | Yelaman Abdullin et.al. | Macquarie University, Deakin University, The University of Melbourne | IEEE Games Entertainment Media Conference | [2401.17461](http://arxiv.org/abs/2401.17461) | **[link](https://github.com/eabdullin/optimouse-quest/)** |
| 8/30 | **2024-01-18** | <details><summary>**Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap**</summary>This paper provides a systematic survey and taxonomy of the intersection between Large Language Models and Evolutionary Algorithms, categorizing works into LLM-enhanced EA (e.g., algorithm generation, search operators) and EA-enhanced LLM (e.g., prompt engineering, NAS). It offers no new methods or empirical results. The single useful takeaway is the associated GitHub repository (LLM4EC), which serves as a convenient bibliography to ensure we haven't missed recent minor papers in our niche. It is useful for onboarding new students but contains no actionable insights for senior researchers.</details> | Xingyu Wu et.al. | The Hong Kong Polytechnic University, Chongqing University | IEEE Transactions on Evolutionary Computation | [2401.10034](http://arxiv.org/abs/2401.10034) | **[link](https://github.com/wuxingyu-ai/LLM4EC)** |
| 8/30 | **2024-01-06** | <details><summary>**Artificial Intelligence for Operations Research: Revolutionizing the Operations Research Process**</summary>This survey reviews the integration of AI into the Operations Research pipeline, categorizing works into parameter generation, model formulation, and solver enhancement (continuous and discrete). It includes a small experimental section benchmarking Llama-2 and Code-Llama on the NL4OPT dataset, showing that fine-tuned smaller models (82% accuracy) outperform zero-shot larger models on textbook problems but fail on complex real-world constraints. The survey aggregates known methods for ML-guided Branch-and-Bound and Column Generation which are relevant to our EvoCut and AlgoEvo projects, but offers no new methodology or novel insights. It serves best as a reading list for new students rather than a resource for the senior team.</details> | Zhenan Fan et.al. |  | arXiv.org | [2401.03244](http://arxiv.org/abs/2401.03244) | ‚Äî |

</details>
