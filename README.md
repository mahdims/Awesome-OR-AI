## Updated on 2026.02.08
<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#or-for-generative-ai>OR for Generative AI</a></li>
    <li><a href=#llms-for-algorithm-design>LLMs for Algorithm Design</a></li>
    <li><a href=#generative-ai-for-or>Generative AI for OR</a></li>
  </ol>
</details>

## OR for Generative AI

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2026-02-03**|**NLI:Non-uniform Linear Interpolation Approximation of Nonlinear Operations for Efficient LLMs Inference**|Jiangyong Yu et.al.|[2602.02988](http://arxiv.org/abs/2602.02988)|null|
|**2026-01-30**|**Matterhorn: Efficient Analog Sparse Spiking Transformer Architecture with Masked Time-To-First-Spike Encoding**|Zhanglu Yan et.al.|[2601.22876](http://arxiv.org/abs/2601.22876)|null|
|**2026-01-28**|**Exact (n + 2) Comparison Complexity for the N-Repeated Element Problem**|Andrew Au et.al.|[2601.21202](http://arxiv.org/abs/2601.21202)|null|
|**2026-01-07**|**Hummingbird: SLO-Oriented GPU Preemption at Microsecond-scale**|Tiancheng Hu et.al.|[2601.04071](http://arxiv.org/abs/2601.04071)|null|
|**2026-01-05**|**LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference**|Hossein Rajabzadeh et.al.|[2601.02569](http://arxiv.org/abs/2601.02569)|null|
|**2025-12-28**|**Argus: Token Aware Distributed LLM Inference Optimization**|Panlong Wu et.al.|[2512.22925](http://arxiv.org/abs/2512.22925)|null|
|**2025-12-25**|**A Model of Causal Explanation on Neural Networks for Tabular Data**|Takashi Isozaki et.al.|[2512.21746](http://arxiv.org/abs/2512.21746)|null|
|**2025-12-18**|**Staggered Batch Scheduling: Co-optimizing Time-to-First-Token and Throughput for High-Efficiency LLM Inference**|Jian Tian et.al.|[2512.16134](http://arxiv.org/abs/2512.16134)|null|
|**2025-12-12**|**Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery: Sublinear Memory Growth for Efficient LLM Inference**|Adilet Metinov et.al.|[2512.11221](http://arxiv.org/abs/2512.11221)|null|
|**2025-12-11**|**Hybrid Learning and Optimization-Based Dynamic Scheduling for DL Workloads on Heterogeneous GPU Clusters**|Shruti Dongare et.al.|[2512.10271](http://arxiv.org/abs/2512.10271)|null|
|**2025-12-07**|**KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models**|Sourjya Roy et.al.|[2512.06727](http://arxiv.org/abs/2512.06727)|null|
|**2025-12-01**|**KV Pareto: Systems-Level Optimization of KV Cache and Model Compression for Long Context Inference**|Sai Gokhale et.al.|[2512.01953](http://arxiv.org/abs/2512.01953)|null|
|**2025-11-27**|**OmniInfer: System-Wide Acceleration Techniques for Optimizing LLM Serving Throughput and Latency**|Jun Wang et.al.|[2511.22481](http://arxiv.org/abs/2511.22481)|null|
|**2026-02-05**|**Opt4GPTQ: Co-Optimizing Memory and Computation for 4-bit GPTQ Quantized LLM Inference on Heterogeneous Platforms**|Yaozheng Zhang et.al.|[2511.19438](http://arxiv.org/abs/2511.19438)|null|
|**2025-11-24**|**An Online Fragmentation-Aware GPU Scheduler for Multi-Tenant MIG-based Clouds**|Marco Zambianco et.al.|[2511.18906](http://arxiv.org/abs/2511.18906)|null|
|**2025-11-20**|**A Scalable NorthPole System with End-to-End Vertical Integration for Low-Latency and Energy-Efficient LLM Inference**|Michael V. DeBole et.al.|[2511.15950](http://arxiv.org/abs/2511.15950)|null|
|**2025-11-18**|**CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design**|Jiawei Yi et.al.|[2511.14510](http://arxiv.org/abs/2511.14510)|null|
|**2025-11-17**|**T-SAR: A Full-Stack Co-design for CPU-Only Ternary LLM Inference via In-Place SIMD ALU Reorganization**|Hyunwoo Oh et.al.|[2511.13676](http://arxiv.org/abs/2511.13676)|null|
|**2025-11-15**|**From Scaling to Structured Expressivity: Rethinking Transformers for CTR Prediction**|Bencheng Yan et.al.|[2511.12081](http://arxiv.org/abs/2511.12081)|null|
|**2025-11-14**|**AccKV: Towards Efficient Audio-Video LLMs Inference via Adaptive-Focusing and Cross-Calibration KV Cache Optimization**|Zhonghua Jiang et.al.|[2511.11106](http://arxiv.org/abs/2511.11106)|null|
|**2025-11-04**|**Optimal Singular Damage: Efficient LLM Inference in Low Storage Regimes**|Mohammadsajad Alipour et.al.|[2511.02681](http://arxiv.org/abs/2511.02681)|null|
|**2026-01-30**|**Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV Cache Time-to-Live**|Hanchen Li et.al.|[2511.02230](http://arxiv.org/abs/2511.02230)|null|
|**2025-11-03**|**Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with Efficient LLM Serving**|Chengying Huan et.al.|[2511.01633](http://arxiv.org/abs/2511.01633)|null|
|**2025-10-30**|**PureKV: Plug-and-Play KV Cache Optimization with Spatial-Temporal Sparse Attention for Vision-Language Large Models**|Zhonghua Jiang et.al.|[2510.25600](http://arxiv.org/abs/2510.25600)|null|
|**2025-10-28**|**Quantum Combinatorial Reasoning for Large Language Models**|Carlos Flores-Garrigos et.al.|[2510.24509](http://arxiv.org/abs/2510.24509)|null|
|**2025-10-30**|**DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference**|Xiang Liu et.al.|[2510.19669](http://arxiv.org/abs/2510.19669)|null|
|**2025-10-19**|**Justitia: Fair and Efficient Scheduling for LLM Applications**|Mingyan Yang et.al.|[2510.17015](http://arxiv.org/abs/2510.17015)|null|
|**2025-10-16**|**MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving**|Jungi Lee et.al.|[2510.14557](http://arxiv.org/abs/2510.14557)|null|
|**2025-10-13**|**Efficient LLM Inference over Heterogeneous Edge Networks with Speculative Decoding**|Bingjie Zhu et.al.|[2510.11331](http://arxiv.org/abs/2510.11331)|null|
|**2025-10-10**|**FLRC: Fine-grained Low-Rank Compressor for Efficient LLM Inference**|Yu-Chen Lu et.al.|[2510.09332](http://arxiv.org/abs/2510.09332)|null|
|**2025-10-05**|**Systematic Diagnosis of Brittle Reasoning in Large Language Models**|V. S. Raghu Parupudi et.al.|[2510.08595](http://arxiv.org/abs/2510.08595)|null|
|**2025-10-07**|**VecInfer: Efficient LLM Inference with Low-Bit KV Cache via Outlier-Suppressed Vector Quantization**|Dingyu Yao et.al.|[2510.06175](http://arxiv.org/abs/2510.06175)|null|
|**2025-09-30**|**Parallax: Efficient LLM Inference Service over Decentralized Environment**|Chris Tong et.al.|[2509.26182](http://arxiv.org/abs/2509.26182)|null|
|**2025-09-30**|**SAIL: SRAM-Accelerated LLM Inference System with Lookup-Table-based GEMV**|Jingyao Zhang et.al.|[2509.25853](http://arxiv.org/abs/2509.25853)|null|
|**2025-12-16**|**SemShareKV: Efficient KVCache Sharing for Semantically Similar Prompts via Token-Level LSH Matching**|Xinye Zhao et.al.|[2509.24832](http://arxiv.org/abs/2509.24832)|null|
|**2025-09-29**|**Speculative Verification: Exploiting Information Gain to Refine Speculative Decoding**|Sungkyun Kim et.al.|[2509.24328](http://arxiv.org/abs/2509.24328)|null|
|**2025-09-26**|**Bridging Draft Policy Misalignment: Group Tree Optimization for Speculative Decoding**|Shijing Hu et.al.|[2509.22134](http://arxiv.org/abs/2509.22134)|null|
|**2025-09-24**|**Gyges: Dynamic Cross-Instance Parallelism Transformation for Efficient LLM Inference**|Haoyu Chen et.al.|[2509.19729](http://arxiv.org/abs/2509.19729)|null|
|**2025-09-22**|**Cronus: Efficient LLM inference on Heterogeneous GPU Clusters via Partially Disaggregated Prefill**|Yunzhao Liu et.al.|[2509.17357](http://arxiv.org/abs/2509.17357)|null|
|**2025-08-26**|**UrgenGo: Urgency-Aware Transparent GPU Kernel Launching for Autonomous Driving**|Hanqi Zhu et.al.|[2509.12207](http://arxiv.org/abs/2509.12207)|null|
|**2025-09-12**|**MCBP: A Memory-Compute Efficient LLM Inference Accelerator Leveraging Bit-Slice-enabled Sparsity and Repetitiveness**|Huizheng Wang et.al.|[2509.10372](http://arxiv.org/abs/2509.10372)|null|
|**2025-09-11**|**Towards Confidential and Efficient LLM Inference with Dual Privacy Protection**|Honglan Yu et.al.|[2509.09091](http://arxiv.org/abs/2509.09091)|null|
|**2025-09-10**|**BitROM: Weight Reload-Free CiROM Architecture Towards Billion-Parameter 1.58-bit LLM Inference**|Wenlun Zhang et.al.|[2509.08542](http://arxiv.org/abs/2509.08542)|null|
|**2025-12-08**|**H2EAL: Hybrid-Bonding Architecture with Hybrid Sparse Attention for Efficient Long-Context LLM Inference**|Zizhuo Fu et.al.|[2508.16653](http://arxiv.org/abs/2508.16653)|null|
|**2025-09-01**|**Adaptively Robust LLM Inference Optimization under Prediction Uncertainty**|Zixi Chen et.al.|[2508.14544](http://arxiv.org/abs/2508.14544)|null|
|**2025-09-27**|**READER: Retrieval-Assisted Drafter for Efficient LLM Inference**|Maxim Divilkovskiy et.al.|[2508.09072](http://arxiv.org/abs/2508.09072)|null|
|**2025-08-08**|**KV Cache Compression for Inference Efficiency in LLMs: A Review**|Yanyu Liu et.al.|[2508.06297](http://arxiv.org/abs/2508.06297)|null|
|**2025-08-31**|**LLM Serving Optimization with Variable Prefill and Decode Lengths**|Meixuan Wang et.al.|[2508.06133](http://arxiv.org/abs/2508.06133)|null|
|**2026-01-19**|**SmallKV: Small Model Assisted Compensation of KV Cache Compression for Efficient LLM Inference**|Yi Zhao et.al.|[2508.02751](http://arxiv.org/abs/2508.02751)|null|
|**2025-08-04**|**Prefill-Decode Aggregation or Disaggregation? Unifying Both for Goodput-Optimized LLM Serving**|Chao Wang et.al.|[2508.01989](http://arxiv.org/abs/2508.01989)|null|
|**2025-08-03**|**AGFT: An Adaptive GPU Frequency Tuner for Real-Time LLM Inference Optimization**|Zicong Ye et.al.|[2508.01744](http://arxiv.org/abs/2508.01744)|null|
|**2025-12-01**|**Optimal Scheduling Algorithms for LLM Inference: Theory and Practice**|Agrim Bari et.al.|[2508.01002](http://arxiv.org/abs/2508.01002)|null|
|**2025-08-06**|**EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices**|Jiyu Chen et.al.|[2508.00370](http://arxiv.org/abs/2508.00370)|null|
|**2025-07-25**|**DeltaLLM: A Training-Free Framework Exploiting Temporal Sparsity for Efficient Edge LLM Inference**|Jiawen Qi et.al.|[2507.19608](http://arxiv.org/abs/2507.19608)|null|
|**2025-07-23**|**BucketServe: Bucket-Based Dynamic Batching for Smart and Efficient LLM Inference Serving**|Wanyi Zheng et.al.|[2507.17120](http://arxiv.org/abs/2507.17120)|null|
|**2025-07-14**|**LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models**|Dachuan Shi et.al.|[2507.14204](http://arxiv.org/abs/2507.14204)|null|
|**2025-07-16**|**IAM: Efficient Inference through Attention Mapping between Different-scale LLMs**|Yi Zhao et.al.|[2507.11953](http://arxiv.org/abs/2507.11953)|null|
|**2025-10-29**|**Oneiros: KV Cache Optimization through Parameter Remapping for Multi-tenant LLM Serving**|Ruihao Li et.al.|[2507.11507](http://arxiv.org/abs/2507.11507)|null|
|**2025-09-16**|**InferLog: Accelerating LLM Inference for Online Log Parsing via ICL-oriented Prefix Caching**|Yilun Wang et.al.|[2507.08523](http://arxiv.org/abs/2507.08523)|null|
|**2025-07-09**|**Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration**|Xinyuan Song et.al.|[2507.06520](http://arxiv.org/abs/2507.06520)|null|
|**2025-08-16**|**OrthoRank: Token Selection via Sink Token Orthogonality for Efficient LLM inference**|Seungjun Shin et.al.|[2507.03865](http://arxiv.org/abs/2507.03865)|null|
|**2025-06-20**|**Towards AI Search Paradigm**|Yuchen Li et.al.|[2506.17188](http://arxiv.org/abs/2506.17188)|null|
|**2025-06-12**|**Understanding the Performance and Power of LLM Inferencing on Edge Accelerators**|Mayank Arya et.al.|[2506.09554](http://arxiv.org/abs/2506.09554)|null|
|**2025-06-09**|**Evaluating Visual Mathematics in Multimodal LLMs: A Multilingual Benchmark Based on the Kangaroo Tests**|Arnau Igualde Sáez et.al.|[2506.07418](http://arxiv.org/abs/2506.07418)|null|
|**2025-06-06**|**Towards Efficient Multi-LLM Inference: Characterization and Analysis of LLM Routing and Hierarchical Techniques**|Adarsh Prasad Behera et.al.|[2506.06579](http://arxiv.org/abs/2506.06579)|null|
|**2025-07-05**|**SparseMM: Head Sparsity Emerges from Visual Concept Responses in MLLMs**|Jiahui Wang et.al.|[2506.05344](http://arxiv.org/abs/2506.05344)|null|
|**2025-09-29**|**METok: Multi-Stage Event-based Token Compression for Efficient Long Video Understanding**|Mengyue Wang et.al.|[2506.02850](http://arxiv.org/abs/2506.02850)|null|
|**2025-05-29**|**Sustainable Carbon-Aware and Water-Efficient LLM Scheduling in Geo-Distributed Cloud Datacenters**|Hayden Moore et.al.|[2505.23554](http://arxiv.org/abs/2505.23554)|null|
|**2025-05-27**|**DualSchool: How Reliable are LLMs for Optimization Education?**|Michael Klamkin et.al.|[2505.21775](http://arxiv.org/abs/2505.21775)|null|
|**2025-05-27**|**TailorKV: A Hybrid Framework for Long-Context Inference via Tailored KV Cache Optimization**|Dingyu Yao et.al.|[2505.19586](http://arxiv.org/abs/2505.19586)|null|
|**2025-05-23**|**DASH: Input-Aware Dynamic Layer Skipping for Efficient LLM Inference with Markov Decision Policies**|Ning Yang et.al.|[2505.17420](http://arxiv.org/abs/2505.17420)|null|
|**2025-10-23**|**Tropical Attention: Neural Algorithmic Reasoning for Combinatorial Algorithms**|Baran Hashemi et.al.|[2505.17190](http://arxiv.org/abs/2505.17190)|null|
|**2025-06-07**|**Robustifying Vision-Language Models via Dynamic Token Reweighting**|Tanqiu Jiang et.al.|[2505.17132](http://arxiv.org/abs/2505.17132)|null|
|**2025-12-16**|**FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference**|Guangda Liu et.al.|[2505.13109](http://arxiv.org/abs/2505.13109)|null|
|**2025-05-21**|**SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices**|Xiangwen Zhuge et.al.|[2505.10259](http://arxiv.org/abs/2505.10259)|null|
|**2025-05-14**|**ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor**|Seungbeom Choi et.al.|[2505.09142](http://arxiv.org/abs/2505.09142)|null|
|**2025-05-13**|**Isolation Forest in Novelty Detection Scenario**|Adam Ulrich et.al.|[2505.08489](http://arxiv.org/abs/2505.08489)|null|
|**2025-05-08**|**Scaling Laws for Speculative Decoding**|Siyuan Yan et.al.|[2505.07858](http://arxiv.org/abs/2505.07858)|null|
|**2025-04-28**|**Taming the Titans: A Survey of Efficient LLM Inference Serving**|Ranran Zhen et.al.|[2504.19720](http://arxiv.org/abs/2504.19720)|null|
|**2025-04-28**|**R-Sparse: Rank-Aware Activation Sparsity for Efficient LLM Inference**|Zhenyu Zhang et.al.|[2504.19449](http://arxiv.org/abs/2504.19449)|null|
|**2025-04-24**|**On-Device Qwen2.5: Efficient LLM Inference with Model Compression and Hardware Acceleration**|Maoyang Xiang et.al.|[2504.17376](http://arxiv.org/abs/2504.17376)|null|
|**2026-01-05**|**Optimizing LLM Inference: Fluid-Guided Online Scheduling with Memory Constraints**|Ruicheng Ao et.al.|[2504.11320](http://arxiv.org/abs/2504.11320)|null|
|**2025-10-31**|**HELIOS: Adaptive Model And Early-Exit Selection for Efficient LLM Inference Serving**|Avinash Kumar et.al.|[2504.10724](http://arxiv.org/abs/2504.10724)|null|
|**2025-11-27**|**KeepKV: Achieving Periodic Lossless KV Cache Compression for Efficient LLM Inference**|Yuxuan Tian et.al.|[2504.09936](http://arxiv.org/abs/2504.09936)|null|
|**2025-04-13**|**LoopLynx: A Scalable Dataflow Architecture for Efficient LLM Inference**|Jianing Zheng et.al.|[2504.09561](http://arxiv.org/abs/2504.09561)|null|
|**2025-04-24**|**Throughput-Optimal Scheduling Algorithms for LLM Inference and AI Agents**|Yueying Li et.al.|[2504.07347](http://arxiv.org/abs/2504.07347)|null|
|**2025-04-08**|**HybriMoE: Hybrid CPU-GPU Scheduling and Cache Management for Efficient MoE Inference**|Shuzhang Zhong et.al.|[2504.05897](http://arxiv.org/abs/2504.05897)|null|
|**2025-04-04**|**Sustainable LLM Inference for Edge AI: Evaluating Quantized LLMs for Energy Efficiency, Output Accuracy, and Inference Latency**|Erik Johannes Husom et.al.|[2504.03360](http://arxiv.org/abs/2504.03360)|null|
|**2025-09-29**|**SentenceKV: Efficient LLM Inference via Sentence-Level Semantic KV Caching**|Yuxuan Zhu et.al.|[2504.00970](http://arxiv.org/abs/2504.00970)|null|
|**2025-04-06**|**ReaLM: Reliable and Efficient Large Language Model Inference with Statistical Algorithm-Based Fault Tolerance**|Tong Xie et.al.|[2503.24053](http://arxiv.org/abs/2503.24053)|null|
|**2025-03-28**|**EdgeInfinite: A Memory-Efficient Infinite-Context Transformer for Edge Devices**|Jiyu Chen et.al.|[2503.22196](http://arxiv.org/abs/2503.22196)|null|
|**2025-03-27**|**WindowKV: Task-Adaptive Group-Wise KV Cache Window Selection for Efficient LLM Inference**|Youhui Zuo et.al.|[2503.17922](http://arxiv.org/abs/2503.17922)|null|
|**2025-03-20**|**SPIN: Accelerating Large Language Model Inference with Heterogeneous Speculative Models**|Fahao Chen et.al.|[2503.15921](http://arxiv.org/abs/2503.15921)|null|
|**2025-10-05**|**ZSMerge: Zero-Shot KV Cache Compression for Memory-Efficient Long-Context LLMs**|Xin Liu et.al.|[2503.10714](http://arxiv.org/abs/2503.10714)|null|
|**2025-05-15**|**Collaborative Speculative Inference for Efficient LLM Inference Serving**|Luyao Gao et.al.|[2503.10325](http://arxiv.org/abs/2503.10325)|null|
|**2026-01-12**|**AdaSpec: Adaptive Speculative Decoding for Fast, SLO-Aware Large Language Model Serving**|Kaiyu Huang et.al.|[2503.05096](http://arxiv.org/abs/2503.05096)|null|
|**2025-03-06**|**$\texttt{SEM-CTRL}$ : Semantically Controlled Decoding**|Mohammad Albinhassan et.al.|[2503.01804](http://arxiv.org/abs/2503.01804)|null|
|**2025-03-01**|**Tutorial Proposal: Speculative Decoding for Efficient LLM Inference**|Heming Xia et.al.|[2503.00491](http://arxiv.org/abs/2503.00491)|null|
|**2025-03-09**|**Can Large Language Models Unveil the Mysteries? An Exploration of Their Ability to Unlock Information in Complex Scenarios**|Chao Wang et.al.|[2502.19973](http://arxiv.org/abs/2502.19973)|null|
|**2025-02-24**|**Make LLM Inference Affordable to Everyone: Augmenting GPU Memory with NDP-DIMM**|Lian Liu et.al.|[2502.16963](http://arxiv.org/abs/2502.16963)|null|

<p align=right>(<a href=#updated-on-20260208>back to top</a>)</p>

## LLMs for Algorithm Design

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2001-05-10**|**Orchestrating an NMR quantum computation: the N=3 Deutsch-Jozsa algorithm**|David Collins et.al.|[quant-ph/0105045](http://arxiv.org/abs/quant-ph/0105045)|null|
|**2004-01-14**|**On the Evolution of Time Horizons in Parallel and Grid Simulations**|L. N. Shchur et.al.|[cond-mat/0401229](http://arxiv.org/abs/cond-mat/0401229)|null|
|**2026-02-04**|**Landscape-aware Automated Algorithm Design: An Efficient Framework for Real-world Optimization**|Haoran Yin et.al.|[2602.04529](http://arxiv.org/abs/2602.04529)|null|
|**2026-02-04**|**ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas**|Wenjun Peng et.al.|[2602.04296](http://arxiv.org/abs/2602.04296)|null|
|**2026-02-03**|**Contrastive Concept-Tree Search for LLM-Assisted Algorithm Discovery**|Timothee Leleu et.al.|[2602.03132](http://arxiv.org/abs/2602.03132)|null|
|**2026-01-29**|**READY: Reward Discovery for Meta-Black-Box Optimization**|Zechuan Huang et.al.|[2601.21847](http://arxiv.org/abs/2601.21847)|null|
|**2026-01-29**|**LLaMEA-SAGE: Guiding Automated Algorithm Design with Structural Feedback from Explainable AI**|Niki van Stein et.al.|[2601.21511](http://arxiv.org/abs/2601.21511)|null|
|**2026-01-29**|**TIDE: Tuning-Integrated Dynamic Evolution for LLM-Based Automated Heuristic Design**|Chentong Chen et.al.|[2601.21239](http://arxiv.org/abs/2601.21239)|null|
|**2026-01-29**|**PathWise: Planning through World Model for Automated Heuristic Design via Self-Evolving LLMs**|Oguzhan Gungordu et.al.|[2601.20539](http://arxiv.org/abs/2601.20539)|null|
|**2026-01-27**|**Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search**|Thomas Bömer et.al.|[2601.19622](http://arxiv.org/abs/2601.19622)|null|
|**2026-02-01**|**Evolving Interdependent Operators with Large Language Models for Multi-Objective Combinatorial Optimization**|Junhao Qiu et.al.|[2601.17899](http://arxiv.org/abs/2601.17899)|null|
|**2026-01-22**|**LLM-Assisted Automatic Dispatching Rule Design for Dynamic Flexible Assembly Flow Shop Scheduling**|Junhao Qiu et.al.|[2601.15738](http://arxiv.org/abs/2601.15738)|null|
|**2026-01-15**|**Global Optimization for Combinatorial Geometry Problems Revisited in the Era of LLMs**|Timo Berthold et.al.|[2601.05943](http://arxiv.org/abs/2601.05943)|null|
|**2026-01-09**|**Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer**|Yifan Zhang et.al.|[2601.05770](http://arxiv.org/abs/2601.05770)|null|
|**2025-12-30**|**LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm**|Chunhui Wan et.al.|[2512.24077](http://arxiv.org/abs/2512.24077)|null|
|**2025-12-25**|**Discovering Sparse Recovery Algorithms Using Neural Architecture Search**|Patrick Yubeaton et.al.|[2512.21563](http://arxiv.org/abs/2512.21563)|null|
|**2025-12-10**|**Beyond Algorithm Evolution: An LLM-Driven Framework for the Co-Evolution of Swarm Intelligence Optimization Algorithms and Prompts**|Shipeng Cen et.al.|[2512.09209](http://arxiv.org/abs/2512.09209)|null|
|**2025-12-03**|**A Retrieval-Augmented Generation Approach to Extracting Algorithmic Logic from Neural Networks**|Waleed Khalid et.al.|[2512.04329](http://arxiv.org/abs/2512.04329)|null|
|**2025-11-11**|**AlphaResearch: Accelerating New Algorithm Discovery with Language Models**|Zhaojian Yu et.al.|[2511.08522](http://arxiv.org/abs/2511.08522)|null|
|**2025-11-10**|**Extending QAOA-GPT to Higher-Order Quantum Optimization Problems**|Leanto Sunny et.al.|[2511.07391](http://arxiv.org/abs/2511.07391)|null|
|**2026-01-06**|**CodeEvolve: an open source evolutionary coding agent for algorithm discovery and optimization**|Henrique Assumpção et.al.|[2510.14150](http://arxiv.org/abs/2510.14150)|null|
|**2025-10-13**|**Refining Hybrid Genetic Search for CVRP via Reinforcement Learning-Finetuned LLM**|Rongjie Zhu et.al.|[2510.11121](http://arxiv.org/abs/2510.11121)|null|
|**2025-10-09**|**Quantum Agents for Algorithmic Discovery**|Iordanis Kerenidis et.al.|[2510.08159](http://arxiv.org/abs/2510.08159)|null|
|**2025-10-10**|**Barbarians at the Gate: How AI is Upending Systems Research**|Audrey Cheng et.al.|[2510.06189](http://arxiv.org/abs/2510.06189)|null|
|**2025-10-07**|**Scientific Algorithm Discovery by Augmenting AlphaEvolve with Deep Research**|Gang Liu et.al.|[2510.06056](http://arxiv.org/abs/2510.06056)|null|
|**2025-09-30**|**Experience-Guided Reflective Co-Evolution of Prompts and Heuristics for Automatic Algorithm Design**|Yihong Liu et.al.|[2509.24509](http://arxiv.org/abs/2509.24509)|null|
|**2025-09-25**|**GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models**|Peng Luo et.al.|[2509.21593](http://arxiv.org/abs/2509.21593)|null|
|**2025-09-02**|**Re-evaluating LLM-based Heuristic Search: A Case Study on the 3D Packing Problem**|Guorui Quan et.al.|[2509.02297](http://arxiv.org/abs/2509.02297)|null|
|**2025-08-25**|**Data-Driven Discovery of Interpretable Kalman Filter Variants through Large Language Models and Genetic Programming**|Vasileios Saketos et.al.|[2508.11703](http://arxiv.org/abs/2508.11703)|null|
|**2025-11-16**|**Automated Algorithmic Discovery for Scientific Computing through LLM-Guided Evolutionary Search: A Case Study in Gravitational-Wave Detection**|He Wang et.al.|[2508.03661](http://arxiv.org/abs/2508.03661)|null|
|**2025-08-20**|**EoH-S: Evolution of Heuristic Set using LLMs for Automated Heuristic Design**|Fei Liu et.al.|[2508.03082](http://arxiv.org/abs/2508.03082)|null|
|**2025-08-03**|**EvoVLMA: Evolutionary Vision-Language Model Adaptation**|Kun Ding et.al.|[2508.01558](http://arxiv.org/abs/2508.01558)|null|
|**2025-07-16**|**MatRL: Provably Generalizable Iterative Algorithm Discovery via Monte-Carlo Tree Search**|Sungyoon Kim et.al.|[2507.03833](http://arxiv.org/abs/2507.03833)|null|
|**2025-07-04**|**Behaviour Space Analysis of LLM-driven Meta-heuristic Discovery**|Niki van Stein et.al.|[2507.03605](http://arxiv.org/abs/2507.03605)|null|
|**2025-07-11**|**Discovering Algorithms with Computational Language Processing**|Theo Bourdais et.al.|[2507.03190](http://arxiv.org/abs/2507.03190)|null|
|**2025-06-16**|**AlphaEvolve: A coding agent for scientific and algorithmic discovery**|Alexander Novikov et.al.|[2506.13131](http://arxiv.org/abs/2506.13131)|null|
|**2025-06-14**|**Automated Heuristic Design for Unit Commitment Using Large Language Models**|Junjin Lv et.al.|[2506.12495](http://arxiv.org/abs/2506.12495)|null|
|**2025-05-22**|**STRCMP: Integrating Graph Structural Priors with Language Models for Combinatorial Optimization**|Xijun Li et.al.|[2506.11057](http://arxiv.org/abs/2506.11057)|null|
|**2025-06-03**|**LLM-Driven Instance-Specific Heuristic Generation and Selection**|Shaofeng Zhang et.al.|[2506.00490](http://arxiv.org/abs/2506.00490)|null|
|**2025-08-08**|**LLM-Meta-SR: In-Context Learning for Evolving Selection Operators in Symbolic Regression**|Hengzhe Zhang et.al.|[2505.18602](http://arxiv.org/abs/2505.18602)|null|
|**2025-05-24**|**Performance report of heuristic algorithm that cracked the largest Gset Ising problems (G81 cut=14060)**|Kenneth M. Zick et.al.|[2505.18508](http://arxiv.org/abs/2505.18508)|null|
|**2025-05-18**|**CALM: Co-evolution of Algorithms and Language Model for Automatic Heuristic Design**|Ziyao Huang et.al.|[2505.12285](http://arxiv.org/abs/2505.12285)|null|
|**2025-06-09**|**Scalable Meta-Learning via Mixed-Mode Differentiation**|Iurii Kemaev et.al.|[2505.00793](http://arxiv.org/abs/2505.00793)|null|
|**2025-04-28**|**BLADE: Benchmark suite for LLM-driven Automated Design and Evolution of iterative optimisation heuristics**|Niki van Stein et.al.|[2504.20183](http://arxiv.org/abs/2504.20183)|null|
|**2025-08-04**|**Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning**|Anja Surina et.al.|[2504.05108](http://arxiv.org/abs/2504.05108)|null|
|**2025-03-25**|**Optimizing Photonic Structures with Large Language Model Driven Algorithm Discovery**|Haoran Yin et.al.|[2503.19742](http://arxiv.org/abs/2503.19742)|null|
|**2025-03-05**|**Leveraging Large Language Models to Develop Heuristics for Emerging Optimization Problems**|Thomas Bömer et.al.|[2503.03350](http://arxiv.org/abs/2503.03350)|null|
|**2025-11-16**|**From Euler to AI: Unifying Formulas for Mathematical Constants**|Tomer Raz et.al.|[2502.17533](http://arxiv.org/abs/2502.17533)|null|
|**2025-01-11**|**AlgoPilot: Fully Autonomous Program Synthesis Without Human-Written Programs**|Xiaoxin Yin et.al.|[2501.06423](http://arxiv.org/abs/2501.06423)|null|
|**2024-12-15**|**RecSys Arena: Pair-wise Recommender System Evaluation with Large Language Models**|Zhuo Wu et.al.|[2412.11068](http://arxiv.org/abs/2412.11068)|null|
|**2024-12-09**|**LLMs as Debate Partners: Utilizing Genetic Algorithms and Adversarial Search for Adaptive Arguments**|Prakash Aryan et.al.|[2412.06229](http://arxiv.org/abs/2412.06229)|null|
|**2024-12-02**|**Algorithmic Discovery of Casimir-Polder forces: Repulsion in the Ground State**|Romuald Kilianski et.al.|[2412.01483](http://arxiv.org/abs/2412.01483)|null|
|**2024-10-30**|**Automatic programming via large language models with population self-evolution for dynamic job shop scheduling problem**|Jin Huang et.al.|[2410.22657](http://arxiv.org/abs/2410.22657)|null|
|**2025-06-10**|**Can Large Language Models Invent Algorithms to Improve Themselves?: Algorithm Discovery for Recursive Self-Improvement through Reinforcement Learning**|Yoichi Ishibashi et.al.|[2410.15639](http://arxiv.org/abs/2410.15639)|null|
|**2025-02-04**|**Multi-objective Evolution of Heuristic Using Large Language Model**|Shunyu Yao et.al.|[2409.16867](http://arxiv.org/abs/2409.16867)|null|
|**2024-09-04**|**TS-EoH: An Edge Server Task Scheduling Algorithm Based on Evolution of Heuristic**|Wang Yatong et.al.|[2409.09063](http://arxiv.org/abs/2409.09063)|null|
|**2024-07-15**|**Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models**|Rui Zhang et.al.|[2407.10873](http://arxiv.org/abs/2407.10873)|null|
|**2024-05-26**|**REX: Designing User-centered Repair and Explanations to Address Robot Failures**|Christine P Lee et.al.|[2405.16710](http://arxiv.org/abs/2405.16710)|null|
|**2024-02-05**|**Open-Universe Indoor Scene Generation using LLM Program Synthesis and Uncurated Object Databases**|Rio Aguina-Kang et.al.|[2403.09675](http://arxiv.org/abs/2403.09675)|null|
|**2024-06-01**|**tnGPS: Discovering Unknown Tensor Network Structure Search Algorithms via Large Language Models (LLMs)**|Junhua Zeng et.al.|[2402.02456](http://arxiv.org/abs/2402.02456)|null|
|**2024-01-22**|**Analyzing the Effectiveness of Large Language Models on Text-to-SQL Synthesis**|Richard Roberson et.al.|[2401.12379](http://arxiv.org/abs/2401.12379)|null|
|**2024-06-01**|**Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model**|Fei Liu et.al.|[2401.02051](http://arxiv.org/abs/2401.02051)|null|
|**2023-11-26**|**Algorithm Evolution Using Large Language Model**|Fei Liu et.al.|[2311.15249](http://arxiv.org/abs/2311.15249)|null|
|**2025-02-10**|**Neural Lattice Reduction: A Self-Supervised Geometric Deep Learning Approach**|Giovanni Luca Marchetti et.al.|[2311.08170](http://arxiv.org/abs/2311.08170)|null|
|**2023-11-04**|**DeepACO: Neural-enhanced Ant Systems for Combinatorial Optimization**|Haoran Ye et.al.|[2309.14032](http://arxiv.org/abs/2309.14032)|null|
|**2023-07-04**|**Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics**|Melanie Swan et.al.|[2307.02502](http://arxiv.org/abs/2307.02502)|null|
|**2023-11-21**|**The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks**|Ziqian Zhong et.al.|[2306.17844](http://arxiv.org/abs/2306.17844)|null|
|**2023-03-19**|**Clifford-based Circuit Cutting for Quantum Simulation**|Kaitlin N. Smith et.al.|[2303.10788](http://arxiv.org/abs/2303.10788)|null|
|**2023-05-08**|**Symbolic Discovery of Optimization Algorithms**|Xiangning Chen et.al.|[2302.06675](http://arxiv.org/abs/2302.06675)|null|
|**2023-02-10**|**Unified Functional Hashing in Automatic Machine Learning**|Ryan Gillard et.al.|[2302.05433](http://arxiv.org/abs/2302.05433)|null|
|**2023-01-30**|**Real-Time Acoustic Perception for Automotive Applications**|Jun Yin et.al.|[2301.12808](http://arxiv.org/abs/2301.12808)|null|
|**2022-07-11**|**Search by triplet: An efficient local track reconstruction algorithm for parallel architectures**|Daniel Hugo Cámpora Pérez et.al.|[2207.03936](http://arxiv.org/abs/2207.03936)|null|
|**2022-03-22**|**Explainability in reinforcement learning: perspective and position**|Agneza Krajna et.al.|[2203.11547](http://arxiv.org/abs/2203.11547)|null|
|**2022-03-07**|**The importance of being constrained: dealing with infeasible solutions in Differential Evolution and beyond**|Anna V. Kononova et.al.|[2203.03512](http://arxiv.org/abs/2203.03512)|null|
|**2021-11-08**|**A Comparison of Model-Free and Model Predictive Control for Price Responsive Water Heaters**|David J. Biagioni et.al.|[2111.04689](http://arxiv.org/abs/2111.04689)|null|
|**2021-09-30**|**Accelerating Perturbed Stochastic Iterates in Asynchronous Lock-Free Optimization**|Kaiwen Zhou et.al.|[2109.15292](http://arxiv.org/abs/2109.15292)|null|
|**2022-02-22**|**Practical Schemes for Finding Near-Stationary Points of Convex Finite-Sums**|Kaiwen Zhou et.al.|[2105.12062](http://arxiv.org/abs/2105.12062)|null|
|**2020-04-02**|**Trustless parallel local search for effective distributed algorithm discovery**|Zvezdin Besarabov et.al.|[2004.01521](http://arxiv.org/abs/2004.01521)|null|
|**2020-04-04**|**Coronavirus Covid-19 spreading in Italy: optimizing an epidemiological model with dynamic social distancing through Differential Evolution**|I. De Falco et.al.|[2004.00553](http://arxiv.org/abs/2004.00553)|null|
|**2015-02-09**|**The effect of stellar migration on Galactic chemical evolution: a heuristic approach**|E. Spitoni et.al.|[1407.5797](http://arxiv.org/abs/1407.5797)|null|
|**2013-08-01**|**Flight demonstration of formation flying capabilities for future missions (NEAT Pathfinder)**|M. Delpech et.al.|[1308.0150](http://arxiv.org/abs/1308.0150)|null|
|**2012-12-18**|**Monte Carlo Search Algorithm Discovery for One Player Games**|Francis Maes et.al.|[1208.4692](http://arxiv.org/abs/1208.4692)|null|
|**2009-05-27**|**Proposition d'une methode de qualification et de selection d'un logiciel d'analyse et de suivi du referencement dans les moteurs de recherche**|Sebastien Bruyere et.al.|[0905.4433](http://arxiv.org/abs/0905.4433)|null|
|**2007-08-10**|**Transport processes in stars: diffusion, rotation, magnetic fields and internal waves**|Suzanne Talon et.al.|[0708.1499](http://arxiv.org/abs/0708.1499)|null|

<p align=right>(<a href=#updated-on-20260208>back to top</a>)</p>

## Generative AI for OR

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2026-02-03**|**LLM-Inspired Pretrain-Then-Finetune for Small-Data, Large-Scale Optimization**|Zishi Zhang et.al.|[2602.03690](http://arxiv.org/abs/2602.03690)|null|
|**2026-02-03**|**MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research**|Yifan Shi et.al.|[2602.03318](http://arxiv.org/abs/2602.03318)|null|
|**2026-02-03**|**ProOPF: Benchmarking and Improving LLMs for Professional-Grade Power Systems Optimization Modeling**|Chao Shen et.al.|[2602.03070](http://arxiv.org/abs/2602.03070)|null|
|**2026-02-02**|**Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation**|Zhongyuan Lyu et.al.|[2602.02029](http://arxiv.org/abs/2602.02029)|null|
|**2026-02-01**|**EvoOpt-LLM: Evolving industrial optimization models with large language models**|Yiliu He et.al.|[2602.01082](http://arxiv.org/abs/2602.01082)|null|
|**2026-01-29**|**NEMO: Execution-Aware Optimization Modeling via Autonomous Coding Agents**|Yang Song et.al.|[2601.21372](http://arxiv.org/abs/2601.21372)|null|
|**2026-01-09**|**OPT-Engine: Benchmarking the Limits of LLMs in Optimization Modeling via Complexity Scaling**|Yitian Chen et.al.|[2601.19924](http://arxiv.org/abs/2601.19924)|null|
|**2026-01-25**|**Grammar-Aware Literate Generative Mathematical Programming with Compiler-in-the-Loop**|Roberto Rossi et.al.|[2601.17670](http://arxiv.org/abs/2601.17670)|null|
|**2026-01-10**|**SimLLM: Fine-Tuning Code LLMs for SimPy-Based Queueing System Simulation**|Jun-Qi Chen et.al.|[2601.06543](http://arxiv.org/abs/2601.06543)|null|
|**2026-01-09**|**Global Optimization for Combinatorial Geometry Problems Revisited in the Era of LLMs**|Timo Berthold et.al.|[2601.05943](http://arxiv.org/abs/2601.05943)|null|
|**2025-12-22**|**ORPR: An OR-Guided Pretrain-then-Reinforce Learning Model for Inventory Management**|Lingjie Zhao et.al.|[2512.19001](http://arxiv.org/abs/2512.19001)|null|
|**2025-12-21**|**Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design**|Yuchen Li et.al.|[2512.18682](http://arxiv.org/abs/2512.18682)|null|
|**2025-12-12**|**A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation**|Hong Je-Gal et.al.|[2512.11270](http://arxiv.org/abs/2512.11270)|null|
|**2025-11-13**|**LM4Opt-RA: A Multi-Candidate LLM Framework with Structured Ranking for Automating Network Resource Allocation**|Tasnim Ahmed et.al.|[2512.00039](http://arxiv.org/abs/2512.00039)|null|
|**2025-11-24**|**Doubly Wild Refitting: Model-Free Evaluation of High Dimensional Black-Box Predictions under Convex Losses**|Haichen Hu et.al.|[2511.18789](http://arxiv.org/abs/2511.18789)|null|
|**2025-09-24**|**DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs**|WenZhuo Zhu et.al.|[2511.11576](http://arxiv.org/abs/2511.11576)|null|
|**2025-11-04**|**An LLM-powered MILP modelling engine for workforce scheduling guided by expert knowledge**|Qingyang Li et.al.|[2511.02364](http://arxiv.org/abs/2511.02364)|null|
|**2025-10-31**|**ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling**|Zhuohan Wang et.al.|[2510.27610](http://arxiv.org/abs/2510.27610)|null|
|**2025-10-29**|**LISTEN to Your Preferences: An LLM Framework for Multi-Objective Selection**|Adam S. Jovine et.al.|[2510.25799](http://arxiv.org/abs/2510.25799)|null|
|**2025-10-24**|**A Unified Model for Multi-Task Drone Routing in Post-Disaster Road Assessment**|Huatian Gong et.al.|[2510.21525](http://arxiv.org/abs/2510.21525)|null|
|**2025-10-21**|**AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library**|Minwei Kong et.al.|[2510.18428](http://arxiv.org/abs/2510.18428)|null|
|**2025-10-20**|**Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents**|Yihong Tang et.al.|[2510.17491](http://arxiv.org/abs/2510.17491)|null|
|**2025-10-19**|**SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search**|Dong Li et.al.|[2510.16916](http://arxiv.org/abs/2510.16916)|null|
|**2025-10-05**|**CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling**|Zhengyang Tang et.al.|[2510.04204](http://arxiv.org/abs/2510.04204)|null|
|**2025-10-04**|**REG: A Regularization Optimizer for Robust Training Dynamics**|Zehua Liu et.al.|[2510.03691](http://arxiv.org/abs/2510.03691)|null|
|**2025-10-03**|**Automated Constraint Specification for Job Scheduling by Regulating Generative Model with Domain-Specific Representation**|Yu-Zhe Shi et.al.|[2510.02679](http://arxiv.org/abs/2510.02679)|null|
|**2025-09-24**|**OR-Toolformer: Modeling and Solving Operations Research Problems with Tool Augmented Large Language Models**|Jianzhang Zhang et.al.|[2510.01253](http://arxiv.org/abs/2510.01253)|null|
|**2025-09-29**|**Graph Foundation Models: Bridging Language Model Paradigms and Graph Optimization**|Yunhao Liang et.al.|[2509.24256](http://arxiv.org/abs/2509.24256)|null|
|**2025-09-26**|**StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models**|Chenyu Zhou et.al.|[2509.22558](http://arxiv.org/abs/2509.22558)|null|
|**2025-09-18**|**Large Language Models in Operations Research: Methods, Applications, and Challenges**|Yang Wang et.al.|[2509.18180](http://arxiv.org/abs/2509.18180)|null|
|**2025-09-21**|**Large Language Models as End-to-end Combinatorial Optimization Solvers**|Xia Jiang et.al.|[2509.16865](http://arxiv.org/abs/2509.16865)|null|
|**2025-09-19**|**"It Was a Magical Box": Understanding Practitioner Workflows and Needs in Optimization**|Connor Lawless et.al.|[2509.16402](http://arxiv.org/abs/2509.16402)|null|
|**2025-09-10**|**Gala: Global LLM Agents for Text-to-Model Translation**|Junyang Cai et.al.|[2509.08970](http://arxiv.org/abs/2509.08970)|null|
|**2025-09-10**|**A Systematic Survey on Large Language Models for Evolutionary Optimization: From Modeling to Solving**|Yisong Zhang et.al.|[2509.08269](http://arxiv.org/abs/2509.08269)|null|
|**2025-09-09**|**PersonaFuse: A Personality Activation-Driven Framework for Enhancing Human-LLM Interactions**|Yixuan Tang et.al.|[2509.07370](http://arxiv.org/abs/2509.07370)|null|
|**2025-09-02**|**Perturbing the Derivative: Wild Refitting for Model-Free Evaluation of Machine Learning Models under Bregman Losses**|Haichen Hu et.al.|[2509.02476](http://arxiv.org/abs/2509.02476)|null|
|**2025-09-02**|**Deep Reinforcement Learning for Drone Route Optimization in Post-Disaster Road Assessment**|Huatian Gong et.al.|[2509.01886](http://arxiv.org/abs/2509.01886)|null|
|**2025-08-27**|**LLM-QUBO: An End-to-End Framework for Automated QUBO Transformation from Natural Language Problem Descriptions**|Huixiang Zhang et.al.|[2509.00099](http://arxiv.org/abs/2509.00099)|null|
|**2025-08-25**|**Teaching LLMs to Think Mathematically: A Critical Study of Decision-Making via Optimization**|Mohammad J. Abdel-Rahman et.al.|[2508.18091](http://arxiv.org/abs/2508.18091)|null|
|**2025-08-22**|**Cooperative Design Optimization through Natural Language Interaction**|Ryogo Niwa et.al.|[2508.16077](http://arxiv.org/abs/2508.16077)|null|
|**2025-08-21**|**R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling**|Raj Jain et.al.|[2508.15204](http://arxiv.org/abs/2508.15204)|null|
|**2025-08-20**|**Adaptively Robust LLM Inference Optimization under Prediction Uncertainty**|Zixi Chen et.al.|[2508.14544](http://arxiv.org/abs/2508.14544)|null|
|**2025-08-20**|**Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning**|Beinuo Yang et.al.|[2508.14410](http://arxiv.org/abs/2508.14410)|null|
|**2025-08-16**|**EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models**|M. Yazdani et.al.|[2508.11850](http://arxiv.org/abs/2508.11850)|null|
|**2025-08-05**|**Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation**|Vinicius Lima et.al.|[2508.03117](http://arxiv.org/abs/2508.03117)|null|
|**2025-07-20**|**LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading**|C. Lou et.al.|[2507.14995](http://arxiv.org/abs/2507.14995)|null|
|**2025-07-15**|**Auto-Formulating Dynamic Programming Problems with Large Language Models**|Chenyu Zhou et.al.|[2507.11737](http://arxiv.org/abs/2507.11737)|null|
|**2025-07-13**|**Fine-tuning Large Language Model for Automated Algorithm Design**|Fei Liu et.al.|[2507.10614](http://arxiv.org/abs/2507.10614)|null|
|**2025-06-30**|**Performance of LLMS on Stochastic Modeling Operations Research Problems: From Theory to Practice**|Akshit Kumar et.al.|[2506.23924](http://arxiv.org/abs/2506.23924)|null|
|**2025-06-09**|**REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models**|Diego Forni'es-Tabuenca et.al.|[2506.07759](http://arxiv.org/abs/2506.07759)|null|
|**2025-05-27**|**DualSchool: How Reliable are LLMs for Optimization Education?**|Michael Klamkin et.al.|[2505.21775](http://arxiv.org/abs/2505.21775)|null|
|**2025-05-27**|**PACT: A Contract-Theoretic Framework for Pricing Agentic AI Services Powered by Large Language Models**|Ya-Ting Yang et.al.|[2505.21286](http://arxiv.org/abs/2505.21286)|null|
|**2025-05-17**|**Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling**|Yitian Chen et.al.|[2505.11792](http://arxiv.org/abs/2505.11792)|null|
|**2025-05-10**|**RideAgent: An LLM-Enhanced Optimization Framework for Automated Taxi Fleet Operations**|Xinyu Jiang et.al.|[2505.06608](http://arxiv.org/abs/2505.06608)|null|
|**2025-05-07**|**Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows**|Wenhao Li et.al.|[2505.04354](http://arxiv.org/abs/2505.04354)|null|
|**2025-05-04**|**LLM-OptiRA: LLM-Driven Optimization of Resource Allocation for Non-Convex Problems in Wireless Communications**|Xinyue Peng et.al.|[2505.02091](http://arxiv.org/abs/2505.02091)|null|
|**2025-05-02**|**CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code**|Tasnim Ahmed et.al.|[2505.01485](http://arxiv.org/abs/2505.01485)|null|
|**2025-03-18**|**Fully Automated Generation of Combinatorial Optimisation Systems Using Large Language Models**|Daniel Karapetyan et.al.|[2503.15556](http://arxiv.org/abs/2503.15556)|null|
|**2025-02-22**|**Text2Zinc: A Cross-Domain Dataset for Modeling Optimization and Satisfaction Problems in MiniZinc**|Akash Singirikonda et.al.|[2503.10642](http://arxiv.org/abs/2503.10642)|null|
|**2025-03-13**|**OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problems with Reasoning LLM**|Bowen Zhang et.al.|[2503.10009](http://arxiv.org/abs/2503.10009)|null|
|**2025-02-21**|**A Comprehensive Survey of Linear, Integer, and Mixed-Integer Programming Approaches for Optimizing Resource Allocation in 5G and Beyond Networks**|N. Ejaz et.al.|[2502.15585](http://arxiv.org/abs/2502.15585)|null|
|**2025-02-15**|**LoRE-Merging: Exploring Low-Rank Estimation For Large Language Model Merging**|Zehua Liu et.al.|[2502.10749](http://arxiv.org/abs/2502.10749)|null|
|**2025-01-30**|**Leveraging LLM Agents for Automated Optimization Modeling for SASP Problems: A Graph-RAG Based Approach**|Tianpeng Pan et.al.|[2501.18320](http://arxiv.org/abs/2501.18320)|null|
|**2025-01-14**|**OptiChat: Bridging Optimization Models and Practitioners with Large Language Models**|Hao Chen et.al.|[2501.08406](http://arxiv.org/abs/2501.08406)|null|
|**2024-10-28**|**Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms**|He Yu et.al.|[2410.20848](http://arxiv.org/abs/2410.20848)|null|
|**2024-10-23**|**AutoRNet: Automatically Optimizing Heuristics for Robust Network Design via Large Language Models**|He Yu et.al.|[2410.17656](http://arxiv.org/abs/2410.17656)|null|
|**2024-10-11**|**A Systematic Survey on Large Language Models for Algorithm Design**|Fei Liu et.al.|[2410.14716](http://arxiv.org/abs/2410.14716)|null|
|**2024-10-17**|**LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch**|Caigao Jiang et.al.|[2410.13213](http://arxiv.org/abs/2410.13213)|null|
|**2024-09-03**|**Leveraging Large Language Models for Solving Rare MIP Challenges**|Teng Wang et.al.|[2409.04464](http://arxiv.org/abs/2409.04464)|null|
|**2024-06-23**|**Efficient Evolutionary Search Over Chemical Space with Large Language Models**|Haorui Wang et.al.|[2406.16976](http://arxiv.org/abs/2406.16976)|null|
|**2024-06-16**|**City-LEO: Toward Transparent City Management Using LLM with End-to-End Optimization**|Zihao Jiao et.al.|[2406.10958](http://arxiv.org/abs/2406.10958)|null|
|**2024-06-15**|**Large Language Models as Surrogate Models in Evolutionary Algorithms: A Preliminary Study**|Hao Hao et.al.|[2406.10675](http://arxiv.org/abs/2406.10675)|null|
|**2024-05-17**|**Large Language Model (LLM) for Telecommunications: A Comprehensive Survey on Principles, Key Techniques, and Opportunities**|Hao Zhou et.al.|[2405.10825](http://arxiv.org/abs/2405.10825)|null|
|**2024-05-16**|**When Large Language Model Meets Optimization**|Sen Huang et.al.|[2405.10098](http://arxiv.org/abs/2405.10098)|null|
|**2024-05-08**|**Automated Conversion of Static to Dynamic Scheduler via Natural Language**|Paul Mingzheng Tang et.al.|[2405.06697](http://arxiv.org/abs/2405.06697)|null|
|**2024-03-04**|**Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism**|Shuvayan Brahmachary et.al.|[2403.02054](http://arxiv.org/abs/2403.02054)|null|
|**2024-03-02**|**LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation**|Zeyuan Ma et.al.|[2403.01131](http://arxiv.org/abs/2403.01131)|null|
|**2024-02-26**|**From Large Language Models and Optimization to Decision Optimization CoPilot: A Research Manifesto**|S. Wasserkrug et.al.|[2402.16269](http://arxiv.org/abs/2402.16269)|null|
|**2024-01-18**|**Evolutionary Computation in the Era of Large Language Model: Survey and Roadmap**|Xingyu Wu et.al.|[2401.10034](http://arxiv.org/abs/2401.10034)|null|
|**2023-11-26**|**Synthesizing mixed-integer linear programming models from natural language descriptions**|Qingyang Li et.al.|[2311.15271](http://arxiv.org/abs/2311.15271)|null|
|**2023-09-22**|**Language Models for Business Optimisation with a Real World Case Study in Production Scheduling**|P. Amarasinghe et.al.|[2309.13218](http://arxiv.org/abs/2309.13218)|null|

<p align=right>(<a href=#updated-on-20260208>back to top</a>)</p>

