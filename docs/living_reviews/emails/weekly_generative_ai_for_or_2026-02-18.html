<!DOCTYPE html>
<html>
<head><meta charset="utf-8"><title>Weekly Research Intelligence — Generative AI for OR</title>
<style>
/* Gmail-compatible toggle: checkbox + sibling selector */
.rd-cb { display:none; }
.rd-content { max-height:0; overflow:hidden; transition:max-height .2s ease; }
.rd-cb:checked ~ .rd-content { max-height:9999px; }
</style>
</head>
<body style="margin:0; padding:0; background:#F5F7FA; font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif; color:#1F2937; font-size:14px; line-height:1.5;">
<div style="display:none; max-height:0; overflow:hidden; mso-hide:all; opacity:0; color:transparent;">Research Intelligence curated digest — Latest papers, research fronts, and framework evolution.</div>
<table width="100%" cellpadding="0" cellspacing="0" style="background:#F5F7FA;">
<tr><td align="center" style="padding:0;">
<table width="85%" cellpadding="0" cellspacing="0" style="width:85%;">

<tr><td style="background:linear-gradient(135deg, #1E3A8A 0%, #2563EB 100%); color:white; padding:20px 24px; border-radius:16px 16px 0 0;">
<table width="100%" cellpadding="0" cellspacing="0">
<tr>
<td style="width:48px; vertical-align:top;">
<div style="width:44px; height:44px; background:rgba(255,255,255,0.2); border-radius:12px; display:flex; align-items:center; justify-content:center; border:2px solid rgba(255,255,255,0.3);">
<span style="font-size:18px; font-weight:800; color:white; line-height:44px; text-align:center; display:block;">RI</span>
</div>
</td>
<td style="padding-left:14px; vertical-align:top;">
<h1 style="margin:0; font-size:20px; font-weight:700; letter-spacing:-0.01em; line-height:1.2;">Weekly Research Intelligence — Generative AI for OR</h1>
<p style="margin:4px 0 0; font-size:11px; opacity:0.85; font-weight:500;">Issue #8 of 2026 · 2026-02-18</p>
</td>
</tr>
</table>
</td></tr>
<tr><td style="background:#FFFFFF; padding:0;">
<table width="100%" cellpadding="0" cellspacing="0"><tr><td style="background:#FFFFFF; padding:20px 24px 12px;">
  <table width="100%" cellpadding="0" cellspacing="0" style="border:1px solid #E1E4E8; border-radius:14px; background:#FAFBFC;">
    <tr>
      <td style="padding:14px 18px; font-size:12px; color:#1F2937; font-weight:700; text-transform:uppercase; letter-spacing:0.03em; border-bottom:1px solid #E1E4E8;">
        This week at a glance
      </td>
    </tr>
    <tr>
      <td style="padding:0 18px 14px;">
        <table width="100%" cellpadding="0" cellspacing="0">
          <tr>
            <td style="width:33%; padding:12px 0; text-align:center;">
              <div style="font-size:24px; font-weight:800; color:#2563EB;">35</div>
              <div style="font-size:11px; color:#6B7280; text-transform:uppercase; letter-spacing:0.02em;">Must-reads</div>
            </td>
            <td style="width:33%; padding:12px 0; text-align:center; border-left:1px solid #E1E4E8; border-right:1px solid #E1E4E8;">
              <div style="font-size:24px; font-weight:800; color:#2563EB;">52</div>
              <div style="font-size:11px; color:#6B7280; text-transform:uppercase; letter-spacing:0.02em;">New papers</div>
            </td>
            <td style="width:33%; padding:12px 0; text-align:center;">
              <div style="font-size:24px; font-weight:800; color:#2563EB;">6</div>
              <div style="font-size:11px; color:#6B7280; text-transform:uppercase; letter-spacing:0.02em;">Active fronts</div>
            </td>
          </tr>
        </table>
        <div style="margin-top:10px; padding-top:10px; border-top:1px solid #E1E4E8; font-size:12px; color:#1F2937;">
          <b>This week's theme:</b> Concept-structured search is outperforming brute code mutation across multiple optimization domains.
        </div>
      </td>
    </tr>
  </table>
</td></tr><tr><td style="padding:20px 24px 12px; border-top:2px solid #F8F9FB; background:#FAFBFC;">
  <h2 style="margin:0; font-size:15px; font-weight:700; color:#1F2937; text-transform:uppercase; letter-spacing:0.03em;">Top Priority Papers</h2>
  <p style="margin:4px 0 0; font-size:11px; color:#6B7280; font-weight:500;">10 must-read papers this week (ranked by significance, recency, and impact)</p>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#1</span>
    <a href="https://arxiv.org/abs/2508.11850" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.8/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-08-16 | Huawei Technologies Canada, University of British Columbia, University of Toronto | <a href="https://arxiv.org/abs/2508.11850" style="color:#6B7280; text-decoration:none;">2508.11850</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=10</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=9</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Yazdani et al. introduce EvoCut, an evolutionary framework where LLMs generate Python code for MILP cuts, filtered by a 'usefulness check' (does it cut the current LP relaxation?) and an 'empirical validity check' (does it preserve known integer opti...<input type="checkbox" id="rd-2508-11850" class="rd-cb"><label for="rd-2508-11850" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:12px; display:block; margin-top:6px;">▶ Read more</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;">Yazdani et al. introduce EvoCut, an evolutionary framework where LLMs generate Python code for MILP cuts, filtered by a 'usefulness check' (does it cut the current LP relaxation?) and an 'empirical validity check' (does it preserve known integer optima?). They report 17-57% gap reductions on TSPLIB and JSSP compared to Gurobi defaults, backed by strong ablation studies on the evolutionary operators. <strong>Key Takeaway:</strong> The reliance on 'acceleration cuts'—constraints verified empirically on small datasets rather than formally proven—bypasses the bottleneck of automated theorem proving while still delivering valid speedups. We should immediately adopt their 'LP separation' check as a cheap, high-signal reward for our own evolutionary search loops.</div>
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#2</span>
    <a href="https://arxiv.org/abs/2601.21372" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">NEMO: Execution-Aware Optimization Modeling via Autonomous Coding Agents</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.6/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2026-01-29 | Carnegie Mellon University, C3 AI | <a href="https://arxiv.org/abs/2601.21372" style="color:#6B7280; text-decoration:none;">2601.21372</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=9</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    NEMO achieves SOTA on 8/9 optimization benchmarks by deploying autonomous coding agents that generate both a declarative optimizer (solver code) and an imperative simulator (verification code). The key innovation is using the simulator to validate th...<input type="checkbox" id="rd-2601-21372" class="rd-cb"><label for="rd-2601-21372" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:12px; display:block; margin-top:6px;">▶ Read more</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;">NEMO achieves SOTA on 8/9 optimization benchmarks by deploying autonomous coding agents that generate both a declarative optimizer (solver code) and an imperative simulator (verification code). The key innovation is using the simulator to validate the optimizer's results in a closed loop, detecting logical errors without ground truth—a technique that beats fine-tuned models like SIRL by up to 28%. The most stealable insight is this asymmetric validation: imperative Python simulation is often less error-prone than declarative constraint formulation, making it a robust 'critic' for generated solvers. This is immediately applicable to our OR-Bench and AlgoEvo projects for generating reliable reward signals.</div>
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#3</span>
    <a href="https://arxiv.org/abs/2509.22558" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.3/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-09-26 | Shanghai Jiao Tong University | <a href="https://arxiv.org/abs/2509.22558" style="color:#6B7280; text-decoration:none;">2509.22558</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=9</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Zhou et al. propose StepORLM, a framework where an 8B policy and a <strong>Generative Process Reward Model (GenPRM)</strong> co-evolve. Unlike standard discriminative PRMs that score steps in isolation, their GenPRM generates a reasoning trace to eva...<input type="checkbox" id="rd-2509-22558" class="rd-cb"><label for="rd-2509-22558" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:12px; display:block; margin-top:6px;">▶ Read more</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;">Zhou et al. propose StepORLM, a framework where an 8B policy and a <strong>Generative Process Reward Model (GenPRM)</strong> co-evolve. Unlike standard discriminative PRMs that score steps in isolation, their GenPRM generates a reasoning trace to evaluate the full trajectory's logic before assigning credit, addressing the interdependency of OR constraints. They align the policy using <strong>Weighted DPO</strong>, where preference weights are derived from the GenPRM's process scores. They claim to beat GPT-4o and DeepSeek-V3 on 6 OR benchmarks (e.g., NL4Opt, MAMO) with an 8B model. <strong>Key Takeaway:</strong> We should test <strong>Generative PRMs</strong> immediately for AlgoEvo; asking the critic to 'explain then score' (generative) rather than just 'score' (discriminative) likely fixes the credit assignment noise in our long-horizon search.</div>
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#4</span>
    <a href="https://arxiv.org/abs/2505.11792" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.3/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-05-17 | Stanford University, Shanghai Jiao Tong University, The University of Hong Kong, Shanghai University of Finance and Economics, Cardinal Operations | <a href="https://arxiv.org/abs/2505.11792" style="color:#6B7280; text-decoration:none;">2505.11792</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=9</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Chen et al. introduce SIRL, a framework for training LLMs to generate optimization models using Reinforcement Learning with Verifiable Rewards (RLVR) and a novel 'Partial KL' surrogate objective. By removing the KL penalty from the reasoning (CoT) se...<input type="checkbox" id="rd-2505-11792" class="rd-cb"><label for="rd-2505-11792" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:12px; display:block; margin-top:6px;">▶ Read more</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;">Chen et al. introduce SIRL, a framework for training LLMs to generate optimization models using Reinforcement Learning with Verifiable Rewards (RLVR) and a novel 'Partial KL' surrogate objective. By removing the KL penalty from the reasoning (CoT) section while retaining it for the code generation section, they balance exploration with syntactic stability, achieving SOTA on OptMATH and IndustryOR against OpenAI-o3 and DeepSeek-R1. The critical takeaway for us is the Partial KL strategy: it allows the model to 'think' freely outside the reference distribution while adhering to strict coding standards—a technique we should immediately test in AlgoEvo. Furthermore, their method of parsing .lp files to extract structural features (variable counts, constraint types) for 'instance-enhanced self-consistency' provides a much richer signal than our current binary success/failure metrics.</div>
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#5</span>
    <a href="https://arxiv.org/abs/2510.27610" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.1/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-10-31 | The Chinese University of Hong Kong, Shenzhen, Shenzhen Research Institute of Big Data, Shenzhen International Center for Industrial and Applied Mathematics, Shenzhen Loop Area Institute | <a href="https://arxiv.org/abs/2510.27610" style="color:#6B7280; text-decoration:none;">2510.27610</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=8</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Wang et al. propose ORGEval, a framework that evaluates LLM-generated optimization models by converting them into bipartite graphs and using the Weisfeiler-Lehman (WL) test to detect isomorphism with a ground truth, rather than solving the instances....<input type="checkbox" id="rd-2510-27610" class="rd-cb"><label for="rd-2510-27610" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:12px; display:block; margin-top:6px;">▶ Read more</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;">Wang et al. propose ORGEval, a framework that evaluates LLM-generated optimization models by converting them into bipartite graphs and using the Weisfeiler-Lehman (WL) test to detect isomorphism with a ground truth, rather than solving the instances. They prove that for 'symmetric decomposable' graphs, this method is guaranteed to detect equivalence correctly, achieving 100% consistency and running in seconds compared to hours for solver-based checks on hard MIPLIB instances. The critical takeaway is the shift from execution-based to <strong>structural evaluation</strong>: we can validate model logic via graph topology ($O(k(m+n)^2)$) without incurring the cost of solving NP-hard problems. This is immediately actionable for our OR benchmarking pipelines and could serve as a rapid 'pre-solve' filter in our evolutionary search loops to reject structurally invalid candidates instantly.</div>
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#6</span>
    <a href="https://arxiv.org/abs/2510.18428" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.1/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-10-21 | Massachusetts Institute of Technology, London School of Economics and Political Science, University of Florida, Northeastern University, Singapore Management University, Singapore-MIT Alliance for Research and Technology | <a href="https://arxiv.org/abs/2510.18428" style="color:#6B7280; text-decoration:none;">2510.18428</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=8</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    AlphaOPT introduces a 'Library Evolution' mechanism that iteratively refines the <em>applicability conditions</em> of cached optimization insights based on solver feedback, allowing it to learn from answers alone (no gold programs). On OOD benchmarks...<input type="checkbox" id="rd-2510-18428" class="rd-cb"><label for="rd-2510-18428" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:12px; display:block; margin-top:6px;">▶ Read more</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;">AlphaOPT introduces a 'Library Evolution' mechanism that iteratively refines the <em>applicability conditions</em> of cached optimization insights based on solver feedback, allowing it to learn from answers alone (no gold programs). On OOD benchmarks like OptiBench, it beats fine-tuned models (ORLM) by ~13% and shows consistent scaling with data size. <strong>Key Takeaway:</strong> The specific mechanism of diagnosing 'unretrieved' vs. 'negative' tasks to rewrite retrieval triggers is a transferable technique for our AlgoEvo memory; it solves the problem of heuristic misapplication in long-term search. We should implement this 'condition refinement' loop immediately to improve our multi-agent memory systems.</div>
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#7</span>
    <a href="https://arxiv.org/abs/2510.04204" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.1/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-10-05 | Qwen Team, Alibaba Inc., The Chinese University of Hong Kong, Shenzhen, Southern University of Science and Technology, Shanghai University of Finance and Economics, Shenzhen Loop Area Institute (SLAI) | <a href="https://arxiv.org/abs/2510.04204" style="color:#6B7280; text-decoration:none;">2510.04204</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=8</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Tang et al. propose CALM, a framework that uses an expert 'Intervener' model to inject corrective hints into a small LRM's reasoning trace (e.g., forcing it to use Python instead of manual calculation), followed by SFT and RL (GRPO). Results are stro...<input type="checkbox" id="rd-2510-04204" class="rd-cb"><label for="rd-2510-04204" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:12px; display:block; margin-top:6px;">▶ Read more</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;">Tang et al. propose CALM, a framework that uses an expert 'Intervener' model to inject corrective hints into a small LRM's reasoning trace (e.g., forcing it to use Python instead of manual calculation), followed by SFT and RL (GRPO). Results are strong and verified: a 4B model matches DeepSeek-R1 (671B) on OR benchmarks, specifically fixing the 'Code Utilization Distrust' we see in our own agents. The key takeaway is the 'Intervener' loop: instead of discarding failed traces, they repair them with hints to create a 'golden' reasoning dataset that preserves the 'thinking' process while enforcing tool use. This is a direct, actionable method for improving our AlgoEvo agents' reliability in generating executable heuristics without massive human annotation.</div>
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#8</span>
    <a href="https://arxiv.org/abs/2505.10117" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">Learning Virtual Machine Scheduling in Cloud Computing through Language Agents</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.1/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-05-15 | Shanghai Jiao Tong University, East China Normal University, Tongji University | <a href="https://arxiv.org/abs/2505.10117" style="color:#6B7280; text-decoration:none;">2505.10117</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=8</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Wu et al. introduce MiCo, a hierarchical framework that uses LLMs to evolve both a library of scenario-specific scheduling heuristics ('Options') and a master policy ('Composer') that dynamically switches between them based on system state. Tested on...<input type="checkbox" id="rd-2505-10117" class="rd-cb"><label for="rd-2505-10117" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:12px; display:block; margin-top:6px;">▶ Read more</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;">Wu et al. introduce MiCo, a hierarchical framework that uses LLMs to evolve both a library of scenario-specific scheduling heuristics ('Options') and a master policy ('Composer') that dynamically switches between them based on system state. Tested on large-scale Huawei/Azure VM traces, it achieves a 96.9% competitive ratio against Gurobi, significantly outperforming Deep RL (SchedRL) by ~11% in dynamic scenarios. <strong>Key Insight:</strong> Instead of evolving a single robust heuristic (which often fails in non-stationary environments), explicitly evolve a <em>portfolio</em> of specialized heuristics and a separate <em>selector</em> function. This SMDP-based decomposition is a concrete architectural pattern we should adopt in AlgoEvo to handle diverse problem instances and non-stationary distributions effectively.</div>
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#9</span>
    <a href="https://arxiv.org/abs/2411.01679" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">Autoformulation of Mathematical Optimization Models Using LLMs</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.1/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2024-11-03 | University of Cambridge, University of Hawaii at Manoa | <a href="https://arxiv.org/abs/2411.01679" style="color:#6B7280; text-decoration:none;">2411.01679</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=8</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Astorga et al. frame optimization modeling as a hierarchical Monte-Carlo Tree Search (MCTS) problem, using LLMs to generate components and—crucially—employing SMT solvers to prune mathematically equivalent branches (e.g., recognizing `x+y` and `y+x` ...<input type="checkbox" id="rd-2411-01679" class="rd-cb"><label for="rd-2411-01679" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:12px; display:block; margin-top:6px;">▶ Read more</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;">Astorga et al. frame optimization modeling as a hierarchical Monte-Carlo Tree Search (MCTS) problem, using LLMs to generate components and—crucially—employing SMT solvers to prune mathematically equivalent branches (e.g., recognizing `x+y` and `y+x` as identical). They achieve SOTA results on NL4OPT and IndustryOR, outperforming fine-tuned models like ORLM while using significantly fewer samples than naive approaches. <strong>Key Takeaway:</strong> The integration of symbolic equivalence checking (SMT) to prune the search tree is a technique we should immediately steal; implementing this in AlgoEvo would allow us to discard functionally identical code/math mutants before expensive evaluation, directly addressing our sample efficiency bottleneck.</div>
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#10</span>
    <a href="https://arxiv.org/abs/2502.14760" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 7.9/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-02-20 | Stanford University, The University of Texas at Austin | <a href="https://arxiv.org/abs/2502.14760" style="color:#6B7280; text-decoration:none;">2502.14760</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=7</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=7</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Zhai et al. propose EquivaMap, a framework that evaluates whether two MILP formulations are equivalent by using an LLM to discover a linear mapping between their decision variables, which is then rigorously verified by a solver. Unlike 'execution acc...<input type="checkbox" id="rd-2502-14760" class="rd-cb"><label for="rd-2502-14760" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:12px; display:block; margin-top:6px;">▶ Read more</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;">Zhai et al. propose EquivaMap, a framework that evaluates whether two MILP formulations are equivalent by using an LLM to discover a linear mapping between their decision variables, which is then rigorously verified by a solver. Unlike 'execution accuracy' (which fails on unit scaling) or 'canonical accuracy' (which fails on variable permutation), they achieve 100% accuracy on a new dataset of equivalent formulations including cuts and slack variables. The core insight is replacing output comparison with a 'propose-mapping-and-verify' loop, effectively using the LLM to construct a proof of equivalence. We must adopt this methodology for the OR-Bench evaluation pipeline immediately, as it eliminates the false negatives currently plaguing our generation benchmarks.</div>
  </div>
</td></tr><tr><td style="padding:20px 24px 12px; border-top:2px solid #F8F9FB; background:#FAFBFC;">
  <h2 style="margin:0; font-size:15px; font-weight:700; color:#1F2937; text-transform:uppercase; letter-spacing:0.03em;">Research Front Landscape</h2>
  <p style="margin:4px 0 0; font-size:11px; color:#6B7280; font-weight:500;">6 active fronts | 52 new papers</p>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">LLM-Guided Search and Fine-Tuning for OR Model and Algorithm Synthesis</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 0.51</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">11 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_in_the_loop</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">program_synthesis</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_heuristic</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_evaluator</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Shanghai Jiao Tong. 18% &nbsp;·&nbsp; City University of. 9% &nbsp;·&nbsp; Huawei 9% &nbsp;·&nbsp; The University of. 9%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front focuses on advanced techniques for leveraging Large Language Models (LLMs) to automate and enhance Operations Research (OR) problem formulation and algorithm design. The core theme revolves around integrating LLMs into sophisticated search algorithms, employing specialized fine-tuning strategies with preference learning and synthetic data, and utilizing structured intermediate representations or hierarchical decomposition to improve the robustness, verifiability, and efficiency of generated OR solutions. Specific frameworks like BPP-Search, MiCo (FunSearch), EvoCut, SolverLLM, EquivaMap, DPLM (DualReflect), CIR, LLaMoCo, and LLOME (MargE) are central to these efforts.</p><input type="checkbox" id="fs-9" class="rd-cb"><label for="fs-9" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:11px; display:block; margin-top:6px;">&#9660; Read full analysis</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;"><p style="margin:8px 0 0;">Key contributions include Liu et al.'s DPO with Diversity-Aware Rank-based sampling, enabling a fine-tuned Llama-3.2-1B to match an 8B model on ASP and CVRP. LLaMoCo demonstrates that a 350M parameter model can significantly outperform GPT-4 in optimization code generation through instruction tuning. LLOME introduces the MargE loss function for stable and diverse fine-tuning in constrained optimization, outperforming DPO. In search, BPP-Search enhances Tree-of-Thought for mathematical modeling, while MiCo applies a hierarchical SMDP framework to VM scheduling, achieving an 11% improvement over Deep RL. EvoCut uses LLMs for MILP cut generation, yielding 17-57% gap reductions. SolverLLM introduces Prompt Backpropagation within MCTS for robust formulation. For verification and representation, EquivaMap achieves 100% accuracy in checking formulation equivalence, OptiTrust uses multi-language execution voting for verifiable synthetic data, and CIR introduces a Canonical Intermediate Representation, boosting accuracy to 47.2% on the ORCOpt-Bench.</p><p style="margin:8px 0 0;">This front is rapidly emerging and maturing, characterized by a strong emphasis on moving beyond generic LLM prompting towards highly specialized and verifiable integration. The trajectory indicates a clear focus on improving the reliability and performance of LLM-generated OR artifacts. Future work will likely concentrate on combining these advanced techniques, such as integrating MargE-style preference learning into MCTS or evolutionary search frameworks, and expanding CIR-like structured generation to encompass more complex, real-world OR problems, potentially with dynamic cut separation and formal proof systems.</p></div></div>
  <input type="checkbox" id="fp-9" class="rd-cb"><label for="fp-9" style="margin-top:10px; font-size:11px; color:#2563EB; font-weight:600; cursor:pointer; display:block;">&#9660; 11 papers in this front</label><div class="rd-content"><ul style="margin:4px 0 0; padding:0; border-top:1px solid #E1E4E8;"><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2507.10614" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Fine-tuning Large Language Model for Automated Algorithm Design</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2025-07</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2411.17404" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2024-11</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2505.10117" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Learning Virtual Machine Scheduling in Cloud Computing through Language Agents</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:8</span> <span style="color:#6B7280; font-size:10px;">· 2025-05</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2508.11850" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:9</span> <span style="color:#6B7280; font-size:10px;">· 2025-08</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2502.14760" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2025-02</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2508.03117" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation</a> <span style="color:#6B7280; font-size:10px;">M:6</span> <span style="color:#6B7280; font-size:10px;">· 2025-08</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2507.11737" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Auto-Formulating Dynamic Programming Problems with Large Language Models</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:8</span> <span style="color:#6B7280; font-size:10px;">· 2025-07</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2510.16916" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:8</span> <span style="color:#6B7280; font-size:10px;">· 2025-10</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2602.02029" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2026-02</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2403.01131" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2024-03</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2410.22296" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Generalists vs. Specialists: Evaluating LLMs on Highly-Constrained Biophysical Sequence Optimization Tasks</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:8</span> <span style="color:#6B7280; font-size:10px;">· 2024-10</span></li></ul></div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">Self-Improving LLM Agents for Iterative OR Program Synthesis</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 0.42</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">10 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_evaluator</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_in_the_loop</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_heuristic</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">program_synthesis</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Huawei Noah’s Ark. 20% &nbsp;·&nbsp; Zhejiang University 20% &nbsp;·&nbsp; Shanghai Jiao Tong. 10% &nbsp;·&nbsp; Xi'an Jiaotong University 10%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front focuses on developing advanced LLM-powered frameworks for robust optimization modeling and program synthesis in Operations Research. Central to these efforts are iterative generation, evaluation, and refinement mechanisms, moving beyond simple prompting. Key approaches include generative process supervision (StepORLM), multi-agent systems with adaptive revision (MIRROR, OptimAI, DAOpt), self-improving experience libraries (AlphaOPT), semantic verification (SAC-Opt), and grammar-aware generation with compiler feedback (SyntAGM). The overarching goal is to reliably translate complex natural language OR problems into executable mathematical programming code.</p><input type="checkbox" id="fs-0" class="rd-cb"><label for="fs-0" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:11px; display:block; margin-top:6px;">&#9660; Read full analysis</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;"><p style="margin:8px 0 0;">Significant contributions include StepORLM's Generative Process Reward Models, achieving a +29.6% Pass@1 accuracy over GPT-4o on NL4Opt. MIRROR's multi-agent framework, using Hierarchical RAG and structured revision tips, improved Macro Avg by +3.68% over Chain-of-Experts. AlphaOPT's 'Library Evolution' mechanism, which refines applicability conditions, boosted performance by +13.6% on OptiBench. SAC-Opt demonstrated ~22% accuracy improvement on ComplexLP via backward-guided semantic verification. OptimAI introduced UCB-based debug scheduling, reducing NLP4LP error rates by 58%. SyntAGM achieved 61.6% accuracy on NL4Opt using compiler-in-the-loop grammar enforcement, while DAOpt integrated LLMs with RSOME for robust optimization, achieving >70% out-of-sample feasibility. CALM enabled a 4B model to match DeepSeek-R1 on OR benchmarks through corrective adaptation. A critical survey highlighted significant error rates in existing benchmarks (16-54%) and the ineffectiveness of Chain-of-Thought for symbolic formulation, while DCP-Bench-Open introduced 'Multi-Instance Accuracy' to address LLM overfitting to example data.</p><p style="margin:8px 0 0;">This front is rapidly maturing, with a clear trajectory towards more autonomous, verifiable, and adaptive LLM agents for OR. Future work will likely emphasize integrating deeper OR domain knowledge, scaling to real-world industrial problems, and enhancing explainability. The focus is shifting from merely generating code to building systems that can intelligently debug, verify, and continually improve their modeling capabilities, moving towards human-level proficiency in complex OR problem formulation.</p></div></div>
  <input type="checkbox" id="fp-0" class="rd-cb"><label for="fp-0" style="margin-top:10px; font-size:11px; color:#2563EB; font-weight:600; cursor:pointer; display:block;">&#9660; 10 papers in this front</label><div class="rd-content"><ul style="margin:4px 0 0; padding:0; border-top:1px solid #E1E4E8;"><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2509.22558" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:9</span> <span style="color:#6B7280; font-size:10px;">· 2025-09</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2602.03318" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research</a> <span style="color:#6B7280; font-size:10px;">M:5</span> <span style="color:#6B7280; font-size:10px;">· 2026-02</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2510.18428" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:8</span> <span style="color:#6B7280; font-size:10px;">· 2025-10</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2510.05115" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">SAC-Opt: Semantic Anchors for Iterative Correction in Optimization Modeling</a> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2025-09</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2504.16918" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents</a> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2025-04</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2601.17670" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Grammar-Aware Literate Generative Mathematical Programming with Compiler-in-the-Loop</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2026-01</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2511.11576" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">DAOpt: Modeling and Evaluation of Data-Driven Optimization under Uncertainty with LLMs</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:6</span> <span style="color:#6B7280; font-size:10px;">· 2025-09</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2508.10047" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:5</span> <span style="color:#6B7280; font-size:10px;">· 2024-08</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2510.04204" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:8</span> <span style="color:#6B7280; font-size:10px;">· 2025-10</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2506.06052" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">DCP-Bench-Open: Evaluating LLMs for Constraint Modelling of Discrete Combinatorial Problems</a> <span style="color:#6B7280; font-size:10px;">M:5</span> <span style="color:#6B7280; font-size:10px;">· 2025-06</span></li></ul></div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">Agentic LLM Frameworks for Robust OR Model Synthesis and Validation</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 0.36</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">9 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_in_the_loop</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_heuristic</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">program_synthesis</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">iterative_refinement</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Carnegie Mellon University 22% &nbsp;·&nbsp; IBM Research 11% &nbsp;·&nbsp; Stanford University 11% &nbsp;·&nbsp; Peking University 11%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front centers on the development of agentic LLM frameworks for automating various aspects of Operations Research, primarily focusing on robust optimization model synthesis and the design of novel heuristics. Key frameworks like NEMO, CP-Agent, and HeuriGym leverage LLMs to generate and iteratively refine optimization models (e.g., MiniZinc, CPMpy) and heuristic algorithms for complex combinatorial problems such as Flexible Job Shop Scheduling and various routing tasks. A significant unifying theme is the use of iterative, execution-aware feedback loops and agentic workflows to enhance the reliability and performance of LLM-generated OR artifacts.</p><input type="checkbox" id="fs-2" class="rd-cb"><label for="fs-2" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:11px; display:block; margin-top:6px;">&#9660; Read full analysis</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;"><p style="margin:8px 0 0;">Notable contributions include Zadorojniy et al.'s multi-agent framework for automatic validation of optimization models, achieving 76% mutation coverage on NLP4LP. Szeider's CP-Agent demonstrates 100% accuracy on a clarified CP-Bench for CPMpy model generation, highlighting the power of persistent IPython kernels and iterative refinement. NEMO (2601.21372) achieves SOTA on 8/9 optimization benchmarks by employing an asymmetric simulator-optimizer validation loop, outperforming fine-tuned models by up to 28%. Forniés-Tabuenca et al.'s REMoH introduces a reflection mechanism with phenotypic clustering for multi-objective FJSSP, improving Pareto front diversity. Benchmarks like HeuriGym and CO-Bench are established to rigorously evaluate LLM-crafted heuristics, revealing that current SOTA LLMs saturate at ~60% of expert performance and highlighting challenges in handling context fragmentation and strict feasibility constraints.</p><p style="margin:8px 0 0;">This front is rapidly maturing, characterized by a shift from basic LLM prompting to sophisticated agentic workflows with robust validation mechanisms. The emphasis on execution-aware feedback, mutation testing, and simulator-optimizer loops signifies a move towards more reliable and verifiable LLM-generated OR solutions. The next wave of papers will likely focus on improving the computational efficiency of these agentic frameworks, scaling them to larger and more complex real-world problems, and integrating them with formal verification tools to address theoretical guarantees, pushing beyond empirical performance to provable correctness.</p></div></div>
  <input type="checkbox" id="fp-2" class="rd-cb"><label for="fp-2" style="margin-top:10px; font-size:11px; color:#2563EB; font-weight:600; cursor:pointer; display:block;">&#9660; 9 papers in this front</label><div class="rd-content"><ul style="margin:4px 0 0; padding:0; border-top:1px solid #E1E4E8;"><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2511.16383" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">An Agent-Based Framework for the Automatic Validation of Mathematical Optimization Models</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2025-11</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2508.14544" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Adaptively Robust LLM Inference Optimization under Prediction Uncertainty</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2025-08</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2508.07468" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">CP-Agent: Agentic Constraint Programming</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:5</span> <span style="color:#6B7280; font-size:10px;">· 2025-08</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2506.07759" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">REMoH: A Reflective Evolution of Multi-objective Heuristics approach via Large Language Models</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2025-06</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2503.10642" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Text2Zinc: A Cross-Domain Dataset for Modeling Optimization and Satisfaction Problems in MiniZinc</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:3</span> <span style="color:#6B7280; font-size:10px;">· 2025-02</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2505.04354" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows</a> <span style="color:#6B7280; font-size:10px;">M:5</span> <span style="color:#6B7280; font-size:10px;">· 2025-05</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2506.07972" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:5</span> <span style="color:#6B7280; font-size:10px;">· 2025-06</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2601.21372" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">NEMO: Execution-Aware Optimization Modeling via Autonomous Coding Agents</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:9</span> <span style="color:#6B7280; font-size:10px;">· 2026-01</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2504.04310" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">CO-Bench: Benchmarking Language Model Agents in Algorithm Search for Combinatorial Optimization</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:4</span> <span style="color:#6B7280; font-size:10px;">· 2025-04</span></li></ul></div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">LLM-Driven Optimization Model Synthesis with Symbolic Pruning and Graph-Theoretic Verification</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 0.89</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">8 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_in_the_loop</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_evaluator</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_heuristic</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_fine_tuned</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Stanford University 25% &nbsp;·&nbsp; Ant Group 12% &nbsp;·&nbsp; East China Normal. 12% &nbsp;·&nbsp; Nanjing University 12%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front centers on advancing automated optimization modeling through Large Language Models (LLMs). It explores LLM-driven synthesis of mathematical optimization models from natural language descriptions, novel data generation techniques like ReSocratic and OptMATH, and innovative structural evaluation methods such as ORGEval. Key frameworks include LLMOPT, SIRL, OptiMUS, and Autoformulator, all aiming to improve the accuracy and scalability of translating real-world problems into solvable optimization programs.</p><input type="checkbox" id="fs-15" class="rd-cb"><label for="fs-15" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:11px; display:block; margin-top:6px;">&#9660; Read full analysis</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;"><p style="margin:8px 0 0;">Key contributions include LLMOPT's multi-instruction supervised fine-tuning with KTO for universal problem definition, achieving a 19.8% SA improvement over ORLM. SIRL introduces Reinforcement Learning with Verifiable Reward (RLVR) and a Partial KL surrogate, boosting Macro AVG by 3.3% for DeepSeek-V3.1. OptiMUS, a multi-agent system, uses a 'Connection Graph' to achieve up to 57.2% higher accuracy on ComplexOR. ORGEval provides a graph-theoretic evaluation framework using the Weisfeiler-Lehman test, achieving 100% consistency with solver-based methods in seconds. ReSocratic and OptMATH introduce novel data synthesis pipelines (Formal Model -> Code -> NL Question and solver-verified reverse generation, respectively), significantly improving LLM performance on benchmarks like OPTIBENCH (Llama-3-8B from 13.6% to 51.1%). The Autoformulator combines LLMs with Monte-Carlo Tree Search and SMT-based symbolic pruning, outperforming OptiMUS by 13.82% on NL4OPT.</p><p style="margin:8px 0 0;">This front is rapidly emerging, characterized by a shift towards more robust, verifiable, and scalable methods for optimization model synthesis. Future work will likely focus on integrating advanced symbolic reasoning (e.g., SMT-based pruning) with reinforcement learning for LLM fine-tuning, leveraging large-scale, synthetically generated, and structurally validated datasets. The next generation of papers will aim for higher reliability and interpretability in LLM-generated models, possibly by incorporating multi-modal problem inputs and human-in-the-loop feedback.</p></div></div>
  <input type="checkbox" id="fp-15" class="rd-cb"><label for="fp-15" style="margin-top:10px; font-size:11px; color:#2563EB; font-weight:600; cursor:pointer; display:block;">&#9660; 8 papers in this front</label><div class="rd-content"><ul style="margin:4px 0 0; padding:0; border-top:1px solid #E1E4E8;"><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2410.13213" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch</a> <span style="color:#6B7280; font-size:10px;">M:5</span> <span style="color:#6B7280; font-size:10px;">· 2024-10</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2505.11792" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:9</span> <span style="color:#6B7280; font-size:10px;">· 2025-05</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2402.10172" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">OptiMUS: Scalable Optimization Modeling with (MI)LP Solvers and Large Language Models</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2024-02</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2510.27610" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:8</span> <span style="color:#6B7280; font-size:10px;">· 2025-10</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2407.09887" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:6</span> <span style="color:#6B7280; font-size:10px;">· 2024-07</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2411.01679" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Autoformulation of Mathematical Optimization Models Using LLMs</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:8</span> <span style="color:#6B7280; font-size:10px;">· 2024-11</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2407.19633" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">OptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2024-07</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2502.11102" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">OptMATH: A Scalable Bidirectional Data Synthesis Framework for Optimization Modeling</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2025-02</span></li></ul></div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">Solver-Independent and Expert-Guided LLM Optimization Problem Formulation</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 1.00</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">2 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_evaluator</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">supervised_learning</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_fine_tuned</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">synthetic_data_generation</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Xidian University 50% &nbsp;·&nbsp; Victoria University of. 50% &nbsp;·&nbsp; Westlake University 50% &nbsp;·&nbsp; Microsoft Research 50%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front explores advanced methods for fine-tuning Large Language Models (LLMs) to automatically formulate optimization problems from natural language descriptions. Paper [1] introduces APF (Automated Problem Formulation), a solver-independent framework specifically designed for high-cost simulation-driven design, exemplified by antenna design. Paper [2] presents OptiMind, which focuses on integrating optimization expertise and rigorous benchmark auditing to enhance LLM accuracy in Mixed-Integer Linear Programming (MILP) formulation. Both works aim to improve the reliability and domain-specificity of LLM-generated optimization models.</p><input type="checkbox" id="fs-10" class="rd-cb"><label for="fs-10" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:11px; display:block; margin-top:6px;">&#9660; Read full analysis</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;"><p style="margin:8px 0 0;">Key contributions include APF's novel approach to synthetic data generation via data augmentation and LLM-based test instance annotation, achieving +4.58% to +13.25% higher alignment scores compared to GPT-4o on antenna design tasks. Crucially, APF proposes a 'solver-independent' evaluation metric using LLM-predicted rankings to replace expensive ground-truth simulations. OptiMind, on the other hand, fine-tunes a 20B-parameter LLM on a meticulously cleaned dataset, integrating class-specific error analysis and multi-turn self-correction, leading to accuracy improvements of +2.7% to +23% on benchmarks like IndustryOR and OptMATH. A significant finding from OptiMind is the revelation that 30-50% of instances in these standard benchmarks are flawed.</p><p style="margin:8px 0 0;">This front is emerging, demonstrating sophisticated techniques for leveraging LLMs in automated optimization modeling. The emphasis on robust data generation (synthetic data, benchmark cleaning) and the integration of expert knowledge (error-aware prompting, solver-independent evaluation) signals a trajectory towards more reliable and domain-specific LLM applications. Future work will likely focus on extending these frameworks to broader engineering domains, addressing computational limitations, and tackling more complex problem types.</p></div></div>
  <input type="checkbox" id="fp-10" class="rd-cb"><label for="fp-10" style="margin-top:10px; font-size:11px; color:#2563EB; font-weight:600; cursor:pointer; display:block;">&#9660; 2 papers in this front</label><div class="rd-content"><ul style="margin:4px 0 0; padding:0; border-top:1px solid #E1E4E8;"><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2512.18682" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Solver-Independent Automated Problem Formulation via LLMs for High-Cost Simulation-Driven Design</a> <span style="color:#6B7280; font-size:10px;">M:7</span> <span style="color:#6B7280; font-size:10px;">· 2025-12</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2509.22979" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">OptiMind: Teaching LLMs to Think Like Optimization Experts</a> <span style="background:#059669; color:white; padding:1px 6px; border-radius:999px; font-size:9px; font-weight:700;">★</span> <span style="color:#6B7280; font-size:10px;">M:5</span> <span style="color:#6B7280; font-size:10px;">· 2025-09</span></li></ul></div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">Hierarchical RAG and Multi-Agent LLMs for Optimization Model Synthesis</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 1.00</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">2 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_in_the_loop</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">retrieval_augmented_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">hierarchical_chunking</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">metadata_augmented_indexing</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Queen's University 50% &nbsp;·&nbsp; University of Southern. 50% &nbsp;·&nbsp; Brown University 50% &nbsp;·&nbsp; Fidelity Investments 50%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front focuses on leveraging advanced LLM architectures, specifically Retrieval-Augmented Generation (RAG) and multi-agent systems, for the automated synthesis of optimization models from natural language descriptions. CHORUS introduces a RAG framework with hierarchical retrieval and metadata-augmented indexing for generating Linear Programming (LP) code (e.g., Gurobi). GALA proposes a multi-agent LLM framework for text-to-MiniZinc translation, specializing agents in detecting and assembling global Constraint Programming (CP) constraints.</p><input type="checkbox" id="fs-12" class="rd-cb"><label for="fs-12" style="color:#2563EB; cursor:pointer; font-weight:600; font-size:11px; display:block; margin-top:6px;">&#9660; Read full analysis</label><div class="rd-content" style="padding-top:8px; border-top:1px solid #E1E4E8; margin-top:6px;"><p style="margin:8px 0 0;">CHORUS significantly improves LP code generation accuracy, achieving a +147.9% increase for Llama3.3 (70B) on the NL4Opt-Code dataset, by using a novel metadata-augmented indexing strategy that bridges the semantic gap between natural language and solver APIs. GALA demonstrates the effectiveness of decomposing complex translation tasks into primitive-specific agents, showing a modest improvement in execution rate (57% vs 52% with o3-mini) over Chain-of-Thought on the TEXT2ZINC benchmark for MiniZinc model generation. Both approaches highlight the power of structured LLM interaction and specialized knowledge retrieval/processing for robust program synthesis in optimization.</p><p style="margin:8px 0 0;">This front is emerging, demonstrating early successes in applying sophisticated LLM architectures to the challenging domain of automated optimization modeling. The trajectory suggests a move towards more structured, agentic, and knowledge-augmented LLM systems that can better understand and formalize complex problem descriptions into executable optimization models. The likely next paper will focus on integrating these architectural innovations, perhaps combining advanced retrieval with multi-agent reasoning, or extending them to more complex problem types and solver paradigms beyond LP and CP.</p></div></div>
  <input type="checkbox" id="fp-12" class="rd-cb"><label for="fp-12" style="margin-top:10px; font-size:11px; color:#2563EB; font-weight:600; cursor:pointer; display:block;">&#9660; 2 papers in this front</label><div class="rd-content"><ul style="margin:4px 0 0; padding:0; border-top:1px solid #E1E4E8;"><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2505.01485" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">CHORUS: Zero-shot Hierarchical Retrieval and Orchestration for Generating Linear Programming Code</a> <span style="color:#6B7280; font-size:10px;">M:5</span> <span style="color:#6B7280; font-size:10px;">· 2025-05</span></li><li style="padding:5px 0; border-bottom:1px solid #E1E4E8; list-style:none;"><a href="https://arxiv.org/abs/2509.08970" style="color:#2563EB; text-decoration:none; font-size:12px; font-weight:500;">Gala: Global LLM Agents for Text-to-Model Translation</a> <span style="color:#6B7280; font-size:10px;">M:5</span> <span style="color:#6B7280; font-size:10px;">· 2025-09</span></li></ul></div>
</td></tr><tr><td style="padding:20px 24px 12px; border-top:2px solid #F8F9FB; background:#FAFBFC;">
  <h2 style="margin:0; font-size:15px; font-weight:700; color:#1F2937; text-transform:uppercase; letter-spacing:0.03em;">Cross-Front Bridge Papers</h2>
  <p style="margin:4px 0 0; font-size:11px; color:#6B7280; font-weight:500;">5 papers connecting multiple research fronts</p>
</td></tr><tr><td style="padding:14px 24px; border-bottom:1px solid #E1E4E8;">
  <div style="margin-bottom:6px;">
    <a href="https://arxiv.org/abs/2502.14760" style="color:#1F2937; text-decoration:none; font-weight:600; font-size:14px; letter-spacing:-0.01em;">EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations</a>
  </div>
  <div style="margin-bottom:6px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; text-transform:uppercase;">TRUE SYNTHESIS</span> <span style="background:#F8F9FB; color:#6B7280; padding:3px 10px; border-radius:999px; font-size:10px;">Front 9 → Front 15, Front 0, Front 2</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-02-20 · 2502.14760
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.5;">
    Zhai et al. propose EquivaMap, a framework that evaluates whether two MILP formulations are equivalent by using an LLM to discover a linear mapping between their decision variables, which is then rigo...
  </div>
</td></tr><tr><td style="padding:14px 24px; border-bottom:1px solid #E1E4E8;">
  <div style="margin-bottom:6px;">
    <a href="https://arxiv.org/abs/2403.01131" style="color:#1F2937; text-decoration:none; font-weight:600; font-size:14px; letter-spacing:-0.01em;">LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation</a>
  </div>
  <div style="margin-bottom:6px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; text-transform:uppercase;">TRUE SYNTHESIS</span> <span style="background:#F8F9FB; color:#6B7280; padding:3px 10px; border-radius:999px; font-size:10px;">Front 9 → Front 15, Front 0, Front 2</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2024-03-02 · 2403.01131
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.5;">
    LLaMoCo fine-tunes small LLMs (down to 350M) to generate executable Python optimization code by training on a synthetic dataset where the 'ground truth' is the empirically best-performing solver ident...
  </div>
</td></tr><tr><td style="padding:14px 24px; border-bottom:1px solid #E1E4E8;">
  <div style="margin-bottom:6px;">
    <a href="https://arxiv.org/abs/2506.06052" style="color:#1F2937; text-decoration:none; font-weight:600; font-size:14px; letter-spacing:-0.01em;">DCP-Bench-Open: Evaluating LLMs for Constraint Modelling of Discrete Combinatorial Problems</a>
  </div>
  <div style="margin-bottom:6px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; text-transform:uppercase;">TRUE SYNTHESIS</span> <span style="background:#F8F9FB; color:#6B7280; padding:3px 10px; border-radius:999px; font-size:10px;">Front 0 → Front 2, Front 15, Front 9</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-06-06 · 2506.06052
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.5;">
    This paper introduces DCP-Bench-Open, a benchmark of 164 discrete combinatorial problems, to evaluate LLMs on translating natural language into constraint models (CPMpy, MiniZinc, OR-Tools). The resul...
  </div>
</td></tr><tr><td style="padding:14px 24px; border-bottom:1px solid #E1E4E8;">
  <div style="margin-bottom:6px;">
    <a href="https://arxiv.org/abs/2508.10047" style="color:#1F2937; text-decoration:none; font-weight:600; font-size:14px; letter-spacing:-0.01em;">A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions</a>
  </div>
  <div style="margin-bottom:6px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; text-transform:uppercase;">TRUE SYNTHESIS</span> <span style="background:#F8F9FB; color:#6B7280; padding:3px 10px; border-radius:999px; font-size:10px;">Front 0 → Front 15, Front 9, Front 2</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2024-08-01 · 2508.10047
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.5;">
    This survey and empirical audit reveals that standard optimization modeling benchmarks (NL4Opt, IndustryOR) suffer from critical error rates ranging from 16% to 54%, rendering prior leaderboards unrel...
  </div>
</td></tr><tr><td style="padding:14px 24px; border-bottom:1px solid #E1E4E8;">
  <div style="margin-bottom:6px;">
    <a href="https://arxiv.org/abs/2507.11737" style="color:#1F2937; text-decoration:none; font-weight:600; font-size:14px; letter-spacing:-0.01em;">Auto-Formulating Dynamic Programming Problems with Large Language Models</a>
  </div>
  <div style="margin-bottom:6px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; text-transform:uppercase;">TRUE SYNTHESIS</span> <span style="background:#F8F9FB; color:#6B7280; padding:3px 10px; border-radius:999px; font-size:10px;">Front 9 → Front 15, Front 0</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-07-15 · 2507.11737
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.5;">
    Zhou et al. introduce DPLM, a 7B model fine-tuned to formulate Dynamic Programming models, achieving performance comparable to o1 on their new DP-Bench. Their key contribution is 'DualReflect,' a synt...
  </div>
</td></tr><tr><td style="padding:20px 24px 12px; border-top:2px solid #F8F9FB; background:#FAFBFC;">
  <h2 style="margin:0; font-size:15px; font-weight:700; color:#1F2937; text-transform:uppercase; letter-spacing:0.03em;">Framework Genealogy</h2>
  <p style="margin:4px 0 0; font-size:11px; color:#6B7280; font-weight:500;">Tracking research lineages and framework evolution</p>
</td></tr><tr><td style="padding:0;">
<div style="padding:12px 24px; background:#F8F9FB; border-radius:12px 12px 0 0; border:1px solid #E1E4E8; border-bottom:none;">
  <div style="font-size:11px; color:#1F2937;">
    <b>27</b> frameworks tracked · <b>27</b> root frameworks · <b>3</b> active (last 30 days)
  </div>
</div>
<div style="padding:16px 24px; background:#FFFFFF; text-align:center; border:1px solid #E1E4E8; border-top:none; border-radius:0 0 12px 12px;">
  <div style="font-size:10px; margin-bottom:10px; color:#6B7280; text-transform:uppercase; letter-spacing:0.03em;">Framework landscape (size = paper count, color = must-read ratio)</div>
  <div style="font-size:12px;">optimus (2 papers, 1 must-read) • funsearch (2 papers, 2 must-read) • chain_of_experts (1 papers, 0 must-read) • proopf (1 papers, 0 must-read) • nemo (1 papers, 1 must-read) • mind (1 papers, 1 must-read) • apf (1 papers, 0 must-read) • llm_driven_meta_optimizer (1 papers, 1 must-read) • wl_test_for_milp_graphs (1 papers, 1 must-read) • autoformulation (1 papers, 1 must-read)</div>
  <div style="margin-top:10px; font-size:9px; color:#6B7280;">
    <span style="color:#1A5F7A;">■</span> Active + Must-read &nbsp;
    <span style="color:#64B5CD;">■</span> Active &nbsp;
    <span style="color:#2E7D32;">■</span> Inactive + Must-read &nbsp;
    <span style="color:#A5D6A7;">■</span> Inactive
  </div>
</div>
</td></tr></table>
</td></tr>
<tr><td style="background:#FAFBFC; padding:20px 24px; border-top:1px solid #E1E4E8; border-radius:0 0 16px 16px; text-align:center;">
<p style="margin:0 0 12px; font-size:11px; color:#6B7280; font-weight:500;">Curated by Research Intelligence System</p>
<table cellpadding="0" cellspacing="0" role="presentation" style="margin:0 auto;">
<tr>
<td style="border-radius:12px; background:#2563EB;">
<a href="#" style="display:inline-block; padding:10px 20px; font-size:12px; font-weight:700; color:#FFFFFF; text-decoration:none; border-radius:12px;">View Full Archive →</a>
</td>
</tr>
</table>
</td></tr>
</table>
</td></tr>
</table>
</body>
</html>