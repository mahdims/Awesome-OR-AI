<!DOCTYPE html>
<html>
<head><meta charset="utf-8"><title>Weekly Research Intelligence — Generative AI for OR</title>
</head>
<body style="margin:0; padding:0; background:#F5F7FA; font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Arial,sans-serif; color:#1F2937; font-size:14px; line-height:1.5;">
<div style="display:none; max-height:0; overflow:hidden; mso-hide:all; opacity:0; color:transparent;">Research Intelligence curated digest — Latest papers, research fronts, and framework evolution.</div>
<table width="100%" cellpadding="0" cellspacing="0" style="background:#F5F7FA;">
<tr><td align="center" style="padding:0;">
<table width="85%" cellpadding="0" cellspacing="0" style="width:85%;">

<tr><td style="background:linear-gradient(135deg, #1E3A8A 0%, #2563EB 100%); color:white; padding:20px 24px; border-radius:16px 16px 0 0;">
<table width="100%" cellpadding="0" cellspacing="0">
<tr>
<td style="width:48px; vertical-align:top;">
<div style="width:44px; height:44px; background:rgba(255,255,255,0.2); border-radius:12px; display:flex; align-items:center; justify-content:center; border:2px solid rgba(255,255,255,0.3);">
<span style="font-size:18px; font-weight:800; color:white; line-height:44px; text-align:center; display:block;">RI</span>
</div>
</td>
<td style="padding-left:14px; vertical-align:top;">
<h1 style="margin:0; font-size:20px; font-weight:700; letter-spacing:-0.01em; line-height:1.2;">Weekly Research Intelligence — Generative AI for OR</h1>
<p style="margin:4px 0 0; font-size:11px; opacity:0.85; font-weight:500;">Issue #8 of 2026 · 2026-02-18</p>
</td>
</tr>
</table>
</td></tr>
<tr><td style="background:#FFFFFF; padding:0;">
<table width="100%" cellpadding="0" cellspacing="0"><tr><td style="background:#FFFFFF; padding:20px 24px 12px;">
  <table width="100%" cellpadding="0" cellspacing="0" style="border:1px solid #E1E4E8; border-radius:14px; background:#FAFBFC;">
    <tr>
      <td style="padding:14px 18px; font-size:12px; color:#1F2937; font-weight:700; text-transform:uppercase; letter-spacing:0.03em; border-bottom:1px solid #E1E4E8;">
        This week at a glance
      </td>
    </tr>
    <tr>
      <td style="padding:0 18px 14px;">
        <table width="100%" cellpadding="0" cellspacing="0">
          <tr>
            <td style="width:33%; padding:12px 0; text-align:center;">
              <div style="font-size:24px; font-weight:800; color:#2563EB;">35</div>
              <div style="font-size:11px; color:#6B7280; text-transform:uppercase; letter-spacing:0.02em;">Must-reads</div>
            </td>
            <td style="width:33%; padding:12px 0; text-align:center; border-left:1px solid #E1E4E8; border-right:1px solid #E1E4E8;">
              <div style="font-size:24px; font-weight:800; color:#2563EB;">52</div>
              <div style="font-size:11px; color:#6B7280; text-transform:uppercase; letter-spacing:0.02em;">New papers</div>
            </td>
            <td style="width:33%; padding:12px 0; text-align:center;">
              <div style="font-size:24px; font-weight:800; color:#2563EB;">6</div>
              <div style="font-size:11px; color:#6B7280; text-transform:uppercase; letter-spacing:0.02em;">Active fronts</div>
            </td>
          </tr>
        </table>
        <div style="margin-top:10px; padding-top:10px; border-top:1px solid #E1E4E8; font-size:12px; color:#1F2937;">
          <b>This week's theme:</b> Concept-structured search is outperforming brute code mutation across multiple optimization domains.
        </div>
      </td>
    </tr>
  </table>
</td></tr><tr><td style="padding:20px 24px 12px; border-top:2px solid #F8F9FB; background:#FAFBFC;">
  <h2 style="margin:0; font-size:15px; font-weight:700; color:#1F2937; text-transform:uppercase; letter-spacing:0.03em;">Top Priority Papers</h2>
  <p style="margin:4px 0 0; font-size:11px; color:#6B7280; font-weight:500;">10 must-read papers this week (ranked by significance, recency, and impact)</p>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#1</span>
    <a href="https://arxiv.org/abs/2508.11850" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.8/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-08-16 | Huawei Technologies Canada, University of British Columbia, University of Toronto | <a href="https://arxiv.org/abs/2508.11850" style="color:#6B7280; text-decoration:none;">2508.11850</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=10</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=9</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Yazdani et al. introduce EvoCut, an evolutionary framework where LLMs generate Python code for MILP cuts, filtered by a 'usefulness check' (does it cut the current LP relaxation?) and an 'empirical validity check' (does it preserve known integer optima?). They report 17-57% gap reductions on TSPLIB and JSSP compared to Gurobi defaults, backed by strong ablation studies on the evolutionary operators. <strong>Key Takeaway:</strong> The reliance on 'acceleration cuts'—constraints verified empirically on small datasets rather than formally proven—bypasses the bottleneck of automated theorem proving while still delivering valid speedups. We should immediately adopt their 'LP separation' check as a cheap, high-signal reward for our own evolutionary search loops.
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#2</span>
    <a href="https://arxiv.org/abs/2601.21372" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">NEMO: Execution-Aware Optimization Modeling via Autonomous Coding Agents</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.6/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2026-01-29 | Carnegie Mellon University, C3 AI | <a href="https://arxiv.org/abs/2601.21372" style="color:#6B7280; text-decoration:none;">2601.21372</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=9</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    NEMO achieves SOTA on 8/9 optimization benchmarks by deploying autonomous coding agents that generate both a declarative optimizer (solver code) and an imperative simulator (verification code). The key innovation is using the simulator to validate the optimizer's results in a closed loop, detecting logical errors without ground truth—a technique that beats fine-tuned models like SIRL by up to 28%. The most stealable insight is this asymmetric validation: imperative Python simulation is often less error-prone than declarative constraint formulation, making it a robust 'critic' for generated solvers. This is immediately applicable to our OR-Bench and AlgoEvo projects for generating reliable reward signals.
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#3</span>
    <a href="https://arxiv.org/abs/2509.22558" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.3/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-09-26 | Shanghai Jiao Tong University | <a href="https://arxiv.org/abs/2509.22558" style="color:#6B7280; text-decoration:none;">2509.22558</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=9</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Zhou et al. propose StepORLM, a framework where an 8B policy and a <strong>Generative Process Reward Model (GenPRM)</strong> co-evolve. Unlike standard discriminative PRMs that score steps in isolation, their GenPRM generates a reasoning trace to evaluate the full trajectory's logic before assigning credit, addressing the interdependency of OR constraints. They align the policy using <strong>Weighted DPO</strong>, where preference weights are derived from the GenPRM's process scores. They claim to beat GPT-4o and DeepSeek-V3 on 6 OR benchmarks (e.g., NL4Opt, MAMO) with an 8B model. <strong>Key Takeaway:</strong> We should test <strong>Generative PRMs</strong> immediately for AlgoEvo; asking the critic to 'explain then score' (generative) rather than just 'score' (discriminative) likely fixes the credit assignment noise in our long-horizon search.
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#4</span>
    <a href="https://arxiv.org/abs/2505.11792" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">Solver-Informed RL: Grounding Large Language Models for Authentic Optimization Modeling</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.3/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-05-17 | Stanford University, Shanghai Jiao Tong University, The University of Hong Kong, Shanghai University of Finance and Economics, Cardinal Operations | <a href="https://arxiv.org/abs/2505.11792" style="color:#6B7280; text-decoration:none;">2505.11792</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=9</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Chen et al. introduce SIRL, a framework for training LLMs to generate optimization models using Reinforcement Learning with Verifiable Rewards (RLVR) and a novel 'Partial KL' surrogate objective. By removing the KL penalty from the reasoning (CoT) section while retaining it for the code generation section, they balance exploration with syntactic stability, achieving SOTA on OptMATH and IndustryOR against OpenAI-o3 and DeepSeek-R1. The critical takeaway for us is the Partial KL strategy: it allows the model to 'think' freely outside the reference distribution while adhering to strict coding standards—a technique we should immediately test in AlgoEvo. Furthermore, their method of parsing .lp files to extract structural features (variable counts, constraint types) for 'instance-enhanced self-consistency' provides a much richer signal than our current binary success/failure metrics.
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#5</span>
    <a href="https://arxiv.org/abs/2510.27610" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.1/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-10-31 | The Chinese University of Hong Kong, Shenzhen, Shenzhen Research Institute of Big Data, Shenzhen International Center for Industrial and Applied Mathematics, Shenzhen Loop Area Institute | <a href="https://arxiv.org/abs/2510.27610" style="color:#6B7280; text-decoration:none;">2510.27610</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=8</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Wang et al. propose ORGEval, a framework that evaluates LLM-generated optimization models by converting them into bipartite graphs and using the Weisfeiler-Lehman (WL) test to detect isomorphism with a ground truth, rather than solving the instances. They prove that for 'symmetric decomposable' graphs, this method is guaranteed to detect equivalence correctly, achieving 100% consistency and running in seconds compared to hours for solver-based checks on hard MIPLIB instances. The critical takeaway is the shift from execution-based to <strong>structural evaluation</strong>: we can validate model logic via graph topology ($O(k(m+n)^2)$) without incurring the cost of solving NP-hard problems. This is immediately actionable for our OR benchmarking pipelines and could serve as a rapid 'pre-solve' filter in our evolutionary search loops to reject structurally invalid candidates instantly.
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#6</span>
    <a href="https://arxiv.org/abs/2510.18428" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.1/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-10-21 | Massachusetts Institute of Technology, London School of Economics and Political Science, University of Florida, Northeastern University, Singapore Management University, Singapore-MIT Alliance for Research and Technology | <a href="https://arxiv.org/abs/2510.18428" style="color:#6B7280; text-decoration:none;">2510.18428</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=8</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    AlphaOPT introduces a 'Library Evolution' mechanism that iteratively refines the <em>applicability conditions</em> of cached optimization insights based on solver feedback, allowing it to learn from answers alone (no gold programs). On OOD benchmarks like OptiBench, it beats fine-tuned models (ORLM) by ~13% and shows consistent scaling with data size. <strong>Key Takeaway:</strong> The specific mechanism of diagnosing 'unretrieved' vs. 'negative' tasks to rewrite retrieval triggers is a transferable technique for our AlgoEvo memory; it solves the problem of heuristic misapplication in long-term search. We should implement this 'condition refinement' loop immediately to improve our multi-agent memory systems.
  </div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div style="margin-bottom:8px;">
    <span style="display:inline-block; background:#2563EB; color:white; padding:2px 10px; border-radius:12px; font-size:11px; font-weight:700; margin-right:8px;">#7</span>
    <a href="https://arxiv.org/abs/2510.04204" style="color:#1F2937; text-decoration:none; font-weight:700; font-size:16px; letter-spacing:-0.01em;">CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700;">PRIORITY 8.1/10</span> <span style="background:#DC2626; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600;">MUST-READ</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-10-05 | Qwen Team, Alibaba Inc., The Chinese University of Hong Kong, Shenzhen, Southern University of Science and Technology, Shanghai University of Finance and Economics, Shenzhen Loop Area Institute (SLAI) | <a href="https://arxiv.org/abs/2510.04204" style="color:#6B7280; text-decoration:none;">2510.04204</a>
  </div>
  <div style="margin-bottom:8px;">
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">M=8</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px; margin-right:4px;">P=9</span>
    <span style="background:#F8F9FB; color:#6B7280; padding:2px 8px; border-radius:999px; font-weight:600; font-size:10px;">I=8</span>
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.6; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #2563EB;">
    Tang et al. propose CALM, a framework that uses an expert 'Intervener' model to inject corrective hints into a small LRM's reasoning trace (e.g., forcing it to use Python instead of manual calculation), followed by SFT and RL (GRPO). Results are strong and verified: a 4B model matches DeepSeek-R1 (671B) on OR benchmarks, specifically fixing the 'Code Utilization Distrust' we see in our own agents. The key takeaway is the 'Intervener' loop: instead of discarding failed traces, they repair them with hints to create a 'golden' reasoning dataset that preserves the 'thinking' process while enforcing tool use. This is a direct, actionable method for improving our AlgoEvo agents' reliability in generating executable heuristics without massive human annotation.
  </div>
</td></tr><tr><td style="padding:20px 24px 12px; border-top:2px solid #F8F9FB; background:#FAFBFC;">
  <h2 style="margin:0; font-size:15px; font-weight:700; color:#1F2937; text-transform:uppercase; letter-spacing:0.03em;">Research Front Landscape</h2>
  <p style="margin:4px 0 0; font-size:11px; color:#6B7280; font-weight:500;">6 active fronts | 52 new papers</p>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">Self-Improving LLM Agents for Iterative OR Program Synthesis</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 0.51</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">11 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_in_the_loop</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">program_synthesis</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_heuristic</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_evaluator</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Shanghai Jiao Tong. 18% &nbsp;·&nbsp; Genentech 9% &nbsp;·&nbsp; New York University 9% &nbsp;·&nbsp; The Hong Kong. 9%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front focuses on developing advanced LLM-powered frameworks for robust optimization modeling and program synthesis in Operations Research. Central to these efforts are iterative generation, evaluation, and refinement mechanisms, moving beyond simple prompting. Key approaches include generative process supervision (StepORLM), multi-agent systems with adaptive revision (MIRROR, OptimAI, DAOpt), self-improving experience libraries (AlphaOPT), semantic verification (SAC-Opt), and grammar-aware generation with compiler feedback (SyntAGM). The overarching goal is to reliably translate complex natural language OR problems into executable mathematical programming code.</p><p style="margin:8px 0 0;">Significant contributions include StepORLM's Generative Process Reward Models, achieving a +29.6% Pass@1 accuracy over GPT-4o on NL4Opt. MIRROR's multi-agent framework, using Hierarchical RAG and structured revision tips, improved Macro Avg by +3.68% over Chain-of-Experts. AlphaOPT's 'Library Evolution' mechanism, which refines applicability conditions, boosted performance by +13.6% on OptiBench. SAC-Opt demonstrated ~22% accuracy improvement on ComplexLP via backward-guided semantic verification. OptimAI introduced UCB-based debug scheduling, reducing NLP4LP error rates by 58%. SyntAGM achieved 61.6% accuracy on NL4Opt using compiler-in-the-loop grammar enforcement, while DAOpt integrated LLMs with RSOME for robust optimization, achieving >70% out-of-sample feasibility. CALM enabled a 4B model to match DeepSeek-R1 on OR benchmarks through corrective adaptation. A critical survey highlighted significant error rates in existing benchmarks (16-54%) and the ineffectiveness of Chain-of-Thought for symbolic formulation, while DCP-Bench-Open introduced 'Multi-Instance Accuracy' to address LLM overfitting to example data.</p><p style="margin:8px 0 0;">This front is rapidly maturing, with a clear trajectory towards more autonomous, verifiable, and adaptive LLM agents for OR. Future work will likely emphasize integrating deeper OR domain knowledge, scaling to real-world industrial problems, and enhancing explainability. The focus is shifting from merely generating code to building systems that can intelligently debug, verify, and continually improve their modeling capabilities, moving towards human-level proficiency in complex OR problem formulation.</p></div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">Self-Improving LLM Frameworks for Robust Optimization Model Synthesis</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 0.47</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">11 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_evaluator</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_in_the_loop</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_heuristic</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">program_synthesis</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Zhejiang University 18% &nbsp;·&nbsp; Huawei Noah’s Ark. 18% &nbsp;·&nbsp; KU Leuven 9% &nbsp;·&nbsp; University of Western. 9%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front focuses on developing advanced LLM-driven frameworks for automated optimization modeling, specifically translating natural language problem descriptions into executable mathematical programming code (e.g., Gurobi, CPMpy, PyOPL). The unifying theme is the move beyond simple prompt engineering to sophisticated multi-agent architectures, self-correction mechanisms, and iterative refinement loops that enhance the accuracy, robustness, and reliability of generated optimization models across various problem domains, including discrete combinatorial problems, MILP, and data-driven optimization under uncertainty.</p><p style="margin:8px 0 0;">Key contributions include the introduction of novel benchmarks like DCP-Bench-Open for constraint modeling and OptU for data-driven optimization under uncertainty, alongside critical re-evaluations of existing datasets (NL4Opt, IndustryOR) to address high error rates. Methodologically, frameworks like CALM leverage corrective adaptation with lightweight modification and RL to achieve significant accuracy gains (e.g., +23.6% Macro AVG for GPT-3.5-Turbo). AlphaOPT introduces a self-improving experience library that refines applicability conditions, outperforming fine-tuned models by 13%. Multi-agent systems like OptiMUS-0.3 (achieving +40% accuracy on NLP4LP) and OptimAI (88.1% accuracy on NLP4LP with UCB-based debug scheduling) integrate connection graphs, structure detection, and adaptive debugging. SAC-Opt employs backward-guided semantic verification for a 22% accuracy improvement, while SyntAGM utilizes a compiler-in-the-loop with grammar-aware generation to match multi-agent systems in accuracy. StepORLM introduces a Generative Process Reward Model (GenPRM) and Weighted DPO, enabling an 8B model to surpass GPT-4o on several OR benchmarks, and DAOpt demonstrates robust modeling under uncertainty, achieving >70% out-of-sample feasibility compared to 27% for deterministic models.</p><p style="margin:8px 0 0;">This front is rapidly maturing, demonstrating a clear trajectory from basic LLM code generation to highly sophisticated, self-correcting, and domain-aware systems. The next wave of papers will likely focus on scaling these frameworks to tackle larger, more complex industrial-scale problems, integrating deeper OR domain knowledge through specialized DSLs or knowledge graphs, and enhancing the explainability and trustworthiness of the automated modeling process to facilitate real-world adoption.</p></div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">Agentic LLM Frameworks for Robust OR Model Synthesis and Validation</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 0.36</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">9 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_in_the_loop</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_heuristic</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">program_synthesis</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">iterative_refinement</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Carnegie Mellon University 22% &nbsp;·&nbsp; University of Minnesota 11% &nbsp;·&nbsp; Tongji University 11% &nbsp;·&nbsp; East China Normal. 11%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front centers on the development of agentic LLM frameworks for automating various aspects of Operations Research, primarily focusing on robust optimization model synthesis and the design of novel heuristics. Key frameworks like NEMO, CP-Agent, and HeuriGym leverage LLMs to generate and iteratively refine optimization models (e.g., MiniZinc, CPMpy) and heuristic algorithms for complex combinatorial problems such as Flexible Job Shop Scheduling and various routing tasks. A significant unifying theme is the use of iterative, execution-aware feedback loops and agentic workflows to enhance the reliability and performance of LLM-generated OR artifacts.</p><p style="margin:8px 0 0;">Notable contributions include Zadorojniy et al.'s multi-agent framework for automatic validation of optimization models, achieving 76% mutation coverage on NLP4LP. Szeider's CP-Agent demonstrates 100% accuracy on a clarified CP-Bench for CPMpy model generation, highlighting the power of persistent IPython kernels and iterative refinement. NEMO (2601.21372) achieves SOTA on 8/9 optimization benchmarks by employing an asymmetric simulator-optimizer validation loop, outperforming fine-tuned models by up to 28%. Forniés-Tabuenca et al.'s REMoH introduces a reflection mechanism with phenotypic clustering for multi-objective FJSSP, improving Pareto front diversity. Benchmarks like HeuriGym and CO-Bench are established to rigorously evaluate LLM-crafted heuristics, revealing that current SOTA LLMs saturate at ~60% of expert performance and highlighting challenges in handling context fragmentation and strict feasibility constraints.</p><p style="margin:8px 0 0;">This front is rapidly maturing, characterized by a shift from basic LLM prompting to sophisticated agentic workflows with robust validation mechanisms. The emphasis on execution-aware feedback, mutation testing, and simulator-optimizer loops signifies a move towards more reliable and verifiable LLM-generated OR solutions. The next wave of papers will likely focus on improving the computational efficiency of these agentic frameworks, scaling them to larger and more complex real-world problems, and integrating them with formal verification tools to address theoretical guarantees, pushing beyond empirical performance to provable correctness.</p></div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">LLM-Enhanced Optimization Modeling via SIRL, MCTS, and Graph-Theoretic Evaluation</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 0.90</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">7 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_in_the_loop</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_evaluator</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_heuristic</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_fine_tuned</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Stanford University 29% &nbsp;·&nbsp; Shanghai Jiao Tong. 14% &nbsp;·&nbsp; The University of. 14% &nbsp;·&nbsp; Shanghai University of. 14%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front focuses on advancing Large Language Models (LLMs) for automated optimization modeling, data synthesis, and rigorous evaluation. Key frameworks include Solver-Informed RL (SIRL) with a Partial KL strategy, LLM-enhanced Monte-Carlo Tree Search (MCTS) with symbolic pruning, modular multi-agent systems like OptiMUS using a Connection Graph, and graph-theoretic evaluation frameworks such as ORGEval. The unifying theme is to develop more robust, scalable, and verifiable methods for LLM-driven generation and refinement of optimization models, often leveraging structured intermediate representations or search processes.</p><p style="margin:8px 0 0;">Key contributions include SIRL's Reinforcement Learning with Verifiable Reward (RLVR) achieving +3.3% Macro AVG on benchmarks like NL4OPT, and LLMOPT's multi-instruction SFT and KTO yielding up to +19.8% SA improvement over ORLM. OptMATH and ReSocratic introduce scalable bidirectional data synthesis frameworks, with OptMATH-Qwen2.5-32B surpassing GPT-4 on NL4Opt. The Autoformulator integrates LLMs with MCTS and SMT-based symbolic pruning, outperforming ORLMLlama3-8B by up to +27.8% on ComplexOR. OptiMUS utilizes a modular multi-agent system with a Connection Graph for context management, achieving significant accuracy gains (e.g., +57.2% on ComplexOR). ORGEval provides a graph-theoretic evaluation using the Weisfeiler-Lehman test for model isomorphism, achieving 100% consistency with solver-based methods in seconds for hard MIPLIB instances.</p><p style="margin:8px 0 0;">This front is emerging and rapidly maturing, with a high density and stable status indicating active, high-impact research. The trajectory suggests a strong push towards integrating these diverse techniques, such as combining RL with symbolic pruning or incorporating graph-theoretic evaluation into RL reward functions. Future work will likely address current limitations like reward hacking, data scarcity for large-scale problems, and extending capabilities to non-linear or stochastic optimization, emphasizing reliable and generalizable LLM capabilities in Operations Research.</p></div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">Hierarchical RAG and Multi-Agent LLMs for Optimization Model Synthesis</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 1.00</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">2 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_in_the_loop</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">retrieval_augmented_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">hierarchical_chunking</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">metadata_augmented_indexing</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Queen's University 50% &nbsp;·&nbsp; University of Southern. 50% &nbsp;·&nbsp; Brown University 50% &nbsp;·&nbsp; Fidelity Investments 50%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front focuses on leveraging advanced LLM architectures, specifically Retrieval-Augmented Generation (RAG) and multi-agent systems, for the automated synthesis of optimization models from natural language descriptions. CHORUS introduces a RAG framework with hierarchical retrieval and metadata-augmented indexing for generating Linear Programming (LP) code (e.g., Gurobi). GALA proposes a multi-agent LLM framework for text-to-MiniZinc translation, specializing agents in detecting and assembling global Constraint Programming (CP) constraints.</p><p style="margin:8px 0 0;">CHORUS significantly improves LP code generation accuracy, achieving a +147.9% increase for Llama3.3 (70B) on the NL4Opt-Code dataset, by using a novel metadata-augmented indexing strategy that bridges the semantic gap between natural language and solver APIs. GALA demonstrates the effectiveness of decomposing complex translation tasks into primitive-specific agents, showing a modest improvement in execution rate (57% vs 52% with o3-mini) over Chain-of-Thought on the TEXT2ZINC benchmark for MiniZinc model generation. Both approaches highlight the power of structured LLM interaction and specialized knowledge retrieval/processing for robust program synthesis in optimization.</p><p style="margin:8px 0 0;">This front is emerging, demonstrating early successes in applying sophisticated LLM architectures to the challenging domain of automated optimization modeling. The trajectory suggests a move towards more structured, agentic, and knowledge-augmented LLM systems that can better understand and formalize complex problem descriptions into executable optimization models. The likely next paper will focus on integrating these architectural innovations, perhaps combining advanced retrieval with multi-agent reasoning, or extending them to more complex problem types and solver paradigms beyond LP and CP.</p></div>
</td></tr><tr><td style="padding:16px 24px; border-bottom:1px solid #E1E4E8; background:#FFFFFF;">
  <div>
    <h3 style="margin:0; font-size:16px; font-weight:700; color:#1F2937; letter-spacing:-0.01em;">LLM-Guided Search and Fine-Tuning for OR Model and Algorithm Synthesis</h3>
  </div>
  <div style="margin-top:8px; line-height:1.8;">
    <span style="background:#4F46E5; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:700; text-transform:uppercase; display:inline-block;">STABLE</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">Density: 1.00</span> <span style="background:#F8F9FB; color:#1F2937; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; display:inline-block;">2 papers</span>
  </div>
  <div style="margin-top:10px; line-height:1.8;"><span style="font-size:11px; color:#6B7280; font-weight:600; text-transform:uppercase; letter-spacing:0.02em; margin-right:6px;">Methods</span><span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_code_generation</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_as_evaluator</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">supervised_learning</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">llm_fine_tuned</span> <span style="display:inline-block; background:#F8F9FB; color:#2563EB; padding:3px 10px; border-radius:999px; margin:2px; font-size:10px; font-weight:600;">synthetic_data_generation</span></div>
  <div style="margin-top:6px; font-size:10px; color:#6B7280;"><span style="font-weight:700; text-transform:uppercase; letter-spacing:0.02em; margin-right:4px;">Inst:</span>Xidian University 50% &nbsp;·&nbsp; Victoria University of. 50% &nbsp;·&nbsp; Westlake University 50% &nbsp;·&nbsp; Microsoft Research 50%</div>
  <div style="margin-top:10px; font-size:13px; line-height:1.6; color:#1F2937; padding:12px; background:#F8F9FB; border-radius:12px; border-left:3px solid #4F46E5;"><p style="margin:0;">This research front focuses on advanced techniques for leveraging Large Language Models (LLMs) to automate and enhance Operations Research (OR) problem formulation and algorithm design. The core theme revolves around integrating LLMs into sophisticated search algorithms, employing specialized fine-tuning strategies with preference learning and synthetic data, and utilizing structured intermediate representations or hierarchical decomposition to improve the robustness, verifiability, and efficiency of generated OR solutions. Specific frameworks like BPP-Search, MiCo (FunSearch), EvoCut, SolverLLM, EquivaMap, DPLM (DualReflect), CIR, LLaMoCo, and LLOME (MargE) are central to these efforts.</p><p style="margin:8px 0 0;">Key contributions include Liu et al.'s DPO with Diversity-Aware Rank-based sampling, enabling a fine-tuned Llama-3.2-1B to match an 8B model on ASP and CVRP. LLaMoCo demonstrates that a 350M parameter model can significantly outperform GPT-4 in optimization code generation through instruction tuning. LLOME introduces the MargE loss function for stable and diverse fine-tuning in constrained optimization, outperforming DPO. In search, BPP-Search enhances Tree-of-Thought for mathematical modeling, while MiCo applies a hierarchical SMDP framework to VM scheduling, achieving an 11% improvement over Deep RL. EvoCut uses LLMs for MILP cut generation, yielding 17-57% gap reductions. SolverLLM introduces Prompt Backpropagation within MCTS for robust formulation. For verification and representation, EquivaMap achieves 100% accuracy in checking formulation equivalence, OptiTrust uses multi-language execution voting for verifiable synthetic data, and CIR introduces a Canonical Intermediate Representation, boosting accuracy to 47.2% on the ORCOpt-Bench.</p><p style="margin:8px 0 0;">This front is rapidly emerging and maturing, characterized by a strong emphasis on moving beyond generic LLM prompting towards highly specialized and verifiable integration. The trajectory indicates a clear focus on improving the reliability and performance of LLM-generated OR artifacts. Future work will likely concentrate on combining these advanced techniques, such as integrating MargE-style preference learning into MCTS or evolutionary search frameworks, and expanding CIR-like structured generation to encompass more complex, real-world OR problems, potentially with dynamic cut separation and formal proof systems.</p></div>
</td></tr><tr><td style="padding:20px 24px 12px; border-top:2px solid #F8F9FB; background:#FAFBFC;">
  <h2 style="margin:0; font-size:15px; font-weight:700; color:#1F2937; text-transform:uppercase; letter-spacing:0.03em;">Cross-Front Bridge Papers</h2>
  <p style="margin:4px 0 0; font-size:11px; color:#6B7280; font-weight:500;">5 papers connecting multiple research fronts</p>
</td></tr><tr><td style="padding:14px 24px; border-bottom:1px solid #E1E4E8;">
  <div style="margin-bottom:6px;">
    <a href="https://arxiv.org/abs/2502.14760" style="color:#1F2937; text-decoration:none; font-weight:600; font-size:14px; letter-spacing:-0.01em;">EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations</a>
  </div>
  <div style="margin-bottom:6px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; text-transform:uppercase;">TRUE SYNTHESIS</span> <span style="background:#F8F9FB; color:#6B7280; padding:3px 10px; border-radius:999px; font-size:10px;">Front 0 → Front 1, Front 14, Front 6</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-02-20 · 2502.14760
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.5;">
    Zhai et al. propose EquivaMap, a framework that evaluates whether two MILP formulations are equivalent by using an LLM to discover a linear mapping between their decision variables, which is then rigo...
  </div>
</td></tr><tr><td style="padding:14px 24px; border-bottom:1px solid #E1E4E8;">
  <div style="margin-bottom:6px;">
    <a href="https://arxiv.org/abs/2403.01131" style="color:#1F2937; text-decoration:none; font-weight:600; font-size:14px; letter-spacing:-0.01em;">LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation</a>
  </div>
  <div style="margin-bottom:6px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; text-transform:uppercase;">TRUE SYNTHESIS</span> <span style="background:#F8F9FB; color:#6B7280; padding:3px 10px; border-radius:999px; font-size:10px;">Front 0 → Front 1, Front 14, Front 6</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2024-03-02 · 2403.01131
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.5;">
    LLaMoCo fine-tunes small LLMs (down to 350M) to generate executable Python optimization code by training on a synthetic dataset where the 'ground truth' is the empirically best-performing solver ident...
  </div>
</td></tr><tr><td style="padding:14px 24px; border-bottom:1px solid #E1E4E8;">
  <div style="margin-bottom:6px;">
    <a href="https://arxiv.org/abs/2407.19633" style="color:#1F2937; text-decoration:none; font-weight:600; font-size:14px; letter-spacing:-0.01em;">OptiMUS-0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale</a>
  </div>
  <div style="margin-bottom:6px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; text-transform:uppercase;">TRUE SYNTHESIS</span> <span style="background:#F8F9FB; color:#6B7280; padding:3px 10px; border-radius:999px; font-size:10px;">Front 14 → Front 1, Front 0, Front 6</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2024-07-29 · 2407.19633
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.5;">
    OptiMUS-0.3 is a modular multi-agent system that translates natural language into Gurobi code, utilizing a 'connection graph' to manage variable-constraint relationships in long contexts and specializ...
  </div>
</td></tr><tr><td style="padding:14px 24px; border-bottom:1px solid #E1E4E8;">
  <div style="margin-bottom:6px;">
    <a href="https://arxiv.org/abs/2506.06052" style="color:#1F2937; text-decoration:none; font-weight:600; font-size:14px; letter-spacing:-0.01em;">DCP-Bench-Open: Evaluating LLMs for Constraint Modelling of Discrete Combinatorial Problems</a>
  </div>
  <div style="margin-bottom:6px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; text-transform:uppercase;">TRUE SYNTHESIS</span> <span style="background:#F8F9FB; color:#6B7280; padding:3px 10px; border-radius:999px; font-size:10px;">Front 14 → Front 6, Front 1, Front 0</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-06-06 · 2506.06052
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.5;">
    This paper introduces DCP-Bench-Open, a benchmark of 164 discrete combinatorial problems, to evaluate LLMs on translating natural language into constraint models (CPMpy, MiniZinc, OR-Tools). The resul...
  </div>
</td></tr><tr><td style="padding:14px 24px; border-bottom:1px solid #E1E4E8;">
  <div style="margin-bottom:6px;">
    <a href="https://arxiv.org/abs/2507.11737" style="color:#1F2937; text-decoration:none; font-weight:600; font-size:14px; letter-spacing:-0.01em;">Auto-Formulating Dynamic Programming Problems with Large Language Models</a>
  </div>
  <div style="margin-bottom:6px;">
    <span style="background:#059669; color:white; padding:4px 12px; border-radius:999px; font-size:10px; font-weight:600; text-transform:uppercase;">TRUE SYNTHESIS</span> <span style="background:#F8F9FB; color:#6B7280; padding:3px 10px; border-radius:999px; font-size:10px;">Front 0 → Front 1, Front 14</span>
  </div>
  <div style="margin-bottom:6px; font-size:11px; color:#6B7280;">
    2025-07-15 · 2507.11737
  </div>
  <div style="font-size:13px; color:#1F2937; line-height:1.5;">
    Zhou et al. introduce DPLM, a 7B model fine-tuned to formulate Dynamic Programming models, achieving performance comparable to o1 on their new DP-Bench. Their key contribution is 'DualReflect,' a synt...
  </div>
</td></tr><tr><td style="padding:20px 24px 12px; border-top:2px solid #F8F9FB; background:#FAFBFC;">
  <h2 style="margin:0; font-size:15px; font-weight:700; color:#1F2937; text-transform:uppercase; letter-spacing:0.03em;">Framework Genealogy</h2>
  <p style="margin:4px 0 0; font-size:11px; color:#6B7280; font-weight:500;">Tracking research lineages and framework evolution</p>
</td></tr><tr><td style="padding:0;">
<div style="padding:12px 24px; background:#F8F9FB; border-radius:12px 12px 0 0; border:1px solid #E1E4E8; border-bottom:none;">
  <div style="font-size:11px; color:#1F2937;">
    <b>27</b> frameworks tracked · <b>27</b> root frameworks · <b>3</b> active (last 30 days)
  </div>
</div>
<div style="padding:16px 24px; background:#FFFFFF; text-align:center; border:1px solid #E1E4E8; border-top:none; border-radius:0 0 12px 12px;">
  <div style="font-size:10px; margin-bottom:10px; color:#6B7280; text-transform:uppercase; letter-spacing:0.03em;">Framework landscape (size = paper count, color = must-read ratio)</div>
  <div style="font-size:12px;">optimus (2 papers, 1 must-read) • funsearch (2 papers, 2 must-read) • chain_of_experts (1 papers, 0 must-read) • proopf (1 papers, 0 must-read) • nemo (1 papers, 1 must-read) • mind (1 papers, 1 must-read) • apf (1 papers, 0 must-read) • llm_driven_meta_optimizer (1 papers, 1 must-read) • wl_test_for_milp_graphs (1 papers, 1 must-read) • autoformulation (1 papers, 1 must-read)</div>
  <div style="margin-top:10px; font-size:9px; color:#6B7280;">
    <span style="color:#1A5F7A;">■</span> Active + Must-read &nbsp;
    <span style="color:#64B5CD;">■</span> Active &nbsp;
    <span style="color:#2E7D32;">■</span> Inactive + Must-read &nbsp;
    <span style="color:#A5D6A7;">■</span> Inactive
  </div>
</div>
</td></tr></table>
</td></tr>
<tr><td style="background:#FAFBFC; padding:20px 24px; border-top:1px solid #E1E4E8; border-radius:0 0 16px 16px; text-align:center;">
<p style="margin:0 0 12px; font-size:11px; color:#6B7280; font-weight:500;">Curated by Research Intelligence System</p>
<table cellpadding="0" cellspacing="0" role="presentation" style="margin:0 auto;">
<tr>
<td style="border-radius:12px; background:#2563EB;">
<a href="#" style="display:inline-block; padding:10px 20px; font-size:12px; font-weight:700; color:#FFFFFF; text-decoration:none; border-radius:12px;">View Full Archive →</a>
</td>
</tr>
</table>
</td></tr>
</table>
</td></tr>
</table>
</body>
</html>