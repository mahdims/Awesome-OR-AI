"""
Layer 3: Daily Living Review Updater

Appends newly analyzed papers to the living review markdown docs.
Each category has its own markdown file in docs/living_reviews/.
"""

import json
from datetime import date, timedelta
from pathlib import Path
from typing import List, Optional
import sys

sys.path.insert(0, str(Path(__file__).parent.parent))

from db.database import Database
from layer3.data_collector import collect_daily_data, _json

LIVING_REVIEWS_DIR = Path(__file__).parent.parent.parent / "docs" / "living_reviews"

CATEGORY_SLUGS = {
    "LLMs for Algorithm Design": "llm_for_algo",
    "Generative AI for OR": "genai_for_or",
    "OR for Generative AI": "or_for_genai",
}


def _category_slug(category: str) -> str:
    return CATEGORY_SLUGS.get(category,
                              category.lower().replace(' ', '_').replace('/', '_')[:30])


def _create_review_scaffold(category: str) -> str:
    """Create initial living review markdown if it doesn't exist."""
    return f"""# Living Review: {category}

**Last Updated:** {date.today().isoformat()}

---

## Recent Papers

<!-- New papers are appended here by the daily updater -->

---

## Research Fronts

<!-- Updated weekly by the revision agent -->

---

## Bridge Papers

<!-- Cross-front connectors, updated weekly -->

---

*Generated by Research Intelligence System*
"""


def _paper_to_markdown(paper: dict) -> str:
    """Format a single paper as markdown."""
    rel = paper.get('relevance', {})
    sig = paper.get('significance', {})
    m = rel.get('methodological', 0)
    p = rel.get('problem', 0)
    i = rel.get('inspirational', 0)

    badges = []
    if sig.get('must_read'):
        badges.append('**MUST-READ**')
    if sig.get('changes_thinking'):
        badges.append('*changes-thinking*')
    if sig.get('team_discussion'):
        badges.append('*discuss*')
    badge_str = ' '.join(badges)

    title = paper.get('title', 'Untitled')
    arxiv_id = paper.get('arxiv_id', '')
    pub_date = paper.get('published_date', '')[:10]
    affiliations = paper.get('affiliations', '')
    brief = paper.get('brief', '')
    meth = paper.get('methodology', {})
    core_method = meth.get('core_method', '')
    llm_role = meth.get('llm_role', 'none')

    lines = [
        f"### [{title}](https://arxiv.org/abs/{arxiv_id})",
        f"",
        f"**{pub_date}** | {affiliations} | M={m} P={p} I={i} {badge_str}",
        f"",
    ]
    if core_method:
        lines.append(f"*Method:* {core_method} | *LLM role:* {llm_role}")
        lines.append("")
    if brief:
        lines.append(f"> {brief}")
        lines.append("")

    return '\n'.join(lines)


def update_living_review(category: str, db: Database,
                         days: int = 1) -> int:
    """
    Append newly analyzed papers to the living review markdown.

    Args:
        category: Category name
        db: Connected Database instance
        days: How many days back to look for new papers

    Returns:
        Number of papers added.
    """
    LIVING_REVIEWS_DIR.mkdir(parents=True, exist_ok=True)

    slug = _category_slug(category)
    review_path = LIVING_REVIEWS_DIR / f"{slug}.md"

    # Create scaffold if needed
    if not review_path.exists():
        review_path.write_text(_create_review_scaffold(category), encoding='utf-8')

    # Collect new papers
    data = collect_daily_data(category, db, days=days)
    papers = data['papers']

    if not papers:
        return 0

    # Read existing review
    content = review_path.read_text(encoding='utf-8')

    # Build new entries
    new_section = f"\n#### {date.today().isoformat()} ({len(papers)} papers)\n\n"
    for paper in papers:
        new_section += _paper_to_markdown(paper) + "\n"

    # Insert after "## Recent Papers" marker
    marker = "## Recent Papers"
    if marker in content:
        idx = content.index(marker) + len(marker)
        # Find end of the marker line
        newline_idx = content.index('\n', idx)
        content = content[:newline_idx + 1] + new_section + content[newline_idx + 1:]
    else:
        # Fallback: append at end
        content += "\n" + new_section

    # Update "Last Updated"
    import re
    content = re.sub(
        r'\*\*Last Updated:\*\* \d{4}-\d{2}-\d{2}',
        f'**Last Updated:** {date.today().isoformat()}',
        content
    )

    review_path.write_text(content, encoding='utf-8')

    # Record in DB
    db.insert_review_update(
        category=category,
        update_type='daily',
        papers_added=len(papers),
        summary=f"Added {len(papers)} papers on {date.today().isoformat()}"
    )

    return len(papers)
