--- Page 1 ---
EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models
Milad Yazdani1*, Mahdi Mostajabdaveh2†, Samin Aref3, Zirui Zhou2
1Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC V6T1Z4, Canada
2Huawei Technologies Canada, Burnaby, BC V5C6S7, Canada
3Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON M5S2E4, Canada
Abstract
Integer programming lies at the heart of crucial combina-
torial optimization tasks but remains challenging due to its
NP-hard nature. An effective approach for practically solv-
ing integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. How-
ever, this creative process demands deep expertise and is yet
to be automated. Our proposed framework, EVOCUT, auto-
mates the generation of acceleration cuts by combining large
language models (LLMs) with an evolutionary search. EVO-
CUT (i) initializes a diverse population of candidate cuts via
an LLM-based initializer agent; (ii) for each cut empirically
evaluates both preservation of the optimal solution and its
ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evo-
lutionary crossover and mutation agents. We quantify each
cut’s utility by its relative reduction in the solver’s optimality
gap. Our comparisons against standard integer programming
practice show that EVOCUT reduces optimality gap by 17-
57% within a fixed time. It obtains the same solutions up to
4× as fast, and obtains higher-quality solutions within the
same time limit. Requiring no human expert input, EVOCUT
reliably generates, improves, and empirically verifies cuts
that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.
1
Introduction
Operations research (OR) workflows usually consist of two
main phases: formulating an optimization model and solv-
ing that model. The first phase involves understanding the
problem, identifying its decision variables, objective, and
constraints, and building a mathematical formulation. The
second phase uses numerical algorithms and generic opti-
mization solvers to find exact or approximate solutions for
the model. With the increasing complexity of real-world prob-
lems, leveraging Artificial Intelligence (AI) for advancing
OR has become essential. Recent advances have used Large
Language Models (LLMs) to automate mathematical mod-
eling, converting natural language descriptions directly into
mathematical formulations (Ramamonjison et al. 2023; Jiang
et al. 2024; Huang et al. 2025; Mostajabdaveh et al. 2025).
*He was an intern at Huawei Technologies Canada during this
work.
†Corresponding Author
While there have been promising results for generating cor-
rect models, improving the efficiency of the generated models
remains an open challenge. Parallel efforts have applied AI to
the solving phase, including AI for heuristic design (Liu et al.
2024a; Ye et al. 2024) and machine learning techniques for ac-
celerating generic optimization solvers (Alvarez, Louveaux,
and Wehenkel 2017; Li et al. 2023). However, the crucial
feedback loop between how a problem is formulated and how
efficiently it can be solved remains largely unexplored. Opti-
mization problems can often be formulated in multiple ways,
with solver performance varying substantially depending on
the strength of the formulation (Klotz and Oberdieck 2024).
In this study, we focus on automating the process for ob-
taining Mixed Integer Linear Programming (MILP) formu-
lations that can be solved more efficiently. We achieve this
by generating and adding acceleration cuts to the base MILP
formulation. These cuts are supplementary constraints intro-
duced solely to improve solver speed. Our proposed method,
EVOCUT, is an evolution-guided LLM-based search algo-
rithm that discovers and refines such problem-specific cuts
using the problem logic. EVOCUT is a general framework
that requires no domain-specific tuning and integrates into
standard solver pipelines across different MILP problems.
Contributions. (i) We introduce EVOCUT, the first frame-
work that, given only an MILP model and a small set of
instances, automatically produces and verifies acceleration
cuts with no human in the loop. Note that EvoCut, will gener-
ate a family of cuts based on the problem combinatorial logic
so it will be applicable to all instances of the problem. (ii)
We test EVOCUT on four MILP problems and observe that
it can generate novel acceleration cuts that improve solver
performance. (iii) We perform computational analyses on
EVOCUT’s components, the sizes of the evaluation and veri-
fication datasets and the evolutionary process, to verify the
reliability of EVOCUT and determine the impact of each
component on the effectiveness of the generated cuts.
Key findings. Across four classic MILP benchmarks, EVO-
CUT substantially improves solver performance. On unseen
test set, adding EVOCUT’s acceleration cut, reduced optimal-
ity gap by up to 57% on Traveling Salesman Problem (TSP),
46% on Capacitated Warehouse Location Problem (CWLP),
37% on Job Shop Scheduling Problem (JSSP), and 17% on
Multi-Commodity Network Design (MCND) withing 300s
budget. For TSP, the time required to reach the target gap
arXiv:2508.11850v1  [cs.AI]  16 Aug 2025


--- Page 2 ---
was reduced by up to 74%.
EVOCUT inequalities are not theoretically proved to be
optimality-preserving cuts and therefore should not be called
as such. However, our results show that they all preserved
optimal solutions in 100% of our test instances. Therefore,
the practical impact of EVOCUT is the same as that of a sys-
tem that generates optimality-preserving cuts 100% of the
time. Moreover, EVOCUT does not require instance-specific
tuning, generalizing across different problem distribution.
2
Related Work
LLM-based mathematical modeling. Recent work has ex-
plored leveraging LLMs to automate various stages of OR
workflows, from problem understanding to algorithm gen-
eration (Liu et al. 2024b; Huang et al. 2024). A central line
of research is on converting natural-language descriptions
into optimization formulations, initiated by the NL4Opt com-
petition (Ramamonjison et al. 2023) and advanced by sys-
tems such as OptiMUS (AhmadiTeshnizi, Gao, and Udell
2024), ORLM (Huang et al. 2025), and LM4Opt (Ahmed and
Choudhury 2024; Li et al. 2025). Recent multi-agent frame-
works incorporate dedicated verification agents to ensure cor-
rectness before generating solver-ready code, including the
chain of experts (Xiao et al. 2023) and the multi-stage agent
architecture of (Mostajabdaveh et al. 2024). These efforts
focus on modeling fidelity, ensuring correct formulations
and code generation from text. In contrast, EVOCUT targets
post-formulation efficiency: we automatically generate accel-
eration cuts and empirically verify optimality preservation
while selecting cuts by their measured impact on solver opti-
mality gap reduction. To our knowledge, prior research has
not considered automating the generation of problem-specific
acceleration cuts, a process that demands both modeling ex-
pertise and a deep understanding of combinatorial logic.
LLM and evolutionary search. Another emerging direction
leverages LLMs within evolutionary frameworks to gener-
ate heuristics for combinatorial optimization. These methods
aim to boost heuristic algorithms performance by modifying
parts of the algorithm code (e.g., heuristic rules) (Liu et al.
2024a; Ye et al. 2024). FunSearch (Romera-Paredes et al.
2024) couples a frozen LLM with evolutionary search and an
evaluator to discover heuristics, while the evolution of heuris-
tics (Liu et al. 2024a) refines natural language ”thoughts” and
executable code using evolutionary strategies. ReEvo (Ye
et al. 2024) introduces reflective evolution with pairwise
comparisons and long-term reflections to iteratively improve
LLM-generated code. While these works evolve heuristics
or code, EVOCUT evolves acceleration cuts for MILPs and
deploys them to reduce optimality-gap faster. Targeting post-
formulation efficiency, it takes advantage of LLMs reasoning
capability for accelerating solver performance.
Learning methods for cut selection Several learning-based
methods have been proposed to improve cut selection in
MILP solvers. Early work framed it as a reinforcement learn-
ing task to choose cutting planes within branch-and-cut (Tang,
Agrawal, and Faenza 2020), while imitation learning ap-
proximated a look-ahead oracle scoring cuts by exact bound
improvement (Paulus et al. 2022). Hierarchical RL jointly
optimized the number and order of cuts for additional speed-
ups (Wang et al. 2023), and more recent LLM-driven ap-
proaches use natural language problem descriptions to selec-
tively activate built-in separators (Lawless et al. 2025). While
these methods select or tune general solver-generated cuts
and solver parameters, EVOCUT differs in that it generates
novel problem-specific acceleration cuts using problem logic.
Moreover, EVOCUT produces entire families of such cuts
rather than individual or instance-specific ones.
3
Preliminaries
To justify the practical relevance of an automatic yet reliable
generator of acceleration cuts, we briefly recall MILPs, their
linear relaxations, and the notions of valid and optimality-
preserving cuts. We highlight that empirically verified accel-
eration cuts are useful in practice even if not proven to equate
valid cuts or optimality-preserving cuts using a traditional
approach of cut design.
MILP formulation. We consider an MILP
max

c⊤x + h⊤y : Ax + Gy ≤b, x ∈Zn
+, y ∈Rp
+
	
,
(1)
with integer variables x ∈Zn
+ and continuous variables
y ∈Rp
+. Its feasible set is S
=
{ (x, y) ∈Zn
+ × Rp
+
:
Ax + Gy ≤b }.
LP relaxation. Relaxing integrality yields the linear program
max

c⊤x + h⊤y : Ax + Gy ≤b, x ∈Rn
+, y ∈Rp
+
	
,
(2)
whose feasible set (the linear-relaxation set) is P
=
{ (x, y) ∈Rn
+ × Rp
+
: Ax + Gy ≤b }. Let conv(S)
denote the convex hull of S, i.e., the smallest convex set
that contains S. Although Eq. (2) is polynomially solvable,
its optimum is generally fractional (i.e., not in S). Valid
cuts progressively tighten P toward conv(S), narrowing the
gap between the LP optimum and the true MILP optimum
(see Fig. 1). Optimality-preserving cuts, in contrast, may not
tighten P toward conv(S) but can still dramatically speed up
the branch-and-bound search by excluding provably subopti-
mal regions while preserving the optimal objective value.
Valid cuts. An inequality w⊤x ≤δ is valid for a set Q if
it is satisfied by every x ∈Q. Adding inequalities that are
valid for conv(S) eliminates fractional extreme points of P
and can close the LP-IP gap. Notions of facet-defining valid
inequalities and their role in describing conv(S) are reviewed
in Appendix D. Designing strong problem-specific valid cuts
typically demands non-trivial proofs and deep insight about
combinatorial structure of the problem.
Optimality-preserving cuts. An inequality is optimality-
preserving for a MILP model if, when added to the MILP,
it leaves at least one optimal solution feasible and hence
does not change the optimal objective value, even though
it may remove other feasible solutions (Laporte and Semet
1999; da Cunha, Simonetti, and Lucena 2015). Optimality-
preserving cuts can dramatically speed-up branch-and-bound
search while they may cut away some parts of conv(S) (i.e.,
some integer feasible solutions). Without a proof on the
preservation of optimal solution, a cut cannot be called an
optimality-preserving cut.
Generic notation for a cut. Throughout the paper we re-
fer to a family of inequalities, or cut, in the form C :


--- Page 3 ---
0
1
2
3
4
x1
0
1
2
3
4
x2
Linear relaxation set
Convex hull
Integer feasible
IP optimum
LP optimum (fractional)
Valid and useful cut
Optimality-preserving cut
Figure 1: Relationship between the integer-feasible set S, its
LP relaxation P, the set conv(S), a valid cut that removes the
fractional LP optimum (useful), and an optimality-preserving
cut that may remove some feasible points while keeping the
optimal value.
A′x + G′y + H′z ≤δ, where z denotes the vector of cut
auxiliary variables that do not exist in the original MILP
formulation. Including z allows the cut to encode additional
logical relations and thus be more expressive.
Acceleration cuts. In the practice of solving computationally
challenging MILPs, one may add inequalities whose sole pur-
pose is to accelerate solving, without a requirement that they
are necessarily valid cuts. We call any such problem-specific
constraint an acceleration cut. Our framework follows this
pragmatic perspective.
Definition 3.1 (Acceleration cut) A constraint added to an
MILP with the explicit aim of reducing solution time. It is
not necessarily a valid cut and is deemed useful on empirical
grounds once it is verified that (i) it does not change the
optimal objective function value on a verification set and (ii)
it yields a tangible speed-up.
This pragmatic perspective is essential for automation: EVO-
CUT generates candidate inequalities, keeps those that pre-
serve the optimal solution on a verification set, and discards
the rest. Consequently, throughout the paper we refer to all
inequalities produced and retained by EVOCUT simply as
acceleration cuts allowing for the possibility that they do not
equate valid cuts.
General-purpose vs. problem-specific. Modern MILP
solvers routinely inject a wide range of general-purpose
cuts that apply to virtually any formulation (Chv´atal 1973;
Balas 1979). These are enabled by default in commercial
software like Gurobi (Gurobi Optimization LLC 2024). By
contrast, problem-specific acceleration cuts exploit structural
insight unique to a given formulation and can outperform
general-purpose cuts in speed-up gains when designed and
verified correctly (Marchand et al. 2002). Examples for typ-
ical sources of such insight include capacity arguments in
vehicle-routing (Toth and Vigo 2002; Lysgaard, Letchford,
and Eglese 2004), minimum cardinality in network design
problems (Costa, Cordeau, and Gendron 2009), logical prece-
dence relations in scheduling (Queyranne and Wang 1991),
and cycle-elimination logic in graph models (Aref, Mason,
and Wilson 2020). Verified problem-specific acceleration
cuts can eliminate large regions of fractional and suboptimal
solutions that general-purpose cuts cannot remove.
We describe how EVOCUT automatically proposes, verifies,
and evolves such acceleration cuts, ultimately speeding up
MILP solution process without the need for human expertise.
4
Proposed Method
We propose EVOCUT, an evolutionary algorithm powered
by multiple LLM-based agents to iteratively generate and
refine acceleration cuts for a given MILP problems. The
overarching goal is to automatically generate acceleration
cuts that ostensibly speed up solver for all instances of the
given MILP problem.
Fig. 2 illustrates the flow diagram of EVOCUT at a high
level. In addition, Appendix A provides the pseudo-code and
additional details for the overall procedure. Our proposed
method can be summarized into three main phases: (1) Data
Pre-processing; (2) Population Initialization (driven by the
initializer agent); and (3) Evolution (crossover and mutation
mediated by LLM-based agents).
In what follows, we provide key details on the three phases,
candidate cut generation, optimal-solution-preservation
check and usefulness checks, as well as the computation of a
fitness score that quantifies the gains in solver performance
for each cut.
Data pre-processing. Consider some instances for a given
MILP to be strengthened by EVOCUT. Using this set, we
construct two sets, an evaluation set De and a verification
set Dv. Dv will be used to check the verification of each
generated cut (for preserving the optimal solution) and use-
fulness (cutting the LP relaxation solution). De will be used
to evaluate the quality of a generated cut. For every in-
stance i ∈De, we run the baseline MILP under a fixed
computational budget (e.g. Gurobi’s WorkLimit (Gurobi
Optimization LLC 2025) set to 10) and record its terminal
optimality gap, gapref(i). This reference gap provides the
baseline to evaluate the impact of new cuts on solver per-
formance within EVOCUT. For the smaller subset Dv, we
append two additional artifacts to each instance i. First, we
solve the MILP within the optimality gap tolerance 10−4 and
record the final solution (ˆx∗
i , ˆy∗
i ) returned by the solver. We
use this solution to verify that new cuts do not violate the
MILP’s optimal solution on that instance. Second, we solve
the LP relaxation (Eq. (2)) to obtain the fractional optimum
(xLP
i , yLP
i
), which must be separated by a cut for it to be
considered useful. Each i ∈Dv therefore carries its refer-
ence gap (gapref(i)) together with (ˆx∗
i , ˆy∗
i ) and (xLP
i , yLP
i
).
Precisely, we have De =

i 7→gapref(i)
	
and
Dv =

i 7→
 (ˆx∗
i , ˆy∗
i ), (xLP
i , yLP
i
), gapref(i)
	
.
Population initialization via LLM. EVOCUT begins by
seeding a population of candidate cuts using an initializer
agent. At each iteration, the LLM-based agent receives three
inputs: (1) the code of the complete MILP formulation along-
side a natural language description of all model components;
(2) the set of cuts generated so far; and (3) explicit instruc-
tions to propose novel and distinct acceleration cuts that
tighten the LP relaxation in Eq. (2). The complete prompt
templates is provided in Appendix B. The LLM response
comprises a high-level description (an idea) of the proposed
inequality together with executable code (e.g., Pyomo (Hart,
Watson, and Woodruff 2011)). We immediately subject each
response to the verification step (Sec. 4). If a candidate fails
any verification check we issue a diagnostic prompt. The
possible failures include a syntax error, an exclusion of the


--- Page 4 ---
Intersection Complement
Hybrid
Min Violation
Feedback
Termination
Condition
Tournament
Selection
Crossover Agent
Mutation Agent
General
Lifted
Exploratory
Uniform
Selection
Uniform
Selection
New Cut Generator
Verifier
Evaluator
Elite Selection
...
Evolution
Evolution
...
Problem Code
Verifier
Initializer
Feedback
Previous Ideas
Initializer Agent
Evaluator
...
...
termination
condition
idea/code/fitness
Initializer
...
...
idea/code/fitness
Figure 2: EVOCUT flow diagram. Magnify the high-resolution figure on the screen for the details.
optimal solution, and the inability to separate an LP relax-
ation optimum. The agent may then revise the idea and retry
up to a preset limit. Every cut idea is logged to prevent dupli-
cation. This loop of generation and check continues until the
population reaches its predefined size, at which point the full
set of verified and distinct inequalities enter the evolutionary
search phase (see Fig. 2).
Verification of candidate cuts. Every newly proposed cut C
undergoes the following three checks (Fig. 3).
1. Code check. We parse and compile the code snippet that
implements C. If a syntax or runtime error occurs, we gener-
ate a diagnostic prompt describing the error and return it to
generator agents for revision. This step may continue up to a
predefined retry limit.
2. Optimal solution preservation (OSP) check. We verify
that C does not exclude the recorded optimal solution in
the verification set Dv. Recall that each instance i ∈Dv
carries the solver’s final solution (ˆx∗
i , ˆy∗
i ). We append C
to the baseline MILP (Eq. (1)), fix (x, y) to (ˆx∗
i , ˆy∗
i ), and
solve the resulting model to check feasibility. Because cuts
may introduce auxiliary variables, we cannot simply evaluate
the inequality on the fixed solution. Instead, we build this
reduced MILP (or LP) by fixing (x, y) and call the solver,
which remains efficient since almost all variables, except cut
auxiliary variables, are fixed. If this model is infeasible, C
fails the OSP check. We then issue a diagnostic prompt and
allow the agent to revise the idea behind C up to the retry
limit. Formally, for instance i, C passes the check iff there
Yes
Yes
Verifier
Instances
Solution
Code Check
OSP Check
Usefulness
Check
Yes
Feedback
Figure 3: EVOCUT Verifier diagram. Magnify for the details.
exists z such that A′ ˆx∗
i + G′ ˆy∗
i + H′ z
≤δ is feasible;
otherwise C fails the OSP check for instance i.
3. Usefulness check. To guide the evolutionary search toward
cuts that tighten the LP relaxation and thereby accelerate the
solution process, we discard any cut that fails to separate an
LP-relaxation optimal solution on at least one instance in Dv.
Specifically, for each instance i ∈Dv, we add cut C to the
baseline MILP, relax all integrality constraints, fix (x, y) to
the stored LP-optimal solution
 xLP
i , yLP
i

, and resolve the
LP. If every such LP remains feasible, C has no tightening
effect and is discarded, triggering a revision feedback prompt
to the agent (up to the retry limit). If at least one of these fixed-
solution LPs becomes infeasible under C, the cut passes the
usefulness check and is retained for evolutionary refinement.
Usefulness check is the strategic component of EVOCUT for
discovery of the acceleration cuts. By filtering out cuts that
do not change the LP relaxation, we prevent the search space
from being flooded with ineffective candidates.


--- Page 5 ---
Evaluation of Candidate Cuts. After a cut C passes the
verification checks of Section 4, we append it to the base-
line MILP and solve every evaluation instance i ∈De under
the same time limit used for the reference solver, recording
the resulting optimality gap (gapcut(i)) and comparing it to
gapref(i).
Intuition. If a cut reduces the gap on average, its fitness
should increase; larger average reductions should produce
larger fitness gains. Conversely, if a cut increases the gap on
average, the fitness should be penalized, with larger increases
inducing stronger penalties. We implement this by computing
the signed relative gap change per instance, averaging over
De. We then apply a monotone mapping so that more effec-
tive cuts receive higher fitness values. The fitness equation is
provided in Appendix H.
The evolutionary process of EVOCUT. Once the initial pop-
ulation of verified and evaluated cuts is ready, the EVOCUT
algorithm iterates for T generations. The main steps of the
evolution are as follows: (i) Elitism: The top re fraction of
cuts with the highest fitness carry over to the next generation.
(ii) Selection: Parent cuts are picked with probability propor-
tional to their fitness. (iii) Crossover: With probability Pc,
two parents are passed to a Crossover LLM, which attempts
to produce a new child inequality Co by merging parental
features. (iv) Mutation: With probability Pm, a single parent
undergoes a Mutation LLM, which alters coefficients or terms
to produce a variant Cm. (v) Verification & Evaluation: Each
newly created candidate (Co or Cm) is checked according
to the verification checks in Section 4. Failed candidates are
discarded, and a feedback prompt is provided to the LLM
(up to a predefined maximum retry limit). Verified candidates
are then forwarded to the evaluation stage (Section 4). Their
fitness is computed and then they are added to the next gen-
eration. At each iteration, reproduction (i.e., the generation
of new cut) continues until the next population reaches its
required size. This evolutionary process then repeats for T
generations.
Agent library. At each reproduction step, the EVOCUT
chooses whether to perform crossover (with probability Pc)
or mutation (with probability Pm). Once the operation type
is chosen, one of the corresponding agents is selected uni-
formly at random. The full list of mutation and crossover
agents, along with their prompt details, is provided in Ap-
pendix B.
5
Experiments and Results
We structure our evaluation around three key questions:
RQ1: Can EVOCUT improve solver efficiency and to
what extent? We measure reductions in optimality gaps and
wall-clock time across diverse unseen instances.
RQ2: Does evolutionary search improve LLM-generated
cuts beyond a single-shot usage? We ablate the evolutionary
component by comparing against cuts produced solely by the
initializer agent.
RQ3: How sensitive is EVOCUT to the sizes of evaluation
(De) and verification (Dv) sets? We vary |De| and |Dv|
to assess their impact on gap improvement and the rate by
which they preserve optimal solutions (OSP rate).
5.1
Overall Experimental Setup
The experiments evaluate EVOCUT effectiveness at strength-
ening MILP formulations and demonstrate the impact of key
design choices. As the MILP solver, we use the Gurobi Op-
timizer 10.0.0 (build v10.0.0rc2, Linux 64-bit) because it
is considered to be among the fastest MILP solvers (Mil-
tenberger 2025). We access Gurobi via the Pyomo inter-
face (Hart, Watson, and Woodruff 2011) using eight threads.
We set the WorkLimit (Gurobi Optimization LLC 2025)
parameter to control solver effort. We fix Seed to 42 for
reproducibility and fix the Method parameter to 4 (deter-
ministic concurrent algorithm for continuous models and the
initial root relaxation).
In our experiments, EVOCUT is configured to run for T = 20
generations with a population size |P| = 8. Within each gen-
eration, we use a mutation probability Pm = 0.3, an elitism
ratio re = 0.2, and a crossover probability Pc = 0.7. To
prevent endless loops, agents may retry cut generation up to
three times if verification checks fail. All these parameter val-
ues were chosen after running empirical tests. Users may run
EVOCUT with these default configurations for reproducibil-
ity or adjust any parameter as needed. These parameters are
chosen empirically because on our hardware, a full run of
T = 20 generations with |P| = 8 required roughly 20 hours
of wall-clock time, which was deemed suitable for our ex-
periments. We used DeepSeek-R1 (Guo et al. 2025) as the
LLM in EVOCUT (the full API configuration and an approxi-
mate cost breakdown are given in Appendix G). EVOCUT is
not restricted to using DeepSeek-R1 and other LLMs that
offer an API can be interchangeably used in it.
Benchmark MILP problems. We benchmark EVOCUT on
four classic NP-hard MILPs from four distinct application do-
mains: routing, network design, facility location, and schedul-
ing. They include TSP, MCND, CWLP, and JSSP. Their for-
mal definitions, instance sources, and citations are in Ap-
pendix F.
Datasets. EVOCUT relies on relatively small datasets De
(default size 10) and Dv (default size 2) to guide its evolu-
tionary process, as detailed in Section 4. To avoid any leakage
to our final test instances, both De and Dv are drawn from
synthetic generators (released alongside our code). For final
benchmarking, we use established public datasets for each
problem class; we denote the set of these test instances by Dt.
Instances are classified as small, medium, and large based on
their numbers of variables and constraints. For each MILP,
our test set has 40 medium and large instances chosen for
their computational difficulty and supplemented by random
instances where public benchmarks fall short (please refer to
the Appendix F for more detail on our test set).
5.2
EVOCUT Generalization to Unseen Instances
We evaluate EVOCUT’s capability to accelerate baseline
MILP solution process on unseen test instances in Dt. Each
instance is solved twice under a 300 s wall-clock limit: once
as the baseline MILP (reference) and once with the strongest
cut proposed by EVOCUT. At each of the five checkpoints
(5 s, 10 s, 50 s, 150 s, 300 s), we record the solver-reported
optimality gap g. We then compute the relative gap improve-
ment: ∆g = (gref −gcut)/gref . We report ¯∆g, the average


--- Page 6 ---
0
50
TSP
MCND
0
50
100
150
200
250
300
0
50
JSSP
0
50
100
150
200
250
300
CWLP
Time (s)
Relative Gap Improvement (%)
Figure 4: Time evolution of the mean relative gap improve-
ment ¯∆g(t) after adding the best EVOCUT inequality com-
pared with the baseline MILP for TSP, MCND, JSSP, and
CWLP. Shaded areas indicate one standard deviation (σ). A
positive value means the augmented model exhibits a smaller
optimality gap at that wall-clock time.
of ∆g over all instances in Dt. Positive values indicate better
solver performance under the same computational budget.
Optimal-solution preservation (OSP). To verify that a can-
didate cut C preserves the optimal solution, we re-solve the
baseline MILP (2000 s time limit), record the optimal so-
lution if one is found, and check that this solution satisfies
C (see Section 4). We report the fraction of test instances
whose recorded optimal solution satisfies the cut (OSP rate).
A 100% success rate across all problems indicates that EVO-
CUT inequality preserves the optimal solution on all test
instances.
Checkpoint analysis. Table 1 reports the mean ¯∆g at each
checkpoint and the OSP rate for each of the four problems.
Higher values indicate greater solver improvement under a
fixed computational budget. At the 300 s checkpoint, ¯∆g
ranges from 17 to 57% across the four problems. Also, for
TSP, Appendices E.2- E.3 provides plots of best bound and
time as well as the primal-dual-integral for a few represen-
tative instances. These example trajectories show that EVO-
CUT’s main benefit comes from significantly faster early
bound tightening and gap closure.
Plots of relative gap and time. To complement the discrete
checkpoint results in Table 1, Fig. 4 tracks the mean relative
gap improvement ¯∆g(t) over the full 300 s horizon for each
problem. For visualization of aggergate results, for each in-
stance in the test set Dt, we apply a K-NN regression (with
K=3) to its raw solver trace to smooth the plot, and then
average the resulting fitted curves across all instances. At
each time stamp, the dark blue line shows this average ∆g(t)
and the shaded band depicts ±1σ. Positive values confirm
that the MILP augmented with the strongest EVOCUT in-
equality generally narrows the optimality gap faster than the
baseline MILP. Raw per-instance traces of the gaps for four
representative TSP cases are provided in Appendix E.1.
5.3
EVOCUT Reducing the Time to Reach a
Specific Optimality Gap
To complement the checkpoint-based gap analysis (Sec-
tion 5.2), we measure EVOCUT’s capability to shorten the
time required to reach specific optimality gaps on the unseen
test set Dt of TSP. For each instance, we record the time tref
taken without EVOCUT (reference) and the time tcut taken
with the strongest EVOCUT inequality to reach the predefined
target gaps g ∈{10−4, 10−3, 10−2, 10−1}. The relative
time saving is quantified as ∆t = (tref −tcut)/tref, ¯∆t =
P
i∈Dt ∆t(i)/|Dt|. Here, ∆t ∈[0, 1] represents the fraction
of time saved. Table 2 reports the average value, ¯∆t, where
higher values indicate faster convergence to the same target
gap. In our experiments, we observed an average time savings
of up to 74%, corresponding to a ≈4× speed-up in reaching
a 10% optimality gap on TSP instances.
5.4
Sensitivity to Size of De and Dv
The sizes of the evaluation and verification sets, De and Dv,
directly affect EVOCUT runtime because each new cut must
be tested on all their instances. We examined how varying
|De| and |Dv| influences both the quality of the generated
cuts and their ability to preserve the optimal solutions using
two experiments on the JSSP instances. In the first experi-
ment, we fixed |De| and varied |Dv| over {2, 5, 10}. In the
second, we held |Dv| constant and varied |De| over the same
three values. In every configuration, the best cut found by
EVOCUT was evaluated on the held-out test set Dt. As Ta-
ble 3 shows, reducing the verification set size degrades the
performance of the generated cuts. Remarkably, the OSP
rate remains at 100% for all configurations regardless of the
verification set size.
5.5
Assessing the Evolutionary Aspects of
EVOCUT
To demonstrate the evolutionary dynamics of EVOCUT,
we performed three complementary diagnostics: agent-level
statistics, steps in the development of the best cut, and
population-wide fitness curves. Each diagnostic is summa-
rized here and presented in detail in Appendix C.
Agent-level statistics. During the EVOCUT process, for each
agent on all benchmarks, we logged (i) code rejections, (ii)
OSP rejections, (iii) usefulness rejections, and (iv) the fitness
improvement of every successful offspring. The aggregated
results are provided in Table 4 (in Appendix C.1) demonstrat-
ing higher success rates for crossover and mutation agents
comparing to the initializer agent. Mutation and crossover
agents succeed on 63−82% of attempts (peak 82.0% for
the exploratory-mutation agent) versus only 25.4% for the
initializer, with the best average fitness gain reaching 17.9%.
Steps in the development of the best cut. For the best accel-
eration cut discovered by EVOCUT for the JSSP, we tracked
its parent–offspring lineage, acting agents, and fitness values
to illustrate how the evolution-guided process produces a
high-quality cut. Fig. 5 (in Appendix C.2) shows the traced
graph for this best cut. It highlights that agent modifications
increased its fitness from the baseline of 10 to 21.4 before
convergence. In Appendix F, we also include the best novel
cut discovered by EVOCUT for each MILP problem.
Population-level fitness curves. For each of the four prob-
lems, we tracked the maximum and mean fitness values of
the population over 20 generations. Fig. 6 (in Appendix C.3)
shows how the best cut improves over generations. It also
shows that evolution causes improvement in best candidate


--- Page 7 ---
Checkpoints
5 s
10 s
50 s
150 s
300 s
OSP rate (%)
TSP
16.3 ± 24.9
15.4 ± 27.3
27.7 ± 31.1
44.4 ± 27.7
57.4 ± 26.3
100
MCND
9.4 ± 21.1
6.3 ± 22.0
11.7 ± 19.1
10.4 ± 18.4
17.1 ± 20.2
100
CWLP
-6.9 ± 17.0
-8.3 ± 15.1
24.0 ± 24.9
42.5 ± 21.3
46.2 ± 41.1
100
JSSP
22.8 ± 18.3
28.8 ± 19.7
39.1 ± 22.8
34.5 ± 22.1
37.3 ± 22.0
100
Table 1: Mean relative gap improvement, ¯∆g (%) achieved for the EVOCUT-augmented problem at fixed checkpoints on Dt,
alongside the OSP rate. Reported values are mean ± standard deviation (σ), expressed in %.
Gap
10−4
10−3
10−2
10−1
¯∆t(%)±σ
51 ± 31
51 ± 30
49 ± 30
74 ± 48
Table 2: Mean relative time-saving ¯∆t achieved by EVOCUT
for reaching predefined target optimality gaps on the unseen
test set of TSP’s instances.
|De|
|Dv|
OSP rate (%)
¯∆g ±σ (%)
10
2
100
37.3 ± 22.0
10
5
100
37.3 ± 22.0
10
10
100
40.4 ± 22.3
5
10
100
37.3 ± 22.0
2
10
100
7.1 ± 16.4
Table 3: Impact of evaluation and verification set sizes on the
quality and OSP rate of the strongest cut proposed by EVO-
CUT for JSSP. For each pair (|De|, |Dv|) we report the OSP
rate and the average relative gap improvement ( ¯∆g ±σ (%))
on the test set Dt.
cut over generations. For example, the fitness for TSP rises
from 10 to 19 confirming substantial evolutionary gains
achieved over the 20 generations.
6
Discussion
Smaller optimality gaps with the same time budgets Start-
ing with RQ1, as shown in Table 1 and Fig. 4, cuts generated
by EVOCUT expeditiously reduce the optimality gap at suc-
cessive checkpoints. Fig. 8 confirms that this reduction is
primarily driven by a faster tightening of the solver’s best
bound1 (Klotz and Oberdieck 2024). Moreover, Fig. 7 shows
that in some cases, the solver closes the gap for the model
with cuts before it does so for the model without the cuts.
Faster convergence to target gaps. As Table 2 shows, EVO-
CUT enables the solver to reach the same optimality gap
noticeably faster than the baseline MILP for most instances,
underscoring its practical value when wall-clock time is con-
sidered as the limit.
Evolutionary search is critical for high-quality cuts. To
answer RQ2, we observe that cuts proposed by the initial-
izer agent alone have a lower success rate than those refined
through evolutionary search (Appendix C.1). This demon-
strates the value added by our evolution-guided search on top
of the LLM. The assessment in Section 5.5 further highlights
1Higher best-bound curves in minimization imply tighter lower
bounds, which directly shrink the optimality gap.
that evolutionary refinement improves the quality of discov-
ered cuts. This improvement can be seen in both the ancestry
trace (Fig. 5) and population-level fitness progress (Fig. 6).
These results show that compared to a zero-shot usage, LLMs
can be made more capable of producing strong cuts when
paired with evolutionary search. EVOCUT consistently un-
covers novel and effective classes of inequalities that would
not be found through a one-shot usage of the current LLM.
Generating cuts independent of the evaluation and verifi-
cation data. Moving on to RQ3, EVOCUT derives cuts from
the underlying problem logic rather than dataset-specific pat-
terns. As a result, these inequalities remain effective even
when the distribution or size of test instances differs from
those used in verification and evaluation. This is evident in
our experiments: both De and Dv were generated using uni-
form random instance generators, whereas our test set Dt
comprised publicly available benchmark collections designed
to mimic real-world scenarios.
Optimal-solution
preservation
is
independent
of
verification-set size. Larger evaluation sets (and, to a lesser
extent, larger verification sets) were observed to lead to better
performance on the test set. Appendix F reports instance
sizes in De and Dv. Our experiment in Section 5.4 shows
that the size of the verification set Dv does not affect the OSP
rate of generated cuts, which remains at 100%. Changing
the sizes of the evaluation sets does not reduce OSP rate
from 100% either. We observed that the evaluation-set size
De directly influences the magnitude of gap improvement
measured on Dt.
7
Conclusion and Future Direction
EVOCUT automates a crucial process that otherwise demands
both modeling expertise and a deep understanding of combi-
natorial logic. It automatically generates effective and inter-
pretable acceleration cuts that can be exploited by any MILP
solver supporting user-defined cuts. Our results showed that
EVOCUT makes a practical difference in solving MILP prob-
lems, improving the performance of the Gurobi solver by
large margins. EVOCUT can be improved in two key direc-
tions. (1) The optimal-solution preservation of the generated
cuts is currently verified empirically on recorded optimal
solutions; providing a formal proof of validity and optimal-
solution preservation would offer stronger guarantees and
allows stronger claims to be made about EVOCUT. With re-
cent advances in automated proof systems (Yang et al. 2024),
a promising direction is to integrate these methods into EVO-
CUT to generate cuts that are provably optimality-preserving
or even generate valid cuts. (2) EVOCUT currently inserts
cuts into the MILP model before the solution process begins.


--- Page 8 ---
Dynamically separating and adding cuts via callbacks during
the solve could further improve solver performance. This
promising research direction requires generating an efficient
separation algorithm for each cut.
References
AhmadiTeshnizi, A.; Gao, W.; and Udell, M. 2024. Opti-
MUS: scalable optimization modeling with (MI)LP solvers
and large language models. In Proceedings of the 41st Inter-
national Conference on Machine Learning, 577–596.
Ahmed, T.; and Choudhury, S. 2024. LM4OPT: Unveiling the
potential of Large Language Models in formulating mathe-
matical optimization problems. INFOR: Information Systems
and Operational Research, 62(4): 559–572.
Alvarez, A. M.; Louveaux, Q.; and Wehenkel, L. 2017. A
machine learning-based approximation of strong branching.
INFORMS Journal on Computing, 29(1): 185–195.
Aref, S.; Mason, A. J.; and Wilson, M. C. 2020. A modeling
and computational study of the frustration index in signed
networks. Networks, 75(1): 95–110.
Art of Problem Solving Wiki. 2025. 2025 IMO Problem-
s/Problem 6. https://artofproblemsolving.com/wiki/index.
php/2025 IMO Problems/Problem 6.
Accessed: 14 Aug
2025.
Balas, E. 1979. Disjunctive programming. Annals of discrete
mathematics, 5: 3–51.
Beasley, J. E. 1988. An algorithm for solving large capac-
itated warehouse location problems. European Journal of
Operational Research, 33(3): 314–325.
Beasley, J. E. 1990. OR-Library: distributing test problems by
electronic mail. Journal of the operational research society,
41(11): 1069–1072.
Chv´atal, V. 1973. Edmonds polytopes and a hierarchy of
combinatorial problems. Discrete mathematics, 4(4): 305–
337.
CommaLAB. 2021.
Multicommodity Flow Problem In-
stances Repository.
https://commalab.di.unipi.it/datasets/
mmcf. Accessed: 2025-05-01.
Costa, A. M.; Cordeau, J.-F.; and Gendron, B. 2009. Ben-
ders, metric and cutset inequalities for multicommodity ca-
pacitated network design. Computational Optimization and
Applications, 42(3): 371–392.
da Cunha, A. S.; Simonetti, L.; and Lucena, A. 2015. Opti-
mality cuts and a branch-and-cut algorithm for the K-rooted
mini-max spanning forest problem. European Journal of
Operational Research, 246(2): 392–399.
Gendron, B.; Crainic, T. G.; and Frangioni, A. 1999. Multi-
commodity capacitated network design. In Telecommunica-
tions Network Planning, 1–19. Springer.
Guo, D.; Yang, D.; Zhang, H.; Song, J.; Zhang, R.; Xu, R.;
Zhu, Q.; Ma, S.; Wang, P.; Bi, X.; et al. 2025. Deepseek-r1:
Incentivizing reasoning capability in llms via reinforcement
learning. arXiv preprint arXiv:2501.12948.
Gurobi Optimization LLC. 2024. Gurobi Optimizer Refer-
ence Manual.
Gurobi Optimization LLC. 2025.
WorkLimit Parame-
ter in Gurobi Optimizer. https://docs.gurobi.com/projects/
optimizer/en/current/reference/parameters.html. Accessed:
2025-05-14.
Hart, W. E.; Watson, J.-P.; and Woodruff, D. L. 2011. Pyomo:
modeling and solving mathematical programs in Python.
Mathematical Programming Computation, 3(3): 219–260.
Huang, C.; Tang, Z.; Hu, S.; Jiang, R.; Zheng, X.; Ge, D.;
Wang, B.; and Wang, Z. 2025. Orlm: A customizable frame-
work in training large models for automated optimization
modeling. Operations Research.
Huang, S.; Yang, K.; Qi, S.; and Wang, R. 2024. When large
language model meets optimization. Swarm and Evolution-
ary Computation, 90: 101663.
Jiang, C.; Shu, X.; Qian, H.; Lu, X.; Zhou, J.; Zhou, A.;
and Yu, Y. 2024. LLMOPT: Learning to Define and Solve
General Optimization Problems from Scratch. arXiv preprint
arXiv:2410.13213.
Klotz, E.; and Oberdieck, R. 2024. Converting Weak to
Strong MIP Formulations: A Practitioner’s Guide. In Opti-
mization Essentials: Theory, Tools, and Applications, 113–
174. Springer.
Laporte, G. 1992.
The traveling salesman problem: An
overview of exact and approximate algorithms. European
Journal of Operational Research, 59(2): 231–247.
Laporte, G.; and Semet, F. 1999. An optimality cut for mixed
integer linear programs. European Journal of Operational
Research, 119(3): 671–677.
Lawless, C.; Li, Y.; Wikum, A.; Udell, M.; and Vitercik, E.
2025. Llms for cold-start cutting plane separator configu-
ration. In International Conference on the Integration of
Constraint Programming, Artificial Intelligence, and Opera-
tions Research, 51–69. Springer.
Li, S.; Kulkarni, J.; Wu, C.; Menache, I.; and Li, B. 2025.
Towards Foundation Models for Mixed Integer Linear Pro-
gramming. In The Thirteenth International Conference on
Learning Representations.
Li, S.; Ouyang, W.; Paulus, M.; and Wu, C. 2023. Learning to
configure separators in branch-and-cut. Advances in Neural
Information Processing Systems, 36: 60021–60034.
Liu, F.; Tong, X.; Yuan, M.; Lin, X.; Luo, F.; Wang, Z.; Lu,
Z.; and Zhang, Q. 2024a. Evolution of heuristics: Towards
efficient automatic algorithm design using large language
model. In Proceedings of the 41st International Conference
on Machine Learning, 32201–32223.
Liu, F.; Yao, Y.; Guo, P.; Yang, Z.; Zhao, Z.; Lin, X.; Tong,
X.; Yuan, M.; Lu, Z.; Wang, Z.; and Zhang, Q. 2024b. A
Systematic Survey on Large Language Models for Algorithm
Design. arXiv:2410.14716.
Lysgaard, J.; Letchford, A. N.; and Eglese, R. W. 2004. A new
branch-and-cut algorithm for the capacitated vehicle routing
problem. Mathematical programming, 100: 423–445.
Manne, A. S. 1960. On the job-shop scheduling problem.
Operations Research, 8(2): 219–223.


--- Page 9 ---
Marchand, H.; Martin, A.; Weismantel, R.; and Wolsey, L.
2002. Cutting planes in integer and mixed integer program-
ming. Discrete Applied Mathematics, 123(1-3): 397–446.
Miltenberger, M. 2025.
Interactive visualizations of
Mittelmann benchmarks.
https://github.com/mattmilten/
mittelmann-plots. Accessed: 2025-05-01.
Mostajabdaveh, M.; Yu, T. T.; Ramamonjison, R.; Carenini,
G.; Zhou, Z.; and Zhang, Y. 2024. Optimization modeling
and verification from problem specifications using a multi-
agent multi-stage LLM framework. INFOR: Information
Systems and Operational Research, 62(4): 599–617.
Mostajabdaveh, M.; Yu, T. T. L.; Dash, S. C. B.; Ramamonji-
son, R.; Byusa, J. S.; Carenini, G.; Zhou, Z.; and Zhang, Y.
2025. Evaluating LLM Reasoning in the Operations Research
Domain with ORQA. In Proceedings of the AAAI Conference
on Artificial Intelligence, volume 39, 24902–24910.
Paulus, M. B.; Zarpellon, G.; Krause, A.; Charlin, L.; and
Maddison, C. 2022. Learning to cut by looking ahead: Cut-
ting plane selection via imitation learning. In International
conference on machine learning, 17584–17600. PMLR.
Queyranne, M.; and Wang, Y. 1991. Single-machine schedul-
ing polyhedra with precedence constraints. Mathematics of
Operations Research, 16(1): 1–20.
Ramamonjison, R.; Yu, T.; Li, R.; Li, H.; Carenini, G.; Ghad-
dar, B.; He, S.; Mostajabdaveh, M.; Banitalebi-Dehkordi,
A.; Zhou, Z.; et al. 2023. NL4Opt competition: Formulat-
ing optimization problems based on their natural language
descriptions. In NeurIPS 2022 Competition Track, 189–203.
Reinelt, G. 1991. TSPLIB—A traveling salesman problem
library. ORSA Journal on Computing, 3(4): 376–384.
Romera-Paredes, B.; Barekatain, M.; Novikov, A.; Balog, M.;
Kumar, M. P.; Dupont, E.; Ruiz, F. J.; Ellenberg, J. S.; Wang,
P.; Fawzi, O.; Kohli, P.; and Fawzi, A. 2024. Mathematical
discoveries from program search with large language models.
Nature, 625(7995): 468–475.
Taillard, E. 1993. Benchmarks for basic scheduling problems.
European Journal of Operational Research, 64(2): 278–285.
Tang, Y.; Agrawal, S.; and Faenza, Y. 2020. Reinforcement
learning for integer programming: Learning to cut. In Interna-
tional conference on machine learning, 9367–9376. PMLR.
Toth, P.; and Vigo, D. 2002. The vehicle routing problem.
SIAM.
Wang, Z.; Li, X.; Wang, J.; Kuang, Y.; Yuan, M.; Zeng, J.;
Zhang, Y.; and Wu, F. 2023. Learning cut selection for mixed-
integer linear programming via hierarchical sequence model.
arXiv preprint arXiv:2302.00244.
Xiao, Z.; Zhang, D.; Wu, Y.; Xu, L.; Wang, Y. J.; Han, X.;
Fu, X.; Zhong, T.; Zeng, J.; Song, M.; et al. 2023. Chain-
of-experts: When LLMs meet complex operations research
problems. In the twelfth International Conference on Learn-
ing Representations.
Yang, K.; Poesia, G.; He, J.; Li, W.; Lauter, K.; Chaudhuri,
S.; and Song, D. 2024. Formal Mathematical Reasoning: A
New Frontier in AI. arXiv preprint arXiv:2412.16075.
Ye, H.; Wang, J.; Cao, Z.; Berto, F.; Hua, C.; Kim, H.; Park,
J.; and Song, G. 2024. ReEvo: Large language models as
hyper-heuristics with reflective evolution. In Proceedings
of the 38th Conference on Neural Information Processing
(NeurIPS 2024), 10–15. Vancouver, Canada.


--- Page 10 ---
A
Pseudo-Code EVOCUT
The full procedure is outlined in Algorithm 1, which presents
the pseudo-code for the proposed EVOCUT framework.
B
Agents for EVOCUT
This section outlines the agents involved in EvoCut process
and presents their prompt structures, including roles, tasks,
requirements, and inputs/outputs. The agent library comprise
a single initializer and several Mutation and Crossover
agents, each endowed with specific instructions to generate
valid and useful cuts. The prompt structure for initializer
agent is as follows,
initializer agent
Role: You are an MILP optimization expert with
extensive knowledge in designing valid inequalities
for MILP models.
Task:
• Propose a valid, effective constraint (cut) that
tightens the feasible region and improves solver
performance.
• Provide a clear, concise explanation of the cut’s
derivation, validity, and impact.
Requirements:
• Cut must be valid for all instances of the problem.
• Introduce new variables or constructs if needed.
• Cut should be conceptually distant from previous
ideas.
Input:
• ¡ Baseline MILP (Pyomo model code) ¿.
• ¡ List of previous ideas (if applicable) ¿.
Output:
{"code": "<Only python code snippet
for the added cut using Pyomo
syntax>",
"idea": "Concise technical explanation
of cut derivation, validity, and
impact"}
We employ three mutation agents, General Mutation,
Lifted Mutation, and Exploratory Mutation, each of which
follows the prompt structure described below.
Mutation Agents
Role: MILP optimization expert tasked with analyz-
ing and modifying an individual’s constraint in an
Evolutionary Algorithm for MILP cut generation.
Task:
• Propose a valid and effective constraint (cut) that
reduce the LP relaxation feasible region but re-
main valid for any integer feasible solution by
Algorithm 1: Pseudo-Code of EVOCUT
Input: (i) Baseline MILP Eq. (1), (ii) MILP data
instances for evaluation and verification. (ii)
Hyper-Parameters: population size µ,
crossover rate Pc, mutation rate Pm, elitism
ratio re, number of generations T, and
Maximum attempts for a failed generation or
verification cycle.
Output: A set of discovered acceleration cuts with
corresponding fitness.
Phase 1: Data Pre-Processing
- Setup De =

i 7→gapref(i)
	
,
Dv =

i 7→
 Fi, (xLP
i , yLP
i
), gapref(i)
	
Phase 2: Population Initialization
- P1 ←∅.
- while |P1| < µ do
Call initializer LLM →propose candidate cut C.
if VerifyAndEvaluate(C) = True then
P1 ←P1 ∪{C}.
else
Provide feedback prompt to LLM and retry
(up to max attempts).
Phase 3: Evolution
for t ←1 to T do
Elitism: Transfer top ⌈reµ⌉from Pt to Pt+1.
while |Pt+1| < µ do
// Reproduction
step
Selection:
With probability proportional to fitness,
select two parents (Cp, Cq) from Pt.
if rand() < Pc then
// Crossover
step
// Agent Selection: randomly
choose a crossover agent
from the available pool Call
the selected Crossover LLM with (Cp, Cq)
→Co.
if VerifyAndEvaluate(Co) = True then
Pt+1 ←Pt+1 ∪{Co}.
if |Pt+1| = µ then
break
else
Provide feedback prompt to the
selected crossover LLM and retry (up
to max attempts).
else if rand() < Pm then
// Mutation
step
// Agent Selection: randomly
choose a mutation agent from
the available pool Call the
selected Mutation LLM with one parent
Cp →Cm.
if VerifyAndEvaluate(Cm) = True
then
Pt+1 ←Pt+1 ∪{Cm}.
else
Provide feedback prompt to the
selected mutation LLM and retry (up
to max attempts).
Return final population PT +1.


--- Page 11 ---
leveraging the idea behind the provided individ-
ual cut.
• Provide a concise explanation of the cut’s deriva-
tion, validity, and impact.
• ¡Agent-specific instruction¿
Requirements:
• The cut must be valid for all instances.
• The new constraint should enhance the provided
Input Cut.
• Introduce new variables if needed.
Input:
• ¡ Baseline MILP (Pyomo model code) ¿.
• ¡ Input Cut (code, idea, and score) ¿.
Output:
{"code": "<Only python code snippet
for the added cut using Pyomo
syntax>",
"idea": "Concise technical explanation
of cut derivation, validity, and
impact"}
Agent-specific instruction: Each mutation agent performs
the same core task, but with variations in the approach:
• General Mutation: Proposes a new cut based on the indi-
vidual constraint while improving the feasible region.
• Lifted Mutation: Enhances the cut by applying lifting
techniques to tighten the feasible region further.
• Exploratory Mutation: Generates an exploratory cut that
diverges from the provided constraint to explore new re-
gions of the solution space.
Similarly EvoCut includes four crossover agents, Intersec-
tion, Complementary, Hybrid and Min Violation with the
following prompt design.
Crossover Agents
Role: MILP optimization expert tasked with perform-
ing crossover between two parent constraint sets.
Task:
• Generate a valid and effective constraint (cut) by
combining elements from the parent cuts.
• Provide a concise explanation of the new cut’s
idea, validity, and impact.
• ¡Agent-specific instruction¿
Requirements:
• The cut must be valid for all instances.
• It should combine elements from both parent cuts
in a novel and effective way.
• Introduce new variables or auxiliary constructs if
needed.
Input:
• ¡ Baseline MILP (Pyomo model code) ¿.
• ¡ First Parent Cut (code, idea, and score) ¿.
• ¡ Second Parent Cut (code, idea, and score) ¿.
Output:
{"code": "<Only python code snippet
for the added cut using Pyomo
syntax>",
"idea": "Concise technical explanation
of cut derivation, validity, and
impact"}
Agent-specific instruction: Each crossover agent per-
forms the same core task but with variations in the approach:
• Intersection Crossover: Combines elements of both par-
ents to generate a cut that ensures both parent cuts are
respected.
• Complementary Crossover: Generates a cut that comple-
ments both parents, creating a more distinct solution.
• Hybrid Crossover: Combines structural elements from
one parent with numerical or conditional features from
the other.
• Min Violation Crossover: Selects a crossover that mini-
mizes the joint violation of both parents in previous runs.
C
Detailed Evolutionary Diagnostics
C.1
Agent-Level Performance Statistics
We quantify how effectively each EVOCUT agent improves
cut fitness. For a generated offspring we compute the rela-
tive improvement rate ∆f = (fchild −fparent)/fparent, where
fparent is the average fitness of the parent population (a single
value for mutation; the mean of two parents for crossover).
For the initializer agent the reference value is the neutral
fitness 10 that corresponds to “no cut”.
Table 4 reports five statistics collected over the full run on
all benchmarks: code-generation failures, OSP failures, use-
fulness rejections, overall success rate, and the average im-
provement ¯∆f of successful offspring.
C.2
Evolutionary Generation of a Novel Cut
Fig. 5 shows how EVOCUT mutates and recombines cuts
to obtain a high-quality inequality for the JSSP. The blue
panel on the right depicts the baseline MILP (minimizing
makespan Cmax under big-M disjunctive constraints). Green
boxes list candidate cuts with their fitness score; arrows con-
nect parents to offspring and yellow panels quote the agent
instructions that produced the offspring.
C.3
Population-Level Fitness Progress
Fig. 6 plots the best (blue) and mean (orange) fitness val-
ues observed over 20 generations of EVOCUT on the TSP,
MCND, CWLP, and JSSP benchmarks; shaded bands indi-
cate one standard deviation.


--- Page 12 ---
Agent
Code
Fail.%
OSP Fail.%
Not
Useful %
Success Rate
%
¯∆f ±σ (%)
initializer
Main
38.1
11.1
25.4
25.4
12.3 ± 20.8
Mutation
General
17.6
13.2
2.9
66.2
15.5 ± 16.6
Exploratory
3.3
13.1
1.6
82.0
17.9 ± 20.8
Lifted
12.2
18.4
6.1
63.3
8.1 ± 13.1
Crossover
Hybrid
13.2
15.1
3.8
67.9
3.0 ± 11.0
Intersect
7.7
9.9
5.5
76.9
1.3 ± 8.7
Complement
4.2
14.3
6.7
74.8
14.7 ± 13.9
Min Violation
10.1
11.9
9.2
68.8
-0.4 ± 9.6
Table 4: Agent-level performance statistics for each EVOCUT agent. Reported are the percentages of code-generation failures,
OSP failures, and usefulness rejections, the overall success rate, and the mean improvement rate ¯∆f ± σ. The improvement rate
∆f = (fchild −fparent)/fparent is computed relative to the average fitness of the parent population (or the neutral fitness value
10 for the initializer).
D
Supplementary Text on Mathematical
Preliminaries
D.1
Polyhedra and Facets
A polyhedron is any set Q in Rd that can be described by
finitely many linear inequalities. The constraints Ax ≤b are
the linear inequalities that define Q
Q = { x ∈Rn : Ax ≤b}.
Polyhedra are convex, and if Q is bounded, it is called a
polytope.
A face of a polyhedron Q is a set of the form F := Q ∩
{x ∈Rn : cx = d} where cx ≤d is a valid inequality for
Q. We say that the valid inequality cx ≤d defines the face
F of the polyhedron P. Note that cx = d is a supporting
hyperplane (has at least one point common with Q). A facet
is a face of maximum dimension (i.e., one dimension less
than that of the polyhedron).
For example, consider a cube as a 3D polytope in R3 and a
plane as the supporting hyperplane. Intersecting a cube with
a supporting hyperplane may result in a 0D corner point, a
1D straight line, or a 2D plane. The corner point, the line
(edge of a cube), and the 2D plane are all faces of the 3D
cube. However, only the 2D plane is a facet of the 3D cube.
D.2
Facet-defining Valid Inequalities
In the context of integer programming, valid inequalities
that are facet-defining for conv(S) are especially important
because they are necessary and sufficient for characterizing
conv(S). When conv(S) is characterized, solving the MILP
on set S (that is generally NP-hard) reduces to the linear
program of maximizing cT x + hT y on conv(S) (which is
polynomially solvable).
E
Additional Experiments
E.1
Representative TSP-instance trajectories
To give a more detailed view of EVOCUT’s behavior, Fig. 7
plots the full gap-time traces for four challenging TSPLIB
instances. Each panel compares the baseline MILP (blue
line) with the same model augmented by the single strongest
EVOCUT inequality found during evolution (orange line).
The line plots confirm that the cut drives a markedly faster
gap closure. Note, the cut used in Fig. 7 for the TSP problem
is described in F.
E.2
Best-Bound Trajectories for Representative
TSP Instances
Fig. 8 complements the gap-based results of Section 5.2 by
plotting the solver-reported best bound over time for four
representative TSP test instances drawn from Dt. For each
instance we show two curves: the baseline MILP (reference)
and the MILP augmented with the strongest EVOCUT in-
equality (cut). Solver logs are sampled when it finds an MILP
incumbent up to the same 300 s wall-clock limit. Because
TSP is formulated as a minimization problem, higher curves
correspond to tighter lower bounds.
E.3
Primal-Dual-Integral (PDI) Trajectories for
Representative TSP Instances
Where Fig. 7 focused on the (instantaneous) gap and Fig. 8
on the solve, reported best lower bound, Fig. 9 complements
both views by plotting the primal-dual-integral (PDI), a cu-
mulative metric that rewards closing the gap early and penal-
izes every second the gap remains open.2 As before, the blue
curve shows the baseline MILP; the orange curve adds the
single strongest EVOCUT acceleration cut. Across all four
cases, the EVOCUT-strengthened model reduces the total
PDI by ≈50−85%, demonstrating that acceleration cuts is
enough to deliver faster, and ultimately better, overall search
progress than the handcrafted baseline.
E.4
Representative IMO-P6-instances trajectories
Fig. 10 reports full MIPGap-time trajectories on the held-
out test set for the IMO 2025 P6 tiling problem (N ∈
2PDI is the time-integral of the optimality gap, hence lower
curves are better and earlier plateauing indicates faster convergence.


--- Page 13 ---
  
Per‑machine workload lower bound: 
 must at least equal each
machine’s total processing time.
Skips machines with no operations to avoid errors. Computes job
prefix/suffix times only when needed, ensuring Cmax respects machine
workloads and job order, while preserving strengthened bounds.
Lifted
  
 ≥ each machine’s load plus its shortest job‐prefix and job‐suffix.
  
 must at least equal the average workload per machine.
Combines Parent1's global average with Parent2's machine-specific bounds. Calculates a
global and machine-based lower bound, enforcing Cmax ≥ their maximum. Improves tightness
by balancing overall load and critical machine sequences.
Intersection
  
 ≥ the largest of (average load, worst machine’s critical path, or longest job).
Job‑interference bound: each job’s duration plus unavoidable minimal overlap on its
machines bounds 
.
Combined the max of the global-average and lifted-machine/longest-job
bounds with the job-interference bound via a max operator to yield the
hybrid cut.
Hybrid
  
Hybrid cut: takes the tightest among global average, lifted machine load, and job‑interference bounds for 
.
  
Combined bound: 
 must exceed both the global average load and the tightest lifted machine workload.
Lifted
Exploratory
Fitness: 15.7 
Fitness: 15.9
Fitness: 10.8
Fitness: 16.7
Fitness: 16.7
Fitness: 17.0
Fitness: 21.4
Lifted the combined max bound by incorporating the longest job’s
total processing time as an additional term.
Computes per-job lower bounds by adding a job’s total time to minimal interference
from others on shared machines. Captures unavoidable delays, reflecting job-
specific contention and complementing machine-based bounds.
Figure 5: Steps in the development of the best cut for the JSSP. Blue panel: baseline formulation. Green panels: candidate cuts
with annotated fitness. Yellow panels: agent instructions that produced each offspring.
{4, 9, 16, 25}; see Sec. F.5). Each panel compares the base-
line MILP (RT-2DFlow) (blue line) with the same model aug-
mented by our strongest EVOCUT family (EC-RT-Breaks)
(orange line).
Qualitatively, the trajectories provide a clear, instance-size
stratified view of EVOCUT’s effect: the hybrid hole-break
constraints accelerate early bound movement and maintain
a consistently lower gap across time compared to the base-
line. The cut used here is exactly the cut family defined
in (EC-RT-Breaks), described in App. F.5.
F
Benchmark MILP Problems and Best
EvoCut’s cut
F.1
Traveling Salesman Problem (TSP)
TSP aims to find the shortest cycle in a graph that visits
every node precisely once. It is a classic NP-hard com-
binatorial optimization (Laporte 1992) which has a pure
MILP model. For our experiments, we used the TSPLIB
instances (Reinelt 1991), a widely-used benchmark and the
formulation Eq. (MTZ).
Compact MILP formulation for TSP.









































min
X
(i,j)∈A
cij xij
s.t.
X
j∈V \{i}
xij = 1
∀i ∈V
X
i∈V \{j}
xij = 1
∀j ∈V
ui −uj + n xij ≤n −1
∀i, j ∈V \ {1}, i ̸= j
xij ∈{0, 1}
∀(i, j) ∈A
1 ≤ui ≤n
∀i ∈V,
u1 = 1
(MTZ)
Notation glossary.
• V (set): cities to be visited (index i, j).
• A ⊆V × V (set): directed arcs (i, j) that can be used.
• cij (parameter): travel cost from city i to city j.
• n = |V | (parameter): number of cities.
• xij ∈{0, 1} (variable): equals 1 iff the tour goes directly
from city i to city j.


--- Page 14 ---
8
10
12
14
16
18
20
Fitness
TSP
2
4
6
8
10
12
14
16
MCND
0
4
8
12
16
20
Generation
5
10
15
20
25
Fitness
JSSP
0
4
8
12
16
20
Generation
5
10
15
20
25
30
CWLP
Best Fitness
Mean Fitness
Figure 6: Best (blue, dashed) and mean (orange, dash-dotted) fitness across 20 generations for the TSP, MCND, CWLP, and
JSSP benchmarks. Shaded regions show one standard deviation.
0.000
0.025
0.050
0.075
0.100
0.125
0.150
0.175
0.200
att48
lin105
0
50
100
150
200
250
300
0.000
0.025
0.050
0.075
0.100
0.125
0.150
0.175
0.200
ulysses22
0
50
100
150
200
250
300
rd100
Time (seconds)
MIP gap
Baseline Problem
Baseline + EvoCut Problem
Figure 7: Gap-time trajectories for four representative TSP in-
stances (att48, lin105, ulysses22, and rd100) from
(Reinelt 1991). The orange lines correspond to the model
strengthened by the strongest EVOCUT inequality; blue lines
show the baseline MILP.
• ui ∈[1, n] (variable): Miller-Tucker-Zemlin (MTZ) po-
sition of city i in the tour; u1 is fixed to 1 to anchor the
numbering.
Inequalities (EC) tighten the LP relaxation of Eq. (MTZ)
by linking depot arcs with MTZ ordering, curbing subtours
and two-city detours. They were the single most effective cut
family selected by EVOCUT according to our gap-reduction
fitness metric.
0
20
40
60
80
100
0
2000
4000
6000
8000
10000
att48
0
50
100
150
200
250
300
13000
13200
13400
13600
13800
14000
14200
14400
lin105
0
10
20
30
40
50
60
0
1000
2000
3000
4000
5000
6000
7000
ulysses22
0
50
100
150
200
250
7550
7600
7650
7700
7750
7800
7850
7900
rd100
Time (seconds)
Best Bound
Baseline Problem
Baseline + EvoCut Problem
Figure 8: Evolution of the solver’s best bound for four rep-
resentative TSP instances. blue lines: baseline MILP (ref-
erence); orange lines: MILP with the strongest EVOCUT
inequality (cut).
Strongest EVOCUT cut family.















uj ≤2 + (n −2)(1 −x1j)
∀j ∈V \ {1}
ui ≥n −(n −2)(1 −xi1)
∀i ∈V \ {1}
xj1 + xji + (uj −ui −1)
≤(n −1)(2 −x1i −xij)
∀i, j ∈V \ {1}, i ̸= j
(EC)
Benchmark sizes.
We considered TSPLIB instances with
20 ≤n ≤250 cities.


--- Page 15 ---
0
20
40
60
80
100
0.0
0.5
1.0
1.5
2.0
2.5
att48
0
50
100
150
200
250
300
0
5
10
15
20
25
30
35
lin105
0
10
20
30
40
50
60
0.0
0.5
1.0
1.5
2.0
ulysses22
0
50
100
150
200
250
0
2
4
6
8
10
12
14
rd100
Time (seconds)
Primal dual integral
Baseline
Baseline+Cut
Figure 9: Primal-dual-integral (PDI) trajectories for the same
four TSPLIB instances used in Figs. 7-8. Lower curves are
better. Orange: baseline + strongest EVOCUT; blue: baseline
MILP.
0.005
0.010
0.015
0.020
0.025
0.030
0.0
0.2
0.4
0.6
0.8
1.0
N=4
0
25
50
75
100
125
150
175
N=9
0
50
100
150
200
250
300
0.0
0.2
0.4
0.6
0.8
1.0
N=16
0
2000
4000
6000
8000
10000
N=25
Time (seconds)
MIP gap
Baseline Problem
Baseline + EvoCut Problem
Figure 10: MIPGap-time trajectories on four IMO P6
test sizes N
∈
{4, 9, 16, 25}. Blue: baseline MILP
(RT-2DFlow). Orange: baseline + strongest EVOCUT family
(EC-RT-Breaks). Each panel shows the full trace from solver
start up to the time limit 10000.
F.2
Multi-Commodity Network Design (MCND)
The MCND problem involves selecting a set of network links
and assigning multiple flow demands (commodities) at mini-
mal cost. Each commodity must be routed from its source to
destination without exceeding link capacities, and activating
a link incurs a fixed cost. MCND problem is an NP-hard com-
binatorial problem (Gendron, Crainic, and Frangioni 1999)
that can be formulated as an MILP. We used a publicly avail-
able set of MCND instances (group R from the CommaLAB
dataset) (CommaLAB 2021), which provide a range of net-
work sizes, cost structures, and capacity tightness scenarios.
We used the MILP formulation (MCND).
Compact MILP formulation for MCND.

































































min
X
(i,j)∈A
X
k∈K
cij xijk +
X
(i,j)∈A
fij yij
s.t.
X
j:(i,j)∈A
xijk = dk
∀k ∈K, i = Ok
X
j:(j,i)∈A
xjik = dk
∀k ∈K, i = Dk
X
j:(i,j)∈A
xijk −
X
j:(j,i)∈A
xjik = 0
∀k ∈K, i ∈N \ {Ok, Dk}
X
k∈K
xijk ≤uij yij
∀(i, j) ∈A
xijk ≥0
∀(i, j) ∈A, k ∈K
yij ∈{0, 1}
∀(i, j) ∈A
(MCND)
Notation glossary.
• N (set): all network nodes (index i).
• A ⊆N × N(set): candidate directed arcs (i, j).
• K(set): commodities to be routed (index k).
• Ok / Dk(nodes): origin and destination of commodity k.
• dk (parameter): demand (quantity) of commodity k that
must be shipped from Ok to Dk.
• cij (parameter): unit transportation cost on arc (i, j).
• fij (parameter): fixed cost to activate arc (i, j).
• uij (parameter): capacity of arc (i, j).
• xijk ≥0 (variable): flow of commodity k on arc (i, j).
• yij ∈{0, 1} (variable): equals 1 iff arc (i, j) is activated.
Strongest EVOCUT cut family.
X
(i,j)∈δ−(Dk)
 uij + umax
k

yij ≥dk + umax
k
∀k ∈K
(EC)
Here, δ−(Dk) denotes the set of arcs entering the destination
node Dk of commodity k, and umax
k
:= max(i,j)∈δ−(Dk) uij
is the maximum incoming capacity. Inequality (EC) strength-
ens the formulation by ensuring that high-capacity arcs must
be selected if the demand is large, improving LP relaxation
bound. This cut was selected by EVOCUT as the most effec-
tive according to the gap-reduction fitness metric.
Benchmark sizes.
We used the group R instances from the
CommaLAB dataset, which cover diverse network topolo-
gies and demand settings. Each instance is identified as rx.y,
where x determines the network size and number of com-
modities, and y encodes the fixed cost and capacity regime.
Table 5 summarizes the key characteristics of the x configu-
rations used in our bencmark dataset.
The fixed cost and capacity configuration is governed by
the second index y in rx.y. Higher fixed costs increase the
relative importance of arc selection costs, while higher capac-
ities relax arc flow constraints.


--- Page 16 ---
x
# Nodes
# Arcs
# Commodities
01-09
10
35-83
10-50
10-12
20
120
40-200
13-15
20
220
40-200
16-18
20
314-318
40-200
Table 5: Representative ranges in CommaLAB R MCND
instances
F.3
Capacitated Warehouse Location Problem
(CWLP)
The CWLP is an NP-hard combinatorial optimization
problem, formulated as a mixed-integer linear program
(MILP) (Beasley 1988). It involves selecting a subset of
candidate warehouse locations to open and assigning each
customer to one open warehouse. The problem is subjected
to capacity constraints at each facility, with the goal of mini-
mizing total fixed opening and transportation costs.We used
a publicly available set (Beasley 1990) CWLP instances. For
our experiments, We use the formulation in Eq. (CWLP).
Compact MILP formulation.





































min
X
j∈J
fj yj +
X
i∈I
X
j∈J
cij xij
s.t.
X
j∈J
xij = 1
∀i ∈I
(each customer is assigned)
X
i∈I
di xij ≤uj yj
∀j ∈J
(capacity)
xij ∈{0, 1}
∀i ∈I, j ∈J
yj ∈{0, 1}
∀j ∈J
(CWLP)
Glossary of notation.
• I (index i): set of customers.
• J (index j): set of candidate warehouses.
• di: demand of customer i.
• uj: capacity of warehouse j.
• fj: fixed cost to open warehouse j.
• cij: total transportation cost incurred if all of customer i’s
demand is served by warehouse j (so cij already accounts
for di).
• yj ∈{0, 1}: decision variable; 1 if warehouse j is opened,
0 otherwise.
• xij ∈{0, 1}: decision variable; 1 if customer i is assigned
to warehouse j, 0 otherwise.
Strongest EVOCUT cut (idea and definition).
This cut
gives a global lower bound on how many warehouses must
be opened. It merges three intuitive sub-bounds:
• Critical-customer bound kcrit: every customer whose
demand exceeds half the capacity of the largest warehouse
must be alone.
• Demand-cover bound kdem: you need enough of the
largest warehouses so that their combined capacity meets
total demand.
• T-cover bound kT : large customers that cannot fit into
”small” facilities force additional large facilities to open.
Let D = P
i∈I di,
uj1
≥uj2
≥. . . ≥uj|J|
be total demand and the capacities in non-increasing order.
Define
C =

i ∈I : di > 1
2 max
j∈J uj
	
,
kcrit = |C|,
kdem = min
n
r :
r
X
ℓ=1
ujℓ≥D
o
,
T =

j ∈J : uj ≥max
i∈I di
	
,
IT =

i ∈I : di > max
j /∈T uj
	
,
kT = fewest j ∈T covering
X
i∈IT
di.
Set
kmin = max

kcrit, kdem, kT
	
.
The Strongest EVOCUT inequality is then
X
j∈J
yj
≥
kmin.
(EC)
Benchmark sizes.
We considered large instances available
in OR-LIB benchmark (Beasley 1990)(100 facility locations
and 1000 customers), also with a random generator available
in our code, we compensated the number of needed instances
for our experiments.
F.4
Job Shop Scheduling Problem (JSSP)
The JSSP is a classic NP-hard combinatorial optimization
problem, typically formulated as an MILP (Manne 1960). It
involves scheduling a set of jobs on multiple machines, where
each job comprises a sequence of operations that must be
processed in a specified order on designated machines. The
objective is to minimize the makespan (the completion time
of the last operation), ensuring that each machine handles
at most one operation at a time. We use the formulation
in Eq. (JSSP) and test EvoCut on the widely used Taillard
benchmark (Taillard 1993).
Compact MILP formulation.



























































min Cmax
s.t.
Sj,k+1 ≥Sj,k + pj,k
∀j, k = 0, . . . , nmach −2
Sj1,k1 + pj1,k1 ≤
Sj2,k2 + M(1 −yj1,k1,j2,k2)
∀
 (j1, k1), (j2, k2)

∈P
Sj2,k2 + pj2,k2 ≤
Sj1,k1 + M yj1,k1,j2,k2
∀
 (j1, k1), (j2, k2)

∈P
Cmax ≥Sj,nmach−1 + pj,nmach−1
∀j
Sj,k ≥0
∀j, k
yj1,k1,j2,k2 ∈{0, 1}
∀
 (j1, k1), (j2, k2)

∈P
(JSSP)


--- Page 17 ---
Variable and set glossary.
• Sj,k ∈R≥0: continuous start time of the k-th operation of
job j.
• pj,k: fixed processing time of operation (j, k) (data).
• P: set of ordered pairs
 (j1, k1), (j2, k2)

of distinct op-
erations that require the same machine. For every such
pair, exactly one of the two order-enforcing inequalities
becomes active.
• yj1,k1,j2,k2 ∈{0, 1}: binary variable that equals 1 if oper-
ation (j1, k1) is scheduled before (j2, k2) on their shared
machine, 0 otherwise.
• Cmax ∈R≥0: continuous makespan (completion time of
the last operation); the objective minimizes this value.
• M: a sufficiently large constant (”big-M”) that deactivates
the non-selected sequencing inequality.
Strongest EVOCUT cut family.
Cmax ≥max
n 1
m
X
(j,k)∈O
pj,k,
max
machines
 CPm

, max
jobs
 Interfj
o
(EC)
This hybrid inequality combines three lower bounds on the
makespan:
• Average load bound: 1
m
P
(j,k)∈O pj,k represents the av-
erage total processing time per machine, ensuring that the
makespan is at least the average workload.
• Machine-level critical path bound (CPm): For each ma-
chine m, this bound considers the sum of processing times
of operations assigned to it plus the minimal cumulative
processing times of operations that must precede or suc-
ceed these operations in their respective jobs. CPm captures
the tightest scheduling constraints on machine m.
• Job interference bound (Interfj): For each job j, this
bound sums the processing times of its operations and
adds the minimal processing times of conflicting operations
from other jobs that share machines with j’s operations.
This accounts for potential delays due to job interference.
These three bounds collectively tighten the LP relaxation
by incorporating both machine workloads and inter-job con-
flicts. The hybrid inequality was identified as the most effec-
tive cut by EVOCUT based on optimality gap reduction.
Benchmark sizes.
We evaluated EVOCUT on the Taillard
benchmarks. This includes instances with the following job
and machine counts:
• 15 jobs × 15 machines (e.g., ta01-ta10),
• 20 jobs × 15 machines (e.g., ta11-ta20),
• 50 jobs × 15 machines (e.g., ta41-ta50),
• 100 jobs × 20 machines (e.g., ta71-ta80).
These instances are widely used in the literature to assess
the performance of scheduling algorithms on problems of
varying complexity.
F.5
Rectangular Tiling with One Hole per Row
and Column (IMO 2025 P6)
This benchmark is based on IMO 2025 Problem 6: given an
N × N grid of unit squares, place axis-aligned rectangular
tiles (no overlaps) so that each row and each column contains
exactly one uncovered unit square (a hole); the objective is to
minimize the number of tiles used (Art of Problem Solving
Wiki 2025). We model this with a 2D “interval×flow” MILP
that matches the Pyomo code used in our experiments.
Compact MILP formulation.
Let R = {1, . . . , N} be the
rows, C = {1, . . . , N} the columns, and I = {(a, b) ∈C ×
C : a ≤b} the set of horizontal column-intervals. Binary
variables: hij indicate the hole position, xab
i
indicate that
interval (a, b) is active on row i, and sab
i /tab
i
are the start/end
markers of the corresponding vertical strip (rectangle) for
(a, b) at row i. The objective counts rectangles because each
rectangle contributes exactly one start.3













































































































min
X
i∈R
X
(a,b)∈I
sab
i
s.t.
X
j∈C
hij = 1
∀i ∈R
(one hole per row)
X
i∈R
hij = 1
∀j ∈C
(one hole per column)
X
(a,b)∈I
a≤j≤b
xab
i
+ hij = 1
∀i ∈R, ∀j ∈C
(each cell covered at most once)
xab
1
−sab
1
= 0
∀(a, b) ∈I
(top flow)
xab
i
−xab
i−1 −sab
i
+ tab
i−1 = 0
∀i = 2, . . . , N, ∀(a, b) ∈I
(mid flow)
xab
N −tab
N = 0
∀(a, b) ∈I
(bottom flow)
hij ∈{0, 1}
∀i ∈R, ∀j ∈C
xab
i , sab
i , tab
i
∈{0, 1}
∀i ∈R, ∀(a, b) ∈I
(RT-2DFlow)
Notation glossary.
• R = {1, . . . , N}, C = {1, . . . , N}: row and column index
sets (i ∈R, j ∈C).
• I = {(a, b) ∈C2 :
a ≤b}: all contiguous column-
intervals (index (a, b)).
• hij ∈{0, 1}: = 1 iff (i, j) is the unique hole in row i and
in column j.
• xab
i
∈{0, 1}: = 1 iff on row i the columns a, a+1, . . . , b
are covered by the same tile.
• sab
i , tab
i
∈{0, 1}: start/end flags of the vertical strip for
interval (a, b) at row i; the number of rectangles equals
P
i,(a,b) sab
i .
3By the flow equalities below, each maximal vertical strip for
(a, b) has one start and one end; hence P s equals the number of
rectangles.


--- Page 18 ---
Strongest EVOCUT cut family.
The best-performing fam-
ily consists of horizontal and vertical break constraints that
couple the hole position to local starts/ends, ensuring cover-
age splits both horizontally and vertically around the hole.













































































hij ≤
X
(a,b)∈I
b=j−1
tab
i
∀i ∈R, ∀j ∈{2, . . . , N}
hij ≤
X
(a,b)∈I
a=j+1
sab
i
∀i ∈R, ∀j ∈{1, . . . , N −1}
h1j ≤
X
(a,b)∈I
a≤j≤b
sab
2
∀j ∈C
hNj ≤
X
(a,b)∈I
a≤j≤b
tab
N−1
∀j ∈C
hij ≤
X
(a,b)∈I
a≤j≤b
tab
i−1
∀i ∈{2, . . . , N−1}, ∀j ∈C
hij ≤
X
(a,b)∈I
a≤j≤b
sab
i+1
∀i ∈{2, . . . , N−1}, ∀j ∈C
(EC-RT-Breaks)
The first two constraints enforce a horizontal split on the row
containing the hole: one interval ends immediately to the left
of the hole, and another begins immediately to the right. The
next two handle holes in the first or last row, forcing a vertical
split in the adjacent row. The final two treat interior holes,
ensuring that above the hole there is an ending interval and
below the hole there is a starting interval, yielding a tighter
LP relaxation.
Benchmark sizes.
We used two disjoint sets of N:
• Verification & evaluation set: N
∈
{4, . . . , 17} \
{4, 9, 16} = {5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17}.
• Held-out test set: N ∈{4, 9, 16, 18, 19, 20, 25}.
G
LLM API Configuration
Table 6 lists the exact parameters used in every call to
the deepseek-reasoner API throughout our EVOCUT
pipeline and the approximate token usage.
Parameter
Value
Model
deepseek-reasoning
Maximum output tokens
10,000
Temperature
1.0
Frequency penalty
0.0
Presence penalty
0.0
Average prompts per cut
4.2
Total input tokens
∼61 M
Total output tokens
∼30 M
Total tokens
∼91 M
Total cost (May 2025 pricing)
∼$50
Table
6:
Approxiamte
configuration
for
all
deepseek-reasoner calls.
H
Fitness definition
Given
the
signed
relative
gap
change
d(i)
=
gapcut(i)−gapref(i)
gapref(i)
, its mean over De, C =
1
|De|
P
i∈De d(i),
is negative when C is beneficial and positive when it is harm-
ful. We map C to a fitness score via Fit(C)
=
10 e−C,
so larger (more negative) gap reductions yield exponentially
higher fitness.
