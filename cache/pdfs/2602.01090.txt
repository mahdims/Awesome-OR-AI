--- Page 1 ---
Hard Constraints Meet Soft Generation:
Guaranteed Feasibility for LLM-based Combinatorial Optimization
Yang Liu 1 Chuan Zhou 1 2 Yancheng Chen 1 Shuai Zhang 1 Xixun Lin 3 Xiaoqing Wang 4
Abstract
Large language models (LLMs) have emerged as
promising general-purpose solvers for combina-
torial optimization (CO), yet they fundamentally
lack mechanisms to guarantee solution feasibility
which is critical for real-world deployment. In
this work, we introduce FALCON, a framework
that ensures 100% feasibility through three key
innovations: (i) grammar-constrained decoding
enforces syntactic validity, (ii) a feasibility repair
layer corrects semantic constraint violations, and
(iii) adaptive Best-of-N sampling allocates infer-
ence compute efficiently. To train the underlying
LLM, we introduce the Best-anchored Objective-
guided Preference Optimization (BOPO) in LLM
training, which weights preference pairs by their
objective gap, providing dense supervision with-
out human labels. Theoretically, we prove conver-
gence for BOPO and provide bounds on repair-
induced quality loss. Empirically, across seven
NP-hard CO problems, FALCON achieves perfect
feasibility while matching or exceeding the solu-
tion quality of state-of-the-art neural and LLM-
based solvers.
1. Introduction
Combinatorial Optimization (CO) underpins critical real-
world systems, from logistics planning (Bao et al., 2018) and
manufacturing scheduling (Zhang et al., 2023) to emergency
resource allocation (Jain & Bharti, 2023). These problems
involve selecting optimal configurations from exponentially
large search spaces while satisfying complex constraints.
Traditionally, solving them has required domain-specific
heuristics or exact algorithms (Liu et al., 2024d; 2023;
2024c), which demand substantial expert engineering and
1Academy of Mathematics and Systems Science, Chinese
Academy of Sciences 2School of Cyber Security, University of Chi-
nese Academy of Sciences 3Institute of Information Engineering,
Chinese Academy of Sciences 4Alibaba Group. Correspondence
to: Chuan Zhou <zhouchuan@amss.ac.cn>.
Preprint. Work in progress.
lack generalizability across problem domains.
The emergence of large language models (LLMs) has in-
troduced a paradigm shift. By directly mapping natural-
language problem descriptions to solution sequences, LLMs
offer a unified, accessible interface for combinatorial op-
timization (Jiang et al., 2025). Recent work demonstrates
that LLMs possess remarkable pattern recognition and se-
quential generation capabilities, achieving competitive per-
formance across diverse CO problems when fine-tuned with
supervised or reinforcement learning (Jiang et al., 2025).
This suggests a promising path toward general-purpose,
language-driven optimization.
However, a fundamental contradiction remains: LLMs are,
at their core, unconstrained generative models. When faced
with hard combinatorial constraints—such as Hamiltonian
cycles, capacity limits, or precedence relations—they lack
any intrinsic mechanism to guarantee constraint satisfaction.
Existing methods treat feasibility as a soft objective, incen-
tivized through reward shaping during training but never
enforced during inference. Consequently, single-sample
feasibility rates vary widely and remain below 100% even
for moderately complex problems (Jiang et al., 2025). For
safety-critical deployments in logistics (McGarvey et al.,
2025), manufacturing (Meurer et al., 2025), or other high-
stakes domains, such unreliability is unacceptable. The
core scientific challenge is therefore clear: How can we
equip expressive generative models with verifiable, 100%
constraint-satisfaction guarantees without sacrificing their
problem-solving power?
This challenge manifests in two layers. First, LLMs can
generate syntactically valid outputs that are semantically
infeasible—a correctly formatted vehicle route may exceed
capacity, or an independent set may contain adjacent ver-
tices. Syntax alone cannot encode the semantic constraints
intrinsic to each problem class. Second, training-time en-
couragement (via rewards or preferences) does not translate
to inference-time guarantees. The model might learn to
often produce feasible solutions, but it cannot be forced to
do so, creating a critical gap between probabilistic encour-
agement and deterministic reliability.
To bridge this gap, we introduce FALCON (Feasibility-
1
arXiv:2602.01090v1  [cs.AI]  1 Feb 2026


--- Page 2 ---
Hard Constraints Meet Soft Generation
Aware Language-based Combinatorial Optimization with
Adaptive Inference), the first LLM-based CO framework
with a provable 100% feasibility guarantee. FALCON is
built on a key conceptual insight: separate the challenge into
syntactic validity and semantic feasibility, and address each
with a dedicated, verifiable layer. Specifically, we integrate
three synergistic components: (1) grammar-constrained
decoding, which enforces output format correctness via
problem-specific context-free grammars; (2) feasibility re-
pair operators, which transform any constraint-violating
solution into a feasible one; and (3) adaptive Best-of-N
sampling, which dynamically allocates inference compute
based on instance difficulty. These components are trained
using Best-anchored Objective-guided Preference Optimiza-
tion (BOPO), a novel objective that weights preference pairs
by their objective-value gaps, providing dense, automatic
supervision.
Our contributions are as follows:
1. We present FALCON, the first LLM-based CO solver
that guarantees 100% feasibility through a layered archi-
tecture of grammar enforcement, semantic repair, and
adaptive inference. We provide formal proofs of feasi-
bility, format validity, and bounds on solution-quality
degradation after repair.
2. We introduce BOPO in LLM training, a principled train-
ing method that incorporates objective-guided weighting
into preference optimization. We prove its O(1/
√
T)
convergence under standard assumptions and demon-
strate its superiority over reward shaping and advantage
normalization.
3. We conduct an extensive evaluation across seven NP-hard
problems spanning routing, graph, and scheduling do-
mains. Results show that FALCON achieves consistent
100% feasibility while maintaining competitive optimal-
ity gaps, outperforming both general-purpose LLMs and
recent neural CO solvers.
2. Preliminaries
2.1. Problem Formulation
Let P represent a class of combinatorial optimization prob-
lems. Each instance p ∈P is defined as a tuple (Xp, fp, Cp),
where Xp is the solution space containing all well-formed
solution representations, fp : Xp →R is the objective func-
tion to minimize, and Cp = {cp,1, . . . , cp,mp} is a set of
constraints with each cp,i : Xp →{0, 1} indicating whether
a solution satisfies constraint i.
Definition 2.1 (Feasible Solution). A solution x ∈Xp is
feasible if it satisfies all constraints: ∀cp,i ∈Cp : cp,i(x) =
1. The feasible region is:
XCp = {x ∈Xp | ∀cp,i ∈Cp : cp,i(x) = 1}.
The optimization goal is to find x∗
p = arg minx∈XCp fp(x).
2.2. LLM as an End-to-End Solver
Let πθ : T →T be an LLM with parameters θ, where
T is the space of text sequences. We define two mapping
functions: ϕ : P →T maps problem instances to text
descriptions, and ψp : T ⇀Xp is a partial function that
parses text sequences into solutions when the text conforms
to valid syntax. The end-to-end solution pipeline attempts
to produce ˆxp = ψp(πθ(ϕ(p))), which succeeds only if
the generated text is parseable and the parsed solution is
feasible, i.e., ˆxp ∈XCp.
3. LLM-based CO Framework: FALCON
3.1. Grammar-Constrained Decoding
The first layer of our feasibility guarantee ensures format
validity—outputs must be syntactically correct with well-
formed brackets, valid delimiters, and in-range indices.
3.1.1. PROBLEM-SPECIFIC GRAMMARS
We define context-free grammars (CFGs) for each CO prob-
lem that precisely specify valid output formats.
Definition 3.1 (CO Output Grammar). A CO output gram-
mar is a tuple G = (V, Σ, R, S), where V is the set of
non-terminal symbols (e.g., NODELIST, NUMBER), Σ is the
set of terminal symbols corresponding to tokens in the LLM
vocabulary, R is the set of production rules specifying valid
derivations, and S is the start symbol.
Definition 3.2 (Input-Dependent Grammar). For an in-
stance p with n nodes, the input-dependent grammar Gp =
(V, Σp, Rp, S) specializes the base grammar G by restrict-
ing the production rules for node indices to generate only
valid indices {0, 1, . . . , n −1}, thereby preventing out-of-
range references.
Complete grammar specifications for all seven problems are
provided in Section D.
3.1.2. CONSTRAINED DECODING ALGORITHM
At each decoding step, we maintain a pushdown automa-
ton (PDA) configuration corresponding to the current parse
state and mask tokens that would lead to invalid continua-
tions. For a given grammar G, we construct an equivalent
PDA A = (Q, Σ, Γ, δ, q0, Z0, F) that recognizes L(G) us-
ing standard CFG-to-PDA conversion.
Theorem 3.3 (Format Validity Guarantee). For any output
y generated by Algorithm 1 upon termination with grammar
G, we have y ∈L(G) where L(G) is the language defined
by G.
Remark 3.4 (Computational Overhead). The overhead per
2


--- Page 3 ---
Hard Constraints Meet Soft Generation
Algorithm 1 Grammar-Constrained Decoding
Input
:Grammar G, prompt x, LLM πθ
Output :Valid solution text y ∈L(G)
1 Initialize PDA configuration (q0, Z0) from A y ←""
2 while not at accepting state do
3
logits ←πθ(x, y)
// Forward pass
4
5
Vvalid ←{v ∈Σ | δ(q, v, top(γ)) ̸= ∅}
6
foreach v /∈Vvalid do
7
logits[v] ←−∞// Mask invalid tokens
8
9
vnext ←sample(softmax(logits))
10
y ←y + vnext
11
Update PDA configuration (q, γ) via δ
12 return y
token is O(|Σ| · |Q|) for computing valid tokens via PDA
transition lookup, where |Σ| is the vocabulary size and
|Q| is the number of PDA states. For CO grammars with
simple structure, |Q| = O(1), yielding O(|Σ|) overhead per
token. With |Σ| ≈32K for modern LLMs, this is negligible
compared to the O(d2) attention computation where d is
the hidden dimension.
3.2. Feasibility Repair Layer
Grammar constraints ensure format validity but not semantic
feasibility. A syntactically valid CVRP route may exceed
vehicle capacity; a well-formed MIS may contain adjacent
vertices. The repair layer addresses this challenge.
3.2.1. REPAIR OPERATOR DESIGN
Definition 3.5 (Repair Operator). A repair operator R :
Xp →XCp for constraint set Cp satisfies:
1. Feasibility: ∀x ∈Xp : R(x) ∈XCp
2. Idempotence: ∀x ∈XCp : R(x) = x
3. Bounded Locality: There exists a distance metric d :
Xp × Xp →R≥0, a violation magnitude function v :
Xp →R≥0, and a constant α > 0 such that:
d(R(x), x) ≤α · v(x),
where v(x) = 0 if and only if x ∈XCp.
Property (1) guarantees that any input is mapped to a feasi-
ble solution. Property (2) ensures that already-feasible so-
lutions are unchanged, avoiding unnecessary quality degra-
dation. Property (3) provides a quantitative bound on the
modification distance, which is proportional to the constraint
violation magnitude.
Table 1. Repair operators for each problem type with worst-case
time complexity. Here n denotes the number of nodes/jobs, m the
number of machines, and |E| the number of edges.
Problem
Repair Strategy
Complexity
TSP
Remove duplicates, greedy insertion of missing nodes
O(n2)
CVRP
TSP repair per route + split overloaded routes
O(n2)
OP
Remove nodes with worst prize/distance ratio†
O(n log n)
MIS
Remove higher-degree vertex from each conflict
O(|E| · n)
MVC
Add higher-degree endpoint of uncovered edges
O(|E|)
PFSP
Greedy insertion to minimize makespan
O(n2m)
JSSP
Permutation repair + topological sort
O(n2m)
†Assumes priority queue; O(n2) without.
3.2.2. PROBLEM-SPECIFIC REPAIR STRATEGIES
We design efficient repair operators for each problem type,
summarized in Table 1. The key insight is that each operator
addresses the specific constraint violation pattern: permuta-
tion problems (TSP, PFSP) require duplicate removal and
missing element insertion; capacity problems (CVRP, OP)
need route splitting or node removal; and graph problems
(MIS, MVC) involve greedy vertex addition or removal
based on degree. Details are provided in Appendix E.
3.2.3. THEORETICAL GUARANTEES
Theorem 3.6 (100% Feasibility Guarantee). With repair
operator R satisfying Definition 3.5, for any number of
samples N ≥1:
P(all N outputs are feasible) = 1.
This guarantee follows directly from Property (1) of Defi-
nition 3.5, which ensures that every output of R lies in the
feasible region XCp regardless of the input.
Theorem 3.7 (Repair Quality Bound). Let d : Xp × Xp →
R≥0 be a distance metric on solutions and v : Xp →R≥0
denote the constraint violation magnitude (e.g., capacity
overflow, number of conflicts). Suppose the repair operator
satisfies d(R(x), x) ≤α · v(x) for some constant α > 0,
and the objective fp is Lf-Lipschitz continuous with respect
to d. Then:
fp(R(ˆxp)) ≤fp(ˆxp) + Lf · α · v(ˆxp).
This theorem provides an explicit bound on quality degra-
dation proportional to the violation magnitude v(ˆxp). In
practice, BOPO-trained models produce mostly feasible so-
lutions, so violations are rare and small, leading to minimal
degradation. When v(ˆxp) = 0 (input already feasible), the
bound becomes trivial and Property (2) ensures no modifi-
cation occurs.
Corollary 3.8 (Sample Efficiency of Repair). To achieve
feasibility rate 1−δ through sampling alone (without repair),
3


--- Page 4 ---
Hard Constraints Meet Soft Generation
the expected number of samples required is:
E[N] = 1
pf
(rejection sampling),
or for fixed-budget sampling with confidence 1 −δ:
N ≥
log(1/δ)
log(1/(1 −pf)) = log(1/δ)
pf
+ O(pf)
as pf →0,
where pf is the single-sample feasibility rate. With repair,
N = 1 suffices for 100% feasibility, providing up to log(1/δ)
pf
speedup for achieving target confidence.
3.3. Adaptive Best-of-N Sampling
Fixed-N sampling is inefficient: easy instances may need
only a single sample while hard instances may benefit from
extensive exploration. We propose adaptive sampling based
on solution consistency.
3.3.1. DIFFICULTY ESTIMATION VIA CONSISTENCY
Definition 3.9 (Solution Consistency). Given K ≥2 solu-
tions {y1, . . . , yK} sampled independently from the model,
the consistency measure is:
Cons =
1
K(K −1)
K
X
i=1
X
j̸=i
1[yi = yj],
which computes the fraction of ordered pairs (yi, yj) that
are identical.
High consistency indicates the model is confident about
the solution—most samples agree, suggesting an “easy” in-
stance. Low consistency indicates uncertainty—samples
are diverse, suggesting a “hard” instance requiring more
exploration.
Lemma 3.10 (Consistency-Difficulty Relationship). For K
solutions sampled independently from distribution p over
solution space Y, the expected consistency satisfies:
E[Cons] =
X
y∈Y
p(y)2.
Furthermore, defining the R´enyi entropy of order 2 as
H2(p) = −log P
y p(y)2, we have:
E[Cons] = e−H2(p).
This result establishes a precise relationship between con-
sistency and the concentration of the model’s output dis-
tribution. Low entropy (concentrated distribution) yields
high consistency, while high entropy (diffuse distribution)
Algorithm 2 Adaptive Best-of-N Sampling
Input
:Instance p, bounds Nmin, Nmax, threshold τ
Output :Best feasible solution x∗
1 n ←0, solutions ←[ ]
2 while n < Nmax do
3
Sample yn from πθ with grammar constraints
4
yn ←R(yn)
// Ensure feasibility
5
solutions.append(yn)
6
n ←n + 1
7
if n ≥Nmin then
8
best ←arg miny∈solutions fp(y)
9
conf ←BayesianConfidence(solutions, best)
10
if conf ≥τ then
11
return best
// Early termination
12 return arg miny∈solutions fp(y)
yields low consistency. For a well-trained model, high con-
sistency among early samples indicates the model is con-
fident in a particular solution, suggesting an easy instance
that does not require extensive sampling. Conversely, low
consistency indicates model uncertainty about the optimal
solution, suggesting a harder instance that benefits from
additional exploration.
3.3.2. ADAPTIVE SAMPLING ALGORITHM
Algorithm 2 uses Bayesian confidence estimation to deter-
mine when to stop sampling. After collecting n samples, the
confidence that the current best solution y∗is optimal among
all samples is estimated using a Beta-Binomial model:
Conf(y∗) =
α0 + ny∗
α0 + β0 + n,
where ny∗is the count of samples matching y∗, and α0, β0
are prior parameters. We use α0 = β0 = 1 (uniform prior),
giving equal weight to all solutions a priori. High confidence
indicates convergence to a stable solution, triggering early
termination.
3.3.3. THEORETICAL ANALYSIS
Theorem 3.11 (Quality Improvement with Sampling). Let
ˆxN be the best solution from N i.i.d. samples and x∗be the
optimal solution to instance p. Define the optimality gap
gN = fp(ˆxN) −fp(x∗). If the single-sample gap g1 has
cumulative distribution function F, then:
E[gN] =
Z ∞
0
(1 −F(ϵ))Ndϵ.
This result follows from the tail integral formula for ex-
pectations: E[gN] =
R ∞
0
P(gN > ϵ)dϵ, combined with
P(gN > ϵ) = (1 −F(ϵ))N since gN is the minimum of N
independent samples.
4


--- Page 5 ---
Hard Constraints Meet Soft Generation
Corollary 3.12 (Exponential Gap Distribution). If the gap
follows an exponential distribution with rate λ > 0, i.e.,
F(ϵ) = 1 −e−λϵ for ϵ ≥0, then:
E[gN] =
1
Nλ = E[g1]
N
.
That is, expected gap decreases linearly with the number of
samples under this distributional assumption.
Theorem 3.13 (Adaptive Sampling Complexity). Let q de-
note the probability that a single sample from πθ yields a
solution with gap at most δ for some target gap threshold
δ > 0. The expected number of samples for Algorithm 2
satisfies:
E[Nadaptive] ≤Nmin + (Nmax −Nmin)(1 −q)Nmin
q
.
For easy instances where q is large (e.g., q = 0.8), the term
(1 −q)Nmin decays exponentially, yielding E[Nadaptive] ≈
Nmin. For hard instances with small q, the algorithm re-
quires more samples up to the maximum budget Nmax. The
bound demonstrates that adaptive sampling efficiently allo-
cates computational resources based on instance difficulty.
Complete proofs are provided in Appendix C.
3.4. BOPO: Best-anchored Objective-guided Preference
Optimization
3.4.1. MOTIVATION
Traditional RL methods for neural CO suffer from sparse
rewards: feedback is only available after complete solution
generation, providing limited guidance for intermediate to-
ken decisions. GRPO (Shao et al., 2024) addresses this by
normalizing rewards within a group and computing relative
advantages. However, in GRPO, gradient updates are dom-
inated by the highest-reward sample, with other samples
contributing minimally through advantage normalization.
We observe that CO problems have a natural preference
structure: given any two feasible solutions yi and yj, we
have yi ≻yj if and only if fp(yi) < fp(yj) (for minimiza-
tion). This provides dense, objective-guided supervision
without requiring explicit human annotation.
3.4.2. PREFERENCE PAIR CONSTRUCTION
For each problem instance p, we sample K solutions
{y1, . . . , yK} from the current policy πθ. Let Fp = {yi |
yi ∈XCp} denote the subset of feasible solutions, and
let y∗= arg miny∈Fp fp(y) be the best feasible solution
among the samples. We construct preference pairs using a
“best-anchored” strategy:
Dp = {(y∗, yi) | yi ∈Fp, yi ̸= y∗}.
This construction ensures that all inferior feasible solutions
contribute to learning, unlike GRPO where gradients are
dominated by the single best sample. Let K′ = |Fp| denote
the number of feasible samples.
3.4.3. OBJECTIVE-GUIDED LOSS FUNCTION
Not all preference pairs are equally informative. A solution
with a 50% optimality gap should provide a stronger learn-
ing signal than one with only a 1% gap. We capture this
intuition through objective-guided weighting:
Definition 3.14 (BOPO Loss). For preference pairs con-
structed from instance p, the BOPO loss LBOPO(θ) is:
−Ep∼D
h
1
K′−1
P
yi∈Fp\{y∗} w(∆i) · log σ (β · sθ(y∗, yi))
i
where ∆i
=
fp(yi) −fp(y∗) is the objective gap,
sθ(yw, yl) = log πθ(yw|ϕ(p))
πθ(yl|ϕ(p)) is the log-probability ratio,
w(∆) = ∆/ ¯∆is the objective-guided scaling factor with
¯∆=
1
K′−1
P
yi∈Fp\{y∗} ∆i > 0 being the average gap,
σ(·) is the sigmoid function, and β > 0 is a temperature
hyperparameter controlling preference strength.
The scaling factor w(∆) ensures that pairs with larger qual-
ity differences contribute proportionally more to the gradi-
ent. This provides dense, informative supervision through-
out training, as every inferior solution contributes according
to its quality gap.
3.4.4. CONVERGENCE ANALYSIS
We establish convergence guarantees for BOPO under stan-
dard assumptions: (i) L-smoothness of the loss function, (ii)
bounded variance of stochastic gradients with variance σ2,
and (iii) bounded scaling factors w(∆) ∈[wmin, wmax] for
some 0 < wmin ≤wmax < ∞. Complete statements are
provided in Appendix C.1.
Theorem 3.15 (BOPO Convergence). Under the smooth-
ness, bounded variance, and bounded scaling assumptions,
with learning rate η =
1
L
√
T , BOPO satisfies:
1
T
T −1
X
t=0
E[∥∇LBOPO(θt)∥2] ≤C1 + C2
√
T
= O
 1
√
T

,
where C1 = 2L(LBOPO(θ0) −L∗) depends on initialization
and C2 = w2
maxσ2 captures the variance from objective-
guided scaling.
The key insight is that the objective-guided scaling fac-
tor w(∆) affects only the variance constant C2, not the
O(1/
√
T) convergence rate, since the bounded scaling as-
sumption ensures w(∆) remains controlled.
Corollary
3.16
(Iteration
Complexity).
To
find
an
ϵ-stationary
point
satisfying
mint∈{0,...,T −1} E[∥∇LBOPO(θt)∥2]
≤
ϵ,
BOPO re-
quires T
= O(1/ϵ2) iterations, matching the rate of
standard SGD for smooth non-convex optimization.
5


--- Page 6 ---
Hard Constraints Meet Soft Generation
Table 2. Comparison with baselines. Fea.: Feasibility (%). Gap: Optimality gap (%). Best and second best are highlighted.
Method
TSP
OP
CVRP
MIS
MVC
PFSP
JSSP
Time (s)
Fea.(%)
Gap(%)
Fea.(%)
Gap(%)
Fea.(%)
Gap(%)
Fea.(%)
Gap(%)
Fea.(%)
Gap(%)
Fea.(%)
Gap(%)
Fea.(%)
Gap(%)
General-Purpose LLMs (Zero-shot)
GPT-4o
39
33.79
59
55.19
15
76.62
8
11.70
6
16.67
88
20.57
7
97.85
5.3
GPT-4o-mini
28
53.38
80
70.70
3
68.10
0
0.00
3
29.52
78
21.47
8
212.00
4.5
Claude-3.5-Sonnet
66
24.53
49
34.62
30
38.34
13
12.51
2
6.25
100
18.42
10
90.00
5.4
Claude-3.5-Haiku
45
38.60
26
51.26
4
41.48
2
23.33
6
43.01
73
20.58
9
95.51
5.1
DeepSeek-V3
73
35.75
50
46.10
21
58.22
5
12.05
15
37.15
58
20.81
52
103.19
26.4
Llama-3.3-70B
50
69.08
27
48.98
31
97.31
8
37.12
20
22.86
98
21.97
29
105.01
2.1
Qwen2.5-72B
20
36.89
32
49.36
61
180.91
14
29.56
5
63.20
98
21.13
53
103.90
12.5
Reasoning Models
GPT-o3-mini
91
306.00
8
43.93
50
139.00
66
9.23
33
2.98
98
16.97
20
77.86
84.0
GPT-o1
54
276.00
31
40.90
24
154.00
82
8.03
47
3.58
89
14.86
29
81.90
192.0
DeepSeek-R1
48
70.99
60
40.54
26
30.46
41
1.60
38
4.17
100
16.65
5
26.29
390.0
LLM-based Optimization
OPRO
83
35.98
85
53.96
21
37.03
7
5.95
9
41.67
99
18.40
65
83.35
126.0
LMEA
77
265.00
48
66.18
24
61.24
5
25.00
13
34.22
98
14.31
44
83.19
318.0
PHP
84
33.84
43
36.08
33
58.11
5
11.67
13
19.84
92
17.23
56
104.04
96.0
SGE
98
29.66
93
24.49
92
3.62
94
3.83
94
3.83
95
4.48
87
38.58
216.0
Neural CO Solvers
SFT Only
89
2.30
54
2.32
59
6.02
80
1.71
98
2.41
100
2.22
100
11.01
5.6
GRPO
91
2.32
92
4.25
80
8.27
83
1.34
98
2.39
100
2.12
100
10.94
5.6
LLMCoSolver (N=1)
91
2.32
92
4.25
80
8.27
83
1.34
98
2.39
100
2.12
100
10.94
5.6
LLMCoSolver (N=8)
100
1.07
100
1.85
100
4.53
94
1.04
100
1.29
100
1.03
100
8.20
9.8
FALCON (Ours)
FALCON (N=1)
100
1.89
100
2.14
100
5.37
100
1.18
100
1.85
100
1.76
100
9.23
5.8
FALCON (N=8)
100
0.95
100
1.42
100
3.68
100
0.87
100
1.12
100
0.89
100
7.15
10.4
FALCON (Adaptive)
100
0.92
100
1.38
100
3.52
100
0.84
100
1.08
100
0.86
100
6.98
6.3
3.5. Training Pipeline
The complete training pipeline consists of two stages:
Stage 1: Supervised Fine-Tuning (SFT). We fine-tune
the base LLM on expert solutions generated by domain-
specific solvers (LKH for TSP/CVRP, Gurobi for MIS-
/MVC, etc.). This teaches the model the solution format and
basic problem-solving patterns.
Stage 2: BOPO Refinement. Starting from the SFT check-
point, we sample K solutions per instance, construct pref-
erence pairs via the best-anchored strategy, and update the
model parameters using the BOPO loss. This refines the
policy toward higher-quality solutions while maintaining
feasibility through the repair layer.
4. Experiments
We conduct extensive experiments to evaluate FALCON
against state-of-the-art baselines across seven NP-hard CO
problems. Our experiments address the following research
questions:
• RQ1: Does FALCON achieve 100% feasibility while
maintaining competitive solution quality?
• RQ2: How does FALCON compare against general-
purpose LLMs and domain-specific solvers?
• RQ3: What is the contribution of each component (BOPO,
grammar, repair, adaptive sampling)?
• RQ4: How does FALCON scale across different problem
sizes and instance distributions?
4.1. Experimental Setup
Problems
We evaluate on seven NP-hard problems across
three domains: Routing (TSP, OP, CVRP), Graph (MIS,
MVC), and Scheduling (PFSP, JSSP). Each problem in-
volves distinct constraint types—such as Hamiltonian tours,
capacity limits, independence, and precedence relations—
providing comprehensive coverage. Following Jiang et al.
(2025), we generate synthetic instances using established
domain-specific solvers (statistics are provided in Table 9).
Formal problem definitions are provided in Appendix B.
Baselines
We compare FALCON against four categories
of baselines. (1) General-purpose LLMs in a zero-shot set-
ting, including proprietary models (GPT-4o, GPT-4o-mini,
Claude-3.5-Sonnet, Claude-3.5-Haiku) and open-source
models (DeepSeek-V3 (Liu et al., 2024a), Llama-3.3-70B
(Dubey et al., 2024), Qwen2.5-72B (Yang et al., 2025)).
(2) Reasoning-enhanced LLMs with extended inference ca-
pabilities: GPT-o3-mini, GPT-o1, and DeepSeek-R1. (3)
LLM-based optimization methods that use LLMs for itera-
6


--- Page 7 ---
Hard Constraints Meet Soft Generation
Table 3. Comparison with domain heuristics.
Optimality gap
(%) across different problem scales. Small: 10–30 nodes/jobs;
Medium: 40–60; Large: 70–100.
Method
TSP
CVRP
Small
Med.
Large
Small
Med.
Large
Nearest Neighbor
19.36
24.13
26.19
18.36
20.59
22.07
OR-Tools
0.82
2.59
3.59
3.60
7.87
8.84
ACO
1.98
17.98
36.69
2.52
17.07
29.49
LLMCoSolver (N=8)
0.14
0.70
1.34
1.70
4.57
7.24
FALCON (N=8)
0.12
0.61
1.15
1.48
3.89
6.28
FALCON (Adaptive)
0.10
0.57
1.08
1.42
3.71
6.05
Method
PFSP
JSSP
Small
Med.
Large
Small
Med.
Large
NEH
1.33
2.78
3.56
–
–
–
FIFO
–
–
–
24.38
32.97
39.00
LLMCoSolver (N=8)
0.45
0.89
1.56
4.23
7.89
12.34
FALCON (N=8)
0.39
0.74
1.28
3.71
6.92
10.85
FALCON (Adaptive)
0.36
0.71
1.21
3.58
6.68
10.52
Table 4. Ablation study on TSP and CVRP.
Configuration
TSP
CVRP
Fea.
Gap
Time
Fea.
Gap
Time
FALCON (Full)
100
0.92
6.3s
100
3.52
6.8s
w/o Grammar
100
0.95
6.5s
100
3.67
7.1s
w/o Repair
94
0.89
6.1s
85
3.41
6.5s
w/o Adaptive
100
0.91
10.4s
100
3.48
11.2s
w/o BOPO
100
1.85
6.3s
100
5.89
6.8s
SFT + Repair
100
2.18
5.9s
100
5.72
6.2s
SFT Only
89
2.30
5.6s
59
6.02
5.8s
tive solution refinement: OPRO (Yang et al., 2023), LMEA
(Liu et al., 2024b), PHP (Zheng et al., 2023), and SGE
(Iklassov et al., 2024). (4) Neural CO solvers: SFT-only (su-
pervised fine-tuning without reinforcement learning), GRPO
(group relative policy optimization), and LLMCoSolver
(Jiang et al., 2025) (which combines SFT with FOARL).
Metrics
We evaluate models using two primary metrics.
The feasibility rate measures the percentage of generated
solutions that satisfy all problem constraints: Mf(Ps) =
|{p∈Ps|ˆxp∈XCp}|
|Ps|
. The optimality gap measures solution
quality relative to reference solutions obtained from domain-
specific solvers: Mo(Ps) =
1
|Ps|
P
p∈Ps
fp(ˆxp)−fp(x∗
p)
|fp(x∗p)|
. We
also report average inference time per instance. For FAL-
CON, we set the minimum samples Nmin = 8, maximum
samples Nmax = 64, confidence threshold τ = 0.85, and
sampling temperature T = 0.7.
4.2. Main Results (RQ1 & RQ2)
A comprehensive comparison across all baselines and prob-
lems is presented in Table 2 (referred to in the main text).
Figure 1. Repair layer statistics across seven CO problems. (a)
Feasibility rates. (b) Optimality gap. (c) Repair frequency and
cost for each problem. (d) Strong correlation (r = 0.912) between
repair frequency and cost.
RQ1: 100% Feasibility Guarantee.
FALCON achieves
100% feasibility across all seven problems, even with a
single sample (N = 1), which validates our theoretical
guarantees (Theorem 3.6). In contrast, general-purpose
LLMs show highly variable feasibility rates (2%–100%),
with CVRP and graph problems being particularly chal-
lenging. LLMCoSolver achieves 80%–100% feasibility at
N = 1, but even with N = 8, it only reaches 94% on
MIS—demonstrating that rejection sampling alone cannot
guarantee feasibility.
RQ2: Competitive Solution Quality.
Despite enforcing
hard feasibility constraints, FALCON maintains competi-
tive optimality gaps. With adaptive sampling, FALCON
achieves the best gaps on 5 out of 7 problems while using,
on average, 40% fewer samples than the fixed N = 8 set-
ting. The minimal quality degradation confirms that: (1)
BOPO-trained models produce a high proportion of feasible
solutions prior to repair, (2) the repair operators preserve
solution locality, and (3) in some cases, repair can even
improve quality by removing inefficient duplicates.
4.2.1. COMPARISON WITH DOMAIN HEURISTICS
Table 3 compares FALCON against classical heuristics
across different problem scales. FALCON consistently out-
performs simple heuristics (e.g., Nearest Neighbor, SPT/-
FIFO) by large margins and achieves competitive or superior
performance compared to more sophisticated methods (e.g.,
OR-Tools, 2-opt, NEH). Notably, FALCON maintains stable
performance as problem size increases, whereas classical
heuristics like ACO degrade significantly on large instances
(e.g., a 36.69% gap on large TSP). This demonstrates the
advantage of learned solvers with strong generalization ca-
pabilities.
7


--- Page 8 ---
Hard Constraints Meet Soft Generation
Figure 2. Comparison of BOPO and GRPO starting from the same
SFT checkpoint and with an identical training budget. (a) BOPO
consistently achieves lower optimality gaps across all problems.
(b,c) BOPO improves both optimality gap and feasibility rates. (d)
Relative gap improvement.
Table 5. Fixed vs. adaptive sampling.
Problem
Fixed (N = 64)
Adaptive
Gap
Samples
Time
Gap
Samples
Time
TSP
0.89
64
42.5s
0.92
18.4
12.8s
OP
1.35
64
45.2s
1.38
22.6
16.4s
CVRP
3.45
64
48.6s
3.52
31.2
24.5s
MIS
0.81
64
41.8s
0.84
25.8
17.9s
MVC
1.05
64
42.3s
1.08
21.4
15.2s
PFSP
0.84
64
46.7s
0.86
19.2
14.1s
JSSP
6.85
64
52.4s
6.98
48.6
41.2s
Avg.
2.18
64
45.6s
2.23
26.7
20.3s
4.3. Ablation Study (RQ3)
Table 4 shows the contribution of each FALCON component.
The repair layer is critical for achieving 100% feasibility—
removing it drops feasibility to levels comparable with the
baseline models. Grammar constraints reduce the repair
burden by ensuring output format validity. BOPO provides
improvements over GRPO in both feasibility and optimal-
ity gap, and adaptive sampling reduces computational cost
while maintaining solution quality.
Figure 2 provides a detailed comparison between BOPO and
GRPO. BOPO consistently outperforms GRPO, with larger
improvements observed on more constrained problems (e.g.,
CVRP: 29% lower gap; MIS: 12 percentage points higher
feasibility).
4.4. Analysis
Repair Layer Statistics.
Figure 1 shows that BOPO-
trained models produce a high proportion of feasible so-
Table 6. Sample allocation by instance difficulty.
Difficulty
TSP
CVRP
Inst.
Samples
Gap
Inst.
Samples
Gap
Easy (Cons.>0.7)
42%
10.2
0.45
28%
11.8
1.89
Medium (0.3–0.7)
38%
24.6
0.98
41%
32.4
3.67
Hard (Cons.<0.3)
20%
52.3
1.82
31%
54.7
5.92
lutions (81%–97%) before repair. Consequently, the repair
layer is invoked infrequently and incurs minimal compu-
tational overhead (<0.5% of total time). The repair fre-
quency correlates with problem constraint complexity: sim-
pler permutation problems (TSP, PFSP) require repair in
only 2.8%–3.2% of cases, while problems with multiple or
complex constraint types (CVRP, JSSP) need repair more
often (13.3%–18.5%). Importantly, the resulting quality
degradation remains bounded regardless of repair frequency,
validating the locality property established in Theorem 3.7.
Adaptive Sampling Efficiency.
Table 5 shows that adap-
tive sampling uses 58% fewer samples on average than a
fixed N = 64 strategy, while achieving comparable solu-
tion quality (optimality gap increase <3%). This reduces
inference time by 55%. The efficiency gains vary by prob-
lem: TSP and PFSP achieve the largest reductions (71%
fewer samples) due to high model confidence, while JSSP
requires more samples (48.6 on average) due to its complex
precedence constraints. This demonstrates that the adaptive
allocation mechanism effectively identifies problem diffi-
culty without requiring manual tuning.
Difficulty-Aware Allocation.
Table 6 shows that easy in-
stances terminate early (using ∼10 samples on average),
while hard instances utilize more samples (∼50). The solu-
tion consistency metric successfully stratifies instance diffi-
culty: easy instances (high consistency >0.7) achieve a low
optimality gap (0.45%) with minimal compute, while hard
instances (low consistency <0.3) benefit from extended ex-
ploration, reducing their optimality gap by 35% compared to
an early-termination baseline. This validates Lemma 3.10,
confirming that solution consistency is a reliable indicator
of problem difficulty for a given model.
5. Conclusion
We presented FALCON, an LLM-based combinatorial op-
timization framework that provides a provable 100% feasi-
bility guarantee—addressing a critical weakness of existing
generative approaches. By separating feasibility enforce-
ment into syntax (via grammar-constrained decoding) and
semantics (via problem-specific repair operators), FALCON
ensures hard constraint satisfaction while preserving com-
petitive solution quality. The adaptive sampling mechanism
efficiently allocates computation according to instance dif-
ficulty, and BOPO training enables objective-aware prefer-
ence learning. Extensive experiments across seven NP-hard
8


--- Page 9 ---
Hard Constraints Meet Soft Generation
problems confirm that FALCON reliably achieves perfect
feasibility while matching or surpassing the performance
of state-of-the-art neural and LLM-based solvers, enabling
robust deployment in real-world settings.
Impact Statement
This paper presents work whose goal is to advance the field
of Machine Learning. There are many potential societal
consequences of our work, none of which we feel must be
specifically highlighted here.
References
Abouelrous, A., Bliek, L., Wu, Y., and Zhang, Y. End-
to-end deep reinforcement learning for stochastic multi-
objective optimization in c-vrptw.
arXiv preprint
arXiv:2512.01518, 2025.
Azar, M. G., Guo, Z. D., Piot, B., Munos, R., Rowland, M.,
Valko, M., and Calandriello, D. A general theoretical
paradigm to understand learning from human preferences.
In International Conference on Artificial Intelligence and
Statistics, pp. 4447–4455. PMLR, 2024.
Bao, L. L. N., Le, D. H., and Nguyen, D. A. Applica-
tion of combinatorial optimization in logistics. In 2018
4th International Conference on Green Technology and
Sustainable Development (GTSD), pp. 329–334. IEEE,
2018.
Bejarano, F. P., Brunke, L., and Schoellig, A. P. Safety
filtering while training: Improving the performance and
sample efficiency of reinforcement learning agents. IEEE
Robotics and Automation Letters, 2024.
Bello, I., Pham, H., Le, Q. V., Norouzi, M., and Bengio,
S. Neural combinatorial optimization with reinforcement
learning. arXiv preprint arXiv:1611.09940, 2016.
Dubey, A., Jauhri, A., Pandey, A., Kadian, A., Al-Dahle,
A., Letman, A., Mathur, A., Schelten, A., Yang, A., Fan,
A., et al. The llama 3 herd of models. arXiv preprint
arXiv:2407.21783, 2024.
Ethayarajh, K., Xu, W., Muennighoff, N., Jurafsky, D., and
Kiela, D. Kto: Model alignment as prospect theoretic op-
timization, 2024. URL https://arxiv. org/abs/2402.01306.
Iklassov, Z., Du, Y., Akimov, F., and Takac, M. Self-guiding
exploration for combinatorial problems. Advances in Neu-
ral Information Processing Systems, 37:130569–130601,
2024.
Jain, S. and Bharti, K. K. A combinatorial optimization
model for post-disaster emergency resource allocation
using meta-heuristics. Soft Computing, 27(18):13595–
13611, 2023.
Jiang, X., Wu, Y., Li, M., Cao, Z., and Zhang, Y. Large lan-
guage models as end-to-end combinatorial optimization
solvers. arXiv preprint arXiv:2509.16865, 2025.
Kool, W., Van Hoof, H., and Welling, M.
Attention,
learn to solve routing problems!
arXiv preprint
arXiv:1803.08475, 2018.
Liu, A., Feng, B., Xue, B., Wang, B., Wu, B., Lu, C., Zhao,
C., Deng, C., Zhang, C., Ruan, C., et al. Deepseek-
v3 technical report. arXiv preprint arXiv:2412.19437,
2024a.
Liu, H., Zhang, Q., Marcus, R., and Sabek, I. Sefrqo: A
self-evolving fine-tuned rag-based query optimizer. Pro-
ceedings of the ACM on Management of Data, 3(6):1–27,
2025.
Liu, S., Chen, C., Qu, X., Tang, K., and Ong, Y.-S. Large
language models as evolutionary optimizers. In 2024
IEEE Congress on Evolutionary Computation (CEC), pp.
1–8. IEEE, 2024b.
Liu, Y., Zhou, C., Zhang, P., Zhang, S., Zhang, X., Li,
Z., and Chen, H. Decision-focused graph neural net-
works for graph learning and optimization. In 2023 IEEE
International Conference on Data Mining (ICDM), pp.
1151–1156. IEEE, 2023.
Liu, Y., Zhou, C., Zhang, P., Li, Z., Zhang, S., Lin, X.,
and Wu, X. Cl4co: A curriculum training framework for
graph-based neural combinatorial optimization. In 2024
IEEE International Conference on Data Mining (ICDM),
pp. 779–784. IEEE, 2024c.
Liu, Y., Zhou, C., Zhang, P., Pan, S., Li, Z., and Chen,
H. Decision-focused graph neural networks for combi-
natorial optimization. arXiv preprint arXiv:2406.03647,
2024d.
McGarvey, J., Grabowski, M. R., Custard, B., and Gabelein,
S. Self-healing databases for emergency response logis-
tics in remote and infrastructure-poor settings. Logistics,
9(1):23, 2025.
Meng, Y., Xia, M., and Chen, D. Simpo: Simple preference
optimization with a reference-free reward.
Advances
in Neural Information Processing Systems, 37:124198–
124235, 2024.
Meurer, M., Kelliger, T., Gerhard, N., R¨uppel, A. K., Grim-
mert, A., and Bergs, T. Manusafenextgen: Model-based
manufacturing of safety-critical components for next gen-
eration engines–part i: Methodology. Procedia CIRP,
133:370–375, 2025.
9


--- Page 10 ---
Hard Constraints Meet Soft Generation
Nazari, M., Oroojlooy, A., Snyder, L., and Tak´ac, M. Rein-
forcement learning for solving the vehicle routing prob-
lem. Advances in neural information processing systems,
31, 2018.
Park, K., Wang, J., Berg-Kirkpatrick, T., Polikarpova, N.,
and D’Antoni, L. Grammar-aligned decoding. Advances
in Neural Information Processing Systems, 37:24547–
24568, 2024.
Qiu, X., Gan, Y., Hayes, C. F., Liang, Q., Meyerson, E.,
Hodjat, B., and Miikkulainen, R. Evolution strategies
at scale: Llm fine-tuning beyond reinforcement learning.
arXiv preprint arXiv:2509.24372, 2025.
Rafailov, R., Sharma, A., Mitchell, E., Manning, C. D.,
Ermon, S., and Finn, C. Direct preference optimiza-
tion: Your language model is secretly a reward model.
Advances in neural information processing systems, 36:
53728–53741, 2023.
Shao, Z., Wang, P., Zhu, Q., Xu, R., Song, J., Bi, X., Zhang,
H., Zhang, M., Li, Y., Wu, Y., et al. Deepseekmath: Push-
ing the limits of mathematical reasoning in open language
models. arXiv preprint arXiv:2402.03300, 2024.
Vinyals, O., Fortunato, M., and Jaitly, N. Pointer networks.
Advances in neural information processing systems, 28,
2015.
Yang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B.,
Yu, B., Gao, C., Huang, C., Lv, C., et al. Qwen3 technical
report. arXiv preprint arXiv:2505.09388, 2025.
Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D.,
and Chen, X. Large language models as optimizers. In
The Twelfth International Conference on Learning Repre-
sentations, 2023.
Zhang, C., Wu, Y., Ma, Y., Song, W., Le, Z., Cao, Z., and
Zhang, J. A review on learning to solve combinatorial op-
timisation problems in manufacturing. IET Collaborative
Intelligent Manufacturing, 5(1):e12072, 2023.
Zheng, C., Liu, Z., Xie, E., Li, Z., and Li, Y. Progressive-
hint prompting improves reasoning in large language
models. arXiv preprint arXiv:2304.09797, 2023.
Zhu, J., Wu, Y., Lin, Z., Zhang, Z., Yin, H., Cao, Z.,
Jayavelu, S., and Li, X.
Bridging synthetic and real
routing problems via llm-guided instance generation and
progressive adaptation. arXiv preprint arXiv:2511.10233,
2025.
10


--- Page 11 ---
Hard Constraints Meet Soft Generation
Appendix
A. Related Work
Neural Combinatorial Optimization
Neural approaches to combinatorial optimization have evolved from pointer net-
works (Vinyals et al., 2015) to transformer-based architectures (Kool et al., 2018; Abouelrous et al., 2025) and reinforcement
learning methods (Bello et al., 2016; Nazari et al., 2018). Recent work explores the use of large language models (LLMs) as
CO solvers through techniques such as prompt optimization (Yang et al., 2023), evolutionary strategies (Qiu et al., 2025),
and direct fine-tuning (Zhu et al., 2025). However, existing methods typically rely on soft constraints via reward shaping or
post-hoc rejection sampling, which lack formal feasibility guarantees.
Constrained Text Generation
Constrained decoding restricts LLM outputs through lexical constraints (Park et al., 2024),
grammar compliance (Liu et al., 2025), and safety filtering (Bejarano et al., 2024). We adapt grammar-based filtering to
enforce the specific output formats required by CO problems. Our approach extends beyond syntactic validity to ensure
semantic feasibility through a dedicated repair layer—constituting a novel two-stage feasibility enforcement mechanism in
the context of LLMs for combinatorial optimization.
Preference Optimization.
Direct Preference Optimization (DPO) (Rafailov et al., 2023) provides an efficient alternative
to reinforcement learning from human feedback (RLHF) for LLM alignment. It reparameterizes the reward function as
an implicit function of the policy, eliminating the need for explicit reward modeling. Subsequent work has extended this
framework: IPO (Azar et al., 2024) addresses overfitting through a general ΨPO framework, KTO (Ethayarajh et al.)
enables learning from unpaired binary feedback inspired by prospect theory, and SimPO (Meng et al., 2024) removes the
dependence on a reference model entirely. For mathematical reasoning, GRPO (Shao et al., 2024) introduces group-relative
advantage estimation that leverages verifiable correctness signals without human annotation, demonstrating the effectiveness
of outcome-based preference learning.
B. Problem Definitions
We provide formal mathematical definitions for all seven combinatorial optimization problems evaluated in this paper. Each
definition specifies the problem input, decision variables, constraints, and optimization objective.
B.1. Traveling Salesman Problem (TSP)
Definition B.1 (TSP). Given a set of n cities with coordinates {(xi, yi)}n−1
i=0 and a Euclidean distance matrix dij =
∥(xi, yi) −(xj, yj)∥2, find a permutation π : {0, 1, . . . , n −1} →{0, 1, . . . , n −1} that minimizes the total tour length:
min
π
n−1
X
i=0
dπ(i),π((i+1) mod n)
s.t.
π is a permutation of {0, 1, . . . , n −1}.
The constraint requires a Hamiltonian tour where each city is visited exactly once and the tour returns to the starting city.
The objective minimizes the total Euclidean distance traveled.
B.2. Orienteering Problem (OP)
Definition B.2 (OP). Given n locations with coordinates {(xi, yi)}n−1
i=0 , prizes {pi}n−1
i=1 where pi > 0, a depot at node 0, a
Euclidean distance matrix dij = ∥(xi, yi) −(xj, yj)∥2, and a distance budget D > 0, find a subset S ⊆{1, . . . , n −1}
and a visiting order π that maximizes the total collected prize:
max
S,π
X
i∈S
pi
s.t.
|S|
X
j=0
dπ(j),π(j+1) ≤D
π(0) = π(|S| + 1) = 0
11


--- Page 12 ---
Hard Constraints Meet Soft Generation
π : {0, 1, . . . , |S| + 1} →{0} ∪S is a valid path.
The distance budget constraint limits the total travel distance to at most D. The route must start and end at the depot (node
0). The objective maximizes the sum of prizes collected from visited locations.
B.3. Capacitated Vehicle Routing Problem (CVRP)
Definition B.3 (CVRP). Given n customers with coordinates {(xi, yi)}n−1
i=0 , demands {qi}n−1
i=1 where qi > 0, a depot at
node 0 with q0 = 0, a Euclidean distance matrix dij = ∥(xi, yi) −(xj, yj)∥2, and a vehicle capacity Q > 0, find a set of
routes {R1, R2, . . . , RK} that minimizes the total travel distance:
min
{Rk}K
k=1
K
X
k=1
length(Rk)
s.t.
K
[
k=1
Rk = {1, . . . , n −1}
Ri ∩Rj = ∅for all i ̸= j
X
i∈Rk
qi ≤Q
for all k ∈{1, . . . , K}
Each route Rk starts and ends at node 0.
Here, length(Rk) = d0,r(1)
k +P|Rk|−1
j=1
dr(j)
k ,r(j+1)
k
+dr
(|Rk|)
k
,0 for a route Rk = (r(1)
k , r(2)
k , . . . , r(|Rk|)
k
), where r(j)
k
denotes
the j-th customer visited in route k.
The partition constraints ensure all customers are served exactly once across all routes. The capacity constraint ensures the
total demand of customers assigned to each route does not exceed the vehicle capacity Q. Each route must start and end at
the depot.
B.4. Maximum Independent Set (MIS)
Definition B.4 (MIS). Given an undirected graph G = (V, E) with vertex set V = {v1, v2, . . . , vn} and edge set E ⊆V ×V ,
find a subset S ⊆V that maximizes its cardinality:
max
S⊆V
|S|
s.t.
∀(u, v) ∈E : ¬(u ∈S ∧v ∈S).
The independence constraint requires that no two vertices in S are adjacent; that is, no edge in E has both endpoints in S.
The objective maximizes the size of the independent set.
B.5. Minimum Vertex Cover (MVC)
Definition B.5 (MVC). Given an undirected graph G = (V, E) with vertex set V = {v1, v2, . . . , vn} and edge set
E ⊆V × V , find a subset S ⊆V that minimizes its cardinality:
min
S⊆V
|S|
s.t.
∀(u, v) ∈E : u ∈S ∨v ∈S.
The coverage constraint requires that every edge in E has at least one endpoint in S, ensuring all edges are ”covered.” The
objective minimizes the size of the vertex cover.
Remark B.6 (MIS-MVC Duality). The Maximum Independent Set and Minimum Vertex Cover problems exhibit a comple-
mentary relationship on any graph G = (V, E). A subset S ⊆V is an independent set if and only if its complement V \ S
is a vertex cover. This duality implies that solving one problem immediately provides the solution to the other.
12


--- Page 13 ---
Hard Constraints Meet Soft Generation
B.6. Permutation Flow Shop Scheduling (PFSP)
Definition B.7 (PFSP). Given n jobs and m machines with processing times pi,j > 0 for job i ∈{1, . . . , n} on machine
j ∈{1, . . . , m}, find a permutation π : {1, . . . , n} →{1, . . . , n} that minimizes the makespan (the completion time of the
last job on the last machine):
min
π
Cπ(n),m
s.t.
Cπ(k),j = max(Cπ(k),j−1, Cπ(k−1),j) + pπ(k),j
for all k ∈{1, . . . , n}, j ∈{1, . . . , m}
Cπ(k),0 = 0
for all k ∈{1, . . . , n}
Cπ(0),j = 0
for all j ∈{1, . . . , m}
π is a permutation of {1, . . . , n},
where Ci,j denotes the completion time of job i on machine j.
The flow shop constraint requires that all jobs are processed in the same order π on all machines. The completion time
recursion ensures that job π(k) on machine j can only start after both the same job has completed on the previous machine
j −1 and the previous job π(k −1) has completed on the current machine j. The boundary conditions set zero completion
times before any processing begins.
B.7. Job Shop Scheduling Problem (JSSP)
Definition B.8 (JSSP). Given n jobs and m machines, where each job i ∈{1, . . . , n} consists of a sequence of m operations
(oi,1, oi,2, . . . , oi,m), with each operation oi,k requiring a specific machine µ(oi,k) ∈{1, . . . , m} for a processing time
p(oi,k) > 0, find a feasible schedule that minimizes the makespan:
min
max
i∈{1,...,n} Ci
s.t.
Soi,k+1 ≥Coi,k
for all i ∈{1, . . . , n}, k ∈{1, . . . , m −1}
Coi,k = Soi,k + p(oi,k)
for all i, k
For any two distinct operations o, o′ with µ(o) = µ(o′) :
So ≥Co′ or So′ ≥Co,
where So and Co denote the start and completion times of operation o, and Ci = Coi,m is the completion time of job i.
The precedence constraints ensure that operations within each job are processed in the specified order; each operation can
only start after the previous operation in its job has completed. The machine resource constraints (disjunctive constraints)
ensure that each machine processes at most one operation at any time (no preemption). The objective minimizes the
completion time of all jobs, which equals the maximum completion time across jobs.
C. Complete Proofs
Assumption C.1 (Smoothness). The loss function LBOPO(θ) is L-smooth:
∥∇LBOPO(θ1) −∇LBOPO(θ2)∥≤L∥θ1 −θ2∥.
Assumption C.2 (Bounded Variance). The stochastic gradient has bounded variance:
E[∥∇LBOPO(θ; B) −∇LBOPO(θ)∥2] ≤σ2,
where B is a randomly sampled mini-batch.
Assumption C.3 (Bounded Objective-Guided Scaling). The objective-guided scaling factor in BOPO satisfies w(∆) ∈
[wmin, wmax] for some 0 < wmin ≤wmax < ∞.
Specifically, for w(∆) = ∆/ ¯∆, where ¯∆=
1
K′−1
P
yi∈Fp\{y∗} ∆i, we require:
• ∆i = fp(yi) −fp(y∗) ≥δmin > 0 for all inferior solutions (ensured by discrete objective values in CO problems).
13


--- Page 14 ---
Hard Constraints Meet Soft Generation
• The ratio maxi ∆i/ minj ∆j ≤C is bounded by a constant C.
Under these conditions, w(∆) ∈[1/C, C], which ensures bounded scaling.
C.1. Proof of Theorem 3.15 (BOPO Convergence)
Proof. We denote L := LBOPO for brevity. The proof proceeds in four steps.
Step 1: Descent Lemma. By Assumption C.1 (L-smoothness), for any θ1, θ2 ∈Rd:
L(θ2) ≤L(θ1) + ⟨∇L(θ1), θ2 −θ1⟩+ L
2 ∥θ2 −θ1∥2.
Applying this to the SGD update θt+1 = θt −ηgt, where gt is the stochastic gradient at iteration t, yields:
L(θt+1) ≤L(θt) + ⟨∇L(θt), −ηgt⟩+ L
2 ∥−ηgt∥2
= L(θt) −η⟨∇L(θt), gt⟩+ Lη2
2 ∥gt∥2.
Step 2: Taking Expectation. Taking expectation conditioned on θt and using the unbiasedness of the stochastic gradient,
E[gt|θt] = ∇L(θt), gives:
E[L(θt+1)|θt] ≤L(θt) −η⟨∇L(θt), E[gt|θt]⟩+ Lη2
2 E[∥gt∥2|θt]
= L(θt) −η∥∇L(θt)∥2 + Lη2
2 E[∥gt∥2|θt].
Step 3: Bounding the Second Moment. We decompose the second moment of the stochastic gradient:
E[∥gt∥2|θt] = E[∥gt −∇L(θt) + ∇L(θt)∥2|θt]
= E[∥gt −∇L(θt)∥2|θt] + ∥∇L(θt)∥2
+ 2E[⟨gt −∇L(θt), ∇L(θt)⟩|θt].
Since E[gt −∇L(θt)|θt] = 0, the cross term vanishes:
E[∥gt∥2|θt] = E[∥gt −∇L(θt)∥2|θt] + ∥∇L(θt)∥2.
By Assumptions C.2 and C.3, the variance is bounded:
E[∥gt −∇L(θt)∥2|θt] ≤w2
maxσ2.
The factor w2
max arises because the BOPO gradient includes the scaling term w(∆i), which is bounded by wmax according
to Assumption C.3. Therefore:
E[∥gt∥2|θt] ≤∥∇L(θt)∥2 + w2
maxσ2.
Step 4: Telescoping and Final Bound. Substituting this bound back into the expectation:
E[L(θt+1)|θt] ≤L(θt) −η∥∇L(θt)∥2 + Lη2
2
 ∥∇L(θt)∥2 + w2
maxσ2
= L(θt) −η

1 −Lη
2

∥∇L(θt)∥2 + Lη2w2
maxσ2
2
.
Taking the full expectation and rearranging terms:
η

1 −Lη
2

E[∥∇L(θt)∥2] ≤E[L(θt)] −E[L(θt+1)] + Lη2w2
maxσ2
2
.
14


--- Page 15 ---
Hard Constraints Meet Soft Generation
Summing from t = 0 to T −1:
η

1 −Lη
2
 T −1
X
t=0
E[∥∇L(θt)∥2] ≤L(θ0) −E[L(θT )] + Lη2w2
maxσ2T
2
.
Since L(θT ) ≥L∗(the minimum possible loss):
T −1
X
t=0
E[∥∇L(θt)∥2] ≤L(θ0) −L∗
η(1 −Lη
2 )
+ Lηw2
maxσ2T
2(1 −Lη
2 )
.
Setting the learning rate η =
1
L
√
T , we have Lη
2 =
1
2
√
T ≤1
2 for T ≥1, implying 1 −Lη
2 ≥1
2. Thus:
1
T
T −1
X
t=0
E[∥∇L(θt)∥2] ≤L(θ0) −L∗
T ·
1
L
√
T · 1
2
+
L ·
1
L
√
T · w2
maxσ2
2 · 1
2
= 2L(L(θ0) −L∗)
√
T
+ w2
maxσ2
√
T
.
This completes the proof.
C.2. Proof of Corollary 3.16 (Iteration Complexity)
Proof. From Theorem 3.15, we have:
min
t∈{0,...,T −1} E[∥∇L(θt)∥2] ≤1
T
T −1
X
t=0
E[∥∇L(θt)∥2] ≤C1
√
T
,
where C1 = 2L(L(θ0) −L∗) + w2
maxσ2.
To achieve mint E[∥∇L(θt)∥2] ≤ϵ, we require:
C1
√
T
≤ϵ
=⇒
T ≥C2
1
ϵ2 .
Therefore, the iteration complexity is O(1/ϵ2).
C.3. Proof of Theorem 3.3 (Format Validity Guarantee)
Proof. We prove the theorem by strong induction on the number of decoding steps.
Setup. Let G = (V, Σ, R, S) be the context-free grammar and A = (Q, Σ, Γ, δ, q0, Z0, F) be the corresponding pushdown
automaton (PDA) that recognizes L(G). At each step t, Algorithm 1 maintains the PDA state (qt, γt), where qt ∈Q is the
current state and γt ∈Γ∗is the stack content.
Invariant. We prove the following invariant: after t decoding steps producing the partial output y(t) = v1v2 · · · vt, there
exists a derivation in G such that y(t) is a prefix of some string in L(G), and the PDA state (qt, γt) is reachable from the
initial configuration (q0, Z0) by reading y(t).
Base Case (t = 0). Initially, y(0) = ϵ (the empty string), and the PDA is in state (q0, Z0). The empty string is trivially a
prefix of any string in L(G), and (q0, Z0) is the initial configuration.
Inductive Step. Assume the invariant holds after step t. At step t + 1:
1. Algorithm 1 computes the set of valid next tokens:
Vvalid = {v ∈Σ | δ((qt, γt), v) is defined}.
15


--- Page 16 ---
Hard Constraints Meet Soft Generation
2. The algorithm masks all tokens v /∈Vvalid by setting their logits to −∞.
3. A token vt+1 is sampled from the remaining valid tokens.
4. By construction, vt+1 ∈Vvalid, so δ((qt, γt), vt+1) is defined.
5. The PDA transitions to (qt+1, γt+1) = δ((qt, γt), vt+1).
Since δ is defined only for transitions that correspond to valid derivation steps in G, the new partial output y(t+1) = y(t)vt+1
remains a prefix of some string in L(G).
Termination. Algorithm 1 terminates when the PDA reaches an accepting state qT ∈F with an empty stack. By the
standard correspondence between context-free grammars and pushdown automata, this occurs if and only if the generated
string y = y(T ) belongs to L(G).
Therefore, the output y satisfies y ∈L(G).
C.4. Proof of Theorem 3.6 (100% Feasibility Guarantee)
Proof. Let y1, y2, . . . , yN be the N samples generated by the LLM policy πθ. After applying the repair operator, we obtain:
˜yi = R(yi),
i = 1, . . . , N.
By property (1) of Definition 3.5 (Feasibility), each repaired solution satisfies:
˜yi ∈XCp.
Therefore, all N solutions {˜y1, . . . , ˜yN} are feasible. In particular:
P(∃i : ˜yi ∈XCp) = P(∀i : ˜yi ∈XCp) = 1.
C.5. Proof of Theorem 3.7 (Repair Quality Bound)
Proof. The objective function fp is assumed to be Lf-Lipschitz continuous with respect to the distance metric d; i.e., for
any x, y ∈Xp:
|fp(x) −fp(y)| ≤Lf · d(x, y).
Applying this inequality to x = R(ˆxp) and y = ˆxp yields:
|fp(R(ˆxp)) −fp(ˆxp)| ≤Lf · d(R(ˆxp), ˆxp).
By the locality assumption on the repair operator R (property (2) in Definition 3.5):
d(R(ˆxp), ˆxp) ≤α · v(ˆxp),
where v(ˆxp) measures the constraint violation of the original solution.
Combining these inequalities gives:
|fp(R(ˆxp)) −fp(ˆxp)| ≤Lf · α · v(ˆxp).
This implies the one-sided bound:
fp(R(ˆxp)) ≤fp(ˆxp) + Lf · α · v(ˆxp).
Note that the repair operation may also improve the objective value, in which case fp(R(ˆxp)) < fp(ˆxp). The bound provides
a worst-case guarantee on the potential degradation.
16


--- Page 17 ---
Hard Constraints Meet Soft Generation
C.6. Proof of Corollary 3.8 (Comparison with Rejection Sampling)
Proof. Let Yi ∈{0, 1} be the indicator that sample yi is feasible. By assumption, P(Yi = 1) = pf, and the samples are
independent.
The probability that none of the N samples is feasible is:
P(∀i : Yi = 0) =
N
Y
i=1
P(Yi = 0) = (1 −pf)N.
Therefore, the probability of obtaining at least one feasible solution is:
P(∃i : Yi = 1) = 1 −(1 −pf)N.
To ensure this probability is at least 1 −δ, we require:
1 −(1 −pf)N ≥1 −δ
(1 −pf)N ≤δ
N log(1 −pf) ≤log δ
N ≥
log(1/δ)
log(1/(1 −pf)).
For small pf, using the approximation log(1 −pf) ≈−pf, we obtain the simplified bound:
N ≳log(1/δ)
pf
.
C.7. Proof of Theorem 3.11 (Quality Improvement with Sampling)
Proof. Let Gi = fp(yi) −fp(x∗) denote the optimality gap of sample yi. Then gN = mini Gi is the gap of the best sample.
We have:
P(gN > ϵ) = P(min
i
Gi > ϵ) =
N
Y
i=1
P(Gi > ϵ)
= (1 −F(ϵ))N,
where F(·) is the cumulative distribution function of the gap of a single sample.
By the standard tail integral formula for the expectation of a non-negative random variable:
E[gN] =
Z ∞
0
P(gN > ϵ) dϵ =
Z ∞
0
(1 −F(ϵ))N dϵ.
This establishes the desired result.
C.8. Proof of Corollary 3.12 (Exponential Distribution)
Proof. For an exponential distribution with rate λ, the tail probability is:
1 −F(ϵ) = e−λϵ.
Substituting this into Theorem 3.11 yields:
E[gN] =
Z ∞
0
 e−λϵN dϵ
17


--- Page 18 ---
Hard Constraints Meet Soft Generation
=
Z ∞
0
e−Nλϵ dϵ
=

−1
Nλe−Nλϵ
∞
0
=
1
Nλ.
Since E[g1] = 1
λ for an exponential distribution, it follows that:
E[gN] = E[g1]
N
.
C.9. Proof of Theorem 3.13 (Adaptive Sampling Complexity)
Proof. Let T denote the random stopping time of Algorithm 2. We decompose the expected number of samples as:
E[T] =
Nmax
X
n=1
Pr(T ≥n)
= Nmin +
Nmax
X
n=Nmin+1
Pr(T ≥n),
where the equality follows from the fact that the algorithm always collects at least Nmin samples before considering early
termination.
After collecting n samples, let ny∗be the number of samples matching the current best solution y∗. The Bayesian confidence
estimate using a Beta-Binomial model with a uniform prior (α0 = β0 = 1) is:
Conf(y∗; n) =
α0 + ny∗
α0 + β0 + n = 1 + ny∗
2 + n .
The algorithm continues sampling at step n if this confidence remains below the threshold τ, which occurs when ny∗<
τ(2 + n) −1.
Consider a problem instance where the model samples a near-optimal solution (with an optimality gap of at most δ) with
probability q. Let Sn denote the event that at least one such near-optimal solution has been sampled among the first n
samples. The probability of the complement event is Pr( ¯Sn) = (1 −q)n. When the confidence estimation mechanism is
well-calibrated and a near-optimal solution has been sampled, the algorithm will eventually recognize this through repeated
sampling of the same high-quality solution, leading to early termination.
For a simplified but informative upper bound, we assume the algorithm stops once it has sampled the near-optimal solution
with sufficient frequency to meet the confidence threshold. Under this assumption, the probability of continuing past step n
is bounded by the probability that no near-optimal solution has appeared, giving Pr(T ≥n) ≤(1 −q)n for n ≥Nmin.
Applying this bound to the expectation decomposition:
E[T] ≤Nmin +
Nmax
X
n=Nmin+1
(1 −q)n
= Nmin + (1 −q)Nmin+1 · 1 −(1 −q)Nmax−Nmin
1 −(1 −q)
= Nmin + (1 −q)Nmin+1
q
·
 1 −(1 −q)Nmax−Nmin
.
Since (1 −q)Nmax−Nmin ≥0, we have:
E[T] ≤Nmin + (1 −q)Nmin · (1 −q)
q
.
18


--- Page 19 ---
Hard Constraints Meet Soft Generation
Using a looser but more interpretable bound (by approximating the sum of the geometric series linearly for the range of
interest), we obtain:
E[Nadaptive] ≤Nmin + (Nmax −Nmin)(1 −q)Nmin
q
.
This bound reveals the adaptive behavior. For easy instances (characterized by a large q where near-optimal solutions
are frequently sampled), the exponential decay term (1 −q)Nmin becomes very small, yielding E[Nadaptive] ≈Nmin. The
algorithm terminates quickly after collecting the minimum required samples. For difficult instances with small q, the bound
grows larger, and the algorithm continues sampling up to the maximum budget Nmax to ensure adequate exploration. This
demonstrates that adaptive sampling automatically allocates computational resources based on instance-specific difficulty
without requiring manual tuning or prior knowledge of problem characteristics.
C.10. Proof of Lemma 3.10 (Consistency-Difficulty Relationship)
Proof. We provide a rigorous derivation of the expected consistency and its relationship to the R´enyi entropy of order 2.
The consistency measure over K independently sampled solutions {y1, . . . , yK} is defined as:
Cons =
1
K(K −1)
K
X
i=1
X
j̸=i
I[yi = yj].
Taking the expectation over the independent samples, each drawn from a distribution p over the solution space Y:
E[Cons] = E


1
K(K −1)
K
X
i=1
X
j̸=i
I[yi = yj]


=
1
K(K −1)
K
X
i=1
X
j̸=i
E[I[yi = yj]]
=
1
K(K −1)
K
X
i=1
X
j̸=i
Pr(yi = yj).
By the independence of the samples, for any i ̸= j:
Pr(yi = yj) =
X
y∈Y
Pr(yi = y) · Pr(yj = y)
=
X
y∈Y
p(y) · p(y) =
X
y∈Y
p(y)2.
Since there are K(K −1) ordered pairs (i, j) with i ̸= j, we obtain:
E[Cons] =
1
K(K −1) · K(K −1) ·
X
y∈Y
p(y)2 =
X
y∈Y
p(y)2.
The R´enyi entropy of order 2 is defined as H2(p) = −log P
y p(y)2. Therefore:
E[Cons] =
X
y
p(y)2 = e−H2(p).
This establishes an inverse exponential relationship between the expected consistency and the R´enyi entropy.
When the model’s output distribution is highly concentrated on a single solution (i.e., most probability mass is on one
particular y∗), we have p(y∗) ≈1 and p(y) ≈0 for y ̸= y∗. This yields P
y p(y)2 ≈1, corresponding to low entropy
19


--- Page 20 ---
Hard Constraints Meet Soft Generation
H2(p) ≈0 and high consistency E[Cons] ≈1. Such concentration indicates the model has high confidence in a specific
solution, which typically occurs for instances where the optimal solution is unambiguous and easily identifiable by the
trained policy.
Conversely, when the model’s distribution is diffuse across many solutions, each solution y in some effective support set
S receives moderate probability p(y) ≈1/|S|. This gives P
y p(y)2 ≈1/|S|, corresponding to high entropy and low
consistency. This dispersion reflects model uncertainty about which solution is optimal, which typically occurs for difficult
instances where multiple solutions appear nearly equivalent or where the problem structure is complex and ambiguous.
For a well-trained model where high predicted probability correlates with actual solution quality, high consistency among
early samples serves as a reliable indicator that the instance is easy and does not require extensive additional sampling.
Low consistency signals that the instance is difficult and would benefit from more exploration to identify high-quality
solutions.
D. Grammar Specifications
This section provides complete context-free grammar (CFG) specifications for all seven combinatorial optimization problems.
These grammars define the syntactic structure of valid solution representations that the LLM must generate. Each grammar
enforces format validity through grammar-constrained decoding as described in Section 3.1.
D.1. Grammar Formalism
We adopt the standard Backus-Naur Form (BNF) notation for context-free grammars. A grammar G = (V, Σ, R, S) consists
of a set of non-terminal symbols V , a set of terminal symbols Σ (corresponding to tokens in the LLM vocabulary), a set of
production rules R, and a start symbol S ∈V . Production rules are written as A →α, where A ∈V and α ∈(V ∪Σ)∗.
The notation X+ denotes one or more occurrences of symbol X, and ϵ denotes the empty string.
For each problem, we define an input-dependent grammar Gp that specializes the base grammar by restricting node and job
indices to valid ranges based on the problem instance p. Specifically, for an instance with n nodes or jobs, the production
rule for indices is specialized to generate only values in {0, 1, . . . , n −1} or {1, . . . , n}, as appropriate for the problem.
D.2. Common Definitions
The following non-terminal symbols are shared across all problem-specific grammars. The Number non-terminal represents
floating-point objective values, while Digit represents individual decimal digits.
Number →Digit+ "." Digit+
Digit →"0" | "1" | "2" | "3" | "4" | "5" | "6" | "7" | "8" | "9"
D.3. TSP Grammar
The TSP grammar enforces the format of a single route represented as an ordered list of node indices, followed by the
computed tour length. The grammar ensures proper bracketing and comma separation but does not enforce the semantic
constraint that all nodes must appear exactly once, which is handled by the repair operator.
S →"Route:
[" NodeList "], Objective:
" Number
NodeList →Node | Node ", " NodeList
Node →Digit+
For an instance with n nodes indexed as {0, 1, . . . , n −1}, the input-dependent grammar restricts Node to generate only
valid indices by replacing the production rule with explicit alternatives: Node →"0" | "1" | · · · | "n −1".
D.4. CVRP Grammar
The CVRP grammar specifies a collection of routes, where each route is a bracketed list of customer nodes. The grammar
allows multiple routes separated by commas, reflecting the multi-route structure of CVRP solutions.
S →"Routes:
[" RouteList "], Objective:
" Number
20


--- Page 21 ---
Hard Constraints Meet Soft Generation
RouteList →Route | Route ", " RouteList
Route →"[" NodeList "]"
NodeList →Node | Node ", " NodeList
Node →Digit+
The grammar permits arbitrary route structures, while the repair operator enforces the semantic constraints: all customers
are visited exactly once, and each route satisfies the vehicle capacity constraint.
D.5. OP Grammar
The Orienteering Problem grammar allows for an optional empty route, reflecting that some instances may have no feasible
solution within the distance budget or that the optimal solution might visit no customers beyond the depot.
S →"Route:
[" NodeListOpt "], Objective:
" Number
NodeListOpt →ϵ | NodeList
NodeList →Node | Node ", " NodeList
Node →Digit+
The production NodeListOpt →ϵ permits the empty route representation, which is syntactically valid and corresponds to
visiting no locations beyond the depot.
D.6. MIS/MVC Grammar
The Maximum Independent Set and Minimum Vertex Cover problems share the same output grammar, as both require
specifying a subset of vertices. The grammar structure is identical to the OP grammar, allowing for potentially empty sets.
S →"Set:
[" NodeListOpt "], Objective:
" Number
NodeListOpt →ϵ | NodeList
NodeList →Node | Node ", " NodeList
Node →Digit+
The semantic constraints of independence for MIS and coverage for MVC are enforced by the respective repair operators
rather than by the grammar itself.
D.7. PFSP Grammar
The Permutation Flow Shop Scheduling grammar specifies a single job processing order that applies to all machines. The
structure is similar to TSP but uses the keyword ”Order” to reflect the scheduling context.
S →"Order:
[" JobList "], Objective:
" Number
JobList →Job | Job ", " JobList
Job →Digit+
For an instance with n jobs indexed as {1, . . . , n}, the input-dependent grammar restricts Job to generate only valid job
identifiers.
D.8. JSSP Grammar
The Job Shop Scheduling Problem grammar represents the assignment of operations to machines by specifying a job
processing sequence for each machine. The nested bracket structure reflects the two-level hierarchy of machines and jobs.
S →"Schedule:
[" MachineList "], Objective:
" Number
MachineList →Machine | Machine ", " MachineList
Machine →"[" JobList "]"
21


--- Page 22 ---
Hard Constraints Meet Soft Generation
JobList →Job | Job ", " JobList
Job →Digit+
The grammar allows flexible machine scheduling orders, while the repair operator enforces precedence constraints and
ensures that each operation appears exactly once in the schedule.
D.9. Grammar Properties and Implementation
All specified grammars are unambiguous context-free grammars that can be recognized by deterministic pushdown automata.
Each grammar has the following computational properties relevant to constrained decoding implementation. The grammars
have bounded recursion depth proportional to the problem size, ensuring that the PDA stack depth remains manageable
during generation. The number of PDA states required is O(|V |), where |V | is the number of non-terminals, which is
constant for each problem class. Valid token computation at each decoding step requires O(|Σ|) time, where |Σ| is the
vocabulary size, dominated by checking terminal symbol compatibility.
The grammar specifications intentionally enforce only syntactic validity, delegating semantic constraint checking to the
repair layer. This separation of concerns allows the LLM to focus on generating well-formed output structures during
decoding, while the repair operators handle problem-specific feasibility requirements that would be impractical to encode
directly within context-free grammars.
E. Repair Algorithm Details
This section provides complete algorithmic specifications for the repair operators introduced in Section 3.2. Each repair
operator is designed to satisfy the three properties stated in Definition 3.5: a feasibility guarantee, idempotence on feasible
solutions, and bounded locality. We present detailed pseudocode, complexity analysis, and formal verification that each
operator satisfies these required properties.
E.1. TSP Repair Algorithm
The TSP repair operator addresses two types of constraint violations: duplicate nodes and missing nodes. The algorithm
operates in two phases: first, it removes all duplicate occurrences while preserving the first appearance of each node; then, it
greedily inserts missing nodes at positions that minimize the increase in tour length.
The algorithm correctly handles boundary conditions through modular arithmetic when computing insertion costs. For a tour
with |r′| nodes, position i connects to position i mod |r′| to form a cycle. The greedy insertion strategy is a well-known
2-approximation heuristic for TSP that provides bounded quality degradation.
Complexity Analysis. The duplicate removal phase processes each of the k input nodes once, requiring O(k) time with
appropriate data structures for the seen set. The missing node insertion phase processes m = |V \ seen| missing nodes,
and for each missing node evaluates O(n) insertion positions, where n = |V |. Each position evaluation requires constant
time to compute the insertion cost. Therefore, the total complexity is O(k + mn). In the worst case, when k = O(n) and
m = O(n), this simplifies to O(n2).
Property Verification. We verify that the TSP repair operator satisfies the three required properties from Definition 3.5. For
feasibility, the algorithm explicitly ensures that the output r′ contains exactly the node set V by construction: the duplicate
removal phase guarantees no duplicates, and the missing node insertion phase guarantees all nodes appear. For idempotence,
if the input route already visits all nodes in V exactly once, the seen set equals V after the first phase, the missing set is
empty, and the second phase performs no insertions, returning the input unchanged. For bounded locality, let the Hamming
distance dH measure the number of position changes; the algorithm modifies at most |V \ seen| positions to insert missing
nodes. Using the violation magnitude v(r) = |V \ seen| + |duplicates(r)|, we have dH(r, r′) ≤v(r), establishing the
bound with constant α = 1.
E.2. CVRP Repair Algorithm
The CVRP repair operator addresses three types of violations: invalid individual routes, missing customers, and capacity
constraint violations. The algorithm applies TSP repair to each route, ensures complete customer coverage, and then splits
overloaded routes.
22


--- Page 23 ---
Hard Constraints Meet Soft Generation
Algorithm 3 TSP Repair
Input
:Route r = [v1, v2, . . . , vk], node set V = {0, 1, . . . , n −1}, distance matrix d
Output :Valid TSP tour r′ visiting all nodes in V exactly once
1 seen ←∅
2 r′ ←[ ]
3 for i ←1 to k do
4
if vi ∈V and vi /∈seen then
5
Append vi to r′
6
seen ←seen ∪{vi}
7 missing ←V \ seen
8 foreach node v ∈missing do
9
best pos ←0
10
best cost ←d(v, r′[0])
// Cost to insert at beginning
11
for i ←1 to |r′| do
12
cost ←d(r′[i −1], v) + d(v, r′[i mod |r′|]) −d(r′[i −1], r′[i mod |r′|])
13
if cost < best cost then
14
best cost ←cost
15
best pos ←i
16
Insert v at position best pos in r′
17 return r′
Algorithm 4 CVRP Repair
Input
:Routes R = {r1, r2, . . . , rm}, customer set V = {1, . . . , n −1}, demands {qi}n−1
i=1 , capacity Q, distance matrix d
Output :Valid CVRP solution with all customers covered and capacity constraints satisfied
1 for k ←1 to m do
2
rk ←TSPRepair(rk, V ∪{0}, d)
// Ensure route visits each customer at most once
3
Remove depot node 0 from the interior of rk if present
4 covered ←Sm
k=1(rk \ {0})
5 missing ←V \ covered
6 foreach customer v ∈missing do
7
k∗←arg mink mini{d(rk[i −1], v) + d(v, rk[i]) −d(rk[i −1], rk[i])}
8
Insert v into route rk∗at the position achieving minimum cost
9 for k ←1 to |R| do
10
while P
v∈rk qv > Q do
11
Find split point i∗= arg min|rk|−1
i=1
SplitCost(rk, i) where Pi−1
j=1 qrk[j] ≤Q
12
rnew ←[rk[i∗], rk[i∗+ 1], . . . , rk[|rk|]]
13
rk ←[rk[1], rk[2], . . . , rk[i∗−1]]
14
R ←R ∪{rnew}
15 return R
The split cost function measures the additional distance incurred by breaking a route at position i and returning both
segments to the depot:
SplitCost(r, i) = d(r[i −1], 0) + d(0, r[i]) −d(r[i −1], r[i]).
The split point search is constrained to positions where the first segment satisfies the capacity constraint, ensuring that
repeated splitting eventually reduces all route loads below capacity.
Complexity Analysis. The route repair phase requires O(m · n2) time for m routes. The missing customer insertion phase
requires O(p · m · n) time for p missing customers. The route splitting phase requires O(m′ · n) time, where m′ is the final
23


--- Page 24 ---
Hard Constraints Meet Soft Generation
number of routes. Since m′ = O(n) in the worst case, the overall complexity is O(n2 + n · m). When m = O(n), this
simplifies to O(n2).
Property Verification. For feasibility, the algorithm ensures all customers in V are covered through explicit missing
customer insertion, and all routes satisfy capacity through repeated splitting until convergence. For idempotence, if all routes
are valid TSP tours, all customers are covered, and all capacity constraints are satisfied, then no modifications occur. For
bounded locality, the number of modifications is bounded by the sum of TSP violations across routes plus the number of
missing customers plus the number of capacity violations, establishing the required bound.
E.3. OP Repair Algorithm
The Orienteering Problem repair operator removes nodes iteratively until the distance budget constraint is satisfied,
prioritizing removal of nodes with the worst prize-to-distance-contribution ratio.
Algorithm 5 OP Repair
Input
:Route r = [v0, v1, . . . , vk, vk+1] with v0 = vk+1 = 0 (depot), distance budget D, prizes {pi}, distance matrix d
Output :Valid OP route satisfying distance budget
1 r ←RemoveDuplicates(r)
// Keep first occurrence of each node
2 while TotalDistance(r) > D and |r| > 2 do
3
v∗←arg minv∈r\{0}
pv
DistContrib(r, v)
4
Remove v∗from r
5 if TotalDistance(r) > D then
6
return [0, 0]
// Return empty route if budget still violated
7 return r
The distance contribution of node v at position i in route r is defined as:
DistContrib(r, v) = d(r[i −1], v) + d(v, r[i + 1]) −d(r[i −1], r[i + 1]),
where i is the position of v in r. This measures the additional distance incurred by including node v in the route. The total
route distance is:
TotalDistance(r) =
|r|−1
X
i=0
d(r[i], r[i + 1]).
Complexity Analysis. Each iteration of the while loop evaluates O(n) candidate nodes and removes one node. In the worst
case, O(n) nodes must be removed, yielding O(n2) total complexity. With a priority queue data structure maintaining nodes
sorted by prize-to-distance ratio, the complexity can be reduced to O(n log n).
Property Verification. For feasibility, the algorithm terminates only when the distance constraint is satisfied or when
only the depot remains (which trivially satisfies the budget). For idempotence, if the input route already satisfies the
distance budget, the while loop condition is false and the input is returned unchanged. For bounded locality, the number
of removed nodes is bounded by the initial budget violation, establishing the required bound with violation magnitude
v(r) = max(0, TotalDistance(r) −D).
E.4. MIS Repair Algorithm
The Maximum Independent Set repair operator iteratively removes vertices involved in conflicts (adjacent pairs both in
the set) until no conflicts remain. Among conflicting pairs, the algorithm removes the vertex with higher degree within the
current set, as this vertex is involved in more conflicts.
24


--- Page 25 ---
Hard Constraints Meet Soft Generation
Algorithm 6 MIS Repair
Input
:Set S ⊆V , graph G = (V, E)
Output :Independent set S′ with no adjacent vertices
1 S′ ←S
2 conflicts ←{(u, v) ∈E : u, v ∈S′}
3 while conflicts ̸= ∅do
4
Select any (u, v) ∈conflicts
5
degu ←|{w ∈S′ : (u, w) ∈E}|
6
degv ←|{w ∈S′ : (v, w) ∈E}|
7
if degu > degv then
8
S′ ←S′ \ {u}
9
else
10
if degv > degu then
11
S′ ←S′ \ {v}
12
else
13
S′ ←S′ \ {u}
// Break ties arbitrarily
14
conflicts ←{(u, v) ∈E : u, v ∈S′}
15 return S′
Complexity Analysis. The algorithm performs at most |S| vertex removals. Each iteration requires recomputing the conflict
set, which takes O(|E|) time by checking all edges. Therefore, the worst-case complexity is O(|V | · |E|). With incremental
conflict tracking, this can be improved to O(|E| + |V | log |V |).
Property Verification. For feasibility, the algorithm terminates only when the conflict set is empty, ensuring no two vertices
in S′ are adjacent. For idempotence, if the input set S is already independent, the initial conflict set is empty and the
algorithm immediately returns S unchanged. For bounded locality, the number of removed vertices equals the number of
conflicts resolved, which is bounded by the violation magnitude v(S) = |{(u, v) ∈E : u, v ∈S}|.
E.5. MVC Repair Algorithm
The Minimum Vertex Cover repair operator adds vertices to cover all uncovered edges. For each uncovered edge, the
algorithm adds the endpoint with higher degree among uncovered edges, as this vertex covers more edges.
Algorithm 7 MVC Repair
Input
:Set S ⊆V , graph G = (V, E)
Output :Vertex cover S′ where every edge has at least one endpoint in S′
1 S′ ←S
2 uncovered ←{(u, v) ∈E : u /∈S′ ∧v /∈S′}
3 while uncovered ̸= ∅do
4
Select any (u, v) ∈uncovered
5
degu ←|{w : (u, w) ∈uncovered}|
6
degv ←|{w : (v, w) ∈uncovered}|
7
if degu ≥degv then
8
S′ ←S′ ∪{u}
9
else
10
S′ ←S′ ∪{v}
11
uncovered ←{(u, v) ∈E : u /∈S′ ∧v /∈S′}
12 return S′
Complexity Analysis. The algorithm adds at most |V | vertices. Each iteration requires updating the uncovered edge set,
which takes O(|E|) time. Therefore, the worst-case complexity is O(|V | · |E|). However, with efficient data structures
25


--- Page 26 ---
Hard Constraints Meet Soft Generation
tracking uncovered edges, the complexity can be reduced to O(|E|) by processing each edge at most twice.
Property Verification. For feasibility, the algorithm terminates only when all edges are covered, ensuring every edge has at
least one endpoint in S′. For idempotence, if the input set S already covers all edges, the uncovered set is empty and the
algorithm immediately returns S unchanged. For bounded locality, the number of added vertices is bounded by the number
of uncovered edges, establishing the required bound with violation magnitude v(S) = |{(u, v) ∈E : u /∈S ∧v /∈S}|.
E.6. PFSP Repair Algorithm
The Permutation Flow Shop Scheduling repair operator ensures all jobs appear exactly once by removing duplicates and
greedily inserting missing jobs at positions that minimize the resulting makespan.
Algorithm 8 PFSP Repair
Input
:Job sequence σ = [j1, . . . , jk], job set J = {1, . . . , n}, processing times {pi,j}, number of machines m
Output :Valid permutation σ′ of all jobs
1 seen ←∅
2 σ′ ←[ ]
3 for i ←1 to k do
4
if ji ∈J and ji /∈seen then
5
Append ji to σ′
6
seen ←seen ∪{ji}
7 missing ←J \ seen
8 foreach job j ∈missing do
9
best pos ←0
10
best makespan ←∞
11
for i ←0 to |σ′| do
12
σtemp ←σ′[0:i] + [j] + σ′[i: ]
13
M ←ComputeMakespan(σtemp, {pi,j}, m)
14
if M < best makespan then
15
best makespan ←M
16
best pos ←i
17
Insert j at position best pos in σ′
18 return σ′
The makespan computation follows the recursive formula from Definition B.7:
Cσ(k),j = max(Cσ(k),j−1, Cσ(k−1),j) + pσ(k),j,
ComputeMakespan(σ, {pi,j}, m) = Cσ(n),m.
Complexity Analysis. The duplicate removal phase requires O(k) time. For each of the O(n) missing jobs, the algorithm
evaluates O(n) insertion positions, and each makespan computation requires O(nm) time. Therefore, the total complexity
is O(n2m).
Property Verification. For feasibility, the algorithm ensures the output contains exactly the job set J through duplicate
removal and missing job insertion. For idempotence, if the input is already a valid permutation of J, the missing set is
empty and no insertions occur. For bounded locality, the number of modifications is bounded by the number of duplicates
plus missing jobs, establishing the required bound.
E.7. JSSP Repair Algorithm
The Job Shop Scheduling repair operator ensures each job appears exactly once on each machine, then resolves precedence
constraint violations through topological sorting of the precedence graph.
26


--- Page 27 ---
Hard Constraints Meet Soft Generation
Algorithm 9 JSSP Repair
Input
:Machine schedules S = [s1, . . . , sm] where si is job sequence for machine i, job set J = {1, . . . , n}, operation
machines {µ(oi,k)}
Output :Valid JSSP schedule respecting precedence constraints
1 for i ←1 to m do
2
si ←PermutationRepair(si, J)
// Remove duplicates, insert missing jobs
3 Construct operation precedence graph Gprec = (O, Eprec), where:
4
O = {oi,k : i ∈J, k ∈{1, . . . , m}}
5
Eprec = {(oi,k, oi,k+1) : i ∈J, k ∈{1, . . . , m −1}}
6 Compute a topological ordering τ of Gprec
7 for i ←1 to m do
8
Reorder si to respect τ while preserving the relative order of jobs already consistent with τ
9 return S
The PermutationRepair subroutine is similar to PFSP repair but without makespan optimization, simply appending missing
jobs to the end of each machine’s sequence.
Complexity Analysis. The permutation repair phase requires O(m · n2) time. Constructing the precedence graph requires
O(nm) time. Topological sorting requires O(nm) time. Reordering each machine schedule requires O(n log n) time using
stable sorting. Therefore, the total complexity is O(nm log(nm)).
Property Verification. For feasibility, the algorithm ensures each operation appears exactly once through permutation
repair, and precedence constraints are satisfied through topological sorting. For idempotence, if the input already has valid
permutations respecting precedence, no modifications occur. For bounded locality, the number of modifications is bounded
by the total number of permutation violations plus precedence violations, establishing the required bound.
F. Extended Theoretical Analysis
F.1. Gradient Comparison Across Training Methods
We provide a formal comparison of the gradient structures in different preference optimization approaches.
Proposition F.1 (Gradient Comparison). Consider a preference pair (yw, yl) where yw ≻yl indicates yw is preferred over
yl. The gradient updates for Direct Preference Optimization (DPO), Group Relative Policy Optimization (GRPO), and
Best-anchored Objective-guided Preference Optimization (BOPO) have the following forms.
For DPO with preference strength parameter β, the gradient is:
∇θLDPO = −β · σ(−β · ∆sθ) · ∇θ∆sθ,
where ∆sθ = log πθ(yw|ϕ(p)) −log πθ(yl|ϕ(p)) is the log-probability ratio and σ(·) denotes the sigmoid function.
For GRPO with normalized advantages {Ai}K
i=1, the gradient is:
∇θLGRPO = −1
K
K
X
i=1
Ai · ∇θ log πθ(yi|ϕ(p)),
where advantages Ai are computed relative to the group mean reward.
For BOPO with objective-guided weights w(∆i) = ∆i/ ¯∆, the gradient is:
∇θLBOPO = −
1
K −1
K−1
X
i=1
w(∆i) · σ(−β · ∆s(i)
θ ) · ∇θ∆s(i)
θ ,
where each ∆s(i)
θ
= log πθ(y∗|ϕ(p)) −log πθ(yi|ϕ(p)) represents the log-probability ratio between the best solution y∗
and the inferior solution yi.
27


--- Page 28 ---
Hard Constraints Meet Soft Generation
The key distinction lies in how different solutions contribute to the gradient update. In DPO, each preference pair contributes
equally regardless of the magnitude of quality difference. In GRPO, contributions are modulated by normalized advantages,
but normalization can dilute the signal from high-quality solutions. In BOPO, the objective-guided weighting ensures that
solutions with larger optimality gaps contribute proportionally more to learning, providing stronger supervision signal for
clearly inferior solutions while maintaining bounded updates through the scaling normalization.
Proposition F.2 (Variance Properties). Under the assumption that the gradient variance Var[∇θ log πθ(y)] is uniformly
bounded across solutions, BOPO achieves lower gradient variance than GRPO when the ratio of objective gap variance to
squared mean, Var[∆i]/E[∆i]2, is smaller than the variance of normalized advantages Var[Ai]. This condition typically
holds for combinatorial optimization problems where objective values have natural scales and the best solution provides a
stable anchor point for computing gaps.
The variance reduction stems from the anchoring strategy. By always comparing against the best solution in the current
batch, BOPO creates a consistent reference point that stabilizes gradient estimates. In contrast, GRPO computes advantages
relative to the batch mean, which can shift substantially across batches, introducing additional variance into the training
signal.
F.2. End-to-End Quality Guarantee
Theorem F.3 (FALCON End-to-End Guarantee). Let πθ be a policy trained with BOPO until convergence to an ϵ-stationary
point satisfying E[∥∇LBOPO(θ)∥2] ≤ϵ. When deployed with grammar-constrained decoding, a repair operator R satisfying
Definition 3.5, and adaptive Best-of-N sampling with N samples, FALCON produces a solution ˆy with the following
guarantees:
1. Format Validity: The solution is syntactically valid with probability one, ensuring the evaluation function ψp(ˆy) is
well-defined. 2. Semantic Feasibility: The solution is semantically feasible with probability one, ensuring ˆy ∈XCp. 3.
Quality Bound: The expected optimality gap satisfies:
E[fp(ˆy) −fp(y∗)] ≤E[gN] + Lf · α · E[v(ˆy)],
where E[gN] = O(1/N) is the expected optimality gap from sampling N solutions (see Theorem 3.11), Lf is the Lipschitz
constant of the objective function with respect to the solution distance metric, α is the locality constant of the repair operator
(Definition 3.5), and v(ˆy) is the violation magnitude before repair.
Proof. The format validity guarantee follows directly from Theorem 3.3, which establishes that grammar-constrained
decoding ensures all generated text belongs to the language defined by the problem-specific grammar.
The feasibility guarantee follows from Theorem 3.6, which shows that the repair operator maps any solution to the feasible
region regardless of the input.
For the quality bound, let ˜yN denote the best solution among N samples before repair, and let ˆy = R(˜yN) be the final
output after repair. By the triangle inequality:
fp(ˆy) −fp(y∗) = [fp(ˆy) −fp(˜yN)] + [fp(˜yN) −fp(y∗)].
Taking expectations and applying Theorem 3.7 to the first term and Theorem 3.11 to the second term yields the stated bound:
E[fp(ˆy) −fp(y∗)] ≤E[fp(ˆy) −fp(˜yN)] + E[fp(˜yN) −fp(y∗)]
≤Lf · α · E[v(ˆy)] + E[gN].
The theorem demonstrates that FALCON’s solution quality depends on two factors: sampling quality, which improves with
more samples (E[gN] = O(1/N)), and repair cost, which decreases as the model produces fewer and smaller violations
through BOPO training (E[v(ˆy)] decreases). The multiplicative interaction between these factors explains the empirical
observation that FALCON maintains competitive optimality gaps despite enforcing hard feasibility constraints.
28


--- Page 29 ---
Hard Constraints Meet Soft Generation
F.3. Generalization Bound
Theorem F.4 (Generalization from Training to Test Distribution). Let Dtrain and Dtest be training and test distributions over
problem instances. Assume:
1. W1(Dtrain, Dtest) ≤δ, where W1 denotes the Wasserstein-1 distance.
2. The policy πθ is Lπ-Lipschitz in problem parameters.
3. The objective function fp is Lf-Lipschitz with respect to the solution representation.
Then for a policy trained on Dtrain:
Ep∼Dtest[Gap(p)] ≤Ep∼Dtrain[Gap(p)] + Lf · Lπ · δ,
where Gap(p) = fp(ˆyp) −fp(y∗
p) is the optimality gap for instance p, and ˆyp is the solution produced by the trained policy.
Proof. The proof follows from the Lipschitz assumptions and the definition of the Wasserstein distance. For any coupling γ
between Dtrain and Dtest with marginals Dtrain and Dtest:
Ep∼Dtest[Gap(p)] −Ep∼Dtrain[Gap(p)] = E(ptrain,ptest)∼γ[Gap(ptest) −Gap(ptrain)]
≤Lf · E(ptrain,ptest)∼γ[∥ˆyptest −ˆyptrain∥]
≤Lf · Lπ · E(ptrain,ptest)∼γ[∥ptest −ptrain∥]
= Lf · Lπ · W1(Dtrain, Dtest)
≤Lf · Lπ · δ.
Taking the infimum over all couplings γ yields the desired bound.
F.4. Repair Approximation Ratios
Proposition F.5 (TSP Repair Approximation). The greedy insertion repair for TSP (Algorithm 3) achieves a solution within
a factor of 2 of the optimal tour length increase due to inserted nodes.
Proposition F.6 (TSP-Specific Repair Bound). For TSP with n cities in the unit square [0, 1]2, the greedy insertion repair
satisfies:
f(R(x)) −f(x) ≤2 · |missing| · max
i,j dij ≤2
√
2 · |missing|,
where |missing| is the number of missing nodes, and dij denotes the Euclidean distance between nodes i and j.
Proposition F.7 (MVC Repair Approximation). The greedy repair for MVC (Algorithm 7) achieves a 2-approximation to
the minimum vertex cover.
G. Implementation Details
G.1. Full Hyperparameter Table
The complete hyperparameter settings for the full pipeline are summarized in Table 7.
G.2. PDA Construction Details
For a context-free grammar G = (V, Σ, R, S), we construct an equivalent pushdown automaton (PDA) A =
(Q, Σ, Γ, δ, q0, Z0, F) using standard CFG-to-PDA conversion techniques for grammar-constrained decoding.
G.2.1. PDA COMPONENTS
The state set is defined as Q = {q0, qacc} ∪{qA : A ∈V }, where q0 is the single control state and qA are auxiliary states for
tracking non-terminals. In practice, a single-state PDA suffices since all derivation information is encoded on the stack.
The input alphabet Σ is the LLM vocabulary (token set), typically |Σ| ≈32,000 for modern language models. The stack
29


--- Page 30 ---
Hard Constraints Meet Soft Generation
Table 7. Complete hyperparameter settings for the full pipeline.
Parameter
Symbol
Value
Model Configuration
Base model
–
Qwen2.5-7B
LoRA rank
r
64
LoRA alpha
α
64
Target modules
–
q, k, v, o, gate, up, down
SFT Training Stage
Batch size
B
4
Gradient accumulation steps
–
4
Learning rate
η
2 × 10−4
Epochs
–
1
Warmup steps
–
20
Weight decay
–
0.01
BOPO Training Stage
Batch size
B
8
Gradient accumulation steps
–
8
Learning rate
η
1 × 10−6
Temperature
β
0.1
Samples per instance
K
8
Epochs
–
1
Inference Configuration
Minimum samples
Nmin
8
Maximum samples
Nmax
64
Confidence threshold
τ
0.85
Sampling temperature
T
0.7
alphabet is defined as Γ = V ∪{$}, where V is the set of non-terminals from grammar G and $ is the bottom-of-stack
marker. We initialize the PDA with configuration (q0, $S), where the stack contains the start symbol S on top of the bottom
marker $. Finally, the accepting states are F = {q0}, and we accept when the stack contains only the bottom marker $.
G.2.2. TRANSITION RULES
The transition function δ operates through two fundamental mechanisms. First, for epsilon transitions (non-terminal
expansion), each production rule A →α in R induces the transition:
δ(q0, ϵ, A) = (q0, α),
which allows the PDA to replace a non-terminal on the stack with its right-hand side. Second, for terminal consumption,
each terminal symbol a ∈Σ gives rise to the transition:
δ(q0, a, a) = (q0, ϵ),
which pops the terminal from the stack when it matches the input token.
G.2.3. VALID TOKEN COMPUTATION
At each decoding step, after generating the partial output y(t) = v1v2 · · · vt, the PDA maintains a configuration (q, γ), where
q is the current state and γ ∈Γ∗is the stack content. The set of valid next tokens is computed through a three-step process.
First, we simulate epsilon-closure: Starting from the current stack configuration (q, γ), we compute the set of all possible
stack configurations reachable via epsilon transitions (non-terminal expansions). This constitutes the epsilon-closure of the
PDA configuration.
30


--- Page 31 ---
Hard Constraints Meet Soft Generation
Second, we collect consumable terminals: After fully expanding all non-terminals via epsilon transitions, the top of the
stack contains either a terminal symbol or the bottom marker. The valid tokens are exactly those that match the stack top:
Vvalid = {a ∈Σ : stack top = a in epsilon-closure}.
Third, we handle bottom-of-stack: If the epsilon-closure yields an empty stack (the stack contains only $), then no more
tokens can be consumed, signaling the end of generation. The algorithm terminates when the stack is empty and an accepting
state is reached. This procedure ensures that only tokens leading to grammatically valid derivations are permitted, effectively
masking invalid continuations before sampling.
G.2.4. CORRESPONDENCE WITH ALGORITHM 1
The valid token computation described above directly implements lines 5–8 of Algorithm 1 in the main paper:
logits ←πθ(x, y) # Line 4
V_valid ←{v ∈Σ | δ(q, v, top(γ)) ̸= ∅} # Line 5
for v /∈V_valid do logits[v] ←-∞# Lines 6-8
The PDA-based approach provides an efficient, declarative way to compute Vvalid for any context-free grammar without
manual enumeration.
G.2.5. COMPUTATIONAL COMPLEXITY
The computational overhead of valid token computation per decoding step is O(|V | · |Q|), where |V | is the number of
non-terminals and |Q| is the number of PDA states. For CO problems, the grammars are typically simple with constant-size
state space (e.g., |Q| = O(1)), yielding O(|V |) = O(1) overhead. Even in the worst case with explicit state tracking, the
overhead is negligible compared to the O(d2) complexity of LLM attention computation, where d is the hidden dimension.
G.2.6. IMPLEMENTATION REMARKS
Several optimizations are recommended for practical implementation. Precompute PDA: Construct the PDA once
during initialization and reuse it across all inference steps, avoiding redundant construction overhead. Memoize epsilon-
closure: Cache epsilon-closure computations for each PDA state to avoid redundant expansion during decoding. Bit-mask
representation: For efficiency, represent the valid token set as a bit mask over the vocabulary, allowing bitwise operations
to identify forbidden tokens for logit masking. Early termination: Monitor stack depth; if the stack reaches the bottom
marker before generating the expected length, force termination to prevent infinite loops in malformed grammars.
G.3. Computational Complexity of Repair Operators
The time and space complexity analysis for each repair operator is summarized in Table 8, where n denotes the number
of nodes or jobs, m the number of machines or routes, and |V |, |E| denote the numbers of vertices and edges in graph
problems.
Table 8. Time and space complexity analysis for each repair operator.
Problem
Time Complexity
Space Complexity
TSP
O(n2)
O(n)
CVRP
O(n2 + n · m)
O(n + m)
OP
O(n2)
O(n)
MIS
O(|V | · |E|)
O(|V |)
MVC
O(|E|)
O(|V |)
PFSP
O(n2 · m)
O(n)
JSSP
O(n · m · log(n · m))
O(n · m)
31


--- Page 32 ---
Hard Constraints Meet Soft Generation
G.4. Dataset
Table 9 presents the dataset statistics for the seven combinatorial optimization problems. GM, ER, and BA denote Gaussian
Mixture, Erd˝os-R´enyi, and Barab´asi-Albert distributions, respectively.
Table 9. Dataset statistics across all seven combinatorial optimization problems.
Problem
Train Set
Test Set
Scale
Distribution
Reference Solver
TSP
500K
100
10–100 nodes
Uniform, GM
LKH-3
OP
500K
100
10–100 nodes
Uniform, GM
COMPASS
CVRP
500K
100
10–100 nodes
Uniform, GM
LKH-3
MIS
500K
100
50–500 nodes
ER, BA
Gurobi
MVC
500K
100
50–500 nodes
ER, BA
Gurobi
PFSP
500K
100
10–100 jobs
Taillard
QIG
JSSP
500K
100
6–30 jobs
Taillard
OR-Tools
32
