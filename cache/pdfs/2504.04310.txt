--- Page 1 ---
CO-Bench: Benchmarking Language Model Agents in
Algorithm Search for Combinatorial Optimization
Weiwei Sun*
Shengyu Feng*
Shanda Li
Yiming Yang
Carnegie Mellon University
{weiweis,shengyuf,shandal,yiming}@cs.cmu.edu
Abstract
Although LLM-based agents have attracted significant atten-
tion in domains such as software engineering and machine
learning research, their role in advancing combinatorial op-
timization (CO) remains relatively underexplored. This gap
underscores the need for a deeper understanding of their poten-
tial in tackling structured, constraint-intensive problems—a
pursuit currently limited by the absence of comprehensive
benchmarks for systematic investigation. To address this, we
introduce CO-Bench, a benchmark suite featuring 36 real-
world CO problems drawn from a broad range of domains
and complexity levels. CO-Bench includes structured problem
formulations and curated data to support rigorous investiga-
tion of LLM agents. We evaluate multiple agentic frameworks
against established human-designed algorithms, revealing the
strengths and limitations of existing LLM agents and identify-
ing promising directions for future research. CO-Bench is pub-
licly available at https://github.com/sunnweiwei/CO-Bench.
Introduction
Combinatorial Optimization (CO) is a foundational prob-
lem class in computer science and operation research, fo-
cused on finding optimal solutions in discrete, structured,
and constraint-rich domains. It underpins a wide range of
real-world applications, including logistics (Vogiatzis and
Pardalos 2013), production planning (Crama 1997), bioinfor-
matics (Gusfield 1997), etc. Many CO problems are compu-
tationally intractable and classified as NP-hard, making exact
solutions impractical at scale. As a result, developing effec-
tive algorithms often demands significant domain expertise
and manual effort—posing a long-standing challenge in both
academic research and industrial applications.
Recent advances in Large Language Models (LLMs) (Ope-
nAI 2024b; DeepSeek-AI 2025a) have positioned LLM-
based agents as increasingly promising tools for a variety
of prediction and decision-making tasks (Jimenez et al. 2023;
Chan et al. 2024; Gottweis et al. 2025). In particular, there is
growing interest in applying LLMs to CO problems. Initial
investigations have largely focused on solution correctness,
evaluated on small-scale test instances (Ramamonjison et al.
2023; Yang et al. 2025a; Xiao et al. 2024a), and are often
geared towards solving problems posed by general users.
More recent works have begun to explore autonomous LLM
*These authors contributed equally.
Figure 1: Overview of CO-Bench. CO-Bench includes 36
problems from 8 categories, and aims to evaluate LLM agents’
ability to develop effective and efficient algorithms for solv-
ing real-world combinatorial optimization problems.
agents capable of conducting research and designing more
efficient algorithms for complex scientific and industrial chal-
lenges. For example, FunSearch (Romera-Paredes et al. 2023)
combines LLM prompting with evolutionary search to dis-
cover heuristics that outperform human-designed counter-
parts in the Cap Set and Bin Packing problems. Subsequent
methods (Liu et al. 2024; Ye et al. 2024; Novikov et al. 2025)
further improve computational efficiency and broaden appli-
cability to domains such as routing and scheduling.
Despite these advancements, most existing efforts focus
on narrow components (e.g., priority functions) within estab-
lished algorithms, across a limited set of tasks (typically 4-7
problems), and often rely on heavily handcrafted, problem-
specific prompts and templates (Romera-Paredes et al. 2023;
Ye et al. 2024). Furthermore, there remains a lack of system-
atic evaluation of how these agents perform across a broader
and more diverse collection of real-world CO problems.
To address this gap, we introduce CO-Bench, a compre-
hensive benchmark designed to evaluate LLM agents in the
context of efficient CO algorithm development. CO-Bench
comprises real-world CO problems spanning a wide range of
domains and complexities. Figure 1 illustrates the problem
categories and examples, while Table 1 compares CO-Bench
with existing CO benchmarks. Compared to prior bench-
arXiv:2504.04310v3  [cs.CL]  22 Aug 2025


--- Page 2 ---
marks, CO-Bench offers broader problem coverage, and
emphasizes end-to-end evaluation of LLM-based research
agents, focusing on their ability to design efficient, potentially
novel algorithms from abstract problem descriptions. This
design enables reproducible and scalable evaluation of agent
performance, including comparisons with human-designed
classical CO solver under equivalent time constraints. By do-
ing so, CO-Bench introduces new challenges for LLM agent
development, such as the discovery of algorithms that extend
beyond current human knowledge of CO.
Using CO-Bench, we benchmark 15 LLMs and 9 agen-
tic frameworks, comparing their performances against both
human-designed classical algorithms and the best-known so-
lutions reported in the literature. Our results show that reason-
ing models (e.g., o3-mini and Claude-3.7-sonnet) consistently
outperform standard no-reasoning LLMs. When integrated
into agentic frameworks like FunSearch, LLMs further im-
prove through trial-and-error exploration. Notably, on 25
problems, LLM-generated algorithms outperformed classical
solvers, and on 3 problems, they surpassed the best-known
solutions. However, our analysis also reveals current limi-
tations, such as limited algorithmic novelty and insufficient
handling of feasibility constraints. These findings highlight
both the promise and challenges of LLM-driven research in
CO and suggest key directions for advancing autonomous
algorithm design.
In summary, this paper makes the following contributions:
(i) We introduce CO-Bench, the first comprehensive bench-
mark to evaluate the capability of LLMs to develop algo-
rithms for diverse and challenging real-world CO prob-
lems
(ii) We benchmark 15 LLMs and 9 agentic frameworks, an-
alyzing their performance relative to expert-designed
pipelines. Our results highlight the strengths of agent-
generated algorithms, while also revealing limitations in
planning, feasibility checking, and the generation of effi-
cient solution.
Preliminary
Combinatorial Optimization
For each CO problem c (for example, Traveling salesman
problem), we follow Papadimitriou and Steiglitz (1982) to
formulate it as a constrained optimization problem in the dis-
crete space. Consider an instance p, the optimization problem
could be expressed as
min
x∈Sc(p) fc(x; p) + gc(x; p),
(1)
where Sc(p) represents the solution space, e.g., Zm × Rn
for d discrete variables and n continuous variables, fc(x; p)
corresponds to the objective function, and gc(x; p) stands
for the constraint violation, which is 0 for feasible solutions
and +∞otherwise. To avoid the clutter, we simply denote
hc(x; p) = fc(x; p) + gc(x; p) in the following text and omit
c if the context is clear.
Given an algorithm set A and a problem instance distribu-
tion D, the algorithm search problem is defined as
min
A∈A Ep∼D,x∼A(p)[h(x; p)].
(2)
Dataset
Algorithm
Dev
Problem
Num
Instance
Num
Largest
Variables
NPHardEval
✗
9
900
24
NL4OPT
✗
5
289
3
OptiBench
✗
4
605
18
ComplexOR
✗
20
100
9
ReEvo
✓
7
597
1,000
CO-Bench
✓
36
6,482
11,000
Table 1: Data statistics for CO-Bench and related CO bench-
marks, including the indicator for algorithm development
support, the number of problem types, the number of test-set
problem instances, and the largest number of test-set vari-
ables (e.g., the number of nodes in the largest graph).
In contrast to previous neural CO solvers (Bengio, Lodi, and
Prouvost 2020) that directly parameterize A with a neural
network, we focus on symbolic searching space where A con-
sists of all algorithms that could be represented by a Python
Program, with a maximum number of d tokens, where d is
typically decided by the output length limit of an LLM. Con-
sidering the popularity of randomized algorithms (Motwani
and Raghavan 2013) for CO, we treat the output of an algo-
rithm A(p) as a distribution of solutions, while deterministic
algorithms would correspond to the point distributions.
The main endeavor of this work is focused on the shaping
of the algorithm set A, the curation of the data distribution
D and the definition of h on our collected CO problems.
LLM Agents
Given a CO problem c, a candidate algorithm could be gener-
ated by an LLM as
A ∼M(textify(c); θ),
(3)
where M denotes an LLM with parameters θ. However, one-
time generation usually leads to inexecutable code or subop-
timal algorithms (Madaan et al. 2023), and agentic frame-
works address this by enabling iterative refinement through
structured interactions with external tools (e.g., a coding en-
vironment). Formally, an agent performs reasoning-action
iterations (Yao et al. 2022):
rt+1 ∼M(textifyr(c, At, Ht); θ),
(4)
at+1 ∼M(textifya(rt+1, Ht); θ),
(5)
where rt is the reasoning step, at is the action step
(e.g., executing code, evaluating results), and Ht
=
(ri, ai, result(ai))t−1
i=1 maintains the interaction history. Thus,
an LLM agent is formally defined as an LLM M(·; θ) guided
by a structured workflow specifying iterative external inter-
actions to enhance its outputs.
CO-Bench
We introduce CO-Bench, a comprehensive benchmark de-
signed to evaluate the algorithm development ability of LLM
agents on combinatorial optimization (CO) problems. The


--- Page 3 ---
benchmark consists of 36 problems mainly sourced from OR-
Library (Beasley 1990), an established archive containing
datasets accumulated by researchers across over 30 years of
operations research. These problems span a wide range of
realistic CO challenges in academia and industrial applica-
tions.
Data Curation
Problem Selection
We first perform rigorous filtering and
cleaning, and select 36 CO problems that cover diverse do-
mains and complexities, including:
• Packing problems: Bin packing (Falkenauer 1996), Multi-
Demand Multidimensional Knapsack problem (Cappanera
and Trubian 2001), Multidimensional knapsack problem (Pe-
tersen 1967), Container loading (Bischoff and Ratcliff 1995;
Ivancic 1988), Container loading with weight restrictions (Rat-
cliff and Bischoff 1998; Bischoff 2006), Packing unequal
circles (López and Beasley 2016), Packing unequal rectangles
and squares number / area (López and Beasley 2018).
• Cutting problems: Assortment problem (Beasley 1985a), Con-
strained / unconstrained guillotine cutting (Christofides and
Whitlock 1977; Beasley 1985b), Constrained non-guillotine
cutting (Beasley 1985c, 2004).
• Facility location problems: Capacitated / Uncapacitated ware-
house location (Beasley 1988, 1993), Capacitated / Unca-
pacitated p-median problem (Beasley 1985d; Osman and
Christofides 1994).
• Scheduling problems: Aircraft landing (Beasley et al. 2000,
2004), Crew scheduling (Beasley and Cao 1996), Common
due date scheduling (Biskup and Feldmann 2001), Flow shop
scheduling (Taillard 1993), Hybrid Reentrant Shop Schedul-
ing (Chakhlevitch and Glass 2009), Job shop scheduling (Tail-
lard 1993), Open shop scheduling (Taillard 1993).
• Routing problems: Traveling salesman problem (Laporte
1992), Period vehicle routing problem
(Christofides and
Beasley 1984), Resource constrained shortest path (Beasley
and Christofides 1989).
• Assignment problems: Constrained / unconstrained assign-
ment (Osman 1995; and 1990).
• Tree problems: Euclidean Steiner (Beasley 1992), Corporate
structuring (Anken and Beasley 2012)
• Graph and set problems: Maximal Independent Set (Erdos and
Rényi 1984), Graph colouring (Fleurent and Ferland 1996),
Equitable partitioning (Mingers and O’Brien 1995), Set par-
titioning (Chu and Beasley 1998), Set covering (Beasley and
Jörnsten 1992).
Data Annotation
For each problem, we manually anno-
tate the following components: (1) Problem description: a
formal definition of the optimization problem in natural lan-
guage, accompanied by a clearly specified solve function
as the starter code; (2) Data loading function: a load_data
function to load and preprocess raw data from the test files;
(3) Evaluation function: an eval_func function that rig-
orously and robustly evaluates the quality of a solution. Ad-
ditionally, each problem comprises a development set and a
test set, each containing several problem instances.
Evaluation Framework
We develop a rigorous and ef-
ficient evaluation framework to assess the performance of
LLM agents in simulated, time-constrained competition sce-
narios (Chan et al. 2024). Specifically, LLM agents operate
within a sandbox environment with access to a Linux ma-
chine. For each problem, agents are provided with a problem
description, development datasets, and an API endpoint for
submitting their solutions (i.e. codebases) to receive evalu-
ation feedback. An independent evaluation system, which
is protected by built-in safeguards, scores the submitted so-
lutions on the development set in parallel. After a limited
number of research steps, the agent submits its final solution
for evaluation on the test set. During the agent development
process, both eval_func and test data are invisible. Figure
2 shows the evaluation pipeline in CO-Bench.
Designing Classical Solver Baselines
To investigate how
existing LLM agents perform compared to classical solvers,
we establish a classical solver baseline. Specifically, the au-
thors of this paper—who have extensive experience in related
areas and are familiar with the problems in CO-Bench—spent
approximately 30 minutes per problem testing and select-
ing the most effective classical solvers (e.g., LKH for TSP,
CPLEX for scheduling, Gurobi for MIS) and tuning their hy-
perparameters on the development set. This process ensures
that the classical solver baseline is well-tuned and competi-
tive for each problem in CO-Bench.
Evaluation Metrics
Avg Score
The main evaluation metric is similar to the
Primal Gap (Berthold 2006), defined as the normalized score
of the primal bound h(x; p) against a pre-computed optimal
(or best-known) objective value h∗
p:
s(x, p) = min{|h(x, p)|, |h∗
p|}
max{|h(x, p)|, |h∗p|},
(6)
A higher value indicates better performance and a score of
1 signifies the performance identical to the optimal or best-
known solution. Program errors or infeasible solutions lead
to a score of 0.0. The score of a solver on a given problem
is computed by averaging its scores across all test instances.
The overall benchmark score is then obtained by averaging
these problem-level scores across all 36 problems.
Valid Solution
We compute the percentage of problems
for which the generated code is correct on all test instances.
Any raised error–such as constraint violation or timeout–is
treated as an invalid signal. If any test instance for a given
problem results in an invalid signal, the entire solution for
that problem is considered invalid, even if it produces valid
results on other test instances.
Above Classical
Given the performance of classical solver,
we calculate the portion of problems where the model outper-
forms the classical solver baseline.
Survival Rate
The survival rate measures that, for each
problem, the percentage of test instances where the model’s
solution is above 99% of the reference score (reported opti-
mal or best-known solution from literature). This serve as a
challenge metric as the model can only get credit when it is
very close or better than previous-best algorithm.


--- Page 4 ---
Figure 2: CO-Bench is an evaluation environment for AI agents. Each problem has an associated description and a development
dataset. Following the setup in Chan et al. (2024), the agent-generated code implements an algorithm design, which is further
graded and compared against the best-known solution and human expert solution.
Experimental Setup
Benchmarked Methods
On CO-Bench, we evaluate various LLMs combined with dif-
ferent agentic frameworks, and compare them with existing
human-designed CO solvers.
LLMs
We conduct experiments on 5 open-source mod-
els and 10 proprietary models. These include instruction-
tuned models such as Llama-3.3-70B-Instruct (Meta 2024),
Qwen-2.5-Code-32B-Instruct (Hui et al. 2024), DeepSeek-
V3 (DeepSeek-AI 2024), and GPT-4o (OpenAI 2024a), as
well as frontier reasoning models, including o3-mini (Ope-
nAI 2025), Claude-3.7-Sonnet-Thinking (Anthropic 2025),
DeepSeek-R1 (DeepSeek-AI 2025b), Grok-3-Thinking (xAI
2025), QwQ-32B (Qwen 2025), and Gemini 2.5 Pro (Deep-
Mind 2025).
Agentic frameworks
For the aforementioned LLMs, we
apply various agentic frameworks to evaluate their perfor-
mance across different strategies. These range from simple
approaches, such as direct generation, to more sophisticated
frameworks that augment LLM with additional tools, work-
flows, and test-time compute:
• Direct Answer: The simplest approach, where the LLM
directly generates a solution to the combinatorial opti-
mization problem without further refinement.
• BestOfN Sampling (Chen et al. 2021): Generate N can-
didate solutions, evaluate each on a development set, and
select the solution with the best performance.
• Chain of Experts (Xiao et al. 2024a): A multi-agent
prompting framework where agents of different roles co-
operate to debug and deliver one solution.
• Greedy Refinement (Shinn et al. 2023; Madaan et al.
2023): Iteratively prompt the LLM to refine the current
best solution based on the evaluation results of the de-
velopment set, repeating this refinement process for N
steps.
• FunSearch (Romera-Paredes et al. 2023): Prompt the
LLM to either draft a new solution or refine an existing
one, followed by employing an evolutionary algorithm to
iteratively select and improve candidate solutions.
• EoH (Liu et al. 2024): Evolve both thoughts and codes
in an evolutionary search framework for generating high-
performance heuristics.
• AIDE (Jiang et al. 2025): A representative method for
machine learning engineering tasks, which stores existing
solutions in a tree structure and selectively prompts the
LLM to draft new solutions, debug or improve previously
stored solutions.
• ReEvo (Ye et al. 2024): A recent evolutionary algorithm
that incorporates short-term and long-term reflection mod-
ules, as well as a multi-agentic framework.
• MSTC-AHD (Zheng et al. 2025): A Monte Carlo Tree
Search (MCTS)-based agentic pipeline that organizes all
LLM-generated heuristics in a tree structure and uses the
MCTS algorithm with progressive widening technique to
guide the evolution of heuristics.
Implementation Details
For benchmark evaluation, we limit the solving time of each
test instance to 10 seconds on a single CPU, such that the
exact solving of the problem (achieving the optimal solution)
is impossible on most test instances. Test instances that result
in a timeout or error receive a score of 0.
For agent implementation, we use o3-mini-medium as the
default base model. Since the original implementations of
these agents may use different evaluation setups, we adapt
their approaches to our benchmark setting (i.e., end-to-end
algorithm search) by adjusting the prompts and tools. For all
agents, we set the number of iteration steps to 64. In each step,
the agent generates a code block as a candidate algorithm and
obtains its evaluation score on the development set. After 64
iterations, the agent produces 64 candidate algorithms, from
which the best-performing solution on the development set is
selected for final benchmark evaluation. All evaluations are
conducted on a single CPU core of a dual AMD EPYC 7313
16-Core processor.
Main Results
Figure 3 presents the results of LLMs and agents on the test
set. We highlight the following key findings.


--- Page 5 ---
0.5
1.0
Avg Score
Classical Solver
Llama-3.3-70B
GPT-4o-mini
Qwen2.5-Coder-32B
GPT-4o
DeepSeek-V3
QwQ-32B
DeepSeek-R1
Grok-3 Thinking
Gemini 2.5 Pro
o3-mini-medium
o1-high
o1-medium
o3-mini-high
Claude-3.7 Sonnet
Chain of Experts
AIDE
MSTC-AHD
BestOfN
ReEvo
Greedy Refine
EoH
FunSearch
Base LLMs
Reasoning LLMs
LLM Agents
0.797
0.123
0.234
0.254
0.400
0.435
0.412
0.474
0.507
0.525
0.571
0.615
0.617
0.650
0.651
0.295
0.753
0.762
0.774
0.774
0.840
0.840
0.842
0.2
0.4
0.6
0.8
Valid Solution
0.611
0.056
0.111
0.111
0.167
0.111
0.250
0.305
0.222
0.250
0.361
0.417
0.361
0.389
0.361
0.139
0.528
0.555
0.472
0.555
0.555
0.555
0.500
0.25
0.50
0.75
1.00
Above Classical
0.028
0.056
0.056
0.111
0.083
0.111
0.083
0.139
0.222
0.167
0.167
0.278
0.305
0.194
0.083
0.278
0.444
0.417
0.444
0.694
0.555
0.639
0.2
0.4
0.6
Survival Rate
0.394
0.057
0.095
0.136
0.138
0.182
0.159
0.173
0.198
0.230
0.190
0.221
0.243
0.251
0.225
0.188
0.227
0.315
0.285
0.320
0.448
0.390
0.426
Figure 3: Overall Performance. LLM Agents are all based on o3-mini-medium. Avg Score refers to the average normalized
objective scores across all problems. Valid Solution indicates the percentage of test-set problems for which the solutions are
feasible. Above Classical represents the percentage of test instances where the model outperforms the classical solver baseline.
Survival Rate measures the percentage of test instances where the model’s score exceeds 99% of the reference score.
Direct generation performance is limited. LLMs show
significantly lower average scores compared to the classi-
cal solver. They often fail to generate valid solutions (i.e.,
bug-free code that satisfies all constraints within the time
limit), rarely outperform the classical solver on individ-
ual instances, and often fail to produce optimal solutions.
Reasoning-capable models tend to perform better than non-
reasoning ones. The best-performing LLM for one-shot gen-
eration is Claude-3.7 Sonnet, with an average score of 0.65.
Agentic systems substantially improve LLM performance.
Compared to direct generation, the agentic pipeline achieves
considerably higher scores across all metrics. Among the
evaluated frameworks, FunSearch attains the highest average
score of 0.842, outperforming the classical solver (0.797).
It also surpasses the solver on over half the test instances
(see "Above Classical" score) and achieves a higher survival
rate. These results highlight the effectiveness of LLM-based
agents in solving CO problems.
Agent performance varies widely. Some advanced agentic
frameworks, such as AIDE, underperform compared to sim-
pler strategies like BestOfN on most metrics, though they
show higher valid solution rates—possibly due to their de-
bugging capabilities. This indicates that current planning
mechanisms in agents are still underdeveloped and may not
reliably outperform random sampling.
Valid solution rates still lag behind classical solvers. Ac-
cording to the Valid Solution metric, the best-performing
agents achieve a success rate of 0.555—lower than that of
the classical solver (0.611). This suggests that current agents
often struggle with solution feasibility and reliability.
Agents Error Analysis
To investigate why the agents’ valid solution scores are low,
Figure 4 shows the types of errors among invalid solutions for
five agents. We observe that code errors (i.e., bugs that pre-
vent compilation) are the least frequent issue. The dominant
error type varies across agents: Greedy Refine and ReEvo ex-
hibit more constraint violations, while FunSearch, AIDE, and


--- Page 6 ---
Figure 4: Agents Error Analysis. Distribution of three types of errors among invalid solutions for five agents.
Figure 5: Avg Score vs. the number of iteration steps (in total
64 steps) during the algorithm development.
BoN encounter more timeout errors. This highlights agents’
limitations in satisfying constraints and generating efficient
algorithms within time limits.
Performance over Iteration Steps
Figure 5 illustrates the performance of several representative
LLM agents across different iteration steps. At each step,
the agent generates a new algorithm and receives evaluation
results on the development set. We also include the perfor-
mance of the classical solver baseline for comparison.
All agents exhibit the ability to improve their performance
with more iteration steps. FunSearch consistently achieves the
best results, reaching a score of 0.8423 and converging after
around 50 steps. Notably, both FunSearch and Refine dis-
cover algorithms that outperform the classical solver within
approximately 10 steps. However, performance tends to satu-
rate after 30 steps, with further search yielding diminishing
returns. Enabling more consistent improvements under longer
search budgets presents an interesting future direction.
Figure 6 shows an example trajectory of algorithm develop-
ment by Greedy Refinement (o3-mini) on TSP over multiple
search steps. In the early stages, the agent enhances code effi-
ciency by adopting vectorized data structures and utilizing a
K-D tree. It then increases the number of search iterations and
introduces perturbations to escape local optima. Finally, the
agent integrates simulated annealing to balance exploration
Figure 6: Trajectory of algorithm development for Greedy
Refinement on TSP over 64 steps. The curve and highlighted
dots indicate the best-ever score and the steps where improve-
ments occurred. The algorithmic ideas behind each improve-
ment step are summarized in corresponding boxes.
and exploitation and applies adaptive heuristics for different
instance sizes. This example demonstrates that LLMs excel
in applying established techniques to improve efficiency and
implementation quality, but failing at algorithmic novelty.
Comparison to Neural Solvers
Table 2 compares the performance of agents with represen-
tative neural solvers on TSP and MIS, two well-studied CO
problems. We include DIMES (Qiu, Sun, and Yang 2022),
DIFUSCO (Sun and Yang 2023), and T2T (Li et al. 2023)
as neural baselines. For the method with multiple variants,
we only include their best results on each dataset. We also
consider a hybrid method, LEHD + ReEvo (Ye et al. 2024),
which combines the neural solver with LLM-designed heuris-
tics. We report both the objective values (the tour length for
TSP and set size for MIS) and the solving time. The results
show that the agents such as Greedy Refine and FunSearch
achieve competitive performance on both problems, often
outperforming existing neural solvers under similar time bud-
get and approaching the best results achieved by previous
solvers given extended search time.
Solution Analysis
In Figure 7, we plot the percentage of algorithms developed
by the Greedy Refinement agent for the 36 CO problems
that utilize existing solvers (e.g., code importing ortools,


--- Page 7 ---
TSP-500
TSP-1000
TSP-10000
ER-Small
ER-Large
Len ↓Time ↓Len ↓Time ↓Len ↓Time ↓Size ↑Time ↓Size ↑Time ↓
Gurobi
16.55
45.6h
-
-
-
-
41.38
50.0m
-
-
DIMES
18.84
1.1m
26.36
2.4m
85.75
4.8m
42.06
12.0m 332.80 12.5m
DIFUSCO
16.65 11.5m 23.45 48.1m 73.89
6.72h
41.12
26.6m
-
-
T2T
16.61 16.0m 23.30 54.6m
-
-
41.37
29.7m
-
-
LEHD + ReEvo
16.78
-
23.82
-
-
-
-
-
-
-
Greedy Refine (o3-mini) 17.37 19.1m 24.40 19.1m 77.65
2.5m
42.35
20.1m 354.00
2.5m
FunSearch (o3-mini)
17.20 19.1m 25.31 19.1m 80.18
2.5m
41.65
1.9m
356.50
2.1m
Table 2: Objective values and solving time of different solvers on TSP and MIS, with varying data sizes.
Figure 7: Percentage of algorithms developed by the Greedy
Refinement agent that rely on existing solvers (e.g., code
importing ortools, pulp) over 64 iteration steps. We ob-
serve an increasing use of existing solvers.
pulp). The percentages are shown across 64 iteration steps.
We observe an increasing trend in the use of existing solvers
in the agent’s solutions. After 64 iterations, the final usage
rate reaches 25% (i.e., solutions for 9 problems use existing
solvers). The solvers used throughout all steps and problems
are limited to three: ortools, pulp, and scipy.
This suggests that while existing LLM agents are capa-
ble of developing algorithms without relying on existing
solvers for most problems, there is a growing tendency to do
so over time. Moreover, the solvers used are basic general-
purpose tools rather than state-of-the-art solvers specifically
designed for each problem (e.g., LKH for TSP), indicating
that the agent lacks the necessary knowledge to select the
best-performing solver.
Related Work
Automatic Algorithm Search for CO
Automating algorithm search for combinatorial optimiza-
tion (CO) has emerged as a significant research direction
in the machine learning community. Traditional machine
learning solvers primarily parameterize CO algorithms as
trainable neural networks (Bengio, Lodi, and Prouvost 2020;
Cappart et al. 2023). Although effective in capturing data
distributions, these neural approaches often struggle to gener-
ate feasible solutions, necessitating integration with human-
designed heuristics such as branch-and-bound (Gasse et al.
2019) and tree search (Böther et al. 2022). To address this
limitation, Kuang et al. (2024a,b) propose to decompose CO
algorithms into symbolic operators and conduct searches in
the symbolic space. However, designing these unit symbolic
operators demands substantial human expertise, limiting gen-
eralizability and comprehensive coverage of all algorithm
types. Recent advances in Large Language Models (LLMs)
and LLM-based agents have significantly mitigated this chal-
lenge by enabling symbolic searching in programming lan-
guage formats (Romera-Paredes et al. 2023; Ye et al. 2024;
Liu et al. 2024). Building on these developments, CO-Bench
aims to extend the success of these methods to more real-
world CO problems and facilitate further research in this
domain.
CO Benchmarks for LLMs
Existing CO benchmarks can be roughly classified into
two categories. The first type formulates CO problems as
question-answering tasks (Fan et al. 2024; Tang et al. 2025).
Although LLMs have the potential to solve CO problems
via natural language reasoning, their excessive parameter
size makes them inefficient CO solvers in general. Therefore,
the second type of benchmarks evaluates the tool-using abil-
ity of LLMs, e.g., calling an existing CO solver, to address
CO problems (Xiao et al. 2024b; Ahmaditeshnizi, Gao, and
Udell 2024; Yang et al. 2025b). However, these benchmarks
only evaluate the correctness of the generated algorithm on
small-scale CO problems, whose problem parameters could
be fully expressed in natural language. In contrast, CO-Bench
targets scientific and industrial challenges, emphasizing the
evaluation of algorithm efficiency on diverse, large-scale CO
instances. This results in a more demanding benchmark, well-
suited for assessing powerful reasoning models and agents.
Conclusion
This work introduces CO-Bench, the first benchmark de-
signed to evaluate the ability of LLMs in the search of combi-
natorial optimization (CO) algorithms. Our systematic evalu-
ation reveals that reasoning-focused LLMs, especially when
paired with agentic frameworks, can automatically discover
effective algorithms that rival or surpass the classical solvers
designed by human experts, with competitive searching time.
However, we also identify key limitations of current LLM


--- Page 8 ---
agents such as they struggle to understand the problem con-
straints. These shortcomings highlight the need for future
research to enhance agents’ problem comprehension and cre-
ative reasoning abilities in CO tasks, enabling more robust
and autonomous scientific discovery.
References
Ahmaditeshnizi, A.; Gao, W.; and Udell, M. 2024. Opti-
MUS: Scalable Optimization Modeling with (MI)LP Solvers
and Large Language Models. In Salakhutdinov, R.; Kolter,
Z.; Heller, K.; Weller, A.; Oliver, N.; Scarlett, J.; and
Berkenkamp, F., eds., Proceedings of the 41st International
Conference on Machine Learning, volume 235 of Proceed-
ings of Machine Learning Research, 577–596. PMLR.
and, J. E. B. 1990. Linear Programming on Cray Supercom-
puters. Journal of the Operational Research Society, 41(2):
133–139.
Anken, F.; and Beasley, J. E. 2012. Corporate structure opti-
misation for multinational companies. Omega-international
Journal of Management Science, 40: 230–243.
Anthropic. 2025. Claude Sonnet. https://www.anthropic.
com/claude/sonnet. Accessed: 2025-03-24.
Beasley, J. E. 1985a. An algorithm for the two-dimensional
assortment problem. European Journal of Operational Re-
search, 19: 253–261.
Beasley, J. E. 1985b. Algorithms for Unconstrained Two-
Dimensional Guillotine Cutting. Journal of the Operational
Research Society, 36: 297–306.
Beasley, J. E. 1985c.
An Exact Two-Dimensional Non-
Guillotine Cutting Tree Search Procedure. Oper. Res., 33:
49–64.
Beasley, J. E. 1985d. A note on solving large p-median
problems. European Journal of Operational Research, 21:
270–273.
Beasley, J. E. 1988. An algorithm for solving large capac-
itated warehouse location problems. European Journal of
Operational Research, 33: 314–325.
Beasley, J. E. 1990. OR-Library: Distributing Test Problems
by Electronic Mail. Journal of the Operational Research
Society, 41: 1069–1072.
Beasley, J. E. 1992. A heuristic for Euclidean and recti-
linear Steiner problems. European Journal of Operational
Research, 58: 284–292.
Beasley, J. E. 1993. Lagrangean heuristics for location prob-
lems. European Journal of Operational Research, 65: 383–
399.
Beasley, J. E. 2004. A population heuristic for constrained
two-dimensional non-guillotine cutting. Eur. J. Oper. Res.,
156: 601–627.
Beasley, J. E.; and Cao, B. 1996. A tree search algorithm for
the crew scheduling problem. European Journal of Opera-
tional Research, 94: 517–526.
Beasley, J. E.; and Christofides, N. 1989. An algorithm for
the resource constrained shortest path problem. Networks,
19: 379–394.
Beasley, J. E.; and Jörnsten, K. 1992. Enhancing an algorithm
for set covering problems. European Journal of Operational
Research, 58: 293–300.
Beasley, J. E.; Krishnamoorthy, M.; Sharaiha, Y. M.; and
Abramson, D. 2000. Scheduling Aircraft Landings - The
Static Case. Transp. Sci., 34: 180–197.
Beasley, J. E.; Krishnamoorthy, M.; Sharaiha, Y. M.; and
Abramson, D. 2004. Displacement problem and dynamically
scheduling aircraft landings. Journal of the Operational
Research Society, 55: 54–64.
Bengio, Y.; Lodi, A.; and Prouvost, A. 2020. Machine Learn-
ing for Combinatorial Optimization: a Methodological Tour
d’Horizon. arXiv:1811.06128.
Berthold, T. 2006. Primal heuristics for mixed integer pro-
grams. Ph.D. thesis, Zuse Institute Berlin (ZIB).
Bischoff, E. E. 2006. Three-dimensional packing of items
with limited load bearing strength. Eur. J. Oper. Res., 168:
952–966.
Bischoff, E. E.; and Ratcliff, M. S. W. 1995. Issues in the
development of approaches to container loading. Omega-
international Journal of Management Science, 23: 377–390.
Biskup, D.; and Feldmann, M. 2001. Benchmarks for schedul-
ing on a single machine against restrictive and unrestrictive
common due dates. Comput. Oper. Res., 28: 787–801.
Böther, M.; Kißig, O.; Taraz, M.; Cohen, S.; Seidel, K.; and
Friedrich, T. 2022. What’s Wrong with Deep Learning in
Tree Search for Combinatorial Optimization. In International
Conference on Learning Representations.
Cappanera, P.; and Trubian, M. 2001. A Local-Search-Based
Heuristic for the Demand-Constrained Multidimensional
Knapsack Problem. INFORMS J. Comput., 17: 82–98.
Cappart, Q.; ChÃ©telat, D.; Khalil, E. B.; Lodi, A.; Morris,
C.; and VeliÄkoviÄ‡, P. 2023. Combinatorial Optimization
and Reasoning with Graph Neural Networks. Journal of
Machine Learning Research, 24(130): 1–61.
Chakhlevitch, K.; and Glass, C. A. 2009. Scheduling reen-
trant jobs on parallel machines with a remote server. Comput.
Oper. Res., 36: 2580–2589.
Chan, J. S.; Chowdhury, N.; Jaffe, O.; Aung, J.; Sherburn, D.;
Mays, E.; Starace, G.; Liu, K.; Maksin, L.; Patwardhan, T. A.;
Weng, L.; and Mkadry, A. 2024. MLE-bench: Evaluating
Machine Learning Agents on Machine Learning Engineering.
ArXiv, abs/2410.07095.
Chen, M.; Tworek, J.; Jun, H.; Yuan, Q.; Pondé, H.; Kaplan,
J.; Edwards, H.; Burda, Y.; Joseph, N.; Brockman, G.; Ray,
A.; Puri, R.; Krueger, G.; Petrov, M.; Khlaaf, H.; Sastry, G.;
Mishkin, P.; Chan, B.; Gray, S.; Ryder, N.; Pavlov, M.; Power,
A.; Kaiser, L.; Bavarian, M.; Winter, C.; Tillet, P.; Such, F. P.;
Cummings, D. W.; Plappert, M.; Chantzis, F.; Barnes, E.;
Herbert-Voss, A.; Guss, W. H.; Nichol, A.; Babuschkin, I.;
Balaji, S.; Jain, S.; Carr, A.; Leike, J.; Achiam, J.; Misra, V.;
Morikawa, E.; Radford, A.; Knight, M. M.; Brundage, M.;
Murati, M.; Mayer, K.; Welinder, P.; McGrew, B.; Amodei,
D.; McCandlish, S.; Sutskever, I.; and Zaremba, W. 2021.
Evaluating Large Language Models Trained on Code. ArXiv,
abs/2107.03374.


--- Page 9 ---
Christofides, N.; and Beasley, J. E. 1984. The period routing
problem. Networks, 14: 237–256.
Christofides, N.; and Whitlock, C. 1977. An Algorithm for
Two-Dimensional Cutting Problems. Oper. Res., 25: 30–44.
Chu, P. C.; and Beasley, J. E. 1998. Constraint Handling in
Genetic Algorithms: The Set Partitioning Problem. Journal
of Heuristics, 4: 323–357.
Crama, Y. 1997. Combinatorial optimization models for
production scheduling in automated manufacturing systems.
European Journal of Operational Research, 99(1): 136–153.
DeepMind, G. 2025. Flash Thinking: Behind the Scenes of
Gemini. https://deepmind.google/technologies/gemini/flash-
thinking/. Accessed: 2025-03-24.
DeepSeek-AI. 2024. DeepSeek-V3 Technical Report. ArXiv,
abs/2412.19437.
DeepSeek-AI. 2025a.
DeepSeek-R1: Incentivizing Rea-
soning Capability in LLMs via Reinforcement Learning.
arXiv:2501.12948.
DeepSeek-AI. 2025b. DeepSeek-R1: Incentivizing Reason-
ing Capability in LLMs via Reinforcement Learning. ArXiv,
abs/2501.12948.
Erdos, P. L.; and Rényi, A. 1984. On the evolution of random
graphs. Transactions of the American Mathematical Society,
286: 257–257.
Falkenauer, E. 1996. A hybrid grouping genetic algorithm
for bin packing. Journal of Heuristics, 2: 5–30.
Fan, L.; Hua, W.; Li, L.; Ling, H.; and Zhang, Y. 2024.
NPHardEval: Dynamic Benchmark on Reasoning Ability
of Large Language Models via Complexity Classes. In Ku,
L.-W.; Martins, A.; and Srikumar, V., eds., Proceedings of the
62nd Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), 4092–4114. Bangkok,
Thailand: Association for Computational Linguistics.
Fleurent, C.; and Ferland, J. A. 1996. Genetic and hybrid al-
gorithms for graph coloring. Annals of Operations Research,
63: 437–461.
Gasse, M.; Chételat, D.; Ferroni, N.; Charlin, L.; and Lodi,
A. 2019. Exact Combinatorial Optimization with Graph
Convolutional Neural Networks.
In Advances in Neural
Information Processing Systems 32.
Gottweis, J.; Weng, W.-H.; Daryin, A.; Tu, T.; Palepu, A.;
Sirkovic, P.; Myaskovsky, A.; Weissenberger, F.; Rong, K.;
Tanno, R.; Saab, K.; Popovici, D.; Blum, J.; Zhang, F.; Chou,
K.; Hassidim, A.; Gokturk, B.; Vahdat, A.; Kohli, P.; Matias,
Y.; Carroll, A.; Kulkarni, K.; Tomaev, N.; Guan, Y.; Dhillon,
V.; Vaishnav, E. D.; Lee, B.; Costa, T. R. D.; Penad’es, J. R.;
Peltz, G.; Xu, Y.; Pawlosky, A.; Karthikesalingam, A.; and
Natarajan, V. 2025.
Towards an AI co-scientist.
ArXiv,
abs/2502.18864.
Gusfield, D. 1997. Algorithms on stings, trees, and sequences:
Computer science and computational biology. Acm Sigact
News, 28(4): 41–60.
Hui, B.; Yang, J.; Cui, Z.; Yang, J.; Liu, D.; Zhang, L.; Liu,
T.; Zhang, J.; Yu, B.; Dang, K.; Yang, A.; Men, R.; Huang,
F.; Quan, S.; Ren, X.; Ren, X.; Zhou, J.; and Lin, J. 2024.
Qwen2.5-Coder Technical Report. ArXiv, abs/2409.12186.
Ivancic, N. J. 1988. An integer programming based heuristic
approach to the three dimensional packing problem.
Jiang, Z.; Schmidt, D.; Srikanth, D.; Xu, D.; Kaplan, I.; Ja-
cenko, D.; and Wu, Y. 2025. AIDE: AI-Driven Exploration
in the Space of Code. ArXiv, abs/2502.13138.
Jimenez, C. E.; Yang, J.; Wettig, A.; Yao, S.; Pei, K.; Press,
O.; and Narasimhan, K. 2023.
SWE-bench: Can Lan-
guage Models Resolve Real-World GitHub Issues? ArXiv,
abs/2310.06770.
Kuang, Y.; Wang, J.; Liu, H.; Zhu, F.; Li, X.; Zeng, J.; HAO,
J.; Li, B.; and Wu, F. 2024a. Rethinking Branching on Exact
Combinatorial Optimization Solver: The First Deep Sym-
bolic Discovery Framework. In The Twelfth International
Conference on Learning Representations.
Kuang, Y.; Wang, J.; Zhou, Y.; Li, X.; Zhu, F.; Hao, J.; and
Wu, F. 2024b. Towards General Algorithm Discovery for
Combinatorial Optimization: Learning Symbolic Branch-
ing Policy from Bipartite Graph.
In Salakhutdinov, R.;
Kolter, Z.; Heller, K.; Weller, A.; Oliver, N.; Scarlett, J.; and
Berkenkamp, F., eds., Proceedings of the 41st International
Conference on Machine Learning, volume 235 of Proceed-
ings of Machine Learning Research, 25623–25641. PMLR.
Laporte, G. 1992.
The traveling salesman problem: An
overview of exact and approximate algorithms. European
Journal of Operational Research, 59(2): 231–247.
Li, Y.; Guo, J.; Wang, R.; and Yan, J. 2023. From Distribution
Learning in Training to Gradient Search in Testing for Com-
binatorial Optimization. In Neural Information Processing
Systems.
Liu, F.; Tong, X.; Yuan, M.; Lin, X.; Luo, F.; Wang, Z.; Lu,
Z.; and Zhang, Q. 2024. Evolution of Heuristics: Towards Ef-
ficient Automatic Algorithm Design Using Large Language
Model. In ICML.
López, C. O.; and Beasley, J. E. 2016. A formulation space
search heuristic for packing unequal circles in a fixed size
circular container. Eur. J. Oper. Res., 251: 64–73.
López, C. O.; and Beasley, J. E. 2018. Packing unequal
rectangles and squares in a fixed size circular container using
formulation space search. Comput. Oper. Res., 94: 106–117.
Madaan, A.; Tandon, N.; Gupta, P.; Hallinan, S.; Gao, L.;
Wiegreffe, S.; Alon, U.; Dziri, N.; Prabhumoye, S.; Yang, Y.;
Welleck, S.; Majumder, B. P.; Gupta, S.; Yazdanbakhsh, A.;
and Clark, P. 2023. Self-Refine: Iterative Refinement with
Self-Feedback. ArXiv, abs/2303.17651.
Meta. 2024.
The Llama 3 Herd of Models.
ArXiv,
abs/2407.21783.
Mingers, J. C.; and O’Brien, F. A. 1995. Creating student
groups with similar characteristics: A heuristic approach.
Omega-international Journal of Management Science, 23:
313–321.
Motwani, R.; and Raghavan, P. 2013.
Randomized Al-
gorithms.
USA: Cambridge University Press.
ISBN
0511814070.
Novikov, A.; V~u, N.; Eisenberger, M.; Dupont, E.; Huang,
P.-S.; Wagner, A. Z.; Shirobokov, S.; Kozlovskii, B. M.; Ruiz,
F. J. R.; Mehrabian, A.; Kumar, M. P.; See, A.; Chaudhuri, S.;


--- Page 10 ---
Holland, G.; Davies, A.; Nowozin, S.; Kohli, P.; Balog, M.;
and Deepmind, G. 2025. AlphaEvolve: A coding agent for
scientific and algorithmic discovery. ArXiv, abs/2506.13131.
OpenAI. 2024a.
GPT-4o System Card.
ArXiv,
abs/2410.21276.
OpenAI. 2024b. OpenAI o1 System Card. arXiv:2412.16720.
OpenAI. 2025. OpenAI o3-mini System Card.
Osman, I. H. 1995. Heuristics for the generalised assignment
problem: simulated annealing and tabu search approaches.
Operations-Research-Spektrum, 17: 211–225.
Osman, I. H.; and Christofides, N. 1994. Capacitated cluster-
ing problems by hybrid simulated annealing and tabu search.
International Transactions in Operational Research, 1: 317–
336.
Papadimitriou, C.; and Steiglitz, K. 1982. Combinatorial Op-
timization: Algorithms and Complexity, volume 32. Courier
Corporation. ISBN 0-13-152462-3.
Petersen, C. C. 1967. Computational Experience with Vari-
ants of the Balas Algorithm Applied to the Selection of R&D
Projects. Management Science, 13: 736–750.
Qiu, R.; Sun, Z.; and Yang, Y. 2022. DIMES: A Differentiable
Meta Solver for Combinatorial Optimization Problems. In
Oh, A. H.; Agarwal, A.; Belgrave, D.; and Cho, K., eds.,
Advances in Neural Information Processing Systems.
Qwen. 2025. QwQ-32B: Embracing the Power of Reinforce-
ment Learning. https://qwenlm.github.io/blog/qwq-32b/. Ac-
cessed: 2025-03-24.
Ramamonjison, R.; Yu, T. T.; Li, R.; Li, H.; Carenini,
G.; Ghaddar, B.; He, S.; Mostajabdaveh, M.; Banitalebi-
Dehkordi, A.; Zhou, Z.; and Zhang, Y. 2023. NL4Opt Com-
petition: Formulating Optimization Problems Based on Their
Natural Language Descriptions. In Neural Information Pro-
cessing Systems.
Ratcliff, M. S. W.; and Bischoff, E. E. 1998.
Allowing
for weight considerations in container loading. Operations-
Research-Spektrum, 20: 65–71.
Romera-Paredes, B.; Barekatain, M.; Novikov, A.; Balog,
M.; Kumar, M. P.; Dupont, E.; Ruiz, F. J. R.; Ellenberg, J. S.;
Wang, P.; Fawzi, O.; Kohli, P.; Fawzi, A.; Grochow, J.; Lodi,
A.; Mouret, J.-B.; Ringer, T.; and Yu, T. 2023. Mathematical
discoveries from program search with large language models.
Nature, 625: 468 – 475.
Shinn,
N.;
Cassano,
F.;
Labash,
B.;
Gopinath,
A.;
Narasimhan, K.; and Yao, S. 2023. Reflexion: language
agents with verbal reinforcement learning. In Neural Infor-
mation Processing Systems.
Sun, Z.; and Yang, Y. 2023.
DIFUSCO: Graph-based
Diffusion Solvers for Combinatorial Optimization. ArXiv,
abs/2302.08224.
Taillard, E. 1993. Benchmarks for basic scheduling problems.
European Journal of Operational Research, 64(2): 278–285.
Tang, J.; Zhang, Q.; Li, Y.; Chen, N.; and Li, J. 2025.
GraphArena: Evaluating and Improving Large Language
Models on Graph Computation. In International Confer-
ence on Learning Representations.
Vogiatzis, C.; and Pardalos, P. 2013. Combinatorial opti-
mization in transportation and logistics networks, volume
2-5, 673–722. Germany: Springer. ISBN 9781441979964.
Publisher Copyright: © Springer Science+Business Media
New York 2013. All rights are reserved.
xAI. 2025. Grok-3 and the Next Phase of xAI. https://x.ai/
news/grok-3. Accessed: 2025-03-24.
Xiao, Z.; Zhang, D.; Wu, Y.; Xu, L.; Wang, Y. J.; Han, X.;
Fu, X.; Zhong, T.; Zeng, J.; Song, M.; and Chen, G. 2024a.
Chain-of-Experts: When LLMs Meet Complex Operations
Research Problems. In International Conference on Learning
Representations.
Xiao, Z.; Zhang, D.; Wu, Y.; Xu, L.; Wang, Y. J.; Han, X.;
Fu, X.; Zhong, T.; Zeng, J.; Song, M.; and Chen, G. 2024b.
Chain-of-Experts: When LLMs Meet Complex Operations
Research Problems. In The Twelfth International Conference
on Learning Representations.
Yang, Z.; Wang, Y.; Huang, Y.; Guo, Z.; Shi, W.; Han, X.;
Feng, L.; Song, L.; Liang, X.; and Tang, J. 2025a. OptiBench
Meets ReSocratic: Measure and Improve LLMs for Optimiza-
tion Modeling. In The Thirteenth International Conference
on Learning Representations.
Yang, Z.; Wang, Y.; Huang, Y.; Guo, Z.; Shi, W.; Han, X.;
Feng, L.; Song, L.; Liang, X.; and Tang, J. 2025b. OptiBench
Meets ReSocratic: Measure and Improve LLMs for Optimiza-
tion Modeling. In The Thirteenth International Conference
on Learning Representations.
Yao, S.; Zhao, J.; Yu, D.; Du, N.; Shafran, I.; Narasimhan,
K.; and Cao, Y. 2022. ReAct: Synergizing Reasoning and
Acting in Language Models. ArXiv, abs/2210.03629.
Ye, H.; Wang, J.; Cao, Z.; Berto, F.; Hua, C.; Kim, H.; Park,
J.; and Song, G. 2024. ReEvo: Large Language Models as
Hyper-Heuristics with Reflective Evolution. In The Thirty-
eighth Annual Conference on Neural Information Processing
Systems.
Zheng, Z.; Xie, Z.; Wang, Z.; and Hooi, B. 2025. Monte Carlo
Tree Search for Comprehensive Exploration in LLM-Based
Automatic Heuristic Design. ArXiv, abs/2501.08603.


--- Page 11 ---
Problem Description and Scores
Aircraft landing
The problem is to schedule landing times for a set of planes
across one or more runways such that each landing occurs
within its prescribed time window and all pairwise separation
requirements are satisfied; specifically, if plane i lands at or
before plane j on the same runway, then the gap between
their landing times must be at least the specified separation
time provided in the input. In a multiple-runway setting, each
plane must also be assigned to one runway, and if planes
land on different runways, the separation requirement (which
may differ) is applied accordingly. Each plane has an earliest,
target, and latest landing time, with penalties incurred pro-
portionally for landing before (earliness) or after (lateness)
its target time. The objective is to minimize the total penalty
cost while ensuring that no constraints are violated—if any
constraint is breached, the solution receives no score.
Method
Score
Classical Solver
0.5985295365478638
BestOfN
0.8057479826999232
Refine
0.7503157815146175
FunSearch
0.9688863336568327
AIDE
0.800637046201484
ReEvo
0.9134454710810906
MCTS
0.801655240273729
EoH
0.8019818529389835
Table 3: Aircraft landing
Assignment problem
The Assignment Problem involves optimally assigning n
items to n agents based on a provided n imes n cost matrix,
where each entry extcost_matrix[i][j] denotes the cost of
assigning item i+1 to agent j+1 . The goal is to identify a
permutation—each item assigned exactly one agent—that
minimizes the total assignment cost. Formally, this is an opti-
mization problem to find a permutation π of agents such that
the total cost P i = 1nextcost_matrix[i −1][π(i) −1] is
minimized. The solution returned includes both the minimal
total cost and the corresponding optimal assignments.
Method
Score
Classical Solver
1
BestOfN
1
Refine
1
FunSearch
1
AIDE
1
ReEvo
1
MCTS
1
EoH
1
Table 4: Assignment problem
Assortment problem
This optimization problem involves arranging a set of rect-
angular pieces within available stock rectangles to minimize
the overall waste area percentage. Each stock rectangle has
a defined area, and each piece—which may be rotated by
90°—must be fully contained within a stock without over-
lapping with other pieces. Additionally, each piece type has
specific total minimum and maximum placement limits. You
have access to an unlimited number of stocks for each type,
but you may use at most two stock types. The objective is to
achieve the lowest possible waste area percentage, defined
as the ratio of unused area to the total stock area. Solutions
must ensure efficient resource utilization while satisfying all
geometric and quantity constraints. Any violation of these
constraints results in no score.
Method
Score
Classical Solver
0.3222852468406736
BestOfN
0.36161788534475603
Refine
0.10475936163370339
FunSearch
0.3622886282031154
AIDE
0.1698107561339298
ReEvo
0.24290833308629933
MCTS
0.1757439194813797
EoH
0.2519474328966603
Table 5: Assortment problem
Bin packing - one-dimensional
The **one-dimensional bin packing problem** seeks to min-
imize the number of bins required to pack a given set of
items while ensuring that the sum of item sizes within each
bin does not exceed the specified bin capacity. Given a test
case with an identifier (‘id‘), a fixed ‘bin_capacity‘, and a
list of ‘num_items‘ with their respective sizes (‘items‘), the
objective is to find a packing arrangement that uses the least
number of bins. The solution is evaluated based on the to-
tal ‘num_bins‘ used, with invalid solutions (e.g., missing or
duplicated items, or bins exceeding capacity) incurring a inf
heavy penalty. The output must include the number of bins
used and a valid assignment of item indices to bins.
Method
Score
Classical Solver
0.9628049317089281
BestOfN
0.8933315064694979
Refine
0.9870315022407082
FunSearch
0.9557154223933677
AIDE
0.8366913237780297
ReEvo
0.9492158360156572
MCTS
0.9396436307329097
EoH
0.9693475618912389
Table 6: Bin packing - one-dimensional


--- Page 12 ---
Capacitated warehouse location
The Capacitated Warehouse Location Problem with Split-
table Demand aims to determine which warehouses to open
and how to allocate portions of customer demands among
these warehouses in order to minimize total costs. Given a set
of potential warehouse locations, each with a fixed opening
cost and capacity limit, and a set of customers with individual
demands and associated per-unit assignment costs to each
warehouse, the objective is to decide which warehouses to
open and how to distribute each customer’s demand among
these open warehouses. The allocation must satisfy the con-
straint that the sum of portions assigned to each customer
equals their total demand, and that the total demand allocated
to any warehouse does not exceed its capacity. The optimiza-
tion seeks to minimize the sum of fixed warehouse opening
costs and the total per-unit assignment costs. However, if any
solution violates these constraints (i.e., a customer’s demand
is not fully satisfied or a warehouse’s capacity is exceeded),
then no score is provided.
Method
Score
Classical Solver
0.6976400141361688
BestOfN
0.0
Refine
0.7518838886310322
FunSearch
0.7196713948459038
AIDE
0.6647355906610447
ReEvo
0.6715266955394039
MCTS
0.6891495773105485
EoH
0.7502493181324346
Table 7: Capacitated warehouse location
Common due date scheduling
Given floor, where h is a predefined fraction (defaulting to
0.6). The goal is to determine an optimal job sequence that
minimizes the penalty, calculated as follows: for each job, if
its completion time C is earlier than d, an earliness penalty
of aimes(d −C) is incurred; if C exceeds d, a tardiness
penalty of bimes(C −d) is applied; otherwise, no penalty
is incurred. The problem requires finding a permutation of
job indices (1-based) that minimizes the total penalty. The
evaluation metric sums these penalties for a given schedule.
Method
Score
Classical Solver
0.9187662046144239
BestOfN
0.97731110557282
Refine
0.9776844987221935
FunSearch
0.976604327923604
AIDE
0.6291657473867996
ReEvo
0.9743199070415761
MCTS
0.8838457578182489
EoH
0.9773286503168127
Table 8: Common due date scheduling
Constrained guillotine cutting
The problem involves optimizing the guillotine feasibl place-
ment of a set of rectangular pieces on a given stock sheet
to maximize total value. Each piece type is characterized by
its length, width, an upper bound on the number of times it
may appear in the final cutting pattern, and an assigned value.
Orientation of the pieces is fixed (the edges of the pieces
are parallel to the edges of the sheet). The task is to select
and place pieces such that each lies completely within the
boundaries of the stock sheet, no two pieces overlap, and
the number of pieces of any type does not exceed its speci-
fied maximum. A set of placements is considered guillotine
feasible if there exists at least one straight cut (vertical or
horizontal) that does not slice through any rectangle, and
the property holds recursively on the resulting subregions.
Empty regions or regions exactly matching a placed piece
are considered valid.The objective is to maximize the sum
of the values of the placed pieces; however, if any spatial or
count constraint is violated, the solution is deemed invalid.
The output is defined as a dictionary reporting the total value
and a list of placements, with each placement specified by
the piece type index, x and y coordinates, placed dimensions,
and orientation flag.
Method
Score
Classical Solver
0.7844900098230463
BestOfN
0.0
Refine
0.981513704843915
FunSearch
0.956424099109148
AIDE
0.9102922923098641
ReEvo
0.0
MCTS
0.0
EoH
0.0
Table 9: Constrained guillotine cutting
Constrained non-guillotine cutting
The constrained non-guillotine cutting problem involves opti-
mally arranging rectangular pieces onto a single rectangular
stock with fixed dimensions (stock_length and stock_width).
Each piece type has defined length, width, value, and mini-
mum and maximum usage constraints. The optimization goal
is to maximize the total value of all placed pieces, subject to
constraints that each piece is entirely within stock boundaries,
pieces do not overlap, each piece type’s usage falls within
its specified [min, max] range, and pieces may optionally be
rotated by 90°. The solution returns a set of placements indi-
cating piece type, bottom-left coordinates (x, y), and rotation
status. If any constraint is violated, the solution receives no
score.
Container loading
Solves a container loading problem: Given a 3D container
of specified dimensions and multiple box types—each de-
fined by dimensions, orientation constraints, and available
quantity—the goal is to optimally place these boxes within


--- Page 13 ---
Method
Score
Classical Solver
0.5585076432266227
BestOfN
0.8760613343780126
Refine
0.99138085452391
FunSearch
0.9623447685846964
AIDE
0.8555320134962818
ReEvo
0.9264764236682984
MCTS
0.7944732650186651
EoH
0.9106930512513293
Table 10: Constrained non-guillotine cutting
the container to maximize the volume utilization ratio. Each
box placement must respect orientation constraints (vertical
alignment flags), fit entirely within container boundaries, and
avoid overlaps. The solution returns precise coordinates and
orientations for each box placement, quantified by a volume
utilization score calculated as the total volume of placed
boxes divided by the container volume. Invalid placements
result in a score of 0.0.
Method
Score
Classical Solver
0.09700224776623062
BestOfN
0.8163545342051534
Refine
0.18895711345505883
FunSearch
0.23070987019597894
AIDE
0.7592850816892841
ReEvo
0.716081346719743
MCTS
0.5451472798828618
EoH
0.7795824394970114
Table 11: Container loading
Container loading with weight restrictions
The Container Loading with Weight Restrictions problem
aims to maximize the utilization of a container’s volume by
selecting and strategically placing boxes inside it. Given a
container with specified dimensions (length, width, height)
and multiple types of boxes, each characterized by their di-
mensions, quantities, weights, and load-bearing constraints,
the optimization goal is to determine the placement and ori-
entation of these boxes (with each box allowed three possible
orientations) that maximizes the ratio of total occupied box
volume to container volume. The solution must strictly ad-
here to spatial constraints (boxes must fit entirely within
the container without overlapping), load-bearing constraints
(boxes must support the weight of boxes stacked above them
according to given limits), and orientation restrictions. The
optimization quality is evaluated by the achieved utilization
metric, defined as the total volume of successfully placed
boxes divided by the container volume; if any constraint is
violated, the utilization score is zero.
Method
Score
Classical Solver
0.009225308452359507
BestOfN
0.13669723873453465
Refine
0.07941319051933145
FunSearch
0.2919729304847129
AIDE
0.12860429344072807
ReEvo
0.1420943670465572
MCTS
0.04806324649022297
EoH
0.051972410039456414
Table 12: Container loading with weight restrictions
Corporate structuring
Given N countries, each defined by: • a tax code (1: Exemp-
tion, 2: Deduction, 3: Source-by-source Pooling, 4: World-
wide Pooling), • a foreign income tax rate, • a domestic
income tax rate, and • a profit, and a withholding tax matrix
W (where W[i][j] is the rate on dividends from country i
to j), construct a valid tree-structured corporate hierarchy
(directed, acyclic, connected) rooted at a designated target
(whose parent is 0) such that every country with profit > 0
appears exactly once.
For each country i, define S as the set of nodes in its
subtree (note the subtree includes itself) with a positive
profit. Also consider the set of child nodes C_i. If i is
not a root country but in the tree, it will send all its in-
come (after tax) to its parent j. Denote this amount as
F[i][j]. Assume the total income after domestic tax and
withholding tax for country i is: domesticincomei ∗(1 −
domesticratei)+(P
k∈Ci F[k][i]∗(1−W[k][i])) The extra
foreign tax under different tax code is defined as follows: 1.
No extra tax. 2. Foreign income tax from the child nodes:
foreignincomeratei ∗(P
k∈Ci F[k][i] ∗(1 −W[k][i])) 3.
Foreign income tax computed from the source nodes in each
child’s subtree: P
k∈Ci max(0, F[k][i] ∗(1 −W[k][i]) −
(1 −foreignincomeratei) ∗(P
s∈Sk domesticincomes))
4. Foreign income tax from all source nodes in the subtree,
excluding itself: max(0, P
k∈Ci F[k][i] ∗(1 −W[k][i]) −
(1−foreignincomeratei)∗((P
s∈Si domesticincomes)−
domesticincomei))
Method
Score
Classical Solver
0.9450572839481785
BestOfN
0.9450572839481785
Refine
0.9726337326585759
FunSearch
0.777775452943618
AIDE
0.9450572839481785
ReEvo
0.5014939649568603
MCTS
0.9844897288603699
EoH
0.9431107030735252
Table 13: Corporate structuring


--- Page 14 ---
Crew scheduling
The Crew Scheduling Problem involves assigning each
task—with defined start and finish times—to exactly one
crew, aiming to minimize the total transition costs between
consecutive tasks. Each crew’s schedule must satisfy three
constraints: tasks within a crew must not overlap; valid tran-
sitions (with associated costs) must exist between every con-
secutive pair of tasks; and the crew’s total duty time (from the
start of the first task to the finish of the last) cannot exceed a
specified time limit. Additionally, no more than K crews can
be used to cover all tasks. Solutions violating any of these
constraints are considered infeasible and receive no score.
The optimization objective is therefore to determine assign-
ments of tasks to no more than K crews that minimize the sum
of transition costs while strictly adhering to all constraints,
yielding a feasible and cost-effective scheduling solution.
Method
Score
Classical Solver
0.45498811952880935
BestOfN
0.4483461488661745
Refine
0.6690343590115082
FunSearch
0.5536756258756895
AIDE
0.44095505708697136
ReEvo
0.45225267224663634
MCTS
0.4446817469828879
EoH
0.5864457661923881
Table 14: Crew scheduling
Equitable partitioning problem
The task is to partition a set of individuals—each charac-
terized by multiple binary attributes—into exactly 8 groups
such that the distribution of attribute values is as balanced
as possible across these groups. For each attribute, count the
number of individuals with a ‘1’ in each group. The optimiza-
tion objective is to minimize the total imbalance, which is
defined as follows: for each attribute, calculate the absolute
differences between the count in each group and the mean
count across all groups, take the average of these differences,
and then sum these averages over all attributes. The goal
is to determine a group assignment for each individual that
achieves the lowest possible total imbalance score.
Method
Score
Classical Solver
1.0
BestOfN
1.0
Refine
1.0
FunSearch
1.0
AIDE
0.7777777777777778
ReEvo
0.7777777777777778
MCTS
1.0
EoH
1.0
Table 15: Equitable partitioning problem
Euclidean Steiner problem
Given a set of 2D points (terminals), the goal of the Eu-
clidean Steiner Problem is to compute a tree connecting all
terminals with minimum total length. The total length is
measured as the sum of Euclidean distances (where the Eu-
clidean distance between two points (x1, y1) and (x2, y2) is
sqrt((x1 −x2)2 + (y1 −y2)2)). Unlike a Minimum Span-
ning Tree (MST) computed solely on the given terminals, a
Steiner tree may introduce extra points, called Steiner points,
to reduce the overall length. In this formulation, it is as-
sumed that the final candidate tree’s total length is given
by the MST computed on the union of the original termi-
nals and the reported Steiner points. A lower ratio (candi-
date_tree_length/MST_original_length) indicates a better so-
lution.
Method
Score
Classical Solver
0.9779703480188361
BestOfN
0.6291391910535526
Refine
0.688025642110573
FunSearch
0.6968176110449371
AIDE
0.04483890014026932
ReEvo
0.5469067768233761
MCTS
0.43093954323065975
EoH
0.5917817000598826
Table 16: Euclidean Steiner problem
Flow shop scheduling
Given n jobs and m machines, the goal of the flow shop
scheduling problem is to determine the optimal job sequence
that minimizes the makespan, i.e., the total time required to
complete all jobs on all machines. Each job follows the same
machine order, and the processing times are specified in an
n imes m matrix. The output is a permutation of job indices
representing the processing order. If the constraints are not
satisfied (e.g., invalid job sequencing), the solution receives
no score. The objective is to optimize the makespan using
the classical flow shop recurrence.
Method
Score
Classical Solver
0.9222700445897257
BestOfN
0.874217493803887
Refine
0.8463439348165006
FunSearch
0.8537338049420798
AIDE
0.9144895115672386
ReEvo
0.8424667927400846
MCTS
0.9242143967817102
EoH
0.940154419652199
Table 17: Flow shop scheduling
Generalised assignment problem
Generalized Assignment Problem (GAP)


--- Page 15 ---
The Generalized Assignment Problem (GAP) involves as-
signing n jobs to m agents such that each job is assigned to
exactly one agent, and the resource consumption for each
agent does not exceed its capacity. The objective is to opti-
mize the total cost based on the problem type. When formu-
lated as a maximization problem, the goal is to maximize the
total cost; when formulated as a minimization problem, the
goal is to minimize the total cost. Given a cost matrix (repre-
senting the cost of assigning jobs to agents), a consumption
matrix (indicating the resource usage per assignment), and
capacities (the resource limits for each agent), the task is to
find a valid assignment that meets the capacity constraints
while optimizing the total cost as specified by the problem
indicator.
Method
Score
Classical Solver
1.000509368510793
BestOfN
1.000152715871272
Refine
0.9997973477884884
FunSearch
0.9360910283983461
AIDE
1.000152715871272
ReEvo
1.0002083856508814
MCTS
1.0001026538510593
EoH
0.9793902133221158
Table 18: Generalised assignment problem
Graph colouring
Given a graph in DIMACS format with vertices, edges, and
an adjacency list, the goal is to assign a positive integer color
(1..n) to each vertex while ensuring that no two adjacent
vertices share the same color. The objective is to minimize the
number of distinct colors used. If any two adjacent vertices
have the same color, the solution is invalid and receives no
score. Otherwise, the score is equal to the number of distinct
colors used, with a lower score being better.
Method
Score
Classical Solver
0.8679121232535366
BestOfN
0.7992347794550977
Refine
0.9237393162393163
FunSearch
0.8993461774953884
AIDE
0.7992347794550977
ReEvo
0.8119485901255648
MCTS
0.8529682767415909
EoH
0.804175457505431
Table 19: Graph colouring
Hybrid Reentrant Shop Scheduling
The problem is a Hybrid Reentrant Shop Scheduling problem
where each of n jobs must sequentially undergo three opera-
tions: an initialization phase on one of m identical primary
machines, a setup phase on a single remote server, and a final
main processing phase on the same primary machine used
for initialization. Jobs are initialized in a fixed natural order
using list scheduling, while the setup phase is processed on
the remote server in an order specified by a permutation deci-
sion variable. Additionally, each job is assigned to a primary
machine for main processing via a batch_assignment, and on
each machine, jobs are processed in natural (initialization)
order. The objective is to minimize the makespan, defined
as the time when the last job completes its main processing,
while ensuring that no machine (primary or server) processes
more than one job simultaneously and that all operational
precedence constraints are satisfied.
Method
Score
Classical Solver
0.9057971372430776
BestOfN
0.9872450518587456
Refine
0.9966666343001128
FunSearch
1.0001780484032463
AIDE
0.7457203947696327
ReEvo
0.9820554515396009
MCTS
0.9961239866411462
EoH
0.9841146688046011
Table 20: Hybrid Reentrant Shop Scheduling
Job shop scheduling
The job shop scheduling problem requires assigning non-
negative integer start times to a set of operations, structured
into multiple jobs, each composed of sequential operations.
Each operation is processed on a specific machine for a given
processing time. The optimization goal is to minimize the
makespan, defined as the maximum completion time across
all jobs. Constraints include (i) sequential processing of op-
erations within each job, meaning each operation cannot
start before its preceding operation finishes, and (ii) non-
overlapping scheduling of operations on the same machine.
If these constraints are violated, the solution receives no score.
Method
Score
Classical Solver
0.8202016779421567
BestOfN
0.7060712883377539
Refine
0.7696287350855926
FunSearch
0.8192815531664928
AIDE
0.6498336005961379
ReEvo
0.7982807066317813
MCTS
0.7293663754433233
EoH
0.7770594374788831
Table 21: Job shop scheduling
MIS
The Maximum Independent Set (MIS) problem is a funda-
mental NP-hard optimization problem in graph theory. Given
an undirected graph G = (V, E), where V is a set of vertices


--- Page 16 ---
and E is a set of edges, the goal is to find the largest sub-
set S in V such that no two vertices in S are adjacent (i.e.,
connected by an edge).
Method
Score
Classical Solver
0.986
BestOfN
0.8461150261004076
Refine
0.9078324503859446
FunSearch
0.9002038932676987
AIDE
0.8425484500134511
ReEvo
0.8342509729450779
MCTS
0.8433127163177989
EoH
0.8763795109859694
Table 22: MIS
Multi-Demand Multidimensional Knapsack
problem
The Multi-Demand Multidimensional Knapsack Problem
(MDMKP) is a binary optimization problem that extends the
classical MKP by incorporating both upper-bound (<=) and
lower-bound (>=) constraints. Formally, given n decision vari-
ables xj ∈{0, 1}, the goal is to maximize Pn
j=1 cjxj sub-
ject toPn
j=1 aijxj ≤bifori = 1, . . . , m and Pn
j=1 aijxj ≥
bifori = m + 1, . . . , m + q. Instances are generated from
standard MKP problems by varying the number of >= con-
straints (with q taking values 1, m/2, or m) and by using
two types of cost coefficients (positive and mixed), thereby
producing six distinct variants per base instance. This formu-
lation enables rigorous evaluation of algorithms in contexts
where both resource limits and demand fulfillment must be
simultaneously addressed.
Method
Score
Classical Solver
0.8957822313136857
BestOfN
0.7144432351611377
Refine
0.8913402342031996
FunSearch
0.8354799525874899
AIDE
0.8805432369541204
ReEvo
0.8920786376031828
MCTS
0.8994648109682947
EoH
0.9082814870567889
Table 23: Multi-Demand Multidimensional Knapsack prob-
lem
Multidimensional knapsack problem
This problem is a multidimensional knapsack optimization
where the objective is to maximize the total profit by selecting
decision variables, each associated with a profit and resource
consumption across multiple constraints. The decision vari-
ables must be chosen such that the sum of resource usage for
each constraint does not exceed its corresponding capacity.
Importantly, if any constraint is violated—that is, if the re-
source consumption for any constraint exceeds its allowed
capacity—the solution is deemed infeasible and earns no
score. The challenge lies in identifying the optimal combina-
tion of items that yields the highest total profit while strictly
satisfying all resource constraints.
Method
Score
Classical Solver
0.9903523477639424
BestOfN
0.9401685100749627
Refine
0.9947726903727786
FunSearch
0.9773347714972982
AIDE
0.925117898068383
ReEvo
1.0018885951740353
MCTS
1.0057751617808324
EoH
1.0010112897238341
Table 24: Multidimensional knapsack problem
Open shop scheduling
The Open Shop Scheduling Problem involves scheduling a
set of jobs across a set of machines with the goal of mini-
mizing the total completion time (makespan). Each job con-
sists of several operations, where each operation must be
processed on a specific machine for a given duration. Un-
like other scheduling problems, the Open Shop variant has
no predetermined order for processing the operations of a
job—operations can be scheduled in any order, but a job can
only be processed on one machine at a time, and a machine
can only process one job at a time. This creates a complex
combinatorial optimization challenge where the scheduler
must determine both the sequence of operations for each
job and the timing of each operation to minimize the overall
completion time while ensuring no resource conflicts.
Method
Score
Classical Solver
0.7851209868863173
BestOfN
0.9017764948703829
Refine
0.9930284498507208
FunSearch
0.9930284498507208
AIDE
0.9156437907474381
ReEvo
0.9825099803205837
MCTS
0.8960699709846601
EoH
0.9930284498507208
Table 25: Open shop scheduling
Packing unequal circles
The problem involves packing a subset of unequal circles
into a fixed circular container with radius R_0 and center at
the origin, where each circle i has a given radius R_i (sorted
in non-decreasing order) and is associated with a binary de-
cision variable alpha_i indicating whether it is packed. The
goal is to maximize the number of circles packed—that is,


--- Page 17 ---
maximize Pn
i=1 αi—subject to two sets of nonlinear con-
straints: (1) each packed circle must lie entirely within the
container, which is enforced by ensuring that the distance
from its center to the container’s center plus its radius does
not exceed R_0; and (2) any two packed circles must not
overlap, meaning the distance between their centers must be
at least the sum of their radii.
Method
Score
Classical Solver
0.9075757575757577
BestOfN
0.8939393939393939
Refine
0.9803030303030303
FunSearch
0.9719696969696969
AIDE
0.8825757575757576
ReEvo
0.8825757575757576
MCTS
0.9522727272727273
EoH
0.8825757575757576
Table 26: Packing unequal circles
Packing unequal circles area
The problem involves packing a subset of unequal circles
into a fixed circular container with radius R_0 and center at
the origin, where each circle i has a given radius R_i (sorted
in non-decreasing order) and is associated with a binary de-
cision variable alpha_i indicating whether it is packed. The
goal is to maximize the total area of all circles packed—that
is, maximize Pn
i=1 αi ∗pi ∗R2
i —subject to two sets of non-
linear constraints: (1) each packed circle must lie entirely
within the container, which is enforced by ensuring that the
distance from its center to the container’s center plus its ra-
dius does not exceed R_0; and (2) any two packed circles
must not overlap, meaning the distance between their centers
must be at least the sum of their radii.
Method
Score
Classical Solver
0.8767896840297265
BestOfN
0.9923476599194556
Refine
1.0226692239919217
FunSearch
1.0404725950195108
AIDE
0.5972138868724692
ReEvo
0.9101821460280035
MCTS
0.9617483396206504
EoH
1.0056059827170811
Table 27: Packing unequal circles area
Packing unequal rectangles and squares
We are given a set of n unequal rectangles (or squares), each
with specified dimensions, and a fixed circular container of
radius R centered at the origin. The problem is to decide
which rectangles to pack and where to position them—by
choosing binary selection variables and continuous center
coordinates—so that every packed rectangle is entirely con-
tained within the circle and no two packed rectangles overlap.
For each rectangle, the four corners must lie inside the circle,
and if an item is not packed it is forced to a dummy position.
The objective is to maximize the number of packed items,
i.e., maximize Pn
i=1 alphai (or a related sum when each
alpha_i is binary). Note that the rotation of the rectagular (by
90 degrees) is sometimes allowed and your algorithm should
take that into account.
Method
Score
Classical Solver
0.9134625513058007
BestOfN
0.8337025039542202
Refine
0.932172162950195
FunSearch
0.9228828411608733
AIDE
0.7950708457573447
ReEvo
0.77954425754769
MCTS
0.8028450160315149
EoH
0.9228828411608733
Table 28: Packing unequal rectangles and squares
Packing unequal rectangles and squares area
We consider the problem of selecting and placing a subset
of n unequal rectangles (or squares) into a fixed-size circular
container of radius R so as to maximize the total area of the
packed items. Each item i has given dimensions Li and Wi
(with Li = Wi for squares) and an associated area LiWi
. The decision variables include a binary indicator αi for
whether item i is packed and continuous variables (xi, yi) for
the placement of its center, along with a rotation angle hetai
when 90◦rotations are allowed. The formulation enforces
that for every packed item, all four of its rotated corners must
lie within the circle, and that no two packed items overlap; if
an item is not packed, it is fixed at a dummy position.
Method
Score
Classical Solver
0.8893527400499813
BestOfN
0.9536806816195774
Refine
1.0513451711752306
FunSearch
1.0839011538182066
AIDE
0.8100272732450019
ReEvo
0.9435059488868657
MCTS
0.995946490673633
EoH
0.9566331174271511
Table 29: Packing unequal rectangles and squares area
Resource constrained shortest path
This problem involves finding the shortest path from vertex
1 to vertex n in a directed graph while satisfying resource
constraints. Specifically, each vertex and arc has associated
resource consumptions, and the cumulative consumption for
each resource must fall within the provided lower_bounds
and upper_bounds. The input includes the number of vertices
(n), arcs (m), resource types (K), resource consumption at


--- Page 18 ---
each vertex, and a graph represented as a mapping from ver-
tices to lists of arcs (each arc being a tuple of end vertex, cost,
and arc resource consumptions). The optimization objective
is to minimize the total arc cost of the path, with the condition
that the path is valid—meaning it starts at vertex 1, ends at
vertex n, follows defined transitions in the graph, and respects
all resource bounds; if any of these constraints are not met,
the solution receives no score.
Method
Score
Classical Solver
0.7508899529136809
BestOfN
0.7508899529136808
Refine
0.7284494767232047
FunSearch
0.7508899529136808
AIDE
0.7508899529136808
ReEvo
0.7508899529136808
MCTS
0.7284494767232047
EoH
0.7508899529136808
Table 30: Resource constrained shortest path
Set covering
Set Covering Problem. The goal is to select a subset of
columns, each with an associated cost, such that every row
is covered by at least one chosen column. For each row,
the available covering columns are provided (as 1-indexed
numbers). The objective is to minimize the total cost of the
selected columns, and if even one row is left uncovered, then
no score is awarded.
Method
Score
Classical Solver
0.8883906244045974
BestOfN
0.8213286754887226
Refine
0.9056204467263304
FunSearch
0.8887733963981322
AIDE
0.8639998129016312
ReEvo
0.9360686599803572
MCTS
0.8672991644233662
EoH
0.8843920544743958
Table 31: Set covering
Set partitioning
This problem involves solving a set partitioning instance
where the goal is to choose a subset of columns such that
each row is covered exactly once while minimizing the total
cost. Each column is associated with a cost and covers a
specific set of rows. The optimization problem is defined
by selecting columns from a given set so that every row is
covered precisely once, and the sum of the selected columns’
costs is minimized. If the solution fails to cover every row
exactly once, then no score is awarded.
Method
Score
Classical Solver
0.9996401983661346
BestOfN
0.8991338255841825
Refine
0.7999991398515384
FunSearch
0.8333333333333334
AIDE
0.9
ReEvo
0.8991338255841825
MCTS
0.8647769492523454
EoH
0.9324671589175159
Table 32: Set partitioning
TSP
The Traveling Salesman Problem (TSP) is a classic combina-
torial optimization problem where, given a set of cities with
known pairwise distances, the objective is to find the shortest
possible tour that visits each city exactly once and returns to
the starting city. More formally, given a complete graph G =
(V, E) with vertices V representing cities and edges E with
weights representing distances, we seek to find a Hamilto-
nian cycle (a closed path visiting each vertex exactly once)
of minimum total weight.
Method
Score
Classical Solver
0.986
BestOfN
0.8590303340408165
Refine
0.9399577646813952
FunSearch
0.9016741050908584
AIDE
0.7710495444635409
ReEvo
0.8488918718349553
MCTS
0.5961113158302597
EoH
0.7935463156320405
Table 33: TSP
Uncapacitated warehouse location
The Uncapacitated Warehouse Location Problem aims to de-
termine which warehouses to open and how to assign each
customer entirely to an open warehouse in order to minimize
the total cost. Given a set of potential warehouse locations,
each with a fixed opening cost, and a set of customers, each
with an associated assignment cost for being served by each
warehouse, the objective is to select a subset of warehouses
to open and assign every customer completely to one of these
open warehouses. The optimization minimizes the sum of
fixed warehouse opening costs and the customer assignment
costs. Each customer must be assigned to exactly one ware-
house; if any customer is left unassigned or assigned to more
than one warehouse, the solution is considered infeasible.
Unconstrained guillotine cutting
The unconstrained guillotine cutting problem involves select-
ing and placing a subset of available pieces within a fixed
stock rectangle to maximize the total value of the placed
pieces. Each piece, defined by its length, width, and value,


--- Page 19 ---
Method
Score
Classical Solver
0.9968157833494645
BestOfN
0.98931916166557
Refine
1.0000000000002045
FunSearch
0.9978398298062331
AIDE
0.9994999857664043
ReEvo
0.998083746641369
MCTS
0.9951604598088827
EoH
0.8749999999978142
Table 34: Uncapacitated warehouse location
may be optionally rotated 90° if allowed and used at most
once. The challenge is to determine both the selection and
the positioning of these pieces such that they do not overlap
and lie entirely within the stock’s boundaries. This optimiza-
tion problem formalizes the decision variables as the x and
y coordinates for the bottom-left placement of each piece
and, if rotation is allowed, a binary variable indicating its
orientation, while the objective function is to maximize the
sum of the values of the pieces successfully placed within
the stock.
Method
Score
Classical Solver
0.9725381370960237
BestOfN
0.8701275303357732
Refine
0.9618177725501762
FunSearch
0.9646369625362231
AIDE
0.8512970128354943
ReEvo
0.9828452190272524
MCTS
0.8628525304460628
EoH
0.9649480933563296
Table 35: Unconstrained guillotine cutting
Vehicle routing: period routing
The Period Vehicle Routing Problem requires planning deliv-
ery routes over a multi-day planning period.
Each customer (other than the depot, whose id is 0) is
provided with a list of candidate service schedules. A sched-
ule is represented by a binary vector of length equal to the
period (e.g., [1, 0, 1] for a 3-day period), where a 1 in a given
position indicates that the customer must be visited on that
day. The decision maker must select exactly one candidate
schedule for each customer.
For every day in the planning period, if a customer’s cho-
sen schedule indicates a delivery (i.e., a 1), then exactly one
vehicle must visit that customer on that day. Otherwise, the
customer should not be visited. The decision maker must also
design, for each day, the tours for the vehicles. Each tour is a
continuous route that starts at the depot (id 0) and, after visit-
ing a subset of customers, returns to the depot. Each vehicle
is only allowed to visit the depot once per day—namely, as
its starting and ending point—and it is not allowed to return
to the depot in the middle of a tour.
Moreover, each vehicle route must obey a capacity con-
straint: the total demand of the customers visited on that tour
must not exceed the vehicle capacity each day. Although mul-
tiple vehicles are available per day (as specified by the input),
not all available vehicles have to be used, but the number
of tours in a given day cannot exceed the provided number
of vehicles. In addition, the tours on each day must cover
exactly those customers who require service per the selected
schedules, and no customer may be visited more than once
in a given day.
The objective is to choose a schedule for every customer
and plan the daily tours so as to minimize the overall distance
traveled by all vehicles during the entire planning period.
Distances are measured using Euclidean distance.
Method
Score
Classical Solver
0.12437943290991642
BestOfN
0.42032326191804853
Refine
0.48371172427664344
FunSearch
0.32385035648314586
AIDE
0.5362363612554435
ReEvo
0.0
MCTS
0.0
EoH
0.0
Table 36: Vehicle routing: period routing
p-median - capacitated
The Capacitated P-Median Problem is a facility location op-
timization problem where the objective is to select exactly
p customers as medians (facility locations) and assign each
customer to one of these medians to minimize the total cost,
defined as the sum of the Euclidean distances (rounded down
to the nearest integer) between customers and their assigned
medians. Each median has a capacity constraint Q , meaning
the total demand of the customers assigned to it cannot exceed
Q . A feasible solution must respect this capacity constraint
for all medians; otherwise, it receives a score of zero. The so-
lution is evaluated by the ratio extscore = rac extbest_known
extcomputed_total_cost , where computed_total_cost is the
total assignment cost if all constraints are satisfied; otherwise,
the score is zero. The output consists of the total cost (if fea-
sible), the selected medians, and the customer assignments.
p-median - uncapacitated
The uncapacitated p-median problem is a combinatorial opti-
mization problem defined on a given graph G = (V, E) with
n vertices and m edges. The objective is to select p medians
(facility locations) from the set of vertices such that the total
assignment cost is minimized. The assignment cost is com-
puted as the sum of the shortest distances from each vertex
to its nearest selected median, where distances are given by a
precomputed complete cost matrix (obtained via Floyd’s al-
gorithm). Formally, given the cost matrix D ∈Rn×n , the op-
timization problem seeks to find a subset S ⊆V with|S| = p
that minimizes the function:


--- Page 20 ---
Method
Score
Classical Solver
0.8996179560649475
BestOfN
0.9892886172082498
Refine
0.9737771618997864
FunSearch
0.9748437166838722
AIDE
0.7442228395960961
ReEvo
0.9786585768154689
MCTS
0.9829650705934849
EoH
0.9853458094532425
Table 37: p-median - capacitated
P
v∈V mins∈S D(v, s)
where D(v, s) is the shortest-path distance between vertex
v and median s . The solution consists of a list of exactly p
distinct vertices representing the chosen medians.
Method
Score
Classical Solver
0.9952341868141825
BestOfN
0.9453613019698086
Refine
0.9982141349797949
FunSearch
0.9996783954983718
AIDE
0.9847816841274486
ReEvo
0.9983315585722753
MCTS
0.9605290267584901
EoH
0.9921177098573016
Table 38: p-median - uncapacitated
