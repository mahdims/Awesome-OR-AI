--- Page 1 ---
arXiv:2507.03920v1  [cs.LG]  5 Jul 2025
Combining Graph Neural Networks and Mixed Integer Linear
Programming for Molecular Inference under the Two-Layered
Model
Jianshen Zhu1,5
Naveed Ahmed Azam2
Kazuya Haraguchi1
Liang Zhao3
Tatsuya Akutsu4
1Graduate of Informatics, Kyoto University, Kyoto 606-8501, Japan
2Department of Mathematics, Quaid-i-Azam University, Islamabad 45320, Pakistan
3Graduate School of Advanced Integrated Studies in Human Survivability
(Shishu-Kan), Kyoto University, Kyoto 606-8306, Japan
4Bioinformatics Center, Institute for Chemical Research, Kyoto University, Uji
611-0011, Japan
5Department of Information Sciences, Tokyo University of Science, Noda, Chiba
278-8510, Japan
Abstract
Recently, a novel two-phase framework named mol-infer for inference of chemical
compounds with prescribed abstract structures and desired property values has been
proposed. The framework mol-infer is primarily based on using mixed integer lin-
ear programming (MILP) to simulate the computational process of machine learning
methods and describe the necessary and suﬃcient conditions to ensure such a chemical
graph exists. The existing approaches usually ﬁrst convert the chemical compounds
into handcrafted feature vectors to construct prediction functions, but because of the
limit on the kinds of descriptors originated from the need for tractability in the MILP
formulation, the learning performances on datasets of some properties are not good
enough.
A lack of good learning performance can greatly lower the quality of the
inferred chemical graphs, and thus improving learning performance is of great impor-
tance. On the other hand, graph neural networks (GNN) oﬀer a promising machine
learning method to directly utilize the chemical graphs as the input, and many existing
GNN-based approaches to the molecular property prediction problem have shown that
they can enjoy better learning performances compared to the traditional approaches
that are based on feature vectors. In this study, we develop a molecular inference frame-
work based on mol-infer, namely mol-infer-GNN, that utilizes GNN as the learning
method while keeping the great ﬂexibility originated from the two-layered model on the
abstract structure of the chemical graph to be inferred. We conducted computational
experiments on the QM9 dataset to show that our proposed GNN model can obtain sat-
isfying learning performances for some properties despite its simple structure, and can
infer small chemical graphs comprising up to 20 non-hydrogen atoms within reasonable
1


--- Page 2 ---
2LMM GNN: July 8, 2025
2
computational time.
Keywords:
Machine Learning, Graph Neural Networks, Integer Programming, Chemoin-
formatics, Molecular Design, Inverse QSAR/QSPR.
1
Introduction
Designing novel molecules with predetermined structures and desired properties is a critical chal-
lenge across diverse research ﬁelds, including materials science [28] and drug discovery [27, 32].
In recent years, signiﬁcant progress has been made in molecular design using various machine
learning techniques [23,40]. Computational molecular design, historically entrenched in chemoin-
formatics, has been studied under the name of quantitative structure activity/property relationship
(QSAR/QSPR) [10,35] and its inverse counterpart inverse quantitative structure activity/property
relationship (inverse QSAR/QSPR) [17,27,30]. Analysis of the activities and properties of chemical
compounds is crucial not only in chemistry but also in biology, given their pivotal roles in various
metabolic pathways.
QSAR/QSPR aims to predict chemical activities from given chemical structures [10]. A pre-
diction function is usually constructed from existing structure-activity relation data, employing
machine learning-based methods, including artiﬁcial neural network (ANN)-based methods [23,40].
On the other hand, inverse QSAR/QSPR seeks to infer chemical structures from given chemical
activities [17, 27, 30]. In most classical approaches, chemical structures are typically treated as
an undirected graph called chemical graphs and encoded as a vector of real numbers called de-
scriptors or feature vectors. A typical approach to inverse QSAR/QSPR involves ﬁrst inferring
feature vectors from given chemical activities and then reconstructing chemical graphs from these
feature vectors [17,27,30]. While these handcrafted features have been eﬀective in many cases, the
limitations become apparent when dealing with large-scale datasets [14].
Recent advancements in deep learning, especially the development of graph neural networks
(GNNs), have provided a promising alternative to traditional feature-based methods. GNNs have
demonstrated superior performance in capturing intricate relationships with chemical graphs by
directly utilizing the graph structure as input, eliminating the need for manually designed descrip-
tors [14,21,31]. The ability to automatically learn meaningful representations from non-Euclidean
data has opened new avenues for molecular property prediction, with several GNN-based models
achieving state-of-the-art results on benchmark datasets like QM9 [11,13,14,31,46]. Also, there are
several GNN-based approaches to the molecular graph generation problem [41]. These methods
either generate a new graph in a sequential manner [15,22]–adding vertices and edges step by step,
or in a global manner [5,8]–outputting an entire graph at once.
However, despite the remarkable progress made with GNNs (and other deep learning-based ap-
proaches), most existing approaches focus mainly on the prediction task of QSAR/QSPR, and few
studies have eﬀectively integrated GNNs into the inverse QSAR/QSPR frameworks. A signiﬁcant
challenge is to ensure the following two important properties of the generated chemical structures,
namely optimality—the quality of the solution for the inverse problem of the learning methods, and
exactness—whether the solution admits a valid chemical graph. While many deep learning-based
generative models (e.g., [6,7,19,34]) aim to create chemically plausible molecules, they often fail
to guarantee the optimality or the exactness of the inferred solutions mathematically, which can
be problematic in practical applications [47].
To overcome these limitations, a novel framework called mol-infer [2,33,44,49] was recently


--- Page 3 ---
2LMM GNN: July 8, 2025
3
Figure 1: An illustration of the two-phase framework mol-infer.
proposed for inferring chemical compounds with prescribed abstract structures and desired prop-
erty values. This framework is primarily based on using the mixed integer linear programming
(MILP) formulation to simulate the computational process of machine learning methods and also
describe the necessary and suﬃcient conditions to ensure the existence of a valid chemical graph.
As a result, mol-infer generates chemical graphs in a global manner and guarantees both the opti-
mality and exactness of the inferred chemical graph. Figure 1 provides an illustration of mol-infer.
Simply put, mol-infer consists of two phases. Phase 1 is the QSAR/QSPR phase aiming to con-
struct a prediction function η between chemical compounds and their observed property values.
Let G denote the set of all possible chemical graphs. First, we collect a dataset Dπ ⊆G of chemical
graphs consisting of chemical graphs C and the observed values a(C) (Stage 1). Then we use a fea-
ture function f : G →RK (K is a positive integer) to convert chemical graphs to a K-dimensional
real vectors (Stage 2). Finally, a prediction function η : RK →R is constructed by some machine
learning methods (Stage 3). Phase 2 is the inverse QSAR/QSPR phase, and the target is to infer
chemical graphs with speciﬁc property values. Given a set of rules called topological speciﬁcation
σ that speciﬁes the desired structure of the inferred chemical graphs, and a desired range [y∗, y∗]
of the target value, Stage 4 is designed to infer chemical graphs C∗that satisfy the rules σ and
η(f(C∗)) ∈[y∗, y∗] by solving an MILP formulation M(g, x, y; C1, C2) that represents:
(i) M(x, y; C1): the computation process of the prediction function η; and
(ii) M(g, x; C2): that of the feature function f and the constraints for C ∈Gσ,
where Gσ denotes the set of all chemical graphs satisfying σ. In Stage 5, dynamic programming-
based graph enumeration algorithms [16] are used to generate isomers of the inferred chemical
graphs C∗obtained in Stage 4. This framework was originally proposed for only limited classes
of chemical graphs; e.g., trees [4,44], rank-1 graphs [18], and rank-2 graphs [52]. The two-layered


--- Page 4 ---
2LMM GNN: July 8, 2025
4
model (2L-model) proposed by Shi et al. [33] admits us to infer any chemical graph, where users
need to design an abstract structure as a part of the input, and is now the standard model in
mol-infer. One of the superiority of mol-infer is that it can suggest that Gσ does not contain
such a desired chemical graph when the MILP formulation M(g, x, y; C1, C2) is infeasible, while
most existing inverse QSAR/QSPR models fail to do this. Several machine learning methods have
been employed into mol-infer, for example, ANNs [33], linear regression [48, 49], and decision
trees [39]. (We refer to the thesis [47] for a more comprehensive description of mol-infer.)
All of these previous approaches rely heavily on handcrafted feature vectors because of the
limit on the kinds of descriptors originating from the need for tractability in the MILP formulation
M(g, x; C2). However, the learning performances on datasets of some properties are limited. For
example, the median test R2 score for the dataset of electric dipole moment (mu) consisting of
randomly selected 1000 molecules from the QM9 dataset is less than 0.7 [48, 50], and for the
dataset of autoignition temeprature annotated from Hazardous Substances Data Bank (HSDB) [1]
on Pubchem [20] it is around 0.8 [50]. A lack of good learning performance can greatly lower the
quality of chemical graphs inferred in Phase 2, and thus developing new ways to improve learning
performance is of great importance. One noteworthy issue is that, more complex methods can
increase the accuracy of the resultant prediction functions in Phase 1. On the other hand, it is
generally hard to represent the computational process of such a method by MILP (e.g., kernel
methods like support vector machine), and even in the case where it is possible, the time needed to
solve the MILP formulations in Phase 2 will increase drastically as well, and thus, it is challenging
to incorporate complicated learning methods into mol-infer.
In this paper, we introduce mol-infer-GNN, an advanced extension of the mol-infer frame-
work that integrates GNNs as the primary learning method while retaining the rigorous MILP
formulations for structure inference. By directly utilizing the chemical graph as input, the newly
proposed framework overcomes the limitations of handcrafted features and enhances the predictive
power of the model. The key contributions of this work are summarized as follows:
- We develop a relatively simple GNN architecture, 2L-GNN, speciﬁcally designed for the two-
layered model, ensuring eﬃcient and eﬀective learning from chemical graphs.
- We incorporate the 2L-GNN model into the mol-infer framework, and manage to formulate
the inverse problem using MILP, thereby guaranteeing both the optimality and exactness
of the inferred chemical structures. While previous studies (e.g., [25, 45]) have used MILP
formulations to simulate the computation process of a given GNN, these approaches have
been restricted in the variety of chemical graphs they can generate. In contrast, our method
beneﬁts from the ﬂexibility of the two-layered model, allowing for a signiﬁcantly broader
range of chemical structures to be inferred.
- We conduct numerical experiments on the QM9 dataset [29, 42] to evaluate the predictive
accuracy and inference eﬃciency of our proposed approach. Speciﬁcally, we demonstrate that
the inverse problem can be solved eﬃciently enough to infer a chemical graph comprising up
to 20 non-hydrogen atoms. Additionally, we use the open-source quantum chemistry software
Psi4 [36] and PySCF [37,38] to compute the property values of the inferred molecules and
compare them with the ones obtained from MILP solutions, and the experimental results
demonstrate that the generated compounds are generally of good quality.
The paper is organized as follows. We introduce some basic notations on graphs, the modeling
of chemical compounds, and the two-layered model in Section 2. Section 3 introduces our newly-


--- Page 5 ---
2LMM GNN: July 8, 2025
5
proposed GNN-based inverse QSAR/QSPR framework mol-infer-GNN. We report some results
on computational experiments conducted on the QM9 dataset in Section 4. Section 5 concludes
the paper. More details are available in the Appendix, including a full list of constraints in MILP
formulations. All program codes and experimental results are available at https://github.com/
ku-dml/mol-infer/tree/master/2LGNN.
2
Preliminary
In this section, we introduce some essential concepts and notations related to graph theory and the
modeling of chemical compounds, which are the foundation for our proposed framework. These
deﬁnitions follow mainly the work of Zhu et al. [49], with some necessary modiﬁcations tailored to
our approach.
For two integers a and b such that a ≤b, let [a, b] denote the set of integers i with a ≤i ≤b.
2.1
Graphs
Throughout this study, we consider a graph as a simple connected undirected graph. The sets of
vertices and edges of G are denoted by V (G) and E(G), respectively. For any vertex v ∈V (G),
the neighborhood of v is denoted by NG(v), and the degree degG(v) of v is deﬁned to be degG(v) =
|NG(v)|.
We sometimes designate a vertex in a graph G as a root, and call such a graph rooted. A leaf-
vertex in a graph G (possibly with a root) is deﬁned to be be a non-root vertex v with degree 1. An
edge uv incident to a leaf-vertex v is called a leaf-edge, and the sets of leaf-vertices and leaf-edges
are denoted by Vleaf(G) and Eleaf(G), respectively. We deﬁne a sequence of graphs Gi, i ∈Z+, for
a graph G by removing the set of leaf-vertices iteratively as follows:
G0 := G;
Gi+1 := Gi −Vleaf(Gi).
We call a vertex v a tree vertex if v ∈Vleaf(Gi) for some integer i ≥0, and deﬁne the height ht(v)
of v to be i. For each non-tree vertex v adjacent to a tree vertex, we deﬁne ht(v) to be ht(u) + 1,
where u is the one with the maximum ht(u) among the neighbors of v. The height is left undeﬁned
for any non-tree vertex that is not adjacent to any tree vertex. The height ht(T ) of a rooted tree
T is deﬁned to be the maximum of ht(v) of a vertex v ∈V (T ).
2.2
Modeling of Chemical Compounds
To represent a chemical compound, we employ the chemical graph which abstracts a molecule as a
graph where vertices represent atoms and edges represent bonds. We refer [49] for a more detailed
description of chemical graphs.
A chemical compound C is represented by a chemical graph which is deﬁned to be a triplet
C = (H, α, β) of a graph H, α : V (H) →Λ assigns chemical elements to vertices, and β : E(H) →
[1, 3] assigns the bond-multiplicity to edges. Here Λ is a set of chemical elements, and we denote
a chemical element a with a valence i by a(i). Such a suﬃx (i) is omitted for a chemical element
a with a unique valence. The hydrogen-suppressed chemical graph ⟨C⟩of C is the graph obtained
by removing all hydrogen atoms.
Two chemical graphs (H1, α1, β1) and (H2, α2, β2) are isomorphic if a bijection φ : V (H1) →
V (H2) exists such that chemical and structural information are preserved under φ; i.e., uv ∈


--- Page 6 ---
2LMM GNN: July 8, 2025
6
Figure 2: An illustration of the 2L-model for a chemical graph C.
Here ⟨C⟩is the hydrogen-
suppressed chemical graphs of C. The interior is represented by the shaded area enclosed by thick
black lines, while the remaining parts form the exterior. Vertices ui, i ∈[1, 28] are the interior-
vertices, and Tu14 is the chemical tree rooted at vertex u14, outlined by a thin gray line.
E(H1), α1(u) = a, α1(v) = b, β1(uv) = m if and only if φ(u)φ(v) ∈E(H2), α2(φ(u)) = a, α2(φ(v)) =
b, β2(φ(u)φ(v)) = m.
2.3
Two-layered Model
This subsection reviews the two-layered model (2L-model) proposed by Shi et al. [33] and further
reﬁned by Zhu et al. [49], which divides the hydrogen-suppressed chemical graph ⟨C⟩into two
parts: the interior and the exterior.
Let ρ ≥1 be an integer, which we call a branch-parameter and ρ = 2 is the standard value. For
a chemical graph C = (H, α, β), we categorize each vertex v ∈V (⟨C⟩) in the hydrogen-suppressed
chemical graph as follows; exterior-vertex if ht(v) < ρ for the height deﬁned on ⟨C⟩, and interior-
vertex otherwise. An edge e ∈E(⟨C⟩) is called an exterior-edge if e is incident to an exterior-vertex,
and interior-edge otherwise. We denote the sets of exterior-vertices, exterior-edges, interior-vertices
and interior-edges of C by V ex(C), Eex(C), V int(C) and Eint(C), respectively. The interior of C
is deﬁned to be the subgraph Cint := (V int(C), Eint(C)) of ⟨C⟩. Notice that the set Eex(C) of
exterior-edges consists of a collection of connected graphs, each of which can be viewed as a rooted
tree T rooted at an interior-vertex v ∈V (T ). We denote the set of these chemical rooted trees in
⟨C⟩as T ex(⟨C⟩). For each interior-vertex u ∈V int(C), let Tu ∈T ex(⟨C⟩) denote the chemical tree
rooted at u (where Tu may consist of only one vertex u). See Figure 2 for an illustration of these
concepts.
The ρ-fringe-tree C[u] is deﬁned to be the chemical rooted tree obtained from Tu by putting
back the hydrogens originally attached with Tu in C. We denote the set of ρ-fringe-trees in C as
T (C). Figure 3 illustrates the set T (C) = {C[ui] | i ∈[1, 28]} of the 2-fringe-trees of the example
C with ⟨C⟩in Figure 2.
In order to describe the abstract structure of the chemical graph to be inferred, a set of
rules called topological speciﬁcation was introduced by Tanaka et al. [39] and later updated by
Zhu et al. [49]. It consists of the following three parts:
(i) A seed graph GC that provides an abstract structure of a target chemical graph C;


--- Page 7 ---
2LMM GNN: July 8, 2025
7
Figure 3: An illustration of 2-fringe-trees C[ui], u ∈[1, 28] of the example C depicted in Figure 2.
We depict the root of each 2-fringe-tree with a black circle and omit the hydrogens attached to
non-root vertices.
(ii) A set F of chemical rooted trees as candidates for the ρ-fringe-tree C[u] rooted at each
interior-vertex u in C; and
(iii) Lower and upper bounds on the number of components in a target chemical graph such as
chemical elements, double/triple bonds and the interior-vertices in C.
We refer Appendix A and [49] for a detailed description of topological speciﬁcation and how
the MILP in Stage 4 expands the seed graph to get a complete chemical graph.
3
mol-infer-GNN: A GNN-based Inverse QSAR/QSPR Frame-
work
In this section, we describe our proposed molecular inference framework, mol-infer-GNN, which
uses GNN as the learning method so that chemical graphs are directly used as the input. As a
variant of mol-infer, mol-infer-GNN inherits the most important feature that the optimality and
exactness of the obtained solution are guaranteed by solving MILP formulations.
The framework consists of two phases, and the basic idea of each phase remains the same as
mol-infer. We illustrate the framework in Figure 4.
3.1
Phase 1: QSAR/QSPR Phase
Given a property π and a dataset consisting of chemical graphs C and their observed values
a(C) ∈R, the target of Phase 1 is to construct a prediction function η : G →R between a chemical
graph C = (H, α, β) and its observed property value a(C).
Graph Neural Networks
Graph neural networks (GNNs) [14, 21, 26] are a specialized class
of neural network models designed to process graph-structured data. Unlike traditional neural
networks, which require ﬁxed-sized vectors as inputs, GNNs can handle the irregular, non-Euclidean
nature of graphs, making them ideal for tasks involving relational data, such as molecular graphs,
social networks, and so on [41]. We will use the term node interchangeably with vertex in the
context of graph neural networks.


--- Page 8 ---
2LMM GNN: July 8, 2025
8
Figure
4:
An
illustration
of
the
two-phase GNN-based
molecular
inference
framework
mol-infer-GNN.
A fundamental concept behind GNNs is message passing, a mechanism that enables each node in
a graph to iteratively update its feature representation by aggregating information from its neigh-
bors. This iterative exchange allows GNNs to capture both local structures (i.e., relationships
between adjacent nodes) and global structures (i.e., long-range dependencies within the graph).
This gives GNNs the capacity to learn highly expressive representations that encode both topolog-
ical and attribute-based information, making them powerful tools for graph-based learning tasks.
One of the key advantages of GNNs over traditional machine learning methods is the ability to
generalize across varying graph sizes and structures, eliminating the need for handcrafted feature
engineering, which greatly limits the learning performance on some datasets.
Formally, for a GNN with L layers, given a graph G = (V, E) with initial node feature vectors
θ(0)
v
for each node v ∈V , the feature update process at the ℓ-th (ℓ∈[1, L]) layer can be described
as:
a(ℓ)
v
←AGGREGATE(ℓ)({θ(ℓ−1)
u
| u ∈NG(v)}),
θ(ℓ)
v
←COMBINE(ℓ)(θ(ℓ−1)
v
, a(ℓ)
v ),
where AGGREGATE(ℓ)(·) is a learnable function that collects features from neighboring nodes,
and COMBINE(ℓ)(·) is a learnable function that merges the aggregated features with the current
node’s features.
After L layers of message passing, the node features θ(L)
v
will capture the structural information
from the L-hop neighborhood of each node [43]. A graph-level representation vector θG can then
be derived by a readout function, typically an aggregation like mean pooling, max pooling, or some
more complex function based on attention mechanisms:
θG ←READOUT({θ(L)
v
| v ∈V }).


--- Page 9 ---
2LMM GNN: July 8, 2025
9
Figure 5: An illustration of the graph neural network 2L-GNN that is used in mol-infer-GNN to
construct a prediction function η.
GNNs have shown remarkable success in various applications, especially in molecular property
prediction, where they outperform traditional feature-based models by directly leveraging the graph
structure of molecules.
2L-GNN
While GNNs have demonstrated their superior performance in QSAR/QSPR tasks,
integrating GNNs into inverse QSAR/QSPR frameworks faces signiﬁcant challenges.
Typical
GNN-based methods often focus on predicting properties from molecular graphs, and they do
not guarantee the optimality or exactness of the inferred structures when applied to the inverse
problem. Additionally, many models rely on 3D structural information (e.g., bond angles and
interatomic distances), which can be computationally expensive to obtain and process [14].
To overcome these limitations, here we propose a novel GNN architecture, 2L-GNN, which is
designed speciﬁcally to enhance learning performance and maintain the ﬂexibility of the 2L-model
of chemical graphs introduced in Section 2.3. Unlike most of the existing approaches that process
all nodes (including the hydrogen atoms), 2L-GNN uses only on the interior-vertices V int(C) as
the nodes in GNN architecture. This selective processing reduces computational overhead while
preserving essential information. An illustration of 2L-GNN is shown in Figure 5.
Let L, Knode, KF, Khid, KC ∈Z+ be ﬁve positive integers, where L denotes the number of layers
in 2L-GNN, Knode denotes the length of an initial node feature vector, KF denotes the length of
the encoded feature vector that represents the local structure, Khid denotes the length of a node
feature vector at the other layers (hidden layers), and KC denotes the length of the representation
vector of a chemical graph C. The initial feature vector θ(0)
v
∈RKnode for each interior vertex
v ∈V int(C) consists of the following components:


--- Page 10 ---
2LMM GNN: July 8, 2025
10
- Atom type: One-hot encoding of the atom type of α(v) (C, O, N or not);
- Degree: The degree degC(v) of the vertex in the chemical graph;
- Valence: The valence of the atom α(v);
- Hydrogen count: The number of hydrogens attached to the vertex v;
- Ion-valence: The ion-valence of the atom;
- Fringe-tree encoding: A feature vector θψ ∈RKF representing the local structure (ρ-fringe-
tree Tv ∈T (C)) rooted at v, obtained via a secondary GNN model.
Notice that we include only 2D information about a molecule since the spatial information like
bond angles or interatomic distances is hard to tract in our MILP formulations of Phase 2.
Because of the need to simulate the computational process by MILP formulations in Phase 2,
our choice of the functions AGGREGATE(ℓ)(·) and COMBINE(ℓ)(·) are rather simple. The features
of each interior vertex are updated through L layers using a straightforward yet eﬀective message-
passing scheme. At each layer ℓ, ℓ∈[1, L], the update rule for the node feature vector θℓ
v ∈RKhid
is given by:
θ(ℓ)
v
←LReLU(
X
u∈NCint(v)∪{v}
W ℓθ(ℓ−1)
v
+ B(ℓ)),
where W (ℓ) ∈RKhid×Khid (W (1) ∈RKnode×Khid) and B(ℓ) ∈RKhid are learnable weight matrices
and biases and the LReLU (Leaky ReLU) activation LReLU(x) := max(αx, x) is used with a slope
parameter of α = 0.1 to avoid vanishing gradients.
The graph-level representation vector θC ∈RKC is computed by aggregating the ﬁnal layer
features of all interior vertices:
θC ←LReLU(
X
v∈V int(C)
θ(L)
v
).
The representation vector θC is then fed into a fully connected artiﬁcial neural network with
ReLU activation function ReLU(x) := max(0, x) (except the ﬁnal layer) to output the predicted
property value y∗:= η(C) of the chemical graph C.
3.2
Phase 2: Inverse QSAR/QSPR Phase
Phase 2 is designed to address the core task of inferring a chemical graph that satisﬁes property
and structural requirements. The challenge of ensuring both the optimality and exactness of the
inferred chemical graph is achieved by formulating the problem as an MILP problem, which we
denote as MGNN(g, x, y; C1, C2).
Formally, the primary goal of Phase 2 is to infer a chemical graph C† given:
- the prediction function η learned in Phase 1;
- a topological speciﬁcation σ, which deﬁnes the desired abstract structure of the chemical
graph to be inferred; and
- a target property range [y∗, y∗], indicating the desired range of the predicted property value.


--- Page 11 ---
2LMM GNN: July 8, 2025
11
The objective is to ﬁnd a chemical graph C† that belongs to the set of all chemical graphs satisfying
the speciﬁcation σ and whose predicted property value lies within the speciﬁed range, i.e.:
C† ∈Gσ, and η(C†) ∈[y∗, y∗],
where Gσ denotes the set of all chemical graphs satisfying σ.
For this, we design an MILP formulation MGNN(g, x, y; C1, C2) consisting of two parts:
(i) MGNN(x, y; C1): the part that simulates the computation process of the prediction function
η, i.e., the graph neural network 2L-GNN from Phase 1; and
(ii) MGNN(g, x; C2): the part of encoding the structural and chemical constraints of the target
graph to ensure it adheres the topological speciﬁcation σ, and the constraints to compute
the initial node feature vectors θ(0)
v .
The basic idea of this formulation remains similar to mol-infer.
In particular, the part
MGNN(g, x; C2) will be somehow similar to the one used in mol-infer, but the other one MGNN(x, y; C1)
that simulates the computation process of a GNN is a challenging task, and the extremely ﬂexible
rules of the topological speciﬁcation make it even harder. Here, we manage to realize the computa-
tion process of 2L-GNN that is proposed in Section 3.1 under the context of the two-layered model
by paying special attention to the situation that a vertex/edge may be not selected in the resultant
chemical graph. We list the complete set of constraints for MGNN(g, x, y; C1, C2) in Appendix C,
especially the ones for MGNN(x, y; C1) in Appendix C.8, since it is quite lengthy.
We acknowledge that several studies have already been done on utilizing MILP formulations
to represent the computation process of a GNN under the context of molecular optimization,
e.g., [25, 45]. However, our MILP formulation for the inverse problem diﬀers signiﬁcantly from
these previous works, in several key aspects:
- Unlike methods that focus on optimizing the property value, our approach aims to solve a
feasibility problem, ﬁnd any valid chemical graph that satisﬁes the speciﬁed property range.
- The use of the 2L-model and topological speciﬁcation provides greater ﬂexibility in deﬁning
the abstract structure of the target chemical graph, while previous approaches like [25, 45]
often rely on simple or predetermined graph structures (e.g., ﬁxed presence of one benzene
ring, at least one sulfur atom, etc.), greatly limiting the class of chemical graphs that can be
inferred.
4
Experimental Results
We implemented our proposed GNN-based molecular inference framework mol-infer-GNN and
conducted numerical experiments to evaluate its computational eﬀectiveness. The model 2L-GNN
was implemented using the library PyTorch Geometric 2.7 [12]. All the experiments were executed
on a workstation with a Core i9-9900K processor (3.6 GHz; 5.0 GHz at the maximum), 128 GB
DDR4 RAM memory, and an NVIDIA Quadro RTX 5000 GPU.
4.1
Results of QSAR/QSPR Phase
To assess the learning capabilities of our proposed 2L-GNN model for predicting chemical properties,
we used the publicly available benchmark QM9 dataset [29,42]. QM9 dataset comprises molecules


--- Page 12 ---
2LMM GNN: July 8, 2025
12
Table 1:
Results in Phase 1 on QM9 dataset with performance comparison to LLR in
mol-infer [49], SchNet [31], MGCN [24], DimeNet++ [13] and PAMNet [46].
The results of
SchNet, MGCN, DimeNet++ and PAMNet are adapted from [46].
π
2L-GNN16
2L-GNN32
mol-infer (LLR) [49]
SchNet [31]
MGCN [24]
DimeNet++ [13]
PAMNet [46]
Metric
MAE; R2
MAE; R2
MAE; R2
MAE
MAE
MAE
MAE
mu
588.930; 0.694
550.239; 0.733
759.067; 0.538
21
56
29.7
10.8
Alpha
2.156; 0.850
1.799; 0.911
0.898; 0.975
0.124
0.030
0.0435
0.0447
Homo
185.550; 0.828
158.878; 0.870
222.917; 0.774
47
42.1
24.6
22.8
Lumo
205.654; 0.952
171.943; 0.967
364.419; 0.873
39
57.4
19.5
19.2
Gap
277.472; 0.916
232.903; 0.940
432.729; 0.820
74
64.2
32.6
31.0
⟨R2⟩
90.020; 0.796
79.073; 0.847
75.571; 0.849
0.158
0.11
0.331
0.093
ZPVE
110.482; 0.970
79.067; 0.984
16.743; 0.999
1.616
1.12
1.21
1.17
Cv
0.9188; 0.896
0.7947; 0.934
0.4610; 0.977
0.034
0.038
0.0230
0.0231
composed of Hydrogen (H), Carbon (C), Oxygen (O), Nitrogen (N), and Fluorine (F) atoms, with
each molecule containing up to 9 heavy (non-hydrogen) atoms. In total, this dataset encompasses
133,885 drug-like organic molecules, representing a diverse array of chemistry. For each molecule
in the QM9 dataset, density functional theory (B3LYP/6-31G(2df,p) based DFT) is employed
to determine a reasonable low-energy structure, and thereby providing access to atom positions,
enable a set of intriguing and fundamental chemical properties to be computed [42].
Although a larger size of network will obtain a better learning performance in general, the
network size, and the time needed to solve the MILP formulation for the inverse problem in
Phase 2 will be increased drastically as well. After some trials of preliminary experiments, we
selected the following two variants of our proposed GNN model for the sake of balancing the
learning performance and the time eﬀectiveness of solving MILP formulations:
- 2L-GNN16: a compact architecture with L = 3, Khid = 16, KC = 32; and
- 2L-GNN32: a larger architecture with L = 3, Khid = 32, KC = 32.
Both models were trained and tested on the following chemical properties from the QM9 dataset:
- mu: electric dipole moment (mD);
- Alpha: isotropic polarizability (a3
0);
- Homo: energy of highest occupied molecular orbital (meV);
- Lumo energy of lowest occupied molecular orbital (meV);
- Gap: the energy diﬀerence between Homo and Lumo (meV);
- ⟨R2⟩: electronic spatial extent (a2
0);
- ZPVE: zero point vibrational energy (meV);
- Cv: heat capacity at 298.15K (cal/molK).
To be consistent with previous works, we ﬁrst remove 3,054 molecules that fail a geometric con-
sistency check or are diﬃcult to converge, We use 110,000 molecules for training, 10,000 for vali-
dation, and the remaining 20,831 molecules are used for testing. We evaluate the mean absolute
error (MAE) and the coeﬃcient of determination (R2) of each property.


--- Page 13 ---
2LMM GNN: July 8, 2025
13
Table 2: Comparison of R2 scores on the test set for 2L-GNN16 and 2L-GNN32 with other approaches
in the mol-infer framework. The results for LLR, ANN, ALR, and R-MLR are adapted from [48],
and for HPS are adapted from [50]. “-” means the corresponding result is not available in the
literature.
π
2L-GNN16
2L-GNN32
LLR
ANN
ALR
R-MLR
HPS
mu
0.694
0.733
0.367
0.409
0.403
0.645
0.708
Alpha
0.850
0.911
0.961
0.888
0.953
0.980
-
Homo
0.828
0.870
0.841
0.689
0.689
0.804
0.847
Lumo
0.952
0.967
0.841
0.860
0.833
0.920
0.948
Gap
0.916
0.940
0.784
0.795
0.755
0.876
0.907
Cv
0.896
0.934
0.970
0.911
0.966
0.978
-
Table 1 presents a comparative analysis of 2L-GNN16 and 2L-GNN32 against the traditional LLR
(Lasso linear regression)-based mol-infer approach and several existing state-of-the-art GNN-
based models, including SchNet [31], MGCN [24], DimeNet++ [13], and PAMNet [46]. Unlike
previous mol-infer approaches, the LLR experiments in Table 1 were conducted on the whole
QM9 dataset for a better comparison with 2L-GNN. A key distinction of our approach to other
GNN-based models is that 2L-GNN does not utilize 3D coordinate information such as bond angles
and interatomic distances, which are commonly leveraged by other models, including the four
mentioned models.
In addition, these models typically employ deeper architectures with more
than 10 hidden layers.
Our model makes use of only 2D graphical information and 3 hidden
layers, and thus generally underperforms compared to them with no surprise. Nevertheless, our
model can still obtain a commendable result with R2 exceeding 0.9 for the properties such as
Alpha, Lumo, Gap, ZPVE, and Cv.
We also compared our new GNN-based approaches to other machine learning methods (LLR [49],
ANN [3], ALR [51], R-MLR [48], and HPS [50]) within the mol-infer framework, as shown in
Table 2. Although a direct comparison is not entirely fair due to the diﬀerences in the dataset (the
baseline models were trained on a randomly selected subset of 1000 molecules from the whole QM9
dataset), our results demonstrate that 2L-GNN signiﬁcantly improves the learning performance for
the properties such as mu, Homo, Lumo and Gap–propertues for which mol-infer approaches
struggled to achieve good learning performance. These improvements highlight the limitations of
handcrafted features used in previous models and showcase the advantage of GNNs in learning di-
rectly from molecular graph structures. While the performance of 2L-GNN on certain properties like
Alpha and Cv was slightly worse than the traditional LLR-based mol-infer approach, it still
achieved strong predictive performance–exceeding an R2 score of 0.9 with the 2L-GNN32 model.
This suggests that for some properties, carefully crafted features may still be critical and capture
key physicochemical characteristics more eﬀectively than GNNs trained solely on 2D structures.
A hybrid approach like [7], combining GNN-based learning with selected handcrafted descriptors,
may improve predictive accuracy. This is left as our future work.
4.2
Results of Inverse QSAR/QSPR Phase
In Phase 2, we formulated and solved MILP formulations to infer chemical graphs with desired
property values and pre-described abstract structures. For the experiments, we use a set of four


--- Page 14 ---
2LMM GNN: July 8, 2025
14
(i) G1
C
(ii) G2
C
(iii) G3
C
(iv) G4
C
(v) G5
C
Figure 6: Illustrations of the seed graph Gi
C of instance Ii, i ∈[1, 5], respectively. The edges in
E(≥2) are depicted with dotted lines, the edges in E(≥1) are depicted with dashed lines, the edges
in E(0/1) are depicted in gray bold lines and the edges in E(=1) are depicted with black solid lines.
See Appendix A for the description of the seed graphs and the sets E(≥2), E(≥1), E(0/1) and E(=1).
Table 3: Number of inverse problems that are determined as feasible/infeasible/timeout among
those having 10 diﬀerent target ranges (2L-GNN16): The time limit is set to 1 hour.
π
I1
I2
I3
I4
I5
Homo
3/0/7
1/0/9
2/0/8
3/0/7
4/0/6
Lumo
7/0/3
0/0/10
1/0/9
4/0/6
5/0/5
Gap
4/0/6
1/0/9
0/0/10
1/0/9
7/0/3
instances originally prepared by Zhu et al. [49], namely Ii, i ∈[1, 4], with slight modiﬁcations
for this research, and one new instance I5. Instance I1 is designed to infer chemical graphs with
cycle index one (i.e., chemical graphs with one cycle), and Ii, i ∈[2, 4] are designed to infer
chemical graphs with cycle index two (i.e., chemical graphs with two cycles). The basic settings
for Ii, i ∈[1, 4] are the same as in [49], except for the set F of chemical rooted trees, and the lower
and upper bounds on the number of components in the target chemical graph. We also prepared
an instance I5 to imitate the chemical compounds appearing in the QM9 dataset. A 0/1 edge
(depicted in gray, see Appendix A for the details) is introduced in I5 to enable the generation of
both a tree-like chemical graph and a chemical graph with cycle index one. The seed graphs Gi
C of
the ﬁve instances Ii, i ∈[1, 5] are illustrated in Figure 6. See Appendix B for a detailed description
of these instances.
We selected the properties Homo, Lumo and Gap, and utilized the prediction functions con-
structed by 2L-GNN16 and 2L-GNN32 for the numerical experiments.
The three properties were
selected because of the good learning performance obtained by GNN, and the fact that it is easy
to compute them by free and open-source softwares. For each property and the corresponding pre-
diction function, we formulated an MILP for each instance and ten target value ranges which were
selected based on the distribution of property values in the QM9 dataset. The MILP formulations
were solved using CPLEX 12.10, with a time limit of 1 hour for each formulation.
Tables 3 and 4 summarize the number of formulations that could be determined within 1
hour for each property and instance with the prediction functions constructed by 2L-GNN16 and
2L-GNN32, respectively. In total, 43 out of 150 (28.7%) formulations for 2L-GNN16 and 20 out of 150
(13.3%) formulations for 2L-GNN32 were successful in obtaining a feasible solution within the time
limit, showing the hardness of the inverse problem. Basically, the more complex model 2L-GNN32
needs more time to be solved, matching the intuition that while a larger model improves learning
performance in Phase 1, the computational time for solving the corresponding MILP formulations


--- Page 15 ---
2LMM GNN: July 8, 2025
15
Table 4: Number of inverse problems that are determined as feasible/infeasible/timeout among
those having 10 diﬀerent target ranges (2L-GNN32): The time limit is set to 1 hour.
π
I1
I2
I3
I4
I5
Homo
0/0/10
0/0/10
0/0/10
0/0/10
4/0/6
Lumo
0/0/10
0/0/10
0/0/10
0/0/10
6/0/4
Gap
1/0/9
0/0/10
1/0/9
2/0/8
6/0/4
Table 5: Selected results of Phase 2 on properties Homo, Lumo, and Gap with the model 2L-GNN16.
No.
π
inst.
y∗, y∗(eV)
#v
#c
I-time
n
η
ηPySCF
ηPsi4
(a)
Homo
I1
-8.00, -7.50
10517
55112
40.644
19
-7.63504
-7.39256
-7.71839
(b)
I2
-7.00, -6.50
10163
57570
4.134
10
-6.51518
-6.25516
-7.31964
(c)
I4
-6.50, -6.00
10151
58342
4.123
10
-6.27818
-5.87852
-6.38071
(d)
I5
-7.50, -7.00
7377
34508
19.008
9
-7.01391
-5.84124
-6.36345
(e)
Lumo
I1
-2.00, -1.50
10517
55112
60.889
19
-1.76264
-2.01727
-2.15115
(f)
I3
-3.50, -3.00
10159
57958
4.013
11
-3.35504
-4.74164
Err.
(g)
I5
1.00, 1.50
7377
34508
881.593
9
1.03216
1.14088
0.73261
(h)
Gap
I1
6.00, 6.50
10517
55112
62.145
20
6.27711
6.07699
6.28504
(i)
I5
7.00, 7.50
7377
34508
753.747
9
7.13251
6.45730
6.48175
Table 6: Selected results of Phase 2 on properties Homo, Lumo, and Gap with the model 2L-GNN32.
No.
π
inst.
y∗, y∗(eV)
#v
#c
I-time
n
η
ηPySCF
ηPsi4
(j)
Homo
I5
-6.00, -5.50
12785
67516
3262.404
9
-5.51096
-6.01995
Err.
(k)
Lumo
I5
1.00, 1.50
12785
67516
6.355
9
1.49046
1.53046
Err.
(l)
Gap
I1
4.50, 5.00
18325
108328
618.418
17
4.98681
4.86001
5.13423
signiﬁcantly increases in Phase 2.
Instance I5 had the highest number of solved formulations,
likely because it was designed to resemble molecules in the QM9 dataset, while instances with
more complex structures (e.g., I2 and I3) showed lower success rates.
To further assess the quality of our inferred chemical graphs, we used two free and open-source
quantum chemistry software PySCF [37,38] and Psi4 [36] to compute the property values using
DFT at the B3LYP/6-31G(2df,p) level and compare them against the predicted values obtained
from our constructed prediction functions.
We summarize some selected results about MILP formulations in Tables 5 and 6 for the model
2L-GNN16 and 2L-GNN32, respectively. The following notations are used:
- No.: numbering of the MILP;


--- Page 16 ---
2LMM GNN: July 8, 2025
16
F
F
N
O
H2N
N
N
O
CH3
N
N
CH3
O
N
H
O
N
O
(a)
(b)
(c)
(d)
N
O
HO
HO
H3C
O
CH3
F
O
OH
O
O
O
O
NH
N
H
O
H3C
O
NH2
O
NH2
O
CH3
NH
O
N
H
O
N
H
O
(e)
(f)
(g)
(h)
O
O
N
H
N
H
NH
N
H
CH3
N
H
O
CH3
H3C
N
O
N
N
O
O
(i)
(j)
(k)
(l)
Figure 7: Illustrations of the inferred chemical graphs. (a)-(l) correspond to the ﬁrst column No.
in Tables 5 and 6, respectively.
- π: the property;
- inst.: instance;
- y∗, y∗: range [y∗, y∗] (in eV) of target value of the chemical graph to be inferred;
- #v: the number of variables in the MILP formulation;
- #c: the number of constraints in the MILP formulation;
- I-time: the time (in seconds) to solve the MILP by CPLEX 12.10;
- n: the number of non-hydrogen atoms in the inferred chemical graph;
- η: the predicted property value by our constructed prediction function;
- ηPySCF: the predicted property value by the software PySCF [37,38]; and
- ηPsi4: the predicted property value by the software Psi4 [36] (Err. indicates that an error
occurred during the computation).
The inferred molecules contained up to 20 non-hydrogen atoms, demonstrating the practical
applicability of our approach. We notice that the predicted values obtained from our prediction
function sometimes diﬀer signiﬁcantly from those computed by PySCF and Psi4 (e.g., the chem-
ical graphs (d), (e) and (j)). We can also see that the diﬀerences between the values computed


--- Page 17 ---
2LMM GNN: July 8, 2025
17
by PySCF and Psi4 are big, pointing out the instability of DFT methods.
In certain cases,
Psi4 calculations failed due to chemically unstable structures, indicating potential limitations in
the MILP-generated molecular graphs. The issue of unstable generated structures is common in
molecular inference studies and highlights the need to incorporate chemical knowledge [9]. Never-
theless, the inferred chemical graphs were of rather good quality, demonstrating the potential of our
proposed framework. Figure 7 provides graphical representations of the inferred chemical graphs.
The results of our experiments indicate that mol-infer-GNN successfully integrates GNN-based
learning with MILP-driven molecular inference.
5
Concluding Remarks
In this study, we proposed mol-infer-GNN, a novel inverse QSAR/QSPR framework that integrates
GNNs into the existing mol-infer approach. A key contribution of our work is the successful
formulation of the inverse problem of GNN within the 2L-model of mol-infer as an MILP for-
mulation. This enables the combination of the deep learning-based molecular property prediction
with the rigorous inference capabilities of MILP. The use of the 2L-model plays a crucial role in our
framework, as it signiﬁcantly broadens the class of chemical graphs that can be eﬀectively inferred
compared with previous studies. By leveraging GNNs, our framework allows to use the chemical
graphs directly, eliminating the need for handcrafted feature vectors while enhancing prediction
accuracy. We validated our approach through computational experiments on the QM9 dataset.
The results demonstrated that our proposed simple GNN model, 2L-GNN, can eﬀectively predict
molecular properties using only 2D graphical information, which is necessary for the inverse prob-
lem to be formulated as MILP formulations at present. Our experiments also indicated that the
framework can infer chemical graphs with up to 20 non-hydrogen atoms, highlighting its potential
applications in cheminformatics and molecular design.
However, several challenges remain. The computational cost of solving MILP formulations re-
mains high, particularly as the complexity of the target molecular graphs and GNN architectures
increases. Future research should focus more on optimizing the inverse problem formulations, us-
ing heuristics to solve MILP formulations, and exploring alternative graph learning architectures.
Discrepancies between predicted and software-computed property values suggest that further im-
provements are needed in both GNN training and MILP constraint formulations. Enhancing the
graph representation learning and incorporating additional chemical constraints could mitigate
these issues. Additionally, trying to incorporate 3D information about molecules is also desired
since they can signiﬁcantly improve prediction accuracy and enhance the overall eﬀectiveness of
the framework. These are left as future works. We believe with further reﬁnements and a more in-
tegrated hybrid approach, our framework has the potential to signiﬁcantly advance computational
molecular design and inverse QSAR/QSPR research.
Acknowledgement
This work is partially supported by JSPS KAKENHI Grant Numbers JP22H00532 and JP22KJ1979.


--- Page 18 ---
2LMM GNN: July 8, 2025
18
References
[1] Annotations from HSDB (on pubchem).
https://pubchem.ncbi.nlm.nih.gov/source/11933.
Accessed on May 16th, 2025.
[2] N. A. Azam, R. Chiewvanichakorn, F. Zhang, A. Shurbevski, H. Nagamochi, and T. Akutsu. A
novel method for the inverse QSAR/QSPR based on artiﬁcial neural networks and mixed inte-
ger linear programming with guaranteed admissibility. In Proceedings of the 13th International
Joint Conference on Biomedical Engineering Systems and Technologies - BIOINFORMATICS,
pages 101–108. INSTICC, SciTePress, 2020.
[3] N. A. Azam, J. Zhu, K. Haraguchi, L. Zhao, H. Nagamochi, and T. Akutsu. Molecular design
based on artiﬁcial neural networks, integer programming and grid neighbor search. In 2021
IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pages 360–363.
IEEE, 2021.
[4] N. A. Azam, J. Zhu, Y. Sun, Y. Shi, A. Shurbevski, L. Zhao, H. Nagamochi, and T. Akutsu. A
novel method for inference of acyclic chemical compounds with bounded branch-height based
on artiﬁcial neural networks and integer programming. Algorithms for Molecular Biology,
16:1–39, 2021.
[5] A. Bojchevski, O. Shchur, D. Z¨ugner, and S. G¨unnemann.
NetGAN: Generating graphs
via random walks. In J. Dy and A. Krause, editors, Proceedings of the 35th International
Conference on Machine Learning, volume 80 of Proceedings of Machine Learning Research,
pages 610–619. PMLR, 10–15 Jul 2018.
[6] W. Bort, D. Mazitov, D. Horvath, F. Bonachera, A. Lin, G. Marcou, I. Baskin, T. Madzhidov,
and A. Varnek. Inverse QSAR: Reversing descriptor-driven prediction pipeline using attention-
based conditional variational autoencoder. Journal of Chemical Information and Modeling,
62(22):5471–5484, 11 2022.
[7] H. Cai, H. Zhang, D. Zhao, J. Wu, and L. Wang. FP-GNN: a versatile deep learning architec-
ture for enhanced molecular property prediction. Brieﬁngs in Bioinformatics, 23(6):bbac408,
09 2022.
[8] N. D. Cao and T. Kipf. MolGAN: An implicit generative model for small molecular graphs.
arXiv:1805.11973, 2022.
[9] Y. Cheng, Y. Gong, Y. Liu, B. Song, and Q. Zou. Molecular design in drug discovery: a
comprehensive review of deep generative models. Brieﬁngs in Bioinformatics, 22(6):bbab344,
08 2021.
[10] A. Cherkasov, E. N. Muratov, D. Fourches, A. Varnek, I. I. Baskin, M. Cronin, J. Dearden,
P. Gramatica, Y. C. Martin, R. Todeschini, et al. QSAR modeling: where have you been?
where are you going to? Journal of Medicinal Chemistry, 57(12):4977–5010, 2014.
[11] D. Duvenaud, D. Maclaurin, J. Aguilera-Iparraguirre, R. G´omez-Bombarelli, T. Hirzel,
A. Aspuru-Guzik, and R. P. Adams. Convolutional networks on graphs for learning molecu-
lar ﬁngerprints. In Proceedings of the 29th International Conference on Neural Information
Processing Systems - Volume 2, NIPS’15, pages 2224–2232, Cambridge, MA, USA, 2015. MIT
Press.


--- Page 19 ---
2LMM GNN: July 8, 2025
19
[12] M. Fey and J. E. Lenssen. Fast graph representation learning with PyTorch Geometric. In
ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019.
[13] J. Gasteiger, S. Giri, J. T. Margraf, and S. G¨unnemann. Fast and uncertainty-aware directional
message passing for non-equilibrium molecules. arXiv:2011.14115, 2022.
[14] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl. Neural message passing for
quantum chemistry. In D. Precup and Y. W. Teh, editors, Proceedings of the 34th International
Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research,
pages 1263–1272. PMLR, 06–11 Aug 2017.
[15] R. G´omez-Bombarelli, J. N. Wei, D. Duvenaud, J. M. Hern´andez-Lobato, B. S´anchez-
Lengeling, D. Sheberla, J. Aguilera-Iparraguirre, T. D. Hirzel, R. P. Adams, and A. Aspuru-
Guzik. Automatic chemical design using a data-driven continuous representation of molecules.
ACS Central Science, 4(2):268–276, 2018.
[16] R. Ido, N. A. Azam, J. Zhu, H. Nagamochi, and T. Akutsu. A dynamic programming algorithm
for generating chemical isomers based on frequency vectors. Scientiﬁc Reports, 15(1):22214,
2025.
[17] H. Ikebata, K. Hongo, T. Isomura, R. Maezono, and R. Yoshida. Bayesian molecular design
with a chemical language model. Journal of Computer-aided Molecular Design, 31:379–391,
2017.
[18] R. Ito, N. A. Azam, C. Wang, A. Shurbevski, H. Nagamochi, and T. Akutsu. A novel method
for the inverse QSAR/QSPR to monocyclic chemical compounds based on artiﬁcial neural
networks and integer programming.
In Advances in Computer Vision and Computational
Biology: Proceedings from IPCV’20, HIMS’20, BIOCOMP’20, and BIOENG’20, pages 641–
655. Springer, 2021.
[19] H. Kaneko. Molecular descriptors, structure generation, and inverse QSAR/QSPR based on
SELFIES. ACS Omega, 8(24):21781–21786, 06 2023.
[20] S. Kim, J. Chen, T. Cheng, A. Gindulyte, J. He, S. He, Q. Li, B. A. Shoemaker, P. A. Thiessen,
B. Yu, et al. PubChem 2023 update. Nucleic Acids Research, 51(D1):D1373–D1380, 2023.
[21] T. N. Kipf and M. Welling. Semi-supervised classiﬁcation with graph convolutional networks.
arXiv:1609.02907, 2017.
[22] M. J. Kusner, B. Paige, and J. M. Hern´andez-Lobato. Grammar variational autoencoder. In
International Conference on Machine Learning, pages 1945–1954. PMLR, 2017.
[23] Y.-C. Lo, S. E. Rensi, W. Torng, and R. B. Altman. Machine learning in chemoinformatics
and drug discovery. Drug Discovery Today, 23(8):1538–1546, 2018.
[24] C. Lu, Q. Liu, C. Wang, Z. Huang, P. Lin, and L. He. Molecular property prediction: a mul-
tilevel quantum interactions modeling perspective. In Proceedings of the Thirty-Third AAAI
Conference on Artiﬁcial Intelligence and Thirty-First Innovative Applications of Artiﬁcial
Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artiﬁcial
Intelligence, AAAI’19/IAAI’19/EAAI’19. AAAI Press, 2019.


--- Page 20 ---
2LMM GNN: July 8, 2025
20
[25] T. McDonald, C. Tsay, A. M. Schweidtmann, and N. Yorke-Smith. Mixed-integer optimisa-
tion of graph neural networks for computer-aided molecular design. Computers & Chemical
Engineering, 185:108660, 2024.
[26] A. Micheli. Neural network for graphs: A contextual constructive approach. IEEE Transac-
tions on Neural Networks, 20(3):498–511, 2009.
[27] T. Miyao, H. Kaneko, and K. Funatsu. Inverse QSPR/QSAR analysis for chemical structure
generation (from y to x). Journal of Chemical Information and Modeling, 56(2):286–299, 2016.
[28] D. Morgan and R. Jacobs. Opportunities and challenges for machine learning in materials
science. Annual Review of Materials Research, 50(Volume 50, 2020):71–103, 2020.
[29] R. Ramakrishnan, P. O. Dral, M. Rupp, and O. A. Von Lilienfeld.
Quantum chemistry
structures and properties of 134 kilo molecules. Scientiﬁc data, 1(1):1–7, 2014.
[30] C. Rupakheti, A. Virshup, W. Yang, and D. N. Beratan. Strategy to discover diverse optimal
molecules in the small molecule universe. Journal of Chemical Information and Modeling,
55(3):529–537, 2015.
[31] K. T. Sch¨utt, F. Arbabzadah, S. Chmiela, K. R. M¨uller, and A. Tkatchenko.
Quantum-
chemical insights from deep tensor neural networks.
Nature Communications, 8(1):13890,
2017.
[32] C. Shi, M. Xu, Z. Zhu, W. Zhang, M. Zhang, and J. Tang. GraphAF: a ﬂow-based autore-
gressive model for molecular graph generation. arXiv:2001.09382, 2020.
[33] Y. Shi, J. Zhu, N. A. Azam, K. Haraguchi, L. Zhao, H. Nagamochi, and T. Akutsu. An inverse
QSAR method based on a two-layered model and integer programming. International Journal
of Molecular Sciences, 22(6):2847, 2021.
[34] Y. Shino and H. Kaneko.
Improving molecular design with direct inverse analysis of
QSAR/QSPR model. Molecular Informatics, 44(1):e202400227, 2025.
[35] M. I. Skvortsova, I. I. Baskin, O. L. Slovokhotova, V. A. Palyulin, and N. S. Zeﬁrov. Inverse
problem in QSAR/QSPR studies for the case of topological indexes characterizing molecular
shape (kier indices). Journal of Chemical Information and Computer Sciences, 33(4):630–634,
1993.
[36] D. G. A. Smith, L. A. Burns, A. C. Simmonett, R. M. Parrish, M. C. Schieber, R. Galvelis,
P. Kraus, H. Kruse, R. Di Remigio, A. Alenaizan, A. M. James, S. Lehtola, J. P. Misiewicz,
M. Scheurer, R. A. Shaw, J. B. Schriber, Y. Xie, Z. L. Glick, D. A. Sirianni, J. S. O’Brien,
J. M. Waldrop, A. Kumar, E. G. Hohenstein, B. P. Pritchard, B. R. Brooks, I. Schaefer,
Henry F., A. Y. Sokolov, K. Patkowski, I. DePrince, A. Eugene, U. Bozkaya, R. A. King, F. A.
Evangelista, J. M. Turney, T. D. Crawford, and C. D. Sherrill. PSI4 1.4: Open-source software
for high-throughput quantum chemistry. The Journal of Chemical Physics, 152(18):184108,
05 2020.
[37] Q. Sun, T. C. Berkelbach, N. S. Blunt, G. H. Booth, S. Guo, Z. Li, J. Liu, J. D. McClain,
E. R. Sayfutyarova, S. Sharma, S. Wouters, and G. K.-L. Chan. PySCF: the python-based
simulations of chemistry framework. WIREs Computational Molecular Science, 8(1):e1340,
2018.


--- Page 21 ---
2LMM GNN: July 8, 2025
21
[38] Q. Sun, X. Zhang, S. Banerjee, P. Bao, M. Barbry, N. S. Blunt, N. A. Bogdanov, G. H. Booth,
J. Chen, Z.-H. Cui, J. J. Eriksen, Y. Gao, S. Guo, J. Hermann, M. R. Hermes, K. Koh, P. Ko-
val, S. Lehtola, Z. Li, J. Liu, N. Mardirossian, J. D. McClain, M. Motta, B. Mussard, H. Q.
Pham, A. Pulkin, W. Purwanto, P. J. Robinson, E. Ronca, E. R. Sayfutyarova, M. Scheurer,
H. F. Schurkus, J. E. T. Smith, C. Sun, S.-N. Sun, S. Upadhyay, L. K. Wagner, X. Wang,
A. White, J. D. Whitﬁeld, M. J. Williamson, S. Wouters, J. Yang, J. M. Yu, T. Zhu, T. C.
Berkelbach, S. Sharma, A. Y. Sokolov, and G. K.-L. Chan. Recent developments in the PySCF
program package. The Journal of Chemical Physics, 153(2):024109, 07 2020.
[39] K. Tanaka, J. Zhu, N. A. Azam, K. Haraguchi, L. Zhao, H. Nagamochi, and T. Akutsu.
An inverse QSAR method based on decision tree and integer programming. In Intelligent
Computing Theories and Application: 17th International Conference, ICIC 2021, Shenzhen,
China, August 12–15, 2021, Proceedings, Part II, pages 628–644. Springer, 2021.
[40] I. V. Tetko and O. Engkvist. From big data to artiﬁcial intelligence: chemoinformatics meets
new challenges. Journal of Cheminformatics, 12:1–3, 2020.
[41] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and P. S. Yu. A comprehensive survey on graph
neural networks. IEEE Transactions on Neural Networks and Learning Systems, 32(1):4–24,
2021.
[42] Z. Wu, B. Ramsundar, E. N. Feinberg, J. Gomes, C. Geniesse, A. S. Pappu, K. Leswing, and
V. Pande. MoleculeNet: a benchmark for molecular machine learning. Chemical Science,
9(2):513–530, 2018.
[43] K. Xu, W. Hu, J. Leskovec, and S. Jegelka. How powerful are graph neural networks?
In
International Conference on Learning Representations, 2019.
[44] F. Zhang, J. Zhu, R. Chiewvanichakorn, A. Shurbevski, H. Nagamochi, and T. Akutsu. A
new approach to the design of acyclic chemical compounds using skeleton trees and integer
linear programming. Applied Intelligence, 52(15):17058–17072, 2022.
[45] S. Zhang, J. S. Campos, C. Feldmann, F. Sandfort, M. Mathea, and R. Misener. Augmenting
optimization-based molecular design with graph neural networks.
Computers & Chemical
Engineering, 186:108684, 2024.
[46] S. Zhang, Y. Liu, and L. Xie. A universal framework for accurate and eﬃcient geometric deep
learning of molecular systems. Scientiﬁc Reports, 13(1):19171, 2023.
[47] J. Zhu. Novel Methods for Chemical Compound Inference Based on Machine Learning and
Mixed Integer Linear Programming. PhD thesis, Kyoto University, 9 2023.
[48] J. Zhu, N. A. Azam, S. Cao, R. Ido, K. Haraguchi, L. Zhao, H. Nagamochi, and T. Akutsu.
Quadratic descriptors and reduction methods in a two-layered model for compound inference.
Frontiers in Genetics, 15:1483490, 2025.
[49] J. Zhu, N. A. Azam, K. Haraguchi, L. Zhao, H. Nagamochi, and T. Akutsu.
An inverse
QSAR method based on linear regression and integer programming. Frontiers in Bioscience-
Landmark, 27(6):188, 2022.


--- Page 22 ---
2LMM GNN: July 8, 2025
22
[50] J. Zhu, N. A. Azam, K. Haraguchi, L. Zhao, H. Nagamochi, and T. Akutsu.
Molecular
design based on integer programming and splitting data sets by hyperplanes. IEEE/ACM
Transactions on Computational Biology and Bioinformatics, 21(5):1529–1541, 2024.
[51] J. Zhu, K. Haraguchi, H. Nagamochi, and T. Akutsu. Adjustive linear regression and its
application to the inverse QSAR. In Proceedings of the 15th International Joint Conference
on Biomedical Engineering Systems and Technologies - BIOINFORMATICS, pages 144–151.
INSTICC, SciTePress, 2022.
[52] J. Zhu, C. Wang, A. Shurbevski, H. Nagamochi, and T. Akutsu. A novel method for inference
of chemical compounds of cycle index two with desired properties based on artiﬁcial neural
networks and integer programming. Algorithms, 13(5):124, 2020.


--- Page 23 ---
2LMM GNN: July 8, 2025
23
Appendix
A
Specifying Target Chemical Graphs
In this section, we review the way of specifying target chemical graphs in the two-layered model
introduced by Zhu et al. [49], with some modiﬁcations for this work.
H H
H H
H
H H
H H
u23
a10
a12
a3
u11
a14
a4
u7
a13
a5
u9
u10
a15
a16
u1
u2
a11
a8
u6
u4
a9
a6
u8
u12
a1
a7
u5
u3
a2
(a) A seed graph GC=(VC,EC) 
(b) A set      of chemical rooted trees 
a17
: E(＞2)={a1,a2,...,a5}
: E(＞1)={a6}
: E(0/1)={a7} 
: E(=1)={a8,a9,...,a17}
- 
- 
H
y1
y3
y2
y4
y6
y5
y7
y9
y8
y11 y12
C
N
O
N
C
C
C
C
O
C
O
C
C
C
C
C
C
C
C
C
C
C
O
O
C
C
C
C
C
N
y10
O
C
C
H
H
C
C
O
H
N
N
H
O
C
C
y14
y15
y13
y17
y16
y19
y20
y18
y21
H H
C
H H
N
C
C
C
C
N
C
O-
O
S(6)
O
C
S(2)
C
N
N
C
P
O
H
P
H H
P
S(2)
S(6)
y24
y26
y28
y30
y29
y22
y23
y25
y27
+
-
+
Figure 8: (a) An illustration of a seed graph GC with r(GC) = 5 where the vertices in VC are
depicted with gray circles, the edges in E(≥2) are depicted with dotted lines, the edges in E(≥1) are
depicted with dashed lines, the edges in E(0/1) are depicted with gray bold lines and the edges in
E(=1) are depicted with black solid lines; (b) A set F = {ψ1, ψ2, . . . , ψ30} ⊆F(Dπ) of 30 chemical
rooted trees ψi, i ∈[1, 30], where the root of each tree is depicted with a gray circle, where the
hydrogens attached to non-root vertices are omitted in the ﬁgure.
Given a prediction function η and a target value y∗∈R, we call a chemical graph C∗such that
η(C∗) = y∗a target chemical graph. This section presents a set of rules for specifying topological
substructure of a target chemical graph in a ﬂexible way in Phase 2.
We ﬁrst describe how to reduce a chemical graph C = (H, α, β) into an abstract form based
on which our speciﬁcation rules will be deﬁned. To illustrate the reduction process, we use the
chemical graph C = (H, α, β) such that ⟨C⟩is given in Figure 2.
R1 Removal of all ρ-fringe-trees:
The interior Hint = (V int(C), Eint(C)) of C is obtained
by removing the non-root vertices of each ρ-fringe-trees C[u] ∈T (C), u ∈V int(C). Figure 9
illustrates the interior Hint of chemical graph C with ρ = 2 in Figure 2.
R2 Removal of some leaf paths:
We call a u, v-path Q in Hint a leaf path if vertex v is a leaf-
vertex of Hint and the degree of each internal vertex of Q in Hint is 2, where we regard that
Q is rooted at vertex u. A connected subgraph S of the interior Hint of C is called a cyclical-
base if S is obtained from H by removing the vertices in V (Qu)\{u}, u ∈X for a subset X of
interior-vertices and a set {Qu | u ∈X} of leaf u, v-paths Qu such that no two paths Qu and
Qu′ share a vertex. Figure 10(a) illustrates a cyclical-base S = Hint −S
u∈X(V (Qu) \ {u})
of the interior Hint for a set {Qu5 = (u5, u24), Qu18 = (u18, u25, u26, u27), Qu22 = (u22, u28)}
of leaf paths in Figure 9.


--- Page 24 ---
2LMM GNN: July 8, 2025
24
a10
a12
a14
a13
a15
a16
a11
a8
a9
a6
u14
u16
u13
u15
u18
u20
u17
u19
u22
u21
u11
u7 u9
u1
u2
u6
u4
u8
u12
u5
u3
u23
u10
a17
O
O
u27
u25
u24
u26
u28
Qu5
Qu18
Qu22
N
C
O
N
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
P
S(2)
S(6)
N
Figure 9: The interior Hint of chemical graph C with ⟨C⟩in Figure 2 for ρ = 2.
u23
a10
a12
a3
u11
a14
a4
u7
a13
a5
u9
u10
a15
a16
u1
u2
a11
a8
u6
u4
a9
a6
u8
u12
a1
u5
u3
a2
a17
(b) A contraction S’ of  S
(a) A cyclical-base S of  Hint
a10
a12
a14
a13
a15
a16
a11
a8
a9
a6
u14
u16
u13
u15
u18
u20
u17
u19
u22
u21
u11
u7 u9
u1
u2
u6
u4
u8
u12
u5
u3
u23
u10
a17
Pa1
Pa2
Pa3
Pa4
Pa5
N
O
N
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
C
N
O
N
C
C
C
C
C
C
C
C
C
C
S(2)
S(2)
S(6)
P
Figure 10: (a) A cyclical-base S = Hint −S
u∈{u5,u18,u22}(V (Qu) \ {u}) of the interior Hint in
Figure 9; (b) A contraction S′ of S for a pure path set P = {Pa1, Pa2, . . . , Pa5} in (a), where a new
edge obtained by contracting a pure path is depicted with a thick line.
R3 Contraction of some pure paths:
A path in S is called pure if each internal vertex of
the path is of degree 2. Choose a set P of several pure paths in S so that no two paths
share vertices except for their end-vertices. A graph S′ is called a contraction of a graph
S (with respect to P) if S′ is obtained from S by replacing each pure u, v-path with a
single edge a = uv, where S′ may contain multiple edges between the same pair of adjacent
vertices. Figure 10(b) illustrates a contraction S′ obtained from the chemical graph S by
contracting each uv-path Pa ∈P into a new edge a = uv, where a1 = u1u2, a2 = u1u3, a3 =
u4u7, a4 = u10u11 and a5 = u11u12 and P = {Pa1 = (u1, u13, u2), Pa2 = (u1, u14, u3), Pa3 =
(u4, u15, u16, u7), Pa4 = (u10, u17, u18, u19, u11), Pa5 = (u11, u20, u21, u22, u12)} of pure paths
in Figure 10(a).
We will deﬁne a set of rules so that a chemical graph can be obtained from a graph (called
a seed graph in the next section) by applying processes R3 to R1 in a reverse way. We specify
topological substructures of a target chemical graph with a tuple (GC, σint, σce) called a target
speciﬁcation deﬁned under the set of the following rules.


--- Page 25 ---
2LMM GNN: July 8, 2025
25
Seed Graph
A seed graph GC = (VC, EC) is deﬁned to be a graph (possibly with multiple edges) such that the
edge set EC consists of four sets E(≥2), E(≥1), E(0/1) and E(=1), where each of them can be empty.
A seed graph plays a role of the most abstract form S′ in R3. Figure 8(a) illustrates an example
of a seed graph GC with r(GC) = 5, where VC = {u1, u2, . . . , u12, u23}, E(≥2) = {a1, a2, . . . , a5},
E(≥1) = {a6}, E(0/1) = {a7} and E(=1) = {a8, a9, . . . , a16}.
A subdivision S of GC is a graph constructed from a seed graph GC according to the following
rules:
- Each edge e = uv ∈E(≥2) is replaced with a u, v-path Pe of length at least 2;
- Each edge e = uv ∈E(≥1) is replaced with a u, v-path Pe of length at least 1 (equivalently e is
directly used or replaced with a u, v-path Pe of length at least 2);
- Each edge e ∈E(0/1) is either used or discarded, where E(0/1) is required to be chosen as a
non-separating edge subset of E(GC) since otherwise the connectivity of a ﬁnal chemical graph
C is not guaranteed; r(C) = r(GC) −|E′| holds for a subset E′ ⊆E(0/1) of edges discarded in a
ﬁnal chemical graph C; and
- Each edge e ∈E(=1) is always used directly.
We allow a possible elimination of edges in E(0/1) as an optional rule in constructing a target
chemical graph from a seed graph, even though such an operation has not been included in the
process R3.
A subdivision S plays a role of a cyclical-base in R2.
A target chemical graph
C = (H, α, β) will contain S as a subgraph of the interior Hint of C.
Interior-speciﬁcation
A graph H∗that serves as the interior Hint of a target chemical graph C will be constructed as
follows. First construct a subdivision S of a seed graph GC by replacing each edge e = uu′ ∈
E(≥2) ∪E(≥1) with a pure u, u′-path Pe. Next construct a supergraph H∗of S by attaching a leaf
path Qv at each vertex v ∈VC or at an internal vertex v ∈V (Pe) \ {u, u′} of each pure u, u′-path
Pe for some edge e = uu′ ∈E(≥2) ∪E(≥1), where possibly Qv = (v), E(Qv) = ∅(i.e., we do not
attach any new edges to v). We introduce the following rules for specifying the size of H∗, the
length |E(Pe)| of a pure path Pe, the length |E(Qv)| of a leaf path Qv, the number of leaf paths
Qv and a bond-multiplicity of each interior-edge, where we call the set of prescribed constants an
interior-speciﬁcation σint:
- Lower and upper bounds nint
LB, nint
UB ∈Z+ on the number of interior-vertices of a target chemical
graph C.
- For each edge e = uu′ ∈E(≥2) ∪E(≥1),
a lower bound ℓLB(e) and an upper bound ℓUB(e) on the length |E(Pe)| of a pure u, u′-path
Pe. (For a notational convenience, set ℓLB(e) := 0, ℓUB(e) := 1, e ∈E(0/1) and ℓLB(e) := 1,
ℓUB(e) := 1, e ∈E(=1).)
a lower bound blLB(e) and an upper bound blUB(e) on the number of leaf paths Qv attached
at internal vertices v of a pure u, u′-path Pe.
a lower bound chLB(e) and an upper bound chUB(e) on the maximum length |E(Qv)| of a leaf
path Qv attached at an internal vertex v ∈V (Pe) \ {u, u′} of a pure u, u′-path Pe.


--- Page 26 ---
2LMM GNN: July 8, 2025
26
Table 7: Example 1 of an interior-speciﬁcation σint.
nint
LB = 20
nint
UB = 28
a1
a2
a3
a4
a5
a6
ℓLB(ai)
2
2
2
3
2
1
ℓUB(ai)
3
4
3
5
4
4
blLB(ai)
0
0
0
1
1
0
blUB(ai)
1
1
0
2
1
0
chLB(ai)
0
1
0
4
3
0
chUB(ai)
3
3
1
6
5
2
u1
u2
u3
u4
u5
u6
u7
u8
u9
u10
u11
u12
u23
blLB(ui)
0
0
0
0
0
0
0
0
0
0
0
0
0
blUB(ui)
1
1
1
1
1
0
0
0
0
0
0
0
0
chLB(ui)
0
0
0
0
1
0
0
0
0
0
0
0
0
chUB(ui)
1
0
0
0
3
0
1
1
0
1
2
4
1
a1
a2
a3
a4
a5
a6
a7
a8
a9
a10
a11
a12
a13
a14
a15
a16
a17
bd2,LB(ai)
0
0
0
1
0
0
0
0
0
0
0
1
0
0
0
0
0
bd2,UB(ai)
1
1
0
2
2
0
0
0
0
0
0
1
0
0
0
0
0
bd3,LB(ai)
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
bd3,UB(ai)
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
- For each vertex v ∈VC,
a lower bound chLB(v) and an upper bound chUB(v) on the number of leaf paths Qv attached
to v, where 0 ≤chLB(v) ≤chUB(v) ≤1.
a lower bound chLB(v) and an upper bound chUB(v) on the length |E(Qv)| of a leaf path Qv
attached to v.
- For each edge e = uu′ ∈EC, a lower bound bdm,LB(e) and an upper bound bdm,UB(e) on
the number of edges with bond-multiplicity m ∈[2, 3] in u, u′-path Pe, where we regard Pe,
e ∈E(0/1) ∪E(=1) as single edge e.
We call a graph H∗that satisﬁes an interior-speciﬁcation σint a σint-extension of GC, where
the bond-multiplicity of each edge has been determined.
Table 7 shows an example of an interior-speciﬁcation σint to the seed graph GC in Figure 8.
Figure 11 illustrates an example of an σint-extension H∗of seed graph GC in Figure 8 under
the interior-speciﬁcation σint in Table 7.
Chemical-speciﬁcation
Let H∗be a graph that serves as the interior Hint of a target chemical graph C, where the
bond-multiplicity of each edge in H∗has be determined.
Finally we introduce a set of rules
for constructing a target chemical graph C from H∗by choosing a chemical element a ∈Λ and
assigning a ρ-fringe-tree ψ to each interior-vertex v ∈V int. We introduce the following rules for
specifying the size of C, a set of chemical rooted trees that are allowed to use as ρ-fringe-trees
and lower and upper bounds on the frequency of a chemical element, a chemical symbol, and an
edge-conﬁguration, where we call the set of prescribed constants a chemical speciﬁcation σce:


--- Page 27 ---
2LMM GNN: July 8, 2025
27
a10
a12
a14
a13
a15
a16
a11
a8
a9
a6
u14
u16
u13
u15
u18
u20
u17
u19
u22
u21
u11
u7 u9
u1
u2
u6
u4
u8
u12
u5
u3
u23
u10
a17
u27
u25
u24
u26
u28
Figure 11: An illustration of a graph H∗that is obtained from the seed graph GC in Figure 8
under the interior-speciﬁcation σint in Table 7, where the vertices newly introduced by pure paths
Pai and leaf paths Qvi are depicted with white squares and circles, respectively.
- Lower and upper bounds nLB, n∗∈Z+ on the number of vertices, where nint
LB ≤nLB ≤n∗.
- Subsets F(v) ⊆F(Dπ), v ∈VC and FE ⊆F(Dπ) of chemical rooted trees ψ with ht(⟨ψ⟩) ≤ρ,
where we require that every ρ-fringe-tree C[v] rooted at a vertex v ∈VC (resp., at an internal
vertex v not in VC) in C belongs to F(v) (resp., FE). Let F∗:= FE ∪S
v∈VC F(v) and Λex
denote the set of chemical elements assigned to non-root vertices over all chemical rooted trees
in F∗.
- A subset Λint ⊆Λint(Dπ), where we require that every chemical element α(v) assigned to an
interior-vertex v in C belongs to Λint. Let Λ := Λint ∪Λex and naa(C) (resp., naint
a (C) and
naex
a (C)) denote the number of vertices (resp., interior-vertices and exterior-vertices) v such
that α(v) = a in C.
- A set Λint
dg ⊆Λ × [1, 4] of chemical symbols and a set Γint ⊆Γint(Dπ) of edge-conﬁgurations
(µ, µ′, m) with µ ≤µ′, where we require that the edge-conﬁguration ec(e) of an interior-edge e
in C belongs to Γint. We do not distinguish (µ, µ′, m) and (µ′, µ, m).
- Deﬁne Γint
ac to be the set of adjacency-conﬁgurations such that Γint
ac := {(a, b, m) | (ad, bd′, m) ∈
Γint}. Let acint
ν (C), ν ∈Γint
ac denote the number of interior-edges e such that ac(e) = ν in C.
- Subsets Λ∗(v) ⊆{a ∈Λint | val(a) ≥2}, v ∈VC, we require that every chemical element α(v)
assigned to a vertex v ∈VC in the seed graph belongs to Λ∗(v).
- Lower and upper bound functions naLB, naUB : Λ →[1, n∗] and naint
LB, naint
UB : Λint →[1, n∗] on
the number of interior-vertices v such that α(v) = a in C.
- Lower and upper bound functions fcLB, fcUB : F∗→[0, n∗] on the number of interior-vertices v
such that C[v] is r-isomorphic to ψ ∈F∗in C.
- Lower and upper bound functions aclf
LB, aclf
UB : Γlf
ac →[0, n∗] on the number of leaf-edges uv in
acC with adjacency-conﬁguration ν.
We call a chemical graph C that satisﬁes a chemical speciﬁcation σce a (σint, σce)-extension of
GC, and denote by G(GC, σint, σce) the set of all (σint, σce)-extensions of GC.
Table 8 shows an example of a chemical-speciﬁcation σce to the seed graph GC in Figure 8.


--- Page 28 ---
2LMM GNN: July 8, 2025
28
Table 8: Example 2 of a chemical-speciﬁcation σce.
nLB = 30, n∗= 50.
branch-parameter: ρ = 2
Each of sets F(v), v ∈VC and FE is set to be
the set F of chemical rooted trees ψ with ht(⟨ψ⟩) ≤ρ = 2 in Figure 8(b).
Λ = {H, C, N, O, S(2), S(6), P = P(5)}
Λint
dg = {C2, C3, C4, N2, N3, O2, S(2)2, S(6)3, P4}
Γint
ac
ν1 =(C, C, 1), ν2 =(C, C, 2), ν3=(C, N, 1), ν4=(C, O, 1), ν5=(C, S(2), 1), ν6 =(C, S(6), 1), ν7 =(C, P, 1)
Γint
γ1 =(C2, C2, 1), γ2=(C2, C3, 1), γ3=(C2, C3, 2), γ4=(C2, C4, 1), γ5=(C3, C3, 1), γ6=(C3, C3, 2),
γ7 =(C3, C4, 1), γ8=(C2, N2, 1), γ9=(C3, N2, 1), γ10=(C3, O2, 1), γ11=(C2, C2, 2), γ12=(C2, O2, 1),
γ13 =(C3, N3, 1), γ14=(C4, S(2)2, 2), γ15 =(C2, S(6)3, 1), γ16 =(C3, S(6)3, 1), γ17 =(C2, P4, 2),
γ18 =(C3, P4, 1)
Λ∗(u1) = Λ∗(u8) = {C, N}, Λ∗(u9) = {C, O}, Λ∗(u) = {C}, u ∈VC \ {u1, u8, u9}
H
C
N
O
S(2)
S(6)
P
naLB(a)
40
27
1
1
0
0
0
naUB(a)
65
37
4
8
1
1
1
C
N
O
S(2)
S(6)
P
naint
LB(a)
9
1
0
0
0
0
naint
UB(a)
23
4
5
1
1
1
ψ ∈{ψi | i = 1, 6, 11}
ψ ∈F∗\ {ψi | i = 1, 6, 11}
fcLB(ψ)
1
0
fcUB(ψ)
10
3
ν ∈{(C, C, 1), (C, C, 2)}
ν ∈Γlf
ac \ {(C, C, 1), (C, C, 2)}
aclf
LB(ν)
0
0
aclf
UB(ν)
10
8
Figure 2 illustrates an example C of a (σint, σce)-extension of GC obtained from the σint-
extension H∗in Figure 11 under the chemical-speciﬁcation σce in Table 8.
Note that r(C) =
r(H∗) = r(GC) −1 = 4 holds since the edge in E(0/1) is discarded in H∗.
B
Test Instances for Phase 2
We prepared the following instances Ii, i ∈[1, 5] for conducting experiments in Phase 2.
(1) Ii = (Gi
C, σi
int, σi
ce), i = 1, 2, 3, 4: An instance for inferring chemical graphs with rank at most
2. In the four instances Ii, i = 1, 2, 3, 4, the following speciﬁcations in (σint, σce) are common.
Set Λ := Λ(π) for a given property π ∈{Homo, Lumo, Gap}, set Λint
dg to be the set of
all possible symbols in Λ × [1, 4] that appear in the data set Dπ and set Γint to be the
set of all edge-conﬁgurations that appear in the data set Dπ. Set Λ∗(v) := Λ, v ∈VC.
The lower bounds ℓLB, blLB, chLB, bd2,LB, bd3,LB, naLB, naint
LB, nsint
LB, acint
LB, ecint
LB and
aclf
LB are all set to be 0.
The upper bounds ℓUB, blUB, chUB, bd2,UB, bd3,UB, naUB, naint
UB, nsint
UB, acint
UB, ecint
UB and
aclf
UB are all set to be an upper bound n∗on n(G∗).
For each property π, let F(Dπ) denote the set of 2-fringe-trees in the compounds in Dπ,
and select a subset Fi
π ⊆F(Dπ) with |Fi
π| = 45 −5i, i ∈[1, 5]. For each instance Ii, set
FE := F(v) := Fi
π, v ∈VC and fcLB(ψ) := 0, fcUB(ψ) := 10, ψ ∈Fi
π.


--- Page 29 ---
2LMM GNN: July 8, 2025
29
Instance I1 is given by the rank-1 seed graph G1
C in Figure 6(i) and Instances Ii, i = 2, 3, 4
are given by the rank-2 seed graph Gi
C, i = 2, 3, 4 in Figure 6(ii)-(iv).
(i) For the instance I1, select as a seed graph the monocyclic graph G1
C = (VC, EC =
E(≥2) ∪E(≥1)) in Figure 6(i), where VC = {u1, u2}, E(≥2) = {a1} and E(≥1) = {a2}.
Set nint
LB := 6, nint
UB := 8, nLB := 15 and n∗:= 20.
(ii) For the instance I2, select as a seed graph the graph G2
C = (VC, EC = E(≥2) ∪E(≥1) ∪
E(=1)) in Figure 6(ii), where VC = {u1, u2, u3, u4}, E(≥2) = {a1, a2}, E(≥1) = {a3} and
E(=1) = {a4, a5}. Set nint
LB := 6, nint
UB := 12, nLB := 10 and n∗:= 15.
(iii) For the instance I3, select as a seed graph the graph G3
C = (VC, EC = E(≥2) ∪E(≥1) ∪
E(=1)) in Figure 6(iii), where VC = {u1, u2, u3, u4}, E(≥2) = {a1}, E(≥1) = {a2, a3} and
E(=1) = {a4, a5}. Set nint
LB := 6, nint
UB := 12, nLB := 10 and n∗:= 15.
(iv) For the instance I4, select as a seed graph the graph G4
C = (VC, EC = E(≥2) ∪E(≥1) ∪
E(=1)) in Figure 6(iv), where VC = {u1, u2, u3, u4}, E(≥1) = {a1, a2, a3} and E(=1) =
{a4, a5}. Set nint
LB := 6, nint
UB := 12, nLB := 10 and n∗:= 15.
(2) I5 = (G5
C, σ5
int, σ5
ce): An instance for inferring chemical graphs resembling the molecules in
the QM9 dataset. Below is the speciﬁcation (σ5
int, σ5
ce) for I5.
Set Λ := Λ(π) for a given property π ∈{Homo, Lumo, Gap}, set Λint
dg to be the set of
all possible symbols in Λ × [1, 4] that appear in the data set Dπ and set Γint to be the
set of all edge-conﬁgurations that appear in the data set Dπ. Set Λ∗(v) := Λ, v ∈VC.
The lower bounds ℓLB, blLB, chLB, bd2,LB, bd3,LB, naLB, naint
LB, nsint
LB, acint
LB, ecint
LB and
aclf
LB are all set to be 0.
The upper bounds ℓUB, blUB, chUB, bd2,UB, bd3,UB, naUB, naint
UB, nsint
UB, acint
UB, ecint
UB and
aclf
UB are all set to be an upper bound n∗on n(G∗).
For each property π, let F(Dπ) denote the set of 2-fringe-trees in the compounds in
Dπ, and select a subset F5
π ⊆F(Dπ) with |F5
π| = 50. For each instance Ii, set FE :=
F(v) := Fi
π, v ∈VC and fcLB(ψ) := 0, fcUB(ψ) := 10, ψ ∈Fi
π.
Instance I5 is given by the seed graph G5
C in Figure 6(v).
(v) For the instance I5, select as a seed graph the graph G5
C = (VC, EC = E(≥2) ∪E(0/1))
in Figure 6(v), where VC = {u1, u2, u3}, E(≥2) = {a1, a2} and E(0/1) = {a3}.
Set
nint
LB := 3, nint
UB := 9, nLB := 3 and n∗:= 9.
C
All Constraints in an MILP Formulation for Chemical
Graphs
We deﬁne a standard encoding of a ﬁnite set A of elements to be a bijection σ : A →[1, |A|], where
we denote by [A] the set [1, |A|] of integers and by [e] the encoded element σ(e). Let ǫ denote
null, a ﬁctitious chemical element that does not belong to any set of chemical elements, chemical
symbols, adjacency-conﬁgurations and edge-conﬁgurations in the following formulation. Given a
ﬁnite set A, let Aǫ denote the set A ∪{ǫ} and deﬁne a standard encoding of Aǫ to be a bijection
σ : A →[0, |A|] such that σ(ǫ) = 0, where we denote by [Aǫ] the set [0, |A|] of integers and by [e]
the encoded element σ(e), where [ǫ] = 0.


--- Page 30 ---
2LMM GNN: July 8, 2025
30
Let σ = (GC, σint, σce) be a target speciﬁcation, ρ denote the branch-parameter in the speciﬁ-
cation σ and C denote a chemical graph in G(GC, σint, σce).
C.1
Selecting a Cyclical-base
Recall that
E(=1) = {e ∈EC | ℓLB(e) = ℓUB(e) = 1};
E(0/1) = {e ∈EC | ℓLB(e) = 0, ℓUB(e) = 1};
E(≥1) = {e ∈EC | ℓLB(e) = 1, ℓUB(e) ≥2};
E(≥2) = {e ∈EC | ℓLB(e) ≥2};
- Every edge ai ∈E(=1) is included in ⟨C⟩;
- Each edge ai ∈E(0/1) is included in ⟨C⟩if necessary;
- For each edge ai ∈E(≥2), edge ai is not included in ⟨C⟩and instead a path
Pi = (vC
tail(i), vTj−1, vTj, . . . , vTj+t, vC
head(i))
of length at least 2 from vertex vCtail(i) to vertex vChead(i) visiting some vertices in VT is
constructed in ⟨C⟩; and
- For each edge ai ∈E(≥1), either edge ai is directly used in ⟨C⟩or the above path Pi of length
at least 2 is constructed in ⟨C⟩.
Let tC ≜|VC| and denote VC by {vCi | i ∈[1, tC]}. Regard the seed graph GC as a digraph
such that each edge ai with end-vertices vCj and vCj′ is directed from vCj to vCj′ when j < j′.
For each directed edge ai ∈EC, let head(i) and tail(i) denote the head and tail of eC(i); i.e.,
ai = (vCtail(i), vChead(i)).
Deﬁne
kC ≜|E(≥2) ∪E(≥1)|,
f
kC ≜|E(≥2)|,
and denote EC = {ai | i ∈[1, mC]}, E(≥2) = {ak | k ∈[1, f
kC]}, E(≥1) = {ak | k ∈[f
kC + 1, kC]},
E(0/1) = {ai | i ∈[kC + 1, kC + |E(0/1)|]} and E(=1) = {ai | i ∈[kC + |E(0/1)| + 1, mC]}. Let I(=1)
denote the set of indices i of edges ai ∈E(=1). Similarly for I(0/1), I(≥1) and I(≥2).
To control the construction of such a path Pi for each edge ak ∈E(≥2) ∪E(≥1), we regard the
index k ∈[1, kC] of each edge ak ∈E(≥2) ∪E(≥1) as the “color” of the edge. To introduce necessary
linear constraints that can construct such a path Pk properly in our MILP, we assign the color k
to the vertices vTj−1, vTj, . . . , vTj+t in VT when the above path Pk is used in ⟨C⟩.
For each index s ∈[1, tC], let IC(s) denote the set of edges e ∈EC incident to vertex vCs, and
E+
(=1)(s) (resp., E−
(=1)(s)) denote the set of edges ai ∈E(=1) such that the tail (resp., head) of ai is
vertex vCs. Similarly for E+
(0/1)(s), E−
(0/1)(s), E+
(≥1)(s), E−
(≥1)(s), E+
(≥2)(s) and E−
(≥2)(s). Let IC(s)
denote the set of indices i of edges ai ∈IC(s). Similarly for I+
(=1)(s), I−
(=1)(s), I+
(0/1)(s), I−
(0/1)(s),
I+
(≥1)(s), I−
(≥1)(s), I+
(≥2)(s) and I−
(≥2)(s).
Note that [1, kC] = I(≥2) ∪I(≥1) and [f
kC + 1, mC] =
I(≥1) ∪I(0/1) ∪I(=1).
constants:
- tC = |VC|, f
kC = |E(≥2)|, kC = |E(≥2) ∪E(≥1)|, tT = nint
UB −|VC|, mC = |EC|.
Note that
ai ∈EC \ (E(≥2) ∪E(≥1)) holds i ∈[kC + 1, mC];
- ℓLB(k), ℓUB(k) ∈[1, tT], k ∈[1, kC]: lower and upper bounds on the length of path Pk;
- rGC ∈[1, mC]: the rank r(GC) of seed graph GC;


--- Page 31 ---
2LMM GNN: July 8, 2025
31
variables:
- eC(i) ∈[0, 1], i ∈[1, mC]: eC(i) represents edge ai ∈EC, i ∈[1, mC] (eC(i) = 1, i ∈I(=1);
eC(i) = 0, i ∈I(≥2)) (eC(i) = 1 ⇔edge ai is used in ⟨C⟩);
- vT(i) ∈[0, 1], i ∈[1, tT]: vT(i) = 1 ⇔vertex vTi is used in ⟨C⟩;
- eT(i) ∈[0, 1], i ∈[1, tT + 1]: eT(i) represents edge eTi = (vTi−1, vTi) ∈ET, where eT1 and
eTtT+1 are ﬁctitious edges (eT(i) = 1 ⇔edge eTi is used in ⟨C⟩);
- χT(i) ∈[0, kC], i ∈[1, tT]: χT(i) represents the color assigned to vertex vTi (χT(i) = k > 0 ⇔
vertex vTi is assigned color k; χT(i) = 0 means that vertex vTi is not used in ⟨C⟩);
- clrT(k) ∈[ℓLB(k) −1, ℓUB(k) −1], k ∈[1, kC], clrT(0) ∈[0, tT]: the number of vertices vTi ∈VT
with color c;
- δT
χ (k) ∈[0, 1], k ∈[0, kC]: δT
χ (k) = 1 ⇔χT(i) = k for some i ∈[1, tT];
- χT(i, k) ∈[0, 1], i ∈[1, tT], k ∈[0, kC] (χT(i, k) = 1 ⇔χT(i) = k);
- g
deg
+
C(i) ∈[0, 4], i ∈[1, tC]: the out-degree of vertex vCi with the used edges eC in EC;
- g
deg
−
C(i) ∈[0, 4], i ∈[1, tC]: the in-degree of vertex vCi with the used edges eC in EC;
- rank: the rank r(C) of a target chemical graph C;
constraints:
rank = rGC −
X
i∈I(0/1)
(1 −eC(i)),
(1)
eC(i) = 1,
i ∈I(=1),
(2)
eC(i) = 0,
clrT(i) ≥1,
i ∈I(≥2),
(3)
eC(i) + clrT(i) ≥1,
clrT(i) ≤tT · (1 −eC(i)),
i ∈I(≥1),
(4)
X
c∈I−
(≥1)(i)∪I−
(0/1)(i)∪I−
(=1)(i)
eC(c) = g
deg
−
C(i),
X
c∈I+
(≥1)(i)∪I+
(0/1)(i)∪I+
(=1)(i)
eC(c) = g
deg
+
C(i),
i ∈[1, tC],
(5)
χT(i, 0) = 1 −vT(i),
X
k∈[0,kC]
χT(i, k) = 1,
X
k∈[0,kC]
k · χT(i, k) = χT(i),
i ∈[1, tT],
(6)
X
i∈[1,tT]
χT(i, k) = clrT(k),
tT · δT
χ (k) ≥
X
i∈[1,tT]
χT(i, k) ≥δT
χ (k),
k ∈[0, kC],
(7)
vT(i −1) ≥vT(i),
kC · (vT(i −1) −eT(i)) ≥χT(i −1) −χT(i) ≥vT(i −1) −eT(i),
i ∈[2, tT].
(8)


--- Page 32 ---
2LMM GNN: July 8, 2025
32
C.2
Constraints for Including Leaf Paths
Let etC denote the number of vertices u ∈VC such that blUB(u) = 1 and assume that VC =
{u1, u2, . . . , up} so that
blUB(ui) = 1, i ∈[1, etC] and blUB(ui) = 0, i ∈[ etC + 1, tC].
Deﬁne the set of colors for the vertex set {ui | i ∈[1, etC]} ∪VT to be [1, cF] with
cF ≜etC + tT = |{ui | i ∈[1, etC]} ∪VT|.
Let each vertex vCi, i ∈[1, etC] (resp., vTi ∈VT) correspond to a color i ∈[1, cF] (resp., i + etC ∈
[1, cF]). When a path P = (u, vFj, vFj+1, . . . , vFj+t) from a vertex u ∈VC ∪VT is used in ⟨C⟩, we
assign the color i ∈[1, cF] of the vertex u to the vertices vFj, vFj+1, . . . , vFj+t ∈VF.
constants:
- cF: the maximum number of diﬀerent colors assigned to the vertices in VF;
- n∗: an upper bound on the number n(C) of non-hydrogen atoms in C;
- nint
LB, nint
UB ∈[2, n∗]: lower and upper bounds on the number of interior-vertices in C;
- blLB(i) ∈[0, 1], i ∈[1, etC]: a lower bound on the number of leaf ρ-branches in the leaf path
rooted at a vertex vCi;
- blLB(k), blUB(k) ∈[0, ℓUB(k) −1], k ∈[1, kC] = I(≥2) ∪I(≥1): lower and upper bounds on the
number of leaf ρ-branches in the trees rooted at internal vertices of a pure path Pk for an edge
ak ∈E(≥1) ∪E(≥2);
variables:
- nint
G ∈[nint
LB, nint
UB]: the number of interior-vertices in C;
- vF(i) ∈[0, 1], i ∈[1, tF]: vF(i) = 1 ⇔vertex vFi is used in C;
- eF(i) ∈[0, 1], i ∈[1, tF + 1]: eF(i) represents edge eFi = vFi−1vFi, where eF1 and eFtF+1 are
ﬁctitious edges (eF(i) = 1 ⇔edge eFi is used in C);
- χF(i) ∈[0, cF], i ∈[1, tF]: χF(i) represents the color assigned to vertex vFi (χF(i) = c ⇔vertex
vFi is assigned color c);
- clrF(c) ∈[0, tF], c ∈[0, cF]: the number of vertices vFi with color c;
- δF
χ(c) ∈[blLB(c), 1], c ∈[1, etC]: δF
χ(c) = 1 ⇔χF(i) = c for some i ∈[1, tF];
- δF
χ(c) ∈[0, 1], c ∈[ etC + 1, cF]: δF
χ(c) = 1 ⇔χF(i) = c for some i ∈[1, tF];
- χF(i, c) ∈[0, 1], i ∈[1, tF], c ∈[0, cF]: χF(i, c) = 1 ⇔χF(i) = c;
- bl(k, i) ∈[0, 1], k ∈[1, kC] = I(≥2) ∪I(≥1), i ∈[1, tT]: bl(k, i) = 1 ⇔path Pk contains vertex
vTi as an internal vertex and the ρ-fringe-tree rooted at vTi contains a leaf ρ-branch;


--- Page 33 ---
2LMM GNN: July 8, 2025
33
constraints:
χF(i, 0) = 1 −vF(i),
X
c∈[0,cF]
χF(i, c) = 1,
X
c∈[0,cF]
c · χF(i, c) = χF(i),
i ∈[1, tF],
(9)
X
i∈[1,tF]
χF(i, c) = clrF(c),
tF · δF
χ(c) ≥
X
i∈[1,tF]
χF(i, c) ≥δF
χ(c),
c ∈[0, cF],
(10)
eF(1) = eF(tF + 1) = 0,
(11)
vF(i −1) ≥vF(i),
cF · (vF(i −1) −eF(i)) ≥χF(i −1) −χF(i) ≥vF(i −1) −eF(i),
i ∈[2, tF],
(12)
bl(k, i) ≥δF
χ( etC + i) + χT(i, k) −1,
k ∈[1, kC], i ∈[1, tT],
(13)
X
k∈[1,kC],i∈[1,tT]
bl(k, i) ≤
X
i∈[1,tT]
δF
χ( etC + i),
(14)
blLB(k) ≤
X
i∈[1,tT]
bl(k, i) ≤blUB(k),
k ∈[1, kC],
(15)
tC +
X
i∈[1,tT]
vT(i) +
X
i∈[1,tF]
vF(i) = nint
G .
(16)
C.3
Constraints for Including Fringe-trees
Recall that F(Dπ) denotes the set of chemical rooted trees ψ r-isomorphic to a chemical rooted
tree in T (C) over all chemical graphs C ∈Dπ, where possibly a chemical rooted tree ψ ∈F(Dπ)
consists of a single chemical element a ∈Λ \ {H}.
To express the condition that the ρ-fringe-tree is chosen from a rooted tree Ci, Ti or Fi, we
introduce the following set of variables and constraints.
constants:
- nLB: a lower bound on the number n(C) of non-hydrogen atoms in C, where nLB, n∗≥nint
LB;
- chLB(i), chUB(i) ∈[0, n∗], i ∈[1, tT]: lower and upper bounds on ht(⟨Ti⟩) of the tree Ti rooted
at a vertex vCi;
- chLB(k), chUB(k) ∈[0, n∗], k ∈[1, kC] = I(≥2) ∪I(≥1): lower and upper bounds on the maximum
height ht(⟨T ⟩) of the tree T ∈F(Pk) rooted at an internal vertex of a path Pk for an edge
ak ∈E(≥1) ∪E(≥2);
- Prepare a coding of the set F(Dπ) and let [ψ] denote the coded integer of an element ψ in
F(Dπ);


--- Page 34 ---
2LMM GNN: July 8, 2025
34
- Sets F(v) ⊆F(Dπ), v ∈VC and FE ⊆F(Dπ) of chemical rooted trees T with ht(T ) ∈[1, ρ];
- Deﬁne F∗:= S
v∈VC F(v) ∪FE, FC
i := F(vCi), i ∈[1, tC], FT
i := FE, i ∈[1, tT] and FF
i := FE,
i ∈[1, tF];
- fcLB(ψ), fcUB(ψ) ∈[0, n∗], ψ ∈F∗: lower and upper bound functions on the number of interior-
vertices v such that C[v] is r-isomorphic to ψ in C;
- FX
i [p], p ∈[1, ρ], X ∈{C, T, F}: the set of chemical rooted trees T ∈FX
i with ht(⟨T ⟩) = p;
- nH([ψ]) ∈[0, 3ρ], ψ ∈F∗: the number n(⟨ψ⟩) of non-root hydrogen vertices in a chemical rooted
tree ψ;
- htH([ψ]) ∈[0, ρ], ψ ∈F∗: the height ht(⟨ψ⟩) of the hydrogen-suppressed chemical rooted tree
⟨ψ⟩;
- degH
r([ψ]) ∈[0, 3], ψ ∈F∗: the number degr(⟨ψ⟩) of non-hydrogen children of the root r of a
chemical rooted tree ψ;
- deghyd
r
([ψ]) ∈[0, 3], ψ ∈F∗: the number degr(ψ) −degr(⟨ψ⟩) of hydrogen children of the root r
of a chemical rooted tree ψ;
- vion(ψ) ∈[−3, +3], ψ ∈F∗: the ion-valence of the root in ψ;
- aclf
ν (ψ), ν ∈Γlf
ac: the frequency of leaf-edges with adjacency-conﬁguration ν in ψ;
- aclf
LB, aclf
UB : Γlf
ac →[0, n∗]: lower and upper bound functions on the number of leaf-edges uv in
acC with adjacency-conﬁguration ν;
variables:
- nG ∈[nLB, n∗]: the number n(C) of non-hydrogen atoms in C;
- vX(i) ∈[0, 1], i ∈[1, tX], X ∈{T, F}: vX(i) = 1 ⇔vertex vXi is used in C;
- δX
fr(i, [ψ]) ∈[0, 1], i ∈[1, tX], ψ ∈FX
i , X ∈{C, T, F}: δX
fr(i, [ψ]) = 1 ⇔ψ is the ρ-fringe-tree
rooted at vertex vXi in C;
- fc([ψ]) ∈[fcLB(ψ), fcUB(ψ)], ψ ∈F∗: the number of interior-vertices v such that C[v] is r-
isomorphic to ψ in C;
- aclf([ν]) ∈[aclf
LB(ν), aclf
UB(ν)], ν ∈Γlf
ac: the number of leaf-edge with adjacency-conﬁguration ν
in C;
- degex
X (i) ∈[0, 3], i ∈[1, tX], X ∈{C, T, F}: the number of non-hydrogen children of the root of
the ρ-fringe-tree rooted at vertex vXi in C;
- hyddegX(i) ∈[0, 4], i ∈[1, tX], X ∈{C, T, F}: the number of hydrogen atoms adjacent to vertex
vXi (i.e., hyddeg(vXi)) in C = (H, α, β);
- eledegX(i) ∈[−3, +3], i ∈[1, tX], X ∈{C, T, F}: the ion-valence vion(ψ) of vertex vXi (i.e.,
eledegX(i) = vion(ψ) for the ρ-fringe-tree ψ rooted at vXi) in C = (H, α, β);
- hX(i) ∈[0, ρ], i ∈[1, tX], X ∈{C, T, F}: the height ht(⟨T ⟩) of the hydrogen-suppressed chemical
rooted tree ⟨T ⟩of the ρ-fringe-tree T rooted at vertex vXi in C;


--- Page 35 ---
2LMM GNN: July 8, 2025
35
- σ(k, i) ∈[0, 1], k ∈[1, kC] = I(≥2) ∪I(≥1), i ∈[1, tT]: σ(k, i) = 1 ⇔the ρ-fringe-tree Tv rooted
at vertex v = vTi with color k has the largest height ht(⟨Tv⟩) among such trees Tv, v ∈VT;
constraints:
X
ψ∈F C
i
δC
fr(i, [ψ]) = 1,
i ∈[1, tC],
X
ψ∈F X
i
δX
fr(i, [ψ]) = vX(i),
i ∈[1, tX], X ∈{T, F},
(17)
X
ψ∈F X
i
degH
r([ψ]) · δX
fr(i, [ψ]) = degex
X (i),
X
ψ∈F X
i
deghyd
r
([ψ]) · δX
fr(i, [ψ]) = hyddegX(i),
X
ψ∈F X
i
vion([ψ]) · δX
fr(i, [ψ]) = eledegX(i),
i ∈[1, tX], X ∈{C, T, F},
(18)
X
ψ∈F F
i [ρ]
δF
fr(i, [ψ]) ≥vF(i) −eF(i + 1),
i ∈[1, tF] (eF(tF + 1) = 0),
(19)
X
ψ∈F X
i
htH([ψ]) · δX
fr(i, [ψ]) = hX(i),
i ∈[1, tX], X ∈{C, T, F},
(20)
X
ψ∈F X
i
i∈[1,tX],X∈{C,T,F}
nH([ψ]) · δX
fr(i, [ψ]) +
X
i∈[1,tX],X∈{T,F}
vX(i) + tC = nG,
(21)
X
i∈[1,tX],X∈{C,T,F}
δX
fr(i, [ψ]) = fc([ψ]),
ψ ∈F∗,
(22)
X
ψ∈F X
i ,i∈[1,tX],X∈{C,T,F}
aclf
ν (ψ) · δX
fr(i, [ψ]) = aclf([ν]),
ν ∈Γlf
ac,
(23)
hC(i) ≥chLB(i) −n∗· δF
χ(i),
clrF(i) + ρ ≥chLB(i),
hC(i) ≤chUB(i),
clrF(i) + ρ ≤chUB(i) + n∗· (1 −δF
χ(i)),
i ∈[1, etC],
(24)
chLB(i) ≤hC(i) ≤chUB(i),
i ∈[ etC + 1, tC],
(25)
hT(i) ≤chUB(k) + n∗· (δF
χ( etC + i) + 1 −χT(i, k)),
clrF( etC + i) + ρ ≤chUB(k) + n∗· (2 −δF
χ( etC + i) −χT(i, k)),
k ∈[1, kC], i ∈[1, tT],
(26)


--- Page 36 ---
2LMM GNN: July 8, 2025
36
X
i∈[1,tT]
σ(k, i) = δT
χ (k),
k ∈[1, kC],
(27)
χT(i, k) ≥σ(k, i),
hT(i) ≥chLB(k) −n∗· (δF
χ( etC + i) + 1 −σ(k, i)),
clrF( etC + i) + ρ ≥chLB(k) −n∗· (2 −δF
χ( etC + i) −σ(k, i)),
k ∈[1, kC], i ∈[1, tT].
(28)
C.4
Descriptor for the Number of Speciﬁed Degree
We include constraints to compute descriptors for degrees in C.
variables:
- degX(i) ∈[0, 4], i ∈[1, tX], X ∈{C, T, F}: the number of non-hydrogen atoms adjacent to
vertex v = vXi (i.e., deg⟨C⟩(v) = degH(v) −hyddegC(v)) in C = (H, α, β);
- degCT(i) ∈[0, 4], i ∈[1, tC]: the number of edges from vertex vCi to vertices vTj, j ∈[1, tT];
- degTC(i) ∈[0, 4], i ∈[1, tC]: the number of edges from vertices vTj, j ∈[1, tT] to vertex vCi;
- δC
dg(i, d) ∈[0, 1], i ∈[1, tC], d ∈[1, 4], δX
dg(i, d) ∈[0, 1], i ∈[1, tX], d ∈[0, 4], X ∈{T, F}:
δX
dg(i, d) = 1 ⇔degX(i) + hyddegX(i) = d;
- dg(d) ∈[dgLB(d), dgUB(d)], d ∈[1, 4]: the number of interior-vertices v with degH(vXi) = d in
C = (H, α, β);
- degint
C (i) ∈[1, 4], i ∈[1, tC], degint
X (i) ∈[0, 4], i ∈[1, tX], X ∈{T, F}: the interior-degree
degHint(vXi) in the interior Hint = (V int(C), Eint(C)) of C; i.e., the number of interior-edges
incident to vertex vXi;
- δint
dg,C(i, d) ∈[0, 1], i ∈[1, tC], d ∈[1, 4], δint
dg,X(i, d) ∈[0, 1], i ∈[1, tX], d ∈[0, 4], X ∈{T, F}:
δint
dg,X(i, d) = 1 ⇔degint
X (i) = d;
- dgint(d) ∈[dgLB(d), dgUB(d)], d ∈[1, 4]: the number of interior-vertices v with the interior-
degree degHint(v) = d in the interior Hint = (V int(C), Eint(C)) of C = (H, α, β).
constraints:
X
k∈I+
(≥2)(i)∪I+
(≥1)(i)
δT
χ (k) = degCT(i),
X
k∈I−
(≥2)(i)∪I−
(≥1)(i)
δT
χ (k) = degTC(i),
i ∈[1, tC],
(29)
g
deg
−
C(i) + g
deg
+
C(i) + degCT(i) + degTC(i) + δF
χ(i) = degint
C (i),
i ∈[1, etC],
(30)
g
deg
−
C(i) + g
deg
+
C(i) + degCT(i) + degTC(i) = degint
C (i),
i ∈[ etC + 1, tC],
(31)


--- Page 37 ---
2LMM GNN: July 8, 2025
37
degint
C (i) + degex
C (i) = degC(i),
i ∈[1, tC],
(32)
X
ψ∈F C
i [ρ]
δC
fr(i, [ψ]) ≥2 −degint
C (i)
i ∈[1, tC],
(33)
2vT(i) + δF
χ( etC + i) = degint
T (i),
degint
T (i) + degex
T (i) = degT(i),
i ∈[1, tT] (eT(1) = eT(tT + 1) = 0),
(34)
vF(i) + eF(i + 1) = degint
F (i),
degint
F (i) + degex
F (i) = degF(i),
i ∈[1, tF] (eF(1) = eF(tF + 1) = 0),
(35)
X
d∈[0,4]
δX
dg(i, d) = 1,
X
d∈[1,4]
d · δX
dg(i, d) = degX(i) + hyddegX(i),
X
d∈[0,4]
δint
dg,X(i, d) = 1,
X
d∈[1,4]
d · δint
dg,X(i, d) = degint
X (i),
i ∈[1, tX], X ∈{T, C, F},
(36)
X
i∈[1,tC]
δC
dg(i, d) +
X
i∈[1,tT]
δT
dg(i, d) +
X
i∈[1,tF]
δF
dg(i, d) = dg(d),
X
i∈[1,tC]
δint
dg,C(i, d) +
X
i∈[1,tT]
δint
dg,T(i, d) +
X
i∈[1,tF]
δint
dg,F(i, d) = dgint(d),
d ∈[1, 4].
(37)
C.5
Assigning Multiplicity
We prepare an integer variable β(e) for each edge e in the scheme graph SG to denote the bond-
multiplicity of e in a selected graph H and include necessary constraints for the variables to satisfy
in H.
constants:
- βr([ψ]): the sum βψ(r) of bond-multiplicities of edges incident to the root r of a chemical rooted
tree ψ ∈F∗;
variables:
- βX(i) ∈[0, 3], i ∈[2, tX], X ∈{T, F}: the bond-multiplicity of edge eXi in C;
- βC(i) ∈[0, 3], i ∈[f
kC + 1, mC] = I(≥1) ∪I(0/1) ∪I(=1): the bond-multiplicity of edge ai ∈
E(≥1) ∪E(0/1) ∪E(=1) in C;
- βCT(k), βTC(k) ∈[0, 3], k ∈[1, kC] = I(≥2) ∪I(≥1): the bond-multiplicity of the ﬁrst (resp., last)
edge of the pure path Pk in C;
- β∗F(c) ∈[0, 3], c ∈[1, cF = etC + tT]: the bond-multiplicity of the ﬁrst edge of the leaf path Qc
rooted at vertex vCc, c ≤etC or vT
c−f
tC, c > etC in C;


--- Page 38 ---
2LMM GNN: July 8, 2025
38
- βX
ex(i) ∈[0, 4], i ∈[1, tX], X ∈{C, T, F}: the sum βC[v](v) of bond-multiplicities of edges in the
ρ-fringe-tree C[v] rooted at interior-vertex v = vXi;
- δX
β (i, m) ∈[0, 1], i ∈[2, tX], m ∈[0, 3], X ∈{T, F}: δX
β (i, m) = 1 ⇔βX(i) = m;
- δC
β (i, m) ∈[0, 1], i ∈[f
kC, mC] = I(≥1) ∪I(0/1) ∪I(=1), m ∈[0, 3]: δC
β (i, m) = 1 ⇔βC(i) = m;
- δCT
β (k, m), δTC
β (k, m) ∈[0, 1], k ∈[1, kC] = I(≥2) ∪I(≥1), m ∈[0, 3]: δCT
β (k, m) = 1 (resp.,
δTC
β (k, m) = 1) ⇔βCT(k) = m (resp., βTC(k) = m);
- δ∗F
β (c, m) ∈[0, 1], c ∈[1, cF], m ∈[0, 3], X ∈{C, T}: δ∗F
β (c, m) = 1 ⇔β∗F(c) = m;
- bdint(m) ∈[0, 2nint
UB], m ∈[1, 3]: the number of interior-edges with bond-multiplicity m in C;
- bdX(m) ∈[0, 2nint
UB], X ∈{C, T, CT, TC}, bdX(m) ∈[0, 2nint
UB], X ∈{F, CF, TF}, m ∈[1, 3]: the
number of interior-edges e ∈EX with bond-multiplicity m in C;
constraints:
eC(i) ≤βC(i) ≤3eC(i), i ∈[f
kC + 1, mC] = I(≥1) ∪I(0/1) ∪I(=1),
(38)
eX(i) ≤βX(i) ≤3eX(i),
i ∈[2, tX], X ∈{T, F},
(39)
δT
χ (k) ≤βCT(k) ≤3δT
χ (k),
δT
χ (k) ≤βTC(k) ≤3δT
χ (k),
k ∈[1, kC],
(40)
δF
χ(c) ≤βXF(c) ≤3δF
χ(c),
c ∈[1, cF],
(41)
X
m∈[0,3]
δX
β (i, m) = 1,
X
m∈[0,3]
m · δX
β (i, m) = βX(i),
i ∈[2, tX], X ∈{T, F},
(42)
X
m∈[0,3]
δC
β (i, m) = 1,
X
m∈[0,3]
m · δC
β (i, m) = βC(i),
i ∈[f
kC + 1, mC],
(43)
X
m∈[0,3]
δCT
β (k, m) = 1,
X
m∈[0,3]
m · δCT
β (k, m) = βCT(k),
k ∈[1, kC],
X
m∈[0,3]
δTC
β (k, m) = 1,
X
m∈[0,3]
m · δTC
β (k, m) = βTC(k),
k ∈[1, kC],
X
m∈[0,3]
δ∗F
β (c, m) = 1,
X
m∈[0,3]
m · δ∗F
β (c, m) = β∗F(c),
c ∈[1, cF],
(44)
X
ψ∈F X
i
βr([ψ]) · δX
fr(i, [ψ]) = βX
ex(i),
i ∈[1, tX], X ∈{C, T, F},
(45)


--- Page 39 ---
2LMM GNN: July 8, 2025
39
X
i∈[f
kC+1,mC]
δC
β (i, m) = bdC(m),
X
i∈[2,tT]
δT
β (i, m) = bdT(m),
X
k∈[1,kC]
δCT
β (k, m) = bdCT(m),
X
k∈[1,kC]
δTC
β (k, m) = bdTC(m),
X
i∈[2,tF]
δF
β(i, m) = bdF(m),
X
c∈[1,f
tC]
δ∗F
β (c, m) = bdCF(m),
X
c∈[f
tC+1,cF]
δ∗F
β (c, m) = bdTF(m),
bdC(m) + bdT(m) + bdF(m) + bdCT(m) + bdTC(m) + bdTF(m) + bdCF(m) = bdint(m),
m ∈[1, 3].
(46)
C.6
Assigning Chemical Elements and Valence Condition
We include constraints so that each vertex v in a selected graph H satisﬁes the valence condition;
i.e., βC(v) = val(α(v)) + eledegC(v), where eledegC(v) = vion(ψ) for the ρ-fringe-tree C[v] r-
isomorphic to ψ. With these constraints, a chemical graph C = (H, α, β) on a selected subgraph
H will be constructed.
constants:
- Subsets Λint ⊆Λ \ {H}, Λex ⊆Λ of chemical elements, where we denote by [e] (resp., [e]int and
[e]ex) of a standard encoding of an element e in the set Λ (resp., Λint
ǫ
and Λex
ǫ );
- A valence function: val : Λ →[1, 6];
- A function mass∗: Λ →Z (we let mass(a) denote the observed mass of a chemical element
a ∈Λ, and deﬁne mass∗(a) ≜⌊10 · mass(a)⌋);
- Subsets Λ∗(i) ⊆Λint, i ∈[1, tC];
- naLB(a), naUB(a) ∈[0, n∗], a ∈Λ: lower and upper bounds on the number of vertices v with
α(v) = a;
- naint
LB(a), naint
UB(a) ∈[0, n∗], a ∈Λint: lower and upper bounds on the number of interior-vertices
v with α(v) = a;
- αr([ψ]) ∈[Λex], ∈F∗: the chemical element α(r) of the root r of ψ;
- naex
a ([ψ]) ∈[0, n∗], a ∈Λex, ψ ∈F∗: the frequency of chemical element a in the set of non-rooted
vertices in ψ, where possibly a = H;
- M: an upper bound for the average ms(C) of mass∗over all atoms in C;
variables:
- βCT(i), βTC(i) ∈[0, 3], i ∈[1, tT]: the bond-multiplicity of edge eCTj,i (resp., eTCj,i) if one
exists;
- βCF(i), βTF(i) ∈[0, 3], i ∈[1, tF]: the bond-multiplicity of eCFj,i (resp., eTFj,i) if one exists;


--- Page 40 ---
2LMM GNN: July 8, 2025
40
- αX(i) ∈[Λint
ǫ ], δX
α (i, [a]int) ∈[0, 1], a ∈Λint
ǫ , i ∈[1, tX], X ∈{C, T, F}: αX(i) = [a]int ≥1 (resp.,
αX(i) = 0) ⇔δX
α (i, [a]int) = 1 (resp., δX
α (i, 0) = 0) ⇔α(vXi) = a ∈Λ (resp., vertex vXi is not
used in C);
- δX
α (i, [a]int) ∈[0, 1], i ∈[1, tX], a ∈Λint, X ∈{C, T, F}: δX
α (i, [a]t) = 1 ⇔α(vXi) = a;
- Mass ∈Z+: P
v∈V (H) mass∗(α(v));
- ms ∈R+: P
v∈V (H) mass∗(α(v))/|V (H)|;
- δatm(i) ∈[0, 1], i ∈[nLB + naLB(H), n∗+ naUB(H)]: δatm(i) = 1 ⇔|V (H)| = i;
- na([a]) ∈[naLB(a), naUB(a)], a ∈Λ: the number of vertices v ∈V (H) with α(v) = a, where
possibly a = H;
- naint([a]int) ∈[naint
LB(a), naint
UB(a)], a ∈Λ, X ∈{C, T, F}: the number of interior-vertices v ∈
V (C) with α(v) = a;
- naex
X ([a]ex), naex([a]ex) ∈[0, naUB(a)], a ∈Λ, X ∈{C, T, F}: the number of exterior-vertices
rooted at vertices v ∈VX and the number of exterior-vertices v such that α(v) = a;
constraints:
βCT(k) −3(eT(i) −χT(i, k) + 1) ≤βCT(i) ≤βCT(k) + 3(eT(i) −χT(i, k) + 1), i ∈[1, tT],
βTC(k) −3(eT(i + 1) −χT(i, k) + 1) ≤βTC(i) ≤βTC(k) + 3(eT(i + 1) −χT(i, k) + 1), i ∈[1, tT],
k ∈[1, kC],
(47)
β∗F(c) −3(eF(i) −χF(i, c) + 1) ≤βCF(i) ≤β∗F(c) + 3(eF(i) −χF(i, c) + 1), i ∈[1, tF],
c ∈[1, etC],
β∗F(c) −3(eF(i) −χF(i, c) + 1) ≤βTF(i) ≤β∗F(c) + 3(eF(i) −χF(i, c) + 1), i ∈[1, tF],
c ∈[ etC + 1, cF],
(48)
X
a∈Λint
δC
α(i, [a]int) = 1,
X
a∈Λint
[a]int · δX
α (i, [a]int) = αC(i),
i ∈[1, tC],
X
a∈Λint
δX
α (i, [a]int) = vX(i),
X
a∈Λint
[a]int · δX
α (i, [a]int) = αX(i),
i ∈[1, tX], X ∈{T, F},
(49)
X
ψ∈F X
i
αr([ψ]) · δX
fr(i, [ψ]) = αX(i),
i ∈[1, tX], X ∈{C, T, F},
(50)
X
j∈IC(i)
βC(j) +
X
k∈I+
(≥2)(i)∪I+
(≥1)(i)
βCT(k) +
X
k∈I−
(≥2)(i)∪I−
(≥1)(i)
βTC(k)
+β∗F(i) + βC
ex(i) −eledegC(i) =
X
a∈Λint
val(a)δC
α(i, [a]int),
i ∈[1, etC],
(51)


--- Page 41 ---
2LMM GNN: July 8, 2025
41
X
j∈IC(i)
βC(j) +
X
k∈I+
(≥2)(i)∪I+
(≥1)(i)
βCT(k) +
X
k∈I−
(≥2)(i)∪I−
(≥1)(i)
βTC(k)
+βC
ex(i) −eledegC(i) =
X
a∈Λint
val(a)δC
α(i, [a]int),
i ∈[ etC + 1, tC],
(52)
βT(i) + βT(i+1) + βT
ex(i) + βCT(i) + βTC(i)
+β∗F( etC + i) −eledegT(i) =
X
a∈Λint
val(a)δT
α(i, [a]int),
i ∈[1, tT] (βT(1) = βT(tT + 1) = 0),
(53)
βF(i) + βF(i+1) + βCF(i) + βTF(i)
+βF
ex(i) −eledegF(i) =
X
a∈Λint
val(a)δF
α(i, [a]int),
i ∈[1, tF] (βF(1) = βF(tF + 1) = 0),
(54)
X
i∈[1,tX]
δX
α (i, [a]int) = naX([a]int),
a ∈Λint, X ∈{C, T, F},
(55)
X
ψ∈F X
i ,i∈[1,tX]
naex
a ([ψ]) · δX
fr(i, [ψ]) = naex
X ([a]ex),
a ∈Λex, X ∈{C, T, F},
(56)
naC([a]int) + naT([a]int) + naF([a]int) = naint([a]int),
a ∈Λint,
X
X∈{C,T,F}
naex
X ([a]ex) = naex([a]ex),
a ∈Λex,
naint([a]int) + naex([a]ex) = na([a]),
a ∈Λint ∩Λex,
naint([a]int) = na([a]),
a ∈Λint \ Λex,
naex([a]ex) = na([a]),
a ∈Λex \ Λint,
(57)
X
a∈Λ∗(i)
δC
α(i, [a]int) = 1,
i ∈[1, tC],
(58)
X
a∈Λ
mass∗(a) · na([a]) = Mass,
(59)
X
i∈[nLB+naLB(H),n∗+naUB(H)]
δatm(i) = 1,
(60)
X
i∈[nLB+naLB(H),n∗+naUB(H)]
i · δatm(i) = nG + naex([H]ex),
(61)
Mass/i −M · (1 −δatm(i)) ≤ms ≤Mass/i + M · (1 −δatm(i)),
i ∈[nLB + naLB(H), n∗+ naUB(H)].
(62)


--- Page 42 ---
2LMM GNN: July 8, 2025
42
C.7
Constraints for Bounds on the Number of Bonds
We include constraints for speciﬁcation of lower and upper bounds bdLB and bdUB.
constants:
- bdm,LB(i), bdm,UB(i) ∈[0, nint
UB], i ∈[1, mC], m ∈[2, 3]: lower and upper bounds on the number
of edges e ∈E(Pi) with bond-multiplicity β(e) = m in the pure path Pi for edge ei ∈EC;
variables :
- bdT(k, i, m) ∈[0, 1], k ∈[1, kC], i ∈[2, tT], m ∈[2, 3]: bdT(k, i, m) = 1 ⇔the pure path Pk for
edge ek ∈EC contains edge eTi with β(eTi) = m;
constraints:
bdm,LB(i) ≤δC
β (i, m) ≤bdm,UB(i), i ∈I(=1) ∪I(0/1), m ∈[2, 3],
(63)
bdT(k, i, m) ≥δT
β (i, m) + χT(i, k) −1,
k ∈[1, kC], i ∈[2, tT], m ∈[2, 3],
(64)
X
j∈[2,tT]
δT
β (j, m) ≥
X
k∈[1,kC],i∈[2,tT]
bdT(k, i, m),
m ∈[2, 3],
(65)
bdm,LB(k) ≤
X
i∈[2,tT]
bdT(k, i, m) + δCT
β (k, m) + δTC
β (k, m) ≤bdm,UB(k),
k ∈[1, kC], m ∈[2, 3].
(66)
C.8
Constraints for 2L-GNN
Recall that the node feature vector θ(0)
v
for each interior-vertex v = vXi, i ∈[1, tX], X ∈{C,T,F}
consists of the following Knode = 15 entries, where a ρ-fringe-tree ψ is encoded into a KF(= 8)-
dimension real vector.
- δX
α (i, [C]int) ∈[0, 1], i ∈[1, tX], X ∈{C,T,F};
- δX
α (i, [O]int) ∈[0, 1], i ∈[1, tX], X ∈{C,T,F};
- δX
α (i, [N]int) ∈[0, 1], i ∈[1, tX], X ∈{C,T,F};
- dgX(i) + hyddegX(i), i ∈[1, tX], X ∈{C,T,F};
- P
a∈Λint val(a)δX
α (i, [a]int) + eledegX(i), i ∈[1, tX], X ∈{C,T,F}
- hyddegX(i), i ∈[1, tX], X ∈{C,T,F};
- eledegX(i), i ∈[1, tX], X ∈{C,T,F};
- θψ(·, [ψ]) ∈RKF : the encoded feature vector of the ρ-fringe-tree ψ.


--- Page 43 ---
2LMM GNN: July 8, 2025
43
constants:
κ = 0.1, the parameter used for the LeakyReLU activation function;
Let I+
a (i) ≜I+
(≥1)(i) ∪I+
(0/1)(i) ∪I+
(=1)(i) and I−
a (i) ≜I−
(≥1)(i) ∪I−
(0/1)(i) ∪I−
(=1)(i) ;
Let I+
b (i) ≜I+
(≥2)(i) ∪I+
(≥1)(i) and I−
b (i) ≜I−
(≥2)(i) ∪I−
(≥1)(i) ;
Let N +
a (i) denote the set of indices i of the tails vCj of edges in (vCj, vCi) ∈E(≥1)∪E(0/1)∪E(=1)
and N −
a (i) denote the set of indices i of the heads vCj of edges (vCi, vCj) ∈E(≥1) ∪E(0/1) ∪E(=1);
Knode, Khid, L, KC ∈Z+;
w0(i, j) ∈R, i ∈[1, Knode], j ∈[1, Khid], ℓ∈[1, L −1];
wℓ(i, j) ∈R, i, j ∈[1, Khid], ℓ∈[1, L −1];
wC(i, j) ∈R, i ∈[1, Khid], j ∈[1, KC];
bias(z; ℓ) ∈R, z ∈[1, Khid], ℓ∈[0, L −1];
Mℓ∈R+, ℓ∈[0, L]: An upper bound on the maximum value θmax(z, ℓ) of entry z in the ℓ-th
layer over all training data Dπ.
variables:
(In order to improve the readability, we will sometimes use θ(v, z) instead of θv(z).)
θC(p) ∈R, p ∈[1, KC]: the p-th entry of a representation vector θC ∈RKC; τC(p) ∈R, δτ
C(p) ∈
{0, 1}, p ∈[1, KC];
θC(0; z; ℓ) ∈R, i ∈[1, tC], z ∈[1, Knode]: the z-th entry of vector θ(ℓ)
v
of vertex v = vCi in the
0-th layer;
θT(0; z; ℓ) ∈R, i ∈[0, tT + 1], z ∈[1, Knode]: the z-th entry of vector θ(ℓ)
v
of vertex v = vTi in
the 0-th layer, where vTi may be not used in a target chemical graph;
θF(0; z; ℓ) ∈R, i ∈[0, tF + 1], z ∈[1, Knode]: the z-th entry of vector θ(ℓ)
v
of vertex v = vFi in
the 0-th layer, where vFi may be not used in a target chemical graph;
θC(i; z; ℓ) ∈R, i ∈[1, tC], z ∈[1, Khid], ℓ∈[1, L]: the z-th entry of vector θ(ℓ)
v
of vertex v = vCi
in the ℓ-th layer; τC(i; z; ℓ) ∈R, δτ
C(i; z; ℓ) ∈{0, 1}, i ∈[1, tC], z ∈[1, Khid], ℓ∈[1, L];
θT(i; z; ℓ) ∈R, i ∈[0, tT + 1], z ∈[1, Khid], ℓ∈[1, L]: the z-th entry of vector θ(ℓ)
v
of vertex
v = vTi in the ℓ-th layer, where vTi may be not used in a target chemical graph; τ T(i; z; ℓ) ∈
R, δτ
T(i; z; ℓ) ∈{0, 1}, i ∈[0, tT + 1], z ∈[1, Khid], ℓ∈[1, L];
θF(i; z; ℓ) ∈R, i ∈[0, tF + 1], z ∈[1, Khid], ℓ∈[1, L]: the z-th entry of vector θ(ℓ)
v
of vertex
v = vFi in the ℓ-th layer, where vFi may be not used in a target chemical graph; τF(i; z; ℓ) ∈
R, δτ
F(i; z; ℓ) ∈{0, 1}, i ∈[0, tF + 1], z ∈[1, Khid], ℓ∈[1, L];
θC
−(k; z; ℓ), θC
+(k; z; ℓ) ∈R, k ∈[f
kC + 1, mC], z ∈[1, Khid], ℓ∈[0, L −1]: the z-th entry of vector
θ(ℓ)
v
of the head and tail v of edge ak ∈E(≥1) ∪E(0/1) ∪E(=1), where ak ∈E(≥1) ∪E(0/1) may be
not used in a target chemical graph;
θT
−(i; z; ℓ), θT
+(i; z; ℓ) ∈R, i ∈[1, tT + 1], z ∈[1, Khid], ℓ∈[0, L −1]: the value to
P
z′∈[1,Knode] wℓ(z′, z)θ(ℓ)(vTi, z′)) for edge e = eTi (resp., edge e = eTi+1), where such an edge
e ∈ET may be not used in a target chemical graph;
θF
−(i; z; ℓ), θF
+(i; z; ℓ) ∈R, i ∈[1, tF + 1], z ∈[1, Khid], ℓ∈[0, L −1]: the value to
P
z′∈[1,Knode] wℓ(z′, z)θ(ℓ)(vFi, z′)) for edge e = eFi (resp., edge e = eFi+1), where such an edge
e ∈EF may be not used in a target chemical graph;
θCT
T (k; z; ℓ), θTC
T (k; z; ℓ) ∈R, k ∈[1, kC], z ∈[1, Khid], ℓ∈[0, L −1]: the value to
P
z′∈[1,Knode] wℓ(z′, z)θ(ℓ)(v, z′) for the edge (u = vCj, v = vTi) ∈ECT (resp., (v = vTi, u = vCj) ∈
ETC and (v = vTi, u = vFj) ∈ETF), where such an edge uv may be not used in a target chemical
graph;
θCT
C (i; z; ℓ), θTC
C (i; z; ℓ), θTF
F (i; z; ℓ) ∈R, i ∈[1, tT], z ∈[1, Khid], ℓ∈[0, L −1]: the value to
P
z′∈[1,Knode] wℓ(z′, z)θ(ℓ)(u, z′) for the edge (u = vCj, v = vTi) ∈ECT (resp., (v = vTi, u = vCj) ∈


--- Page 44 ---
2LMM GNN: July 8, 2025
44
ETC and (v = vTi, u = vFj) ∈ETF), where such an edge uv may be not used in a target chemical
graph;
θCF
F (c; z; ℓ) ∈R, c ∈[1, etC], z ∈[1, Khid], ℓ∈[0, L −1]: the value to
P
z′∈[1,Knode] wℓ(z′, z)θ(ℓ)(u, z′) for the edge (v = vCc, u = vFi) ∈ECF, where such an edge uv may
be not used in a target chemical graph;
θCF
C (i; z; ℓ), θTF
T (i; z; ℓ) ∈R, i ∈[1, tF], z ∈[1, Khid], ℓ∈[0, L −1]: the value to
P
z′∈[1,Knode] wℓ(z′, z)θ(ℓ)(u, z′) for the edge (u = vCj, v = vFi) ∈ECF (resp., (v = vTj, u = vFi) ∈
ETF), where such an edge uv may be not used in a target chemical graph;
constraints:
Initializing vectors θ(0)(v):
θX(i; 1; 0) = δX
α (i; [C]int),
θX(i; 2; 0) = δX
α (i; [O]int),
θX(i; 3; 0) = δX
α (i; [N]int),
θX(i; 4; 0) = dgX(i) + hyddegX(i),
θX(i; 5; 0) =
X
a∈Λint
val(a)δX
α (i, [a]int) + eledegX(i),
θX(i; 6; 0) = hyddegX(i),
θX(i; 7; 0) = eledegX(i),
i ∈[1, tX], X ∈{C,T,F}
θX(i; j; 0) =
X
ψ∈F X
i
δX
fr(i, [ψ])θψ(j −7; [ψ])
i ∈[1, tX], j ∈[8, Knode], X ∈{C,T,F}
(67)
We denote the function h such that h(ℓ) := Knode when ℓ= 0 and h(ℓ) := Khid otherwise in
order to simplify the formulations.
Calculating the (ℓ+ 1)-th vector from the ℓ-th vecctor:
−Mℓ+1 ≤
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θC(i; z′; ℓ) +
X
k∈I−
a (i)
θC
−(k; z; ℓ) +
X
k∈I+
a (i)
θC
+(k; z; ℓ)
+
X
k∈I+
b (i)
θCT
T (k; z; ℓ) +
X
k∈I−
b (i)
θTC
T (k; z; ℓ) + θCF
F (i; z; ℓ) + bias(z; ℓ) = τ C(i; z; ℓ+ 1) ≤Mℓ+1,
−Mℓ+1δτ
C(i; z; ℓ+ 1) ≤θC(i; z; ℓ+ 1) −κτ C(i; z; ℓ+ 1) ≤Mℓ+1δτ
C(i; z; ℓ+ 1),
−Mℓ+1(1 −δτ
C(i; z; ℓ+ 1)) ≤θC(i; z; ℓ+ 1) −τ C(i; z; ℓ+ 1) ≤Mℓ+1(1 −δτ
C(i; z; ℓ+ 1)),
−Mℓ+1δτ
C(i; z; ℓ+ 1) ≤τ C(i; z; ℓ+ 1) ≤Mℓ+1(1 −δτ
C(i; z; ℓ+ 1)),
z ∈[1, Khid], ℓ∈[0, L −1], i ∈[1, etC],
(68)


--- Page 45 ---
2LMM GNN: July 8, 2025
45
−Mℓ+1 ≤
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θC(i; z′; ℓ) +
X
k∈I−
a (i)
θC
−(k; z; ℓ) +
X
k∈I+
a (i)
θC
+(k; z; ℓ)
+
X
k∈I+
b (i)
θCT
T (k; z; ℓ) +
X
k∈I−
b (i)
θTC
T (k; z; ℓ) + bias(z; ℓ) = τ C(i; z; ℓ+ 1) ≤Mℓ+1
−Mℓ+1δτ
C(i; z; ℓ+ 1) ≤θC(i; z; ℓ+ 1) −κτ C(i; z; ℓ+ 1) ≤Mℓ+1δτ
C(i; z; ℓ+ 1),
−Mℓ+1(1 −δτ
C(i; z; ℓ+ 1)) ≤θC(i; z; ℓ+ 1) −τ C(i; z; ℓ+ 1) ≤Mℓ+1(1 −δτ
C(i; z; ℓ+ 1)),
−Mℓ+1δτ
C(i; z; ℓ+ 1) ≤τ C(i; z; ℓ+ 1) ≤Mℓ+1(1 −δτ
C(i; z; ℓ+ 1)),
z ∈[1, Khid], ℓ∈[0, L −1], i ∈[ etC + 1, tC],
(69)
−Mℓ+1 · (1 −vT(i)) ≤τ T(i; z; ℓ+ 1) −(
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θT(i; z′; ℓ) + θT
−(i; z; ℓ) + θT
+(i; z; ℓ)
+θCT
C (i; z; ℓ) + θTC
C (i; z; ℓ) + θTF
F (i; z; ℓ) + bias(z; ℓ)) ≤Mℓ+1 · (1 −vT(i)),
−Mℓ+1 · vT(i) ≤θT(i; z; ℓ+ 1) ≤Mℓ+1 · vT(i),
−Mℓ+1δτ
T(i; z; ℓ+ 1) ≤θT(i; z; ℓ+ 1) −κτ T(i; z; ℓ+ 1) ≤Mℓ+1δτ
T(i; z; ℓ+ 1),
−Mℓ+1(1 −δτ
T(i; z; ℓ+ 1)) ≤θT(i; z; ℓ+ 1) −τ T(i; z; ℓ+ 1) ≤Mℓ+1(1 −δτ
T(i; z; ℓ+ 1)),
−Mℓ+1δτ
T(i; z; ℓ+ 1) ≤τ T(i; z; ℓ+ 1) ≤Mℓ+1(1 −δτ
T(i; z; ℓ+ 1)),
θT(0; z; ℓ) = θT(tT + 1; z; ℓ) = 0,
z ∈[1, Khid], ℓ∈[0, L −1], i ∈[1, tT], (70)
−Mℓ+1 · (1 −vF(i)) ≤τ F(i; z; ℓ+ 1) −(
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θF(i; z′; ℓ) + θF
−(i; z; ℓ) + θF
+(i; z; ℓ)
+θCF
C (i; z; ℓ) + θTF
T (i; z; ℓ) + bias(z; ℓ)) ≤Mℓ+1 · (1 −vF(i)),
−Mℓ+1 · vF(i) ≤θF(i; z; ℓ+ 1) ≤Mℓ+1 · vF(i),
−Mℓ+1δτ
F(i; z; ℓ+ 1) ≤θF(i; z; ℓ+ 1) −κτ F(i; z; ℓ+ 1) ≤Mℓ+1δτ
F(i; z; ℓ+ 1),
−Mℓ+1(1 −δτ
F(i; z; ℓ+ 1)) ≤θF(i; z; ℓ+ 1) −τ F(i; z; ℓ+ 1) ≤Mℓ+1(1 −δτ
F(i; z; ℓ+ 1)),
−Mℓ+1δτ
F(i; z; ℓ+ 1) ≤τ F(i; z; ℓ+ 1) ≤Mℓ+1(1 −δτ
F(i; z; ℓ+ 1)),
θF(0; z; ℓ) = θF(tF + 1; z; ℓ) = 0,
z ∈[1, Khid], ℓ∈[0, L −1], i ∈[1, tF], (71)
Preparing associated variables: /* The values for θC(i; z; ℓ), θT(i; z; ℓ) and θF(i; z; ℓ) deter-
mine the values for θC
−(k; z; ℓ), θC
+(k; z; ℓ), θT
−(k; z; ℓ), θT
+(k; z; ℓ), θF
−(k; z; ℓ), θF
+(k; z; ℓ), θCT
T (k; z; ℓ),
θTC
T (k; z; ℓ), θCT
C (k; z; ℓ), θTC
C (k; z; ℓ), θTF
F (k; z; ℓ),θCF
F (k; z; ℓ), θCF
C (k; z; ℓ) and θTF
T (k; z; ℓ) by the
following. */


--- Page 46 ---
2LMM GNN: July 8, 2025
46
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θC(tail(k); z′; ℓ) = θC
−(k; z; ℓ),
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θC(head(k); z′; ℓ) = θC
+(k; z; ℓ),
−Mℓ· eC(k) ≤θC
−(k; z; ℓ) ≤Mℓ· eC(k),
−Mℓ· eC(k) ≤θC
+(k; z; ℓ) ≤Mℓ· eC(k),
k ∈[f
kC + 1, mC], z ∈[1, Khid], ℓ∈[0, L −1],
(72)
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θT(i −1; z′; ℓ) = θT
−(i; z; ℓ),i ∈[2, tT],
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θT(i + 1; z′; ℓ) = θT
+(i; z; ℓ),i ∈[1, tT −1],
−Mℓ· eT(i) ≤θT
−(i; z; ℓ) ≤Mℓ· eT(i),
−Mℓ· eT(i + 1) ≤θT
+(i; z; ℓ) ≤Mℓ· eT(i + 1),i ∈[1, tT],
z ∈[1, Khid], ℓ∈[0, L −1],
(73)
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θF(i −1; z′; ℓ) = θF
−(i; z; ℓ),i ∈[2, tF],
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θF(i + 1; z′; ℓ) = θF
+(i; z; ℓ),i ∈[1, tF −1],
−Mℓ· eF(i) ≤θF
−(i; z; ℓ) ≤Mℓ· eF(i),
−Mℓ· eF(i + 1) ≤θF
+(i; z; ℓ) ≤Mℓ· eF(i + 1),i ∈[1, tF],
z ∈[1, Khid], ℓ∈[0, L −1],
(74)
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θT(i; z′; ℓ) −Mℓ· (1 −χT(i, k) + eT(i)) ≤θCT
T (k; z; ℓ)
≤
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θT(i; z′; ℓ) + Mℓ· (1 −χT(i, k) + eT(i)), i ∈[1, tT],
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θT(i; z′; ℓ) −Mℓ· (1 −χT(i, k) + eT(i + 1)) ≤θTC
T (k; z; ℓ)
≤
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θT(i; z′; ℓ) + Mℓ· (1 −χT(i, k) + eT(i + 1), i ∈[1, tT],
−Mℓ· δT
χ (k) ≤θCT
T (k; z; ℓ) ≤Mℓ· δT
χ (k),
−Mℓ· δT
χ (k) ≤θTC
T (k; z; ℓ) ≤Mℓ· δT
χ (k),
k ∈[1, kC], z ∈[1, Khid], ℓ∈[0, L −1],
(75)


--- Page 47 ---
2LMM GNN: July 8, 2025
47
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θC(tail(k); z′; ℓ) −Mℓ· (1 −χT(i, k) + eT(i)) ≤θCT
C (i; z; ℓ)
≤
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θC(tail(k); z′; ℓ) + Mℓ· (1 −χT(i, k) + eT(i)), k ∈[1, kC],
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θC(head(k); z′; ℓ) −Mℓ· (1 −χT(i, k) + eT(i + 1)) ≤θTC
C (i; z; ℓ)
≤
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θC(head(k); z′; ℓ) + Mℓ· (1 −χT(i, k) + eT(i + 1), k ∈[1, kC],
−Mℓ· (1 −eT(i)) ≤θCT
C (i; z; ℓ) ≤Mℓ· (1 −eT(i)),
−Mℓ· vT(i) ≤θCT
C (i; z; ℓ) ≤Mℓ· vT(i),
−Mℓ· (1 −eT(i + 1)) ≤θTC
C (i; z; ℓ) ≤Mℓ· (1 −eT(i + 1)),
−Mℓ· vT(i) ≤θTC
C (i; z; ℓ) ≤Mℓ· vT(i),
i ∈[1, tT], z ∈[1, Khid], ℓ∈[0, L −1],
(76)
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θF(i; z′; ℓ) −Mℓ· (1 −χF(i, c) + eF(i)) ≤θCF
F (c; z; ℓ)
≤
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θF(i; z′; ℓ) + Mℓ· (1 −χF(i, c) + eF(i)), i ∈[1, tF],
−Mℓ· χF(c) ≤θCF
F (c; z; ℓ) ≤Mℓ· χF(c),
c ∈[1, etC], z ∈[1, Khid], ℓ∈[0, L −1],
(77)
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θC(c; z′; ℓ) −Mℓ· (1 −χF(i, c) + eF(i)) ≤θCF
C (i; z; ℓ)
≤
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θC(c; z′; ℓ) + Mℓ· (1 −χF(i, c) + eF(i)), c ∈[1, etC],
−Mℓ·
X
c∈[1,f
tC]
χF(i, c) ≤θCF
C (i; z; ℓ) ≤Mℓ·
X
c∈[1,f
tC]
χF(i, c),
−Mℓ· (1 −eF(i)) ≤θCF
C (i; z; ℓ) ≤Mℓ· (1 −eF(i)),
i ∈[1, tF], z ∈[1, Khid], ℓ∈[0, L −1],
(78)
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θF(j; z′; ℓ) −Mℓ· (1 −χF(j, etC + i) + eF(j)) ≤θTF
F (i; z; ℓ)
≤
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θF(j; z′; ℓ) + Mℓ· (1 −χF(j, etC + i) + eF(j)), j ∈[1, tF],
−Mℓ· χF( etC + i) ≤θTF
F (i; z; ℓ) ≤Mℓ· χF( etC + i),
i ∈[1, tT], z ∈[1, Khid], ℓ∈[0, L −1],
(79)


--- Page 48 ---
2LMM GNN: July 8, 2025
48
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θT(j; z′; ℓ) −Mℓ· (1 −χF(i, etC + j) + eF(i)) ≤θTF
T (i; z; ℓ)
≤
X
z′∈[1,h(ℓ)]
wℓ(z′, z)θT(j; z′; ℓ) + Mℓ· (1 −χF(i, etC + j) + eF(i)), j ∈[1, tT],
−Mℓ·
X
j∈[1,tT]
χF(i, etC + j) ≤θTF
T (i; z; ℓ) ≤Mℓ·
X
j∈[1,tT]
χF(i, etC + j),
−Mℓ· (1 −eF(i)) ≤θTF
T (i; z; ℓ) ≤Mℓ· (1 −eF(i)),
i ∈[1, tF], z ∈[1, Khid], ℓ∈[0, L −1],
(80)
X
i∈[1,tX],X∈{C,T,F}
X
z∈[1,Khid]
wC(z, p)θX(i; z; L) = τftr(p),
−MLδτ
ftr(p) ≤θC(p) −κτftr(p) ≤MLδτ
ftr(p),
−ML(1 −δτ
ftr(p)) ≤θC(p) −τftr(p) ≤ML(1 −δτ
ftr(p)),
−MLδτ
ftr(p) ≤τftr(p) ≤ML(1 −δτ
ftr(p)),
p ∈[1, KC],
(81)
