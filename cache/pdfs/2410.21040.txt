--- Page 1 ---
LiP-LLM: Integrating Linear Programming and dependency graph
with Large Language Models for multi-robot task planning
Kazuma Obata1 Tatsuya Aoki1 Takato Horii1 Tadahiro Taniguchi2 and Takayuki Nagai1
Abstract—This study proposes LiP-LLM: integrating linear
programming and dependency graph with large language models
(LLMs) for multi-robot task planning. In order for multiple
robots to perform tasks more efficiently, it is necessary to manage
the precedence dependencies between tasks. Although multi-
robot decentralized and centralized task planners using LLMs
have been proposed, none of these studies focus on precedence
dependencies from the perspective of task efficiency or leverage
traditional optimization methods. It addresses key challenges
in managing dependencies between skills and optimizing task
allocation. LiP-LLM consists of three steps: skill list generation
and dependency graph generation by LLMs, and task allocation
using linear programming. The LLMs are utilized to generate
a comprehensive list of skills and to construct a dependency
graph that maps the relationships and sequential constraints
among these skills. To ensure the feasibility and efficiency of
skill execution, the skill list is generated by calculated likelihood,
and linear programming is used to optimally allocate tasks to
each robot. Experimental evaluations in simulated environments
demonstrate that this method outperforms existing task plan-
ners, achieving higher success rates and efficiency in executing
complex, multi-robot tasks. The results indicate the potential of
combining LLMs with optimization techniques to enhance the
capabilities of multi-robot systems in executing coordinated tasks
accurately and efficiently. In an environment with two robots,
a maximum success rate difference of 0.82 is observed in the
language instruction group with a change in the object name.
I. INTRODUCTION
The integration of multi-robot systems into various environ-
ments enhances the execution of a broad spectrum of tasks. For
efficient performance, it is necessary to manage the precedence
dependencies between tasks and identify which tasks can be
executed in parallel and which cannot. A key challenge in
multi-robot task planning is managing these dependencies
from natural language instructions, ensuring tasks are executed
in the correct sequence, which increases the success rate.
Additionally, actions without dependencies can be parallelized,
further boosting efficiency. It is also important to consider
the diverse characteristics of each robot, such as the different
grippers attached to the robotic arms.
Complete automation of the entire process of multi-robot
task planning, including task decomposition, remains a signif-
icant challenge. Brian et al. [1] proposed SayCan, a task plan-
ning method for a single robot that uses LLMs to decompose
language instructions into more detailed tasks and accomplish
*This work was supported by Japan Science and Technology Agency (JST)
Moonshot R&D Grant Number JPMJMS2011.
1 Dept. of Systems Innovation, Graduate School of Engineering Science,
Osaka University, Osaka, Japan
{k.obata@rlg., t.aoki@rlg., takato@, nagai@}
sys.es.osaka-u.ac.jp
2 Dept. of Informatics, Kyoto University, Kyoto, Japan
taniguchi@i.kyoto-u.ac.jp
them. However, the relationships between decomposed tasks
are simple sequence structures, and their extension to multiple
robots has not been discussed. Kutter et al. [2] modeled tasks
as structures with precedence dependencies and proposed an
approach to execute independent tasks in parallel. However,
the modeling is performed manually, requiring human inter-
vention to decompose complex tasks into simpler subtasks.
Extensive research has been conducted on multi-robot systems
[3], [4]. Most multi-robot task planning systems focus on two
main aspects: task decomposition and task-allocation. Task
allocation is frequently automated using optimal assignment
problems. However, as stated earlier, human involvement is
necessary in many cases to ensure accurate task decomposition
and handling of dependencies.
Recently, research on multi-robot task planning has explored
the application of LLMs. Two primary approaches have been
proposed: decentralized processing, such as RoCo [5], where
multiple agents determine tasks through dialogue [6], [7],
and centralized processing, such as SMART-LLMs [8], that
use multistage reasoning to assign tasks to each agent [9].
In both approaches, LLMs manage all stages of task plan-
ning, including task decomposition and task allocation. De-
centralized processing requires textual information exchange
between robots, which will increase the dialogue history and
expand the prompt size with the number of robots. Issues
with hallucinations and task allocation are also common to
both. Although LLMs can be applied to various tasks, they
struggle to effectively address domain-specific problems, and
their performance does not match task-specific algorithmic ap-
proaches [10]. Leveraging external planners may be useful for
addressing this issue. The task allocation problem addressed
in this study is classified as ST-SR-TA (Single-Task Robots,
Single-Robot Tasks, Time-Extended Assignment) [11], [12].
Since ST-SR-TA is NP-hard, approaches have been proposed
that approximate it as ST-SR-IA (Single-Task Robots, Single-
Robot Tasks, Instantaneous Assignment), which can be solved
using optimization, or solve it heuristically. McIntirel et al.
[13] proposed an approximation approach for ST-SR-IA in
the context of ST-SR-TA with precedence constraints between
tasks. In this study, task execution time is not considered, and
the difference between the number of robots and the number
of assignable tasks at each step is at most a few. Therefore,
the approximation approach can achieve a solution that is
sufficiently close to optimal [12].
This study proposes a multi-robot task planning method,
LiP-LLM, which combines linear programming with LLMs.
As shown in Fig. 1, LiP-LLM divides task planning into
three steps: skill list generation, dependency graph generation,
and task allocation. LLMs manage task decomposition and
dependencies traditionally handled by humans. First, LLMs
arXiv:2410.21040v1  [cs.RO]  28 Oct 2024


--- Page 2 ---
Task allocation
Dependency Graph Generation
A
E
C
D
B
Linear Programming
Skill List Generation
transport(table)
pick_and_place(green block, corner)
pick_and_place(blue block, green block)
pick_and_place(red block, blue block)
pick_and_place(yellow block, middle)
A. 
B. 
C. 
D. 
E. 
Dependency Graph 
Skill List
Skill set
Environment
A
E
C
D
B
Execute task
Pick up the 
root nodes
Do they have dependencies?
Stack blocks and put block.
Stacking task has dependency.
Transport task has dependency.
Dependencies : 
A ➞D, A ➞E
B ➞C, C ➞D
pick_and_place
(green block, corner)
transport(table)
Fig. 1: LiP-LLM generates a dependency graph from a skill list and allocates the actions to multiple robots using linear
programming. In the skill list generation phase, it creates a skill list from a predefined skill set to accomplish the given
instructions. Next, it analyzes the skills in the skill list for precedence dependencies and generates a dependency graph.
Finally, it allocates the tasks to each robot using linear programming and executes them.
generate a required skill list for a given language instruction,
with SayCan’s likelihood calculation method ensuring feasible
skills. To address hallucination by the LLMs, we employed
the likelihood calculation used in SayCan [1] to generate
the skill list. Next, a dependency graph is created, linking
skills as nodes and dependencies as edges. Finally, tasks
are optimally allocated to robots via linear programming,
removing completed nodes from the graph after execution.
This process enables effective multi-robot task allocation.
The contributions of this study are as follows
1) We proposed LiP-LLM to handle task dependencies
by structuring the graph so that tasks with precedence
dependencies are executed in the correct order. This
allows us to structure the precedence dependencies be-
tween tasks and allocate parallelizable tasks using linear
programming.
2) Multi-robot task system improves the performance over
decentralized and centralized task planners proposed in
related studies.
II. RELATED WORKS
A. Application of LLMs to robotics
Recently, LLMs have been widely applied to task planning
in robotics [14]. Brian et al. [1] proposed SayCan, which is a
system that integrates skill prediction with LLM and a value
function to guide robotic actions. SayCan works by combining
the prediction probability from a LLM, which estimates the
usefulness of a skill, with the execution probability from the
value function, which assesses the likelihood that a skill can
be executed correctly. When commanded, the robot detects a
skill based on these combined probabilities, resulting in ap-
propriate and feasible actions, given the language instructions.
This method leverages the extensive knowledge embedded in
LLMs and supplements it with real-world information, with
which that LLMs typically struggle. This integration enables
generalized action generation, even for commands that contain
ambiguity.
Some approaches combine LLMs with classical plan-
ners, specifically the Planning Domain Definition Language
(PDDL), to perform a variety of planning tasks [15]–[18].
These studies demonstrate that converting natural language
commands into PDDL using LLMs and then using a con-
ventional planner could provide solutions to a wide range
of problems. In their work on using LLMs for robot task
representation, Cao et al. [19] utilized pre-trained LLMs to
generate behavior-tree-based tasks for robots. Similarly, Lin et
al. [20] proposed the ”Plan Like a Graph,” which calculated
the optimal execution time of tasks by transforming a sequence
of tasks with ordering constraints into a graph structure using
LLMs. Additionally, efforts have been made to leverage LLMs
to create robot application programming interface and other
behavioral programs [21]–[23], as well as to determine robot
behavior [24]–[26] and improve the accuracy of robotic actions
[27]. As these studies indicated, the LLM can be effectively
applied to robotics, suggesting their potential for enhancing
robot task planning through human robot interaction.
B. Utilization of LLMs for multi-robot systems
Zhao et al. [5] proposed RoCo, a system in which multiple
robots interactively discuss task strategies using LLMs to
perform tasks and trajectory planning. RoCo leverages the
role-setting and interactive nature of ChatGPT by assigning
names to each robot and providing environmental feedback,
resulting in a highly interpretable and flexible system. This
approach demonstrated a high success rate in six benchmark
tasks that emphasized the sequential and overlapping nature
of a robot’s workspace. However, the benchmarks involved a
relatively small number of robots (2-3), and action decisions
were made in a constrained environment with limited action


--- Page 3 ---
options for each robot. The scalability of the number of
robots and limitations on the number of actions were not
addressed. Shyam et al. [8] proposed SMART-LLM, a task
planning framework for multiple robots using LLMs. This
method involves task decomposition, team formation, and task
assignment based on input language instructions, subdividing
tasks and assigning them according to robot characteristics.
However, the task decomposition granularity in this method is
coarse, and the framework was not evaluated for instructions
requiring complex task decomposition.
Chen et al. [28] evaluated agent structures and prompt
configurations for a multi-robot system using LLMs. They
proposed and compared four types of structures: convention-
ally distributed structure and two centralized hybrid types. The
study found that one of the hybrid types achieved a higher
performance. Chen et al. [29] proposed Autotamp, an approach
that uses LLMs and STL for multi-robot planning, but it is
limited to mobile robots and does not address the problem
settings that include manipulators. Zhang et al. [6] introduced
a method for determining actions through natural language
communication using LLMs in a multi-agent system. Yu et al.
[9] developed Co-NavGPT, a cooperative navigation system
for multiple robots using LLMs. In this system, environmental
information, such as obstacles and uncharted areas on a map,
is converted into text, thereby enabling cooperative navigation.
Furthermore, research on the application of LLMs for multi-
agent systems extends beyond robotics, with various studies
exploring their applications in different domains, such as
virtual game worlds and education [30].
Thus, various approaches for multi-robot task planning
using LLMs were proposed. However, these studies did not
comprehensively compare the different methods or adequately
evaluate their performances. In this study, a series of task
planning with natural language as input is realized in a multi-
robot task plan by having LLMs handle task dependencies that
are previously managed by humans.
III. PROPOSED METHOD
A. Skill List Generation
The algorithmic procedure for skill list generation is out-
lined in Algorithm 1. In the skill list generation process,
we used LLMs to generate a list of skills necessary to
accomplish given language instructions from a predefined skill
set. First, a set of executable robot skills Π was defined.
Each skill language description sπ ∈sΠ was represented
by a command in the format of function + arguments, such
as ”pick and place(red block, middle)”, which a robot can
execute. The probability that skill sπ is predicted for language
instruction i is represented as p(sπ|i) and can be computed
using the LLM. In lines 4-5, for each skill sπ
∈
sΠ,
p(sπ|i) is calculated, and skill sn with the highest probability
is selected in step n from C, which represents the set of
predicted probabilities for each skill(shown in lines 3, 6-8).
Subsequently, skill sn is appended to the end of language
instruction i, and the next skill is selected in lines 1, 8-9.
This process is repeated until the end command is selected
by p(sπ|i, sn−1, . . . , s0)(lines 2-10). By using the predicted
Algorithm 1 Skill List Generation
Input: Language instruction i, predefined skill set Π
1: n = 0
2: while sπn−1 ̸= ”done” do
3:
C = ∅
4:
for sπ ∈sΠ do
5:
p(sπ|i, sn−1, . . . , s0) ←LLMs(prompt+i+s0+. . .+
sn)
6:
C = C ∪p(sπ|i, sn−1, . . . , s0)
7:
end for
8:
sn = argmaxsπ∈sΠC
9:
n = n + 1
10: end while
Output: S: skill list
probabilities of skills instead of directly generating text, we
can prevent hallucinations where undefined skills are output.
The prompt configuration used in this step is shown below.
1) Purpose of inference and brief description: Describe
the number of robots present in the environment and the
objective of the inference.
2) Rules: Describe basic rules, including explanations of
what each generated skill represents.
3) Considerations for Inference: Provide information to
consider during inference, such as the necessary condi-
tions for object transfer.
4) Few-shot Examples [31]: The Few-shot method is used
to improve the prediction performance. For this method,
five examples are provided.
B. Dependency Graph Generation
Taking as input the skill list S and language instruction
generated in the previous steps, Directed Acyclic Graph (DAG)
G = (V, E) is generated based on the dependencies using
LLMs. In this graph:
• Each node vi ∈V represents a skill, where vi corre-
sponds to each element in a sequence of skills from the
previous steps.
• Each edge eij ∈E represents the dependencies between
skills, indicating that skill vj depends on skill vi.
This process involves leveraging LLMs to infer depen-
dencies and construct a dependency graph that captures the
sequential relationships among skills, thus enabling paralleliz-
able skill selection. In this study, a ”dependency” is defined
as the relationship between two tasks where task B cannot be
executed unless task A has been completed. This dependency
ensures that tasks are performed in the correct order.
We utilized a step-wise inference method known as Chain
of Thought [32] to enhance the inference performance of the
language model during dependency graph generation. First,
we generated the dependency relationships between skills in
textual form. Next, we generated TS, which represents the
edges between nodes in the text format ”vi →vj” in line
2 of Algorithm 2. In line 3, this output was converted into
edge eij ∈ES to create graph GS (VS, ES), consisting of
nodes VS, representing each element of the skill list, and


--- Page 4 ---
edges ES. In line 1-4, we detect whether the generated graph
contains cycles, and if a cycle is found, the dependencies are
regenerated. As described in the previous section, the prompt
includes information regarding the surrounding environment
of the robot to provide a comprehensive context.
C. Task Allocation
This allocation was achieved using an optimal assignment
problem approach, which is commonly employed in task
allocation for multi-robot systems. The algorithm of Depen-
dency Graph Generation and Task Allocation is presented in
Algorithm 2.
1) Election of skills with no dependencies
A dependency graph is a directed graph with skills as
nodes and dependencies between skills as edges. We
searched for the root nodes Vr within the graph and
selected them as executable skills (lines 6-11). As the se-
lected nodes did not have parent nodes, no dependencies
were existed between them, enabling parallel execution.
2) Weight Calculation
The weights for each robot’s skills were calculated. This
experiment involved two robot types: an arm robot and a
mobile robot. For the arm robots, weights were assigned
based on skill feasibility and adjusted by distance, as
operating on distant objects raises the risk of motion
failure or collision with other robots. The weights were
calculated based on the distance from the robot to the
target object, with observation o representing environ-
mental data from the simulation(line 12). Weight wjk
for each skill k is calculated using the normalized value
d′
jbk of the distance djbk between each robot j and the
grasping object bk, using (1). α represents a constant
ranging from 0 to 1. In this case, α was empirically set
to 0.3. For mobile robots, a value of 1 or 0 is calculated
as the weight, depending on the skill’s executability (2).
wjk = 1 −αd′
jbk
(1)
wjk =
(
1
if executable
0
otherwise
(2)
3) Optimal Assignment
To allocate tasks to multiple robots, we use a linear pro-
gramming assignment problem based on skill weights.
For each skill selected in Section III-A, we created an
allocation problem as described in (3), where the sum of
the skill weights for each robot is the objective function.
Let N and M represent the number of robots and skills,
respectively, and xjk be a variable indicating whether
robot j executes skill k.
maximize
z =
N
X
j
M
X
k
wjkxjk
subject to
N
X
j
xjk ≤1,
M
X
k
xjk ≤1,
xjk ∈{0, 1}, ∀j ∈N, ∀k ∈M
(3)
Algorithm 2 Dependency Graph Generation and Task Allo-
cation
Input: Language instruction i, observation o, skill list S
1: while CycleDetection(Gs) = True do
2:
TS ←LLMs(prompt + i + S)
3:
GS(VS, ES) ←CreateGraph(S, TS)
4: end while
5: while VS ̸= ∅do
6:
Vr = ∅
7:
for v ∈VS do
8:
if v is rootnode then
9:
Vr = Vr ∪v
10:
end if
11:
end for
12:
Wjk ←CaluculateWeights(o)
13:
Ve ←OptimizationSolver(Vr, Wjk)
14:
Execute Ve
15:
GS ←DeleteNode(GS, Ve)
16: end while
Robot can simultaneously perform at most one skill,
and at most one robot can be assigned to each skill.
Therefore, we imposed the constraint that each robot
was assigned no more than one skill, and that each skill
was assigned to no more than one robot.
In lines 13-14, the solution to this allocation problem
assigned skill Ve to each robot. Any robot that is not
assigned a skill is given the waiting skill ”stay()”. Once
a robot completed its skill and provided feedback, the
corresponding node Ve and its associated edges were
removed from dependency graph GS (line 15). These
steps were repeated until all nodes in the graph were
removed or until no more skills can be performed (lines
5-16).
IV. EXPERIMENT
Two types of experiments were conducted to evaluate the
performance of the proposed LiP-LLM. Experiment 1 eval-
uated the versatility of the planner by examining whether it
could appropriately plan various instructions. In Experiment 2,
experiments were conducted in a more complex environment
with a larger number of robots than in Experiment 1, to
evaluate the limitations of the planner’s performance and
scalability.
In this experiment, the AWS RoboMaker Small House
World ROS package1 was used to simulate a home environ-
ment. The furniture arrangement was partially modified for this
experiment. Four colored blocks and bowls (blue, red, yellow,
and green) were placed in the experimental environment. The
robot was assumed to know the locations of the objects. Three
experimental environments were used with variation in the
type and number of robots. LiP-LLM used OpenAI’s GPT
model ”text-davinci-003” as the LLM.
1https://github.com/aws-robotics/aws-robomaker-small-house-world


--- Page 5 ---
(a) Environment A
(b) Environment B
(c) Environment C
Fig. 2: Experiment environments : (a)Environment A includes two arm robots. (b)Environment B includes two arm robots and
one mobile robot. (c)Environment C includes three arm robots (two in the living room and one in the kitchen) and two mobile
robots.
TABLE I. LANGUAGE INSTRUCTION
’GROUP NAME’ REPRESENTS THE INSTRUCTION GROUP. ’DETAIL’ PROVIDES DETAILS ABOUT EACH INSTRUCTION GROUP.
’EXAMPLE’ SHOWS EXAMPLE OF THE INSTRUCTIONS. ’TRIAL’ IS THE NUMBER OF INSTRUCTIONS IN EACH GROUP.
Group name
Detail
Example
Trial
Group1:
Basic
Instruction composed of a stacking task and a placement task, which
are the basic operations among the tasks assumed in this study.
Stack the blocks in the order of red, yellow on the middle, and put
green block and blue block on the different corner of the table.
15
Group2:
Name Change
Instruction refers to a name that differs from that of the object or
location defined in the skill, such as ”block” being described as ”box”.
Put green cube on the lower right edge, and stack cubes in order
of red, blue on the upper right edge.
15
Group3:
Ambiguity
Name and location of the block are euphemistic and ambiguous, such
as ”place the block clockwise.
Put the blocks in the order of red, blue, yellow, and green
clockwise starting from the top right corner.
15
Group4:
Add Bowl
Instruction consisting of an environment with an additional bowl in the
environment.
Put bowl to the middle, then put red, green, and blue block in the
bowl.
18
• Environment A: This setup featured a living room with
two arm robots (Fig. 2a). These robots can interact with
object placement and stacking tasks on a table.
• Environment B: This environment included a living
room with two arm robots and a mobile robot (Fig. 2b).
The robots performed object placement and stacking tasks
on a table, with some objects requiring transportation by
the mobile robot.
• Environment C: This configuration comprised two arm
robots in the living room, one arm robot in the kitchen,
and two mobile robots (Fig. 2c). The robots performed
tasks either at the table or in the kitchen and might need
to move objects between these areas.
A. Task Setting
1) Experiment 1: In Experiment 1, we evaluated the gener-
ality of LiP-LLM by changing two variables: language instruc-
tions and constraints provided to the robot in Environments A
and B.
1) Instruction: Four groups of instructions were used to
evaluate generality, resulting in 63 different languages
instructions. The list of instructions is shown in TABLE
I.
2) Constraints on the robot: Each robot in an environment
has different characteristics. Two arm robots in living
rooms have constraints on the objects they can grasp.
a) Condition 1: There are no restrictions on the
robots, allowing them to grasp any object in the
environment.
b) Condition 2: Robot 1 can grasp red, blue, and
yellow objects (blocks and bowls), whereas Robot
2 can only grasp red and green objects.
c) Condition 3: Robot 1 can grasp red and blue
objects, and Robot 2 can grasp yellow and green
objects.
2) Experiment 2: We evaluated the utility of LiP-LLM
by varying three variables: language instructions, constraints
imposed on robots, and object placement positions in Envi-
ronment C.
1) Instruction: The same 15 language instructions from the
instruction group (basic instructions used in Experiment
1) were applied, with the same structure but different
installation positions.
2) Constraints on the robot: The arm robot to be placed
in the living room were subjected to the same constraints
as in Experiment 1. However, no constraints are imposed
on the arm robot placed in the kitchen.
3) Location of objects: In Environment C, task planning
results can vary significantly based on the object place-
ment, even when using the same language instructions.
Therefore, three difficulty levels were set based on the
necessity of object transportation by the mobile robot:
a) Level 1: Objects were placed close to the target
positions,thus requiring no object transportation for
the initial placement. This is the least challenging
setting as the mobile robot does not need to trans-
port objects.
b) Level 2: Objects may be held by the mobile robot
instead of leaving them at the target position, which
requires initial transportation by the mobile robot.
This setting has a medium difficulty level because
the mobile robot needs to transport objects.
c) Level 3: Objects are placed in a room differ-
ent from the target location, necessitating object
transportation between rooms. This is the most
challenging setting, requiring coordination between


--- Page 6 ---
TABLE II.
EXPERIMENT 1: RESULTS FOR EACH INSTRUCTION GROUP
methods
Environment A
Environment B
Success
Rate↑
SPL↑
Time
[s]↓
Success
Rate↑
SPL↑
Time
[s]↓
G1
LiP-LLM
0.93
0.89
21.0
0.82
0.72
33.2
RoCo
0.71
0.60
26.3
0.58
0.44
86.9
SMART-LLM
0.62
0.59
33.4
0.49
0.45
49.4
G2
LiP-LLM
0.93
0.88
21.9
0.91
0.81
35.5
RoCo
0.69
0.45
47.9
0.36
0.22
117
SMART-LLM
0.11
0.11
46.0
0.22
0.19
66.0
G3
LiP-LLM
0.44
0.40
25.0
0.44
0.43
37.2
RoCo
0.44
0.37
46.6
0.18
0.12
105
SMART-LLM
0.36
0.34
45.3
0.29
0.17
60.9
G4
LiP-LLM
0.50
0.46
25.4
0.17
0.15
40.6
RoCo
0.22
0.18
66.0
0.09
0.06
117
SMART-LLM
0.37
0.37
48.8
0.13
0.11
52.6
the arm and mobile robots to transport the objects.
B. Comparative methods
• RoCo [5]: A method in which multiple robots interac-
tively make skilled decisions using LLMs. The LLMs
uses OpenAI’s GPT-4-0613.
• SMART-LLM [8]: A task planning method in which
a series of operations, including task decomposition,
team formation, and task allocation were performed using
LLMs. The LLMs also used the OpenAI’s GPT-4-0613.
C. Evaluation index
1) Success Rate: The success rate was recorded as 1 if a
plan that fulfilled a language instruction was generated
and 0 if it failed. Only trials with a success rate of one
were considered in the computation time metrics.
2) Success weighted by Path Length(SPL) [33]: This
metric evaluates plan efficiency by comparing the ideal
shortest number of steps, determined by a human, with
the steps in the generated plan. In this study, the SPL
reflects success rates weighted by step count rather than
path length. In this experiment, (4) was used.
1
N
N
X
i=1
Si
li
max(pi, li)
(4)
where N is the number of trials, Si is one for success
and zero for failure, li is the minimum number of steps
in trial i, and pi is the number of steps in trial i.
3) Process Time: The time taken by the planner to process
the allocation and planning from the time it receives
instructions to the time it sends commands to the robots.
D. Result
1) Experiment 1:
1) Success Rate: As shown in TABLEs II and III, LiP-
LLM achieved the highest success rate in Environments
A and B, with a maximum difference of 0.82. TABLE II
indicates that LiP-LLM maintains robust task planning
even when language commands aim to induce failures.
TABLE III.
EXPERIMENT 1: RESULT FOR EACH CONSTRAINT
methods
Environment A
Environment B
Success
Rate↑
SPL↑
Time
[s]↓
Success
Rate↑
SPL↑
Time
[s]↓
C1
LiP-LLM
0.70
0.67
22.8
0.56
0.51
34.3
RoCo
0.55
0.43
37.5
0.25
0.17
97.7
SMART-LLM
0.48
0.46
40.9
0.33
0.29
58.1
C2
LiP-LLM
0.67
0.60
22.7
0.60
0.56
36.2
RoCo
0.49
0.36
53.2
0.33
0.23
96.9
SMART-LLM
0.30
0.29
42.3
0.24
0.18
57.1
C3
LiP-LLM
0.71
0.67
22.8
0.52
0.47
34.2
RoCo
0.49
0.39
53.2
0.29
0.20
109
SMART-LLM
0.32
0.31
41.8
0.25
0.21
51.9
TABLE III shows no significant changes across methods
under varying constraints.
2) SPL: The SPL results followed a similar trend to the
success rate, indicating efficiency differences. SMART-
LLM, LiP-LLM, and RoCo scored higher in efficiency,
with a maximum difference of 0.77 compared to the
baseline. Although SMART-LLM had a lower success
rate, its SPL was not high because in successful trials, it
generated near-optimal plans. LiP-LLM and RoCo were
slightly less efficient due to redundant tasks.
3) Process Time: LiP-LLM outperformed SMART-LLM
and RoCo in terms of process time. This showed a
difference of up to approximately 80 s from the baseline
method. In the proposed method, the waiting time for the
LLM invocation accounted for the majority of the pro-
cessing time. Therefore, the processing time increased
with the number of inference calls in both the proposed
and comparative methods.
2) Experiment 2:
1) Success Rate: As shown in TABLEs IV and V, LiP-LLM
had the highest success rate, with a maximum difference
of 0.34, similar to Experiment 1. Although success rates
were lower for all methods in the more complex long-
term tasks of Experiment 2, LiP-LLM still produced
robust plans. As TABLE IV indicates, the comparative
method’s success rate declined under stricter constraints,
while LiP-LLM was less affected. The comparative
method often ignored robot constraints, leading to errors,
whereas LiP-LLM made no such errors.
2) SPL: Similar trends were observed in Experiment 1,
with LiP-LLM performing best, followed by SMART-
LLM and RoCo. The maximum difference from the
baseline was 0.19. SPL highlighted task allocation effi-
ciency, where the proposed method excelled with fewer
redundant tasks.
3) Process Time: As shown in TABLE IV, unlike in Ex-
periment 1, SMART-LLM had the shortest computation
time. LiP-LLM took about 56 seconds longer than the
baseline due to the increased number of API calls
required for skill generation in long-term task planning.


--- Page 7 ---
TABLE IV.
EXPERIMENT 2: RESULTS FOR EACH INSTRUCTION LEVEL
methods
Environment C
Success Rate↑
SPL ↑
Time[s] ↓
L1
LiP-LLM
0.58
0.36
72.9
RoCo
0.36
0.19
113
SMART-LLM
0.24
0.24
40.4
L2
LiP-LLM
0.31
0.16
77.2
RoCo
0.18
0.13
137
SMART-LLM
0.16
0.15
35.1
L3
LiP-LLM
0.31
0.19
96.9
RoCo
0.00
0.00
-
SMART-LLM
0.04
0.04
40.8
TABLE V.
EXPERIMENT 2: RESULT FOR EACH CONSTRAINT
methods
Environment C
Success Rate↑
SPL ↑
Time[s] ↓
C1
LiP-LLM
0.40
0.24
81.4
RoCo
0.24
0.15
122
SMART-LLM
0.22
0.21
39.0
C2
LiP-LLM
0.38
0.24
81.1
RoCo
0.18
0.09
141
SMART-LLM
0.09
0.09
33.4
C3
LiP-LLM
0.42
0.23
78.2
RoCo
0.11
0.08
85.5
SMART-LLM
0.13
0.13
41.2
V. DISCUSSION
A. Effectiveness
1) Success Rate: As detailed in Section IV, LiP-LLM
showed high success rates in task planning across all con-
ditions in Experiments 1 and 2, while comparative methods
experienced significant drops in success rates with more robots
or varying command types. This result is attributed to the
proposed method’s ability to mitigate LLM hallucinations by
selecting skill lists through likelihood calculations and enforc-
ing order constraints inferred from dependencies. In contrast,
comparative methods failed due to command hallucinations
and task failures from ignoring order constraints, such as
simultaneous stacking tasks causing collisions. In addition,
robustness to the increased number of robots contributed to
success. In Experiment 2, with five robots and two rooms
(kitchen and living room), accurate location tracking was
essential, as shown by the success rate differences between
Levels 2 and 3 in TABLE IV. Unlike the LLM-based method,
which struggled with task allocation due to tracking limita-
tions, LiP-LLM’s use of linear programming led to fewer
allocation errors. Regarding the scaling of the number of
robots, theoretically, linear programming can be used to assign
an optimal task to any number of robots. In these experiments,
LiP-LLM demonstrated almost no failures in task allocation
when using linear programming.
2) Efficiency: The SPL results indicate that LiP-LLM pro-
vides task planning results closer to the optimal steps set by
humans. The proposed method considers dependencies among
skills in the process of dependency graph generation, thereby
enabling more tasks to be executed in parallel and more
efficient task execution.
3) Process Times: In Experiment 1, LiP-LLM demonstrated
reduced computation time for task planning. The proposed
method leverages combinatorial optimization for task allo-
cation, resulting in much shorter process times compared to
the comparative methods, which rely on time-intensive LLM
inference. Reducing frequent LLM calls and using algorithmic
approaches effectively shorten process time, though this was
not observed in Experiment 2. The process time of LiP-
LLM increases with task plan length, whereas SMART-LLM
mitigates this by decomposing tasks into a single inference,
improving process time. Although SMART-LLM exhibited
advantages in process time, its performance was not sufficient.
Additionally, the application of linear programming affects the
scaling of the number of robots. Compared with RoCo, which
is a decentralized system, LiP-LLM requires a shorter planning
time. This result suggests that the proposed method is useful
for scaling the number of units.
B. Limitations
1) Challenges in Skill List Generation: The creation of a
predefined skill set is a challenge. The skill list was generated
using SayCan, which calculates the likelihood of each pre-
defined skil from a prompt. A skill is defined by a function
name and arguments, such as ”pick and place(red block, blue
block)”. In environments with multiple objects, the number of
predefined skills increasing owing to large number of object
combinations. In addition, it is not feasible to generate skills
that are not predefined. For example, if a door needs to be
opened to move between rooms, the task would be impossible
without a predefined ”open door” skill.
2) Challenges in Dependency Graph Generation: In de-
pendency graph generation, the increase in environmental
information and diversification of tasks due to the complexity
of the environment is a challenge. In this experiment, the
success rate of environment C was clearly lower than those
of environments A and B. The lower success rate can be
attributed to both increased environmental complexity and skill
adjustments within the robot due to task diversification. As
the number of rooms increases, the environmental information
input to the LLM increases, complicating tasks such as moving
objects between rooms. To address scalability issues, methods
that can adequately handle the complexity introduced by en-
vironmental changes, including inter-robot skill coordination,
must be developed.
VI. CONCLUSION
In this study, we proposed a multi-robot task planning
method LiP-LLM that integrates dependency graph generation
using LLMs and task allocation via linear programming. By
generating a dependency graph between skills, we demon-
strated that skills with order constraints can be executed
in the appropriate sequence, leading to more accurate and
efficient task execution. Additionally, by adopting optimization
methods for the task allocation step, we showed that the
computation time can be reduced compared to methods that
use LLMs for the same process.


--- Page 8 ---
Future studies should focus on applying LiP-LLM to real-
world environments. The simulation environment used in
this study was ideal, with known object coordinates. How-
ever, obtaining accurate environmental information in real
environments is challenging and the available data may be
limited. Therefore, it is necessary to improve the updating of
environmental information through sequential environmental
recognition and to enhance the methods for calculating weights
used in linear programming. In addition, the selected actions
of a robot in a real environment may not always be successful.
For example, a robot may fail to pick up or drop a red block.
To handle such situations more effectively, it is crucial to
develop a robust task planning method that includes sequential
environmental recognition and task replanning with feedback,
as demonstrated by Huang et al. [26]. This ensures that robots
can adapt to dynamic environments and unexpected results,
thereby improving overall task execution reliability.
REFERENCES
[1] Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman,
Alexander Herzog, Daniel Ho, Julian Ibarz, Alex Irpan, Eric Jang, Ryan
Julian, et al. Do as i can, not as i say: Grounding language in robotic
affordances.
In Conference on robot learning, pp. 287–318. PMLR,
2023.
[2] Jutta Kiener and Oskar Von Stryk.
Towards cooperation of hetero-
geneous, autonomous robots: A case study of humanoid and wheeled
robots. Robotics and Autonomous Systems, Vol. 58, No. 7, pp. 921–929,
2010.
[3] Yara Rizk, Mariette Awad, and Edward W Tunstel.
Cooperative
heterogeneous multi-robot systems: A survey. ACM Computing Surveys
(CSUR), Vol. 52, No. 2, pp. 1–31, 2019.
[4] Zhi Yan, Nicolas Jouandeau, and Arab Ali Cherif. A survey and analysis
of multi-robot coordination. International Journal of Advanced Robotic
Systems, Vol. 10, No. 12, p. 399, 2013.
[5] Zhao Mandi, Shreeya Jain, and Shuran Song. Roco: Dialectic multi-
robot collaboration with large language models.
In 2024 IEEE
International Conference on Robotics and Automation (ICRA), pp. 286–
299. IEEE, 2024.
[6] Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun
Du, Joshua B Tenenbaum, Tianmin Shu, and Chuang Gan. Building
cooperative embodied agents modularly with large language models. In
The Twelfth International Conference on Learning Representations.
[7] Jun Wang, Guocheng He, and Yiannis Kantaros.
Safe task planning
for language-instructed multi-robot systems using conformal prediction.
arXiv preprint arXiv:2402.15368, 2024.
[8] Shyam Sundar Kannan, Vishnunandan LN Venkatesh, and Byung-Cheol
Min.
Smart-llm: Smart multi-agent robot task planning using large
language models. In 2024 International Conference on Intelligent Robots
and Systems (IROS). IEEE, 2024.
[9] Bangguo Yu, Hamidreza Kasaei, and Ming Cao. Co-navgpt: Multi-robot
cooperative visual semantic navigation using large language models.
arXiv preprint arXiv:2310.07937, 2023.
[10] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen
Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al.
A
survey on large language model based autonomous agents. Frontiers of
Computer Science, Vol. 18, No. 6, p. 186345, 2024.
[11] Ernesto Nunes, Marie Manner, Hakim Mitiche, and Maria Gini.
A
taxonomy for task allocation problems with temporal and ordering
constraints.
Robotics and Autonomous Systems, Vol. 90, pp. 55–70,
2017.
[12] Brian P Gerkey and Maja J Matari´c. A formal analysis and taxonomy
of task allocation in multi-robot systems. The International journal of
robotics research, Vol. 23, No. 9, pp. 939–954, 2004.
[13] Mitchell McIntire, Ernesto Nunes, and Maria Gini. Iterated multi-robot
auctions for precedence-constrained task scheduling. In Proceedings of
the 2016 international conference on autonomous agents & multiagent
systems, pp. 1078–1086, 2016.
[14] Kento Kawaharazuka, Tatsuya Matsushima, Andrew Gambardella, Jiax-
ian Guo, Chris Paxton, and Andy Zeng. Real-world robot applications
of foundation models: A review. Advanced Robotics, pp. 1–23, 2024.
[15] Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep
Biswas, and Peter Stone. Llm+ p: Empowering large language models
with optimal planning proficiency.
arXiv preprint arXiv:2304.11477,
2023.
[16] Lin Guan, Karthik Valmeekam, Sarath Sreedharan, and Subbarao Kamb-
hampati. Leveraging pre-trained large language models to construct and
utilize world models for model-based task planning, 2023.
[17] Zhehua Zhou, Jiayang Song, Kunpeng Yao, Zhan Shu, and Lei Ma.
Isr-llm: Iterative self-refined large language model for long-horizon
sequential task planning.
In 2024 IEEE International Conference on
Robotics and Automation (ICRA), pp. 2081–2088. IEEE, 2024.
[18] Alessio Capitanelli and Fulvio Mastrogiovanni.
A framework for
neurosymbolic robot action planning using large language models, 2023.
[19] Yue Cao and C. S. George Lee.
Robot behavior-tree-based task
generation with large language models, 2023.
[20] Fangru Lin, Emanuele La Malfa, Valentin Hofmann, Elle Michelle
Yang, Anthony G. Cohn, and Janet B. Pierrehumbert. Graph-enhanced
large language models in asynchronous plan reasoning.
In Ruslan
Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria
Oliver, Jonathan Scarlett, and Felix Berkenkamp, editors, Proceedings
of the 41st International Conference on Machine Learning, Vol. 235 of
Proceedings of Machine Learning Research, pp. 30108–30134. PMLR,
21–27 Jul 2024.
[21] Sai H Vemprala, Rogerio Bonatti, Arthur Bucker, and Ashish Kapoor.
Chatgpt for robotics: Design principles and model abilities.
IEEE
Access, 2024.
[22] Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei
Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, and Animesh
Garg.
Progprompt: Generating situated robot task plans using large
language models. In 2023 IEEE International Conference on Robotics
and Automation (ICRA), pp. 11523–11530. IEEE, 2023.
[23] Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian
Ichter, Pete Florence, and Andy Zeng. Code as policies: Language model
programs for embodied control. In 2023 IEEE International Conference
on Robotics and Automation (ICRA), pp. 9493–9500. IEEE, 2023.
[24] Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang
Dou, Yanjun Chen, Li Fei-Fei, Anima Anandkumar, Yuke Zhu, and Linxi
Fan. Vima: General robot manipulation with multimodal prompts. In
Fortieth International Conference on Machine Learning, 2023.
[25] Kento Kawaharazuka, Naoaki Kanazawa, Yoshiki Obinata, Kei Okada,
and Masayuki Inaba. Continuous Object State Recognition for Cooking
Robots Using Pre-Trained Vision-Language Models and Black-box
Optimization. IEEE Robotics and Automation Letters (RA-L), 2024.
[26] Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Flo-
rence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar,
et al.
Inner monologue: Embodied reasoning through planning with
language models. In Conference on Robot Learning, pp. 1769–1782.
PMLR, 2023.
[27] Brianna Zitkovich, Tianhe Yu, Sichun Xu, Peng Xu, Ted Xiao, Fei Xia,
Jialin Wu, Paul Wohlhart, Stefan Welker, Ayzaan Wahid, et al.
Rt-
2: Vision-language-action models transfer web knowledge to robotic
control.
In Jie Tan, Marc Toussaint, and Kourosh Darvish, editors,
Proceedings of The 7th Conference on Robot Learning, Vol. 229 of
Proceedings of Machine Learning Research, pp. 2165–2183. PMLR,
06–09 Nov 2023.
[28] Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, and Chuchu
Fan.
Scalable multi-robot collaboration with large language models:
Centralized or decentralized systems?
In 2024 IEEE International
Conference on Robotics and Automation (ICRA), pp. 4311–4317. IEEE,
2024.
[29] Yongchao Chen, Jacob Arkin, Charles Dawson, Yang Zhang, Nicholas
Roy, and Chuchu Fan. Autotamp: Autoregressive task and motion plan-
ning with llms as translators and checkers. In 2024 IEEE International
Conference on Robotics and Automation (ICRA), pp. 6695–6702. IEEE,
2024.
[30] Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei,
Nitesh V. Chawla, Olaf Wiest, and Xiangliang Zhang. Large language
model based multi-agents: A survey of progress and challenges.
In
Kate Larson, editor, Proceedings of the Thirty-Third International Joint
Conference on Artificial Intelligence, IJCAI-24, pp. 8048–8057. Interna-
tional Joint Conferences on Artificial Intelligence Organization, 8 2024.
Survey Track.
[31] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D
Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish
Sastry, Amanda Askell, et al. Language models are few-shot learners.
Advances in neural information processing systems, Vol. 33, pp. 1877–
1901, 2020.


--- Page 9 ---
[32] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia,
Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elic-
its reasoning in large language models. Advances in Neural Information
Processing Systems, Vol. 35, pp. 24824–24837, 2022.
[33] Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Doso-
vitskiy, Saurabh Gupta, Vladlen Koltun, Jana Kosecka, Jitendra Malik,
Roozbeh Mottaghi, Manolis Savva, et al. On evaluation of embodied
navigation agents. arXiv preprint arXiv:1807.06757, 2018.
