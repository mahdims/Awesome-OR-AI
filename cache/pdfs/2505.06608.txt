--- Page 1 ---
1
RideAgent: An LLM-Enhanced Optimization Framework for
Automated Taxi Fleet Operations
Xinyu Jiang, Haoyu Zhang, Mengyi Sha, Zihao Jiao, Long He, Junbo Zhang, Wei Qi
Abstract—Efficient management of electric ride-hailing fleets,
particularly pre-allocation and pricing during peak periods to
balance spatio-temporal supply and demand, is crucial for urban
traffic efficiency. However, practical challenges include unpre-
dictable demand and translating diverse, qualitative managerial
objectives from non-expert operators into tractable optimization
models. This paper introduces RideAgent, an LLM-powered
agent framework that automates and enhances electric ride-
hailing fleet management. First, an LLM interprets natural
language queries from fleet managers to formulate corresponding
mathematical objective functions. These user-defined objectives
are then optimized within a Mixed-Integer Programming (MIP)
framework, subject to the constraint of maintaining high opera-
tional profit. The profit itself is a primary objective, estimated by
an embedded Random Forest (RF) model leveraging exogenous
features. To accelerate the solution of this MIP, a prompt-guided
LLM analyzes a small sample of historical optimal decision data
to guide a variable fixing strategy. Experiments on real-world
data show that the LLM-generated objectives achieve an 86%
text similarity to standard formulations in a zero-shot setting.
Following this, the LLM-guided variable fixing strategy reduces
computation time by 53.15% compared to solving the full MIP
with only a 2.42% average optimality gap. Moreover, this variable
fixing strategy outperforms five cutting plane methods by 42.3%
time reduction with minimal compromise to solution quality.
RideAgent offers a robust and adaptive automated framework for
objective modeling and accelerated optimization. This framework
empowers non-expert fleet managers to personalize operations
and improve urban transportation system performance.
Note to Practitioners—The daily management of electric ride-
hailing fleets, particularly the tasks of taxi pre-allocation and
dynamic pricing during peak hours, poses operational complex-
ities for service providers aiming to balance supply with urban
demand. Translating diverse business objectives—such as max-
imizing revenue or enhancing taxi utilization—into actionable
strategies can be challenging for managers without optimization
expertise. This work introduces RideAgent, a Large Language
Model (LLM)-based framework that automates and simplifies
these core operational decisions. RideAgent assists fleet managers
by interpreting their objectives stated in natural language into
formal optimization goals. It then uses historical data to acceler-
ate the computation of pre-allocation and pricing decisions. For
fleet management practitioners, RideAgent offers a more intuitive
and adaptive approach to operations: it enables the incorporation
of specific managerial insights into the optimization process and
significantly reduces the time needed to generate high-quality
Xinyu
Jiang
and
Mengyi
Sha
are
with
the
Department
of
Industrial
Engineering,
Tsinghua
University,
Beijing,
China
(e-mail:
jiangxin24@mails.tsinghua.edu.cn;
mengyisha@mail.tsinghua.edu.cn).
Haoyu Zhang and Zihao Jiao are with the School of Computer and Artificial
Intelligence, Beijing Technology and Business University, Beijing, China
(e-mail: haoyuzhang@st.btbu.edu.cn; jiaozihao@btbu.edu.cn). Long He is
with the School of Business, George Washington University, Washington,
District of Columbia (e-mail: longhe@gwu.edu). Junbo Zhang is with JD
Intelligent Cities Research (e-mail: msjunbozhang@outlook.com). Wei Qi
is with the Department of Industrial Engineering, Tsinghua University,
Beijing, China, and also with the Desautels Faculty of Management, McGill
University, Montreal, Quebec, Canada (e-mail: qiw@tsinghua.edu.cn).
operational decisions. Our findings show that solution times can
be reduced by over 50% while maintaining near-optimal results.
This allows for more agile and personalized decision-making. By
lowering the technical barrier to using advanced optimization,
RideAgent empowers a broader range of personnel to contribute
to efficient fleet management. As the ride-hailing industry adopts
AI-driven solutions, RideAgent provides a practical pathway
for integrating advanced natural language understanding and
automated optimization into daily fleet operations, improving
urban mobility services.
Index Terms—E-taxis, large language models, joint pricing and
pre-allocation, feature-driven optimization, variable fixing.
I. INTRODUCTION
A
S electric taxi services become integral to urban mobility,
fleet operators face the critical challenge of mitigating the
spatio-temporal mismatch between taxi supply and passenger
demand
[8]. This requires the joint optimization of two
interdependent strategies [45]: taxi pre-allocation to anticipate
demand hotspots and dynamic pricing to modulate demand.
These strategies should be flexible enough to adapt to the ebb
and flow of demand, yet robust enough to ensure profitability.
To mitigate these practical challenges, fleet operators in-
creasingly turn to operations research (OR) techniques to
jointly optimize zone-level pre-allocation and dynamic pricing.
OR provides a set of rigorous methods for mathematical
modeling, statistical inference, and algorithmic optimization
for complex decision-making [17]. Classic methods—such as
mixed-integer programming (MIP) and dynamic programming
(DP)—can, in principle, deliver provably optimal resource
allocation and pricing solutions. However, when these formu-
lations must incorporate high-dimensional demand covariates,
fine-grained spatial grids, and evolving operator objectives,
they become exceedingly difficult to construct and computa-
tionally prohibitive to solve. Consequently, practitioners face
the following limitations:
(i) Data and Computational Challenges. Accurate urban
taxi demand forecasting and optimization are complex due to
various external factors (e.g., weather, public events). Integrat-
ing these dynamic covariates into predictive models increases
model complexity and computational overhead. Moreover, the
trend towards finer-grained urban management, characterized
by an expanding number of pre-allocation areas, imposes a
substantial computational burden. Consequently, there is a
pressing need for scalable algorithms that can solve large-scale
optimization models in near real-time to ensure operational
effectiveness.
(ii) Dynamic and Personalized Objectives. The paradigm
of urban management is undergoing a fundamental shift from
experience-based decision-making to a data-driven approach,
arXiv:2505.06608v2  [math.OC]  7 Aug 2025


--- Page 2 ---
2
propelled by the increasing availability of granular data within
smart city ecosystems [15, 32]. This transition has fostered a
greater reliance on Key Performance Indicators (KPIs) and
quantifiable objectives to guide operational strategies. Con-
sequently, urban operators now demand optimization models
that are not only contextually aware and actionable but also
adaptable to a diverse set of objectives. These objectives often
encompass competing priorities such as cost minimization,
operational efficiency, service equity, and customer satisfac-
tion. Traditional OR models, which typically feature fixed and
predetermined objective functions, often lack the flexibility to
accommodate these dynamic and personalized preferences.
(iii)
Knowledge
Gaps.
A
significant
barrier
to
the
widespread adoption of advanced OR techniques in urban
mobility lies in the knowledge gap between OR specialists
and operational practitioners. Complex optimization models
pose a steep learning curve for non-expert operators, limiting
their effective leveraging of OR tools. Conversely, this gap
also complicates the task for OR modelers, who struggle to
accurately formulate objective functions that are nonlinear,
nonconvex, and truly representative of the practitioners’ real-
world goals.
In light of these obstacles, frameworks that couple Large
Language Models (LLMs) with domain-specific optimization
engines offer a promising way forward by leveraging their
capabilities in natural language understanding, reasoning, and
tool use [35]. However, most current LLM–OR systems still
rely on shallow natural-language parsing followed by a one-
shot call to a generic solver [27]; this often compromises
modeling fidelity and yields biased or even infeasible solu-
tions. For instance, even after prompt tuning, GPT-4 reports
an 11 % optimality gap on a 50-node traveling-salesperson in-
stance [1, 43]. Moreover, the enlarged, tightly coupled models
required for real-time joint pre-allocation and pricing remain
difficult to solve within operational deadlines.
To address these limitations, we introduce RideAgent, an
LLM-powered framework designed to make large-scale fleet
optimization both accessible and computationally tractable.
RideAgent employs an LLM in two capacities: problem for-
mulation and solution acceleration. First, it translates the nat-
ural language objectives of non-expert operators into precise
mathematical formulations for the optimization model. Our
primary innovation, however, is a novel LLM-guided acceler-
ation heuristic that performs model reduction. Distinct from
approaches that use LLMs to construct models from scratch,
we start with a full-scale, expert-defined optimization model
and use the LLM to intelligently prune it. By learning from
few-shot examples of historical optimal solutions, the agent
identifies and fixes decision variables with low sensitivity to
the optimal solution. This intelligent reduction of the decision
space renders the complex, high-dimensional optimization
problem more tractable for conventional solvers like Gurobi.
The result is a hybrid architecture that dramatically accelerates
computation for real-time decision-making while maintaining
near-optimal solution quality.
• An LLM-Powered Architecture for Feature-Driven Fleet
Optimization. In order to account for environmental
uncertainties and covariates, RideAgent incorporates a
feature-driven optimization framework that integrates a
random forest (RF) with an optimization model. This
framework allows for the inclusion of numerous features,
thereby enhancing the alignment with user requirements
and reducing decision-making bias.
• An LLM-Guided Variable Fixing Heuristic for Acceler-
ated Optimization. We introduce a novel variable fixing
strategy guided by LLMs’ reasoning ability. Based on
limited historical optimal decision data, RideAgent can
learn the rules of optimal decision-making and proac-
tively fix a subset of decision variables that have low
sensitivity to the optimal solution. By focusing on key
variables, this approach simplifies the pre-defined large-
scale optimization problem and enhances the computa-
tional efficiency.
• Real-World Case Study Validation of LLM-Driven Op-
timization. We validate the effectiveness of RideAgent
through a comprehensive real-world case study. Results
demonstrate that RideAgent excels in generating accurate
objective functions to accommodate user requirements.
Benchmarking against the full-scale MIP model and
established cutting plane methods, RideAgent demon-
strates significant acceleration with minimal compromise
in solution quality.
The remainder of this paper is organized as follows: Section 2
reviews some related work. Section 3 defines the optimization
models. Section 4 introduces the structure and functions of
RideAgent. Section 5 analyzes the results of the case study.
Section 6 summarizes our work.
II. RELATED WORK
Mitigating the supply-demand mismatch in urban taxi sys-
tems is a cornerstone of enhanced urban mobility. A substantial
body of literature has focused on this challenge by optimizing
joint taxi pre-allocation and pricing strategies. However, the
integration of LLM agents to simultaneously address modeling
flexibility and computational scalability in this domain remains
unexplored. This section reviews the pertinent literature across
three key areas to situate our contributions.
A. Joint Taxi Pre-Allocation and Pricing
The joint taxi pre-allocation and pricing problem has
attracted considerable attention in the transportation litera-
ture [11, 25]. The intrinsic fluctuations of service demand
introduce complexity to the decision-making framework [22,
29]. Conventional deterministic optimization models do not
account for dynamic changes, which may result in biased
solutions. To address these challenges, an increasing number of
researchers have adopted various optimization approaches to
account for spatiotemporal uncertainty in service demand and
enhance decision-making effectiveness. Existing studies pro-
pose stochastic or robust optimization models [10, 12, 30, 42]
or dynamic programming models
[9, 34], and then use re-
formulation techniques, heuristic algorithms or approximation
algorithms to derive efficient solutions.
Existing research often overlooks the impact of covariate
features on uncertainty and struggles to incorporate features


--- Page 3 ---
3
into OR models [14]. Additionally, the complexity of the joint
strategy necessitates OR expertise, which may limit its wider
application to non-expert groups. To bridge these gaps, we
integrate OR models with LLMs to provide more accessible
and reliable solutions.
B. LLM-Assisted OR Tools
LLMs are increasingly being explored for their potential
to augment OR. Current research predominantly follows two
primary approaches:
(1) LLMs as Optimizers. This paradigm utilizes tech-
niques like in-context learning [18, 28] and Chain-of-Thought
(CoT) prompting [21] to solve optimization problems directly
through conversational interfaces. A key appeal of this ap-
proach is its accessibility, as it often does not require users to
have specialized OR expertise.
(2) LLM Agents [19, 47]. This approach integrates LLMs
with external tools, such as callable APIs [7, 41] or traditional
OR solvers, to form a more robust system. By offloading
complex calculations to specialized tools, these agents can
mitigate the hallucination and token-limitation issues inherent
in standalone LLMs. Recent studies in this domain have
focused on creating agents that can solve MIPs [2, 44, 46].
Nevertheless, these emerging techniques still face signif-
icant limitations in terms of solution quality and modeling
flexibility. LLMs as optimizers, for instance, often struggle
to guarantee the accuracy or optimality of solutions for com-
plex combinatorial problems [43]. Meanwhile, existing LLM
agents, especially those interfacing with MIP solvers [2, 24],
are often constrained to static and well-defined problems.
They typically lack the flexibility to dynamically formulate
the nuanced or non-standard objective functions required to
address the diverse and evolving requests of practitioners.
C. Feature-Driven Optimization
While LLM-powered agents can formulate optimization
models, they often rely on deterministic frameworks (e.g.,
standard MIPs). Such models struggle to account for the
inherent uncertainties of dynamic environments, like urban
mobility, potentially leading to biased or suboptimal solutions
when faced with fluctuating demand or changing external con-
ditions. The Feature-Driven Optimization paradigm directly
addresses this challenge. Instead of solving a problem based
on average or point estimates of uncertain parameters, feature-
driven optimization seeks to learn a policy or decision rule
that maps observable covariates (features) directly to optimal
decisions [37]. This approach integrates machine learning with
optimization, allowing decisions to adapt to real-time infor-
mation. Dominant feature-driven paradigms include decision
rule optimization, sequential learning and optimization, and
integrated learning and optimization [31, 37]. Our proposed
RideAgent adopts the latter approach and extends the inte-
grated framework of Biggs et al. [4]. Specifically, we embed
predictions from a pre-trained RF directly into the MIP’s
objective function. This allows our model to leverage a rich
set of exogenous features (e.g., weather, time of day, public
events) and makes the core profit-maximization objective
highly responsive to real-world conditions. The result is a more
robust optimization engine that yields contextually relevant
and practically grounded pre-allocation and pricing strategies.
III. PROBLEM FORMULATION
A. Joint Taxi Pre-Allocation and Pricing Model
We address the optimal pre-positioning of an electric taxi
fleet to mitigate spatio-temporal supply-demand mismatches.
The mismatch results in service shortages in some areas and
idle taxis in others. To formalize this, we first partition the city
into a set of operational areas. Areas with a surplus of taxis
relative to local demand are defined as the set of supply areas,
I = {1, . . . , |I|}. Conversely, areas with a service deficit form
the set of demand areas, J = {1, . . . , |J|}. Our model aims
to mitigate this supply-demand imbalance by optimizing taxi
repositioning from set I to set J. Electric taxis are categorized
by their state of charge (SOC), which is discretized into a set
of levels K = {1, . . . , |K|}, ordered from lowest to highest.
A key operational rule is that a request for a taxi with SOC
k can be served by any available taxi with an SOC of k or
higher, but not lower.
Our model setup is informed by the framework for taxi
pre-allocation problems presented in Hao et al. (2020) [14].
The system is defined by a set of given parameters and the
key decisions the operator must make. The primary inputs
include the initial supply of taxis Sik in each area and the
parameters that affect the demand. The pre-allocation cost of
each taxi paid by operators is wij = ˆwij + bj, where ˆwij is
the inconvenience cost and bj is the fixed online booking fee.
ˆwij is proportional to the distance between areas. The total
fare paid by a customer is composed of a variable mileage-
based fee ˆujk and the booking fee bj. For each successful
trip, the booking fee functions as a passthrough payment: the
operator collects bj from the customer and transfers it directly
to the driver who is allocated to demand area j. Operators
earn average revenue ujk per order for taxis with SOC k:
ujk = θ · ˆujk + bj.
Given these parameters, the operator’s core task involves
two sets of decisions: first, determining the number of taxis
xijk to reposition, and second, setting the variable portion
of the fare ˆujk. The operating income is the order rev-
enue in demand areas: R(ˆu, d)
=
P
j∈J
P
k∈K ujkdjk.
The operating cost is the taxi pre-allocation cost: C(x) =
P
i∈I
P
j∈J
P
k∈K wijxijk. The goal is to maximize the
operational profit: R(ˆu, d) −C(x). To model the cascading
nature of SOC fulfillment, we introduce an auxiliary variable
vjk that represents the number of taxis with an SOC greater
than k that are available in area j after demands for all higher
SOC levels have been met. All symbols and their definitions
are consolidated in Table I.
Based on these definitions, we formulate the electric taxi
pre-allocation and pricing optimization model as follows. For
clarity, we use the notation [A]+ = max(0, A) and A ∧B =


--- Page 4 ---
4
TABLE I
NOTATION FOR THE PROBLEM FORMULATION
Symbol
Definition
I, J, K
Sets of supply areas, demand areas, and SOC levels, respectively.
Sik
Number of available taxis with SOC k at supply area i.
zjk
Anticipated demand for SOC k or higher in demand area j.
wij
Unit cost of pre-allocating a taxi from area i to area j.
bj
Fixed booking fee for a trip originating in area j.
θ
Operator’s revenue share from the variable fare.
Decision Variables
xijk
Number of taxis with SOC k pre-allocated from i to j.
ˆujk
Variable portion of the average fare for a trip from j with SOC
k.
Auxiliary Variables
djk
Number of satisfied demands for SOC k in demand area j.
vjk
Surplus taxis from higher SOC levels available for level k in area
j.
min(A, B).
max
x,ˆu,v,d
R(ˆu, d) −C(x)
(1)
s.t.
X
j∈J
xijk ≤Sik, ∀i ∈I, k ∈K,
(2)
djk = zjk ∧
 X
i∈I
xijk + vj(k+1)

, ∀j ∈J, k ∈K,
(3)
vjk =
 X
i∈I
xijk −zjk + vj(k+1)
+, ∀j ∈J, k ∈K,
(4)
vj(|K|+1) = 0, ∀j ∈J,
(5)
xijk ∈N, ∀i ∈I, j ∈J, k ∈K.
(6)
Objective (1) represents the total operational profit from taxi
pre-allocation and pricing decisions. Constraint (2) ensures
that the number of taxis allocated from a supply area does
not exceed its available fleet. Constraint (3) then determines
the satisfied demand based on the total available supply, which
is composed of the newly allocated taxis and the surplus taxis
from higher SOC levels. Constraint (4) calculates the resulting
surplus for the next level. Constraint (5) sets the boundary
condition for this process, while Constraint (6) enforces the
integrality of the allocation decisions.
B. RF-based Feature-Driven Model
The model formulated in the previous section operates
under a predict-then-optimize paradigm. Demand is predicted
upfront and then treated as a fixed input for the optimization
stage. A well-known limitation of such sequential frameworks
is error propagation: any inaccuracies from the initial demand
prediction are inevitably carried into the optimization model,
which may then yield a solution that is optimal for the flawed
prediction but suboptimal in reality. To circumvent error prop-
agation, we replace the deterministic objective function with
a feature-driven profit prediction model based on a RF. This
model directly learns the relationship from system features
and operator decisions to the final predicted profit, thereby
avoiding the intermediate prediction step and its associated
error accumulation. To embed this new objective model into
our MIP, we apply the RF-to-MIP conversion technique from
Biggs et al. (2022) [4].
The core of this integrated method is to embed the entire
trained RF structure as a set of constraints within a MIP.
Figure 1 illustrates the workflow of training and deploying
the RF model. The RF is first trained using historical records,
which include exogenous features like weather and date, and
operational data such as allocation and pricing decisions, along
with the resulting profit. In the second stage, the trained model
is deployed for optimization. It takes the current day’s exoge-
nous information as fixed inputs. The allocation and pricing
actions are treated as decision variables, and an optimization
solver selects their optimal values. This process effectively
navigates a path through the tree’s branches to a leaf node
that predicts a final profit. The objective is to determine the
set of decisions that leads to the leaf with the maximum profit.
Suppose there are |H| trees in the RF, and the leaf node of
each tree h represents the predicted operational profit P(y, c),
where y = (x, ˆu) is the decision variable and c is the feature.
Our goal is to maximize the operation profit by maximizing
P(y, c). Let N h denote the number of nodes (excluding
the leaves) in tree h. For each interior node n, let pn, ln
and rn be the immediate parent, the left and right children,
respectively. Let Lh represent the set of leaves in tree h, and let
P h
m (m ∈Lh) denote the score of each leaf. Given the trained
RF, we introduce binary variables qh
n1,n2 to select branches and
decide the range of the variables. The resulting feature-driven
optimization model is as follows:
max
y,q
1
|H|
|H|
X
h=1
X
m∈Lh
P h
mqh
pm,m
(7)
s.t.
an,hy −M
 1 −qh
n,ln

≤bh
n, ∀h ∈H, n ∈N h,
(8)
an,hy + M
 1 −qh
n,rn

≥bh
n, ∀h ∈H, n ∈N h, (9)
qh
n,ln + qh
n,rn = qh
pn,n, ∀h ∈H, n ∈N h,
(10)
X
n∈Lh
qh
pn,n = 1, ∀h ∈H,
(11)
qh
n,ln, qh
n,rn, qh
pn,n ∈{0, 1}, ∀h ∈H, n ∈N h,
(12)
Constraints (2)-(6).
Objective (7) is to maximize the average predicted profit
across all trees in the forest. Constraint (8) and constraint
(9) are big-M logical constraints to determine which leaf the
solution y lies in. Constraint (10) ensures that if a parent
node is inactive, its children must also be inactive; but if any
child is active, then the parent must also be active. Constraint
(11) guarantees that within each tree h, only one leaf can be
active. Constraint (12) defines the binary variables. Finally, the
solution must also satisfy the operational constraints (2)-(6)
from the previous section to ensure its physical feasibility.
C. LLM-embedded Feature-Driven Model
While our feature-driven model can find profit-maximizing
strategies, it faces two key practical challenges in large-scale
urban operations. First, operators often have complex and


--- Page 5 ---
5
Fig. 1. Training and Usage Process of the random forest
dynamic goals that are difficult to translate into a mathemat-
ical objective. Second, the sheer scale of urban optimization
problems often makes finding exact solutions computationally
prohibitive in a reasonable timeframe. To address both chal-
lenges, we introduce an LLM-powered agent that performs
two synergistic functions: 1) dynamic objective formulation to
translate user queries into formal objectives, and 2) heuristic
model reduction to accelerate computation.
To accelerate computation, the agent employs a novel
heuristic strategy learned from a small set of pre-solved opti-
mal instances. By analyzing these few-shot examples, which
pair historical scenarios with their true optimal decisions, the
LLM learns to identify a subset of decision variables y′ ⊂y
that consistently exhibit low sensitivity to shaping the optimal
solution. Then it proposes fixing these variables to their
historical average values, ¯y′, leaving a smaller set of active
decision variables, ˆy = y \ y′, to be optimized. This model
refinement process is achieved by employing a prompted
LLM, which we formally denote as LLM(Q; D, P PP). In
this formulation, a structured prompt P PP, which incorporates
the user’s query Q, instructs the LLM to analyze historical
data D as the evidence base for identifying low-sensitivity
variables [33]. The LLM agent is described in detail in the
next section. This dual-functionality results in a bi-objective
optimization problem that we solve using a lexicographical
method. The primary goal is to maximize the predicted profit.
The secondary goal is to optimize the new LLM-generated
objective, LLM(Q; D, P IG), where P IG denotes the predefined
prompts. Define A(c)F(y) ≤K(c) to depict the feasible
region and constraints related to y. After reducing the scope
of the RF-based model by fixing some decision variables, we
have the following optimization problem:
max
ˆy,q
1
|H|
|H|
X
h=1
X
m∈Lh
P h
mqh
pm,m
(13)
min
ˆy,q
LLM(Q; D, P IG)
(14)
s.t.
A(c)F(ˆy, ¯y′) ≤K(c),
(15)
Constraints (8)-(12).
Objective (14) is generated by the LLM agent based on
the user’s query Q and is treated as a secondary objective,
optimized only after the primary, RF-based objective (7) is
maximized. Constraint (15) compactly represents the feasible
region of the problem, where ˆy and the fixed variables ¯y′ must
satisfy all operational constraints. Constraints (8)-(12) involve
binary variables to model the branch and leaf selection in RF.
After fixing some redundant variables y′, RideAgent offers
a more agile model.
IV. LLM-BASED AGENT
This section details the architecture and workflow of
our proposed RideAgent, the framework responsible for the
model’s agility and for orchestrating the overall optimization
process. We first present its multi-component framework,
which synergizes the reasoning capabilities of LLMs with
formal optimization methods We then conclude by discussing
the core intuition behind its design, which we term Small-
Sample Guided Optimization.
A. The RideAgent Framework
The macro-structure of RideAgent mimics a human-like
cooperative decision-making process, tailored for the taxi
pre-allocation and pricing problem
[38, 40]. The agent’s
architecture, visualized in Figure 2, is composed of five key
components that sequentially process a user’s natural language
(NL) query to produce an optimized operational decision. The
detailed workflow is formally delineated in Algorithm 1.
Step 1: Problem Matcher. The process begins when a
user submits a natural language (NL) query Q focused on
a particular objective within a defined region (e.g., How to
improve the electric taxi dispatching efficiency?). Such a query
is then analyzed by Problem Matcher (see Figure 2 Step 1)
to identify an appropriate domain-specific agent (e.g., electric
taxis) and routes the request for further processing.
Step 2: Indicator Generator. Using a predefined prompt
P IG, the indicator generator (see Figure 2 Step 2) formulates
NL queries Q into a mathematical function f(y; w) based on
operation decisions y (e.g., number of allocated electric taxis
and average order price for high SOC taxis) and parameters
w in the feature-driven programming.
f(y; w) = LLM(Q; D, P IG) : R|Y|×|W| →R+,
(16)
where Y, W denote the feasible domain of decision variables
y and set of parameters w, respectively. The objective function
f(y; w) is then integrated into the objective of MIP for
re-optimization purposes. Furthermore, the historical opera-
tional database D is available in the form of an API that
generates Structured Query Language (SQL) by an LLM.
D contains rich historical taxi operational data and a small
amount of historical optimal decisions that maximize operating
profits. Finally, Code Safeguard scrutinizes the output code
of f(y; w) to ensure compliance with the coding standards
required by solvers like Gurobi and CPLEX [16].
Step 3: Problem Tailor. The role of the Problem Tailor
is to prune the vast decision space by identifying the most
influential decision variables relevant to the query Q. A
metric S is established to evaluate how well a given solution
satisfies the query Q. This score is typically defined as the
percentage improvement of the indicator function f for a


--- Page 6 ---
6
Fig. 2. The agent framework
new solution y∗
t compared to a baseline, where all decision
variables are set to their historical average values ¯yhist:
St = f(ˆy∗
t ,¯y′;w)−f(¯yhist;w)
f(¯yhist;w)
.
This module operates inside the iterative loop. The prompt
P PP
t (ˆyt−1, St−1) in iteration t contains previously remaining
variables ˆyt−1 and satisfaction score St−1. Based on this
information, the LLM provides guidance on which subset of
variables y′
t is least sensitive and can be fixed to their historical
average values ¯y′
t. This leaves a smaller, more promising set
of active variables ˆyt = y \ y′
t for the solver to focus on.
This interaction can be described by the following functional
mapping:
ˆyt = LLM(Q; D, P PP
t (ˆyt−1, St−1)).
(17)
After that, Code Safeguard reviews the constraints generated
by the LLM to ensure they adhere to the syntax requirements
of optimization solvers.
Step 4: RF-based Feature-Driven Model. The RF-based
feature-driven model maxy∈Y g(y; w) (see details in the pre-
vious section) consists of two components (Figure 2 Step 4):
(i) Pre-trained RF, tailored to a particular urban optimization
goal (taxi operation profits), functions as a predictive analytics
tool. (ii) MIP: Drawing on previous research [4], the structure
of the RF is embedded within an MIP model, as formulated in
Section III. The MIP’s objectives encompass operational tar-
gets as well as indicators related to the query f(y; w) supplied
by Indicator Generator. The MIP takes the reduced set of active
variables ˆyt and the fixed variable constraints (y′
t = ¯y′
t) and
solves the bi-objective optimization problem lexicographically.
Subsequently, the agent proceeds to optimize the problem on
a more focused decision subset:
ˆy∗
t = arg max
ˆy [g(ˆy, ¯y′
t; w), f(ˆy, ¯y′
t; w)].
(18)
Step 5: Response Prompter. The framework iteratively
performs steps 3 and 4, generating a sequence of improving
solutions (ˆy∗
t , St). After the loop terminates (i.e., when the
satisfaction score St no longer improves), Response Prompter
translates the optimal solutions and associated scores (y∗, S∗)
into a clear, understandable natural language summary for the
end users.
B. Core Intuition: Small-Sample Guided Large-Scale Opti-
mization
The central challenge in urban operations management is
bridging the gap between high-level, often ambiguous, nat-
ural language objectives and the vast, combinatorial solution
space of mathematical optimization. A brute-force approach is
computationally intractable. The core intuition of RideAgent
is to avoid this by establishing a synergistic, iterative dialogue
between a heuristic guide and a rigorous solver. This concept,
which we term Small-Sample Guided Optimization, is the
cornerstone of our framework. Instead of treating the problem
monolithically, we decompose it into two specialized roles:
1. Heuristic Guide (LLM-powered Problem Tailor): This
module acts like an experienced human operations manager.
It leverages the LLM’s reasoning capabilities to interpret the
user’s query Q in the context of historical data D. It does not
attempt to find the globally optimal solution itself. Instead,
its purpose is to provide intelligent heuristics—to identify
the most promising sub-region of the vast solution space and
advise the solver on where to focus its efforts. This is achieved


--- Page 7 ---
7
Algorithm 1 RideAgent pseudocode
Input: User’s query Q, Max iterations Tmax, LLM prompts
P IG and P PP
0 .
Output: Best found decision variables ybest and satisfaction
score Sbest.
1: Initialization: ¯yhist ←GetHistoricalAverage(D), t ←0,
S−1 ←−∞, S0 ←0. ybest ←¯yhist, Sbest ←S0.
2: Problem Matcher: Determine an area-specific agent.
3: Indicator Generator: Generate query-relevant objective
function and code: f(y; w) = LLM(Q; D, P IG) .
4: Code Safeguard: Check the code generated by LLMs.
5: while t < Tmax and St > St−1 do
6:
t ←t + 1
7:
a. Problem Tailor:
8:
1. Call empirical data D from a database.
9:
2. Output the set of names for remained decision
variables ˆyt: ˆyt = LLM(Q; D, P PP
t (ˆyt−1, St−1)).
10:
3. Add variable constraints for y′
t = y\ˆyt: y′
t ←¯y′
t.
11:
b. Solve the reduced bi-objective MIP:
ˆy∗
t ←max
ˆ
yt (g(ˆyt, ¯y′
t; w), f(ˆyt, ¯y′
t; w))
12:
1. Update optimal solutions: y∗
t ←(ˆy∗
t , ¯y′
t).
13:
2. Update St = f(ˆy∗
t ,¯y′;w)−f(¯yhist;w)
f(¯yhist;w)
.
14:
if St > Sbest then
15:
Sbest ←St, ybest ←y∗
t .
16:
end if
17: end while
18: return ybest, Sbest.
by selecting a subset of decision variables ˆy for optimization
and fixing the remaining variables to pre-determined values.
2. Rigorous Solver (RF-based Feature-Driven Model): This
module is highly effective at finding a mathematically veri-
fiable optimal solution within a well-defined and reasonably
sized problem space. By accepting the advice from the Heuris-
tic Guide, it can direct its powerful search capabilities to the
most promising areas and bypass the need to explore low-
quality regions of the solution space.
The iterative loop between these two components creates a
powerful feedback mechanism. The Guide proposes a search
direction; the Solver explores it and reports back its findings;
the satisfaction score St quantifies the quality of this result
and informs the Guide’s next suggestion. This process allows
RideAgent to efficiently navigate an immense decision space
by combining the contextual understanding and flexible rea-
soning of LLMs with the mathematical precision of traditional
optimization solvers.
V. CASE STUDY
In this section, we conduct a case study using a real-
world taxi dataset from New York City to validate the
RideAgent framework. The numerical experiments are de-
signed to demonstrate RideAgent’s capabilities in translating
diverse user objectives into actionable decisions and to evalu-
ate the framework’s computational efficiency.
A. Dataset Description
Experiments are conducted using New York City yellow
taxi trip records in 2016 [36]. The trip records of New York
yellow taxis include information such as trip start/end times
and locations. Since the dataset lacks information on real-
time taxi counts and historical dispatch decisions, we simulate
this data using a flow-based model where taxis completing
a trip in a zone become available supply for the next time
step. Weather data for New York City in 2016, including
features like temperature and dew point, are sourced from
Kaggle
[20]. The day of the week was also included as an
exogenous feature. The inconvenience cost, ˆwij, is set to $0.5
per kilometer. The operator’s fixed share, θ, is 0.2 and the
online booking fee bj = $5 per trip. Assume that electric
taxis have three discrete power levels: low, medium, and high,
corresponding to SOC of 0, 1, and 2 respectively. For spatial
analysis, all trip origins and destinations are clustered into
50 zones based on their geographical locations. The morning
peak time is defined as 8:00 a.m. to 8:30 a.m. Our analysis of
historical data reveals a consistent supply-demand imbalance:
8 zones regularly exhibit unmet demand (defined as “demand
areas”), while the remaining 42 have surplus taxis (defined as
“supply areas”). The RF model, which predicts operational
profit, is trained on the morning peak operation data and
exogenous features of 366 days in 2016. In the RF, the number
of trees is 200 and the maximum depth is limited to 150.
30% of the data is used as a test set. The RF achieves an
R-squared value of 93.4% and 60.7% on the training set and
test set, respectively. To create a small sample of historical
optimal decisions, we solve for the profit-maximizing (obj
13) allocation and pricing optimal decisions for 14 randomly
selected days. These optimal decisions are provided as input
to the agent as small sample optimal decision data.
All experiments are conducted on a macOS system equipped
with an Apple M1 Pro CPU and 16GB of RAM. With GPT-4o
mini as the core LLM, The agent framework is implemented
in Python leveraging Langchain, a standard framework for
creating applications powered by LLMs.
B. Experimental Settings
We evaluate the accuracy of objective generation and the
efficiency of model solving using a unit-testing methodology,
inspired by software engineering [23]. To ensure a compre-
hensive evaluation, we design a series of 18 queries, 15
of which can be formulated as linear objective functions,
and the remaining three need to be formulated as nonlinear
objective functions. The relevant objective function of each
query is accompanied by a correct answer verified by human
annotators. To account for the inherent stochasticity of LLM
outputs [5], each query is executed 10 times. The reported
accuracy and efficiency metrics are the average over these 10
runs. The underlying MIP models are solved using Gurobi
10.0.
C. Experiment Results
1) Tests on the Accuracy of Objective Function Generation:
We first evaluate the ability of the Indicator Generator to


--- Page 8 ---
8
Fig. 3. Effect of Fixed Variable Scale on linear objective function gaps
Fig. 4. Agent performance on different user queries
accurately translate a user’s natural language query into a
valid objective function. The assessment is performed by
comparing the LLM-generated function against a human-
annotated, ground-truth objective function. A key challenge is
that functionally equivalent objectives can be expressed with
syntactically different code. To account for this, we employ
two distinct metrics based on the Jaro-Winkler distance: text
similarity and result similarity. These metrics quantify the
similarity between the “generated objective function” and the
“standard objective function” concerning their codes and math-
ematical essence, respectively. The experiments are conducted
in both an in-sample setting (where the model is tested on a
query it has seen as an example in its prompt) and an out-of-
sample setting (where the model is tested on a novel query).
The results presented in Tables II and III lead to two
key findings. First, RideAgent demonstrates strong zero-shot
capability. Even with zero examples provided in the prompt, it
achieves a high text similarity of 86% for both linear and non-
linear objectives, which indicates a robust intrinsic ability to
interpret user requests. Second, the performance consistently
improves as more examples are included in the prompt, which
demonstrates effective few-shot learning. For instance, in the
linear out-of-sample test, result similarity increases from 0.72
to 0.81 as the number of prompts grows from 0 to 10. These
TABLE II
ACCURACY TEST RESULTS FOR LINEAR OBJECTIVES
1 The term “Prompts” refers to the number of query-function pairs
provided to the LLM in each experiment.
Prompts1
In-sample
Out-of-sample
Result
similarity
Text
similarity
Result
similarity
Text
similarity
0
——
——
0.72
0.86
5
0.85
0.94
0.79
0.90
10
0.89
0.95
0.81
0.91
15
0.93
0.96
——
——
TABLE III
ACCURACY TEST RESULTS FOR NONLINEAR OBJECTIVES
Prompts1
In-sample
Out-of-sample
Result
similarity
Text
similarity
Result
similarity
Text
similarity
0
——
——
0.71
0.86
1
0.81
0.94
0.75
0.85
2
0.83
0.95
0.78
0.84
3
0.83
0.96
——
——
results confirm that RideAgent can leverage the generalization
capabilities of LLMs to reliably formulate objectives that align
with user intent. Furthermore, they demonstrate that incorpo-


--- Page 9 ---
9
TABLE IV
RESULTS OF THE EFFICIENCY TEST FOR LINEAR OBJECTIVES
Fixed Variable
Scale
In-sample
Out-of-sample
RideAgent
FULL
RideAgent
FULL
Optimization GAP(%)
CPU time
(s)
CPU time
(s)
Optimization GAP(%)
CPU time
(s)
CPU time
(s)
RF-Obj gap
QR-Obj Gap
RF-Obj Gap
QR-Obj Gap
[0-50]
0.41
1.73
65.19
120.07
0.57
2.68
99.76
150.81
[50-100]
1.23
1.31
15.81
96.16
1.10
5.78
102.02
159.34
[100-150]
1.17
0.05
16.69
85.75
1.20
5.78
66.51
156.51
[150-250]
1.61
2.07
19.42
111.21
1.47
3.82
38.08
128.68
TABLE V
RESULTS OF THE EFFICIENCY TEST FOR NONLINEAR OBJECTIVES
Fixed Variable
Scale
Dispatching efficiency
Market share
Supply-demand matching degree
CPU time(s)
RF-Obj
Gap(%)
QR-Obj
Gap(%)
CPU time(s)
RF-Obj
Gap(%)
QR-Obj
Gap(%)
CPU time(s)
RF-Obj
Gap(%)
QR-Obj
Gap(%)
Agent
FULL
Agent
FULL
Agent
FULL
10%
133.93
221.18
1.08
13.90
209.67
261.41
0.10
4.10
35.29
162.53
2.42
2.82
20%
31.00
225.06
2.60
19.54
11.45
241.29
3.12
3.88
98.78
158.40
0.20
2.22
30%
160.31
223.75
2.84
14.82
185.17
236.24
0.36
13.52
88.14
156.69
0.88
5.52
rating a small amount of domain-specific expert knowledge via
few-shot prompting is an effective strategy to mitigate LLM
hallucinations and enhance generation accuracy.
2) Tests on the Efficiency of Model Solving: In this section,
we evaluate the core trade-off of the RideAgent framework: its
ability to reduce computational time while maintaining near-
optimal solution quality.
a) Motivation and Benchmark: While existing LLM-
assisted OR tools (OptiMUS [2], ORPO [43], OptiGuide [23])
have advanced human-computer interaction, they are not de-
signed for the specific challenge of our case study, which
requires integrating rich historical data to heuristically guide
a large-scale feature-driven optimization model. To provide
a rigorous benchmark, we compare RideAgent’s performance
against a baseline model, which we term the “FULL” model.
This is the complete, feature-driven MIP model solved without
any heuristic variable fixing from the Problem Tailor.
b) Evaluation Metrics:
• CPU Time: The time required to solve the optimization
problem.
• Time Gap: The reduction in computational time achieved
by RideAgent relative to the FULL model. It is calculated
as (CPU TimeFULL −CPU TimeRideAgent).
• RF-Obj Gap: The percentage deviation of RideAgent’s
primary objective (operational profit) from the FULL
model’s optimal profit.
• QR-Obj Gap: The percentage deviation of RideAgent’s
secondary, query-relevant objective from that of the
FULL model.
Together, these metrics allow us to quantify the trade-off
between computational efficiency (CPU Time) and solution
optimality (the two objective gaps). For all tests, the number
of few-shot examples (Prompts) is fixed at 8. Define the metric
Fixed Variable Scale as the number of decision variables
heuristically fixed by RideAgent.
c) Performance on Linear Query-Relevant Objectives:
We first analyze the results for linear query-relevant objectives.
Figure 3 illustrates the overall effect of the Fixed Variable
Scale while Table IV provides the aggregated numerical data.
Figure 3 provides a detailed analysis using a log-transformed
x-axis to better visualize trends across different scales. Figure
3(a) illustrates the clear and growing computational advantage
of our approach. It reveals that RideAgent’s solution time
is consistently lower than the FULL model’s, and crucially,
this time advantage widens as more variables are fixed. This
efficiency gain, however, introduces a trade-off in solution
quality, which is detailed in Figure 3(b). The box plots
show that as the Fixed Variable Scale increases, both the
median objective gaps and their variance tend to increase.
Furthermore, the in-sample tests (blue boxes) consistently
show lower medians and tighter distributions than the out-of-
sample tests (orange boxes). This finding demonstrates that
providing relevant examples improves the reliability of the
agent’s heuristic guidance. Table IV quantifies the increasing
gap trend with concrete numbers: the in-sample RF-Obj Gap
climbs from 0.41% at the lowest scale to 1.61% at the highest.
Simultaneously, it also confirms that even at its peak, this
primary objective gap remains at an acceptably low level.
To provide a more granular view, Figure 4 breaks down the
performance for each of the 15 specific linear user queries.
The RF-Obj Gap (left panel) remains low across all queries
(typically below 1.2%), and the Time Gap (right panel) is con-
sistently large. The QR-Obj Gap (middle panel) exhibits more
variability. Notably, for queries like #4 (“Improve number of


--- Page 10 ---
10
TABLE VI
COMPARISON RESULTS WITH CUTTING METHODS
Cuts Name
In-sample
Out-of-sample
Time Gap
RF-Obj Gap
QR-Obj Gap
Time Gap
RF-Obj Gap
QR-Obj Gap
CliqueCuts [3]
39.46s(30.49%)
0.80%
5.13%
50.75s(42.58%)
1.08%
5.30%
CoverCuts [6]
43.18s(33.09%)
0.80%
5.13%
55.44s(46.75%)
1.08%
5.09%
GomoryCuts [13]
53.00s(43.01%)
0.80%
5.26%
62.33s(52.48%)
1.08%
4.97%
GUBCoverCuts [39]
46.45s(36.80%)
0.80%
5.18%
59.35s(49.94%)
1.08%
5.02%
MIRCuts [26]
46.56s(36.46%)
0.80%
5.13%
61.31s(51.65%)
1.08%
5.27%
Total average
45.73s(35.97%)
0.80%
5.16%
57.83s(48.68%)
1.08%
5.13%
Fig. 5. Objective function gaps and time advantage of RideAgent compared to different cutting methods
high-powered taxis”) and #12 (“Reduce complaint rate”), the
QR-Obj Gap is extremely low. This suggests that the historical
data provided strong guidance for these particular objectives.
d) Performance on Nonlinear Query-Relevant Objec-
tives: The results for more computationally intensive nonlinear
queries are summarized in Table V. For these tests, the Fixed
Variable Scale are set to specific percentages (10%, 20%, 30%)
of the 1032 total decision variables. RideAgent’s advantage is
even more pronounced in this context. The average CPU time
is reduced by a remarkable 50.04%, while the RF-Obj Gap
remains exceptionally low at an average of just 1.51% across
all tests. However, the QR-Obj Gap is significantly higher
than in the linear case, and it increases substantially as more
variables are fixed. This result provides a crucial insight into
the framework’s mechanics. The historical guidance data is
optimized for the primary profit objective (RF-Obj). When a
user introduces a conflicting, nonlinear objective, this guidance
is less relevant. As a result, the deviation from the optimal
solution for that specific query is larger. This highlights that
the effectiveness of the heuristic depends on the alignment
between the historical guidance data and the new user query.
3) Comparison with Cutting Planes Methods: We bench-
mark our LLM-guided heuristic against five standard cutting
planes (CliqueCuts, CoverCuts, GomoryPassesCuts, GUBCov-
erCuts, MIRCuts) on linear objectives. The performance of
RideAgent is compared against solving the FULL model with
only one of these cut types disabled at a time, providing a
direct comparison of solution acceleration strategies.
Figure 5 presents a visual comparison of the performance
trade-offs, while Table VI provides the corresponding mean
values. The left panel of Figure 5 shows that the RF-Obj Gap
for RideAgent is consistently low, with a tight distribution,
especially for the in-sample (blue) tests. In contrast, the middle
and right panels display a more complex, counter-intuitive
pattern. Specifically, in-sample tests result in a surprisingly
higher median and variance for the QR-Obj Gap (middle
panel), alongside a smaller average Time Gap (right panel).
Both phenomena stem from the aggressive nature of the
heuristic generated by the LLM for high-confidence, in-sample
queries. This strategy retains profit-critical variables as active
and creates a reduced model that is ideal for the primary profit
objective but challenging for any conflicting secondary goal.
This has two direct consequences: first, in the lexicographical
second step, the solver is forced into a compromise further
from the QR-Obj optimum, thus increasing its gap. Second,
this same difficult search process increases RideAgent’s so-
lution time, which shrinks the average Time Gap. The high
variance in both metrics is also explained by this “high-risk,
high-reward” heuristic. If the heuristic aligns with the user’s
query, the problem is solved almost instantly, which yields a
large Time Gap. If the two conflict, the solver struggles with
the difficult second-stage problem, which leads to a very long
solution time and thus a small or even negative Time Gap.
Conversely, out-of-sample queries yield more conservative
heuristics and lead to lower variance.


--- Page 11 ---
11
Despite these dynamics, the Time Gap box plots are almost
entirely in positive territory, which indicates that RideAgent
consistently outperforms disabling a standard cut. Table VI
quantifies these visual trends with precise numbers. On av-
erage, the LLM-guided strategy achieves a time saving of
51.78 seconds (42.32%) while incurring only minor objective
gaps (an average RF-Obj Gap of 0.94% and QR-Obj Gap
of 5.15%). These results demonstrate a favorable balance
between computational efficiency and solution quality.
VI. CONCLUSION
This paper introduces RideAgent, a novel agent framework
designed to bridge the persistent gap between ambiguous hu-
man objectives and the precise requirements of mathematical
optimization. Our core contribution is a new paradigm we term
Small-Sample Guided Optimization, where an LLM acts as
a heuristic guide for a feature-driven MIP model. The LLM
interprets user intent and, guided by a small set of historical
optimal examples, prunes the vast decision space so that the
rigorous MIP solver can focus its computational power on the
most promising regions.
Our case study provides robust empirical validation for
this paradigm. The results demonstrate that RideAgent is not
only conceptually novel but also practically effective. First, its
Indicator Generator reliably translates natural language into
valid objectives, and it achieves up to 86% text similarity
in zero-shot settings. Second, the framework demonstrates
remarkable efficiency. It reduces CPU time by over 80%
for complex nonlinear problems while keeping the primary
objective gap below 1.5%. Finally, its heuristic strategy proves
more effective than standard MIP acceleration techniques, and
it outperforms five established cutting plane methods by an
average of 52 seconds per solve.
Beyond the immediate application of taxi operations, we
believe the Small-Sample Guided Optimization framework
offers a generalizable and powerful approach for a wide range
of complex decision-making problems in domains such as
supply chain management, logistics, and resource scheduling.
By creating an effective bridge between human intuition
and mathematical optimization, this paradigm promises to
democratize the power of operations research and make it
more accessible and responsive to the dynamic needs of
practitioners.
Future research could proceed in several exciting directions.
Enhancing the underlying predictive models would further
improve the quality of the primary objective. Investigating
more sophisticated dialogue protocols between the LLM and
the solver could unlock further efficiencies. Finally, deploying
and testing the RideAgent framework in other real-world op-
erational environments will be a crucial next step in validating
its broader applicability and impact.
REFERENCES
[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama
Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo
Almeida, Janko Altenschmidt, Sam Altman, Shyamal
Anadkat, et al. Gpt-4 technical report. arXiv preprint
arXiv:2303.08774, 2023.
[2] Ali AhmadiTeshnizi, Wenzhi Gao, and Madeleine Udell.
Optimus: Optimization modeling using mip solvers and
large language models. arXiv preprint arXiv:2310.06116,
2023.
[3] Alper Atamt¨urk, George L Nemhauser, and Martin WP
Savelsbergh.
Conflict graphs in solving integer pro-
gramming problems. European Journal of Operational
Research, 121(1):40–55, 2000.
[4] Max Biggs, Rim Hariss, and Georgia Perakis.
Con-
strained optimization of objective functions determined
from random forests. Production and Operations Man-
agement, 32(2):397–415, 2022.
doi: 10.1111/poms.
13877.
[5] Stephen
Casper,
Xander
Davies,
Claudia
Shi,
Thomas
Krendl
Gilbert,
J´er´emy
Scheurer,
Javier
Rando,
Rachel
Freedman,
Tomasz
Korbak,
David
Lindner, Pedro Freire, et al.
Open problems and
fundamental limitations of reinforcement learning from
human feedback.
arXiv preprint arXiv:2307.15217,
2023.
[6] Sebastian Ceria, C´ecile Cordier, Hugues Marchand, and
Laurence A Wolsey. Cutting planes for integer programs
with general integer variables. Mathematical program-
ming, 81:201–214, 1998.
[7] Camilo Chac´on Sartori, Christian Blum, and Gabriela
Ochoa.
Large language models for the automated
analysis of optimization algorithms. In Proceedings of
the Genetic and Evolutionary Computation Conference,
pages 160–168, 2024.
[8] Mengjing Chen, Weiran Shen, Pingzhong Tang, and Song
Zuo. Dispatching through pricing: modeling ride-sharing
and designing dynamic prices. In Proceedings of the 28th
International Joint Conference on Artificial Intelligence,
IJCAI’19, page 165–171, 2019. ISBN 9780999241141.
[9] Qi Chen, Yanzhe Lei, and Stefanus Jasin.
Real-time
spatial–intertemporal pricing and relocation in a ride-
hailing network: Near-optimal policies and the value of
dynamic pricing. Operations Research, 2023.
[10] Ulrik Eilertsen, Olav M Falck-Pedersen, Jone V Hen-
riksen, Kjetil Fagerholt, and Giovanni Pantuso.
Joint
relocation and pricing in electric car-sharing systems.
European Journal of Operational Research, 315(2):553–
566, 2024.
[11] Maria Pia Fanti, Agostino Marcello Mangini, Michele
Roccotelli, and Biagio Silvestri. Innovative approaches
for electric vehicles relocation in sharing systems. IEEE
Transactions on Automation Science and Engineering, 18
(3):1116–1130, 2021.
[12] Maria Pia Fanti, Agostino Marcello Mangini, Michele
Roccotelli, and Bartolomeo Silvestri.
Innovative ap-
proaches for electric vehicles relocation in sharing sys-
tems.
IEEE Transactions on Automation Science and
Engineering, 19(1):21–36, 2022.
[13] Ralph E Gomory. Outline of an algorithm for integer
solutions to linear programs and an algorithm for the
mixed integer problem. Springer, 2010.


--- Page 12 ---
12
[14] Zhaowei Hao, Long He, Zhenyu Hu, and Jun Jiang.
Robust vehicle pre-allocation with uncertain covariates.
Production and Operations Management, 29(4):955–972,
2020.
[15] S. Hasija, Z. J. M. Shen, and C. P. Teo.
Smart city
operations: Modeling challenges and opportunities. Man-
ufacturing & Service Operations Management, 22(1):
203–213, 2020.
[16] Qianyu He, Jie Zeng, Wenhao Huang, Lina Chen, Jin
Xiao, Qianxi He, Xunzhe Zhou, Jiaqing Liang, and
Yanghua Xiao. Can large language models understand
real-world complex instructions? In Proceedings of the
AAAI Conference on Artificial Intelligence, volume 38,
pages 18188–18196, 2024.
[17] Frederick S Hillier and Gerald J Lieberman. Introduction
to operations research. McGraw-Hill, 2015.
[18] Chenyu Huan, Zhengyang Tang, Shixi Hu, Ruoqing
Jiang, Xin Zheng, Dongdong Ge, Benyou Wang, and
Zizhuo Wang. Orlm: A customizable framework in train-
ing large models for automated optimization modeling.
Operations Research, 2025.
[19] Sen Huang, Kaixiang Yang, Sheng Qi, and Rui Wang.
When large language model meets optimization. arXiv
preprint arXiv:2405.10098, 2024.
[20] Kaggle.
New york city taxi trip - hourly weather
data.
https://www.kaggle.com/datasets/meinertsen/
new-york-city-taxi-trip-hourly-weather-data, 2017.
[21] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-
taka Matsuo, and Yusuke Iwasawa.
Large language
models are zero-shot reasoners.
Advances in neural
information processing systems, 35:22199–22213, 2022.
[22] Damianos Kypriadis, Grammati Pantziou, Charalampos
Konstantopoulos, and Damianos Gavalas.
Optimizing
relocation cost in free-floating car-sharing systems. IEEE
Transactions on Intelligent Transportation Systems, 21
(9):4017–4030, 2020. doi: 10.1109/TITS.2020.2995197.
[23] Beibin Li, Konstantina Mellou, Bo Zhang, Jeevan
Pathuri, and Ishai Menache.
Large language mod-
els for supply chain optimization.
arXiv preprint
arXiv:2307.03875, 2023.
[24] Qingyang Li, Lele Zhang, and Vicky Mak-Hau.
Syn-
thesizing
mixed-integer
linear
programming
models
from natural language descriptions.
arXiv preprint
arXiv:2311.15271, 2023.
[25] Zhidan Liu, Guofeng Ouyang, Bolin Zhang, Bo Du, Chao
Chen, and Kaishun Wu.
Joint order dispatching and
vehicle repositioning for dynamic ridesharing.
IEEE
Transactions on Mobile Computing, 24(4):2628–2643,
2025. doi: 10.1109/TMC.2024.3493974.
[26] Hugues Marchand and Laurence A Wolsey. Aggregation
and mixed integer rounding to solve mips. Operations
research, 49(3):363–371, 2001.
[27] Younes Mechqrane, Christian Bessiere, and Ismail Elab-
bassi. Using large language models to improve query-
based constraint acquisition.
In Proceedings of the
Thirty-Third International Joint Conference on Artificial
Intelligence, IJCAI-24, pages 1916–1925, 2024.
doi:
10.24963/ijcai.2024/212. URL https://doi.org/10.24963/
ijcai.2024/212.
[28] Allen Nie, Ching-An Cheng, Andrey Kolobov, and
Adith Swaminathan.
The importance of directional
feedback for llm-based optimizers.
arXiv preprint
arXiv:2405.16434, 2024.
[29] Erhun ¨Ozkan. Joint pricing and matching in ride-sharing
systems. European Journal of Operational Research, 287
(3):1149–1160, 2020.
[30] Giovanni Pantuso. Exact solutions to a carsharing pricing
and relocation problem under uncertainty. Computers &
Operations Research, 144:105802, 2022.
[31] Mengyi Qi and Zuo-Jun (Max) Shen. Integrating pre-
diction/estimation and optimization with applications in
operations management.
In Tutorials in Operations
Research: Emerging and Impactful Topics in Operations,
pages 36–58. INFORMS, 2022.
[32] Wei Qi and Zuo-Jun Max Shen.
A smart-city scope
of operations management. Production and Operations
Management, 28(2):393–406, 2019.
[33] Alireza Salemi, Surya Kallumadi, and Hamed Zamani.
Optimization methods for personalizing large language
models through retrieval augmentation. In Proceedings
of the 47th International ACM SIGIR Conference on
Research and Development in Information Retrieval,
pages 752–762, 2024.
[34] Sanket Shah, Meghna Lowalekar, and Pradeep Varakan-
tham.
Joint pricing and matching for city-scale ride-
pooling. In Proceedings of the International Conference
on Automated Planning and Scheduling, volume 32,
pages 499–507, 2022.
[35] Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li,
Weiming Lu, and Yueting Zhuang. Hugginggpt: Solving
ai tasks with chatgpt and its friends in hugging face.
Advances in Neural Information Processing Systems, 36,
2024.
[36] Taxi & Limousine Commission.
Tlc trip record data.
https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.
page, 2024.
[37] Sadana
Utsav,
Abhilash
Chenreddy,
Erick
Delage,
Alexandre Forel, Emma Frejinger, and Thibaut Vidal. A
survey of contextual optimization methods for decision-
making under uncertainty. European Journal of Opera-
tional Research, 2024.
[38] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,
et al.
Chain-of-thought prompting elicits reasoning in
large language models. Advances in neural information
processing systems, 35:24824–24837, 2022.
[39] Laurence A Wolsey. Valid inequalities for 0–1 knapsacks
and mips with generalised upper bound constraints. Dis-
crete Applied Mathematics, 29(2-3):251–261, 1990.
[40] Ziyang Xiao, Dongxiang Zhang, Yangjun Wu, Lilin Xu,
Yuan Jessica Wang, Xiongwei Han, Xiaojin Fu, Tao
Zhong, Jia Zeng, Mingli Song, et al. Chain-of-experts:
When llms meet complex operations research problems.
In The Twelfth International Conference on Learning
Representations, 2023.
[41] Jinglue
Xu,
Jialong
Li,
Zhen
Liu,
Nagar
An-


--- Page 13 ---
13
thel Venkatesh Suryanarayanan, Guoyuan Zhou, Jia Guo,
Hitoshi Iba, and Kenji Tei. Large language models syn-
ergize with automated machine learning. arXiv preprint
arXiv:2405.03727, 2024.
[42] Min Xu, Qiang Meng, and Zhiyuan Liu. Electric vehicle
fleet size and trip pricing for one-way carsharing services
considering vehicle relocation and personnel assignment.
Transportation Research Part B: Methodological, 111:
60–82, 2018.
[43] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao
Liu, Quoc V Le, Denny Zhou, and Xinyun Chen.
Large language models as optimizers.
arXiv preprint
arXiv:2309.03409, 2023.
[44] Bowen Zhang and Pengcheng Luo. Or-llm-agent: Au-
tomating modeling and solving of operations research op-
timization problem with reasoning large language model.
arxiv preprint arxiv:2503.10009, 2025.
[45] Xianjie Zhang, Pradeep Varakantham, and Hao Jiang.
Future aware pricing and matching for sustainable on-
demand ride pooling.
In Proceedings of the AAAI
Conference on Artificial Intelligence, volume 37, pages
14628–14636, 2023.
[46] Yansen Zhang, Qingcan Kang, Wing Yin Yu, Hailei
Gong, Xiaojin Fu, Xiongwei Han, Tao Zhong, and Chen
Ma. Decision information meets large language models:
The future of explainable operations research.
arXiv
preprint arXiv:2502.09994, 2025.
[47] Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin,
Yong-Jin Liu, and Gao Huang.
Expel: Llm agents
are experiential learners.
In Proceedings of the AAAI
Conference on Artificial Intelligence, volume 38, pages
19632–19642, 2024.
APPENDIX
A. Objective Function Standard Answer
In this section, we provide the ground-truth Q&A in-
structions adopted in the prompt of RideAgent. Specifically,
we provide accurate Q&A information (human-labeled) in
three specific scenarios: Operational, Customer-Related, and
Regulatory. These scenarios encompass the majority of oper-
ational inquiries proposed by taxi fleet operators. Within each
scenario, there are typically 3 to 8 key QR-objs that are of
utmost relevance to the majority of taxi fleet operators (as
shown in Table VII). For each QR-obj, we provide a ground-
truth “Answers” that is derived from human experience. This
information is supplied in the form of a Gurobi objective code.
B. Objective Function Similarity Index
This section presents the mathematical representation of
the Gurobi code created by RideAgent, which is utilized to
quantify the “Results Similarity” in the relevance test. The
Gurobi code is shown below, which represents the objective
of maximizing the total number of accessible e-bikes and its
related mathematical essence:
• Gurobi
code:
model.setObjective(
gp.quicksum(model.getVarByName(
f"cluster{i}_cluster{j}_{k}") for
i in S for j in D for k in K),
GRB.MAXIMIZE)
• Mathematical essence: max
ˆu0,0 + ˆu0,1 + ˆu0,2 +
· · · · · ·
|
{z
}
ˆuj,k for j in [4,7,12,15,37,38,44] for k in [0,1,2]
+ˆu49,0
+
ˆu49,1 + ˆu49,2
• Gurobi
code:
model.setObjective(
gp.quicksum(model.getVarByName(
f"cluster{i}_cluster{j}_{k}") for i
in S for j in D for k in K if k >0),
GRB.MAXIMIZE)
• Mathematical
essence:
max
ˆu0,1
+
ˆu0,2
+
· · · · · ·
|
{z
}
ˆuj,k for j in [4,7,12,15,37,38,44] for k in [0,1,2]
+ˆu49,1
+
ˆu49,2
C. Prompt
Figure 6 shows the prompts input to the LLMs for two parts
of the agent, Indicator Generator and Problem Tailor. These
prompts contain role definitions, task descriptions, and valid
problem information.


--- Page 14 ---
14
Fig. 6. Brief introduction of prompt


--- Page 15 ---
15
TABLE VII
Ground-truth Objective Functions
Query Relevant Objective Function
Ground-truth Objective Function Code
Proportion of idle taxis
model.setObjective(gp.quicksum(S[i, k] −gp.quicksum(x[i, j, k] for j in D)
for i in S for k in K), GRB.MINIMIZE)
Idle taxis cost
model.setObjective(gp.quicksum((k + 1) ∗(S[i, k] −gp.quicksum(x[i, j, k] for j in D))
for i in S for k in K), GRB.MINIMIZE)
Number of high-powered taxis
in demand areas
model.setObjective(gp.quicksum(x[i, j, 2] for i in S for j in D), GRB.MAXIMIZE)
Future service Level of taxis
model.setObjective(gp.quicksum(k ∗x[i, j, k] for i in S for j in D for k in K), GRB.MAXIMIZE)
Scheduled taxi response time
model.setObjective(gp.quicksum(d[i, j] ∗x[i, j, k] for i in S for j in D for k in K), GRB.MINIMIZE)
Dispatching efficiency of taxis
model.setObjective(gp.quicksum((u[j, k] −w[i, j]) ∗x[i, j, k]
for i in S for j in D for k in K), GRB.MAXIMIZE)
Complaint rate of taxis
model.setObjective(gp.quicksum((k + 1) ∗x[i, j, k] for i in S for j in D for k in K), GRB.MAXIMIZE)
Service Level of taxis
model.setObjective(gp.quicksum((k + 1) ∗x[i, j, k] for i in S for j in D for k in K), GRB.MAXIMIZE)
Average travel price of taxis
model.setObjective(gp.quicksum(u[j, k] for j in D for k in K), GRB.MINIMIZE)
Order completion rate of taxis
model.setObjective(gp.quicksum((k + 1) ∗x[i, j, k] for i in S for j in D for k in K), GRB.MAXIMIZE)
Average waiting time of taxis
model.setObjective(gp.quicksum(d[i, j] ∗x[i, j, k] for i in S for j in D for k in K), GRB.MINIMIZE)
Supply-demand matching degree
of taxis
model.setObjective(gp.quicksum(S[i, k] −gp.quicksum(x[i, j, k] for j in D) for i in S for k in K)
+ gp.quicksum(gp.abs(demand avg[j] −inventory avg −
gp.quicksum(x[i, j, k] for i in S for k in K)) for j in D), GRB.MINIMIZE)
Number of pre-allocated taxis
model.setObjective(gp.quicksum(x[i, j, k] for i in S for j in D for k in K), GRB.MAXIMIZE)
Average passenger capacity
of taxis
model.setObjective(gp.quicksum((k + 1) ∗x[i, j, k] for i in S for j in D for k in K), GRB.MAXIMIZE)
Number of users covered
by taxis
model.setObjective(gp.quicksum((k + 1) ∗x[i, j, k] for i in S for j in D for k in K), GRB.MAXIMIZE)
User satisfaction of taxis
model.setObjective(gp.quicksum((k + 1) ∗x[i, j, k] for i in S for j in D for k in K), GRB.MAXIMIZE)
Demand satisfaction rate
model.setObjective(gp.quicksum((k + 1) ∗x[i, j, k] for i in S for j in D for k in K), GRB.MAXIMIZE)
Market share of taxis
model.setObjective(gp.quicksum(u[j, k] ∗x[i, j, k] for i in S for j in D for k in K), GRB.MAXIMIZE)
