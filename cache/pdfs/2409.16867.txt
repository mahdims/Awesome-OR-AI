--- Page 1 ---
Multi-objective Evolution of Heuristic Using Large Language Model
Shunyu Yao1, * Fei Liu1, * Xi Lin1, Zhichao Lu1, Zhenkun Wang2, â€ , Qingfu Zhang1, â€ 
1Department of Computer Science, City University of Hong Kong, Hong Kong, China
2School of System Design and Intelligent Manufacturing, Southern University of Science and Technology, Shen Zhen, China
{shunyuyao8, fliu36}-c@my.cityu.edu.hk, {xilin4, zhichao.lu}@cityu.edu.hk, wangzhenkun90@gmail.com,
qingfu.zhang@cityu.edu.hk
Abstract
Heuristics are commonly used to tackle various search and
optimization problems. Design heuristics usually require te-
dious manual crafting with domain knowledge. Recent works
have incorporated Large Language Models (LLMs) into au-
tomatic heuristic search, leveraging their powerful language
and coding capacity. However, existing research focuses on
the optimal performance on the target problem as the sole
objective, neglecting other criteria such as efficiency and
scalability, which are vital in practice. To tackle this chal-
lenge, we propose to model the heuristic search as a multi-
objective optimization problem and consider introducing ad-
ditional practical criteria beyond optimal performance. Due
to the complexity of the search space, conventional multi-
objective optimization methods struggle to effectively han-
dle LLM-based multi-objective heuristic search. We propose
the first LLM-based multi-objective heuristic search frame-
work, Multi-objective Evolution of Heuristic (MEoH), which
integrates LLMs in a zero-shot manner to generate a non-
dominated set of heuristics to meet multiple design crite-
ria. We design a new dominance-dissimilarity mechanism for
effective population management and selection, which in-
corporates both code dissimilarity in the search space and
dominance in the objective space. MEoH is demonstrated
in two well-known combinatorial optimization problems: the
online Bin Packing Problem (BPP) and the Traveling Sales-
man Problem (TSP). The results indicate that a variety of elite
heuristics are automatically generated in a single run, offering
more trade-off options than the existing methods. It success-
fully achieves competitive or superior performance while im-
proving efficiency up to 10 times. Moreover, we also observe
that the multi-objective search introduces novel insights into
heuristic design and leads to the discovery of diverse heuris-
tics.
Code â€” https://github.com/Optima-CityU/LLM4AD
1
Introduction
Heuristics are commonly used in solving optimization and
decision-making problems in a variety of fields, including
engineering (Bozorg-Haddad, Solgi, and LoÂ´aiciga 2017),
*Equal contribution.
â€ Corresponding authors.
Copyright Â© 2025, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
industry (Silver 2004), and economics (Vasant 2012). Un-
like exact methods, heuristics offer practical alternatives
for finding sub-optimal solutions within a reasonable time
cost (Pearl 1984) and are particularly adept at handling com-
plex problems with diverse attributes and constraints. How-
ever, developing effective heuristics typically requires ex-
pert knowledge and involves laborious trial-and-error man-
ual crafting, presenting a significant challenge for real-world
applications.
To address this challenge, much effort has been devoted
to automating the design of heuristics (Pillay and Qu 2021).
These efforts can be broadly classified into three categories:
heuristic configuration (Ramos et al. 2005; Visheratin, Mel-
nik, and Nasonov 2016), heuristic selection (Tang et al.
2014; Xu, Hoos, and Leyton-Brown 2010), and heuristic
composition (Burke et al. 2010; Drake et al. 2020; Pillay and
Qu 2018). Despite the successful creation of novel heuris-
tics, the effectiveness of these heuristics still heavily relies
on algorithmic components crafted by human experts (Drake
et al. 2020).
In recent years, Large Language Models (LLMs) have
demonstrated remarkable capabilities in algorithm de-
sign (Liu et al. 2024b). The integration of LLMs with Evo-
lutionary Computation (EC) has enabled the automatic gen-
eration and refinement of heuristics along with their corre-
sponding code implementations (Liu et al. 2024a; Romera-
Paredes et al. 2024; Ye et al. 2024). The designed heuris-
tics achieved competitive performance with minimized hu-
man design and model training. However, all existing LLM-
based evolutionary heuristic search methods focus on a sin-
gle objective regarding the optimized performance of the tar-
get problem (Ma et al. 2023; Nasir et al. 2024; Liu et al.
2024a; Romera-Paredes et al. 2024; Zhang et al. 2024; Yao
et al. 2024; van Stein and BÂ¨ack 2024; Li et al. 2024; Zeng
et al. 2024; Mao et al. 2024; Ma et al. 2024). Other im-
portant heuristic design criteria, such as heuristic complex-
ity (Ausiello et al. 2012) and code readability (Buse and
Weimer 2009), which could be vital in practice, are often ne-
glected. Although some studies have attempted to optimize
multiple objectives by combining them into a single objec-
tive function, resulting in a single heuristic, the conflicting
nature of diverse objectives often makes it challenging to
find a single heuristic that satisfies all simultaneously. The
exploration of effective methods for searching a set of non-
arXiv:2409.16867v2  [cs.AI]  4 Feb 2025


--- Page 2 ---
dominated heuristics in a single run remains unexplored.
In this study, we model the automatic heuristic design as a
multi-objective optimization problem (DrÂ´eo 2009) and pro-
pose the first LLM-based multi-objective heuristic search
framework, termed Multi-objective Evolution of Heuristic
(MEoH), to effectively search for a set of non-dominated
heuristics in a single run. The contributions of this paper are
as follows:
â€¢ We propose an LLM-based automated heuristic design
framework to consider the heuristic design from a multi-
objective optimization perspective.
â€¢ We propose a dominance-dissimilarity mechanism to en-
hance diversity and improve search efficiency by con-
sidering both the dominance relationships in the objec-
tive space and the dissimilarity of heuristics in the search
space.
â€¢ We demonstrate the superiority compared with the coun-
terpart of single-objective LLM-based automated heuris-
tic design on two classical optimization problems: the
Traveling Salesman Problem (TSP) and the online Bin
Packing Problem (BPP).
2
Related Works
2.1
Automated Heuristic Design
Automated heuristic design methods can be broadly clas-
sified into automated heuristic configuration, automated
heuristic selection, and automated heuristic composi-
tion (Pillay and Qu 2021). The first category involves
using optimization methods and machine learning tech-
niques (Ramos et al. 2005; Visheratin, Melnik, and Nasonov
2016) to automatically adjust the parameters within a given
algorithm framework (Agasiev and Karpenko 2017). The
second category focuses on automatically choosing a suit-
able heuristic for each specific instance from a pool of ex-
isting heuristics (Tang et al. 2014; Xu, Hoos, and Leyton-
Brown 2010). The third category combines various algorith-
mic elements to create novel heuristics (Burke et al. 2010;
Drake et al. 2020; Pillay and Qu 2018). While these methods
have shown promise in enhancing the automation of heuris-
tic design and improving performance, they still heavily rely
on human-designed algorithmic components.
2.2
LLM-based Automated Heuristic Design
Large language models have shown remarkable perfor-
mance across a variety of tasks and exhibit promising zero-
shot capabilities in linguistic processing and code genera-
tion. The use of LLMs in automated heuristic design is still
in its early stages (Liu et al. 2024b). For example, Fun-
Search (Romera-Paredes et al. 2024) leverages LLMs to
generate and improve code implementations of heuristics
based on EC frameworks, achieving state-of-the-art results
in mathematical and combinatorial optimization problems.
EoH (Liu et al. 2024a) evolves both idea descriptions and
code implementations of heuristics simultaneously, leading
to competitive performance in a more efficient manner. This
EC+LLM approach has been successfully applied in heuris-
tic and function design across various tasks such as reward
function design (Ma et al. 2023), molecular design (Wang
et al. 2024), network design (Mao et al. 2024), and Bayesian
optimization (Yao et al. 2024). While effective heuristics are
developed, they often focus solely on performance for spe-
cific target instances, overlooking other crucial objectives
like efficiency and complexity.
2.3
Multi-objective Heuristic Design
Heuristic design can be modeled as a multi-objective opti-
mization problem. DrÂ´eo (2009) consider automated heuristic
design as a multi-objective problem to design a set of non-
dominated heuristics to balance optimality and efficiency. S-
Race (Zhang, Georgiopoulos, and Anagnostopoulos 2013)
employs a racing algorithm to automatically choose ma-
chine learning models based on multiple objectives. Further-
more, MO-ParamILS (Blot et al. 2016) extends the single-
objective heuristic configuration framework ParamILS to
handle multiple objectives. Multi-objective genetic pro-
gramming has also been utilized in heuristic search (Schmidt
and Lipson 2009; Vladislavleva, Smits, and Den Hertog
2008; Fan et al. 2024). However, they still demand existing
hand-crafted primitives for defining and generating heuris-
tics.
3
Preliminaries
3.1
Multi-objective Optimization
A Multi-objective Optimization Problem (MOP) can be de-
fined as
min
xâˆˆX f(x) = (f1(x), f2(x), . . . , fM(x)),
(1)
where X represents the search space, x is a decision vector,
and f(x) is an M-objective vector to optimize. A non-trivial
MOP cannot be solved by a single decision vector, and we
have the following definitions for multi-objective optimiza-
tion:
Pareto Dominance: Let xa, xb âˆˆX, xa is said to dom-
inate xb (xa â‰ºxb) if and only if fi(xa) â‰¤fi(xb), âˆ€i âˆˆ
{1, 2, . . . , M} and fj(xa) < fj(xb), âˆƒj âˆˆ{1, 2, . . . , M}.
Pareto Optimality: A decision vector xâˆ—âˆˆX is Pareto-
optimal if there does not exist xâ€² âˆˆX dominates xâˆ—, i.e.,
âˆ„xâ€² âˆˆX such that xâ€² â‰ºxâˆ—.
Pareto Set/Front: The set of all Pareto-optimal decision
vectors is called the Pareto Set (PS), and its mapping in the
objective space is called the Pareto Front (PF).
In this paper, we investigate multi-objective heuristic de-
sign. The decision vector x indicates the heuristic and the
M-objective vector represents different criteria measuring
different aspects of the performance of heuristics (e.g., opti-
mal performance and complexity).
3.2
Multi-objective Evolutionary Algorithms
Multi-objective Evolutionary Algorithms (MOEAs) are
among the most commonly used methods to solve MOPs.
MOEAs work by maintaining a population of N candidate
individuals that evolve iteratively through genetic operators
like crossover and mutation. There are three main paradigms
for MOEAs: the dominance-based approach (Deb et al.


--- Page 3 ---
Optimal Gap
Thought
Code
Objective
Designer
(a) Manual Heuristic Design
Optimal Gap
LLM
Thoughts
â€¦
Codes
â€¦
Objective
(b) Single-objective LLM-based
Heuristic Design 
Optimal Gap
Complexity
LLM
Objectives
Thoughts
â€¦
Codes
â€¦
(c) Multi-objective LLM-based 
Heuristic Design, MEoH (Ours)
Figure 1: Comparison to human design and existing LLM-based heuristic design (a) manual heuristic design by human experts,
(b) single-objective LLM-based heuristic design (e.g., FunSearch and EoH), and (c) our proposed multi-objective heuristic
design (MEoH).
2002), the decomposition-based approach (Zhang and Li
2007), and the indicator-based approach (Zitzler and KÂ¨unzli
2004).
4
Methodology
4.1
Framework
Multi-objective Evolution of Heuristic (MEoH) is a fusion
of LLMs and multi-objective evolutionary optimization for
effective multi-objective heuristic design. As illustrated in
Algorithm 1, MEoH begins with population initialization,
where the population comprises heuristics, and progres-
sively improves the population using MOEA until the termi-
nation condition is satisfied, to obtain a set of non-dominated
heuristics that represent trade-offs among multiple objec-
tives. Throughout each iteration, MEoH generates offspring
using search operators. These operators are implemented
through LLMs and predefined prompts to create offspring
based on the selected parents from the population. New off-
spring are added to the population and population manage-
ment is utilized to update the population to keep its size,
with a focus on maintaining diversity and convergence. The
dominance-dissimilarity mechanism is utilized in both par-
ent selection and population management. Detailed expla-
nations of each of these components will be provided in the
subsequent sections.
MEoH advances existing LLM-based heuristic design by
extending the single-objective approach (Romera-Paredes
et al. 2024; Liu et al. 2024a) to the multi-objective sce-
narios and designing a set of non-dominated heuristics in
a single run. Moreover, unlike directly combining MOEA
and LLM-based heuristic search, MEoH introduces a unique
dominance-dissimilarity measure to navigate the complex
and discrete heuristic search space, overcoming challenges
faced by conventional MOEAs like NSGA-II (Deb et al.
2002) and MOEA/D (Zhang and Li 2007).
4.2
Dominance-dissimilarity Mechanism
Traditional MOEAs (Deb et al. 2002; Zhang and Li 2007)
and single-objective LLM-based heuristic design meth-
Algorithm 1: MEoH
1: Input: Population size N; Maximum number of itera-
tions T, Parent selection size d; Initial population P 0;
Pre-trained LLM L.
2: Output: Approximate Pareto-set P âˆ—.
3: if P 0 = âˆ…then
4:
for i = 1, . . . , N do
5:
o â†Generation(L);
6:
P 0 â†P 0 âˆªo
7:
end for
8: end if
9: for t = 1, . . . , T do
10:
for i = 1, . . . , N do
11:
P parent â†ParentSelection(P tâˆ’1, d);
12:
o â†Search(L, P parent);
13:
P tâˆ’1 â†P tâˆ’1 âˆªo
14:
end for
15:
P t â†PopulationManagement(P tâˆ’1, N)
16: end for
17: P âˆ—â†P T
ods (Romera-Paredes et al. 2024; Liu et al. 2024a) lack ef-
fective diversity maintenance strategies for multi-objective
automated heuristic design. To address this, we propose
a novel dominance-dissimilarity mechanism that considers
both objective space dominance and heuristic search space
dissimilarity.
Dominance Measure in Objective Space:
In the objec-
tive space, the Pareto dominance relationship between each
pair of heuristics is evaluated, which is widely used in
MOEAs (Zitzler and Thiele 1998; Deb et al. 2002).
Dissimilarity Measure in Search Space:
In the search
space, the heuristics are represented through natural lan-
guage descriptions and implemented in Python code. We
evaluate the dissimilarity between code segments. Notably,
there are various techniques available for this purpose, and
we choose to utilize the widely adopted Abstract Syntax
Tree (AST) (Neamtiu, Foster, and Hicks 2005). The AST


--- Page 4 ---
converts the code segment to an abstract syntactic struc-
ture (Baxter et al. 1998). And the similarity of code a and
code b can be calculated based on the tree structures follow-
ing Ren et al. (2020):
SimAST(a, b) = Countclip(Treea)/Count(Treeb),
(2)
where Count(Treeb) is the number of subtrees of Treeb, and
Countclip(Treea) is the number of subtrees of Treea that are
matched the Treeb. The AST similarity value ranges from
0 to 1, with 0 indicating complete dissimilarity between the
two code segments and 1 signifying identical code segments.
This quantitative approach enables the assessment of struc-
tural similarity between code segments, facilitating the com-
parison and evaluation of heuristics based on their code im-
plementations.
Dominance-dissimilarity Score:
As illustrated in Fig-
ure 2, to determine the dominance-dissimilarity of each
heuristic in the population, the dissimilarity, i.e., the nega-
tive AST similarity, between each pair of heuristics is cal-
culated and stored in a matrix. Concurrently, in the objec-
tive space, the dominance relationship between each pair
of heuristics is captured and represented as a mask with
the same size as the dissimilarity matrix. Specifically, only
the dominance relationship is considered, while all other
relationships are masked. Subsequently, the masked dis-
similarity matrix is aggregated column-wise. The result-
ing dominance-dissimilarity score vector encapsulates both
dominance and diversity aspects to guide parent selection
and population management in the subsequent steps. The de-
tails can be found in Appendix A.
4.3
Heuristic Representation
Similar to Liu et al. (2024a), each heuristic in MEoH is com-
posed of three elements: a description in plain language, a
code snippet in a specific format, and a fitness score.
The description is a brief linguistic explanation generated
by LLMs that conveys the main idea. The code snippet is the
actual implementation of the heuristic. In the experiments,
we opted to use Python functions for implementation. The
code snippet must include the 1) function name, 2) input
variables, and 3) output variables for clarity. The fitness is
evaluated on a set of instances for the specific target prob-
lem. Example heuristics can be found in Appendix H.
4.4
Heuristic Generation
Initial Heuristic Generation
The initial population of
MEoH is comprised of heuristics. These heuristics can be
generated by leveraging a LLM with a predefined genera-
tion prompt or by using human-designed existing heuristics.
In order to fully demonstrate the capability of MEoH in de-
signing competitive heuristics, we let LLM generate all the
heuristics in both the initiation and evolution processes.
Offspring Heuristic Generation
The parent selection is
the first step of generating offspring, in which a set of parent
heuristics P parent are selected from the current population.
To consider both convergence and diversity in the heuris-
tic search process, the dominance-dissimilarity score is uti-
lized to guide the probability of parent selection. A higher
dominance-dissimilarity score indicates a lower likelihood
of being dominated or a more diverse code segment, making
it preferable. The parents are selected with probability pro-
portional to their dominance-dissimilarity scores. The de-
tails can be found in Appendix A.
The selected parent heuristics serve as samples in the
prompt to instruct LLM in generating offspring heuris-
tics. We employ five different search operators with diverse
prompt strategies adapted from EoH (Liu et al. 2024a) to
produce offspring heuristics. The details of these prompts
can be found in Appendix G.
4.5
Population Management
As the offspring generated through search operations are in-
corporated into the population, the size of the population
gradually increases. In order to ensure a consistent popu-
lation size and update the population effectively, a popu-
lation management strategy is proposed. The dominance-
dissimilarity score is utilized for this purpose. Specifically,
the heuristics in the population are sorted based on their
dominance-dissimilarity score and the worst heuristics are
removed to ensure that only the most promising individu-
als are retained within the population, as detailed in Ap-
pendix A. By employing this strategy, the population is con-
tinually refined to maintain a high-quality and diverse set of
individuals, enhancing the overall efficiency and effective-
ness of the evolutionary process.
5
Experiments
5.1
Experimental Settings
Problems & Implementation Details
We demonstrate
MEoH on two representative combinatorial optimization
problems:
1) Online Bin Packing Problem: In online Bin Packing
Problem (BPP) (Seiden 2002), a set of items, each with its
own weight, needs to be packed into bins with a predeter-
mined capacity. The objective of the BPP is to minimize the
total number of bins required to accommodate all the items.
In an online scenario, items are packed as they are received
without prior knowledge. The generated heuristics are eval-
uated on 5 Weibull instances with 5, 000 items (referred to
as 5k), and the capacity of bins is 100.
We inherit the settings from Romera-Paredes et al. (2024)
to design constructive heuristics for aligning the arriving
items to the appropriate bins. The designed heuristics in-
volve a function scoring the bins, where the input includes
the arriving item size and the remaining capacities of the
bins. The item will be assigned to the bin with the highest
score.
2) Travelling Salesman Problem: In Traveling Salesman
Problem (TSP) (Reinelt 2003), the objective is to find the
shortest route that visits all given nodes exactly once and
returns to the starting node. In this work, we evaluate the fit-
ness of designed heuristics during evolution on 64 instances
with 100 nodes. The coordinate of each node is randomly
sampled from [0, 1] (Kool, van Hoof, and Welling 2018).
The Guided Local Search (GLS) framework is em-
ployed (Voudouris, Tsang, and Alsheddy 2010) to iteratively


--- Page 5 ---
Code1
Code4
Code5
Code3
Code2
Search Space
ð‘“ð‘“1
ð‘“ð‘“2
Objective Space
â‰º
1
2
3
4
5
1
0
-0.5
-0.4
-0.9
-0.2
2
-0.4
0
-0.3
-0.6
-0.6
3
-0.5
-0.2
0
-0.7
-0.1
4
-0.7
-0.7
-0.6
0
-0.4
5
-0.3
-0.5
-0.2
-0.5
0
Dissimilarity
Dominance
à·
0
0
-0.3
0
-0.8
Parent Selection
Population Management
0
0.05
0.1
0.15
0.2
0.25
0.3
Probability
Code1
Code2
Code4
New Population
1
2
4
3
5
0
0
0
-0.3
-0.8
Figure 2: An illustration of parent selection and population management with dominance-dissimilarity mechanism. By incor-
porating code dissimilarity in the search space and dominance relationships in the objective space, the parent selection and
population management are enhanced to promote diversity and improve search efficiency.
improve the solution quality following (Liu et al. 2024a).
GLS iteratively performs two steps: 1) local search and 2)
perturbation. Until the stop criterion is satisfied, the best so-
lution obtained throughout the iterations is considered the
final solution. We aim to design a heuristic to update the dis-
tance matrix in the perturbation step.
The experimental parameter settings are as follows: the
number of generations is 20, and the population size is 20
and 10 for online BPP and TSP, respectively. Each crossover
operator selects 5 parent heuristics to reproduce the off-
spring heuristics. The number of iterations and running time
in the GLS for TSP is limited to 1, 000 and 60 seconds, re-
spectively.
Environments
To ensure fairness and consistency, all ex-
periments in this study were conducted on a computer
equipped with an Intel Core i7-11700 processor and 32GB
of memory. GPT3.5-turbo is employed as the per-trained
LLM, with each experiment repeated three times to ensure
the robustness and reliability of the results.
Performance Metric
Objectives
1) Optimal Gap: We use the optimal gap to
baseline as the first objective (e.g., the gap between the num-
ber of bins used in designed heuristics to the lower bound of
bin number). 2) Efficiency: The running time of heuristics
is used as the second objective to reflect the efficiency of
heuristics.
Metric
1) Hypervolume:
The Hypervolume(HV) is a
commonly used metric in multi-objective optimization. It
provides a comprehensive assessment of convergence and
diversity of the approximate Pareto front without the ground
truth Pareto front (Audet et al. 2021). A larger HV value
indicates a better performance. 2) IGD: The Inverted Gen-
erational Distance(IGD) measures the quality of the gener-
ated approximate Pareto front in relation to the reference set.
Here the reference set is the nondominated set derived from
the union of all generated heuristics. A lower IGD value is
preferred, which indicates better convergence and diversity,
implying that the generated population is closer to the refer-
ence set. The detailed formulation of the two metrics can be
found in Appendix D.
Baseline Methods
In this study, our primary focus lies
in exploring LLM-based automated heuristic design ap-
proaches. Consequently, we compare the two closest related
works, namely FunSearch (Romera-Paredes et al. 2024) and
EoH (Liu et al. 2024a). The details can be found in Ap-
pendix C.
5.2
Experimental Results
Convergence Analysis
The curve of HV and IGD for the
heuristic populations generated in each iteration on BPP are
displayed in Figure 3(b) and (c), respectively. As EoH only
pursues optimal gaps without considering diversity, the HV
and IGD become worse as the evolution progresses. In con-
trast, MEoH systematically takes into account both the op-
timal gap and running time. As a result, MEoH achieves
notably higher HV and lower IGD, indicating significantly
better multi-objective trade-off results. Figure 4(b) and (c)
provide more evidence on TSP. MEoH converges faster and
clearly outperforms EoH in terms of HV and IGD. Addi-
tionally, the average dominance-dissimilarity score is shown
in Figure 3 (d) and Figure 4 (d). Results demonstrate the
superiority of MEoH and the efficiency of our dominance-
dissimilarity mechanism in maintaining population diver-
sity. The details can be found in Appendix F.
Pareto Fronts
Figure 3(a) and Figure 4(a) compare the
non-dominated heuristics of the final population obtained by
MEoH and EoH. Results show that 1) MEoH generates a di-
verse set of heuristics with different trade-offs over the two
objectives. In contrast, EoH only finds similar heuristics that
cover a much smaller region in the objective space. 2) The
heuristics obtained from MEoH can significantly reduce the
running time (up to 10 times) when achieving a similar op-
timal gap.
Performance Measurement
1) BPP:
To comprehen-
sively evaluate the performance of our MEoH in more gen-


--- Page 6 ---
2
4
Gap
0.5
1.0
1.5
Running Time/s
Pareto Front
MEoH
EoH
(a) Pareto Front
5
10
15
20
Iterations
0.0
0.5
1.0
HV
MEoH
EoH
(b) HV
5
10
15
20
Iterations
0.2
0.4
0.6
0.8
IGD
MEoH
EoH
(c) IGD
5
10
15
Iterations
75
50
25
0
Dominance-dissimilarity
MEoH
EoH
(d) Score
Figure 3: Comparations of EoH and MEoH on BPP5k.
7.8
7.9
8.0
Gap
0
10
20
Running Time/s
Pareto Front
MEoH
EoH
(a) Pareto Front
5
10
15
20
Iterations
0.0
0.5
1.0
HV
MEoH
EoH
(b) HV
5
10
15
20
Iterations
0.0
2.5
5.0
7.5
IGD
MEoH
EoH
(c) IGD
5
10
15
Iterations
60
40
20
0
Dominance-dissimilarity
MEoH
EoH
(d) Score
Figure 4: Comparations of EoH and MEoH on TSP100.
eral cases, we test FunSearch, EoH, and MEoH on various
problem instances with different sizes and capacities. The
problem sizes in our test include 5k, 10k, and 100k, and
the capacities of the bins are set at 100 and 500. Each test
set consists of five instances sampled from Weibull distribu-
tion (Romera-Paredes et al. 2024). The average gap with ref-
erence to the relaxation lower bound lb and the running time
are shown in Table 1. For the in-distribution instances, i.e.,
the bin capacity is 100, all of these three frameworks exhibit
promising performance in terms of the optimal gap, and the
running time of MEoH heuristics are significantly less than
the counterparts of FunSearch and EoH, especially in large-
size instances, i.e., BPP100k. MEoH heuristics achieve com-
petitive performance compared to EoH but do so in signifi-
cantly less running time (up to 10 times faster). In contrast,
for out-distribution instances, i.e., the bin capacity is 500, the
performance of FunSearch heuristics drastically deteriorates
in terms of the optimal gap. On the other hand, both EoH and
MEoH heuristics exhibit promising performances in such
scenarios. Notably, MEoH demonstrates a balanced trade-
off between the optimal gap and running time, showcasing
its effectiveness in handling out-distribution instances effi-
ciently.
2) TSP: We evaluate these three methods on randomly
generated TSP instances comprising 100, 500, and 1, 000
nodes and a variety of TSP instances with up to 1, 002 nodes
from TSPLIB (Reinelt 1991). Table 2 and Table 3 display
the gap compared to the best-known solution (for the ran-
domly generated instances, the best-known solutions are ob-
tained using the Concorde solver (Applegate et al. 2006))
Weibull
FunSearch
EoH
MEoH
Gap
Time/s
Gap
Time/s
Gap
Time/s
5k C100
0.802%
0.728
0.753%
1.362
1.387%
0.191
10k C100
2.595%
2.128
0.537%
5.128
0.651%
0.650
100k C100
3.319%
195.734
0.391%
502.938
0.080%
59.078
Avg.
2.239%
66.197
0.560%
169.809
0.706%
19.973
5k C500
29.494%
0.750
0.100%
1.672
0.351%
0.100
10k C500
47.734%
2.459
0.125%
6.337
0.473%
0.306
100k C500
53.640%
259.094
0.099%
646.828
0.410%
22.078
Avg.
43.623%
87.434
0.108%
218.279
0.411%
7.495
Table 1: Results of in- and out-of-distribution BPP.
and the corresponding running times. As shown in Table 2,
FunSearch and MEoH (Best) heuristics exhibit promising
performance on TSP100 and TSP500 instances. In general,
MEoH provides a set of heuristics that enable trade-offs be-
tween optimality and efficiency. As shown in Table 3, for
smaller instances (up to 200 nodes), the MEoH heuristics
demonstrate superior performance in terms of both the opti-
mal gap and running time. For larger instances (201 to 1, 002
nodes), MEoH still outperforms in running time, although
slightly lagging behind EoH in terms of the optimal gap.
The details can be found in Appendix E.
5.3
Comparison to Conventional MOEAs
In this section, we evaluate the impact of our proposed
dominance-dissimilarity mechanism on the optimization
process and compare to two representative MOEAs: NSGA-
II (Deb et al. 2002) and MOEA/D (Zhang and Li 2007).


--- Page 7 ---
TSP100
TSP500
TSP1000
Gap
Time/s
Gap
Time/s
Gap
Time/s
FunSearch
0.100%
1.452
1.525%
27.598
2.344%
161.124
EoH
0.113%
22.434
1.750%
43.541
2.524%
262.603
MEoH(Best)
0.109%
1.373
1.733%
30.945
4.208%
26.844
MEoH(Fast)
3.690%
0.175
4.402%
3.306
4.536%
21.900
Table 2: Results of in- and out-of-distribution randomly gen-
erated TSP.
TSPLIB
FunSearch
EoH
MEoH
Gap
Time/s
Gap
Time/s
Gap
Time/s
Avg. (0-200)
0.050%
3.418
0.093%
25.917
0.018%
2.354
Avg. (201-1002)
1.535%
419.613
1.376%
1515.992
1.50%
355.754
Table 3: Results of small and large TSPLIB instances.
TSPLIB
BPP C100
Gap
Time/s
Gap
Time/s
FunSearch
0.050%
3.418
2.239%
66.197
EoH
0.093%
25.917
0.560%
169.809
MEoH (Best)
0.018%
2.354
0.706%
19.973
MEoH (Fast)
3.563%
0.138
4.326%
6.533
Table 4: Two top heuristics designed by MEoH.
5
10
15
20
Iterations
0.0
0.2
0.4
0.6
HV
MOEA/D
NSGA-II
MEoH
(a) HV
5
10
15
20
Iterations
0
1
2
3
IGD
MOEA/D
NSGA-II
MEoH
(b) IGD
Figure 5: Comparison to conventional MOEAs on BPP.
5
10
15
20
Iterations
0.2
0.4
0.6
0.8
HV
MOEA/D
NSGA-II
MEoH
(a) HV
5
10
15
20
Iterations
0.0
0.2
0.4
IGD
MOEA/D
NSGA-II
MEoH
(b) IGD
Figure 6: Comparison to conventional MOEAs on TSP.
Figure 5 and Figure 6 depict the results on BPP and
TSP, respectively. MEoH can obtain the best HV and IGD.
Our findings highlight the effectiveness of our dominance-
dissimilarity mechanism, which integrates considerations
from both the search and objective spaces, in improving the
optimization process.
7.8
7.9
8.0
Gap
0
20
40
Running Time/s
100
500
1000
1500
2000
Pareto Front
MEoH
EoH *
Figure 7: Comparations of the non-dominated heuristics
generated by MEoH and the any-time performance of the
best heuristic generated by EoH (termed as EoHâˆ—) on TSP.
5.4
Comparison to Any-time Performance
The performance of a single heuristic at any given time can
provide a set of heuristics that offer different trade-offs be-
tween optimal gap and running time. For instance, reducing
the number of iterations in GLS from 1, 000 to 100 results in
a decrease in running time but a deterioration in the optimal
gap. By comparing the heuristics generated by MEoH to the
best heuristic produced by EoH, we can further illustrate the
benefits of multi-objective heuristic design. We evaluate the
performance of the best EoH heuristic with varying numbers
of iterations. Figure 7 demonstrates that the heuristics gener-
ated by MEoH outperform those of EoH. Even the best EoH
heuristic with 100 iterations falls short in terms of running
time and optimal gap compared to all MEoH heuristics. Ad-
ditionally, while the best EoH heuristic with 2, 000 iterations
can achieve competitive optimality, it lags behind in running
time by approximately 20 times.
6
Conclusion, Limitation, and Future Work
Conclusion
This paper develops a novel framework,
termed MEoH, for LLM-based multi-objective automatic
heuristic design. We propose a dominance-dissimilarity
mechanism for effective search in the discrete and com-
plex heuristic space. We demonstrate MEoH on two widely-
studied combinatorial optimization problems to optimize
both heuristicsâ€™ optimal gap and running time. Results show
that MEoH significantly outperforms existing LLM-based
heuristic design methods including FunSearch and EoH in
producing trade-off heuristics over multiple objectives. The
efficiency can be increased dramatically up to 10 times with
a close optimal gap. Moreover, additional ablation studies
and visualization of the evolution process validate the su-
periority of MEoH over conventional MOEAs and the ef-
fectiveness of the proposed dominance-dissimilarity mecha-
nism in multi-objective automatic heuristic design.
Limitation and Future Work
Although we have demon-
strated the effectiveness of MEoH primarily on two objec-
tives, and three objectives in Appendix I, we aim to investi-
gate the performance of MEoH on many-objective cases and
a broader range of heuristic design tasks.


--- Page 8 ---
Acknowledgments
This work was supported by the Research Grants Council
of the Hong Kong Special Administrative Region, China
(GRF Project No. CityU 11215622), the National Natu-
ral Science Foundation of China (Grant No. 62106096 and
Grant No. 62476118), the Natural Science Foundation of
Guangdong Province (Grant No. 2024A1515011759), the
National Natural Science Foundation of Shenzhen (Grant
No. JCYJ20220530113013031).
References
Agasiev, T.; and Karpenko, A. 2017. The program system
for automated parameter tuning of optimization algorithms.
Procedia Computer Science, 103: 347â€“354.
Applegate, D.; Bixby, R.; Chvatal, V.; and Cook, W. 2006.
Concorde TSP solver.
Audet, C.; Bigeon, J.; Cartier, D.; Le Digabel, S.; and Sa-
lomon, L. 2021. Performance indicators in multiobjective
optimization.
European journal of operational research,
292(2): 397â€“422.
Ausiello, G.; Crescenzi, P.; Gambosi, G.; Kann, V.;
Marchetti-Spaccamela, A.; and Protasi, M. 2012. Complex-
ity and approximation: Combinatorial optimization prob-
lems and their approximability properties. Springer Science
& Business Media.
Baxter, I. D.; Yahin, A.; Moura, L.; Santâ€™Anna, M.; and Bier,
L. 1998. Clone detection using abstract syntax trees. In
Proceedings. International Conference on Software Mainte-
nance (Cat. No. 98CB36272), 368â€“377. IEEE.
Blot, A.; Hoos, H. H.; Jourdan, L.; Kessaci-Marmion, M.-Â´E.;
and Trautmann, H. 2016. MO-ParamILS: A multi-objective
automatic algorithm configuration framework.
In Learn-
ing and Intelligent Optimization: 10th International Confer-
ence, LION 10, Ischia, Italy, May 29â€“June 1, 2016, Revised
Selected Papers 10, 32â€“47. Springer.
Bozorg-Haddad, O.; Solgi, M.; and LoÂ´aiciga, H. A. 2017.
Meta-heuristic and evolutionary algorithms for engineering
optimization. John Wiley & Sons.
Burke, E. K.; Hyde, M.; Kendall, G.; Ochoa, G.; Â¨Ozcan,
E.; and Woodward, J. R. 2010. A classification of hyper-
heuristic approaches.
Handbook of metaheuristics, 449â€“
468.
Buse, R. P.; and Weimer, W. R. 2009. Learning a metric for
code readability. IEEE Transactions on software engineer-
ing, 36(4): 546â€“558.
Deb, K.; Pratap, A.; Agarwal, S.; and Meyarivan, T. 2002.
A fast and elitist multiobjective genetic algorithm: NSGA-
II. IEEE transactions on evolutionary computation, 6(2):
182â€“197.
Drake, J. H.; Kheiri, A.; Â¨Ozcan, E.; and Burke, E. K. 2020.
Recent advances in selection hyper-heuristics.
European
Journal of Operational Research, 285(2): 405â€“428.
DrÂ´eo, J. 2009. Using performance fronts for parameter set-
ting of stochastic metaheuristics. In Proceedings of the 11th
Annual Conference Companion on Genetic and Evolution-
ary Computation Conference: Late Breaking Papers, 2197â€“
2200.
Fan, L.; Su, Z.; Liu, X.; and Wang, Y. 2024. Decomposition
based cross-parallel multiobjective genetic programming for
symbolic regression. Applied Soft Computing, 112239.
Kool, W.; van Hoof, H.; and Welling, M. 2018. Attention,
Learn to Solve Routing Problems! In International Confer-
ence on Learning Representations.
Li, H.; Yang, X.; Wang, Z.; Zhu, X.; Zhou, J.; Qiao, Y.;
Wang, X.; Li, H.; Lu, L.; and Dai, J. 2024. Auto mc-reward:
Automated dense reward design with large language models
for minecraft. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, 16426â€“16435.
Liu, F.; Xialiang, T.; Yuan, M.; Lin, X.; Luo, F.; Wang, Z.;
Lu, Z.; and Zhang, Q. 2024a. Evolution of Heuristics: To-
wards Efficient Automatic Algorithm Design Using Large
Language Model. In Forty-first International Conference on
Machine Learning.
Liu, F.; Yao, Y.; Guo, P.; Yang, Z.; Lin, X.; Tong, X.; Yuan,
M.; Lu, Z.; Wang, Z.; and Zhang, Q. 2024b. A Systematic
Survey on Large Language Models for Algorithm Design.
arXiv preprint arXiv:2410.14716.
Ma, P.; Wang, T.-H.; Guo, M.; Sun, Z.; Tenenbaum, J. B.;
Rus, D.; Gan, C.; and Matusik, W. 2024.
LLM and
Simulation as Bilevel Optimizers: A New Paradigm to
Advance Physical Scientific Discovery.
arXiv preprint
arXiv:2405.09783.
Ma, Y. J.; Liang, W.; Wang, G.; Huang, D.-A.; Bastani, O.;
Jayaraman, D.; Zhu, Y.; Fan, L.; and Anandkumar, A. 2023.
Eureka: Human-level reward design via coding large lan-
guage models. arXiv preprint arXiv:2310.12931.
Mao, J.; Zou, D.; Sheng, L.; Liu, S.; Gao, C.; Wang, Y.;
and Li, Y. 2024.
Identify Critical Nodes in Complex
Network with Large Language Models.
arXiv preprint
arXiv:2403.03962.
Nasir, M. U.; Earle, S.; Togelius, J.; James, S.; and Cleghorn,
C. 2024. LLMatic: neural architecture search via large lan-
guage models and quality diversity optimization. In Pro-
ceedings of the Genetic and Evolutionary Computation Con-
ference, 1110â€“1118.
Neamtiu, I.; Foster, J. S.; and Hicks, M. 2005. Understand-
ing source code evolution using abstract syntax tree match-
ing. In Proceedings of the 2005 international workshop on
Mining software repositories, 1â€“5.
Pearl, J. 1984. Heuristics: intelligent search strategies for
computer problem solving. Addison-Wesley Longman Pub-
lishing Co., Inc.
Pillay, N.; and Qu, R. 2018. Hyper-heuristics: theory and
applications. Springer.
Pillay, N.; and Qu, R. 2021. Automated Design of Machine
Learning and Search Algorithms. Springer.
Ramos, I. C.; Goldbarg, M. C.; Goldbarg, E. G.; and Neto,
A. D. D. 2005. Logistic regression for parameter tuning on
an evolutionary algorithm. In 2005 IEEE congress on evo-
lutionary computation, volume 2, 1061â€“1068. IEEE.
Reinelt, G. 1991. TSPLIBâ€“A Traveling Salesman Problem
Library. ORSA Journal on Computing, 3(4): 376â€“384.


--- Page 9 ---
Reinelt, G. 2003. The traveling salesman: computational
solutions for TSP applications, volume 840. Springer.
Ren, S.; Guo, D.; Lu, S.; Zhou, L.; Liu, S.; Tang, D.; Sun-
daresan, N.; Zhou, M.; Blanco, A.; and Ma, S. 2020. Code-
bleu: a method for automatic evaluation of code synthesis.
arXiv preprint arXiv:2009.10297.
Romera-Paredes, B.; Barekatain, M.; Novikov, A.; Balog,
M.; Kumar, M. P.; Dupont, E.; Ruiz, F. J.; Ellenberg, J. S.;
Wang, P.; Fawzi, O.; et al. 2024. Mathematical discoveries
from program search with large language models. Nature,
625(7995): 468â€“475.
Schmidt, M.; and Lipson, H. 2009. Distilling free-form natu-
ral laws from experimental data. science, 324(5923): 81â€“85.
Seiden, S. S. 2002. On the online bin packing problem. Jour-
nal of the ACM (JACM), 49(5): 640â€“671.
Silver, E. A. 2004. An overview of heuristic solution meth-
ods. Journal of the operational research society, 55: 936â€“
956.
Tang, K.; Peng, F.; Chen, G.; and Yao, X. 2014. Population-
based algorithm portfolios with automated constituent algo-
rithms selection. Information Sciences, 279: 94â€“104.
van Stein, N.; and BÂ¨ack, T. 2024.
LLaMEA: A
Large Language Model Evolutionary Algorithm for Au-
tomatically Generating Metaheuristics.
arXiv preprint
arXiv:2405.20132.
Vasant, P. M. 2012.
Meta-heuristics optimization algo-
rithms in engineering, business, economics, and finance. IGI
Global.
Visheratin, A. A.; Melnik, M.; and Nasonov, D. 2016. Auto-
matic workflow scheduling tuning for distributed processing
systems. Procedia Computer Science, 101: 388â€“397.
Vladislavleva, E. J.; Smits, G. F.; and Den Hertog, D. 2008.
Order of nonlinearity as a complexity measure for models
generated by symbolic regression via pareto genetic pro-
gramming. IEEE Transactions on Evolutionary Computa-
tion, 13(2): 333â€“349.
Voudouris, C.; Tsang, E. P.; and Alsheddy, A. 2010. Guided
local search.
In Handbook of metaheuristics, 321â€“361.
Springer.
Wang, H.; Skreta, M.; Ser, C.-T.; Gao, W.; Kong, L.;
Streith-Kalthoff, F.; Duan, C.; Zhuang, Y.; Yu, Y.; Zhu, Y.;
et al. 2024.
Efficient Evolutionary Search over Chemi-
cal Space with Large Language Models.
arXiv preprint
arXiv:2406.16976.
Xu, L.; Hoos, H.; and Leyton-Brown, K. 2010. Hydra: Auto-
matically configuring algorithms for portfolio-based selec-
tion. In Proceedings of the AAAI Conference on Artificial
Intelligence, volume 24, 210â€“216.
Yao, Y.; Liu, F.; Cheng, J.; and Zhang, Q. 2024.
Evolve
Cost-aware Acquisition Functions Using Large Language
Models. In International Conference on Parallel Problem
Solving from Nature, 374â€“390. Springer.
Ye, H.; Wang, J.; Cao, Z.; and Song, G. 2024. ReEvo: Large
Language Models as Hyper-Heuristics with Reflective Evo-
lution. arXiv preprint arXiv:2402.01145.
Zeng, J.; Li, C.; Sun, Z.; Zhao, Q.; and Zhou, G. 2024.
tnGPS: Discovering Unknown Tensor Network Structure
Search Algorithms via Large Language Models (LLMs). In
Forty-first International Conference on Machine Learning.
Zhang, Q.; and Li, H. 2007.
MOEA/D: A multiobjec-
tive evolutionary algorithm based on decomposition. IEEE
Transactions on evolutionary computation, 11(6): 712â€“731.
Zhang, R.; Liu, F.; Lin, X.; Wang, Z.; Lu, Z.; and Zhang, Q.
2024. Understanding the Importance of Evolutionary Search
in Automated Heuristic Design with Large Language Mod-
els. In International Conference on Parallel Problem Solv-
ing from Nature, 185â€“202. Springer.
Zhang, T.; Georgiopoulos, M.; and Anagnostopoulos, G. C.
2013. S-Race: A multi-objective racing algorithm. In Pro-
ceedings of the 15th annual conference on Genetic and evo-
lutionary computation, 1565â€“1572.
Zitzler, E.; and KÂ¨unzli, S. 2004. Indicator-based selection in
multiobjective search. In International conference on paral-
lel problem solving from nature, 832â€“842. Springer.
Zitzler, E.; and Thiele, L. 1998.
An evolutionary algo-
rithm for multiobjective optimization: The strength pareto
approach. TIK report, 43.


--- Page 10 ---
A
Algorithm Details
In this part, we elaborate on the details of parent selection and population management used in our proposed MEoH, as
shown in Algorithm 1 and Algorithm 2, respectively.
Calculation of Dominance-dissimilarity Score
The lines 3-16 in Algorithm 1 and the lines 4-17 in Algorithm 2 are almost
identical, illustrating the computation of the dominance-dissimilarity score. Specifically, two square matrices, namely the dis-
similarity score matrix S and the dominance mask matrix D, are initialized to be zeros. Each heuristic within the population is
compared in pairs, with their dissimilarity (negative AST similarity) and dominance relationships recorded in the corresponding
matrices. Subsequently, these matrices are element-wise multiplied to yield the dominance-dissimilarity score matrix Sâ€². The
dominance-dissimilarity vector v is then derived by summing the columns of Sâ€². This vector encapsulates a blend of dominance
and dissimilarity considerations, guiding the following parent selection and population management.
Parent Selection
For parent selection, as delineated in Algorithm 1, the dominance-dissimilarity vector v is leveraged to con-
struct a probability distribution Ï€ using the softmax function. The parents are subsequently sampled based on this distribution
to strike a balance between exploration and exploitation.
Population Management
For population management, as shown in Algorithm 2, the dominance-dissimilarity vector v is
descending sorted, and the resulting indices k are utilized to truncate the population, and the first N individuals consists the
new population P â€².
Algorithm 1: ParentSelection
1: Input: Population P ; Population size N; Parent selection size d.
2: Output: Selected parents P parent.
3: Initialize the dissimilarity score matrix S as an N Ã— N matrix filled with zeros;
4: Initialize the dominance mask matrix D as an N Ã— N matrix filled with zeros;
5: for i = 1, . . . , N do
6:
for j = 1, . . . , N do
7:
if i Ì¸= j then
8:
S[i, j] â†âˆ’AST(P [i], P [j]);
9:
if P [i] â‰ºP [j] then
10:
D[i, j] â†1;
11:
end if
12:
end if
13:
end for
14: end for
15: Sâ€² â†S âŠ™D
16: v â†ColumnwiseSum(Sâ€²)
17: Ï€ â†Softmax(v)
18: P parent â†Sample(P , Ï€, d)


--- Page 11 ---
Algorithm 2: PopulationManagement
1: Input: Population P ; Population size N.
2: Output: New population P â€².
3: Current population size N â€² â†size(P )
4: Initialize the dissimilarity score matrix S as an N â€² Ã— N â€² matrix filled with zeros;
5: Initialize the dominance mask matrix D as an N â€² Ã— N â€² matrix filled with zeros;
6: for i = 1, . . . , N do
7:
for j = 1, . . . , N do
8:
if i Ì¸= j then
9:
S[i, j] â†âˆ’AST(P [i], P [j]);
10:
if P [i] â‰ºP [j] then
11:
D[i, j] â†1;
12:
end if
13:
end if
14:
end for
15: end for
16: Sâ€² â†S âŠ™D
17: v â†ColumnwiseSum(Sâ€²)
18: k â†DescendingSortedIndexes(v)
19: Initialize a new population P â€² â†âˆ…
20: for i = 1, . . . , N do
21:
P â€² â†P â€² âˆªP [k[i]]
22: end for


--- Page 12 ---
B
Heuristic Design Task Details
We demonstrate the proposed method on two heuristic design tasks: 1) heuristics design for online Bin Packing Problem
(BPP) and 2) heuristic design for guided local search for Traveling Salesman Problem (TSP). We introduce the detailed heuristic
design settings for each task.
B.1
BPP
In online Bin Packing Problem (BPP) (Seiden 2002), a set of items, each with its own weight, needs to be packed into bins with
a predetermined capacity. The objective of the BPP is to minimize the total number of bins required to accommodate all the
items. In an online scenario, items are packed as they are received without prior knowledge.
The heuristic operates by loading items sequentially in an online fashion, requiring only the selection of the best bin at each
iteration. This designed function scores bins based on their remaining capacities and the size of the arriving item, with the
highest scoring bin chosen for each iteration. The function takes two inputs - the size of the arriving item and the remaining
capacities of the bins - and outputs a vector that ranks the bins accordingly. A task description used in the prompt and the
Python code snippet template are illustrated as follows:
'
&
$
%
Task Description: Implement a function that returns the priority with which we want to add an item to each bin.
Template Program:
import numpy as np
def priority(item: float, bins: np.ndarray) -> np.ndarray:
"""Returns priority with which we want to add item to each bin.
Args:
item: Size of item to be added to the bin.
bins: Array of capacities for each bin.
Return:
Array of same size as bins with priority score of each bin.
"""
return item - bins
Figure 1: BPP heuristic design description and template program.
B.2
TSP
For TSP, one of the widely used metaheuristics, Guided Local Search (GLS), is used (Voudouris, Tsang, and Alsheddy 2010).
The pipeline of GLS is as follows:
Step 1: Create an initial solution using nearest neighbor constructive heuristics.
Step 2: Local Search Stage: Perform a local search (swap and relocate) to improve the current solution and generate a local
optimal solution.
Step 3: Perturbation Stage: Update the distance matrix. Perform another local search based on the updated distance matrix
to perturb the local optimal solution to escape from local optimality.
Steps 2 and 3 are iteratively repeated until the stopping criterion (maximum number of iterations set to 1, 000 in the experi-
ments) is satisfied. The best solution obtained throughout the iterations is considered the final solution.
Our goal is to develop a heuristic to update the distance matrix in the perturbation step. The task description provided in the
prompt and the template of the Python code snippet is outlined below. The inputs include the original distance matrix, the local
optimal solution, and the frequency of edge usage in perturbation. The output should be the updated distance matrix.


--- Page 13 ---
'
&
$
%
Task Description: Given an edge distance matrix and a local optimal route, please help me design a strategy to
update the distance matrix to avoid being trapped in the local optimum with the final goal of finding a tour with
minimized distance. You should create a heuristic for me to update the edge distance matrix.
Template Program:
import numpy as np
def update_edge_distance(edge_distance: np.ndarray, local_opt_tour:
np.ndarray, edge_n_used: np.ndarray) -> np.ndarray:
,â†’
"""
Design a novel algorithm to update the distance matrix.
Args:
edge_distance: A matrix of the distance.
local_opt_tour: An array of the local optimal tour of IDs.
edge_n_used: A matrix of the number of each edge used during
permutation.
,â†’
Return:
updated_edge_distance: A matrix of the updated distance.
"""
updated_edge_distance = np.copy(edge_distance)
# Calculate combined importance and frequency factor
updated_edge_distance = edge_distance
return updated_edge_distance
Figure 2: TSP heuristic design task description and template program.
C
Baseline Settings
In this work, we employ FunSearch (Romera-Paredes et al. 2024) and EoH (Liu et al. 2024a) as baseline. For EoH, we inherit
the default settings, including the number of iterations T = 20, the parent selection size d = 5, and the population size N = 10
for the TSP and N = 20 for the BPP. Our MEoH also follows these settings. In summary, 1, 000 heuristics are generated for
solving TSP, and 2, 000 heuristics for BPP. For FunSearch, we also adopt the default settings, the number of islands is 10 and
the number of samples for each prompt is 4. FunSearch generates 10, 000 heuristics for solving BPP and TSP.
D
Metric Definition
D.1
HV
Hypervolume (HV) is calculated as follows:
HV(P, râˆ—) = VOL

âˆª
vâˆˆP[v1, râˆ—
1] Ã— . . . Ã— [vm, râˆ—
m]

,
(3)
where P represents the approximate Pareto front obtained by an automated heuristic design approach, v = (v1, . . . , vm)âŠº
denotes the corresponding objective vector, VOL(Â·) represents the Lebesgue measure, and râˆ—= (râˆ—
1, . . . , râˆ—
m)âŠºis a reference
objective vector.
To account for variations in HV values across different objective domains, i.e., the scalar of intrinsic objective value and the
running time, we normalized each objective value for each instance. Specifically, the generated heuristic x can be normalized
in the objective space using the approximated ideal point zideal = (zideal
1
, . . . , zideal
M )âŠºand the approximated nadir point znadir =
(znadir
1
, . . . , znadir
M )âŠºderived from the union of all approximated Pareto-front P as
f â€²
i(x) = fi(x) âˆ’zideal
i
znadir
i
âˆ’zideal
i
,
(4)


--- Page 14 ---
where zideal
i
= min{vi|v âˆˆP} and znadir
i
= max{vi|v âˆˆP}, âˆ€i âˆˆ{1, . . . , M}. Consequently, the value of each objective is
normalized to [0, 1]. Based on that, the reference point râˆ—= (1.1, . . . , 1.1)âŠº.
D.2
IGD
Inverted Generational Distance (IGD) measures the convergence and diversity of the obtained Pareto front approximation
concerning the true Pareto front. It is calculated as follows:
IGD(P, P âˆ—) =
1
|P âˆ—|
X
pâˆˆP âˆ—
min
qâˆˆP d(p, q),
(5)
where P is the set of decision vectors, i.e, the approximated Pareto front. P âˆ—is the true Pareto front, |P âˆ—| is the number of
points in the true Pareto front d(p, q) is the Euclidean distance between the points p and q in the objective space.
The IGD calculates the average distance from the true Pareto front points to their nearest neighbor in the approximated Pareto
front. A lower IGD value indicates a better approximation of the true Pareto front.
Itâ€™s important to note that the true Pareto front is required for calculating the IGD metric, which may not always be available
in many cases. So, a reference set of well-distributed Pareto-optimal heuristics is often used as an approximation of the true
Pareto front, here the reference set is the nondominated set derived from the union of all generated heuristics.
E
TSPLIB Results
Table 5: Results of small and large TSPLIB instances.
TSPLIB
FunSearch
EoH
MEoH
Gap
Time/s
Gap
Time/s
Gap
Time/s
berlin52
0.000%
0.484
0.000%
8.500
0.000%
0.344
ch130
0.156%
2.031
0.233%
42.360
0.233%
1.016
ch150
0.306%
2.500
0.502%
56.062
0.000%
1.250
eil101
0.000%
28.391
0.373%
56.031
0.000%
22.297
eil51
0.000%
0.515
0.000%
7.109
0.000%
0.312
eil76
0.183%
0.938
0.107%
14.844
0.000%
0.531
kroA100
0.000%
1.407
0.000%
24.437
0.000%
0.734
kroC100
0.000%
1.500
0.000%
24.781
0.000%
0.703
kroD100
0.000%
1.578
0.000%
24.563
0.000%
0.734
lin105
0.000%
1.812
0.000%
26.703
0.000%
0.890
pr76
0.000%
0.969
0.000%
14.469
0.000%
0.546
rd100
0.000%
1.453
0.000%
24.266
0.000%
0.750
st70
0.000%
0.859
0.000%
12.797
0.000%
0.500
Avg.
0.050%
3.418
0.093%
25.917
0.018%
2.354
a280
0.195%
378.656
0.059%
640.453
1.245%
356.468
pcb442
1.389%
932.093
1.714%
1694.547
1.284%
916.219
pr1002
2.878%
354.813
2.487%
3592.891
3.272%
142.000
tsp225
1.679%
12.891
1.243%
136.078
0.197%
8.328
Avg.
1.535%
419.613
1.376%
1515.992
1.50%
355.754
F
Visualization of Dominance-dissimilarity Scores
We visualize the evolution of Dominance-dissimilarity Scores in Figure 3. The x-axis is the heuristic index, and the y-axis
is the iteration index. It is important to note that the presence of blank blocks in the early iterations indicates cases where the
population is not filled, due to the generation of illegal code segments by LLM. As shown in Figure 3, MEoH heuristics can
maintain diversity during the evolutionary process, while the diversity of EoH drastically deteriorates.


--- Page 15 ---
0 2 4 6 8 10 12 14 16 18
Individuals
0
2
4
6
8
10
12
14
16
18
Iterations
0.0 0.0 0.0 0.0 -1.4
0.0 0.0 -0.6-0.7-1.1-1.5-1.5-1.5-1.6-2.8
0.0 0.0 0.0 -0.6-0.7-1.4-1.5-1.5-1.5-2.1-2.1-3.0-3.1-3.3-4.1
0.0 0.0 0.0 -0.6-0.7-0.7-1.5-1.5-1.5-1.7-2.0-2.1-2.5-2.6-2.7-2.8-3.1-3.2-3.2-3.5
0.0 0.0 0.0 -0.6-0.7-0.7-1.4-1.5-1.5-1.5-1.7-2.0-2.1-2.2-2.2-2.4-2.5-3.2-3.4-3.4
0.0 0.0 0.0 -0.6-0.7-0.7-1.4-1.5-1.5-1.5-1.7-2.0-2.1-2.2-2.2-2.4-2.5-3.2-3.4-3.4
0.0 0.0 0.0 -0.5-0.5-0.6-0.7-0.7-1.5-1.5-1.5-1.7-2.0-2.1-2.7-2.8-2.8-2.8-2.9-3.1
0.0 0.0 0.0 -0.5-0.6-0.6-0.7-0.8-1.2-1.3-1.6-2.5-2.5-2.5-2.6-3.0-3.0-3.1-3.2-3.8
0.0 0.0 0.0 0.0 0.0 -0.5-0.6-0.6-0.7-0.7-0.8-1.6-1.9-2.0-2.5-2.5-2.6-2.6-2.8-3.0
0.0 0.0 0.0 0.0 0.0 0.0 -0.6-0.6-0.7-0.8-1.0-1.2-1.4-1.6-1.7-2.0-2.5-2.5-2.6-2.8
0.0 0.0 0.0 0.0 0.0 0.0 -0.5-0.6-0.6-0.7-0.8-1.0-1.1-1.2-1.4-1.6-1.7-2.0-2.5-2.5
0.0 0.0 0.0 0.0 0.0 0.0 -0.3-0.3-0.5-0.6-0.7-0.8-1.0-1.0-1.2-1.3-1.6-1.7-2.0-2.0
0.0 0.0 0.0 0.0 0.0 0.0 -0.3-0.3-0.3-0.6-0.7-0.8-0.9-1.0-1.0-1.2-1.3-1.4-1.6-1.7
0.0 0.0 0.0 0.0 0.0 0.0 -0.3-0.5-0.6-0.7-0.8-0.9-1.0-1.0-1.0-1.0-1.1-1.2-1.5-1.6
0.0 0.0 0.0 0.0 0.0 0.0 -0.4-0.4-0.5-0.5-0.6-0.6-0.7-0.7-0.8-1.0-1.0-1.1-1.3-1.4
0.0 0.0 0.0 0.0 0.0 0.0 -0.4-0.4-0.5-0.5-0.6-0.6-0.7-1.0-1.0-1.0-1.0-1.1-1.3-1.4
0.0 0.0 0.0 0.0 0.0 0.0 -0.4-0.5-0.5-0.6-0.7-0.8-1.0-1.0-1.0-1.1-1.3-1.4-1.4-1.5
0.0 0.0 0.0 0.0 0.0 0.0 0.0 -0.4-0.4-0.5-0.5-0.6-0.6-0.7-0.7-0.8-1.0-1.0-1.1-1.3
0.0 0.0 0.0 0.0 0.0 0.0 0.0 -0.4-0.4-0.5-0.5-0.6-0.6-0.7-0.7-0.8-1.0-1.0-1.1-1.1
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 -0.4-0.4-0.5-0.5-0.5-0.6-0.7-0.9-1.0-1.0-1.0
4
2
0
(a) BPP, MEoH
0 2 4 6 8 1012141618
Individuals
0
2
4
6
8
10
12
14
16
18
20
Iterations
0.0 0.0 0.0-0.4-0.4-0.4-1.1-1.2-1.6-1.9-2.3-2.4-2.9-3.0-3.2-3.6-3.7-4.3-4.5-6.2
0.0 0.0 0.0 0.0-0.5-0.9-1.0-1.5-1.7-3.6-3.8-4.0-4.1-4.2-4.3-4.9-6.2-6.9-7.5-9.2
0.0 0.0 0.0 0.0-0.5-0.5-0.6-0.7-0.9-1.1-1.2-1.4-1.6-2.9-3.4-3.7-4.3-6.8-7.8-7.8
0.0 0.0 0.0 0.0-0.6-1.2-1.3-1.8-2.0-2.0-2.3-2.5-3.1-3.3-4.2-4.4-5.2-6.3-6.4-6.6
0.0 0.0 0.0-0.7-0.7-0.8-0.8-1.8-1.8-1.9-1.9-2.7-3.1-3.1-3.3-6.4-6.4-8.4-9.1-9.9
0.0 0.0 0.0-0.5-0.6-0.6-0.6-0.8-0.8-1.1-1.3-1.4-2.5-2.5-4.1-5.0-5.8-6.5-6.6-8.4
0.0 0.0 0.0 0.0 0.0-0.6-0.6-1.2-1.3-1.3-1.3-1.5-1.8-2.6-3.2-5.0-6.1-6.4-8.4-8.6
0.0 0.0 0.0 0.0 0.0 0.0-0.5-0.6-1.2-1.3-1.9-2.3-2.3-2.5-3.1-3.2-3.8-4.6-8.4-9.1
0.0 0.0 0.0 0.0 0.0 0.0 0.0-0.5-0.5-0.6-1.2-1.3-1.5-1.8-2.3-2.5-2.8-3.7-4.5-5.2
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0-0.5-0.5-0.5-0.7-0.9-1.8-2.3-2.5-3.3-3.3-5.1-5.3
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0-0.4-0.5-0.5-0.5-0.7-0.9-1.4-1.8-3.3-3.4-4.3-5.3
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0-0.4-0.5-0.5-0.5-0.6-0.7-3.4-3.9-5.0-5.2-6.5
0.0 0.0 0.0 0.0 0.0 0.0-0.4-0.5-0.7-1.2-1.2-1.2-1.3-1.5-1.5-1.7-3.8-7.6-8.4-8.8
0.0 0.0 0.0 0.0 0.0-0.4-0.5-0.5-0.7-0.9-0.9-1.1-1.8-2.5-3.4-4.2-5.8-7.8-7.8-10.5
0.0 0.0 0.0 0.0-0.4-0.5-0.5-0.5-0.6-0.7-1.2-1.5-2.5-3.5-3.6-3.8-4.3-6.8-7.7-9.5
0.0 0.0 0.0 0.0-0.4-0.4-0.5-0.5-0.7-1.1-1.1-1.2-1.9-2.1-3.0-3.6-3.8-5.8-7.2-8.1
0.0 0.0 0.0-0.4-0.5-0.5-0.5-0.7-1.1-1.6-1.9-2.6-2.7-3.0-3.2-4.1-4.5-6.4-7.8-8.2
0.0 0.0 0.0 0.0-0.4-0.4-0.5-0.7-1.1-1.1-1.4-1.9-2.5-3.0-3.0-4.1-4.3-4.4-6.2-6.3
0.0 0.0 0.0-0.4-0.5-0.6-0.6-0.6-0.7-1.0-1.3-2.8-2.8-3.2-3.3-3.7-3.7-3.8-3.9-6.0
0.0 0.0 0.0 0.0 0.0 0.0-0.6-0.6-1.6-2.2-2.3-2.5-2.8-3.9-4.4-4.5-4.5-5.6-6.1-6.3
0.0 0.0 0.0 0.0 0.0-0.4-0.5-0.5-1.3-1.8-2.2-2.8-3.0-3.3-3.9-4.1-4.4-4.4-4.8-6.6
10
5
0
(b) BPP, EoH
0 1 2 3 4 5 6 7 8 9
Individuals
0
2
4
6
8
10
12
14
16
18
Iterations
0.0 0.0 -0.6 -0.6 -2.0
0.0 0.0 0.0 0.0 0.0 0.0 -0.5 -0.7 -0.7 -1.2
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 -0.3
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 -0.4
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2
1
0
(c) TSP, MEoH
0 1 2 3 4 5 6 7 8 9
Individuals
0
2
4
6
8
10
12
14
16
18
Iterations
0.0 0.0 0.0 0.0 -0.5 -0.6 -1.4 -3.8 -4.3 -5.4
0.0 0.0 0.0 -0.7 -0.7 -0.8 -2.3 -2.3 -4.6 -4.9
0.0 0.0 0.0 -0.5 -0.7 -0.7 -0.8 -1.9 -4.1 -5.3
0.0 0.0 0.0 0.0 -0.7 -1.3 -2.2 -2.9 -3.6 -3.7
0.0 0.0 0.0 -0.8 -0.8 -0.8 -1.6 -2.3 -2.3 -7.1
0.0 0.0 0.0 0.0 -0.8 -0.8 -2.3 -2.5 -2.6 -3.0
0.0 0.0 0.0 -0.8 -0.8 -0.8 -0.8 -0.8 -4.5 -5.8
0.0 0.0 0.0 0.0 0.0 -0.9 -2.2 -2.6 -4.3 -6.9
0.0 0.0 -0.8 -0.8 -1.0 -1.8 -2.4 -4.8 -4.9 -5.7
0.0 0.0 0.0 -0.8 -0.8 -1.6 -2.1 -2.5 -3.2 -3.8
0.0 -0.8 -0.8 -0.8 -2.8 -3.9 -4.1 -5.4 -5.6 -6.4
0.0 0.0 0.0 -0.8 -1.6 -1.7 -3.7 -3.9 -5.8 -6.4
0.0 0.0 -0.8 -1.0 -1.6 -1.7 -3.4 -3.4 -4.7 -5.4
0.0 0.0 0.0 -0.8 -0.9 -1.6 -2.5 -2.5 -6.8 -6.9
0.0 0.0 0.0 -0.8 -0.8 -1.6 -1.6 -3.2 -4.1 -6.7
0.0 0.0 -0.8 -0.8 -1.8 -1.8 -2.9 -4.4 -4.4 -4.4
0.0 0.0 0.0 0.0 -1.6 -1.6 -1.6 -1.6 -2.3 -5.1
0.0 0.0 0.0 -0.8 -0.8 -0.9 -2.2 -2.8 -3.1 -3.7
0.0 0.0 0.0 0.0 -0.8 -1.7 -3.5 -4.3 -5.2 -5.3
0.0 0.0 -0.8 -1.6 -1.6 -1.6 -3.3 -4.2 -4.5 -5.8
6
4
2
0
(d) TSP, EoH
Figure 3: Visualization of the evolution of dominance-dissimilarity score.
G
Search Operators
MEoH inherits 5 search operators from EoH (Liu et al. 2024a). These operators are all implemented based on LLMs. In
this part, the corresponding prompts will be elaborated. Generally, the prompt consists of operator-specific guidance, task
description, and program template. For brevity, the task description and the program template are denoted as $Task Description
and $Program Template, respectively.
G.1
E1 Operator
As shown in Figure 4, the E1 operator is used to explore a new heuristic different from the 5 selected heuristics. For simplicity,
the heuristics including corresponding heuristic description and code are omitted.


--- Page 16 ---
'
&
$
%
$Task Description
I have 5 existing algorithms with their codes as follows:
<Algorithm description>: ...
<Code>: ...
...
Please help me create a new algorithm that has a totally different form from the given ones.
1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed
{}.
2. Next, implement the following Python function: $Program Template
Do not give additional explanations.
Figure 4: An example of E1 prompt for TSP
G.2
E2 Operator
As shown in Figure 5, the E2 operator is used to generate a new heuristic based on the common idea of the 5 selected heuristics.
'
&
$
%
$Task Description
I have 5 existing algorithms with their codes as follows:
<Algorithm description>: ...
<Code>: ...
...
Please help me create a new algorithm that has a totally different form from the given ones but can be motivated
from them.
1. Firstly, identify the common backbone idea in the provided algorithms.
2. Secondly, based on the backbone idea describe your new algorithm in one sentence. The description must be
inside within boxed {}.
3. Thirdly, implement the following Python function: $Program Template
Do not give additional explanations.
Figure 5: An example of E2 prompt for TSP
G.3
M1 Operator
As shown in Figure 6, the M1 operator is desired to generate a new heuristic based on a given heuristics to improve the
performance.


--- Page 17 ---
'
&
$
%
$Task Description
I have one algorithm with its code as follows:
<Algorithm description>: ...
<Code>: ...
Please assist me in creating a new algorithm that has a different form but can be a modified version of the
algorithm provided.
1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed
{}.
2. Next, implement the following Python function: $Program Template
Do not give additional explanations.
Figure 6: An example of M1 prompt for TSP
G.4
M2 Operator
As shown in Figure 7, the goal of the M2 operator is to modify the parameters of a given heuristic.
'
&
$
%
$Task Description
I have one algorithm with its code as follows:
<Algorithm description>: ...
<Code>: ...
Please identify the main algorithm parameters and assist me in creating a new algorithm that has a different
parameter settings of the score function provided.
1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed
{}.
2. Next, implement the following Python function: $Program Template
Do not give additional explanations.
Figure 7: An example of M2 prompt for TSP
G.5
M3 Operator
In Figure 8, the M3 operator is used to simplify a given heuristic by eliminating redundant components. In this context, the task
description and code requirements are not required.


--- Page 18 ---
'
&
$
%
1. First, you need to identify the main components in the function below.
2. Next, analyze whether any of these components can be overfit to the in-distribution instances.
3. Then, based on your analysis, simplify the components to enhance the generalization to potential out-of-
distribution instances.
4. Finally, provide the revised code, keeping the function, inputs, and outputs unchanged.
<Code>: ...
Do not give additional explanations.
Figure 8: An example of M3 prompt for TSP
H
Designed Heuristics
In this section, we present a variety of representative heuristics designed by LLM-based automated heuristic design frame-
works, encompassing FunSearch (Romera-Paredes et al. 2024), EoH (Liu et al. 2024a), and our own MEoH.
H.1
BPP
EoH Heuristics
The heuristic developed by EoH with the best performance in terms of the optimal gap, as shown in Fig-
ure 9, utilizes sophisticated mathematical operators such as logarithm, square root, and exponential. The complexity of this
scoring function renders it challenging to construct manually due to its intricate nature and reliance on advanced mathematical
operations.
'
&
$
%
Algorithm Description: My new algorithm calculates the score for each bin as the sum of the binâ€™s current
capacity divided by the product of the logarithm of the difference between the binâ€™s capacity and the item size
and the square root of the difference between the binâ€™s capacity and the item size, raised to the power of the binâ€™s
current capacity, and multiplied by the exponential function raised to the power of the item size multiplied by the
difference between the binâ€™s capacity and the item size. Additionally, the score is multiplied by the reciprocal of
the binâ€™s current capacity to prioritize bins with lower capacities.
import numpy as np
def score(item, bins):
scores = (bins / ((np.log(bins - item) * np.sqrt(bins - item)) **
bins)) * np.exp(item * (bins - item)) * (1/bins)
,â†’
return scores
Figure 9: The EoH heuristic with the best optimal gap on BPP.
FunSearch Heuristics
The heuristic devised by FunSearch, illustrated in Figure 10, it incorporates numerous sophisticated
parameters and introduces a random noise. Unlike the EoH approach, the FunSearch heuristic relies on intricate parameter
settings and stochastic perturbations for optimization.


--- Page 19 ---
'
&
$
%
def priority(item: float, bins: np.ndarray) -> np.ndarray:
eps = 1e-7
# Calculate scores based on available space and current capacity
scores = (bins - item) / (bins + eps)
# Adjust the penalty if necessary
penalty = np.power(np.min(bins), 0.5) * np.arange(len(bins)) * 0.01
scores -= penalty
# Scale the scores and add a weight
weight = 0.8
scores = (scores - np.min(scores)) / (np.max(scores) - np.min(scores))
* (1 - weight) + weight
,â†’
# Favor bins where the item fits perfectly
scores += 0.5 * (bins == item)
# Favor bins with relatively higher remaining capacity
scores += 0.02 * (bins - item) / np.max(bins)
# Normalize the priority values
priority = scores / np.sum(scores)
# Add a small randomness to the priorities for exploration
priority += np.random.uniform(0, 1e-5, bins.shape)
# Handle the case where the sum of priorities is not equal to 1
if np.abs(np.sum(priority) - 1) > 1e-6:
remaining_capacity = bins - np.sum(priority * bins)
priority += remaining_capacity / (np.sum(remaining_capacity) *
len(bins))
,â†’
return priority
Figure 10: The FunSearch heuristic with the best optimal gap on BPP.


--- Page 20 ---
Figure 11: An illustration of MEoH heuristics on BPP.
MEoH Heuristics
In this section, Figure 11 showcases the heuristics developed by MEoH, featuring heuristic descriptions,
corresponding code segments, and images in the objective space.
Specifically, these heuristics are designed to assign scores to bins based on the arriving items, subsequently arranging the
items in bins with the highest scores.
Among these heuristics highlighted in Figure 11, three exhibit superior performance in terms of the optimal gap, leveraging
advanced mathematical operators like absolute value and square root. Furthermore, in the case of the fast heuristic, the score is
consistently set to a fixed value of 1, which deviates from the intended description.
Given the integration of these heuristics into a greedy algorithm, the running time demonstrates low variance. Neverthe-
less, these MEoH-generated heuristics effectively balance the optimal gap and running time, enabling adaptability to diverse
scenarios.


--- Page 21 ---
H.2
TSP
EoH Heuristics
The heuristic crafted by EoH, as illustrated in Figure 12, intricately incorporates advanced mathematical
functions such as tanh alongside sophisticated parameters. It is noteworthy that this complex operation is executed within two
nested for-loops, resulting in a computational complexity of O(n2).
'
&
$
%
Algorithm Description: Update the edge distances in the edge distance matrix by applying a genetic algorithm-
inspired method, where the update is determined by a combination of edge count, distance, usage, and a cus-
tomized genetic function to promote global exploration and improved convergence.
import numpy as np
def update_edge_distance(edge_distance, local_opt_tour, edge_n_used):
updated_edge_distance = np.copy(edge_distance)
edge_count = np.zeros_like(edge_distance)
for i in range(len(local_opt_tour) - 1):
start = local_opt_tour[i]
end = local_opt_tour[i + 1]
edge_count[start][end] += 1
edge_count[end][start] += 1
edge_n_used_max = np.max(edge_n_used)
mean_edge_distance = np.mean(edge_distance)
for i in range(edge_distance.shape[0]):
for j in range(edge_distance.shape[1]):
if edge_count[i][j] > 0:
score_factor = (np.tanh(edge_count[i][j]) /
edge_count[i][j]) + (edge_distance[i][j] /
mean_edge_distance) - (0.6 / edge_n_used_max) *
edge_n_used[i][j]
,â†’
,â†’
,â†’
updated_edge_distance[i][j] += score_factor * (1 +
edge_count[i][j])
,â†’
return updated_edge_distance
Figure 12: The EoH heuristic with the best optimal gap on TSP.
FunSearch Heuristics
The heuristic formulated by FunSearch, as depicted in Figure 13, incorporates a logarithm operation
base 2, Gaussian-distributed noise sampling, and intricate parameter configurations. It is worth noting that this heuristic only
includes a single for-loop, indicating a computational efficiency that surpasses the aforementioned EoH heuristic.


--- Page 22 ---
Figure 14: An illustration of MEoH heuristics on TSP.
'
&
$
%
def update_edge_distance(edge_distance: np.ndarray, local_opt_tour:
np.ndarray, edge_n_used: np.ndarray) -> np.ndarray:
,â†’
num_nodes = edge_distance.shape[0]
updated_edge_distance = np.copy(edge_distance)
decay_factor = 0.99
for i in range(num_nodes - 1):
node_i, node_j = local_opt_tour[i], local_opt_tour[i + 1]
edge_score = edge_distance[node_i, node_j] * np.log2((num_nodes -
edge_n_used[node_i, node_j]) + 1)
,â†’
edge_score *= decay_factor ** edge_n_used[node_i, node_j]
#
Multiply by decay factor
,â†’
edge_score += np.random.normal(0, 0.1)
# Add small noise
updated_edge_distance[node_i, node_j] = edge_score
updated_edge_distance[node_j, node_i] = edge_score
return updated_edge_distance
Figure 13: The FunSearch heuristic with the best optimal gap on TSP.


--- Page 23 ---
MEoH Heuristics
In this section, the heuristics designed by MEoH are shown in Figure 14, showcasing 5 representative
heuristic descriptions along with corresponding code segments, and visual representations of all the heuristics in the objective
space.
In this work, GLS is employed to solve TSP, and the heuristics are designed to update the edge distance to facilitate the
perturbation in each iteration.
As shown in Figure 14, the designed heuristics leverage advanced mathematical operators including logarithm, square root,
and exponential functions. Furthermore, for the fast heuristic, the edge distances remain unchanged, deviating from the original
description due to the complexity of implementing Q-Learning.
These heuristics underscore the capability of our MEoH to strike a balance between the optimal gap and running time,
allowing for effective adaptation to various scenarios.
I
MEoH on 3-objective tasks
In this section, MEoH is utilized to develop heuristics while taking into account 3 objectives. In addition to performance and
efficiency, we also consider code readability, which is crucial for user comprehension and maintenance of the programming
code (Buse et al., 2009). The readability is assessed using the Halstead difficulty metric (Curtis et al., 1979). As illustrated in
Figure 15 and 16, MEoH continues to perform well, particularly in the TSP task. Despite the promising outcomes achieved
with three objectives, future research will be essential to address the challenges associated with handling more objectives.
5
10
15
20
Iterations
0.0
0.2
0.4
0.6
HV
MEoH
EoH
(a) HV
5
10
15
20
Iterations
1
2
IGD
MEoH
EoH
(b) IGD
Figure 15: Comparations of EoH and MEoH on BPP5k.
5
10
15
20
Iterations
0.0
0.5
1.0
HV
MEoH
EoH
(a) HV
5
10
15
20
Iterations
0
5
10
IGD
MEoH
EoH
(b) IGD
Figure 16: Comparations of EoH and MEoH on TSP100.
