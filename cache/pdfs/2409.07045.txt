--- Page 1 ---
Beyond IID: Optimizing Instruction Learning from the Perspective of Instruction
Interaction and Dependency
Hanyu Zhao∗, Li Du* †, Yiming Ju, Chengwei Wu, Tengfei Pan
Beijing Academy of Artificial Intelligence, Beijing, China
{hyzhao, duli, ymju, cwwu, tfpan}@baai.ac.cn
Abstract
With the availability of various instruction datasets, a pivotal
challenge is how to effectively select and integrate these in-
structions to fine-tune large language models (LLMs). Pre-
vious research mainly focuses on selecting individual high-
quality instructions. However, these works overlooked the
joint interactions and dependencies between different cate-
gories of instructions, leading to suboptimal selection strate-
gies. Moreover, the nature of these interaction patterns re-
mains largely unexplored, let alone optimize the instruction
set with regard to them. To fill these gaps, in this paper, we:
(1) systemically investigate interaction and dependency pat-
terns between different categories of instructions, (2) man-
age to optimize the instruction set concerning the interaction
patterns using a linear programming-based method, and opti-
mize the learning schema of SFT using an instruction depen-
dency taxonomy guided curriculum learning. Experimental
results across different LLMs demonstrate improved perfor-
mance over strong baselines on widely adopted benchmarks.
1
Introduction
Supervised fine-tuning (SFT) is the key to aligning large lan-
guage models (LLMs) with human beings, enabling them
to complete various downstream tasks and adapt to specific
domains such as healthcare and finance (Zhao et al., 2023a).
The effectiveness of the SFT process relies on a high-quality
instruction set, so as to ensure the performance of LLMs
(Longpre et al., 2023; Wang et al., 2023; Xu et al., 2023).
Temporarily, with the availability of various instruction sets,
a new challenge has been raised, i.e., how to select and inte-
grate existing datasets to obtain an optimized instruction set.
To address this issue, previous research typically works by
selecting and combining individual “high-quality” instruc-
tions. Then often construct proxy indicators to evaluate dif-
ferent aspects of quality, such as factual correctness, com-
plexity, and informativeness. Then the raw instruction set
could be refined by selecting instructions with the highest
relative quality scores (Latif and Zhai, 2024; Li et al., 2024;
Lu et al.; Zhao et al., 2023b).
However, emerging evidence (Dong et al.; Yuan et al.,
2023) and our analyses indicate that complex correlation and
*Equal contribution.
†Corresponding Author
Copyright © 2024, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.
dependency relationships exist between different categories
of instructions. Therefore, considering the quality of indi-
vidual instructions alone can be a suboptimal approach for
building a fine-tuning instruction set. Research indicates that
these categories are interrelated; incorporating one category
of instructions may enhance or diminish the model’s per-
formance in others (Dong et al., 2023; Huang and Chang,
2023). Additionally, the skills required for different tasks
often form hierarchical taxonomies. For instance, solving a
bioinformatics problem requires both biological knowledge
and coding skills. Consequently, instructions are intercon-
nected and collectively influence model performance. Ignor-
ing these correlations can reduce the efficiency of instruction
selection, as incorporating one category of instruction may
even degrade the model’s performance in another category.
Moreover, the dependency between skills necessitates that
models acquire foundational knowledge before progressing
to more complex tasks; otherwise, the effectiveness of in-
struction tuning will be compromised (Longpre et al., 2023).
Hence, it is crucial to account for these joint effects for op-
timizing the instruction set. However, two main challenges
remain unaddressed: (1) The potential correlation and de-
pendency patterns are largely unknown; (2) How to opti-
mize the instruction set while considering these correlation
and dependency patterns remains an unexplored area. To fill
these gaps, as Figure 1 (b)-(e) shows, we systemically inves-
tigated the correlation patterns between different categories
of instructions, and induced an ability taxonomy of instruc-
tions based on causal interventions on the distribution of
the instruction set. Then, with the guidance of the correla-
tion patterns and dependency taxonomy, we optimized the
instruction set by adjusting the proportion of different cat-
egories of instructions, and arranging the order of learning
different categories of instructions.
Specifically, we construct an automatic tagging system to
assign the instruction with tags describing the detailed ca-
pability and knowledge required to complete this instruc-
tion. With the tags, we do interventions in the dataset dis-
tribution by adding or removing instructions with certain
tags, so that we can observe how the LLM’s performance
changes with the incorporation of each category of instruc-
tions, as well as how the performance of the LLM on one
category of instruction changes depending on another cat-
egory of instructions. Given the correlation patterns, we
arXiv:2409.07045v1  [cs.CL]  11 Sep 2024


--- Page 2 ---
Figure 1: Framework of our work. Baseline methods selection instructions using quality scores (a). In this paper, we first induce
the correlation pattern (b) and dependency taxonomy (d), then optimize the instruction set collection concerning the correlation
(c) and dependency taxonomy (e).
managed to optimize the proportion of different categories
of instructions by turning it into an effect-equivalence-
based linear programming problem. Furthermore, we pro-
pose a dependency taxonomy-based curriculum learning
(Wang, Chen, and Zhu, 2021) method to rearrange the
learning order of categories of instructions. We release the
code and dataset at https://github.com/BAAI-DIPL/sft-set-
optimization-via-instruction-interaction-and-dependency.
Our experiments demonstrate extensive correlations and
dependencies among various categories of instruction data,
particularly between reasoning-related and commonsense
memorization tasks. Mathematics and coding also emerge
as foundational elements for LLMs in executing general do-
main tasks. By leveraging these correlations and dependen-
cies, we applied guided optimization and curriculum learn-
ing methods, resulting in improved performance across dif-
ferent LLMs, including Qwen (Yang et al., 2024) and Llama
(Dubey et al., 2024), compared to state-of-the-art baselines
on widely recognized benchmarks. Such results in turn sup-
port the reasonability of our analysis method and induced
instruction interaction patterns.
2
Causal Intervention based Instruction
Correlation Analysis and Ability
Taxonomy Induction
In the SFT stage, the LLM is trained to learn given instruc-
tion set D = {Ci}n
i=1, where Ci is the ith category of instruc-
tions. With the maximum likelihood estimation and indepen-
dent identical distribution (iid) assumption, the training ob-
jective could be formalized as maxθ
Q
i[P(Cij)], where Cij
is the jth instruction of Ci.
Due to the inherent correlation and dependency between
the knowledge and skills involved in different categories of
instructions, the distribution of instruction set D should be
characterized using an joint distribution P(C1, . . . , Ci, CN),
and P(C1, . . . , Ci, . . . , CN) ̸= Q
i P(Cij). Such discrep-
ancy would lead to ineffectiveness and inefficiency of the
SFT process, as: (1) Under the iid assumption, the train-
ing objective deviates from the actual distribution of in-
struction set; (2) The joint distribution could be decom-
posed into a sequential manner as P(C1, . . . , Ci, . . . , CN) =
Q P(Ck|Cj, . . . ), which indicates a sequential learning
schema, i.e., advanced skills could be learned only enough
preliminary knowledge is equipped. Nevertheless, in the cur-
rent SFT schema, different categories of instructions are
randomly distributed in the whole epoch, making the ad-
vanced skills been trained before equipped with enough
prior knowledge. This limits the efficiency of the SFT pro-
cess. Thus, it would be necessary to consider the optimiza-
tion of instruction set beyond the iid assumption.
However, the category of instructions are unknown pri-
orly. Thus, to induce the correlation pattern and dependency
taxonomy between different categories of instructions, we
first systematically collect publicly available high-quality in-
structions and design an ability tagging system to automat-
ically confer instruction a set of tags, which describes the
ability and knowledge necessary for completing the instruc-
tion. So that we can categorize the instructions with the tags.
Then based on the category tags, by adding or removing cer-
tain categories of instructions (Cause), we could obtain how
the performances of other categories of instructions change
(Effect) brought by such intervention, and induce the corre-
lation and dependency pattern.
2.1
Instruction Collection and Automatic Ability
Tagging System
The prerequisites of analyzing the relationship patterns be-
tween different categories of instructions are collecting a


--- Page 3 ---
Instruction
Category Tag
Write a piece of code to count the number
of different types of nucleotide bases in a
DNA sequence:
[STEM Knowl-
edge’,
’Pro-
gram Ability’]
Table 1: Examples of the tags of instruction.
large enough instruction set and elucidating the category dis-
tribution of the instruction set. To this end, we comprehen-
sively collect currently available high-quality open-source
instruction sets, and build an automatic tagging system, to
confer each instruction tag(s) about the main skill or knowl-
edge necessary for completing the instruction. For example,
as shown in Table 1, the LLM should have both the pro-
gramming ability and STEM knowledge (biology) to fulfill
the requirement described by the instruction.
We systematically collected the available high-quality
instruction sets constructed by manual annotation, GPT4
Achiam et al. (2023) or GPT 3.5. After quality filtering and
de-duplication, we collect a large-scale instruction collec-
tion with 9 million instructions.
Given the vast scale instructions set, we construct an
LLM-based tagging system to automatically confer each in-
struction a set of tags. Specifically, we employ Qwen-1.5-
72B-Instruction (Yang et al., 2024) as the tagger, and guide
it to generate tags through prompts. Whereas the LLM may
describe the same ability or knowledge using different ex-
pressions, making the normalization of tags necessary. To
address this issue, we combine the tags with high seman-
tic similarity. Specifically, we first obtain the semantic rep-
resentation of the tags using a text embedding model BGE
(Xiao et al., 2023). Then semantically similar tags are recog-
nized if their cosine similarity of embeddings is larger than
an empirical threshold λ = 0.85. For a set of semantically
similar tags, they are normalized to the one with the highest
frequency among them (Hahsler, Piekenbrock, and Doran,
2019). After normalization, about 21,000 tags are left. More
details about the instruction collection and cleaning, tag con-
struction, normalization, and results of tagging are described
in the Appendix.
It would be impractical to investigate the correlation and
dependency of all the 21,000 categories of instructions.
Thus, as listed in Table 2, we manually choose 29 cate-
gories of instructions according to frequency and impor-
tance, which cover the main tasks and abilities across the
Math, Coding, QA, Commonsense Reasoning, Natural Lan-
guage Processing and Understanding, together with Dia-
logue and Applications.
2.2
Causal Intervention based Instruction
Correlation Analysis
Previous research suggests that instructions from differ-
ent domains and tasks are interconnected. After incorpo-
rating one category of instructions, after SFT, performance
across other categories would also be influenced. The source
of such correlations could be rather complex Dong et al.
(2023); Huang and Chang (2023). In this paper, rather than
Domain
Category List
Math
[’Math Reasoning’, ’Mathematical Mod-
elling’,
’Arithmetic
Calculation’,
’Data
Process and Analysis’]
Coding
[’Python’,
’Java’,
’Programm
Ability’,
’Coding Algorithm’]
QA
[’STEM Knowledge QA’, ’Humanities &
Social Sciences QA’, ’Commonsense Un-
derstanding’, ’Open Domain QA’]
Commonsense
Reasoning
[’Commonsense Reasoning’, ’Concept Un-
derstanding’, ’Logical Reasoning’]
NLP & NLU
[’Information
Extraction’,
’Sentiment
Analysis’, ’Story Understanding’, ’Text
Classification’, ’NLU’, ’Textual Summa-
rization’, ’Translation’, ’Event Understand-
ing’]
Dialogue
&
Applications
[’Multiturn Dialogue’, ’Communication &
Social Media’, ’Character Understanding
and Role-Playing’, ’String Process’, ’Aca-
demic Writing’, ’Creative Writing’]
Table 2: Categories of instructions included for analysis.
investigating the source of such correlation, we focus on sys-
tematically inducing the patterns of correlation, so as to di-
rectly guide the optimization of instruction sets.
There are various potential methods for quantifying such
correlation. In this paper, we propose a effect equivalence
coefficient to quantify the correlation between the ith and
jth category of instruction:
γM
ij = Avg
 
ρ[M ∪˜Ci(Ceval,jk)] −ρ[M(Ceval,jk)]
ρ[M ∪˜Cj(Ceval,jk)] −ρ[M(Ceval,jk)]
!
(1)
where M is a base model, D is an already existing instruc-
tion set, M ∪˜Ci and M ∪˜Cj is obtained by finetuning M on
D ∪˜Ci and D ∪˜Cj, respectively, ˜Ci are instructions of cat-
egory i out of D. M(Ceval,jk) is the output of M on the
kth instruction of category j on the evaluation set (Ceval,jk),
M ∪˜Ci(Ceval,jk) similarly. ρ(·) is a performance evaluation
function. Thus, heuristically, the effect equivalence coeffi-
cient γM
ij measures one instruction of category i “equals”
how many instructions of category j on average, with the
existence of an existing instruction set D. Thus, a larger
γM
ij indicates a stronger correlation.
The reasons for measuring the effect equivalence coeffi-
cient with regard to D are twofold: (1) in practical scenarios,
it often involves incorporating a certain category of instruc-
tions into the existing instruction set to enhance the LLM’s
capabilities in this area. Thus, investigating the correlation
pattern under such a scenario would guide evaluating the
influence of category proportion adjustments. (2) If induc-
ing ρij by removing Ci from D, it would be hard to eluci-
date whether the performance change is due to the absence
of necessary preliminary knowledge in Ci, or the correla-
tions between the instructions. The base instruction set D
at each time with different categories of instructions evenly


--- Page 4 ---
Figure 2: The effect equivalence coefficients between differ-
ent categories of instructions.
distributed. The list of instruction data categories is shown in
Table 1. We set the performance evaluation function ρ(·) as
the log-likelihood of the response corresponding to Ceval,jk.
One remaining issue is that γM
ij depends on the choice
of M. Actually, due to the similarity in the capabilities of
frequently used open-source LLMs, the effect equivalence
coefficients induced by different models could be rather sim-
ilar. In this section, we demonstrate the analysis results ob-
tained using M =Qwen-1.5-7B. More results based on other
LLMs such as LLama-3-8B (Dubey et al., 2024) are pro-
vided in the Appendix. Moreover, we argue that due to the
similarity in the pretraining corpus, the results based on 7B-
sized models could be scaled up to models with larger sizes.
Experimental Settings
We use llama3-8B and Qwen-1.5-
7B as base models for inducing the correlations. Within the
base instruction set and the evaluation set contain 1,000 and
500 instructions of each category, respectively. To induce the
correlation patterns, at each time, 2,000 additional instruc-
tions belonging to one of the 29 categories are incorporated
into the base instruction set.
Analysis Results
Figure 2 and Figure 5 of the Appendix
show the effect equivalence coefficients between different
categories of instructions derived from Qwen and Llama,
respectively. The ijth element of the matrix corresponds to
γM
ij , i.e., one instruction of category i “equals” how many
instructions of category j on average. We observe that: (1)
The existence of the correlation pattern is widespread, as
it could be found across multiple categories, and upon dif-
ferent LLMs. Moreover, the correlation patterns show sim-
ilarities across different LLMs. (2) Besides the positive re-
lationships, the negative elements also account for a large
proportion of the effect equivalence coefficients (e.g., The
influence of Programming Ability on Text Summarization
to Story Understanding). These suggest the wide existence
of antagonistic relationships between different categories of
instruction, i.e., incorporating one category of instruction
would lead to performance degradation of another one. This
highlights the necessity of optimizing the category propor-
tion of the whole instruction set beyond filtering individ-
ual high-quality instructions or simply enlarging the scale
of the instruction set. On the one hand, the synergistic cat-
egories may lead to redundancy of the instruction set, since
the instructions could substitute each other to some extent;
on the other hand, due to the existence of performance an-
tagonistic effect, adding instructions of one category would
jointly impact performance on the other categories, and vice
versa. Especially when constructing domain models, often
involves incorporating a large number of domain-specific or
task-specific instructions. This further necessitates the care-
ful arrangement of the types of instructions to ensure perfor-
mance on other domains is not severely impacted. Moreover,
one category of instructions may have synergistic and an-
tagonistic effects with other categories of instructions at the
same time. For example, incorporating the Program Ability
category could promote the performance of Math and Code
related categories, meanwhile impacting the performance on
STEM Knowledge or open Domain QA. Such complexity
further increases the difficulty of category proportion opti-
mization. (2) According to the correlation patterns, using hi-
erarchical clustering, the instruction categories could be fur-
ther classified into two “meta-groups”: I. A Symbolic Rea-
soning related group, including math and coding-related cat-
egories. II. A Commonsense Memorization-related group,
including knowledge understanding, knowledge QA, etc.
Heuristically, the categories within the meta-groups do share
inherent similarities in the knowledge and ability required
for completing these tasks, suggesting the effect equivalence
coefficients can reflect the inner correlations between differ-
ent instruction categories. Since both meta-groups are cru-
cial for LLMs, it is necessary to optimize the category dis-
tribution of instruction sets to enhance both types of meta-
capabilities simultaneously, concerning the performance an-
tagonistic effects.
2.3
Causal Intervention based Large Language
Model Ability Taxonomy Induction
Heuristically, human beings could not learn advanced
knowledge before mastering the necessary preliminary
knowledge. For example, it would be rather hard for a stu-
dent to learn advanced math before he has acquired basic
arithmetic calculations. Such a phenomenon inspires us to
investigate whether the dependency also exists when LLMs
learn different categories of instructions in the SFT process.
To induce the dependency taxonomy of different instruc-
tion categories, given an instruction set Dtrain, we sequen-
tially remove one category of instructions Ci and obtain a set
of ablation instruction sets {D\Ci
train}N
i=1, N is the total num-
ber of instructions, then compare the performance change
of LLM fine-tuned on Dtrain with that fine-tuned on D\Ci
train,
and that fine-tuned on D\Cj
train. This is because: (1) If the ex-
clusion of Ci causes significant performance degradation on


--- Page 5 ---
Subsequantial
categories
[’Humanities & Social Sciences QA’, ’Commonsense Understanding’,
’Open Domain QA’, ’Communication & Social Media’, ’Character Un-
derstanding and Role-Playing’, ’Creative Writing’]
Intermediary Cat-
egories
[’Data Process and Analysis’, ’STEM Knowledge QA’, ’Commonsense
Reasoning’, ’Concept Understanding’, ’Logical Reasoning’, ’Informa-
tion Extraction’, ’Sentiment Analysis’, ’Story Understanding’, ’Text
Classification’, ’NLU’, ’Text Summarization’, ’Translation’, ’Event
Understanding’, ’Multiturn Dialogue’, ’String Process’, ’Academic
Writing’]
Preliminary Cate-
gories
[’Math Reasoning’, ’Mathematical Modelling’, ’Arithmetic Calcula-
tion’, ’Python’, ’Java’, ’Programm Ability’, ’Coding Algorithm’]
Table 3: Dependency taxonomy between instruction cate-
gories.
another category of instructions Cj (effect), then it could be
assumed that the LLM fails to learn Cj if Ci not exists; (2)
If without Cj, Ci could also be well learned, then the per-
formance degradation of D\Cj
train is not due to the synergistic
effect between Ci and Cj. Thus, Cj depends on Ci. Note that,
compared to the observational-based dependency induction
methods, the causal intervention-based method could pro-
vide the strongest evidence.
One remaining issue is how to define the “significant”
performance degradation. To this end, we measure the per-
formance of LLM on a certain category of instructions us-
ing the average PPL on the evaluation set, and employ
a non-parametrical statistical test to measure the signifi-
cance. Specifically, given LLMs M and M \Ci fine-tuned
on Dtrain and D\Ci
train respectively, on the evaluation set, we
can obtain the PPL on the kth instance of the jth category
PPL(Ceval,jk) and PPL\Ci(Ceval,jk). To compare whether
M \Ci has a larger PPL than M on Cj, considering the
complexity of the distribution of PPL, we test whether
{PPL\Ci(Ceval,jk) −PPL(Ceval,jk)}|Ceval,j|
k=0
> 0 using the
non-parametrical Wilcoxon signed-rank test. Furthermore,
since given N categories there would be (N −1)2 times
of statistical tests, the risk of the False Positive would be
increased. Thus we further adjust the P-values using the
Benjamini-Hochberg procedure and only keep the depen-
dency relationships with an adjusted P-value smaller than
0.05.
Experimental Settings
Experiments are conducted on
Llama3-8B and Qwen-1.5-7B, with the same base instruc-
tion set and category collection of instructions as the instruc-
tion correlation analysis. To induce the dependency taxon-
omy of different categories of instructions, one category of
instructions is excluded from the base instruction set at each
time. Note that since the number of instructions of each type
is the same, the difference in the change of PPL after exclud-
ing different categories of instructions is not brought about
by the difference in the number of instructions.
An Empirical Ability Taxonomy of LLM
Table 3
demonstrates the dependency taxonomy between differ-
ent categories of instructions. By performing causal inter-
ventions on the distribution of the instruction set, under
strict statistical significance criteria, a significant number
of dependencies between different categories of instructions
could still be identified. For clarity, we define the roots of the
taxonomy as preliminary categories, the leaf of the taxon-
omy as subsequantial categories, and the intermediate nodes
of the taxonomy as intermediary categories. In general, the
roots of the taxonomy are math and coding-related abili-
ties, such as Python Programming and Math Modeling. Intu-
itively, these categories correspond to basic reasoning abil-
ities fundamental to completing more complicated tasks. In
contrast, categories such the Creativity and Design, Com-
monsense Understanding, and Communication and Social
Media, etc. require multiple capabilities. For example, the
creativity generation task requires both abundant knowledge
and strong textual generation ability to output creative texts.
As a result, these instruction categories serve as “leaves” of
the taxonomy tree depending on different fundamental abil-
ities. The complex dependency patterns indicate that differ-
ent categories of instructions may not contribute to model
performance independently and identically, and suggest the
necessity of training LLMs by arranging different categories
of instructions in a sequential manner, as heuristically, com-
plex skills could be acquired only if the necessary founda-
tion knowledge or ability is equipped.
3
Category Relationship Guided Instruction
Set Optimization
With the relationship patterns, we further explore optimiz-
ing the SFT process of LLM. We investigate optimizing the
category distribution of the instruction set based on the cor-
relation pattern between instructions, and concerning the de-
pendency taxonomy between different categories of instruc-
tions, we explore optimizing the instruct tuning process by
curriculum learning.
3.1
Effect Equivalence-based Category
Proportion Optimization
With the correlation patterns between different categories of
instructions, we aim to optimize the instruction set by ad-
justing the proportion of each instruction category. The ob-
jective function of the optimization could be formalized as:
Obj = s(fA(w|{γij}i,j∈[1,N], D, Dcandidate))
(2)
where w is the optimized weight of each category of in-
struction, γij is the equivalence effect coefficient measuring
the correlation strength between category i and j, D is the
original instruction set, fA(·) is the weight adjust function,
s(·) is a score function evaluating the effectiveness of the
weight adjustment. By adjusting the proportion of each cat-
egory of instructions according to w, certain categories of
instructions are removed from D, or incorporated into the
new instruction set from Dcandidate. However, it could be a
challenging task, as the score function is not clearly defined.
Generally, it should be related to the performance of LLM
finetuned using the adjusted instruction set. Whereas it is
rather hard to be modeled using a parametric function and
thus obstructs solving w.
To address this issue, we propose an Effect Equivalence-
based Category Proportion Optimization (EE-CPO) method.
We notice that, since different categories of instructions are


--- Page 6 ---
correlated, the equivalent total amount of instruction cate-
gory i is not its size |Ci| alone, but should also include the
effect caused by correlation with other categories of instruc-
tions: |Ci| + P
j γji|Cj|. Note that, γji could be smaller than
0. Hence, if we can increase the equivalent total amount for
an arbitrary category of instructions by adjusting the propor-
tion of instructions meanwhile controlling the total amount
of instructions unchanged, then the instruction could be opti-
mized. Thus, the objective of optimization could be formal-
ized as:
obj = max
X
i
|Ci| +
X
j
γji|Cj|
s.t.
X
i
|Ci| = |D| (3)
where |D| is the size of the instruction set D.
Since P
i |Ci| = |D|, by setting wj = |Cj|/|D|, i.e., the
proportion of category j, the objective function could be
converted to:
obj = max
X
i
γjiwj
s.t.
X
j
wj = 1, wj > 0
(4)
So with this objective function, we can optimize the cate-
gory proportion. However, this objective function implicitly
assumes that all instruction categories have an equal impor-
tance. In practice, certain categories would be more impor-
tant. Hence, another vital issue is how to define the category
importance αi. We notice that since the instruction set ob-
tained using previous quality score-based methods achieves
promising performance on benchmarks, its category propor-
tion could provide an empirical guide for the category im-
portance. Hence, we estimate αi using the proportion of
category i in the instruction set Dqs obtained by the qual-
ity score-based method, such as DEITA (Liu et al., 2023):
αi = |Cqs,i|/|Dqs|. Thus, concerning the category impor-
tance, as shown inFigure 1 (d), the objective function could
be further formalized as:
obj = max
X
i
αjγjiwj
s.t.
X
j
wj = 1, wj > 0
(5)
This objective function could be solved using Linear Pro-
gramming. Essentially, the increase of the equivalent total
amount could be regarded as increasing the information den-
sity of the instruction set. Different from the previous works
approaching this by selecting high-quality instructions, EE-
CPO achieves this goal by exploiting the correlations be-
tween instructions.
Experimental Settings
We constructed three instruction
sets, containing 10,000, 20,000, and 50,000 instructions re-
spectively. Given the size of the instruction set and the
weight of each category of instruction, the number of each
category of instruction could be obtained. For each category,
we select the instructions with the highest quality scores
from the whole instruction collection. The quality score is
calculated using the method of (Liu et al., 2023). To test
the generality of our approach, we employ the correlation
patterns induced from Qwen-1.5-7B to optimize the instruc-
tion set, and test whether the optimized instruction could
boost the performance of both the LLama3-8B-base model
MT-Bench
AlpacaEval2.0
Method
Qwen1.5
Llama3
Qwen1.5
Llama3
Random Selection
6.83
6.50
5.42
5.89
Instag
6.69
6.96
8.90
6.67
IFD
6.53
6.25
5.77
5.43
DEITA (10k)
7.08
7.00
8.98
7.84
DEITA (50k)
7.02
7.13
10.41
9.74
EE-CPO (10k)
7.09
7.17
9.94
8.09
EE-CPO (50k)
7.17
7.51
11.29
11.47
Table 4: Performance of Llama3-8B and Qwen 1.5-7B fine-
tuned on instruction set obtained by EE-CPO and quality
score-based methods.
Figure 3: Performance of Llama3-8B and Qwen 1.5-7B fine-
tuned on instruction set obtained by EE-CPO and DEITA
with different sample sizes.
and Qwen-1.5-7B-base model. Then widely adopted bench-
mark MT-Bench (Zheng et al., 2024) and AlpacaEval 2.0
(Dubois et al., 2024) are used to evaluate the performance of
the instruct-tuned LLMs.
Baseline Methods
We make comparisons with the quality
score based instruction selection methods: (1) Random Se-
lection selects instances from the whole instruction collec-
tion randomly; (2) Instag (Lu et al.) measures the informa-
tiveness of an instruction instance using the number of Tags
it carries; (3) IFD (Li et al., 2024) evaluates the complexity
of instruction using the response loss; (4) DEITA (Liu et al.,
2023) scores the instructions using both a complexity scor-
ing model and a quality score model, then rank the instruc-
tions using the synthesis of the quality score and complexity
score to select instructions.
Results
From Table 4 and Figure 3, we observe that:
(1) DEITA outperforms other instruction set optimiza-
tion methods which selects individual instructions with the
highest quality. Compared to the State-of-the-Art method
DEITA, our approach EE-CPO could further increase the
performance of LLMs by only optimizing the proportion
of instruction category, without incorporating additional
instances. This shows the necessity of considering the inter-
action between instructions when optimizing the instruction
set and the effectiveness of our approach. Moreover, the ad-
vantage of DEITA over random selection diminishes along
with the increase of sample size Liu et al. (2023). This is
because the number of high-quality instruction is limited.
However, our approach demonstrates a consistent advantage
over random selection and DEITA on different sample sizes,


--- Page 7 ---
especially on the instruction set with a relatively large size
of 50,000, showing that the necessity of optimizing the dis-
tribution of instruction categories could not be offset by en-
larging the scale of instruction sets.
(2) Based on the performance relationship patterns in-
duced on Qwen 1.5, we can improve the performance of both
LLama-3 and Qwen 1.5, suggesting the widespread of cor-
relation patterns and the generality of our approach.
(3) Figure 7 of the Appendix shows the weight change of
instruction categories. Categories that could not be well sub-
stituted by other categories, such as Text Summarization and
Academic Writing, together with the preliminary categories,
such as Mathematical Modeling and Python Programming,
are up-weighted. On the contrary, the instruction categories
that can be approximated by other categories of instructions
are down-weighted. This suggests the reasonability of our
category proportion optimization method.
3.2
Ability Dependency Taxonomy Guided
Curriculum Instruction Learning
The dependency between instruction categories underscores
the need to optimize the SFT process, as learning efficiency
would be hindered by the lack of preliminary skills. To ad-
dress this issue, we resort to Curriculum Learning. Rather
than simply repeating the instruction set with several epochs,
Curriculum Learning aims at arranging the samples with
different content and difficulty in a sequential manner, so
that the model can acquire enough preliminary skills before
learning the more complex instructions.
Specifically, as shown in Figure 1 (e), given the depen-
dency taxonomy, and an already existing instruction set D
to equip LLM with enough preliminary skills, we adjust the
learning sequence of the SFT process by increasing the pro-
portion of preliminary categories in the early stage of the
SFT process. Correspondingly, the proportion of subsequen-
tial categories is accordingly decreased. In contrast, at the
later stage of SFT, the weight of subsequential categories is
increased, and the weight of preliminary categories is de-
creased, so that the LLM is trained to complete the com-
plex tasks using preliminary skills. For brevity, we abbrevi-
ate our proposed approach as DT-CSFT (Dependency Tax-
onomy guided Curriculum SFT). Thus, DF-CSFT makes ad-
justments only by adjusting the learning sequential of differ-
ent categories.
Experimental Settings
We obtain D with 10,000, 20,000,
and 50,000 instances using DEITA (Liu et al., 2023). As a
baseline method, we finetune the LLM on D with 3 epochs,
in other words, the LLM is trained with a total 3|D| in-
stances, with each instance repeated 3 times. In comparison,
in the first |D| instances, DT-CSFT increases the proportion
of preliminary category instructions by 50%. Accordingly,
in the last |D| instances, the proportion of preliminary cat-
egory instructions is decreased by 50% by removing them
to the first |D| instance. We also include a baseline (called
Mix+) by uniformly mixing additional preliminary category
instructions within each epoch. For a dataset with |D| in-
stances, 2|D| more additional preliminary category instruc-
tions are randomly sampled from the whole instruction col-
Figure 4: Performance of Llama3-8B and Qwen 1.5-7B fine-
tuned on instruction set obtained by DF-CSFT and DEITA
with different sample sizes.
lection. More details are provided in the Appendix.
Results
From Figure 4 we observe that:
(1) Compared to the strong baseline DEITA, by only ad-
justing the order of learning different categories of in-
struction, DT-CSFT demonstrates improved performance in
general. This indicates the reasonability of the taxonomy in-
duced by our approach, as it could provide more necessary
fundamental information for LLM to acquire complex skills
and thus increase the efficiency of the SFT process. More-
over, based on the taxonomy induced from Qwen 1.5, the
performance of LLama-3 could also be improved. This sug-
gests the broad existence and generality of the dependency
taxonomy among different LLMs.
(2) Comparing DT-CSFT with Mix+ shows that incorpo-
rating more instructions would not necessarily bring ben-
efits to model performance. This suggests the importance
of sequentially arranging the training samples in curriculum
learning, as if the preliminary category instructions do not
appear in the early stage of SFT, then it could not help to
learn the complex skills.
(3) Our analysis provides theoretical support for the pre-
vious empirical observations that Math and Code instruc-
tions should be placed in the early stage of SFT Dong et al.
(2023); Hu et al. (2024). This is because, Math and Code
mainly serve as the necessary primary knowledge for more
complex tasks. On the contrary, if placed in the later stage
of SFT, the learning of complex knowledge would lack of
necessary background and thus limit the effectiveness and
efficiency.
4
Related Work
With the availability of various instruction sets, one crucial
issue is how to optimize the existing instruction sets. To ad-
dress this issue, most current methods focus on selecting
high-quality instructions to obtain a refined instruction set
(Latif and Zhai, 2024; Li et al., 2024; Lu et al.). While the
“quality” of instruction could be a comprehensive concept
containing multiple aspects. Pioneer works use proxy indi-
cators such as length and perplexity to evaluate the qual-
ity of instructions (Huang and Chang, 2021; Wang et al.,
2024). However, such indicators would not be enough to
comprehensively measure the instructions’ quality. Another
line of work aims at measuring the complexity of instruc-
tions, as there is no need to focus too much on learning sim-
ple instructions, while overly difficult instructions cannot be


--- Page 8 ---
learned. Hence, Zhao et al. (2023b) propose to measure the
complexity of instructions using the number of nodes within
a syntax tree, the number of ability tags for completing the
instruction Lu et al., or the difficulty of learning the instruc-
tion Li et al. (2024). Experimental results suggest improve-
ments in the efficiency of SFT with the instruction set op-
timized by these methods. Nevertheless, Liu et al. (2023)
argue that these methods only measure certain aspects of the
quality of instructions. They propose DEITA, which simul-
taneously employs a complexity score, a grammar and fac-
tual quality score to choose new instructions.
However, emerging evidence suggests interactions and
dependencies between different categories of instructions
(Chen et al., 2024; Dong et al.). These findings highlight
the necessity of optimizing the category proportion of the
instruction set and the learning sequence of the SFT pro-
cess. Whereas a main obstacle is that the interaction and de-
pendent patterns between different instruction categories are
largely unknown. To fill this gap, in this paper, we system-
ically investigate these patterns and explore optimizing the
content distribution and SFT schema with regard to them.
5
Conclusion
In this paper, we systemically investigate the correlations
and dependency taxonomy between different categories of
instructions. Analyses results show the widespread of such
interactions across multiple categories of instructions and
different LLMs, suggesting the necessity of taking the cor-
relation and dependency in the optimization of the content
distribution of the instruction set and learning schema of
the SFT process. Hence, we further managed to optimize
the category proportion and the learning sequence of the in-
struction set with regard to the correlation and dependency
patterns. The improved performance in turn supports the
existence of correlation and dependency patterns, together
with the reasonability of our investigation and instruction set
optimization method. Considering the numerous categories
of instruction data, their interaction patterns could be quite
complex. Our work might serve as a pioneer and call for fur-
ther research to conduct a more comprehensive exploration.
References
Achiam, J.; Adler, S.; Agarwal, S.; Ahmad, L.; Akkaya, I.;
Aleman, F. L.; Almeida, D.; Altenschmidt, J.; Altman, S.;
Anadkat, S.; et al. 2023. Gpt-4 technical report. arXiv
preprint arXiv:2303.08774.
Chen, M.; Roberts, N.; Bhatia, K.; Wang, J.; Zhang, C.;
Sala, F.; and R´e, C. 2024. Skill-it! a data-driven skills
framework for understanding and training language mod-
els. Advances in Neural Information Processing Systems
36.
Dong, G.; Yuan, H.; Lu, K.; Li, C.; Xue, M.; Liu, D.; Wang,
W.; Yuan, Z.; Zhou, C.; and Zhou, J. How abilities in large
language models are affected by supervised fine-tuning
data composition.
Dong, G.; Yuan, H.; Lu, K.; Li, C.; Xue, M.; Liu, D.; Wang,
W.; Yuan, Z.; Zhou, C.; and Zhou, J. 2023. How abilities
in large language models are affected by supervised fine-
tuning data composition. arXiv e-prints arXiv–2310.
Dubey, A.; Jauhri, A.; Pandey, A.; Kadian, A.; Al-Dahle, A.;
Letman, A.; Mathur, A.; Schelten, A.; Yang, A.; Fan, A.;
et al. 2024. The llama 3 herd of models. arXiv e-prints
arXiv–2407.
Dubois, Y.; Galambosi, B.; Liang, P.; and Hashimoto, T. B.
2024. Length-controlled alpacaeval: A simple way to de-
bias automatic evaluators. arXiv e-prints arXiv–2404.
Hahsler, M.; Piekenbrock, M.; and Doran, D. 2019. dbscan:
Fast density-based clustering with r. Journal of Statistical
Software 91(1).
Hu, S.; Tu, Y.; Han, X.; He, C.; Cui, G.; Long, X.; Zheng, Z.;
Fang, Y.; Huang, Y.; Zhao, W.; et al. 2024. Minicpm: Un-
veiling the potential of small language models with scal-
able training strategies. arXiv preprint arXiv:2404.06395.
Huang, K.-H., and Chang, K.-W. 2021. Generating syntacti-
cally controlled paraphrases without using annotated par-
allel pairs. In Proceedings of the 16th Conference of the
European Chapter of the Association for Computational
Linguistics: Main Volume, 1022–1033.
Huang, J., and Chang, K. C.-C. 2023. Towards reasoning in
large language models: A survey. In Findings of the Asso-
ciation for Computational Linguistics: ACL 2023, 1049–
1065.
Latif, E., and Zhai, X. 2024. Fine-tuning chatgpt for auto-
matic scoring. Computers and Education: Artificial Intel-
ligence 6:100210.
Li, M.; Zhang, Y.; Li, Z.; Chen, J.; Chen, L.; Cheng, N.;
Wang, J.; Zhou, T.; and Xiao, J.
2024.
From quan-
tity to quality: Boosting llm performance with self-guided
data selection for instruction tuning. In Proceedings of
the 2024 Conference of the North American Chapter of
the Association for Computational Linguistics: Human
Language Technologies (Volume 1: Long Papers), 7595–
7628.
Liu, W.; Zeng, W.; He, K.; Jiang, Y.; and He, J. 2023. What
makes good data for alignment? a comprehensive study
of automatic data selection in instruction tuning. In The
Twelfth International Conference on Learning Represen-
tations.
Longpre, S.; Hou, L.; Vu, T.; Webson, A.; Chung, H. W.;
Tay, Y.; Zhou, D.; Le, Q. V.; Zoph, B.; Wei, J.; et al. 2023.
The flan collection: Designing data and methods for ef-
fective instruction tuning. In International Conference on
Machine Learning, 22631–22648. PMLR.
Lu, K.; Yuan, H.; Yuan, Z.; Lin, R.; Lin, J.; Tan, C.; Zhou,
C.; and Zhou, J. # instag: Instruction tagging for analyz-
ing supervised fine-tuning of large language models. In
NeurIPS 2023 Workshop on Instruction Tuning and In-
struction Following.
Ouyang, L.; Wu, J.; Jiang, X.; Almeida, D.; Wainwright, C.;
Mishkin, P.; Zhang, C.; Agarwal, S.; Slama, K.; Ray, A.;


--- Page 9 ---
et al. 2022. Training language models to follow instruc-
tions with human feedback. Advances in neural informa-
tion processing systems 35:27730–27744.
Wang, Y.; Kordi, Y.; Mishra, S.; Liu, A.; Smith, N. A.;
Khashabi, D.; and Hajishirzi, H.
2023.
Self-instruct:
Aligning language models with self-generated instruc-
tions.
In Proceedings of the 61st Annual Meeting of
the Association for Computational Linguistics (Volume 1:
Long Papers), 13484–13508.
Wang, J.; Zhang, B.; Du, Q.; Zhang, J.; and Chu, D. 2024. A
survey on data selection for llm instruction tuning. arXiv
e-prints arXiv–2402.
Wang, X.; Chen, Y.; and Zhu, W. 2021. A survey on cur-
riculum learning. IEEE transactions on pattern analysis
and machine intelligence 44(9):4555–4576.
Xiao, S.; Liu, Z.; Zhang, P.; and Muennighof, N. 2023. C-
pack: Packaged resources to advance general chinese em-
bedding. arXiv preprint arXiv:2309.07597.
Xu, C.; Sun, Q.; Zheng, K.; Geng, X.; Zhao, P.; Feng, J.; Tao,
C.; and Jiang, D. 2023. Wizardlm: Empowering large
language models to follow complex instructions. arXiv
e-prints arXiv–2304.
Yang, A.; Yang, B.; Hui, B.; Zheng, B.; Yu, B.; Zhou, C.;
Li, C.; Li, C.; Liu, D.; Huang, F.; et al. 2024. Qwen2
technical report. arXiv e-prints arXiv–2407.
Yuan, H.; Yuan, Z.; Tan, C.; Huang, F.; and Huang, S. 2023.
Hype: Better pre-trained language model fine-tuning with
hidden representation perturbation. In The 61st Annual
Meeting Of The Association For Computational Linguis-
tics.
Zhao, W. X.; Zhou, K.; Li, J.; Tang, T.; Wang, X.; Hou, Y.;
Min, Y.; Zhang, B.; Zhang, J.; Dong, Z.; et al. 2023a. A
survey of large language models. arXiv e-prints arXiv–
2303.
Zhao, Y.; Yu, B.; Hui, B.; Yu, H.; Huang, F.; Li, Y.; and
Zhang, N. L. 2023b. A preliminary study of the intrinsic
relationship between complexity and alignment. arXiv e-
prints arXiv–2308.
Zheng, L.; Chiang, W.-L.; Sheng, Y.; Zhuang, S.; Wu, Z.;
Zhuang, Y.; Lin, Z.; Li, Z.; Li, D.; Xing, E.; et al. 2024.
Judging llm-as-a-judge with mt-bench and chatbot arena.
Advances in Neural Information Processing Systems 36.
6
Reproducibility Checklist
This paper:
• Includes a conceptual outline and/or pseudocode descrip-
tion of AI methods introduced. [Yes] , see section Intro-
duction.
• Clearly delineates statements that are opinions, hypothe-
ses, and speculations from objective facts and results.
[Yes] , see section Introduction.
• Provides well-marked pedagogical references for less-
familiar readers to gain the background necessary to repli-
cate the paper. [Yes]
Does this paper make theoretical contributions? [Yes]
Does this paper rely on one or more datasets? [Yes]
Does this paper include computational experiments?
[Yes]
• Any code required for pre-processing data is included in
the appendix. [Yes]
• All source code required for conducting and analyzing the
experiments is included in a code appendix. [Yes]
• All source code required for conducting and analyzing the
experiments will be made publicly available upon publi-
cation of the paper with a license that allows free usage
for research purposes. [Yes]
• All source code implementing new methods have com-
ments detailing the implementation, with references to the
paper where each step comes from [Yes]
• If an algorithm depends on randomness, then the method
used for setting seeds is described in a way sufficient to
allow replication of results. [Yes]
• This paper specifies the computing infrastructure used for
running experiments (hardware and software), including
GPU/CPU models; amount of memory; operating sys-
tem; names and versions of relevant software libraries and
frameworks. [Yes]
• This paper formally describes evaluation metrics used and
explains the motivation for choosing these metrics. [Yes]
• This paper states the number of algorithm runs used to
compute each reported result. [Yes]
• Analysis of experiments goes beyond single-dimensional
summaries of performance (e.g., average; median) to in-
clude measures of variation, confidence, or other distribu-
tional information. [Yes]
• The significance of any improvement or decrease in per-
formance is judged using appropriate statistical tests (e.g.,
Wilcoxon signed-rank). [Yes]
• This paper lists all final (hyper-)parameters used for each
model/algorithm in the paper’s experiments. [Yes]
• This paper states the number and range of values tried
per (hyper-) parameter during development of the paper,
along with the criterion used for selecting the final param-
eter setting. [Yes]


--- Page 10 ---
Figure 5: The effect equivalence coefficients between differ-
ent categories of instructions derived by Qwen and Llama,
respectively.
7
Appendix
7.1
Comparison between Correlation Pattern
Induced from Different LLMs
Figure 5 shows the correlation pattern derived from Qwen-
1.5-7B and Llama3-8B, respectively. Correlation patterns
derived from different LLMs demonstrate a high similar-
ity. This shows the widespread and generality of the corre-
lation patterns. Such similarity would partly be brought by
the significant overlap between the pretraining of different
LLMs, and the inherent logical and knowledge relationships
between different categories of instructions.
7.2
Comparison between Ability Dependency
Taxonomy Induced from Different LLMs
Table 5 shows the dependency taxonomy derived from
Qwen-1.5-7B and Llama3-8B, respectively. Comparison be-
tween the two taxonomies suggests a high similarity be-
tween two taxonomies, especially in the preliminary cate-
gories. This shows the widespread and generality of such
dependency taxonomy, as the dependency patterns are es-
sentially decided by the inherent relationship of knowledge
and skills for completing different categories of instructions.
7.3
Instruction Collection
In this paper, before analyzing the interaction relationships
between instruction categories, a prerequisite is collecting
enough instructions so that the main categories of instruc-
tions can be covered. provide a comprehensive list. Based on
their list, we exclude all instructions that are not constructed
by human annotation or advanced LLMs such as GPT-4 or
ChatGPT. Beyond their list, we also include Logi-QA, Wild-
Chat, and COIG-CQIA. Table 6 provided a detailed list of
the included instruction set.
Given the instruction set, we employ SimHash with a
threshold=0.95 to remove the potential duplicated instruc-
tions. After the duplication process, 9,509,526 instances in
total are left in the instruction collection.
7.4
Tag Generation
Considering the vast amount of instruction, we construct an
automatic tagging system that employs an LLM to generate
tags for a given instruction.
Specifically, given an instance from the instruction col-
lection which is composed by (several) {Instruct-Response}
pair(s), we concatenate them into a string, and as Figure 6
shows, using the following prompt, to demand the LLM
to generate tags describing the necessary knowledge and
skills for completing the dialogue described by the {Instruct-
Response} pair(s):
We employ Qwen-1.5-72B-instruct as the tagger.
7.5
Tag Normalization
The LLM would describe one kind of knowledge or skill
with different expressions, for example, “math calculation”
with “mathematical calculation”. To address this issue, we
propose to combine these tags according to their semantic
similarity. Specifically, we obtain the embedding of the tags
using BGE (Xiao et al., 2023). Then semantically similar
tags are recognized if their cosine similarity of embeddings
is larger than an empirical threshold λ = 0.85. For a set of se-
mantically similar tags, they are normalized to the one with
the highest frequency among them. After the normalization
process, tags With a frequency lower than 100 are consid-
ered as long-tail and are filtered out Lu et al.. After the nor-
malization and filtering, a total of 21,378 tags are left. We
manually selected 29 categories across 7 domains for analy-
sis.
7.6
Experimental Settings
Before analysis, we excluded the instructions that were se-
mantically similar to the test instances in the benchmarks Al-
pacaEval and MTBench using semantic similarity. Instruc-
tions with a cosine similarity larger than 0.3 are excluded
from further analysis. Without generality, we only select in-
structions in English for analysis.
In the causal intervention-based instruction correlation
analysis, the base instruction set D are constructed by ran-
domly sampling 1,000 instances of each category from the
whole instruction collection. The same base instruction set
is also adopted in the ability taxonomy induction, to control
potential confounders.
To induce the correlation pattern of each category of in-
struction with the others, at each time, 2,000 instructions of
one category are added into the base instruction set to obtain
D ∪Ci. Then we use D ∪Ci to fine-tune an LLM M and ob-
tain M ∪Ci. During the fine-tuning process, M is fine-tuned
for 3 epochs, with a batch size of 32, the initial learning rate
of 9.65e-6, optimized with the Adam optimizer, β1 = 0.9,
β2 = 0.95 Ouyang et al. (2022). This group of hyperparame-
ters is also adopted in all other sections when the fine-tuning
process is involved.
For the baseline quality score-based instruction selection
method IFD and Instag, we implemented their using their
codes on our instruction collection. As we included more
instructions in the collection set, our implementations out-
performed the original implementations on the MT-Bench
and AlpacaEval2.0.
In the ability dependency taxonomy guided curriculum in-
struction learning, assume the base instruction set D con-
tains Npre, Ninter, and Nsub preliminary, intermediate, and
subsequential category instructions. Note that D = Npre +


--- Page 11 ---
Qwen
Llama
Subsequantial
cate-
gories
[’Humanities & Social Sciences QA’, ’Commonsense Understanding’,
’Open Domain QA’, ’Communication & Social Media’, ’Character Un-
derstanding and Role-Playing’, ’Creative Writing’]
[’Humanities & Social Sciences QA’, ’Communication & Social Me-
dia’, ’Character Understanding and Role-Playing’, ’Creative Writing’]
Intermediary
Cate-
gories
[’Data Process and Analysis’, ’STEM Knowledge QA’, ’Commonsense
Reasoning’, ’Concept Understanding’, ’Logical Reasoning’, ’Informa-
tion Extraction’, ’Sentiment Analysis’, ’Story Understanding’, ’Text
Classification’, ’NLU’, ’Text Summarization’, ’Translation’, ’Event
Understanding’, ’Multiturn Dialogue’, ’String Process’, ’Academic
Writing’]
[’Data Process and Analysis’, ’STEM Knowledge QA’, ’Commonsense
Reasoning’, ’Concept Understanding’, ’Information Extraction’, ’Sen-
timent Analysis’, ’Story Understanding’, ’Text Classification’, ’NLU’,
’Text Summarization’, ’Translation’, ’Event Understanding’, ’Multiturn
Dialogue’, ’String Process’, ’Academic Writing’, ’Commonsense Un-
derstanding’, ’Open Domain QA’, ’Mathematical Modelling’]
Preliminary Categories
[’Math Reasoning’, ’Mathematical Modelling’, ’Arithmetic Calcula-
tion’, ’Python’, ’Java’, ’Programm Ability’, ’Coding Algorithm’]
[’Math Reasoning’, ’Arithmetic Calculation’, ’Python’, ’Java’, ’Pro-
gramm Ability’, ’Coding Algorithm’]
Table 5: Dependency taxonomy between instruction categories derived from two LLMs.
Figure 6: Prompt used for guiding the LLM to generate tags for given instruction.
Alpaca GPT4
LIMA
Alpaca GPT4 ZH
LongForm
BaiZe
logi-COT
BELLE Generated Chat
ShareGPT-Chinese-English-90k
BELLE Multiturn Chat
UltraChat
BELLE train 3.5M CN
Wizard Evol instruct zh
databricks-dolly-15K
Wizard Evol instruct 196K
BELLE School Math
Code Alpaca 20K
MetaMath
WildChat
COIG-CQIA
Table 6: List of instructions included for analysis.
Ninter + Nsub. Then the curriculum data is arranged as fol-
lows:
• First D instances=
random shuffle(1.5Npre[preliminary category instructions]+
Ninter[intermediary category instructions]+
(Nsub −0.5Npre)[subsequential category instructions])
• Second D instances=
random shuffle(Npre[preliminary category instructions]+
Ninter[intermediary category instructions]+
(Nsub −0.5Npre)[subsequential category instructions])
• Third D instances=
random shuffle(0.5Npre[preliminary category instructions]+
Ninter[intermediary category instructions]+
(Nsub −1.5Npre)[subsequential category instructions])
In this way, we arranged the instructions to increase the
proportion of preliminary category instructions in the early
stage of SFT and increase the proportion of subsequential
category instructions in the later stage of SFT, meanwhile


--- Page 12 ---
Figure 7: Change in weights of categories after optimization.
keeping the total number and constitution of the curricu-
lum data identical to the original base instruction set D un-
changed.
7.7
Changes in weights of Categories after
Optimization
As Figure 7 shows, in general, the weights of categories that
can be well substituted such as NLU, Concept Understand-
ing, or Commonsense Reasoning are decreased. On the con-
trary, the weights of Text Summarization, Academic Writ-
ing which could not be well substituted by another cate-
gory of instructions, and the preliminary categories, such
as Mathematical Modeling and mathematical Reasoning, are
increased.
