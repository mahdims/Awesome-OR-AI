--- Page 1 ---
Heuristic Search as Language-Guided Program Optimization
Mingxin Yu 1 Ruixiao Yang 1 Chuchu Fan 1
Abstract
Large Language Models (LLMs) have advanced
Automated Heuristic Design (AHD) in combinato-
rial optimization (CO) in the past few years. How-
ever, existing discovery pipelines often require
extensive manual trial-and-error or reliance on do-
main expertise to adapt to new or complex prob-
lems. This stems from tightly coupled internal
mechanisms that limit systematic improvement of
the LLM-driven design process. To address this
challenge, we propose a structured framework for
LLM-driven AHD that explicitly decomposes the
heuristic discovery process into modular stages:
a forward pass for evaluation, a backward pass
for analytical feedback, and an update step for
program refinement. This separation provides a
clear abstraction for iterative refinement and en-
ables principled improvements of individual com-
ponents. We validate our framework across four
diverse real-world CO domains, where it consis-
tently outperforms baselines, achieving up to 0.17
improvement in QYI on unseen test sets. Finally,
we show that several popular AHD methods are
restricted instantiations of our framework. By in-
tegrating them in our structured pipeline, we can
upgrade the components modularly and signifi-
cantly improve their performance.
1. Introduction
Heuristics play a critical role in solving complex search
and optimization problems, where exact algorithms are of-
ten computationally challenging (Lin & Kernighan, 1973;
Lourenc¬∏o et al., 2003; HromkoviÀác, 2013).
Automated
Heuristic Design (AHD) aims to reduce the substantial
manual effort and domain expertise required to design
such heuristics by automatically discovering effective strate-
gies (Burke et al., 2013). However, traditional AHD meth-
ods often rely on hand-crafted algorithmic primitives, which
restrict their search space and limit their ability to generalize
1Massachusetts Institute of Technology, Cambridge, MA, USA.
Correspondence to: Mingxin Yu <yumx35@mit.edu>.
Preprint. February 19, 2026.
to novel problem settings (O‚ÄôNeill et al., 2010; St¬®utzle &
L¬¥opez-Ib¬¥aÀúnez, 2018; Drake et al., 2020).
Recent advancements in Large Language Models (LLMs)
have significantly expanded the scope of AHD by enabling
the direct generation of executable code from natural lan-
guage descriptions or partial program specifications (Austin
et al., 2021; Chen, 2021). Unlike traditional methods that
operate within a fixed, predefined search space, LLM-based
approaches explore a far more open-ended space of heuris-
tic programs (Chen et al., 2023a; Meyerson et al., 2024).
A growing body of work demonstrates that LLMs can dis-
cover competitive heuristics for challenging CO problems
by iteratively proposing, evaluating, and refining heuristic
programs (Romera-Paredes et al., 2024; Liu et al., 2024).
Recent studies have proposed various enhancements for
LLM-based AHD, including refined prompt engineering or
specialized feedback mechanisms (Ye et al., 2024; 2025; Cui
et al., 2025). Despite empirical successes, the development
of these systems remains driven by manual trial-and-error or
expert insights. This is largely because these advancements
are typically introduced within tightly coupled heuristic dis-
covery pipelines, where evaluation, feedback, and update
logic are implemented as a single, intertwined loop. Such
coupling makes it difficult to isolate the contribution of
individual components or systematically improve the LLM-
driven heuristic design process and to transfer effective de-
sign strategies across new or complex problem domains.
In this work, we address these challenges by reformulating
AHD as an explicit optimization problem over a discrete pro-
gram space. We propose Language-Guided Optimization
(LaGO), a framework decomposing the heuristic discovery
process into three distinct, modular stages: (1) a forward
pass evaluating candidate heuristic and records execution-
level behavior; (2) a backward pass analyzing behaviors to
derive structured feedback; and (3) an update stage refining
the heuristic code based on the feedback. This decomposi-
tion transforms the search from a stochastic mutation pro-
cess into a directed optimization. By disentangling these
components, LaGO enables principled, ‚Äùplug-and-play‚Äù up-
grades to individual stages of the search process.
Our contributions are summarized as follows:
‚Ä¢ We introduce LaGO, a unified framework that formal-
1
arXiv:2602.16038v1  [cs.NE]  17 Feb 2026


--- Page 2 ---
Heuristic Search as Language-Guided Program Optimization
izes LLM-based AHD as a language-guided optimiza-
tion problem. By decomposing the pipeline into for-
ward, backward, and update modules, LaGO enables
systematic analysis of the heuristic search process and
principled modification of its components.
‚Ä¢ LaGO provides a general mechanism for improving
existing AHD methods by re-implementing prior ap-
proaches as LaGO instantiations and upgrading indi-
vidual modules. Specifically, we introduce executable
feedback in the backward pass, a joint optimization
strategy to improve constructive and refinement heuris-
tics, and a diversity-aware population management
strategy for the update stage.
‚Ä¢ We validate LaGO across four real-world CO case stud-
ies with challenging feasibility constraints. Across all
domains, LaGO consistently outperforms existing base-
lines, while detailed analysis shows that the proposed
modular upgrades improve search efficiency and help
avoid common failure modes like mode collapse.
2. Related Works
2.1. Automated Heuristic Design (Pre-LLM)
The automation of algorithm design, historically referred to
as hyper-heuristic (Burke et al., 2013), aims to reduce the
manual effort required to solve combinatorial optimization
problems. Early methods (Hutter et al., 2009; Blot et al.,
2016; L¬¥opez-Ib¬¥aÀúnez et al., 2016; Akiba et al., 2019) focus
primarily on selecting, combining, and tuning predefined
algorithmic components in an automated manner. Beyond
simple selection, evolutionary approaches such as genetic
programming (Mei et al., 2022; Xu et al., 2023) have also
been used to automatically synthesize heuristics and algo-
rithmic components. These methods can yield interpretable,
domain-specific heuristics and have shown practical success
in real-world applications (Zhu et al., 2023; Zhang et al.,
2023b). However, these approaches still require substantial
human effort to design the search space. This requirement
for domain expertise limits flexibility and can constrain
further performance improvements.
2.2. LLM-Based Heuristic and Algorithm Discovery
The emergence of Large Language Models (LLMs) has in-
troduced a new paradigm in algorithm discovery by enabling
the direct synthesis of executable algorithms (Yang et al.,
2023; Lange et al., 2024). Early approaches primarily use
LLMs as black-box solvers, using in-context learning to
generate solutions for individual problem instances. While
effective for small or structured instances, this solver-style
paradigm often suffers from limited generalization, particu-
larly when scaling to complex problems or larger instance
sizes. More recent work has shifted toward iterative heuris-
tic evolution, where LLMs are used to generate and refine
algorithmic components through repeated evaluation and
selection (Romera-Paredes et al., 2024; Liu et al., 2024)
or Monte-Carlo tree search (Zheng et al., 2025). These
approaches introduce an explicit evaluation loop that en-
ables the discovery of reusable heuristics, and have been
successfully adapted to domain-specific settings such as
large neighborhood search (Ye et al., 2025).
Despite their empirical success (Dat et al., 2025; Zheng
et al., 2025; Zhong et al., 2025), most existing methods
operate as forms of randomized evolutionary search: LLMs
are typically employed as stochastic mutation or crossover
operators guided by scalar fitness values, with limited in-
sight into why a heuristic succeeds or fails. As a result,
the optimization process in these methods remains largely
implicit. Evaluation and update mechanisms are tightly
coupled, and feedback is restricted to coarse performance
signals, making it difficult to systematically analyze, com-
pare, or extend the underlying search dynamics. ReEvo (Ye
et al., 2024) and CALM (Huang et al., 2025) partially ad-
dresses this limitation by introducing textual reflection into
the evolutionary process, but the overall evolution process
remains entangled. In contrast, our work focuses on making
the optimization structure of LLM-based heuristic discovery
explicit. By formulating heuristic design as an optimization
problem over a discrete program space and decomposing the
process into stages, we enable systematic analysis and prin-
cipled improvement of heuristic discovery methods, moving
beyond ad-hoc evolutionary search.
3. Method
We propose LaGO, a modular framework that formalizes
Automated Heuristic Design (AHD) as a structured opti-
mization process. The entire framework is illustrated in Fig-
ure 1. In the following sections, we will detail our problem
formulation and the specific module architectures that in-
stantiate this language-guided optimization pipeline.
3.1. Problem Formulation: Heuristic Search as
Program Optimization
We formally define the Heuristic Design Problem as an
optimization task over a space of executable programs
Œò. Consider a distribution of Combinatorial Optimization
(CO) problem instances Dtarget. Each problem instance
is defined as a tuple Œ¶ = (X, g, C, T ), where X denotes
the decision variable space of the combinatorial problem,
g : X 7‚ÜíR+‚à™{0} is the objective function to be minimized,
C is the set of hard constraints, which a valid solution x ‚ààX
must satisfy, and T is a natural language description of the
problem logic and constraints, which provides the semantic
context required for Large Language Models (LLMs).
2


--- Page 3 ---
Heuristic Search as Language-Guided Program Optimization
Update Step (Generator)
Forward Pass (Evaluation)
Backward Pass (Analyst)
Heuristic Population
LLM Analyzer
Extracts Patterns from traces ‚Ñ∞
Execution
Inject ùúÉinto Code Skeleton
Feedback
semantic gradient ‚àÜ
LLM Optimizer 
Generates new heuristics from 
inputs and feedbacks
Problem
Instances
Problem 
Description
Template 
Code
¬∑¬∑¬∑
Sample
Operators (mutation/crossover/‚Ä¶)
Candidate 
Heuristic ùúΩ
Feedback
Execution Traces ‚Ñ∞
Code
LLM
File
Tester
Solver
Figure 1. The LaGO framework for language-guided optimization. Our framework decomposes the automated heuristic design process
into three modular stages: a forward pass (red), a backward pass (green), and an update step (blue). This modular structure supports
systematic refinement of heuristic logic while preserving compatibility across different problem domains.
Following recent works (Romera-Paredes et al., 2024; Liu
et al., 2024) in algorithm discovery, we search for a heuristic
policy hŒ∏, parameterized by executable code Œ∏ ‚ààŒò, that
constructs or improves a solution x = hŒ∏(Œ¶). The quality
of a heuristic is measured by a fitness metric
f(Œ¶, x) = min
n
1, g(x‚àó)
g(x)
o
‚àà[0, 1],
(1)
where x‚àóis the best-known solution, or an optimal solution
if available. Our objective is to find the optimal program
parameters Œ∏‚àóthat maximize the expected fitness over the
target distribution:
Œ∏‚àó= arg max
Œ∏‚ààŒò EŒ¶‚àºDtarget [f(Œ¶, hŒ∏(Œ¶))]
(2)
In practice, Dtarget is unknown. We are provided with a
limited training set Dtrain = {Œ¶1, . . . , Œ¶K}. The goal is
to learn a heuristic ÀÜŒ∏‚àóon Dtrain that generalizes to a larger,
potentially out-of-distribution test set Dtest.
3.2. The LaGO Framework: Language-Guided
Optimization
In order to solve the problem in Equation (2), we propose a
general framework, LaGO. As illustrated in Figure 1, our
framework reformulates the heuristic evolution process by
drawing a direct parallel to gradient-based learning (LeCun
et al., 2015). The system decomposes the optimization
process into three stages: a Forward Pass (evaluation), a
Backward Pass (analyst), and an Update Step (generator).
Following (Liu et al., 2024; Dat et al., 2025; Ye et al., 2024),
we maintain a population of candidate heuristics across op-
timization iterations. Formally, we define the optimization
step at iteration t as an update to a population of program
parameters Pt = {Œ∏(i)
t }N
i=1 to next population Pt+1. The
framework is composed of the following components:
Forward Pass (Evaluation).
The forward pass takes a
heuristic Œ∏ as input, injects it into the provided algorithm
skeleton, and evaluates it on the training set Dtrain. The
process yields an execution trace EŒ∏ containing runtime er-
rors, generated solutions, and potentially other intermediate
messages. These traces then provide the raw empirical data
for the feedback signal in the backward pass.
Backward Pass (Analyst).
To guide the population up-
date, we require a feedback signal analogous to the gradient
‚àáŒ∏J. Standard evolutionary methods constrict this signal
to a scalar fitness value or plain text, causing significant in-
formation loss. We introduce the Analyst module A, which
maps execution traces to a semantic gradient ‚àÜ:
‚àÜ(i)
t
‚ÜêA(E(i)
t , T ).
(3)
Crucially, LaGO imposes no constraints on the format of ‚àÜ.
It serves as a flexible container for the information critical
to improvement. Depending on the domain, ‚àÜmay be:
‚Ä¢ Structured Tensors: High-dimensional vectors con-
catenating fitness with other statistics.
‚Ä¢ Unstructured Semantics: Natural language critiques,
debug logs, or code derived from the execution trace.
This design decouples the feedback mechanism from the
scalar optimization objective, allowing the Analyst to pass
structural and qualitative insights back to the optimizer.
Update Step (Generator).
The Generator module G func-
tions as a semantic evolutionary operator. It aggregates
the current population Pt and the set of feedback signals
{‚àÜ(i)
t }N
i=1 to synthesize the next generation:
Pt+1 ‚ÜêG(Pt, {‚àÜ(i)
t }N
i=1).
(4)
3


--- Page 4 ---
Heuristic Search as Language-Guided Program Optimization
Unlike standard genetic algorithms that rely on blind mu-
tation or random crossover, G utilizes an LLM to perform
reasoned evolution. By analyzing the feedback ‚àÜacross
the population, the generator constructs new candidates that
conceptually represent a directed jump in the search space.
This process replaces stochastic genetic operators with a
learned, context-aware optimization step that maximizes the
population‚Äôs expected improvement.
3.3. Framework Instantiation
The Forward, Backward, and Update modules form an it-
erative cycle that evolves the population Pt. The detailed
procedure for transitioning from Pt to Pt+1 is as follows:
Initialization.
The process begins with empty feedback
and a seed population P0 generated via zero-shot prompting
on the problem description T , creating an initial baseline
for the optimization process.
Step 1: Selection (Generator).
One or more subset(s) of
parent heuristics Pparents ‚äÇPt are sampled by a selection
customized operator;
Step 2: Directed Generation (Generator).
For each
parent set Pparents, the Generator G is prompted with
the parent‚Äôs code and their semantic gradient ‚àÜparents =
{‚àÜ(i)
t‚àí1|Œ∏(i) ‚ààPparents} to generate a new candidate Œ∏‚Ä≤,
Œ∏‚Ä≤ ‚àºLLMG(Pparents, ‚àÜparents, T ),
(5)
formulating a batch of new candidates Pnew = {Œ∏‚Ä≤
1, . . . }.
Step 3: Candidate Evaluation (Forward Pass).
Each
new candidate Œ∏‚Ä≤ ‚ààPnew is then injected into the algo-
rithm skeleton and evaluated on the training set to get the
execution traces EŒ∏‚Ä≤;
Step 4: Semantic Gradient Estimation (Backward Pass):
The analyst A then analyzes the execution traces EŒ∏‚Ä≤ and
generate feedback {‚àÜ‚Ä≤
t} for each heuristic Œ∏‚Ä≤ ‚ààPnew;
Step 5: Population Survival (Generator).
The popula-
tion is updated by selecting N survivors from the union of
the current population and the new candidates, Pt ‚à™Pnew.
This selection is driven by a survival function S that evalu-
ates the comprehensive feedback of all candidates:
Pt+1 = S
 (Œ∏, ‚àÜŒ∏
t ) | Œ∏ ‚ààPt ‚à™Pnew

.
(6)
This formulation allows the survival mechanism to consider
not just scalar fitness, but also trade-offs in runtime or struc-
tural diversity encoded in ‚àÜ.
The framework iterates steps 1-5 until a maximum budget
of evaluations is reached.
3.4. Detailed Module Design
We now highlight the key module-level design choices that
distinguish our method from prior LLM-based heuristic
search methods.
Forward Pass: Co-evolution of Heuristic Components
In our framework, we enable the joint optimization of mul-
tiple algorithmic components. Specifically, we target the
Large Neighborhood Search (LNS) paradigm and genetic
algorithm (GA) and co-evolve:
1. Constructive Heuristic (Œ∏cons): Responsible for gen-
erating high-quality initial solutions, where the later
local search is more promising and landscape more
smooth. Unlike traditional step-by-step construction,
we only request the heuristic to output a solution, and
allow this solution to later perform limited search. The
constructive heuristic here is aimed to enable the solver
begin in a promising region of the landscape.
2. Refinement Heuristic (Œ∏ref): Responsible for select-
ing neighborhoods (sub-problems) in LNS or select-
ing parent heuristic(s) in GA to re-optimize or mu-
tate/crossover. This heuristic must identify local bottle-
necks in the solution structure.
Co-evolving these components allows the system to dis-
cover synergistic strategies (e.g., a constructive heuristic
that leaves specific ‚Äùgaps‚Äù which the refinement heuristic
is particularly good at filling) that are inaccessible when
evolving components in isolation.
Code-writing analyst in backward pass.
The back-
ward pass provides critical guidance for heuristic synthesis.
While a scalar fitness signal f(Œ∏(i)
t ) provides a global perfor-
mance measure, its sparsity fails to characterize the specific
structural failure of a heuristic. Conversely, purely textual
reflection often lacks the precision required to guide code
synthesis for complex combinatorial landscapes. To bridge
this gap, we propose to use an executable ‚ÄôAnalyst‚Äô module,
which interprets the backward pass as a feature discovery
task. Leveraging its own analytical history, the Analyst syn-
thesizes a new set of feature functions Œ® : (Œ¶, x) 7‚ÜíR at
each call, which are designed to capture structural proper-
ties of the problem instances and corresponding solutions.
These functions are optimized to distinguish high-quality
solutions from poor ones based on specific attributes with-
out computing the cost. Once the Analyst generates a set
of features {Œ®j}M
j=1, the functions are executed across the
training set Dtrain to produce a feature distribution for each
heuristic Œ∏(i)
t . The resulting structured feedback ‚àÜ(i)
t
is
defined as a tuple of distributional statistics:
‚àÜ(i)
t
=

f(Œ∏(i)
t ), range(Œ®), ¬µŒ®, Œ®best, Œ®worst

(7)
4


--- Page 5 ---
Heuristic Search as Language-Guided Program Optimization
Table 1. Comparison of representative methods with LaGO.
Existing approaches can be interpreted as restricted instantiations
of our proposed forward‚Äìbackward‚Äìupdate decomposition.
Method
Forward
Backward
Update
EoH
single
scalar
random
LLM-LNS
single
scalar
random
ReEvo
single
scalar + text
elitist
Ours
joint
code-based
diversity
where ¬µŒ® is the mean feature value across all (instance,
solution) pairs, and Œ®best/Œ®worst represent the feature sig-
natures of the highest and lowest-performing solutions, re-
spectively. When provided with these distributions, the
Generator aims to generate heuristics that improve the fea-
tures of poorly performing instances to the good ones, rather
than performing a blind search.
Sampling and population survival in generator.
To mit-
igate mode collapse, where the population converges prema-
turely to a single local minimum, the generator G employs a
diversity-aware strategy for both parent selection and popu-
lation survival. This design builds on prior observations that
behavioral diversity is critical for effective heuristic evolu-
tion (Dat et al., 2025). For each heuristic Œ∏, we maintain a
fitness vector vŒ∏ = [f(Œ¶1, hŒ∏(Œ¶1), ¬∑ ¬∑ ¬∑ , f(Œ¶K, hŒ∏(Œ¶K))]
representing its performance across the training instances.
Rather than selecting parents based solely on average fitness,
we compute the pairwise Euclidean distance between these
vectors and prioritize pairs that are both high-performing
and behaviorally diverse. This encourages the LLM to per-
form ‚Äùsemantic crossover‚Äù by merging distinct algorithmic
strategies that succeed on different types of problem in-
stances. When updating population Pt with newly generated
candidates {Œ∏‚Ä≤}, we first preserve a subset of top-performing
individuals to ensure the search remaining high quality. The
remaining slots in Pt+1 are filled by randomly selecting
candidates from Pt ‚à™{Œ∏‚Ä≤} by a weighted criterion that bal-
ances fitness and marginal diversity. This ensures the new
population maintain strong heuristics while continuing to
explore a broad range of heuristic behaviors.
Relation to existing methods
Existing LLM-based
heuristic design methods can be interpreted as specific in-
stantiations of our proposed modular framework, as sum-
marized in Table 1. In EoH (Liu et al., 2024), the forward
pass optimizes a single heuristic component, while the back-
ward pass doesn‚Äôt provide any explicit feedback (not even
fitness value). The heuristic updates are driven by muta-
tion/crossover over randomly selected parents under fixed
prompts. LLM-LNS (Ye et al., 2025) augments this pipeline
with scalar fitness value as feedback. ReEvo (Ye et al.,
2024) further introduces textual reflection to the backward
pass and updates the heuristic based on crossover over the
best-performing heuristics and randomly-selected parents.
By explicitly decoupling evaluation, feedback, and update
mechanisms, our formulation exposes these design choices
and enables systematic extensions of joint optimization of
multiple heuristic components and richer feedback gener-
ation. While prompt evolution, as in LLM-LNS (Ye et al.,
2025), is fully compatible with the generator module of our
framework, we do not include it as a modular upgrade in this
work to isolate the effects of feedback structure, heuristic
component co-optimization, and population dynamics.
4. Experiment
4.1. Experimental Settings
Benchmarks and datasets.
We evaluate our framework
on four diverse real-world combinatorial optimization prob-
lems selected from the HeuriGym benchmark (Chen et al.,
2025). These tasks were chosen for their semantic diversity
and complex, irregular constraints, ensuring that the evalua-
tion measures the framework‚Äôs reasoning capability rather
than its retrieval of standard textbook algorithms (e.g., TSP
heuristics). The problem set includes: pickup and deliv-
ery with time windows (PDPTW) and airline crew pairing
from the logistics domain; technology mapping problem
from electronic design automation; intra-operator paral-
lelism scheduling (intra-op) from compiler applications.
For each problem, we utilize the dataset of approximately 30
instances. To rigorously assess generalization, we uniformly
sample 50% of instances from each data source to form the
training set Dtrain, and use the remaining instances as the
test set Dtest. This small-data regime poses a significant
challenge, requiring the framework to learn generalizable
heuristic logic from limited feedback.
Baselines
We compare our framework against representa-
tive LLM-based heuristic design methods, including Heuri-
Gen (Chen et al., 2025), EoH (Liu et al., 2024), ReEvo (Ye
et al., 2024), and LLM-LNS (Ye et al., 2025). For a com-
prehensive evaluation, we employ three distinct comparison
protocols that reflect common practices in prior work:
‚Ä¢ Improvement-Only (Primary Protocol): Most ex-
isting approaches focus on optimizing the refinement
heuristic while keeping the constructive heuristic fixed
or randomly initialized. We adopt this as our primary
comparison setting for consistency with the original
evaluation procedures of EoH, ReEvo, and LLM-LNS.
‚Ä¢ Constructive-Only (Initialization Protocol): To ex-
amine the impact of initialization, we evaluate vari-
ants in which the baselines evolve only the construc-
tive heuristic and use a random improvement operator.
These variants are denoted with the suffix -I.
5


--- Page 6 ---
Heuristic Search as Language-Guided Program Optimization
Table 2. Comparison of our framework with LLM-based heuristic design methods. Results are reported in terms of QYI (higher
is better). Baseline methods include end-to-end generation, improvement-only optimization, and construction-focused settings. Our
framework consistently achieves the best performance across domains, demonstrating the advantage of our proposed framework.
Method
PDPTW
Crew Pairing
Techno Mapping
Intra-op
Train
Test
Train
Test
Train
Test
Train
Test
Heurigen
0.000¬±0.000
0.000¬±0.000
0.605¬±0.429
0.603¬±0.428
0.206¬±0.356
0.210¬±0.364
0.284¬±0.060
0.477¬±0.071
EoH
0.560¬±0.035
0.314¬±0.057
0.881¬±0.018
0.853¬±0.000
0.677¬±0.086
0.686¬±0.009
0.513¬±0.001
0.522¬±0.044
ReEvo
0.561¬±0.037
0.303¬±0.153
0.868¬±0.000
0.853¬±0.000
0.635¬±0.037
0.696¬±0.025
0.513¬±0.001
0.548¬±0.000
LLM-LNS
0.595¬±0.051
0.354¬±0.129
0.866¬±0.000
0.853¬±0.000
0.687¬±0.042
0.699¬±0.025
0.514¬±0.002
0.532¬±0.023
EoH-I
0.838¬±0.005
0.521¬±0.042
0.947¬±0.004
0.888¬±0.035
0.629¬±0.002
0.678¬±0.001
0.610¬±0.031
0.450¬±0.076
ReEvo-I
0.859¬±0.042
0.636¬±0.065
0.912¬±0.038
0.882¬±0.032
0.631¬±0.001
0.681¬±0.003
0.597¬±0.110
0.542¬±0.054
LLM-LNS-I
0.836¬±0.002
0.487¬±0.032
0.936¬±0.035
0.916¬±0.026
0.629¬±0.002
0.682¬±0.002
0.560¬±0.031
0.515¬±0.081
Ours
0.882¬±0.031
0.808¬±0.002
0.953¬±0.003
0.918¬±0.006
0.732¬±0.061
0.713¬±0.013
0.783¬±0.045
0.636¬±0.060
‚Ä¢ End-to-End Generation: For HeuriGen, we follow
its original protocol, where the LLM directly produces
the complete executable code without a predefined
algorithm skeleton.
These protocols allow us to isolate the performance contri-
butions of different algorithmic components, contrasting the
component-wise optimization of baselines against the joint
optimization capability of our proposed framework.
Metrics.
Following (Chen et al., 2025), we adopt the
Quality-Yield Index (QYI) as the primary metric for eval-
uating performance. QYI provides a unified measure of
a heuristic‚Äôs robustness (feasibility) and optimality. It is
defined as the harmonic mean of Quality and Yield:
QYI = 2 ¬∑ Quality ¬∑ Yield
Quality + Yield
(8)
where the components are calculated as:
Quality = 1
ÀÜK
ÀÜ
K
X
k=1
min

1, c‚àó
k
ck

,
Yield =
ÀÜK
K
(9)
Here, K is the total number of instances, ÀÜK is the number of
instances for which a feasible solution was found, and ck and
c‚àó
k represent the costs of the LLM-generated solution and
the expert or optimal solution for instance k, respectively.
While QYI is used for final evaluation, directly optimizing
hard constraints can lead to sparse rewards (sparse feed-
back). To facilitate smoother gradient estimation during
training, we relax hard constraints into soft penalties. For
internal fitness computation, we treat all generated solutions
as ‚Äùvalid‚Äù (i.e., setting effective Yield ‚â°1) but add a
large penalty term M to the cost ck for every constraint
violation. This allows the framework to distinguish between
‚Äùpromising but invalid‚Äù heuristics and ‚Äùcompletely broken‚Äù
ones, providing a stronger signal to the Analyst module.
4.2. Results
We first report the performance of our full framework and all
baselines across four combinatorial optimization domains
in Table 2 using Gemini-3-Flash (Team et al., 2025)
with temperature T = 1 and medium reasoning effort. The
performance is reported by averaging 3 runs. Here, we
highlight four key empirical findings.
End-to-End Generation is Ineffective for Constrained
Heuristics.
The HeuriGen baseline (Chen et al., 2025),
which relies on end-to-end code generation, performs poorly
across all domains and solves only a limited number of them.
We also observed that the generated heuristics frequently
violate problem constraints. This result indicates that direct
program synthesis is insufficient for real-world combinato-
rial optimization with complex feasibility requirements.
Joint Optimization Outperforms Partial Optimization.
Under the standard protocol where baselines optimize
only improvement heuristics, our framework consistently
achieves the strongest performance across all domains. On
the highly constrained PDPTW and intra-operative schedul-
ing tasks, our method achieves QYI scores of 0.882 and
0.783 on the training set, outperforming the strongest base-
line by +0.29 and +0.27, respectively. When baselines are
instead configured to generate initial solutions, our method
still maintains a performance advantage, achieving an av-
erage QYI gap of 0.09 compared to the best baseline. Al-
though the relative gap is smaller than in the improvement-
focused regime, the consistent advantage across both pro-
tocols indicates that optimizing only initialization or im-
provement in isolation is insufficient. Overall, these re-
sults demonstrate that jointly optimizing the full algorithmic
pipeline yields substantially higher solution quality. The ex-
panded scope provides greater expressivity, allowing LaGO
to adapt to the training distribution while simultaneously
exploring a broader, synergistic search space that partial
optimization methods cannot access.
6


--- Page 7 ---
Heuristic Search as Language-Guided Program Optimization
EoH
ReEvo
LLM-LNS
0.2
0.4
0.6
0.8
1.0
Training QYI
Variant A (Heuristics)
EoH
ReEvo
LLM-LNS
Variant B (Analyst)
EoH
ReEvo
LLM-LNS
Variant C (Population Manager)
EoH
ReEvo
LLM-LNS
Variant D (Code Skeleton)
EoH
ReEvo
LLM-LNS
0.2
0.4
0.6
0.8
1.0
Test QYI
EoH
ReEvo
LLM-LNS
EoH
ReEvo
LLM-LNS
EoH
ReEvo
LLM-LNS
EoH
ReEvo
LLM-LNS
Base
Figure 2. Component analysis of framework modules on PDPTW To isolate the performance gains contributed by specific components
of our framework, we independently upgrade the baseline models with each proposed module, while keeping other modules the same as
the original. Variant A introduces the co-evolution of constructive and refinement heuristics; variant B uses a code-writing analyst module;
variant C applies a diversity-aware population management strategy; variant D adds the algorithm skeleton code to the generator prompt.
Generalization Capability.
Finally, we analyze the per-
formance drop between training (seen instances) and testing
(all instances). Baselines such as EoH suffer from an aver-
age QYI drop of 0.24 on the PDPTW test set. In contrast,
our framework maintains a much tighter generalization gap
of only 0.07. This suggests that the heuristics obtained
from our framework transfer more reliably across problem
instances than they overfit to specific training cases.
4.3. Cross-Method Component Analysis
To demonstrate that the performance gains are driven by
our proposed modules, we conduct a cross-method compo-
nent analysis on the PDPTW task. Instead of limiting the
ablation study to the LaGO framework, we independently
integrate each proposed module into three baseline methods
(EoH, ReEvo, and LLM-LNS), while keeping all other com-
ponents as originally defined. Specifically, we evaluate: (A)
co-evolution of constructive and refinement heuristics, (B)
code-writing analyst for structured feedback, (C) diversity-
aware population management. We also evaluate another
variant (D) of explicitly adding the skeleton algorithm to the
generator. Results in Figure 2 demonstrate that the LaGO
framework‚Äôs modular improvements are quite transferable.
Joint Optimization Boosts Cold-Start Method.
The
introduction of co-evolving constructive and refinement
heuristics (Variant A) yields a consistent performance boost
across all methods, especially EoH, with a QYI score in-
crease of 0.3 over the baseline (red dashed line). This
confirms that evolutionary methods lacking a strong ini-
tialization mechanism suffer from a cold start problem, in
which they become stuck in a bad local minimum, especially
when the fitness landscape is rugged and soft constraints are
present. By optimizing the constructive heuristic to provide
a valid starting point, Variant A enables the solver to finally
converge to a feasible and better solution.
Analyst Complements Sparse Feedback.
Introducing
the code-writing Analyst (Variant B) substantially improves
performance for EoH and LLM-LNS, both of which rely pri-
marily on scalar reward signals. The Analyst provides struc-
tured, instance-aware feedback that complements sparse
fitness values and enables more targeted heuristic updates.
In contrast, ReEvo shows only marginal gains, consistent
with its existing textual reflection mechanism. This result
suggests that the Analyst‚Äôs primary value lies in upgrading
methods with limited feedback channels rather than replac-
ing existing reflection-based designs.
Population Diversity Enable Sustained Exploration.
Diversity-aware population management (Variant C) bene-
fits all baselines, with the largest gains +0.2 observed for
ReEvo. While ReEvo‚Äôs reflection mechanism enables strong
local refinement, it also tends to induce mode collapse, re-
peatedly elaborating on a narrow set of high-performing
heuristics. Our diversity-driven sampling forces the selec-
tion of distinct parents, encouraging exploration of distinct
algorithmic structures. This result indicates that managing
population diversity is critical for long-horizon exploration
in LLM-driven heuristic search.
7


--- Page 8 ---
Heuristic Search as Language-Guided Program Optimization
Table 3. Traveling Salesman Problems Heuristic Comparison.
This table provides a sanity check of the proposed method on well-
studied combinatorial problems. The best results are marked bold,
the second-best results are marked by underline.
Method
rd100 pr124 bier127 kroA150 u159 kroB200
EoH
0.08
0.00
0.49
1.12
0.00
2.39
ReEvo
0.00
0.09
0.41
0.00
0.00
0.90
LLM-LNS
0.01
0.08
0.62
1.35
0.32
1.92
Ours
0.00
0.00
1.06
0.45
0.00
1.19
Role of the Algorithm Skeleton.
Finally, we evaluate the
impact of explicitly providing an algorithm skeleton (Vari-
ant D). Interestingly, this modification yields negligible im-
provements for simpler EoH and slight deficits for advanced
methods like ReEvo. This suggests that, for single-heuristic
frameworks, enforcing a static code structure constrains the
LLM‚Äôs exploration of diverse logic. The limited benefit of
Variant D for baselines confirms that LaGO‚Äôs performance
gains do not stem from providing a code template, but from
the other three components.
4.4. Further Analysis
Impact of Problem Complexity
To examine the applica-
bility of our framework across problem domains of different
maturity, we evaluate it on the Traveling Salesman Problem
(TSP) (J¬®unger et al., 1995), following the same training and
test protocols as EoH. As shown in Table 3, while relative
gains are modest compared to real-world tasks, our method
remains competitive with state-of-the-art constructive base-
lines (Voudouris & Tsang, 1999), achieving the best results
on three of six instances and ranking second on two others.
We attribute the more modest gains to two factors. First,
TSP is a highly mature and well-studied problem domain:
decades of research have produced specialized heuristics,
such as Lin‚ÄìKernighan‚ÄìHelsgaun (Lin & Kernighan, 1973),
that already operate near-optimally, leaving limited room
for further algorithmic improvement. In contrast, many
real-world optimization problems lack such dominant, hand-
engineered solutions, where a flexible heuristic design
framework can be more impactful. Second, our framework
is particularly effective with richly structured semantics.
Real-world tasks often involve complex logical constraints
(e.g., precedence relations or time windows) that allow rich
diagnostic feedback. By comparison, TSP is governed by
metric distance, offering fewer opportunities for leveraging
semantic feedback. These results suggest that our frame-
work is most valuable in complex, under-explored domains
where domain-specific heuristics are not yet fully optimized.
Search Dynamics and Efficiency.
We visualize the evo-
lution of heuristic performance on the training set in Fig-
ure 3. A key challenge in our framework is the signifi-
0
4
8
12
16
20
0.25
0.50
0.75
Fitness
PDPTW
0
2
4
6
8
10
0.8
0.9
Crew Pairing
0
4
8
12
16
20
Iteration
0.4
0.6
Fitness
Technology Mapping
0
4
8
12
16
20
Iteration
0.25
0.50
Intra-Op
EoH
ReEvo
LLM-LNS
LaGO (ours)
Figure 3. Convergence curves during training. Despite opti-
mizing a larger joint search space, our diversity-aware sampling
enables stable convergence to a better final fitness score than single-
refinement baselines.
cantly expanded search space introduced by jointly opti-
mizing constructive and refinement heuristics, which may
impede search efficiency and convergence. However, we
observe that our method not only converges stably but also
achieves a higher final fitness score than baselines restricted
to refinement-only search. We attribute this efficiency to the
diversity-aware management strategy in our update mod-
ule. By actively maintaining diversity in the population
and leveraging it in heuristic generation, our optimizer miti-
gates premature convergence to suboptimal local optima and
achieves a more effective exploration-exploitation balance
throughout the evolutionary process.
5. Conclusion and Discussion
In this work, we introduced a unified framework for large
language model-based automated heuristic design. By re-
formulating the heuristic discovery process as an explicit
optimization problem over the program space, we moved be-
yond ad hoc evolutionary pipelines to a principled Language-
Guided Optimization paradigm. Decomposing the search
loop into forward, backward, and update modules enabled us
to systematically improve existing methods. Extensive em-
pirical evaluations on challenging real-world benchmarks,
including PDPTW and crew pairing, demonstrate that our
proposed instantiations yield significant performance gains
over state-of-the-art baselines.
More broadly, our framework provides a foundation for
future research in automated algorithm discovery. In par-
ticular, it offers a common abstraction for reasoning about,
comparing, and extending LLM-based AHD methods across
domains. Potential directions include dynamic component
selection within heuristic pipelines; alternative feedback
modalities beyond code execution-based profiling; advanced
update strategies beyond genetic programming.
8


--- Page 9 ---
Heuristic Search as Language-Guided Program Optimization
Impact Statement
This paper presents work whose goal is to advance the field
of Machine Learning. There are many potential societal
consequences of our work, none which we feel must be
specifically highlighted here.
References
Akiba, T., Sano, S., Yanase, T., Ohta, T., and Koyama, M.
Optuna: A next-generation hyperparameter optimization
framework. In Proceedings of the 25th ACM SIGKDD
international conference on knowledge discovery & data
mining, pp. 2623‚Äì2631, 2019.
Andersson, E., Housos, E., Kohl, N., and Wedelin, D. Crew
pairing optimization. In Operations research in the airline
industry, pp. 228‚Äì258. Springer, 1998.
Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski,
H., Dohan, D., Jiang, E., Cai, C., Terry, M., Le, Q., et al.
Program synthesis with large language models. arXiv
preprint arXiv:2108.07732, 2021.
Blot, A., Hoos, H. H., Jourdan, L., Kessaci-Marmion, M.-
¬¥E., and Trautmann, H. Mo-paramils: A multi-objective
automatic algorithm configuration framework. In Interna-
tional Conference on Learning and Intelligent Optimiza-
tion, pp. 32‚Äì47. Springer, 2016.
Burke, E. K., Gendreau, M., Hyde, M., Kendall, G.,
Ochoa, G., ¬®Ozcan, E., and Qu, R.
Hyper-heuristics:
a survey of the state of the art. Journal of the Opera-
tional Research Society, 64(12):1695‚Äì1724, 2013. doi:
10.1057/jors.2013.71. URL https://doi.org/10.
1057/jors.2013.71.
Chen, A., Dohan, D., and So, D. Evoprompting: Lan-
guage models for code-level neural architecture search.
Advances in neural information processing systems, 36:
7787‚Äì7817, 2023a.
Chen, D. and Cong, J. Daomap: A depth-optimal area
optimization mapping algorithm for fpga designs. In
IEEE/ACM International Conference on Computer Aided
Design, 2004. ICCAD-2004., pp. 752‚Äì759. IEEE, 2004.
Chen, H., Wang, Y., Cai, Y., Hu, H., Li, J., Huang, S.,
Deng, C., Liang, R., Kong, S., Ren, H., Samaranayake,
S., Gomes, C. P., and Zhang, Z. Heurigym: An agentic
benchmark for llm-crafted heuristics in combinatorial
optimization. arXiv preprint arXiv:2506.07972, 2025.
URL https://arxiv.org/abs/2506.07972.
Chen, M. Evaluating large language models trained on code.
arXiv preprint arXiv:2107.03374, 2021.
Chen, X., Lin, M., Sch¬®arli, N., and Zhou, D. Teaching
large language models to self-debug.
arXiv preprint
arXiv:2304.05128, 2023b.
Cui, W., Zhang, J., Li, Z., Sun, H., Lopez, D., Das, K.,
Malin, B. A., and Kumar, S.
Heuristic-based search
algorithm in automatic instruction-focused prompt opti-
mization: A survey. In Findings of the Association for
Computational Linguistics: ACL 2025, pp. 22093‚Äì22111,
2025.
Dat, P. V. T., Doan, L., and Binh, H. T. T. Hsevo: Elevating
automatic heuristic design with diversity-driven harmony
search and genetic algorithm using llms. In Proceed-
ings of the AAAI Conference on Artificial Intelligence,
volume 39, pp. 26931‚Äì26938, 2025.
Drake, J. H., Kheiri, A., ¬®Ozcan, E., and Burke, E. K. Recent
advances in selection hyper-heuristics. European Journal
of Operational Research, 285(2):405‚Äì428, 2020.
Dumas, Y., Desrosiers, J., and Soumis, F. The pickup and
delivery problem with time windows. European journal
of operational research, 54(1):7‚Äì22, 1991.
Guo, D., Zhu, Q., Yang, D., Xie, Z., Dong, K.,
Zhang, W., Chen, G., Bi, X., Wu, Y., Li, Y., et al.
Deepseek-coder: When the large language model meets
programming‚Äìthe rise of code intelligence. arXiv preprint
arXiv:2401.14196, 2024.
Hao, Y., Chen, Y., Zhang, Y., and Fan, C. Large language
models can solve real-world planning rigorously with
formal verification tools. In Proceedings of the 2025
Conference of the Nations of the Americas Chapter of
the Association for Computational Linguistics: Human
Language Technologies (Volume 1: Long Papers), pp.
3434‚Äì3483, 2025.
HromkoviÀác, J. Algorithmics for hard problems: introduction
to combinatorial optimization, randomization, approxi-
mation, and heuristics. Springer Science & Business
Media, 2013.
Huang, Z., Wu, W., Wu, K., Wang, J., and Lee, W.-B. Calm:
Co-evolution of algorithms and language model for auto-
matic heuristic design. arXiv preprint arXiv:2505.12285,
2025.
Hutter, F., Hoos, H. H., Leyton-Brown, K., and St¬®utzle, T.
Paramils: an automatic algorithm configuration frame-
work. Journal of artificial intelligence research, 36:267‚Äì
306, 2009.
J¬®unger, M., Reinelt, G., and Rinaldi, G.
The traveling
salesman problem. Handbooks in operations research
and management science, 7:225‚Äì330, 1995.
9


--- Page 10 ---
Heuristic Search as Language-Guided Program Optimization
Kwon, M., Xie, S. M., Bullard, K., and Sadigh, D. Re-
ward design with language models.
arXiv preprint
arXiv:2303.00001, 2023.
Lange, R., Tian, Y., and Tang, Y. Large language models as
evolution strategies. In Proceedings of the Genetic and
Evolutionary Computation Conference Companion, pp.
579‚Äì582, 2024.
LeCun, Y., Bengio, Y., and Hinton, G. Deep learning. nature,
521(7553):436‚Äì444, 2015.
Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J.,
Leblond, R., Eccles, T., Keeling, J., Gimeno, F., Dal Lago,
A., et al. Competition-level code generation with alpha-
code. Science, 378(6624):1092‚Äì1097, 2022.
Lin, S. and Kernighan, B. W. An effective heuristic algo-
rithm for the traveling-salesman problem. Operations
research, 21(2):498‚Äì516, 1973.
Liu, F., Tong, X., Yuan, M., Lin, X., Luo, F., Wang, Z.,
Lu, Z., and Zhang, Q. Evolution of heuristics: Towards
efficient automatic algorithm design using large language
model. In International Conference on Machine Learning
(ICML), 2024.
URL https://arxiv.org/abs/
2401.02051.
Liventsev, V., Grishina, A., H¬®arm¬®a, A., and Moonen, L.
Fully autonomous programming with large language mod-
els. In Proceedings of the Genetic and Evolutionary
Computation Conference, pp. 1146‚Äì1155, 2023.
L¬¥opez-Ib¬¥aÀúnez, M., Dubois-Lacoste, J., C¬¥aceres, L. P., Bi-
rattari, M., and St¬®utzle, T. The irace package: Iterated
racing for automatic algorithm configuration. Operations
Research Perspectives, 3:43‚Äì58, 2016.
Lourenc¬∏o, H. R., Martin, O. C., and St¬®utzle, T. Iterated local
search. In Handbook of metaheuristics, pp. 320‚Äì353.
Springer, 2003.
Ma, Y. J., Liang, W., Wang, G., Huang, D.-A., Bastani, O.,
Jayaraman, D., Zhu, Y., Fan, L., and Anandkumar, A.
Eureka: Human-level reward design via coding large lan-
guage models. arXiv preprint arXiv:2310.12931, 2023.
Mei, Y., Chen, Q., Lensen, A., Xue, B., and Zhang, M. Ex-
plainable artificial intelligence by genetic programming:
A survey. IEEE Transactions on Evolutionary Computa-
tion, 27(3):621‚Äì641, 2022.
Meyerson, E., Nelson, M. J., Bradley, H., Gaier, A., Moradi,
A., Hoover, A. K., and Lehman, J. Language model
crossover: Variation through few-shot prompting. ACM
Transactions on Evolutionary Learning, 4(4):1‚Äì40, 2024.
Moffitt, M. D. and Fegade, P. The asplos 2025/eurosys 2025
contest on intra-operator parallelism for distributed deep
learning. In Proceedings of the 30th ACM International
Conference on Architectural Support for Programming
Languages and Operating Systems, Volume 3, pp. 5‚Äì17,
2025.
O‚ÄôNeill, M., Vanneschi, L., Gustafson, S., and Banzhaf, W.
Open issues in genetic programming. Genetic Program-
ming and Evolvable Machines, 11(3):339‚Äì363, 2010.
Romera-Paredes, B., Barekatain, M., Novikov, A., Balog,
M., Kumar, M. P., Dupont, E., Ruiz, F. J., Ellenberg, J. S.,
Wang, P., Fawzi, O., et al. Mathematical discoveries from
program search with large language models. Nature, 625
(7995):468‚Äì475, 2024.
Shi, Q., Tang, M., Narasimhan, K., and Yao, S. Can lan-
guage models solve olympiad programming?
arXiv
preprint arXiv:2404.10952, 2024.
St¬®utzle, T. and L¬¥opez-Ib¬¥aÀúnez, M. Automated design of
metaheuristic algorithms. In Handbook of metaheuristics,
pp. 541‚Äì579. Springer, 2018.
Team, G., Kamath, A., Ferret, J., Pathak, S., Vieillard,
N., Merhej, R., Perrin, S., Matejovicova, T., Ram¬¥e, A.,
Rivi`ere, M., et al. Gemma 3 technical report. arXiv
preprint arXiv:2503.19786, 2025.
Tian, R., Ye, Y., Qin, Y., Cong, X., Lin, Y., Pan, Y., Wu, Y.,
Haotian, H., Weichuan, L., Liu, Z., et al. Debugbench:
Evaluating debugging capability of large language mod-
els. In Findings of the Association for Computational
Linguistics: ACL 2024, pp. 4173‚Äì4198, 2024.
Voudouris, C. and Tsang, E. Guided local search and its
application to the traveling salesman problem. European
journal of operational research, 113(2):469‚Äì499, 1999.
Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J.,
Chen, Z., Tang, J., Chen, X., Lin, Y., et al. A survey on
large language model based autonomous agents. Frontiers
of Computer Science, 18(6):186345, 2024.
Xu, M., Mei, Y., Zhang, F., and Zhang, M. Genetic program-
ming for dynamic flexible job shop scheduling: Evolution
with single individuals and ensembles. IEEE Transac-
tions on Evolutionary Computation, 28(6):1761‚Äì1775,
2023.
Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D.,
and Chen, X. Large language models as optimizers. In
The Twelfth International Conference on Learning Repre-
sentations, 2023.
Ye, H., Wang, J., Cao, Z., Berto, F., Hua, C., Kim, H.,
Park, J., and Song, G. Reevo: Large language models as
10


--- Page 11 ---
Heuristic Search as Language-Guided Program Optimization
hyper-heuristics with reflective evolution. In Advances in
Neural Information Processing Systems, 2024. https:
//github.com/ai4co/reevo.
Ye, H., Xu, H., Yan, A., and Cheng, Y. Large language
model-driven large neighborhood search for large-scale
milp problems. In Forty-second International Conference
on Machine Learning, 2025.
Zelikman, E., Lorch, E., Mackey, L., and Kalai, A. T. Self-
taught optimizer (stop): Recursively self-improving code
generation. In First Conference on Language Modeling,
2024.
Zhang, S., Chen, Z., Shen, Y., Ding, M., Tenenbaum, J. B.,
and Gan, C. Planning with large language models for code
generation. arXiv preprint arXiv:2303.05510, 2023a.
Zhang, Z.-Q., Wu, F.-C., Qian, B., Hu, R., Wang, L., and
Jin, H.-P. A q-learning-based hyper-heuristic evolutionary
algorithm for the distributed flexible job-shop scheduling
problem with crane transportation. Expert Systems with
Applications, 234:121050, 2023b.
Zheng, Z., Xie, Z., Wang, Z., and Hooi, B. Monte carlo tree
search for comprehensive exploration in llm-based auto-
matic heuristic design. arXiv preprint arXiv:2501.08603,
2025.
Zhong, R., Hussien, A. G., Yu, J., and Munetomo, M.
Llmoa: A novel large language model assisted hyper-
heuristic optimization algorithm. Advanced Engineering
Informatics, 64:103042, 2025.
Zhu, L., Zhou, Y., Sun, S., and Su, Q. Surgical cases assign-
ment problem using an efficient genetic programming
hyper-heuristic. Computers & Industrial Engineering,
178:109102, 2023.
11


--- Page 12 ---
Heuristic Search as Language-Guided Program Optimization
A. Overview of Appendix
This Appendix contains several sections, each addressing a specific aspect of the experimental setups and results. Below is a
brief overview of each section:
‚Ä¢ Discussion on additional related works of executable feedback in code generation;
‚Ä¢ More details about the problems we include in Table 2, and the reasons we select them from the benchmark while
excluding the rest;
‚Ä¢ Additional experiment results using GPT-4.1-mini on PDPTW;
‚Ä¢ The prompts we use in our system.
B. Additional Related Works
Code Generation with Execution Feedback
Beyond the specific domain of heuristics, there is a broader literature on
how LLMs can iteratively improve executable code through interaction with execution environments (Wang et al., 2024).
This paradigm has been explored in diverse settings, including debugging (Chen et al., 2023b; Tian et al., 2024), algorithmic
competition challenges (Li et al., 2022; Shi et al., 2024), and general planning problems (Zhang et al., 2023a; Hao et al.,
2025). A common theme in these approaches is the use of execution-based feedback, such as test outcomes, traces, or
scalar rewards‚Äîto drive iterative refinement (Liventsev et al., 2023; Guo et al., 2024). This idea has proven effective
in applications ranging from reward design for reinforcement learning (Ma et al., 2023; Kwon et al., 2023) to algorithm
self-improvement (Zelikman et al., 2024). However, despite their success, most existing methods treat the optimization
loop as a tightly coupled, end-to-end process, where evaluation, diagnosis, and code generation are intertwined. In the
specific context of automated heuristic design for CO, where solution quality depends on subtle structural interactions and
constraint satisfaction, this design makes it difficult to reason about the role of individual components, compare methods in
a principled manner, or systematically extend them to more structured domains such as combinatorial optimization.
C. Combinatorial Problems in HeuriGym
There are nine real-world combinatorial optimization problems from Heurigym (Chen et al., 2025) that were excluded from
the main paper. In this paper, we include four problems from the benchmark and exclude the remaining five problems. The
main criterion is the quality of the greedy algorithm‚Äôs solution. Simple greedy algorithms can find optimal or near-optimal
solutions for all the test cases of Operator Scheduling, E-Graph Extraction, Protein Sequence Design, Global Routing, and
Mendelian Error Detection. The problems, hence, are not challenging enough to evaluate the performance of LLM-based
heuristic evolution pipelines with the latest LLMs. Here we introduce the problems included in Table 2.
C.1. Pickup and Delivery Problem with Time Windows
The Pickup and Delivery Problem with Time Windows (PDPTW) (Dumas et al., 1991) is a generalization of the Capacitated
Vehicle Routing Problem (CVRP), in which a fleet of vehicles must serve a set of transportation requests, each consisting of
a pair of pickup and delivery locations. The core challenge is to construct a set of routes that minimizes travel cost (distance
or time) and fleet size while strictly adhering to pairing and precedence constraints‚Äîspecifically, that a request‚Äôs pickup
must precede its delivery on the same vehicle. Additionally, service at every location must commence within a specified
time window, and the vehicle‚Äôs load must never exceed its capacity. This problem is widely used to benchmark solvers on
their ability to handle precedence-constrained routing and tight temporal feasibility checks, which are central to applications
like on-demand logistics, paratransit services, and autonomous ride-sharing.
C.2. Airline Crew Pairing
The Airline Crew Pairing Problem (CPP) (Andersson et al., 1998) is formulated as a cost-minimization problem over a set
of flight legs, modeled as a large-scale Set Partitioning Problem (SPP) or Set Covering Problem (SCP). The objective is to
construct a set of ‚Äùpairings‚Äù, e.g., sequences of flight legs starting and ending at the same crew base, to cover every flight leg
exactly once. This problem is characterized by highly constrained search spaces due to complex validity regulations, such as
FAA safety rules on maximum flying time and minimum rest periods. The total costs are a complex function of factors such
12


--- Page 13 ---
Heuristic Search as Language-Guided Program Optimization
Table 4. PDPTW Performance Evaluation with GPT4.1-mini.
Method
GPT train
Switch Gain
GPTtest
Switch Gain
EoH
0.469
0.091
0.244
0.070
ReEvo
0.467
0.094
0.333
‚àí0.030
LLM-LNS
0.533
0.063
0.246
0.108
Ours
0.736
0.146
0.637
0.171
as wages, hotel accommodations, and deadhead travel. We utilize CPP instances to evaluate the solver‚Äôs ability to handle
high-dimensional combinatorial constraints and non-convex objective landscapes.
C.3. Technology Mapping
Technology Mapping (Chen & Cong, 2004) is a fundamental step in the Electronic Design Automation (EDA) logic synthesis
flow, responsible for binding a technology-independent Boolean network (typically an And-Inverter Graph) to a specific
library of physical gates. The problem is formally defined as a graph covering problem: finding a valid cover of the subject
graph using a set of K-input subgraphs. The optimization goal is to minimize the total number of subgraphs. We utilize CPP
instances to evaluate the solver‚Äôs ability to handle high-dimensional combinatorial constraints and non-convex objective
landscapes. This problem serves as a rigorous benchmark for combinatorial optimization under large input size.
C.4. Intra-Operator Parallelism
The Intra-Operator Parallelism (IOPDDL) (Moffitt & Fegade, 2025) is a combinatorial optimization challenge introduced in
the ASPLOS‚Äô25 contest track, focusing on the efficient distribution of large-scale deep learning models across multiple
hardware accelerators. The problem is formulated on a large computational graph, where nodes represent operations
and edges represent tensor dependencies. For each node, the solver must select a single execution strategy from a set of
discrete candidates, each defined by specific computational costs and memory requirements. The objective is to minimize
the aggregate cost‚Äîcomprising both operation execution (node cost) and communication overhead (edge cost)‚Äîwhile
strictly adhering to peak memory usage constraints on every device. Due to the diversity of model topologies and the scale
of operations involved, this problem serves as a rigorous benchmark for constrained graph optimization, where leading
solutions currently rely on specialized meta-heuristic strategies.
D. Experiment
D.1. Experiment Detail
In the experiments on all tested domains (including TSP), we run the automatic heuristic design for 20 iterations, except for
10 in crew pairing, as it‚Äôs simple enough to converge at an early stage. And the population size is 10, except for 4 in crew
pairing.
D.2. Additional Experiment
We conduct an additional experiment on PDPTW using a previous-generation model, GPT-4.1-mini. The experimental
results, summarized in Table 4, demonstrate that our framework is not tailored to a specific LLM architecture but rather
generalizes effectively across different backends. While baseline methods exhibit inconsistent behavior when transitioning
from GPT-4.1-mini to Gemini-3-Flash, e.g., ReEvo suffers a performance degradation (‚àÜ= ‚àí0.030), our
approach maintains robust superiority on both models. This confirms that the proposed method captures the intrinsic
structure of the PDPTW problem, rather than exploiting the idiosyncrasies of a single language model. Furthermore, our
framework benefits most significantly from the enhanced reasoning capabilities of Gemini-3-Flash, achieving the
largest performance gain on the test set (+0.171). This positive scaling indicates that, unlike prior heuristics (e.g., LLM-LNS
and EoH), which see diminishing or marginal returns, our method is uniquely positioned to leverage advancements in
next-generation foundation models.
13


--- Page 14 ---
Heuristic Search as Language-Guided Program Optimization
E. Prompt Design
We present the prompt used in the framework for analyst LLM and generator LLM, respectively.
E.1. Analyst
System Prompt
You are a world-class optimization expert specializing in metaheuristics and LNS. Your task is to design a suite of
diagnostic features that characterize both the difficulty of a problem instance and the quality/bottlenecks of a current
solution.
Objectives:
1. Discriminative Power: Features must help distinguish why certain instances are harder than others and why
specific solutions are suboptimal. Please also be noted that different instances may have significant difference
in scale and absolute cost values, which doesn‚Äôt necessarily reflect the performance.
2. Feasibility Analysis: Capture violations, which are represented as soft constraint costs.
3. Diversity: Include spatial, temporal, and other structural metrics if applicable.
Implementation Requirements:
‚Ä¢ Input Argument: Every function must accept exactly the arguments as provided in the example.
‚Ä¢ Output: Each function must return a single ‚Äòfloat‚Äò.
‚Ä¢ Aggregation: You must provide a list named ‚Äòfeature func list‚Äò containing all your function objects.
‚Ä¢ Environment: Python 3.12. Use ‚Äònumpy‚Äò for efficiency. Include all necessary imports.
‚Ä¢ Strictness: Output ONLY the Python code. No explanations, no markdown code blocks, no comments outside
the code.
Problem Information: {problem description}
Template analyst code: {template analyst code}
User Prompt
The following features were used in the previous iteration: {history feature code}
Your analysis for currently best individual is {current best heuristic feature},
Whereas the solution costs are as follows: {current best heuristic training cost}
(if no improved in last iteration)
The previous iteration did NOT show improvement in heuristic performance. This suggests the current features
might not be capturing the critical aspects of the problem needed for better decision-making. Please significantly
modify or add new features that provide deeper insights into the solution state.
(if improved in last iteration)
The previous iteration showed improvement in heuristic performance. You can choose to refine the existing features
or add complementary ones to further capture the problem structure.
Please provide several feature functions that can characterize the state of a solution for this problem or the critical
aspects of the problem instance. End your response with a list named ‚Äòfeature func list‚Äò containing the function
objects.
14


--- Page 15 ---
Heuristic Search as Language-Guided Program Optimization
User Prompt (Error Fixing)
Your previous feature code encountered errors during execution. Please identify and fix the issues in the feature
functions to ensure they run correctly and provide meaningful analysis. Use same formatting as provided feature
code and modify only the necessary parts to fix the errors.
Previous Feature Code:{past feature code}
The errors are as follows:{best individual analysis traceback errors}
E.2. Generator
System Prompt
The task can be solved step-by-step by starting from a constructive initial solution and iteratively selecting a subset
of decision variables to relax and re-optimize. In each step, most decision variables are fixed to their values in the
current solution, and only a small subset is allowed to change. You need to score all the decision variables based on
the information I give you, and I will choose the decision variables with high scores as neighborhood selection. To
avoid getting stuck in local optima, the choice of the subset can incorporate a degree of randomness.
+ You need to come up with a heuristic function which score a state. A good practice is to analyze the cost function
and current solution to find what contributes most to the cost. Think systematically and creatively. Also I suggest the
score function to be weighted sum. Note that the cost function actually soft constraints with very heavy penalty. You
should pay more attention to these than the normal cost.
+ You also need to provide an initial solution function, which should be a constructive heuristic. The initial solution
itself does not necessarily perform well, but it needs to provide a warmstart for neighborhood search to get close to a
good local minimum. You also need to pay attention to the synergy between the initial solution and heuristics.
+ You should be noted that the generated solution should be general for out-of-distribution data, which may vary in
scale and characteristic of numbers. So don‚Äôt just exploit what you know, try to find different strategies which all
work good on training sets.
+ A problem template is provided below. You need to implement both the ‚Äôheuristic‚Äô and ‚Äô init solution‚Äô function. Do
NOT modify the function signature including the data types of the input arguments. Make sure you have imported
necessary libraries and modules.
Template Heuristic Code: {template heuristic}
User Prompt (Operator i1 - initialization)
‚ÄùYour task is to initialize a new heuristic algorithm for scoring decision variables. ‚Äù ‚ÄùRefer to the format of a trivial
design provided. Be very creative.‚Äù
‚ÄùStep 1: Briefly describe your new algorithm and its main steps in one sentence. This description MUST be inside
braces {} and commented by ‚Äù‚Äù‚Äù ‚Äù‚Äù‚Äù as in Python.‚Äù
‚ÄùStep 2: Implement the algorithm in Python. Ensure all necessary imports are included, and the function signature
matches the template.‚Äù
15


--- Page 16 ---
Heuristic Search as Language-Guided Program Optimization
User Prompt (Operator e1 - crossover)
‚ÄùI have two existing algorithms with their codes and performance features as follows:‚Äù
‚ÄùAlgorithm 1 (better):‚Äù
f‚Äù{Individual 1}‚Äù
‚ÄùAlgorithm 2 (worse):‚Äù
f‚Äù{Individual}‚Äù
‚ÄùPlease help me create a new algorithm that is different from the given ones but can be motivated from them.‚Äù ‚ÄùYour
task is to synthesize a new algorithm by merging the most effective components as hints and design patterns from
both.‚Äù
‚ÄùStep 1: Briefly describe the new synthesized algorithm and its main steps in one sentence. This description MUST
be inside braces and commented by ‚Äù‚Äù‚Äù ‚Äù‚Äù‚Äù as in python.‚Äù
‚ÄùStep 2: Implement the new algorithm in Python. Ensure all necessary imports are included and the function signature
matches the template.‚Äù
User Prompt (Operator e2 - crossover)
‚ÄùI have two existing algorithms with their codes and performance features as follows:‚Äù
‚ÄùAlgorithm 1 (better):‚Äù
f‚Äù{Individual 1}‚Äù
‚ÄùAlgorithm 2 (worse):‚Äù
f‚Äù{Individual 2}‚Äù
‚ÄùYour task is to evolve a new algorithm by identifying the differences in their performance and logic. ‚Äù ‚ÄùDetermine
which algorithm performs better and why. Then, identify a limitation in the better algorithm that the other might
address, ‚Äù ‚Äùor propose a novel mechanism inspired by their differences to overcome current bottlenecks.‚Äù
‚ÄùStep 1: Briefly describe the new evolved algorithm and its main steps in one sentence. This description MUST be
inside braces and commented by ‚Äù‚Äù‚Äù ‚Äù‚Äù‚Äù as in python.‚Äù
‚ÄùStep 2: Implement the new algorithm in Python. Ensure all necessary imports are included and the function signature
matches the template.‚Äù
16


--- Page 17 ---
Heuristic Search as Language-Guided Program Optimization
User Prompt (Operator m1 - mutation)
‚ÄùI have one existing algorithm with its code and performance features as follows:‚Äù
f‚Äù{Individual}‚Äù
‚ÄùYour task is to ‚Äômutate‚Äô this algorithm to create a new variant. ‚Äù ‚ÄùAnalyze the current scoring logic and identify
one core component or assumption that can be improved, ‚Äù ‚Äùdiversified, or replaced with a different mathematical
approach to explore a new area of the search space.‚Äù
‚ÄùStep 1: Briefly describe the new mutated algorithm and its main steps in one sentence. This description MUST be
inside braces and commented by ‚Äù‚Äù‚Äù ‚Äù‚Äù‚Äù as in python.‚Äù
‚ÄùStep 2: Implement the new algorithm in Python. Ensure all necessary imports are included and the function signature
matches the template.‚Äù
E.3. Format of Individual Heuristic
Individual
Response at iteration {iteration}
code={code}
text description=‚Äù‚Äù‚Äù{text description}‚Äù‚Äù‚Äù
avg objective {avg objective}
error msg=‚Äô{error msg}‚Äô
Performance Summary:
- {feature 1}: Avg={avg feature 1 value}, Range=[minimum feature 1 value, maximum feature 1 value]‚Äù
- {feature 2}: Avg={avg feature 2 value}, Range=[minimum feature 2 value, maximum feature 2 value]‚Äù
¬∑ ¬∑ ¬∑
- {feature N}: Avg={avg feature N value}, Range=[minimum feature N value, maximum feature N value]‚Äù
- Worst Instance ({instance}): Fitness={instance fitness}, Features={instance feature values}‚Äù
- Best Instance ({instance}): Fitness={instance fitness}, Features={instance feature values}‚Äù
17
