--- Page 1 ---
CODEEVOLVE: an open-source evolutionary framework for
algorithmic discovery and optimization
Henrique Assumpção1,3, Diego Ferreira1,3, Leandro Campos1,3, Fabricio Murai2
1Inter&Co., Belo Horizonte, MG, Brasil
2Worcester Polytechnic Institute, Worcester, MA, USA
3Universidade Federal de Minas Gerais, Belo Horizonte, MG, Brasil
Correspondence: henrique.soares@inter.co
Abstract
We introduce CODEEVOLVE, an open-source
framework that combines large language mod-
els (LLMs) with evolutionary search to syn-
thesize high-performing algorithmic solutions.
CODEEVOLVE couples an islands-based ge-
netic algorithm with modular LLM orchestra-
tion, using execution feedback and task-specific
metrics to guide selection and variation. Explo-
ration and exploitation are balanced through
context-aware recombination, adaptive meta-
prompting, and targeted refinement of promis-
ing solutions. We evaluate CODEEVOLVE on
benchmarks previously used to assess Google
DeepMind’s AlphaEvolve, showing superior
performance on several tasks and competitive
results overall. Notably, open-weight models
often match or exceed closed-source baselines
at a fraction of the compute cost. We provide
extensive ablations analyzing the contribution
of each component and release our framework
and experimental results at https://github.
com/inter-co/science-codeevolve.
1
Introduction
Recent strides in Large Language Models (LLMs)
and agentic systems research have achieved major
breakthroughs in program synthesis and automated
scientific discovery (Chen et al., 2021; Li et al.,
2022; Fawzi et al., 2022; Romera-Paredes et al.,
2024). A common thread in such frameworks is the
use of algorithmic orchestration to systematically
enrich model context and reduce the dependency
on human prompters, enabling LLMs to iteratively
propose, test, and refine candidate solutions. In par-
allel, multi-agent and ensemble approaches explore
how smaller or open models can be coordinated to
tackle complex tasks with greater transparency and
lower operational cost (Belcak et al., 2025).
Of particular relevance to our work is AlphaE-
volve (Novikov et al., 2025), which combines
genetic algorithms with the Gemini family of
LLMs (Team et al., 2025) to discover solutions
across diverse domains, including data-center op-
timization, matrix multiplication, and combinato-
rial constructions (Nagda et al., 2025; Georgiev
et al., 2025). Despite promising results, AlphaE-
volve is closed-source and described only at a high
level, limiting reproducibility, controlled ablations,
and systematic exploration of orchestration design
choices. In response, several open-source frame-
works (Sharma, 2025; Lange et al., 2025; Wang
et al., 2025; Yu et al., 2025) have begun to explore
LLM-driven evolutionary agents, offering acces-
sible baselines but leaving open questions about
orchestration design, evaluation rigor, and quality–
cost trade-offs.
In this work, we introduce CODEEVOLVE, an
evolutionary coding framework that operational-
izes LLM-driven search within a transparent, fully
open framework. CODEEVOLVE addresses a meta-
optimization task: the population consists of can-
didate programs for a target optimization prob-
lem, and the evolutionary loop applies selection,
variation, and recombination guided by execution
feedback and fitness signals. Concretely, it inte-
grates (i) an islands-based genetic algorithm to
maintain diversity and enable parallel search, (ii)
a weighted LLM ensemble that performs model
selection based on population state, and (iii) three
modular operators that structure exploration and
exploitation: an inspiration-based crossover using
contextual recombination, a meta-prompting strat-
egy to diversify search trajectories, and a depth-
based exploitation mechanism for targeted edits.
These components work in concert to balance
global search with local refinement and to translate
LLM proposals into executable, testable artifacts.
Our evaluation on benchmarks previously used
for assessing AlphaEvolve compares solution qual-
ity, sample efficiency, and compute cost against
both reported AlphaEvolve results and open-source
baselines. CODEEVOLVE achieves state-of-the-
art performance on several problems, including
1
arXiv:2510.14150v3  [cs.AI]  6 Jan 2026


--- Page 2 ---
instances where open-weight models such as
Qwen (Yang et al., 2025) match or outperform
closed-source LLMs at significantly lower cost.
Extensive ablations quantify the contribution of
each component and reveal interactions between
diversity-preserving and refinement mechanisms.
Our work makes the following contributions:
• An open-source framework for algorithmic
discovery that integrates islands-based evo-
lutionary search with modular LLM orches-
tration, designed for transparency and repro-
ducibility.
• A comprehensive empirical evaluation on es-
tablished algorithm-discovery benchmarks,
demonstrating strong performance and favor-
able quality–cost trade-offs, including with
open-weight models.
• An extensive ablation and component-level
analysis that isolates the effects of individual
operators and their interactions on search effi-
ciency and solution quality.
2
Related Work
Genetic programming and LLMs.
Automated
generation and optimization of computer programs
has long been the domain of Genetic Programming
(GP) (Koza, 1992, 1994; Langdon and Poli, 2013),
where populations of programs are iteratively im-
proved by operators such as crossover and mutation.
Although foundational, classical GP methods of-
ten struggle with the semantic complexity of mod-
ern programming languages. The recent advent of
LLMs represents a paradigm shift: with demon-
strated success in generating high-quality solutions
for competitive programming tasks (Li et al., 2022),
LLMs can serve as semantically-aware operators
for code improvement and synthesis.
This synergy has given rise to “Evolution
through Large Models” (Lehman et al., 2023; Hem-
berg et al., 2024). The breakthrough application
of this concept was FunSearch (Romera-Paredes
et al., 2023), which paired an LLM with a program-
matic evaluator to discover novel solutions to open
problems in mathematics, establishing the viability
of the approach for scientific discovery. Building
on this idea, Google DeepMind introduced AlphaE-
volve (Novikov et al., 2025; Georgiev et al., 2025),
a closed-source system that generalizes FunSearch
from evolving single functions to entire codebases
and a broader range of optimization tasks, includ-
ing GPU kernels, warehouse-scale computing, and
complexity theory (Nagda et al., 2025).
Evolutionary coding agents.
Following AlphaE-
volve, several open-source projects developed
LLM-driven evolutionary agents.
OpenEvolve
(Sharma, 2025) provided an accessible implemen-
tation of core features, accelerating community
adoption. ShinkaEvolve (Lange et al., 2025) and
ThetaEvolve (Wang et al., 2025) propose distinct
orchestration designs and evaluation pipelines. Spe-
cialized variants target domains such as scaling
law discovery (Lin et al., 2025) and cloud schedul-
ing (Cheng et al., 2025), etc (Brown et al., 2025;
Nagaitsev et al., 2025). CODEEVOLVE sits within
this class of LLM-driven evolutionary systems and
is designed to be broadly applicable to algorithmic
problems with quantifiable metrics, while prioritiz-
ing reproducibility and transparent evaluation.
Meta-prompting. LLMs are sensitive to prompt
variations (Anagnostidis and Bulian, 2024), moti-
vating systems that automatically design and im-
prove prompts (“meta-prompting”) (Suzgun and
Kalai, 2024; Zhang et al., 2025). CODEEVOLVE
builds on evolutionary strategies for improving
prompts (Chen et al., 2023), mirroring the optimiza-
tion of solution programs and enabling the LLM to
reflect on and rewrite its own instructions to yield
more diverse and effective search trajectories.
Alternative algorithm discovery paradigms.
LLM-driven evolution is part of a broader land-
scape of AI for scientific discovery, and many dis-
tinct approaches have seen major success in recent
years. Deep Reinforcement Learning (RL), for
instance, has achieved landmark results such as
discovering faster matrix multiplication algorithms
with AlphaTensor (Fawzi et al., 2022). While in-
credibly powerful, RL typically requires a more
structured environment and a well-defined action
space.
Other approaches, such as agentic sys-
tems, leverage LLMs to reason over scientific hy-
potheses expressed in natural language (Gottweis
et al., 2025). CODEEVOLVE aims to bridge these
paradigms by combining LLM-based reasoning
with a genetic algorithm that enforces rigorous ex-
ploration of the solution space through explicit eval-
uation and selection.
3
Preliminaries
The task addressed here constitutes a meta-level
optimization: we use an evolutionary algorithm to
optimize programs, which themselves solve math-
ematical optimization problems. To clarify this
distinction, this section formally defines the core
concepts and notation used throughout the paper.
2


--- Page 3 ---
A solution is a program generated to solve a
problem. When an existing solution S is used in a
prompt to generate a new solution S′, we say that S
is the parent solution of S′. This parent-children re-
lationship imposes a natural forest structure on the
solution population, which is a collection of rooted,
directed trees. For any solution S, we denote the
set of its k nearest ancestors as Ak(S).
A prompt is a textual input provided to a Large
Language Model (LLM) to generate a solution. We
define the prompt used for generating solution S as
its parent prompt, denoted by P(S). Since LLMs
are inherently probabilistic, a single prompt can
generate multiple distinct solutions.
The quality of a solution is quantified by an eval-
uation function, h : S 7→Rd, which maps a
solution S from the space of all possible solutions
S to a real-valued vector of performance metrics,
such as runtime, memory usage, or objective value.
We also define two fitness functions to measure
the overall quality of prompts and solutions. The
solution fitness, fsol : S 7→R≥0, maps a solution
to a non-negative score and typically corresponds
to the primary metric in h that we aim to optimize.
The prompt fitness, fprompt, is derived from fsol
and is defined as the maximum fitness achieved by
any solution generated from that prompt:
fprompt(P) =
max
S:P(S)=P{fsol(S)}.
(1)
This rewards prompts that have demonstrated the
potential to generate high-quality solutions, making
them valuable candidates for future evolution, even
if some of their offspring may be suboptimal.
The primary optimization goal is to iteratively
evolve an initial population of prompts and solu-
tions, in order to maximize the solution fitness fsol
over a maximum number of epochs N, while re-
specting constraints on other metrics from h, such
as execution time and memory.
4
Methodology
CODEEVOLVE integrates an evolutionary frame-
work with LLMs to optimize programs. The ar-
chitecture is based on the island genetic algo-
rithm (Whitley and Starkweather, 1990): multiple
populations (islands) evolve independently and pe-
riodically exchange their best-performing individu-
als (migration) according to a predefined topology.
This design improves concurrent evaluation, main-
tains diversity, and propagates successful solutions
across the search. At each epoch t, every island i
maintains a population of prompts Pi
t and solutions
Si
t. CODEEVOLVE operates through an iterative
process that progressively enhances populations of
prompts and solutions via three components. Evo-
lutionary Operators (Section 4.2) generate new indi-
viduals, balancing exploration and exploitation. An
LLM Ensemble (Section 4.1) provides the genera-
tive engine for code modification and recombina-
tion. Population Management (Section 4.4) handles
evaluation, fitness tracking, migration, and archive
updates using the MAP-Elites method (Mouret and
Clune, 2015).
4.1
LLM Ensemble for Solution Generation
The engine behind CODEEVOLVE’s solution gener-
ation is a weighted ensemble of LLMs—denoted
LLMEnsemble—that modify and combine preexist-
ing solutions. For each generation task, a model
is sampled according to ensemble weights. Users
can configure distinct ensembles for exploration
and exploitation (e.g., cheaper, higher-temperature
models for exploration; more accurate, lower-
temperature models for exploitation). In the sim-
plest case, it consists of a single LLM. We evaluate
two ensemble configurations: one using Google’s
GEMINI-2.5 models (Comanici et al., 2025) for
direct comparison with AlphaEvolve, and another
using only Qwen’s Qwen3-Coder-30B (Yang et al.,
2025) to explore the performance–cost trade-off
with open-weight models. See Appendix C for
further details on the ensemble configurations.
4.2
Evolutionary Operators
New solutions are generated in parallel using ex-
ploitation or exploration operators, sampled inde-
pendently across islands. At each step, one opera-
tor is chosen according to an exploration rate pexplr,
which is governed by a scheduler (Section 4.3):
1. Depth exploitation. This operator refines high-
performing solutions. A parent S is selected
from Si
t via rank-based selection, with probabil-
ity inversely proportional to its rank:
Pr(S) :=
rk(S)−1
P
S′∈Si
t rk(S′)−1 ,
(2)
where rk(S) is the position of S when sorting
Si
t by fsol in descending order. The ensemble is
prompted with S, its parent prompt P(S), and
its k nearest ancestors Ak(S). This truncated
ancestral context encourages targeted, incremen-
tal improvements as depth increases, rather than
wholesale strategy changes.
3


--- Page 4 ---
Evolution step  at island 
t
i
Population State
 P
Prompt Pool
i
t
S
Solution Pool 
i
t
Evolution Loop
Initial Prompt(s)
Seed Solution(s)
Configuration
Task Spec
Best Solution
Metrics
{ }
Islands
runs in parallel
0
1
2
3
...
N
Apply Diff
<<< SEARCH
# Old Code
# New Code
>>> REPLACE
=======
Exploit
vs
Explore
pexplr
Population 
Management
Selection
Update Fitness
Migration
LLMEnsemble
...
LM2
LM1
P S , A
S , I
( )
k( )
Evolution Operators
MetaP 
 P', I
→
Sandbox 
Evaluator
Compile/Run
h S
( )
f
, f
⟩
sol
prompt
Figure 1: Overview of CODEEVOLVE.
2. Meta-prompting exploration.
This opera-
tor fosters solution diversity and enriches the
prompt population with feedback from previ-
ous solutions. A solution S and a prompt P
are sampled independently and uniformly at ran-
dom. An auxiliary LLM MetaPromptingLLM
generates an enriched prompt P ′ by analyzing
P and S. The LLMEnsemble uses P ′ and S to
generate a new solution S′. We intentionally ex-
clude the ancestor chain to allow exploration of
novel strategies unconstrained by lineage, while
leveraging the richer prompt P ′.
Inspiration-based Crossover.
Directly splicing
code often breaks syntax and semantics. Instead,
CODEEVOLVE uses inspiration-based crossover:
for both exploitation and exploration, we provide
the ensemble with a set of “inspiration” solutions
sampled either by rank in case of exploitation
(Eq. 2) or uniformly, in case of exploration. The
LLM integrates successful patterns, logic, or func-
tions from multiple parents within its generative
process, thus performing a semantic crossover.
Algorithm 1 presents the core operator loop.
The LLMEnsemble receives a prompt, an ances-
tor set (possibly empty), the target solution, and
inspirations, and outputs a new solution.
The
MetaPromptingLLM receives a prompt and a solu-
tion and outputs a new prompt. For readability, the
pseudocode omits the exploration scheduler and
MAP-Elites integration, as both are orthogonal to
the operator logic and described below.
In practice, new solutions are expressed via LLM
edits using a diff-based SEARCH/REPLACE format:
the model identifies a code region and proposes a
targeted replacement.
4.3
Exploration Scheduling
To adaptively balance exploration and exploitation,
CODEEVOLVE uses a scheduler that controls pexplr
over time. We have implemented two scheduler
policies: (i) Decay scheduling, where we initialize
Algorithm 1 Core exploitation/exploration loop of
CODEEVOLVE at epoch t
1: Input: Populations Pi
t, Si
t, exploration proba-
bility pexplr, maximum ancestor depth k
2: Output: New solution S′, and new prompt P ′
if exploration is chosen
3: Sample p ∼Uniform(0, 1)
4: if p < 1 −pexplr then
5:
Sample S ∈Si
t and inspirations I ⊆Si
t \
{S} according to Eq. 2
6:
Collect ancestor solutions Ak(S) from S to
its root in Si
t
7:
S′ ←LLMEnsemble(P(S), Ak(S), S, I)
8:
P ′ ←NULL
9: else
10:
Sample S ∈Si
t, inspirations I ⊆Si
t \ {S},
and P ∈Pi
t uniformly at random
11:
P ′ ←MetaPromptingLLM(P, S)
12:
S′ ←LLMEnsemble(P ′, ∅, S, I)
13: end if
14: return S′, P ′
the exploration rate at a high value, and monotoni-
cally decrease it (e.g., exponential or cosine decay)
as the search progresses, and (ii) Plateau schedul-
ing, where we monitor the best-so-far fitness using
a moving window, increasing the exploration rate
to escape local optima, then gradually decrease
it to the baseline rate. Both variants require only
lightweight state (recent fitness history) and are
orthogonal to operator design.
4.4
Population Management
CODEEVOLVE includes three mechanisms to man-
age populations over time.
Initialization: The algorithm begins with an ini-
tial solution (often trivial, e.g., a function returning
zero) and a basic prompt describing the problem.
To create a diverse starting population at each is-
land, the LLMEnsemble is prompted multiple times
with this initial pair, generating independent ap-
4


--- Page 5 ---
proaches that become roots of new solution trees.
Evaluation and Population Control: Each new
solution is executed in a sandbox with runtime and
memory limits. If execution succeeds, we compute
fsol(S) and metrics h(S) and add S to the popula-
tion. Failures receive fitness zero, with logs stored
for instructive context in future prompts.
Elitist Migration: Top performers from each
island are copied to neighboring islands at a fixed
migration frequency and rate. To prevent cycles
and premature convergence, a solution migrates
at most once from its origin island, and we never
migrate the best-performing solution of an island in
order to preserve its uniqueness (Romera-Paredes
et al., 2024). Migrants become roots of new trees
upon arrival, with parent pointers set to NULL.
Quality–diversity via MAP-Elites.
In addition
to island populations, CODEEVOLVE maintains a
per-island MAP-Elites archive (Mouret and Clune,
2015). Users define feature descriptors (e.g., code-
level properties, algorithmic behaviors, or run-
time profiles). The archive partitions the feature
space either as a regular lattice (MAP-Elites) or
via centroidal Voronoi tessellations (CVT-MAP-
Elites) (Vassiliades et al., 2017), storing the elite
(i.e., most fit) solution per cell. Archive updates
occur after evaluation: each successful solution
S is mapped to its feature cell; if S improves the
cell’s fitness, it replaces the incumbent elite. Sam-
pling for inspirations or parents can draw from the
archive to inject structured diversity, e.g., propor-
tional to the rank of all elites in the grid or uni-
formly over filled cells. The archive thus comple-
ments island dynamics by probing diverse niches
and reducing premature convergence. The pseu-
docode (Algo. 1) omits archive maintenance for
readability as implementation is straightforward.
5
Experiments
We evaluate CODEEVOLVE on a set of mathemat-
ical problems from the benchmark suite used to
validate AlphaEvolve (Novikov et al., 2025). We
are interested in answering the following questions:
RQ1 Can CODEEVOLVE advance the state of the
art in automated algorithmic discovery?
RQ2 Can smaller open-weight models compete
with more expensive, closed-source LLMs as
the backbone of CODEEVOLVE?
RQ3 How do the different components of CODEE-
VOLVE impact its performance on the pro-
posed benchmarks?
5.1
Benchmark Problems
Following AlphaEvolve (Novikov et al., 2025), we
evaluate CODEEVOLVE on a number of open prob-
lems from mathematics and algorithm design. We
now briefly describe each problem.
Packing Circles and Hexagons.
This bench-
mark consists of three distinct problems, referred to
as CirclePackingSquare, CirclePackingRect
and HexagonPacking. The first problem consists
of placing n disjoint unit circles inside a unit square
in order to maximize the sum of their radii, with
instances n = 26 and n = 32. The second consists
of placing n disjoint unit circles inside a rectangle
of perimeter 4 in order to maximize the sum of their
radii, with n = 21. The third asks for a placement
of n disjoint unit regular hexagons into a larger
regular hexagon, minimizing the side length of the
outer hexagon, with n = 11 and n = 12.
Minimizing ratio of maximum to minimum dis-
tance.
This benchmark consists of placing n d-
dimensional points in order to minimize the ratio
between their maximum to minimum distance, re-
ferred to as MinimizeMaxMinDist, with instances
n = 16, d = 2 and n = 14, d = 3.
Autocorrelation Inequalities.
This benchmark
encompasses two distinct optimization prob-
lems, referred to as FirstAutocorrIneq and
SecondAutocorrIneq, related to constructing
step-functions to improve certain convolution
bounds that arise in additive combinatorics. The
first problem is a minimization problem, and the
second is a maximization one. See Appendix A for
further details.
5.2
Experimental setup
All experiments were conducted using AWS Sage-
maker. To ensure fair resource allocation, each
experimental run was assigned a fixed computa-
tional budget of vCPUS and RAM, with each so-
lution being evaluated with a maximum runtime
and memory budget.
For the LLM ensemble,
we utilized API endpoints for GEMINI-2.5 and
Qwen3-Coder-30B. See Appendix C for a complete
description of our setup for each experiment.
To provide a rigorous assessment of CODEE-
VOLVE, we use Google DeepMind’s AlphaE-
volve (Novikov et al., 2025) as our primary base-
line, as it currently defines the state-of-the-art for
this benchmark suite. We further compare CODEE-
VOLVE against ThetaEvolve (Wang et al., 2025),
5


--- Page 6 ---
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
AlphaEvolve
26 circles, sum of radii = 2.63586
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
CodeEvolve
26 circles, sum of radii = 2.63598
Figure 2:
Comparison of best solutions found by
CODEEVOLVE and AlphaEvolve for the CirclePack-
ingSquare problem with n = 26.
AlphaEvolve
16 points, ratio ~ sqrt(12.88927)
maximum distance
minimum distance
CodeEvolve
16 points, ratio ~ sqrt(12.88923)
maximum distance
minimum distance
Figure 3:
Comparison of best solutions found by
CODEEVOLVE and AlphaEvolve for both instances of
the MinimizeMaxMinDist problem.
an open-source framework for algorithmic discov-
ery that relies on RL-tuning. While other frame-
works such as OpenEvolve (Sharma, 2025) and
ShinkaEvolve (Lange et al., 2025) exist, they only
report results for a single instance in our suite
(CirclePackingSquare (n = 26)); for this spe-
cific case, ShinkaEvolve matches our results while
OpenEvolve is slightly inferior. Consequently, we
focus our comparative analysis on AlphaEvolve
and ThetaEvolve to provide a broader view of per-
formance across diverse problem domains.
5.3
Main Results
As shown in Table 1, CODEEVOLVE matches or
surpasses the results reported for AlphaEvolve
in 5 out of 9 benchmark instances.
Notably,
in the MinimizeMaxMinDist and CirclePacking-
Square (n = 32) instances, CODEEVOLVE estab-
lishes new state-of-the-art marks. While ThetaE-
volve performs strongly on the Autocorrelation
inequalities, it lacks reported results on all other
benchmarks except for one of the CirclePacking-
Square instances. In contrast, CODEEVOLVE’s
consistency across packing and distance optimiza-
tion problems demonstrates its robustness as a dis-
covery engine, and also its ability to advance the
7.55.02.50.02.55.0
10
5
0
5
5
0
5
AlphaEvolve
14 points, ratio ~ sqrt(4.16585)
maximum distance
minimum distance
0.0 0.2 0.4 0.6 0.8
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
CodeEvolve
14 points, ratio ~ sqrt(4.16579)
maximum distance
minimum distance
Figure 4:
Comparison of best solutions found by
CODEEVOLVE and AlphaEvolve for both instances of
the MinimizeMaxMinDist problem.
state-of-the-art, answering RQ1 in the affirmative.
For both CirclePackingSquare problem in-
stances, the Qwen3 configuration presented the
best results (one of them illustrated in Fig-
ure 2), surpassing the configuration using an en-
semble of GEMINI-2.5 FLASH/PRO, whereas the
GEMINI-2.5 Ensemble produced the best results
for the CirclePackingRect problem and for the
two instances of the MinimizeMaxMinDist prob-
lem (shown in Figure 3).
Figure 5 shows the
solution history for the n = 26 instance, with
Qwen3-Coder-30B on the left and GEMINI-2.5
on the right. The Qwen3 configuration requires
around 900 LLM calls to surpass AlphaEvolve’s
solution, with a total API cost of approximately
6 USD, whereas the GEMINI-2.5 configuration
needs approximately 400 LLM calls and costs
a little under 35 USD. A similar behavior in
terms of LLM calls and cost can be observed
for the CirclePackingSquare (n=32) (see Ap-
pendix B.2). This order-of-magnitude difference in
cost-efficiency suggests that, for well-defined algo-
rithmic tasks, modular orchestration—rather than
raw model scale—is the primary driver of success,
answering RQ2 in the affirmative.
5.4
Ablations
To evaluate the individual contributions of CODEE-
VOLVE’s components, we conduct an extensive
ablation study using the CirclePackingSquare
benchmark. This problem was selected due to its
computational efficiency and its status as a stan-
dard comparison point in recent literature (Sharma,
2025; Lange et al., 2025; Wang et al., 2025). To
maintain a sustainable experimental budget, all
ablations use Qwen3-Coder-30B as the backbone
model. In these analyses, we report the best and
worst results across runs rather than standard devi-
6


--- Page 7 ---
Table 1: Results comparison between CODEEVOLVE, AlphaEvolve and ThetaEvolve. We display only the best
results reported in the respective articles.
Problem
AlphaEvolve
ThetaEvolve
CODEEVOLVE
Distill-Qwen3-8B
Qwen3-Coder-30B
GEMINI-2.5 FLASH/PRO
CirclePackingSquare(n = 26) (↑)
2.63586
2.63598
2.63598
2.63597
CirclePackingSquare(n = 32) (↑)
2.93794
—
2.93954
2.93950
CirclePackingRect(n = 21) (↑)
2.36583
—
2.36339
2.36583
HexagonPacking(n = 11) (↓)
3.93009
—
4.07507
3.93794
HexagonPacking(n = 12) (↓)
3.94191
—
4.02519
4.00001
MinimizeMaxMinDist(n = 16, d = 2) (↓)
12.88927
—
13.43612
12.88923
MinimizeMaxMinDist(n = 14, d = 3) (↓)
4.16585
—
4.20692
4.16579
FirstAutocorrIneq (↓)
1.50316
1.50313
1.55837
1.55438
SecondAutocorrIneq (↑)
0.96102
0.94690
0.88110
0.87067
0
500
1000
1500
2000
Number of Evaluated LLM Solutions
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Target Score
0
1
2
3
4
5
6
Cumulative API cost (USD)
Solution history for CirclePackingSquare(n=26) with Qwen3-Coder-30B
Correct solutions
Best Score
Cumulative cost
AlphaEvolve
0
100
200
300
400
Number of Evaluated LLM Solutions
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Target Score
0
5
10
15
20
25
30
35
Cumulative API cost (USD)
Solution history for CirclePackingSquare(n=26) with GEMINI-2.5
Correct solutions
Best Score
Cumulative cost
AlphaEvolve
Figure 5: Comparison between Qwen3-Coder-30B and GEMINI-2.5 in CirclePackingSquare (n = 26). Left
vertical axis shows −log(M −y + ϵ), where M is the maximum fitness attained in all experiments, y is the best
fitness, and ϵ = 10−3 is a constant controlling space between curves. Individual points show the score of solutions
that were executed without errors. Right vertical axis displays the cumulative API cost in USD of the LLM calls.
ation. In the context of algorithmic discovery, we
argue this is more instructive: our main goal is to
exceed existing state-of-the-art results, and aggre-
gate metrics can mask the “breakthrough” runs that
successfully surpass AlphaEvolve. Furthermore,
given that each experiment is executed 3 times,
the standard deviation is an unreliable estimator
of population variance; reporting the full range of
outcomes provides a more transparent and represen-
tative view of the framework’s peak potential and
its reliability. See Appendix C for further details.
Impact of components
In order to evaluate the
impact of the components described in Section 4,
we evaluated CODEEVOLVE on three distinct con-
figurations: (i) “full method”, utilizes all operators
implemented by CODEEVOLVE; (ii) “naive evolu-
tion”, utilizes the standard exploration/exploitation
pipeline, without any of the aforementioned compo-
nents; and (iii) “no evolution”, repeatedly prompts
the LLM with the initial prompt and solution, with
no contextual data from other solutions.
Figure 6 shows the ablation results for the Cir-
clePackingSquare problem. On both instances,
we see that “full method” outperforms the other
configurations both in terms of mean score and
LLM calls required to surpass AlphaEvolve (sam-
ple efficiency). For the n = 32 case, it is the
only configuration that manages to surpass AlphaE-
volve’s results, and for the n = 26 case, the Naive
configuration also matches it, requiring, however,
over twice the number of solutions to do so. This
shows that, in regards to RQ3, CODEEVOLVE’s
components not only increase overall performance,
but are the enabling factor that allows the frame-
work to obtain state-of-the-art results.
Impact of depth and inspirations
We study the
impact of two hyperparameters of the operators de-
scribed in Section 4.2 for the n = 32 instance of
the CirclePackingSquare problem, namely: (i)
maximum ancestor depth k used in the Depth Ex-
ploitation operator, and (ii) number ι of inspiration
solutions used in the Inspiration-based Crossover
7


--- Page 8 ---
0
500
1000
1500
2000
2500
Number of Evaluated LLM Solutions
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Target Score
Component ablation for CirclePackingSquare(n=26)
full method
naive evolution
no evolution
AlphaEvolve
0
200
400
600
800
1000
Number of Evaluated LLM Solutions
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Target Score
Component ablation for CirclePackingSquare(n=32)
full method
naive evolution
no evolution
AlphaEvolve
Figure 6: Component ablations for CODEEVOLVE using Qwen3-Coder-30B on the CirclePackingSquare problem.
Curves show the mean across three distinct runs, and shaded regions show the best and worst results across all runs.
0
200
400
600
800
1000
Number of Evaluated LLM Solutions
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Target Score
Depth ablation for CirclePackingSquare(n=32)
full method
Depth = 0
Depth = 3
Depth = 5
Unlimited Depth
AlphaEvolve
0
200
400
600
800
1000
Number of Evaluated LLM Solutions
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Target Score
Inspiration ablation for CirclePackingSquare(n=32)
full method
No Inspirations
1 Inspiration
2 Inspirations
3 Inspirations
AlphaEvolve
Figure 7: Depth and Inspiration ablations for CODEEVOLVE using Qwen3-Coder-30B on the CirclePacking-
Square problem with n = 32.
operator. In order to control for the impact that
these two operators may have on each other, we set
ι = 0 for (i) and, conversely, set k = 0 for (ii). We
also show the results for the “full method” config-
uration of the previous experiment to analyze the
synergy between these two operators.
As shown in Figure 7, all depth configurations
failed to exceed AlphaEvolve’s results, but inspi-
ration configurations (ι = 2, 3) succeeded. Conse-
quently, for RQ3, the Inspiration-based Crossover
can independently surpass AlphaEvolve, unlike the
Depth Exploitation operator. However, in both
scenarios we see that the “full method” curve out-
performs all other configurations in mean value,
while also requiring less LLM calls to surpass the
SOTA, thus highlighting a positive synergistic be-
havior between these two components. Additional
ablation studies in Appendix B.1 demonstrate the
importance of MAP-Elites and migration topology.
6
Conclusion
We introduced CODEEVOLVE, an open-source
framework that democratizes the search for novel
algorithms. By integrating an islands-based ge-
netic algorithm with modular LLM operators—
specifically inspiration-based crossover and meta-
prompting—CODEEVOLVE bridges the gap be-
tween opaque, large-scale systems and accessible
research tools. Our experiments demonstrate that
CODEEVOLVE consistently matches or exceeds
the performance of closed-source baselines like
AlphaEvolve. Perhaps most significantly, our re-
sults show that high-performing open-weight mod-
els, when properly orchestrated, offer a transparent
and cost-effective alternative to proprietary APIs.
CODEEVOLVE provides a foundation for future
work in automated scientific discovery, enabling
the community to iterate on search strategies and
model ensembles within a reproducible framework.
8


--- Page 9 ---
Limitations
While CODEEVOLVE achieves state-of-the-art re-
sults, several limitations remain. First, budget con-
straints prevented a full-scale ablation study using
the Gemini ensemble; however, the success of the
Qwen-based ablations suggests the architectural
benefits are model-agnostic. For the same reason,
we opted for listing the reported results for ThetaE-
volve, ShinkaEvolve and AlphaEvolve, rather than
attempting to reproduce them. Third, while our
operators are effective, there is significant potential
for “heterogeneous orchestration,” such as using
a frontier model (e.g., Gemini Pro) for the meta-
prompting stage to distill complex insights, while
using a smaller, faster model for iterative exploita-
tion. Fourth, the current framework uses static
hyperparameters for LLM generation; future iter-
ations could explore dynamic scheduling of tem-
perature and top-p values to adaptively control the
creativity-precision trade-off during the search pro-
cess. Fifth, the framework introduces new hyper-
parameters (e.g., migration topology, number of
islands, number of inspirations, maximum ancestor
depth) that require tuning; while we provide ro-
bust defaults, performance on novel domains may
require specific calibration. Finally, while we re-
duce costs compared to manual discovery, the in-
ference budget for large-scale evolution remains
non-trivial, potentially limiting accessibility for re-
searchers with constrained compute resources.’
Acknowledgments
The authors thank Bruno Grossi for reviewing this
paper and for the continuous support during the de-
velopment of this project. We also thank Fernando
Augusto and Tiago Machado for the useful con-
versations about possible applications of CODEE-
VOLVE at Inter.
Author Contributions
H.A. started the project, designed and implemented
the core features of CODEEVOLVE, and conducted
experiments on all of the proposed benchmarks.
D.F. implemented the benchmarks related to analy-
sis and the code for the solution evaluator, and also
conducted experiments for problem P1. L.C. and
F.M. were involved in design discussions about the
main components of CODEEVOLVE, as well as the
analysis of the experimental results. H.A. and F.M.
wrote the manuscript, and D.F. drafted preliminary
versions of the two first sections. L.C. and F.M.
were responsible for multiple rounds of revisions
before the final submission
References
Sotiris Anagnostidis and Jannis Bulian. 2024. How sus-
ceptible are llms to influence in prompts? Preprint,
arXiv:2408.11865.
Peter Belcak, Greg Heinrich, Shizhe Diao, Yonggan
Fu, Xin Dong, Saurav Muralidharan, Yingyan Ce-
line Lin, and Pavlo Molchanov. 2025. Small lan-
guage models are the future of agentic ai. Preprint,
arXiv:2506.02153.
Davis Brown, Jesse He, Helen Jenne, Henry Kvinge,
and Max Vargas. 2025.
Even with ai, bijection
discovery is still hard: The opportunities and chal-
lenges of openevolve for novel bijection construction.
Preprint, arXiv:2511.20987.
Angelica Chen, David M. Dohan, and David R. So.
2023. EvoPrompting: Language models for code-
level neural architecture search. In Advances in Neu-
ral Information Processing Systems.
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan,
and others Penedones, Henrique and. 2021. Evalu-
ating large language models trained on code. arXiv
preprint arXiv:2107.03374.
Audrey Cheng, Shu Liu, Melissa Pan, Zhifei Li,
Bowen Wang, Alex Krentsel, Tian Xia, Mert Cemri,
Jongseok Park, Shuo Yang, Jeff Chen, Lakshya
Agrawal, Aditya Desai, Jiarong Xing, Koushik Sen,
Matei Zaharia, and Ion Stoica. 2025. Barbarians
at the gate: How ai is upending systems research.
Preprint, arXiv:2510.06189.
Gheorghe Comanici, Eric Bieber, Mike Schaekermann,
Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Mar-
cel Blistein, Ori Ram, Dan Zhang, Evan Rosen, Luke
Marris, Sam Petulla, Colin Gaffney, Asaf Aharoni,
Nathan Lintz, Tiago Cardal Pais, Henrik Jacobs-
son, Idan Szpektor, Nan-Jiang Jiang, and 3290 oth-
ers. 2025. Gemini 2.5: Pushing the frontier with
advanced reasoning, multimodality, long context,
and next generation agentic capabilities. Preprint,
arXiv:2507.06261.
Alhussein Fawzi, Matej Balog, Alexander Huang,
Thomas Hubert, Bernardino Romera-Paredes, and
1 others. 2022. Discovering faster matrix multiplica-
tion algorithms with reinforcement learning. Nature,
610(7930):47–53.
Bogdan Georgiev, Javier Gómez-Serrano, Terence
Tao, and Adam Zsolt Wagner. 2025.
Mathemat-
ical exploration and discovery at scale. Preprint,
arXiv:2511.02864.
Jonas Gottweis, Wen-Hao Weng, Aleksandr Daryin,
Tuan Tu, Anirudh Palepu, and 1 others. 2025.
Towards an ai co-scientist.
arXiv preprint
arXiv:2502.18864.
9


--- Page 10 ---
Erik Hemberg, Stephen Moskal, and Una-May O’Reilly.
2024. Evolving code with a large language model.
Genetic Programming and Evolvable Machines,
25(2):21.
John R Koza. 1992. Genetic programming: on the
programming of computers by means of natural se-
lection, volume 1. MIT press.
John R. Koza. 1994. Genetic programming as a means
for programming computers by natural selection.
Statistics and Computing, 4(2):87–112.
William B Langdon and Riccardo Poli. 2013. Founda-
tions of genetic programming. Springer Science &
Business Media.
Robert Tjarko Lange, Yuki Imajuku, and Edoardo
Cetin. 2025. Shinkaevolve: Towards open-ended and
sample-efficient program evolution. arXiv preprint
arXiv:2509.19349.
Joel Lehman, Jonathan Gordon, Shreyas Jain, Kenz
Ndousse, Christine Yeh, and Kenneth O Stanley.
2023. Evolution through large models. In Handbook
of Evolutionary Machine Learning, pages 331–366.
Springer.
Yujia Li, David Choi, Junyoung Chung, Nate Kush-
man, Julian Schrittwieser, and 1 others. 2022.
Competition-level code generation with alphacode.
Science, 378(6624):1092–1097.
Haowei Lin, Haotian Ye, Wenzheng Feng, Quzhe
Huang, Yujun Li, Hubert Lim, Zhengrui Li, Xiangyu
Wang, Jianzhu Ma, James Zou, and Yitao Liang.
2025. Can language models discover scaling laws?
Preprint, arXiv:2507.21184.
S. Lloyd. 1982.
Least squares quantization in
pcm.
IEEE Transactions on Information Theory,
28(2):129–137.
Mate Matolcsi and Carlos Vinuesa. 2009.
Im-
proved bounds on the supremum of autoconvolutions.
Preprint, arXiv:0907.1379.
Jean-Baptiste Mouret and Jeff Clune. 2015.
Illumi-
nating search spaces by mapping elites. Preprint,
arXiv:1504.04909.
Kirill Nagaitsev, Luka Grbcic, Samuel Williams, and
Costin Iancu. 2025.
Optimizing pytorch infer-
ence with llm-based multi-agent systems. Preprint,
arXiv:2511.16964.
Ansh Nagda, Prabhakar Raghavan, and Abhradeep
Thakurta. 2025. Reinforced generation of combina-
torial structures: Applications to complexity theory.
Preprint, arXiv:2509.18057.
Alexander Novikov, Ngân V˜u, Marvin Eisenberger, Em-
ilien Dupont, Po-Sen Huang, Adam Zsolt Wagner,
Sergey Shirobokov, Borislav Kozlovskii, Francisco
J. R. Ruiz, Abbas Mehrabian, M. Pawan Kumar, Abi-
gail See, Swarat Chaudhuri, George Holland, Alex
Davies, Sebastian Nowozin, Pushmeet Kohli, and
Matej Balog. 2025. Alphaevolve: A coding agent
for scientific and algorithmic discovery. Preprint,
arXiv:2506.13131.
Bernardino Romera-Paredes, Mohammad Barekatain,
Alexander Novikov, Matej Balog, M. Pawan Ku-
mar, Emilien Dupont, Francisco J. R. Ruiz, Jor-
dan S. Ellenberg, Pengming Wang, Omar Fawzi, and
1 others. 2023. Mathematical discoveries from pro-
gram search with large language models. Nature,
624(7992):545–552.
Bernardino
Romera-Paredes,
Mohammadamin
Barekatain,
Alexander Novikov,
Matej Balog,
M. Pawan Kumar, Emilien Dupont, Francisco J. R.
Ruiz, Jordan S. Ellenberg, Pengming Wang, Omar
Fawzi, Pushmeet Kohli, and Alhussein Fawzi. 2024.
Mathematical discoveries from program search with
large language models. Nature, 625(7995):468–475.
Asankhaya Sharma. 2025. Openevolve: an open-source
evolutionary coding agent.
Mirac Suzgun and Adam Tauman Kalai. 2024. Meta-
prompting: Enhancing language models with task-
agnostic scaffolding. Preprint, arXiv:2401.12954.
Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-
Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan
Schalkwyk, Andrew M. Dai, Anja Hauth, Katie
Millican, David Silver, Melvin Johnson, Ioannis
Antonoglou, Julian Schrittwieser, Amelia Glaese,
Jilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki
Lazaridou, and 1332 others. 2025. Gemini: A fam-
ily of highly capable multimodal models. Preprint,
arXiv:2312.11805.
Vassilis Vassiliades, Konstantinos Chatzilygeroudis,
and Jean-Baptiste Mouret. 2017.
Using cen-
troidal voronoi tessellations to scale up the multi-
dimensional archive of phenotypic elites algorithm.
Preprint, arXiv:1610.05729.
Yiping Wang, Shao-Rong Su, Zhiyuan Zeng, Eva
Xu, Liliang Ren, Xinyu Yang, Zeyi Huang, Xue-
hai He, Luyao Ma, Baolin Peng, Hao Cheng,
Pengcheng He, Weizhu Chen, Shuohang Wang, Si-
mon Shaolei Du, and Yelong Shen. 2025. Thetae-
volve:
Test-time learning on open problems.
Preprint, arXiv:2511.23473.
Darrell Whitley and Timothy Starkweather. 1990. Geni-
tor ii.: a distributed genetic algorithm. J. Exp. Theor.
Artif. Intell., 2(3):189–214.
An Yang, Anfeng Li, Baosong Yang, Beichen Zhang,
Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao,
Chengen Huang, Chenxu Lv, Chujie Zheng, Day-
iheng Liu, Fan Zhou, Fei Huang, Feng Hu, Hao
Ge, Haoran Wei, Huan Lin, Jialong Tang, and 41
others. 2025.
Qwen3 technical report.
Preprint,
arXiv:2505.09388.
10


--- Page 11 ---
Zhaojian Yu, Kaiyue Feng, Yilun Zhao, Shilin He, Xiao-
Ping Zhang, and Arman Cohan. 2025.
Alphare-
search: Accelerating new algorithm discovery with
language models. Preprint, arXiv:2511.08522.
Yifan Zhang, Yang Yuan, and Andrew Chi-Chih Yao.
2025.
Meta prompting for ai systems.
Preprint,
arXiv:2311.11482.
A
Benchmark Problems
In this section, we provide further details about
some of the problems used to evaluate CODEE-
VOLVE.
A.1
First Autocorrelation Inequality
Let C1 be the largest constant such that
max
−1/2 ≤t ≤1/2(f ∗f)(t) ≥C1
 Z 1/4
−1/4
f(x)dx
!2
,
for all nonnegative functions f : R 7→R, where
f ∗f denotes the convolution operation. Upper
bounds on C1 can be obtained by explicitly con-
structing step-functions (Matolcsi and Vinuesa,
2009), thus we wish to create an algorithm that
generates a nonnegative step function that mini-
mizes the ratio between max−1/2≤t≤1/2(f ∗f)(t)
and (
R 1/4
−1/4 f(x)dx)2.
A.2
Second Autocorrelation Inequality
Let C2 be the smallest constant satisfying
∥f ∗f∥2
2 ≤C∥f ∗f∥1∥f ∗f∥∞,
for all nonnegative functions f : R 7→R, where
∥· ∥p denotes the p-norm of a given function, and
f ∗f denotes the convolution operation. Hölder’s
inequality immediately yields C2 ≤1, and mathe-
maticians have been attempting to bound C2 from
below by constructing explicit step functions (Ma-
tolcsi and Vinuesa, 2009). The task at hand is thus
to create an algorithm that generates a nonnega-
tive step function that maximizes the ratio between
∥f ∗f∥2
2 and ∥f ∗f∥1∥f ∗f∥∞.
B
Supplemental experiments and results
In this section, we provide supplemental experi-
mental results using CODEEVOLVE.
B.1
Further ablations
Impact of MAP-Elites
In this experiment, we
evaluate the performance of CODEEVOLVE us-
ing three distinct elite selection policies:
(i)
the centroidal Voronoi tesselations MAP-Elites
0
200
400
600
800
1000
Number of Evaluated LLM Solutions
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Target Score
Elite selection ablation for CirclePackingSquare(n=32)
CVT
Grid
Naive
AlphaEvolve
Figure 8: Elite selection ablations for CODEEVOLVE us-
ing Qwen3-Coder-30B on the CirclePackingSquare
problem with n = 32.
method (Vassiliades et al., 2017), referred to as CVT,
is a variant of the MAP-Elites (Mouret and Clune,
2015) algorithm, in which the feature space is par-
titioned according to a fixed number of centroids
that approximate a centroidal Voronoi tesselation,
e.g., by means of Lloyd’s algorithm (Lloyd, 1982);
(ii) the traditional MAP-Elites method, referred to
as Grid, in which the feature space is partitioned
according to a regular lattice; and (iii) a naive elite
selection, referred to as Naive, in which we define
a maximum population cap and only add a new so-
lution/prompt if its fitness is greater than the fitness
of the worst live individual.
Figure 8 shows the results of this experiment for
the CirclePackingSquare problem with n = 32.
The most notable finding is that the MAP-Elites
method is clearly necessary for surpassing AlphaE-
volve’s results, and moreover, the CVT variant dis-
plays the best performance both in terms of sample
efficiency and mean score.
Choice of island topology
In this experiment,
we vary the underlying migration topology in or-
der to assess its impact on the performance of
CODEEVOLVE. We consider three distinct topolo-
gies: (i) the Cycle topology connects the N islands
according to the undirected cycle graph CN, i.e.,
if {0, ..., N −1} are the island indices, then is-
land i can send and receive migrants from islands
i−1 mod N and i+1 mod N; (ii) the Complete
topology connects the islands according to the undi-
rected complete graph KN, i.e., all islands can send
an receive migrants from one another; and (iii) the
Empty topology does not connect any of the islands,
thus supressing migration.
Figure 9 shows that, for the CirclePacking-
11


--- Page 12 ---
0
200
400
600
800
1000
Number of Evaluated LLM Solutions
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Target Score
Migration topology ablation for CirclePackingSquare(n=32)
Cycle
Complete
Empty
AlphaEvolve
Figure 9: Migration topology ablations for CODEE-
VOLVE using Qwen3-Coder-30B on the CirclePack-
ingSquare problem with n = 32.
Square problem with n = 32, the Cycle configura-
tion is the only one able to surpass AlphaEvolve’s
results, with the Complete topology only being
slightly superior to the Empty topology in mean
score. This shows that migration between islands
clearly plays a crucial role in producing state-of-
the-art results, but also that excessively migrating
between islands can be detrimental, as the overall
diversity tends to decrease.
B.2
Cost and Runtime comparison
In this section, we provide further information
about the cost and runtime of our experiments. Fig-
ure 10 shows the solution and cost history for both
ensemble configurations in the n = 32 instance
of the CirclePackingSquare problem. As dis-
cussed in Section 5, we again see that, although
Qwen3-Coder-30B presents a smaller sample effi-
ciency when compared to GEMINI-2.5, it not only
finds the best performing solution but does so at
almost 10% of the cost.
Table 2 provides approximate costs and runtimes
for the best runs of both ensemble configurations
on the considered benchmarks. Overall, we can
easily see that Qwen3 is significantly less expen-
sive when compared to GEMINI-2.5. The runtime
varies between problems, as it mainly depends on
the evaluation timeout and number of islands being
used (see Table 3), but overall it remains similar be-
tween configurations. For the costs and runtimes of
all experiments conducted, including the multiple
runs done for the ablation studies, see https://
github.com/inter-co/science-codeevolve.
C
Experiment Details
In this section, we provide further details about the
configurations used in our experiments. CODEE-
VOLVE’s components have many different parame-
ters, so we only list the most important ones here.
For the complete configuration files, see https://
github.com/inter-co/science-codeevolve.
Ensemble configurations.
All experiments with
the Qwen3-Coder-3B model use a temperature of
0.7 and top-p of 0.8. The ensemble with GEMINI
2.5 FLASH/PRO uses temperatures of 0.7 and top-p
of 0.95 for both models. During exploration steps,
we only call the FLASH variant, and during exploita-
tion steps, we call FLASH with 60% probability and
PRO with 40% probability by default.
CODEEVOLVE
hyperparameters
Table
3
shows the hyperparameters for the best runs of
CODEEVOLVE on the proposed benchmarks. By
default, we start with an exploration probability
of 0.2, and use the Plateau Scheduler to increase
this probability by a multiplicative factor of 1.05
if no fitness increase is observe for 5 epochs,
and decrease it by 0.95 otherwise, preserving a
minimum rate of 0.2 and a maximum rate of 0.5.
12


--- Page 13 ---
0
200
400
600
800
Number of Evaluated LLM Solutions
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Target Score
0.0
0.5
1.0
1.5
2.0
Cumulative API cost (USD)
Solution history for CirclePackingSquare(n=32) with Qwen3-Coder-30B
Correct solutions
Best Score
Cumulative cost
AlphaEvolve
0
50
100
150
200
250
Number of Evaluated LLM Solutions
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Target Score
0.0
2.5
5.0
7.5
10.0
12.5
15.0
17.5
Cumulative API cost (USD)
Solution history for CirclePackingSquare(n=32) with GEMINI-2.5
Correct solutions
Best Score
Cumulative cost
AlphaEvolve
Figure 10: Solution and cost history of Qwen3-Coder-30B and GEMINI-2.5 in the CirclePackingSquare problem
with n = 32.
Table 2: Cost and time comparison between Qwen3-Coder-30B and GEMINI-2.5 for the best runs of CODEEVOLVE
on the benchmark problems.
Problem
Qwen3-Coder-30B
GEMINI-2.5
Cost (USD)
Time (Hours)
Cost (USD)
Time (Hours)
CirclePackingSquare(n = 26)
6.5
6.2
34.5
6.1
CirclePackingSquare(n = 32)
2.1
2.2
17.2
7.5
CirclePackingRect(n = 21)
11.4
15.3
67.5
11.1
HexagonPacking(n = 11)
6.2
16.0
73.7
17.5
HexagonPacking(n = 12)
6.1
14.5
77.4
15.6
MinimizeMaxMinDist(n = 16, d = 2)
4.9
21.7
51.5
15.7
MinimizeMaxMinDist(n = 14, d = 3)
9.6
10.9
54.4
13.1
FirstAutocorrIneq
9.7
15.3
70.8
17.3
SecondAutocorrIneq
6.7
14.5
66.7
18.7
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
AlphaEvolve
32 circles, sum of radii = 2.93794
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
CodeEvolve
32 circles, sum of radii = 2.93956
Figure 11: Comparison of best solutions found by
CODEEVOLVE and AlphaEvolve for the CirclePack-
ingSquare problem with n = 32.
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
1.0
AlphaEvolve
21 circles, Perimeter: 4.0
sum of radii = 2.36583
0.0
0.2
0.4
0.6
0.8
0.0
0.2
0.4
0.6
0.8
1.0
CodeEvolve
21 circles, Perimeter: 4.0
sum of radii = 2.36583
Figure 12:
Comparison of best solutions found
by
CODEEVOLVE
and
AlphaEvolve
for
the
CirclePackingRect problem with n = 21.
13


--- Page 14 ---
Table 3: Hyperparameters used in the best runs of CODEEVOLVE for the proposed benchmarks.
Problem
Hyperparameters
Model
Islands
Epochs
Depth
Inspirations
CPUs
Evaluation (s)
Evaluation
Timeout (s)
Max Memory (GB)
CirclePackingSquare(n = 26)
Qwen3-Coder-30B
10
250
5
2
10
60
1
CirclePackingSquare(n = 32)
Qwen3-Coder-30B
10
100
5
2
10
60
1
CirclePackingRect(n = 21)
GEMINI-2.5
5
200
5
2
10
60
1
HexagonPacking(n = 11)
GEMINI-2.5
5
200
Unlimited
3
10
180
5
HexagonPacking(n = 12)
GEMINI-2.5
5
200
Unlimited
3
10
180
5
MinimizeMaxMinDist(n = 16, d = 2)
GEMINI-2.5
5
200
Unlimited
3
10
180
5
MinimizeMaxMinDist(n = 14, d = 3)
GEMINI-2.5
10
100
Unlimited
3
20
360
5
FirstAutocorrIneq
GEMINI-2.5
5
200
Unlimited
3
10
180
5
SecondAutocorrIneq
Qwen3-Coder-30B
10
250
5
3
10
90
5
14
