--- Page 1 ---
LM4Opt-RA: A Multi-Candidate LLM Framework
with Structured Ranking for Automating Network
Resource Allocation
Tasnim Ahmed
School of Computing
Queen’s University
Kingston, Ontario, Canada K7L 2N8
tasnim.ahmed@queensu.ca
Siana Rizwan
School of Computing
Queen’s University
Kingston, Ontario, Canada K7L 2N8
siana.rizwan@queensu.ca
Naveed Ejaz
School of Computing
Queen’s University
Kingston, Ontario, Canada K7L 2N8
ht57@queensu.ca
Salimur Choudhury
School of Computing
Queen’s University
Kingston, Ontario, Canada K7L 2N8
s.choudhury@queensu.ca
December 2, 2025
Abstract
Building on advancements in Large Language Models (LLMs), we can tackle complex
analytical and mathematical reasoning tasks requiring nuanced contextual understanding.
A prime example of such complex tasks is modelling resource allocation optimization in
networks, which extends beyond translating natural language inputs into mathematical
equations or Linear Programming (LP), Integer Linear Programming (ILP), and Mixed-
Integer Linear Programming (MILP) models. However, existing benchmarks and datasets
cannot address the complexities of such problems with dynamic environments, interdependent
variables, and heterogeneous constraints. To address this gap, we introduce NL4RA, a curated
dataset comprising 50 resource allocation optimization problems formulated as LP, ILP, and
MILP. We then evaluate the performance of well-known open-source LLMs with varying
parameter counts. To enhance existing LLM based methods, we introduce LM4Opt RA,
a multi candidate framework that applies diverse prompting strategies such as direct, few
shot, and chain of thought, combined with a structured ranking mechanism to improve
accuracy. We identified discrepancies between human judgments and automated scoring
such as ROUGE, BLEU, or BERT scores. However, human evaluation is time-consuming
and requires specialized expertise, making it impractical for a fully automated end-to-end
framework. To quantify the difference between LLM-generated responses and ground truth,
we introduce LLM-Assisted Mathematical Evaluation (LAME), an automated metric designed
for mathematical formulations. Using LM4Opt-RA, Llama-3.1-70B achieved a LAME score
of 0.8007, outperforming other models by a significant margin, followed closely by Llama-3.1-
8B. While baseline LLMs demonstrate considerable promise, they still lag behind human
expertise; our proposed method surpasses these baselines regarding LAME and other metrics.
Keywords Large Language Models · LLM-as-a-judge · Mathematical Formulation · Network Resource
Allocation · Optimization · Linear Programming.
arXiv:2512.00039v1  [cs.NI]  13 Nov 2025


--- Page 2 ---
Preprint - December 2, 2025
1
Introduction
Networks are evolving to support a wide range of heterogeneous applications in increasingly diverse and
dynamic environments. These modern networks accommodate IoT devices, vehicular communications, mobile
edge computing, automated industries, remote telemedicine, and smart cities [1, 2]. Consequently, the demand
for faster, more reliable, and low-latency connections has intensified, as these services require varying levels of
Quality of Service (QoS) [3]. To achieve maximum performance and provide a good user experience in networks,
their resources must be dynamically and efficiently allocated to meet the continuously changing demands
regarding power control, bandwidth allocation, deployment strategies, association allocation, etc.[4, 5]. The
performance of a network largely depends on how its resources are allocated. Linear Programming (LP),
Integer Linear Programming (ILP), and Mixed-Integer Linear Programming (MILP) are commonly used to
formulate resource allocation problems in networks [6]. LP addresses problems with continuous variables, ILP
handles problems with integer variables, and MILP tackles problems involving both continuous and integer
variables [7].
Formulating a network resource allocation problem into LP, ILP, or MILP requires significant mathematical
expertise and in-depth knowledge of the problem domain, and it is often time-consuming [8]. With the growing
popularity of Large Language Models (LLMs), some researchers have investigated methods to automate the
formulation of optimization problems using LLMs. Some of the recent works suggest that LLMs can formulate
and solve linear programming problems adequately using natural language description [9, 10, 11, 12]. This
early success of LLMs indicates their potential to simplify the process of problem formulation and solution
in operations research, including network resource allocation, which falls under the broader category of
similar mathematical optimization problems. By automating the generation and solving of mathematical
formulation, LLM-based frameworks can effectively reduce the need for extensive mathematical expertise,
allowing professionals or stakeholders to focus on listing resources and constraints. This approach lowers the
resource allocation cost and improves the efficiency and accuracy of translating complex real-world problems
into solvable mathematical formats, advancing quicker solution development and innovation.
Existing benchmarks for optimization modeling, such as NL4Opt, MAMO, and IndustryOR, focus predom-
inantly on generalized optimization tasks, often constrained to LP or elementary MILP problems. These
datasets fail to encompass the heterogeneity and real-time adaptation requirements inherent in modern
network resource allocation. Furthermore, current LLM-based frameworks exhibit limitations in generating
solver-specific code and handling unstructured problem descriptions. Consequently, there remains a critical
gap in addressing network-specific optimization challenges with the precision and adaptability required for
practical deployment.
To address these challenges, we introduce NL4RA, a curated dataset comprising 50 peer-reviewed research-
based optimization problems designed for network resource allocation. The dataset spans diverse domains,
including 5G/6G technologies, edge computing, and software-defined networking (SDN), offering mathematical
formulations for LP, ILP, and MILP problems.
Building on this dataset, we propose LM4Opt-RA, a
multi-candidate LLM framework designed to improve the translation of natural language descriptions into
mathematical formulations. The framework adopts diverse prompting strategies—direct, few-shot, and
chain-of-thought—to generate multiple candidate solutions, followed by a structured ranking mechanism to
identify the most accurate formulation. Our evaluation implements both traditional and advanced metrics,
including BLEU, ROUGE, Math-aware BERTScore, and LLM-Assisted Mathematical Evaluation (LAME)
score. These metrics evaluate the semantic and structural correctness of mathematical formulations. We
evaluate the proposed framework with two open-source LLMs at different parameter scales and temperature
settings. In our empirical evaluation, the proposed framework exhibited superior performance compared
to the baseline LLMs. For instance, at a temperature setting of 0.0, the proposed framework enhanced
LAME-5 scores for Llama-3.1-70B to 0.8007, substantially improving over the baseline (0.7492). Figure 1
illustrates an example of translating a natural language description of a resource allocation problem into
a mathematical formulation using our proposed framework, LM4Opt-RA. Additionally, we emphasize the
distinction between traditional automated evaluation metrics and our novel LAME Score, which evaluates
the framework-generated solution against the ground truth.
The contributions of this study can be summarized as:
1. We introduce NL4RA, a curated dataset of 50 real-world network resource allocation problems (LP,
ILP, and MILP) capturing the heterogeneity and complexity overlooked in previous benchmarks.
2


--- Page 3 ---
Preprint - December 2, 2025
Decision Variables:
Let 
 be a binary variable indicating whether VNO  is allocated to network slice , and let 
 be
the bandwidth allocated to VNO  on network slice .
Objective Function:
Maximize revenue: 
Constraints:
Bandwidth capacity constraint for each network slice: 
Each VNO can be assigned to a single slice only: 
No partial allocation of slices: 
Non-negativity and binary constraints: 
Subject to: Bandwidth Constraint: 
User-Slice Assignment Constraint: 
Allocation Constraint: 
where:  : Set of different slices, 
;  : Set of VNO users, 
; 
: Resource request
of VNO user ; 
: Price paid by VNO user  for using a unit bandwidth; 
: Bandwidth used by
each VNO user 
; 
: Available bandwidth in slice 
;  : Admission policy factor; 
: Revenue of the Infrastructure Provider (InP); 
: Revenue from slices 
; 
:
Bandwidth of new VNO user requests; 
: Bandwidth used by accepted VNO users
Decision Variables: 
An Infrastructure Provider (InP) manages a set of
network slices, each with a fixed bandwidth capacity.
The goal of the InP is to allocate these slices to Virtual
Network Operators (VNOs) as per their bandwidth
requirement for which they pay. Suppose, you are the
InP and so, your task is to ensure efficient usage of
bandwidth maximizing the revenue of the Infrastructure
Provider and satisfying the QoS requirements of VNO
users. However, while efficiently allocating the
resources you must satisfy some constraints: total
bandwidth allocated to a VNO user cannot exceed the
available bandwidth for that slice, each VNO can be
assigned to a single slice only and there can't be any
partial allocation of the slices, i.e., each user is assigned
to a slice or not assigned to a slice.
Reference Solution
Problem Description
Solution from LM4Opt-RA
Evaluation Metrics
{"Objective_Function_Correctness": 9, "Constraint_Accuracy": 8,
"Variable_Definitions": 9, "Overall_Score": 36,
 "Analysis": "The candidate formulation aligns well with the ground
truth in terms of maximizing revenue and ensuring slice allocation
constraints. However, it introduces $b_{ij}$ for bandwidth allocation,
which is not explicitly needed in the ground truth, potentially adding
complexity. The constraints correctly enforce bandwidth capacity,
single-slice assignment, and binary decisions, but the additional
variable may overcomplicate the problem."}
Math-aware
BERTScore 0.58
ROUGE-1
0.36
ROUGE-2
0.05
ROUGE-L
0.21
BLEU
0.01
LAME
Score
0.90
LAME Score Decomposition
Figure 1: Translation of a natural language resource allocation problem into a mathematical formulation
using LM4Opt-RA, highlighting the distinction between traditional metrics and the proposed LAME Score
2. A multi-candidate LLM approach, LM4Opt-RA, is proposed that integrates direct, few-shot, and
chain-of-thought prompts with a structured ranking mechanism for more accurate mathematical
formulations.
3. We develop a math-aware evaluation metric, LAME, which evaluates correctness and completeness
more effectively than standard text-overlap measures.
4. An empirical study is conducted to demonstrate that our approach outperforms baseline LLMs on
the new dataset, showing improved formulation accuracy and alignment with human judgments.
The remainder of this paper is organized as follows: Related Work reviews prior efforts on using LLMs
for optimization modeling and identifies gaps in network resource allocation. System Model outlines
the system architecture and its components, emphasizing the integration of LLM-based resource allocation
frameworks. NL4RA Dataset details the dataset’s design methodology, problem categorization, and features
tailored to network optimization challenges. In Mathematical Formulations with a Multi-Candidate
LLM Framework, we present LM4Opt-RA, elaborating on multi-candidate generation and structured
ranking. Evaluation Metrics discusses the metrics used, including the novel LAME score, and highlights
their alignment with human judgments. Findings and Analysis provides a comprehensive evaluation
of experimental results, comparing LM4Opt-RA with baseline models and discussing limitations. Finally,
Conclusion summarizes key findings, contributions, and directions for future research in LLM-driven
optimization for network resource allocation.
2
Related Work
Recently, several approaches have been proposed to bridge the gap between natural language descriptions and
mathematical optimization problems. Ramamonjison et al. [10] introduced the NL4Opt Competition focused
on identifying linked entities within optimization problem descriptions and generating the corresponding
mathematical formulations. Extending one of the subtasks of the competition, Dakle et al. [13] proposed
a hybrid approach that combines lexical and semantic models, enhanced by feature engineering, classical
3


--- Page 4 ---
Preprint - December 2, 2025
NER techniques, and data augmentation techniques, to enhance performance in recognizing optimization-
related entities. However, both works primarily addressed LP problems, and the curated dataset comprised
elementary optimization problem samples that do not adequately represent real-world scenarios. Additionally,
the competition did not involve generating solver-specific code. Building on the contributions of NL4Opt,
Ahmed et al. [11] evaluated various LLMs for converting linguistic descriptions to mathematical problem
formulation, introducing the LM4OPT framework. Their study demonstrated that GPT-4 outperformed other
models, achieving 63.30% accuracy without additional named entity information. Fine-tuning smaller models
with LM4OPT was shown to narrow the performance gap between smaller and larger models. However,
their findings were based solely on the NL4Opt dataset, limiting generalizability to more complex, real-world
problems.
Li et al. [9] extended the NL4Opt framework by incorporating MILP problems and handling logic constraints.
Their approach involved expanding the NL4Opt dataset to include binary variables and various logic
constraints and proposing a three-stage framework using LLMs for variable identification, classification,
and generation. Despite these advancements, the dataset remained limited in diversity regarding contexts,
constraint types, and optimization problem types and did not cover solver-specific code generation.
AhmadiTeshnizi et al. [14] presented OptiMUS, an LLM-based agent for generating mathematical formulations
and solver code, with automated testing and debugging features, and data augmentation through problem
rephrasing. They introduced the NLP4LP dataset, which includes LP and MILP problems from textbooks
and lecture notes. While providing solutions and code for optimality checks, the NLP4LP dataset remains
relatively small and may not fully capture the complexity of real-world problems. Moreover, OptiMUS relied
on structured natural language representations, limiting its applicability to unstructured problem descriptions.
Xiao et al. [15] introduced the Chain-of-Experts framework, employing multiple LLM-based agents for model
construction, programming, and code review, coordinated by a “Conductor" with a reflection mechanism for
error correction. They also introduced ComplexOR, a new benchmark with 37 diverse problems, including
expert annotations and model formulations. However, using multiple LLM agents increases computational
costs, and the ComplexOR dataset samples may not fully represent real-world problem diversity. Huang et al.
[16] proposed MAMO, a benchmark evaluating the mathematical modeling capabilities of LLMs by focusing
on the underlying modeling process rather than just assessing the correctness of final responses. The dataset
includes 346 ordinary differential equations problems, 652 easy, and 211 complex LP problems. However,
MAMO’s focus on LP problems limits its applicability to a broader range of optimization problems. Yang et
al. [17] introduced E-Opt, a benchmark requiring LLMs to generate Python code that utilizes optimization
solvers. It covers a range of optimization problems, including LP, MILP, and quadratic programming, with
varying difficulty levels. The study explored different prompting strategies and demonstrated the benefits of
fine-tuning LLMs on domain-specific datasets. Nonetheless, the E-Opt benchmark remains relatively small in
scale.
Tang et al. [18] proposed a semi-automated process for creating synthetic data to train open-source LLMs for
optimization modeling tasks. They introduced IndustryOR, the first industrial benchmark for evaluating
LLMs on real-world optimization problems. Their results showed that fine-tuned open-source LLMs achieved
accuracy rates of 85.7% on NL4Opt, 82.3% on MAMO (Easy LP), and 37.4% on MAMO (Complex LP).
However, the data generation process may introduce biases, and the study focused on 7b-size LLMs, leaving
other larger models unexplored. Furthermore, Mostajabdaveh et al. [19] introduced Operations Research
Question Answering (ORQA), a benchmark aimed at evaluating the generalization capabilities of LLMs in the
specialized domain of operations research (OR). ORQA drafted by OR experts, presents complex optimization
problems that require multi-step reasoning. They evaluated various open-source LLMs, including LLaMA 3.1,
DeepSeek, and Mixtral, revealing modest performance, with LLaMA 3.1-405B-Instruct achieving the highest
accuracy of 0.772 compared to human expert accuracy of 0.93. Nonetheless, a more detailed evaluation of
diverse real-world scenarios is needed to evaluate LLMs’ capabilities as both works suggest.
As seen in Table 1, the existing datasets focused mainly on using LLMs for general optimization tasks, with
limited or no attention to the specific challenges of network resource allocation. Most datasets have textbook
optimization problems and are relatively easier to understand. The network resource optimization problem is a
specialized niche with additional complexity. The optimization problems in modern network resource allocation
problems are usually more complex than traditional optimization problems contained in the existing datasets.
Unlike standard textbook optimization problems, network resource allocation problems are characterized by
a dynamic probabilistic ecosystem with multiple interdependent variables, real-time adaptation requirements,
and exponential computational complexity. There are usually heterogeneous constraints such as bandwidth
limitations, latency requirements, energy efficiency, security protocols, and quality of service metrics. Moreover,
network resource allocation must continuously balance multiple conflicting objectives—maximizing throughput
4


--- Page 5 ---
Preprint - December 2, 2025
Table 1: Datasets Containing Optimization Problems for LLM Modeling
Dataset Name
# Problems
LP
ILP
MILP
Optimization Problem Types
NL4Opt [10]
1101
✓
×
×
Sales, Advertising, Investment, etc.
Mamo Easy [16]
652
×
×
✓
High school-level textbook problems
Mamo
Complex
[16]
211
✓
×
×
Undergrad level textbook problems
IndustryOR [18]
100
✓
✓
✓
General Industry problems
NLP4LP [14]
52
✓
×
✓
Text Books
ComplexOR [15]
37
×
×
✓
Research Papers, Textbooks, Industry
Proposed
50
✓
✓
✓
Network Resource Allocation Optimization
while minimizing latency, ensuring security without compromising performance, and maintaining energy
efficiency—all within a constantly evolving technical environment. Our study addresses this gap by providing
a dataset specifically for network resource allocation and introducing a natural language interface framework
tailored to solve network resource allocation problems.
3
System Model
A high-level system model representing a use case of the proposed LM4Opt-RA framework is depicted in
Figure 2. The access and core networks are the foundational layers responsible for handling data transmission
and routing between user requests and the network infrastructure. These layers provide crucial inputs to the
network orchestrator, which oversees the overall management and flow of resources across the system. Central
to this model is the LLM-based resource allocation framework, which is responsible for generating and solving
optimization problems and managing resources using AI-based methods. It is responsible for dynamically
adjusting and allocating resources based on real-time inputs, predictive analytics, and optimization techniques.
The monitoring/feedback loop continuously gathers performance data from various network components and
feeds it back into the optimization process, ensuring the system adapts to changing conditions efficiently.
Resource allocation decisions are made iteratively, with the system checking whether the assignments are
satisfactory through the monitoring loop. If the allocation is not optimal, expert (network operators) feedback
is considered, and adjustments are made before arriving at the final allocation of resources, e.g., hosted in
data centers or on the cloud. Network operators oversee the entire system, provide human oversight, and
intervene when necessary to adjust policies or parameters in the LM4Opt-RA framework.
4
NL4RA Dataset
The proposed NL4RA dataset is a collection of mathematical models and natural language problem descriptions
covering a wide range of cellular networking scenarios. For the dataset, we systematically reviewed the
literature, including publications from 2015 to 2024. The works were selected from Google Scholar, emphasizing
keywords like ‘LP’ OR ‘ILP’ OR ‘MILP’ AND ‘Resource’ AND/OR ‘Allocation’ OR ‘Optimization,’. This
resulted in a diverse pool of relevant research works focusing on LP, ILP, and MILP problems as detailed in
Table 2. The ILP problems further include a good number of BILP problems as well. The categorization of
selected works based on the wide range of networking domains is provided in Appendix A. Each selected
paper was extensively analyzed to extract the mathematical formulations and their corresponding problem
descriptions. The problem descriptions and formulations are prepared in LATEX format. The mapping of
the selected works with the sample instances extracted from it for NL4RA is also present in Appendix A.
The mathematical formulations include a list of variables, constraints, and problem descriptions. The natural
language problem descriptions were restructured for clarity and easy interpretability. Figure 3 provides an
overview of the overall dataset preparation process.
NL4RA consists of 50 unique mathematical models with their problem descriptions. An overview of the
attributes of NL4RA is shown in Figure 4, indicating that, on average, each problem instance contains
11 variables and 5 constraints, with a total of 26 minimization problems and 24 maximization problems.
Furthermore, Figure 5 categorizes the samples of the dataset into distinct resource allocation types. Each
category includes samples depicting the diversity of resource management challenges in telecommunications
and networking.
5


--- Page 6 ---
Preprint - December 2, 2025
Access Network
Core Network
Network
Orchestrator
Monitor/Feedback
Resource Management System
AI/ML Systems
Optimization Algorithms
Proposed Framework
Network Operators
Data Centers/
Cloud Resources
Figure 2: High-level System Model. The system model integrates an AI-driven resource allocation
framework that combines resource management systems, AI/ML, and optimization algorithm solvers to
manage network resources dynamically. Data from the access and core networks is processed by the LLM-based
proposed resource allocation framework, which uses real-time monitoring and feedback to optimize resource
allocation. Network operators oversee the process, implementing final decisions in data centers or Cloud
resources.
Table 2: Categorization of Selected Works for NL4RA based on Problem Formulation Types
Types
References
LP
[21], [22], [23], [24],[25], [26]
ILP
[27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42],
[43], [44], [45], [46], [47], [48],[49], [50], [51], [52], [53], [54], [55]
MILP
[53], [56], [57], [58], [59], [60], [61], [62], [63], [64]
Given the limitations of current LLMs in performing logical and mathematical reasoning [20], we imposed
restrictions on the complexity of the problem scenarios in NL4RA. We chose problem scenarios with a count
of variables not more than 20 and constraints not more than 10. To further restructure the dataset, we have
categorized the size of problem instances into Small (constraints not more than 3), Moderate (constraints
more than 3 but less than 6), and Large (constraints equal to or more than 6) based on the number of
constraints as detailed out in Figure 6. However, there are multiple instances where multiple constraints are
grouped under one parent constraint. These multiple constraints were considered individual constraints while
the samples were being categorized.
The creation of NL4RA required extensive analysis and integration of diverse research works into a unified,
standardized benchmarking dataset. We expect that NL4RA will offer a foundation for benchmarking LLMs
in resource allocation tasks, enabling advancements in networking and AI research domains.
Literature Selection
(Relevant papers published between
2015 and 2024)
Sample Selection
(Problem chosen based on our
complexity constraints)
Sample Extraction
(LP, ILP and MILP mathematical
formulations with problem
descriptions)
Sample Processing
(Formulation in LaTeX Eqn. format)
Annotation and Validation
(Paraphrasing problem descriptions)
Keywords:
‘LP’ OR ‘ILP’ OR ‘MILP’ AND
‘Resource’ AND/OR ‘Allocation’
OR ‘Optimization,’
- Small (Constraints  3)
- Moderate (3 < Constraints < 6)
- Large (Constraints  6)
- Paraphrasing problem description
- Manual validation and verification
of the formulation
- Formualtion in LaTeX eqn. format
- Extraction of various metadata for
each sample e.g., difficulty level,
category/domain of the problem, etc.
- BILP problems are considered as
part of ILP.
Figure 3: Dataset Preparation Process
6


--- Page 7 ---
Preprint - December 2, 2025
11
5
26
24
Avg. # of Variables
Avg. # of Constraints
Minimization Problems
Maximization Problems
0
5
10
15
20
25
Count
Figure 4: Statistical summary of the NL4RA dataset
7
23
11
6
5
4
1
2
1
2
Heterogeneous
Services/Networks
Wireless/Cellular Networks
(IoT, 4G, 5G and beyond)
QoS and QoE
Radio
Edge Computing
Energy
Fronthaul/Backhaul
Multicell Network
NFV/SDN
Spectrum Allocation
0
5
10
15
20
Count
Figure 5: Categorization of dataset samples based on resource allocation types
5
Mathematical Formulations with a Multi-Candidate LLM Framework
5.1
Task Definition
For the task of formulating network resource allocation optimization problem, we use a corpus of network
resource allocation problems derived from peer-reviewed research articles and evaluate the capability of LLMs
to generate their corresponding mathematical formulations. We focus on complete problem formulations
rather than standalone equation generation, as they provide a comprehensive context and better represent
real-world applications of resource allocation modeling. The original corpus of problem descriptions is denoted
as P = {p1, p2, . . . , pn}, where n = 50. We obtain mathematical formulations for these problems denoted as
M = {f(p1), f(p2), . . . , f(pn)}, where f represents LM4Opt-RA framework that transforms natural language
problem descriptions into mathematical formulations. Each problem formulation m ∈M consists of three
essential components, i.e., m = {V, C, O}, where V represents the set of variable definitions, C denotes the
7


--- Page 8 ---
Preprint - December 2, 2025
46%
40%
14%
Large
Moderate
Small
Figure 6: Categorization of samples based problem size
set of constraints, and O represents the objective function. Each component is expressed in standardized
mathematical notation following LP, ILP, or MILP conventions. Our secondary objective is to evaluate how
accurately the generated formulations M capture the mathematical relationships and optimization goals
presented in the original problem descriptions while maintaining mathematical correctness and completeness.
5.2
LM4Opt-RA
In contrast to approaches that rely on a single generative step to translate a natural language description
into a mathematical formulation, we hypothesize that the quality of these formulations can be substantially
improved by incorporating multiple prompts and a ranking mechanism. Instead of forcing an LLM to
memorize or guess the best strategy for every type of resource allocation problem, we propose first to generate
multiple candidate solutions —each guided by a different prompting strategy—and then select the most
suitable candidate through a subsequent ranking procedure. To this end, we introduce LM4Opt-RA, a
multistage framework composed of three main prompts: (i) a direct LLM query, (ii) a few-shot strategy,
(iii) a chain-of-thought prompt, and (iv) a final ranking component that evaluates and ranks the candidate
formulations. In doing so, LM4Opt-RA ensures that each candidate formulation is informed by a distinct
prompting strategy which allows it to capture diverse constraints and contextual nuances.
5.3
Generating Multiple Candidate Formulations
Let T be a textual problem description that describes domain-specific details.
We aim to create an
LP/ILP/MILP model that aligns with T. Rather than treating this generation process as a single-prompt
task, we produce a set of candidate formulations: F(T) = {f1(T), f2(T), f3(T)}, where f1(T), f2(T), and
f3(T) refer respectively to the formulations generated by the direct, few-shot, and chain-of-thought strategy.
The direct prompt query is constructed as a minimal set of instructions focusing on equation generation
and the prohibition of extraneous text. It resembles a zero-shot or near-zero-shot scenario, where the LLM
is instructed to directly translate T into a coherent optimization model. In contrast to the direct query, a
few-shot prompt demonstrates how a sample resource allocation description (including decision variables,
constraints, and an objective function) translates into a final formulation. By providing a structured, validated
example, the LLM is more likely to produce a well-structured solution, complete with appropriate indexing,
standard notations, and alignment between constraints and the objective function. The third candidate
formulation, f3(T) is derived using a chain-of-thought strategy. Rather than specifying only the final output
format, this strategy instructs the LLM to systematically reason through each step: variable definition,
constraint identification, and the objective function. Although the final response must remain in the compact
form, this strategy tends to generate more thorough formulations. The prompts used for candidate solution
generation are given in Appendix B.
8


--- Page 9 ---
Preprint - December 2, 2025
5.4
Ranking and Selecting the Final Formulation
Although each fi(T) may include a valid set of decision variables, constraints, and an objective function,
certain candidates can more accurately reflect the requirements. To address this variability, our methodology
proposes a ranking framework that systematically compares multiple candidates rather than evaluating them
in isolation. Each candidate formulation is evaluated for its completeness, correctness, and logical consistency
through a structured comparative evaluation process using an instruction-tuned LLM. Additionally, the
formatting of the mathematical model is evaluated to ensure adherence to standard conventions for LP,
ILP, or MILP formulations. Unlike traditional ranking mechanisms that rank all candidate solutions in a
single step, our methodology adopts a sample-by-sample ranking strategy, where candidates are compared
in pairs. For example, if there are three candidates f1(T), f2(T), and f3(T), we first compare f1(T) and
f2(T), selecting the better of the two, and then compare the best candidate with f3(T). While this approach
requires one more LLM inference than single-step ranking, our empirical study shows that it provides higher
and more reliable solution quality.
One of the critical aspects of our proposed pipeline is the requirement for fully automated inference and
evaluation, implying that the determination of the best candidate solution should proceed without external
annotations or human involvement. When we treat evaluation as a downstream task, we must provide or
produce data in a structured format to make the process more effective. Our initial tests with open-source
LLMs indicate that the ranking model’s responses do not consistently follow a single pattern across different
samples—even when the sampling temperature is set to a very low value. This presents an intriguing paradox:
LLMs inherently generate unstructured text, reflecting their training on massive, mostly unstructured
datasets. To achieve formatted responses, we propose a structured output-parsing approach, where each
LLM inference is accompanied by a predefined data model (class definition) that helps extract the final
best candidate formulation. In our data model, we included a field to denote the best solution (either 1
or 2) for pairwise comparisons, alongside a second field for the second-best choice. For example, if the
model identifies candidate 2 as the best, it must label it accordingly (best = 2, second-best = 1) to prevent
random or incorrect outputs. While this rigid formatting may seem trivial to a human annotator—given
that if one solution is better, the other must logically be second-best—it proved highly effective in reducing
hallucinations. However, a separate study by Tam et al. [65] presents empirical evidence that LLMs face
difficulties with reasoning tasks when subject to format constraints. Moreover, their findings show that the
models’ reasoning performance deteriorates further as these constraints become stricter. In our preliminary
experiments, we observed a similar trend, especially among smaller LLMs: while the restrictions effectively
prevented any “hallucinations” (the model consistently provided only “1” or “2” and reversed them for best
and second-best), they also caused the model to frequently pick the simplest candidate solution. This usually
meant selecting the direct prompt query rather than the few-shot or chain-of-thought versions as the best
option. We hypothesize that these rigorous formatting requirements may hinder the model’s deeper reasoning
processes, prompting it to default to the simplest outcome. According to OpenAI [66], the quality of an
LLM’s final output can be enhanced by incorporating reasoning steps within the schema. This field allows
the model to explicitly outline its reasoning process before providing the final answer in a separate field.
Building on this insight, we added a ‘reasoning_steps’ text field to our data model, instructing the LLM to
justify choosing one response over another as shown in the following data model. This modification led to an
improvement in performance.
class ComparisonResult(BaseModel):
best: int
# 1 for Candidate 1, 2 for Candidate 2
second_best: int
# 1 for Candidate 1, 2 for Candidate 2
reasoning_steps: str
# Reason for ranking
The prompt used for ranking the solutions is given in Appendix C.
6
Evaluation Metrics
We evaluate the similarity between the generated and reference formulations using a combination of metrics.
We use two overlap-based metrics: BLEU [67], a precision-oriented metric that measures token n-gram overlap
and is widely used in machine translation, and ROUGE-1, ROUGE-2, and ROUGE-L [68], recall-oriented
metrics commonly applied in summarization tasks. Additionally, we utilize BERTScore [69], a representation-
based metric that calculates cosine similarity between contextualized token embeddings and has demonstrated
a stronger correlation with human judgments compared to BLEU and ROUGE across various tasks.
9


--- Page 10 ---
Preprint - December 2, 2025
6.1
Math-aware BERTScore
The original BERT [70], designed for general natural language tasks, struggles with mathematical equations
due to its pre-training on corpora deficient in mathematical notation and a tokenizer not suited for LaTeX
equation format. It cannot effectively process symbols or capture the structural nuances of mathematical
expressions. Constructs like ‘\sum’, ‘\frac’, or ‘\alpha’ are fragmented into multiple tokens, disrupting their
semantic meaning as unified entities. Since mathematical equations rely heavily on precise relationships and
syntactic structure, this fragmentation compromises coherence and leads to significant information loss. We
use embeddings from Math-aware BERT [71] to address this limitation for cosine similarity in BERTScore.
This model, pre-trained on the MathSE dataset and extended tokenizer with 501 LaTeX tokens, effectively
handles mathematical expressions. Fine-tuning pairs questions with answers using ARQMath annotations
and formulas are processed as Symbol Layout and Operator Trees. These adaptations improve the baseline
BERT’s performance in mathematical content retrieval.
However, existing metrics for comparing mathematical formulations have key limitations. BLEU and ROUGE
rely on exact token matching, missing semantic equivalence in structurally different but equivalent formulations.
Math-aware BERTScore addresses this but lacks a mechanism for capturing nuanced equivalence in complex
constructs, emphasizing the need for a more semantically aligned metric for mathematical content. In a similar
task, Manas et al. [72] proposed an instruction-tuned LLM-based LAVE metric to evaluate open-ended visual
question answering tasks by including semantic reasoning and contextual understanding. By aligning with
human judgment and addressing gaps in traditional metrics, LAVE demonstrated significant improvements
in evaluating nuanced and complex answers. Motivated by these advancements, we propose LLM-Assisted
Mathematical Evaluation Score (LAME), an automated evaluation framework that evaluates the quality of
mathematical formulations generated for LP, ILP, or MILP problems.
6.2
LAME Score
Each evaluation example comprises a problem description p, a ground truth mathematical formulation g, and
a candidate mathematical formulation c. The objective of LAME is to evaluate the candidate formulation c
by comparing it with the ground truth g and considering the context provided by the problem description
p. To achieve this, we utilize the in-context learning capabilities of instruction-tuned LLMs. We construct
a textual prompt using p, g, and c, which is then fed to the LLM to generate a detailed evaluation across
multiple criteria, including the correctness of the objective function, accuracy of constraints, definition of
variables, and overall validity of the formulation. Below, we describe the design decisions underlying LAME
scoring.
6.2.1
Choosing a Large Language Model
The selection of a suitable LLM is critical to the performance of LAME, as its effectiveness depends upon the
model’s ability to analyze and compare mathematical formulations. We pose the evaluation as a close-ended
assessment task with detailed scoring, which aligns well with the reasoning capabilities of instruction-tuned
LLMs. Consequently, we select the Flan-T5 model family [73] as the primary LLM for LAME. This choice is
informed by the model’s instruction-tuning and chain-of-thought reasoning capabilities, which enable it to
provide step-by-step evaluations for complex tasks.
To validate the generalizability of LAME, we design it to work with multiple LLMs. In addition to Flan-T5,
we test LAME using other instruction-tuned models. While Flan-T5 serves as the baseline, this adaptability
ensures that LAME can incorporate future advancements in LLMs with minimal changes to its structure.
6.2.2
Prompt for Mathematical Formulation Evaluation
The prompt for the LAME score comprises three main components: a task definition, demonstrations of
evaluations, and the input test example. The task definition specifies the evaluation criteria, including:
i. Objective Function Correctness: Is the objective function correctly formulated to match the problem
description? (Score out of 10)
ii. Constraint Accuracy: Are the constraints comprehensive and correctly stated? (Score out of 10)
iii. Variable Definitions: Are the decision variables properly defined and utilized? (Score out of 10)
iv. Overall Validity: Does the formulation faithfully represent the problem requirements? (Score out of
40)
10


--- Page 11 ---
Preprint - December 2, 2025
Each demonstration includes a problem description, ground truth formulation, candidate formulation, and
the corresponding evaluation output with detailed scores and rationales. The demonstrations are curated to
cover diverse cases, including examples with varying complexity, precision, and types of errors. Users can
extend these demonstrations to adapt the framework to specific domains. The test example consists of a
problem description, ground truth formulation, and candidate formulation. The LLM generates an evaluation
in the format:
Objective
Function
Correctness : X/10
Constraint
Accuracy : Y/10
Variable
D e f i n i t i o n s : Z/10
Overall
Score : W/40
Overall
Analysis :
[A b r i e f summary of
the
evaluation ]
The prompt also includes filtering mechanisms for references and rationalization.
By default, outlier
references are not filtered, as all components in a mathematical formulation are typically crucial. Rationaliza-
tion—providing a justification for each score—is an integral part of the task to improve explainability and
consistency.
6.2.3
Scoring Function
The scoring function extracts numerical ratings from the LLM-generated text, processes them, and aggregates
them into a final evaluation score. Using regular expressions, it identifies specific patterns in the generated
text to extract ratings for each criterion and the overall score. In cases where a score is missing or ambiguous,
default values are applied to maintain consistency. This ensures that LAME can handle noisy or unexpected
outputs without compromising reliability. Each score is normalized to a range of 0 to 1, and the overall score
is computed as a weighted sum of these normalized values:
S = wo · So + wc · Sc + wv · Sv + wa · Sa
where So, Sc, Sv, and Sa represent the normalized scores for the objective function, constraints, variables,
and overall validity, respectively. The weights wo, wc, wv, wa are predefined to reflect the importance of each
criterion (e.g., wo = 0.4, wc = 0.3, wv = 0.2, wa = 0.1).
7
Findings and Analysis
7.1
Technical Details
The evaluation was conducted on a server equipped with an NVIDIA H100 NVL GPU featuring 96GB VRAM,
64GB RAM, and an Intel Xeon Gold CPU with 64 cores and 128 threads. As the focus was on evaluating the
in-context learning capabilities of the LLMs, no fine-tuning was applied during the evaluation process.
7.2
Results
We present the baseline LLM performance on the curated NL4RA dataset in Table 3, where we report overlap
based metrics such as BLEU, ROUGE 1, ROUGE 2, ROUGE L, BERTScore, and our proposed LAME 1,
LAME 3, and LAME 5 metrics. The evaluation includes four language models, namely Llama 3.1 at two
parameter scales (70B and 8B) and Phi 3 at two parameter scales (3.5B and 14B), with the temperature
parameter varied among 0, 0.5, and 1.
An interesting observation from the ROUGE and BLEU scores is that they remain consistently low across
all temperature settings and models. This result supports our initial hypothesis that exact token matching
is not suitable for comparing mathematical expressions, as notational differences or symbol placement can
cause low n-gram overlaps. For instance, despite Llama-3.1-8B at temperature 0 achieving moderately higher
ROUGE-1 (0.4534) relative to Phi-3-14B (0.4321), its BLEU score is still below 0.06. Such discrepancies reveal
the inherent weakness of purely lexical measures, as small notational variations in LaTeX code can escape
direct matching. BERTScore, adapted to math-aware embeddings, tries to address these issues by focusing
on contextual meaning rather than exact token matches. Nevertheless, as Table 3 shows, the BERTScore
values across most configurations are relatively close (ranging mostly between 0.70 and 0.79) and do not
fully correlate with human evaluations. Our analysis suggests that large formulations with more elaborate
LaTeX equations can confuse the tokenizer of standard BERT or even math-aware BERT, causing suboptimal
11


--- Page 12 ---
Preprint - December 2, 2025
0.8007
0.7390
0.2560
0.6872
0.7623
0.7159
0.5800
0.6825
0.7543
0.7222
0.2681
0.6932
Llama-3.1-70B
Llama-3.1-8B
Phi-3.5-3.8B
Phi-3-14B
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
T=0.0
T=0.5
T=1.0
LAME-5 Score
Figure 7: LAME-5 scores for different models at various temperatures using the proposed framework
alignment and limited variation in BERTScore. The frequent mis-tokenization of domain-specific variables
and constraint names further lessens the reliability of this metric in ranking the best formulation.
To address these weaknesses, we rely on our LAME scores, shown in the last three columns of Table 3. LAME-
1, LAME-3, and LAME-5 each use an instruction-tuned LLM to judge how well a candidate formulation aligns
with a ground truth while conditioning on 1, 3, or 5 examples, respectively, in an in-context learning scenario.
Across all models, LAME-{3,5} exhibits a wider score spread than BERTScore or ROUGE, indicating that
the method captures a richer spectrum of correctness criteria. For instance, Phi-3.5-3.8B at temperature
1.0 achieves a BERTScore of 0.7092, but obtains a notably low LAME-5 of 0.226. Moreover, comparing
LAME-1, LAME-3, and LAME-5 reveals that LAME-5 consistently demonstrates the highest correlation
with manual inspections of the generated formulations. According to our partial human annotations of the
LLM-generated responses, LAME-5 effectively penalizes these incorrect expansions while rewarding correct
variable usage and coherent constraint sets. By contrast, LAME-1 sometimes oversimplifies the evaluation,
leading to less sensitive gradations among candidate solutions. These findings are consistent with our prior
analysis that purely lexical or token-level metrics can be misaligned with human judgment, especially for
syntactically complex LaTeX formulations. In several instances, BERTScore and ROUGE underreported
differences between models that humans identified as significant; likewise, BLEU remained too low to offer
meaningful distinctions. By contrast, LAME-{3,5} showed an enhanced capacity.
Table 3: Performance Metrics for Various Models Across Different Temperatures
Temp.
Model
BERT Score
ROUGE-1
ROUGE-2
ROUGE-L
BLEU
LAME-3
LAME-5
LAME-1
0
Llama-3.1-70B
0.7559
0.4249
0.1624
0.2797
0.0326
0.7728
0.7492
0.89
0
Llama-3.1-8B
0.7873
0.4534
0.1684
0.2758
0.0508
0.7306
0.7152
0.854
0
Phi-3.5-3.8B
0.7181
0.1166
0.0077
0.0723
0.0014
0.2016
0.202
0.336
0
Phi-3-14B
0.7458
0.4321
0.1341
0.2006
0.0263
0.6802
0.6504
0.83
0.5
Llama-3.1-70B
0.7727
0.4465
0.1683
0.2806
0.0325
0.7782
0.7451
0.91
0.5
Llama-3.1-8B
0.7817
0.4534
0.1689
0.2645
0.0439
0.7444
0.7088
0.87
0.5
Phi-3.5-3.8B
0.7758
0.3684
0.0938
0.1851
0.0112
0.6330
0.5738
0.764
0.5
Phi-3-14B
0.7409
0.4286
0.1328
0.2068
0.0282
0.7018
0.6698
0.864
1
Llama-3.1-70B
0.7830
0.4345
0.1463
0.2656
0.0291
0.7621
0.713
0.914
1
Llama-3.1-8B
0.7584
0.4389
0.1574
0.2636
0.0413
0.7572
0.7152
0.872
1
Phi-3.5-3.8B
0.7092
0.0979
0.0023
0.0587
0.0010
0.1498
0.226
0.254
1
Phi-3-14B
0.7821
0.4126
0.1119
0.1935
0.0196
0.7360
0.6862
0.864
Figure 7 presents the LAME-5 performance of our proposed multi-candidate LLM framework, LM4Opt-RA,
applied to four models at three temperature settings. Compared to our baseline results in Table 3, there is an
improvement in LAME-5 scores under the new approach, particularly for Llama-3.1-70B at T = 0.0, which
now exceeds 0.80. Although Llama-3.1-70B still shows a slight decrease in performance when the temperature
is raised to 1.0, its LAME-5 scores remain robust relative to the baseline. Interestingly, Phi-3.5-3.8B exhibits
sharper fluctuations at T = 0.0, T = 0.5 and T = 1.0, which shows the model’s sensitivity to randomness in
generation.
12


--- Page 13 ---
Preprint - December 2, 2025
5.0
5.5
6.3
5.9
4.7
8.2
9.8
8.7
Direct Query
Few-shot
Chain-of-Thought
LM4Opt-RA
0
2
4
6
8
10
Avg. Constraints
Avg. Variables
Average Count
Figure 8: Comparison of average number of constraints and variables across different strategies
7.3
Effect of Prompting Strategies on Solution Complexity
Figure 8 compares the average number of constraints and variables generated by each prompting strategy:
direct query, chain-of-thought, few-shot, and our proposed LM4Opt-RA. A notable observation is that the
direct query approach generates the simplest formulations: the fewest constraints and a smaller number
of variables. Upon manual review, these solutions often fail to capture the full intricacy of the problem
description, overlooking important constraints or variables. In contrast, the chain-of-thought strategy produces
the largest average counts. While this approach generally provides better coverage and accounts for more
aspects of the problem, it can also become excessively complex—introducing additional variables or constraints
not strictly required by the original scenario. The few-shot strategy stands somewhere in between, occasionally
including more variables but fewer constraints. Our proposed multi-candidate framework, LM4Opt-RA,
selects the best solution among these three strategies. Consequently, the average constraints and variables for
LM4Opt-RA are closer to the original formulations in the curated dataset. Moreover, manual inspections
reveal that LM4Opt-RA most frequently picks either a few-shot or chain-of-thought solution, indicating that
these strategies often provide a more comprehensive alignment with the real-world complexity of network
resource allocation problems. To illustrate how each strategy handles the same problem description, Figure 9
presents three candidate formulations side by side—along with their final rankings. We observe that the direct
query solution omits important details and yields a more compact formulation, whereas the chain-of-thought
version introduces additional complexity and sometimes unnecessary variables. By contrast, the few-shot
solution balances more effectively between completeness and clarity, resulting in its top ranking by our
framework.
7.4
Effect of Formatting Constraints on Reasoning Capabilities
We detailed our candidate solution ranking mechanism in Ranking and Selecting the Final Formulation,
arriving at the final proposed methodology through a step-by-step process, moving from lenient to stricter
formatting constraints. Initially, we used generic prompts where the LLM was asked to rank solutions as
best, second-best, and third-best. While the LLM performed satisfactorily, identifying discrepancies with
the ground truth reasonably well, its responses were overly descriptive and lacked a consistent format across
samples. To address this, we implemented stricter formatting, instructing the LLM to provide only the
ranks without additional text. Most models in the Llama series handled this task effectively, although
the smaller Llama model often ranked the easiest and smallest solution as the best, even when it did not
align well with the problem description which indicates a notable decrease in reasoning capability. The
Phi models, particularly the smaller one, failed noticeably to adhere to the specified format. Instead, the
smaller Phi model frequently produced irrelevant, overly verbose gibberish responses. This issue arose due
to the lengthy prompt, which included the problem description, three candidate solutions, and detailed
ranking and formatting instructions. Although the prompt length fell within the model’s context limit, the
smaller Phi model exhibited unpredictable behavior with longer inputs. Consequently, the shift from generic
conversational prompts to strict formatting diminished the LLM’s reasoning capabilities. To ensure structured
13


--- Page 14 ---
Preprint - December 2, 2025
Problem Description:
Suppose you are assigned the responsibility of efficiently allocating computing resources in an Open Radio Access Network (O-RAN) to process data for two types
of users: enhanced Mobile Broadband (eMBB) users and Ultra-Reliable Low-Latency Communication (URLLC) users. You aim to fairly  allocate computing
resources to eMBB and URLLC users and optimize the QoS of URLLC users without neglecting eMBB users. The processing is done in a shared cloud environment
(O-Cloud) where you have to maximize the minimum number of transmissions for both user types. However, while doing so, you have to satisfy some constraints:
each user's unique transmission must not be processed more than once, ensure that the eMBB and URLLC processing deadlines are met and minimum transmission
requirements for both eMBB and URLLC are satisfied. Your task is to formulate the problem with the objective of maximizing the weighted sum of the minimum
ratio of granted throughput to demanded throughput for eMBB and URLLC users.
Direct Query (Rank 2):
Objective Function:  
Constraints:  
  
  
  
  
  
  
Decision Variables:  
: Binary variable indicating whether the 
 eMBB user's transmission
is processed by the 
 cloud resource.  
: Binary variable indicating whether the 
 URLLC user's transmission
is processed by the 
 cloud resource.  
: Capacity of the 
 cloud resource.  
: Demanded throughput of the 
 eMBB and URLLC user respectively.  
: Processing deadline of the 
 cloud resource for eMBB and URLLC
users respectively.  
: Weights for eMBB and URLLC users respectively.
Few-shot (Rank 1):
Objective Function:  
Constraints:  
  
  
  
  
Decision Variables:  
: The amount of data processed for user  at time slot .  
: Weight factor for eMBB users.  
: Weight factor for URLLC users.  
: Set of eMBB users.  
: Set of URLLC users.  
: Set of time slots.  
: Minimum transmission requirement for eMBB user .  
: Minimum transmission requirement for URLLC user .  
: Throughput achieved by processing eMBB user  at time slot .  
: Throughput achieved by processing URLLC user  at time slot .  
: Deadline for processing eMBB user .  
: Deadline for processing URLLC user .  
: Whether user  is processed at time slot .
Chain-of-Thought (Rank 3):
Objective Function:  
Constraints:  
  
  
  
;     
  
  
  
;     
  
  
  
Decision Variables:  
: Number of transmissions for eMBB user  at time slot .  
: Number of transmissions for URLLC user  at time slot .  
: Binary variable indicating whether eMBB user  is processed at time slot .  
: Binary variable indicating whether URLLC user  is processed at time slot .  
: Weight for eMBB users; 
: Weight for URLLC users.  
: Number of eMBB users; 
: Number of URLLC users.  
: Number of time slots for eMBB processing.  
: Number of time slots for URLLC processing.  
: Available computing resources at time slot .  
: Available computing resources at time slot .  
: Demanded throughput for eMBB user  at time slot .  
: Demanded throughput for URLLC user  at time slot .  
: Minimum transmission requirement for eMBB user .  
: Minimum transmission requirement for URLLC user .  
: Large number; 
: Positive integers.
Figure 9: Side-by-side comparison of three candidate solutions (Direct Query, Few-Shot, and Chain-of-
Thought) for the same resource allocation problem description
responses, we then adopted a structured LLM output with a specific data model, and all models provided
rankings without extra text. However, we observed that most rankings followed the sequence {1, 2, 3},
leading us to hypothesize that the strict response format reduced the model’s reasoning abilities, prompting
it to default to selecting the simplest solution as the best. At this stage, we incorporated reasoning steps into
the data model, which significantly improved the outcomes and enhanced the LLM’s reasoning capabilities.
7.5
Limitations
7.5.1
Academic Sources for Problem Descriptions
We acknowledge that the language used in the NL4RA dataset is predominantly formal and domain-specific,
owing to the peer-reviewed scientific articles from which these problem statements are derived. While this
choice allows us to focus on the technical precision and consistency necessary for network resource allocation
tasks, it may not fully reflect more colloquial or layperson-written descriptions encountered in everyday
contexts. Consequently, the framework’s performance could vary when adapting to problem statements
that lack specialized terminology or use more casual, non-technical language—an area that requires further
exploration.
7.5.2
Reliance on Automated Evaluation Metrics
Although the LAME score provides a math-aware assessment of LP, ILP, and MILP formulations, it cannot
fully replicate the nuanced judgment of domain experts, particularly regarding problem-specific constraints
or specialized terminology. Subtle inaccuracies may consequently slip through which emphasizes the need for
human oversight in high-stakes or sensitive environments. However, by substantially reducing the resource
requirements for preliminary evaluations, LAME broadens access to advanced optimization techniques, making
them more approachable for a wider range of users and facilitating quicker, more iterative problem-solving
processes.
7.5.3
Choice of Open-Source Models
Our empirical evaluation focuses on the open-source Llama and Phi language models, ensuring that the
experiments are reproducible and transparent. We have chosen these LLMs as various benchmarks recognize
them among the most capable open-source LLMs for reasoning tasks. However, this choice may not fully
represent the capabilities of more advanced or proprietary systems, such as GPT-{4, 4o, o1}.
Future
investigations examining a broader array of models could yield a more comprehensive understanding of
performance and generalizability in the domain of resource allocation.
14


--- Page 15 ---
Preprint - December 2, 2025
8
Conclusion
We introduce NL4RA, the first curated dataset explicitly tailored for network resource allocation, creating a
foundational benchmark that captures the dynamic, heterogeneous constraints of real-world problems and
supports future research in this domain. In addition, we have presented LM4Opt-RA, a multi-candidate LLM
framework for automatically generating mathematical formulations of network resource allocation problems.
By implementing direct, few-shot, and chain-of-thought prompts, followed by a ranking mechanism, we show
that LM4Opt-RA produces more coherent, complete, and context-aligned formulations than single-prompt
approaches. Our evaluation with standard overlap-based metrics (BLEU, ROUGE) highlights their inadequacy
for capturing nuanced, notation-heavy mathematical expressions, while math-aware BERTScore only partially
addresses these limitations. In contrast, our proposed LAME metric, particularly LAME 5, shows a stronger
correspondence with human evaluations, highlighting its promise as a reliable automated judge of formulation
correctness. Looking ahead, future work can expand LM4Opt-RA to broader classes of resource allocation
problems, including multi-objective or stochastic formulations, and investigate advanced embedding strategies
that better handle domain-specific symbolic expressions. We expect these refinements to further narrow the
gap between machine-generated formulations and the expertise of human domain specialists.
References
[1] Hans Jakob Damsgaard, Aleksandr Ometov, Md Munjure Mowla, Adam Flizikowski, and Jari Nurmi.
Approximate computing in b5g and 6g wireless systems: A survey and future outlook. Computer
Networks, page 109872, 2023.
[2] Mohammad Kamrul Hasan, Nusrat Jahan, Mohd Zakree Ahmad Nazri, Shayla Islam, Muhammad At-
tique Khan, Ahmed Ibrahim Alzahrani, Nasser Alalwan, and Yunyoung Nam. Federated learning for
computational offloading and resource management of vehicular edge computing in 6g-v2x network.
IEEE Transactions on Consumer Electronics, 2024.
[3] Cheng-Xiang Wang, Xiaohu You, Xiqi Gao, Xiuming Zhu, Zixin Li, Chuan Zhang, Haiming Wang,
Yongming Huang, Yunfei Chen, Harald Haas, et al. On the road to 6g: Visions, requirements, key
technologies and testbeds. IEEE Communications Surveys & Tutorials, 2023.
[4] Fatima Salahdine, Tao Han, and Ning Zhang. 5g, 6g, and beyond: Recent advances and future challenges.
Annals of Telecommunications, pages 1–25, 2023.
[5] Annisa Sarah, Gianfranco Nencioni, and Md Muhidul I Khan. Resource allocation in multi-access edge
computing for 5g-and-beyond networks. Computer Networks, 227:109720, 2023.
[6] Hayder Faeq Alhashimi, MHD Nour Hindia, Kaharudin Dimyati, Effariza Binti Hanafi, Nurhizam Safie,
Faizan Qamar, Khairul Azrin, and Quang Ngoc Nguyen. A survey on resource management for 6g
heterogeneous networks: Current research, future trends, and challenges. Electronics, 12(3):647, 2023.
[7] Hamdy A Taha. Operations research: an introduction. Pearson Education India, 2013.
[8] Hamza Chakraa, François Guérin, Edouard Leclercq, and Dimitri Lefebvre. Optimization techniques for
multi-robot task allocation problems: Review on the state-of-the-art. Robotics and Autonomous Systems,
page 104492, 2023.
[9] Qingyang Li, Lele Zhang, and Vicky Mak-Hau. Synthesizing mixed-integer linear programming models
from natural language descriptions. arXiv preprint arXiv:2311.15271, 2023.
[10] Rindranirina Ramamonjison, Timothy Yu, Raymond Li, Haley Li, Giuseppe Carenini, Bissan Ghaddar,
Shiqi He, Mahdi Mostajabdaveh, Amin Banitalebi-Dehkordi, Zirui Zhou, et al. Nl4opt competition:
Formulating optimization problems based on their natural language descriptions. In NeurIPS 2022
Competition Track, pages 189–203. PMLR, 2023.
[11] Tasnim Ahmed and Salimur Choudhury. Lm4opt: Unveiling the potential of large language models
in formulating mathematical optimization problems. INFOR: Information Systems and Operational
Research, 0(0):1–14, 2024.
[12] Dimos Tsouros, Hélène Verhaeghe, Serdar Kadıoğlu, and Tias Guns. Holy grail 2.0: From natural
language to constraint models. arXiv preprint arXiv:2308.01589, 2023.
[13] Parag Pravin Dakle, Serdar Kadıoğlu, Karthik Uppuluri, Regina Politi, Preethi Raghavan, SaiKrishna
Rallabandi, and Ravisutha Srinivasamurthy.
Ner4opt: Named entity recognition for optimization
modelling from natural language. In International Conference on Integration of Constraint Programming,
Artificial Intelligence, and Operations Research, pages 299–319. Springer, 2023.
15


--- Page 16 ---
Preprint - December 2, 2025
[14] Ali AhmadiTeshnizi, Wenzhi Gao, and Madeleine Udell. Optimus: Optimization modeling using mip
solvers and large language models. arXiv preprint arXiv:2310.06116, 2023.
[15] Ziyang Xiao, Dongxiang Zhang, Yangjun Wu, Lilin Xu, Yuan Jessica Wang, Xiongwei Han, Xiaojin Fu,
Tao Zhong, Jia Zeng, Mingli Song, et al. Chain-of-experts: When llms meet complex operations research
problems. In The Twelfth International Conference on Learning Representations, 2023.
[16] Xuhan Huang, Qingning Shen, Yan Hu, Anningzhe Gao, and Benyou Wang. Mamo: a mathematical
modeling benchmark with solvers. arXiv preprint arXiv:2405.13144, 2024.
[17] Zhicheng Yang, Yinya Huang, Wei Shi, Liang Feng, Linqi Song, Yiwei Wang, Xiaodan Liang, and
Jing Tang. Benchmarking llms for optimization modeling and enhancing reasoning via reverse socratic
synthesis. arXiv preprint arXiv:2407.09887, 2024.
[18] Zhengyang Tang, Chenyu Huang, Xin Zheng, Shixi Hu, Zizhuo Wang, Dongdong Ge, and Benyou Wang.
Orlm: Training large language models for optimization modeling. arXiv preprint arXiv:2405.17743,
2024.
[19] Mahdi Mostajabdaveh, Timothy T. Yu, Samarendra Chandan Bindu Dash, Rindranirina Ramamonjison,
Jabo Serge Byusa, Giuseppe Carenini, Zirui Zhou, and Yong Zhang. Evaluating llm reasoning in the
operations research domain with orqa, 2024. To be appeared in AAAI 2025.
[20] Iman Mirzadeh, Keivan Alizadeh, Hooman Shahrokhi, Oncel Tuzel, Samy Bengio, and Mehrdad Fara-
jtabar. Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language
models. arXiv preprint arXiv:2410.05229, 2024.
[21] Firooz B Saghezchi, Ayman Radwan, and Jonathan Rodriguez. Energy-aware relay selection in cooperative
wireless networks: An assignment game approach. Ad Hoc Networks, 56:96–108, 2017.
[22] Lei You, Qi Liao, Nikolaos Pappas, and Di Yuan. Resource optimization with flexible numerology and
frame structure for heterogeneous services. IEEE Communications Letters, 22(12):2579–2582, 2018.
[23] Haneul Ko, Jaewook Lee, and Sangheon Pack. Pdras: Priority-based dynamic resource allocation scheme
in 5g network slicing. Journal of Network and Systems Management, 30(4):68, 2022.
[24] Guo Yang, Qi Liu, Xiangwei Zhou, Yuwen Qian, and Wen Wu. Two-tier resource allocation in dynamic
network slicing paradigm with deep reinforcement learning. In 2019 IEEE Global Communications
Conference (GLOBECOM), pages 1–6. IEEE, 2019.
[25] Rhishi Pratap Singh and Garimella Rama Murthy. Economic node allocation in software defined wireless
networks with forecasted traffic and distance constraints. In 2017 8th International Conference on
Computing, Communication and Networking Technologies (ICCCNT), pages 1–5, 2017.
[26] Mohammad Alnakhli. Optimizing spectrum efficiency in 6g multi-uav networks through source correlation
exploitation. EURASIP Journal on Wireless Communications and Networking, 2024(1):6, 2024.
[27] Yeakub Hassan, Faisal Hussain, Sakhawat Hossen, Salimur Choudhury, and Muhammad Mahbub
Alam. Interference minimization in d2d communication underlaying cellular networks. IEEE Access,
5:22471–22484, 2017.
[28] Francesco Spinelli, Antonio Bazco-Nogueras, and Vincenzo Mancuso. Edge gaming: A greening perspec-
tive. Computer Communications, 192:89–105, 2022.
[29] Nasim Ferdosian, Sara Berri, and Arsenia Chorti. 5g new radio resource allocation optimization for
heterogeneous services. In 2022 International Symposium ELMAR, pages 1–6. IEEE, 2022.
[30] Mahdi Sharara, Turgay Pamuklu, Sahar Hoteit, Véronique Vèque, and Melike Erol-Kantarci. Policy-
gradient-based reinforcement learning for computing resources allocation in o-ran. In 2022 IEEE 11th
International Conference on Cloud Networking (CloudNet), pages 229–236. IEEE, 2022.
[31] Daosen Zhai. Adaptive codebook design and assignment for energy saving in scma networks. IEEE
Access, 5:23550–23562, 2017.
[32] Mohammad Javad-Kalbasi and Shahrokh Valaee. Re-configuration of uav relays in 6g networks. In 2021
IEEE International Conference on Communications Workshops (ICC Workshops), pages 1–6. IEEE,
2021.
[33] Mingjie Feng and Shiwen Mao. Adaptive pilot design for massive mimo hetnets with wireless backhaul.
In 2017 14th Annual IEEE International Conference on Sensing, Communication, and Networking
(SECON), pages 1–9. IEEE, 2017.
16


--- Page 17 ---
Preprint - December 2, 2025
[34] Renchao Xie, Zishu Li, Tao Huang, and Yunjie Liu. Energy-efficient joint content caching and small
base station activation mechanism design in heterogeneous cellular networks. China Communications,
14(10):70–83, 2017.
[35] Fadoua Debbabi, Raouia Taktak, Rihab Jmal, Lamia Chaari Fourati, and Rui Luis Aguiar. Inter-slice
b5g bandwidth resource allocation. In 2022 IEEE 21st International Symposium on Network Computing
and Applications (NCA), volume 21, pages 157–163. IEEE, 2022.
[36] Mahzabeen Emu and Salimur Choudhury. Ensemble deep learning assisted vnf deployment strategy for
next-generation iot services. IEEE Open Journal of the Computer Society, 2:260–275, 2021.
[37] Abdulhalim Fayad, Tibor Cinkler, and Jacek Rak. 5g millimeter wave network optimization: Dual
connectivity and power allocation strategy. IEEE Access, 2023.
[38] Yifan Pan, Lin Gao, Jingjing Luo, Tong Wang, and Jiaqi Luo. A multi-dimensional resource crowd-
sourcing framework for mobile edge computing. In ICC 2020-2020 IEEE International Conference on
Communications (ICC), pages 1–7. IEEE, 2020.
[39] Yang Yang, Xiaolin Chang, Ziye Jia, Zhu Han, and Zhen Han. Towards 6g joint haps-mec-cloud 3c
resource allocation for delay-aware computation offloading. In 2020 IEEE Intl Conf on Parallel &
Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing &
Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom), pages
175–182. IEEE, 2020.
[40] Andrea Fendt, Simon Lohmuller, Lars Christoph Schmelz, and Bernhard Bauer. A network slice resource
allocation and optimization model for end-to-end mobile networks. In 2018 IEEE 5G World Forum
(5GWF), pages 262–267. IEEE, 2018.
[41] Qingmin Jia, Renchao Xie, Tao Huang, Jiang Liu, and Yunjie Liu. Efficient caching resource allocation
for network slicing in 5g core network. IET Communications, 11(18):2792–2799, 2017.
[42] Zeinab Sasan and Siavash Khorsandi. Slice-aware resource calendaring in cloud-based radio access
networks. In 2022 30th International Conference on Electrical Engineering (ICEE), pages 1005–1009,
2022.
[43] Hisham M Almasaeid. Minimum cost spectrum allocation with qos guarantees in multi-interface multi-hop
dynamic spectrum access networks. Computer Networks, 231:109824, 2023.
[44] Huda Yousef Alsheyab, Salimur Choudhury, Ebrahim Bedeer, and Salama S Ikki. Near-optimal resource
allocation algorithms for 5g+ cellular networks. IEEE Transactions on Vehicular Technology, 68(7):6578–
6592, 2019.
[45] Francesco Spinelli and Vincenzo Mancuso. A migration path toward green edge gaming. In 2022 IEEE
23rd International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM),
pages 347–356. IEEE, 2022.
[46] Taejin Kim, Sandesh Dhawaskar Sathyanarayana, Siqi Chen, Youngbin Im, Xiaoxi Zhang, Sangtae Ha,
and Carlee Joe-Wong. Modems: Optimizing edge computing migrations for user mobility. IEEE Journal
on Selected Areas in Communications, 41(3):675–689, 2022.
[47] Niezi Mharsi and Makhlouf Hadji. Joint optimization of communication latency and resource allocation
in cloud radio access networks. In 2018 International Conference on Smart Communications in Network
Technologies (SaCoNeT), pages 13–18. IEEE, 2018.
[48] Faisal Hussain, Md Yeakub Hassan, Md Sakhawat Hossen, and Salimur Choudhury. System capacity
maximization with efficient resource allocation algorithms in d2d communication. IEEE Access, 6:32409–
32424, 2018.
[49] Md Sakhawat Hossen, Md Yeakub Hassan, Faisal Hussain, Salimur Choudhury, and Muhammad Mahbub
Alam. Relax online resource allocation algorithms for d2d communication. International Journal of
Communication Systems, 31(10):e3555, 2018.
[50] Md Yeakub Hassan, Faisal Hussain, Md Sakhawat Hossen, and Salimur Choudhury. An online re-
source allocation algorithm to minimize system interference for inband underlay d2d communications.
International Journal of Communication Systems, 32(13):e4011, 2019.
[51] Christoforos Vlachos and Vasilis Friderikos. Moca: Multiobjective cell association for device-to-device
communications. IEEE Transactions on Vehicular Technology, 66(10):9313–9327, 2017.
[52] Do Hyeon Kim, S. M. Ahsan Kazmi, Anselme Ndikumana, Aunas Manzoor, Walid Saad, and Choong Seon
Hong. Distributed radio slice allocation in wireless network virtualization: Matching theory meets
auctions. IEEE Access, 8:73494–73507, 2020.
17


--- Page 18 ---
Preprint - December 2, 2025
[53] Antonio De Domenico, Ya-Feng Liu, and Wei Yu. Optimal virtual network function deployment for
5g network slicing in a hybrid cloud infrastructure. IEEE Transactions on Wireless Communications,
19(12):7942–7956, 2020.
[54] Haythem Bany Salameh, Haitham Al-Obiedollah, Ruba Mahasees, and Yaser Jararweh. Opportunistic
non-contiguous ofdma scheduling framework for future b5g/6g cellular networks. Simulation Modelling
Practice and Theory, 119:102563, 2022.
[55] Ahmed Zoha, Arsalan Saeed, Hasan Farooq, Ali Rizwan, Ali Imran, and Muhammad Ali Imran.
Leveraging intelligence from network cdr data for interference aware energy consumption minimization.
IEEE Transactions on Mobile Computing, 17(7):1569–1582, 2017.
[56] Mohammed S Hadi, Ahmed Q Lawey, Taisir EH El-Gorashi, and Jaafar MH Elmirghani. Patient-centric
hetnets powered by machine learning and big data analytics for 6g networks. IEEE Access, 8:85639–85655,
2020.
[57] Mingjin Gao, Wenqi Cui, Di Gao, Rujing Shen, Jun Li, and Yiqing Zhou. Deep neural network task
partitioning and offloading for mobile edge computing. In 2019 IEEE Global Communications Conference
(GLOBECOM), pages 1–6. IEEE, 2019.
[58] Danish Sattar and Ashraf Matrawy. Optimal slice allocation in 5g core networks. IEEE Networking
Letters, 1(2):48–51, 2019.
[59] Ye Yu, Xiangyuan Bu, Kai Yang, Hung Khanh Nguyen, and Zhu Han. Network function virtualization
resource allocation based on joint benders decomposition and admm. IEEE Transactions on Vehicular
Technology, 69(2):1706–1718, 2019.
[60] Jiming Yao, Duanyun Chen, Yue Yu, and Wei Wang. Ran slice access control scheme based on qos
and maximum network utility. In 2022 IEEE 6th Advanced Information Technology, Electronic and
Automation Control Conference (IAEAC ), pages 1853–1858, 2022.
[61] ABM Bodrul Alam, Zubair MD Fadlullah, and Salimur Choudhury. A resource allocation model based
on trust evaluation in multi-cloud environments. IEEE Access, 9:105577–105587, 2021.
[62] Fahd N Al-Wesabi, Imran Khan, Mohammad Alamgeer, Ali M Al-Sharafi, Bong Jun Choi, and Abdallah
Aldosary. A joint algorithm for resource allocation in d2d 5g wireless networks. Comput. Mater. Continua,
69(1):301–317, 2021.
[63] Masoud Shokrnezhad and Siavash Khorsandi. Joint power control and channel assignment in uplink iot
networks: A non-cooperative game and auction based approach. Computer communications, 118:1–13,
2018.
[64] Lei You and Di Yuan. Load optimization with user association in cooperative and load-coupled lte
networks. IEEE Transactions on Wireless Communications, 16(5):3218–3231, 2017.
[65] Zhi Rui Tam, Cheng-Kuang Wu, Yi-Lin Tsai, Chieh-Yen Lin, Hung-yi Lee, and Yun-Nung Chen. Let me
speak freely? a study on the impact of format restrictions on large language model performance. In
Franck Dernoncourt, Daniel Preoţiuc-Pietro, and Anastasia Shimorina, editors, Proceedings of the 2024
Conference on Empirical Methods in Natural Language Processing: Industry Track, pages 1218–1236,
Miami, Florida, US, November 2024. Association for Computational Linguistics.
[66] OpenAI.
Introducing
structured
outputs
in
the
api.
https://openai.com/index/
introducing-structured-outputs-in-the-api, August 2024. Accessed: 2025-10-05.
[67] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation
of machine translation. In Pierre Isabelle, Eugene Charniak, and Dekang Lin, editors, Proceedings of
the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia,
Pennsylvania, USA, July 2002. Association for Computational Linguistics.
[68] Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. In Text Summarization
Branches Out, pages 74–81, Barcelona, Spain, July 2004. Association for Computational Linguistics.
[69] Tianyi Zhang*, Varsha Kishore*, Felix Wu*, Kilian Q. Weinberger, and Yoav Artzi. Bertscore: Evaluating
text generation with bert. In International Conference on Learning Representations, 2020.
[70] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep
bidirectional transformers for language understanding. In Jill Burstein, Christy Doran, and Thamar
Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association
for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers),
pages 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.
18


--- Page 19 ---
Preprint - December 2, 2025
[71] Anja Reusch, Maik Thiele, and Wolfgang Lehner. Transformer-encoder and decoder models for questions
on math. In Conference and Labs of the Evaluation Forum, 2022.
[72] Oscar Mañas, Benno Krojer, and Aishwarya Agrawal. Improving automatic vqa evaluation using large
language models. Proceedings of the AAAI Conference on Artificial Intelligence, 38(5):4171–4179, Mar.
2024.
[73] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi
Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac
Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha
Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun
Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, and
Jason Wei. Scaling instruction-finetuned language models. Journal of Machine Learning Research,
25(70):1–53, 2024.
A
Funding
This research was supported by the Natural Sciences and Engineering Research Council of Canada
(NSERC).
B
Selected Works for NL4RA
NL4RA consists of various resource allocation optimization problems in the networking domain. Table
A.1 categorizes the selected works based on multiple network domains relevant to the NL4RA dataset.
Furthermore, Table A.2 presents a mapping between selected works and specific problem instances from the
NL4RA dataset.
Table A.1: Categorization of Selected Works based on Different Network Domains for NL4RA
Network Domain
References
Radio Access Networks (Cloud-RAN, MIMO,
HetNet, Cognitive Radio Network and 5G NR)
[54], [56],[30],[32],[31],[33], [21], [34]
Network Technologies (Network Slicing, NFV
and SDN)
[22], [35],[36], [37],[38],[32], [39], [23], [24],[40],[31],[25], [34],
[41], [28], [55],[57],[58], [59],[53], [60], [42], [43]
Advanced Distributed Systems (Distributed
Cloud, F-RAN, Edge Computing, Fog Com-
puting, and UAV Relay Network)
[61],[36],[44],[53],[45], [46], [38],[32], [28],[57], [47], [53]
Communication Technologies (D2D and Wire-
less Communication)
[62],[27], [48],[49], [50], [63], [64],[51], [52], [26]
C
Prompt Templates for Candidate Generation
To systematically generate mathematical formulations for network resource allocation optimization problems,
we designed three distinct prompt strategies: Direct Prompt, Few-Shot Prompt, and Chain-of-Thought
Prompt. The detailed descriptions of these prompts are presented below.
Direct Prompt
The Direct Prompt focuses on providing minimal instructions to the LLM for translating a natural language
problem description into a mathematical formulation. The prompt emphasizes conciseness, with strict
adherence to LaTeX formatting for all equations and definitions, as shown below:
You are an expert in writing mathematical formulations for network resource allocation
optimization problems. I will give you a problem description. Your task is to give me a problem
formulation that includes the optimization model based on the decision variables, constraints, and
objective functions from the problem description.
Your response MUST contain only the problem formulation and equations or mathematical terms MUST
be in Latex format. After the objective function and constraints, include decision variable
definitions as well. DO NOT add additional text, or explanation before or after it.
19


--- Page 20 ---
Preprint - December 2, 2025
Table A.2: Selected Paper Vs Sample Dataset Mapping - NL4RA
Selected Works
Problem Instance
Resource Optimization With Flexible Numerology and Frame Structure for Heterogeneous Services [22]
Sample 1
A Joint Algorithm for Resource Allocation in D2D 5G Wireless Networks [62]
Sample 2, Sample 3
Inter-slice B5G Bandwidth Resource Allocation [35]
Sample 4
A Resource Allocation Model Based on Trust Evaluation in Multi-Cloud Environments [61]
Sample 5
Ensemble Deep Learning Assisted VNF Deployment Strategy for Next-Generation IoT Services [36]
Sample 6
Interference Minimization in D2D Communication Underlaying Cellular Networks [27]
Sample 7
Near-Optimal Resource Allocation Algorithms for 5G+ Cellular Networks [44]
Sample 8
System Capacity Maximization With Efficient Resource Allocation Algorithms in D2D Communication [48]
Sample 9
Relax online resource allocation algorithms for D2D communication [49]
Sample 10
An online resource allocation algorithm to minimize system interference for inband underlay D2D
communications [50]
Sample 11
Optimal Allocation of vBBUs Considering Distance Between MDC and RRH in F-RANs [53]
Sample 12
5G Millimeter Wave Network Optimization: Dual Connectivity and Power Allocation Strategy [37]
Sample 13, Sample 14,
Sample 15
A Migration Path Toward Green Edge Gaming [45]
Sample 16
MoDEMS: Optimizing Edge Computing Migrations for User Mobility [46]
Sample 17
Opportunistic non-contiguous OFDMA scheduling framework for future B5G/6G cellular networks [54]
Sample 18
Patient-Centric HetNets Powered by Machine Learning and Big Data Analytics for 6G Networks [56]
Sample 19
A Multi-Dimensional Resource Crowdsourcing Framework for Mobile Edge Computing [38]
Sample 20
Policy-Gradient-Based Reinforcement Learning for Computing Resources Allocation in O-RAN [30]
Sample 21
Re-configuration of UAV Relays in 6G Networks [32]
Sample 22
Towards 6G Joint HAPS-MEC-Cloud 3C Resource Allocation for Delay-Aware Computation Offloading [39]
Sample 23
PDRAS: Priority-Based Dynamic Resource Allocation Scheme in 5G Network Slicing [23]
Sample 24
Two-Tier Resource Allocation in Dynamic Network Slicing Paradigm with Deep Reinforcement Learning
[24]
Sample 25
A Network Slice Resource Allocation and Optimization Model for End-to-End Mobile Networks [40]
Sample 26
Adaptive Codebook Design and Assignment for Energy Saving in SCMA Networks [31]
Sample 27, Sample 28
Adaptive Pilot Design for Massive MIMO HetNets with Wireless Backhaul [33]
Sample 29
Economic Node Allocation in Software Defined Wireless Networks with Forecasted Traffic and Distance
Constraints [25]
Sample 30
Energy-aware relay selection in cooperative wireless networks: An assignment game approach [21]
Sample 31
Energy-Efficient Joint Content Caching and Small Base Station Activation Mechanism Design in
Heterogeneous Cellular Networks [34]
Sample 32
Efficient caching resource allocation for network slicing in 5G core network [41]
Sample 33
Joint power control and channel assignment in uplink IoT Networks: A noncooperative game and auction
based approach [63]
Sample 34
Edge Gaming: A Greening Perspective [28]
Sample 35
Leveraging Intelligence from Network CDR Data for Interference Aware Energy Consumption Minimization
[55]
Sample 36
Load Optimization With User Association in Cooperative and Load-Coupled LTE Networks [64]
Sample 37, Sample 38
MOCA: Multiobjective Cell Association for Device-to-Device Communications [51]
Sample 39, Sample 40
Deep Neural Network Task Partitioning and Offloading for Mobile Edge Computing [57]
Sample 41
Joint Optimization of Communication Latency and Resource Allocation in Cloud Radio Access Networks
[47]
Sample 42
Distributed Radio Slice Allocation in Wireless Network Virtualization: Matching Theory Meets Auctions
[52]
Sample 43
Optimal Slice Allocation in 5G Core Networks [58]
Sample 44
Network Function Virtualization Resource Allocation Based on Joint Benders Decomposition and ADMM
[59]
Sample 45
Optimal Virtual Network Function Deployment for 5G Network Slicing in a Hybrid Cloud Infrastructure
[53]
Sample 46
RAN Slice Access Control Scheme Based on QoS and Maximum Network Utility [60]
Sample 47
Slice-Aware Resource Calendaring in Cloud-based Radio Access Networks [42]
Sample 48
Optimizing spectrum efficiency in 6G multi-UAV networks through source correlation exploitation [26]
Sample 49
Minimum cost spectrum allocation with QoS guarantees in multi-interface multi-hop dynamic spectrum
access networks [43]
Sample 50
20


--- Page 21 ---
Preprint - December 2, 2025
Problem description to formulate:
Few-Shot Prompt
The Few-Shot Prompt provides an example problem and its corresponding mathematical formulation to
guide the LLM. The example problem and its formulation are embedded within the prompt, as demonstrated
below:
You are an expert in writing mathematical formulations for network resource allocation
optimization problems. I will give you a problem description. Your task is to give me a problem
formulation that includes the optimization model based on the decision variables, constraints, and
objective functions from the problem description.
Your response MUST contain only the problem formulation and equations or mathematical terms MUST
be in Latex format. After the objective function and constraints, include decision variable
definitions as well. DO NOT add additional text, or explanation before or after it. Here is an
example:
----------------------------------
"Suppose a base station has two categories of services, denoted by $K(\ell)$ and $K(c)$, where
services of $K(\ell)$ are prioritized over $K(c)$. For any service $k \in K(\ell)$, the data
demand is denoted by $q_k$ (in bits) and must be met with a latency tolerance (time until data has
been fully transmitted) of $\tau_k$.
The target is to maximize the total throughput of $K(c)$ through optimal resource configuration of
numerology and frame structure for each service, subject to latency and demand constraints for
$K(\ell)$. You can consider the resource configuration of numerology and frame structure as
blocks, and define a candidate set $B$ for blocks and a set of basic units $I$ where each unit i
is associated with each block to ensure that the services are non-overlapping. For each $b \in B$,
the achieved throughput on block $b$, if $b$ is assigned to service $k$ ($k \in K$), is denoted by
$r_{{b,k}}$.
The optimization task is to select the blocks for each service so that the latency and demand
requirements for $K(\ell)$ are met, without overlapping the chosen ones."
Example Problem Formulation:
\max_{{x \in \{{0,1\}}}} \sum_{{k \in K(c)}} \sum_{{b \in B}} r_{{b,k}} x_{{b,k}}
\\ \text{{s.t.}}
& \sum_{{b \in B}} r_{{b,k}} x_{{b,k}} \geq q_k, \quad k \in K(\ell) \\
& r_{{b,k}} = 0 \quad \text{{if block }} b \text{{ exceeds the latency }} \tau_k \text{{ for
service }} k \in K(\ell) \\
& \sum_{{k \in K}} \sum_{{b \in B}} a_{{b,i}} x_{{b,k}} \leq 1, \quad i \in I
where:
- $x_{{b,k}} \in \{{0, 1\}}$: Whether block $b$ is assigned to service $k$. If $x_{{b,k}} = 1$,
block $b$ is assigned to service $k$; otherwise, $x_{{b,k}} = 0$.
- $a_{{b,i}}$: Whether block $b$ includes basic unit $i$. $a_{{b,i}}=1$ if it includes the basic
unit, otherwise 0.
- $K(\ell)$: Category of service that has strict latency requirement.
- $K(c)$: Another category of service that has a specific latency tolerance.
- $q_k$: Data demand (in bits) for any service $k \in K(\ell)$.
- $\tau_k$: Latency tolerance for service $k \in K(\ell)$.
- $B$: Set of blocks.
- $I$: Set of basic units.
- $r_{{b,k}}$: Achieved throughput on block $b$ if assigned to service $k$.
----------------------------------
Now, apply the same procedure for the following problem description:
Chain-of-Thought Prompt
The chain-of-thought Prompt guides the LLM through a step-by-step reasoning process. The prompt is given
below:
You are an expert in mathematical optimization modeling for network resource allocation problems.
Your task is to formulate optimization problems step by step by following these systematic
reasoning stages:
1. Variable Identification:
21


--- Page 22 ---
Preprint - December 2, 2025
- Begin by carefully identifying all decision variables mentioned in the problem description.
- For each variable, determine its domain (binary, continuous, integer) and define its indices
and associated sets.
2. Constraint Analysis:
- Systematically analyze the problem to identify resource limitations.
- Note down technical requirements specific to the system.
- Recognize and categorize system constraints.
3. Objective Function:
- Identify the primary goal of optimization (maximize or minimize a specific metric).
- Clearly express this goal as a mathematical formula.
- Ensure the formulation aligns with the problem's stated objectives.
4. Mathematical Formulation:
- Present a detailed mathematical representation:
- Write the complete objective function using LaTeX.
- List all constraints in LaTeX format.
- Provide precise definitions for all variables and parameters.
Output Requirements:
- Your response MUST adhere to the following format, strictly using LaTeX for all mathematical
expressions:
\text{{Objective Function:}} & \quad <Objective in LaTeX> \\
\text{{s.t.}} \\
\text{{Constraints:}} & \quad <Constraints in LaTeX> \\
where:
- <Variable Definitions>
- <Parameter Definitions>
Additional Requirements:
- Do NOT include any explanatory text or additional information outside this format.
- Your response should contain: 1. The objective function in LaTeX format.
2. All constraints in LaTeX format.
3. Complete definitions of variables and parameters.
Follow the format strictly and avoid any deviations. Problem description:
D
Structured Ranking Prompt
The structured ranking prompt used for evaluating candidate solutions is given below:
You are an expert in formulating and evaluating mathematical optimization problems. Below are two
candidate solutions to a problem description.
1. **Read the problem description thoroughly** and carefully examine each candidate solution.
2. Evaluate them against these criteria:
- **Completeness**: Does it include all necessary decision variables, constraints, and a proper
objective function?
- **Correctness**: Are the expressions coherent, consistent with the problem description, and
logically valid?
- **Clarity**: Is the LaTeX notation and overall structure easy to follow and aligned with
standard optimization conventions?
3. **Rank** the solutions:
- **"Best" (rank=1)**: The most complete, correct, and clear.
- **"Second_Best" (rank=2)**: Good, but weaker than the best.
4. **Important**:
- Any candidate (1 or 2) could be best.
- Do not automatically select Candidate 1 as best.
- Provide each rank only once (1, 2).
5. At the end, output your final ranking strictly in the JSON format we require (with keys "Best"
and "Second_Best").
Problem Description:
Candidate 1:
Candidate 2:
Now, based on your thorough evaluation, provide your final ranking as valid JSON.
22
