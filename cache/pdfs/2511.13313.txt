--- Page 1 ---
1
Distributed Hierarchical Machine Learning for Joint
Resource Allocation and Slice Selection in
In-Network Edge Systems
Sulaiman Muhammad Rashid, Ibrahim Aliyu, Jaehyung Park, Seungmin Oh and Jinsul Kim
Abstract—The Metaverse promises immersive, real-time ex-
periences; however, meeting its stringent latency and resource
demands remains a major challenge. Conventional optimization
techniques struggle to respond effectively under dynamic edge
conditions and high user loads. In this study, we explore a slice-
enabled in-network edge architecture that combines computing-
in-the-network (COIN) with multi-access edge computing (MEC).
In addition, we formulate the joint problem of wireless and
computing resource management with optimal slice selection as
a mixed-integer nonlinear program (MINLP). Because solving
this model online is computationally intensive, we decompose
it into three sub-problems—(SP1) intra-slice allocation, (SP2)
inter-slice allocation, and (SP3) offloading decision—and train
a distributed hierarchical DeepSets-based model (DeepSets-S)
on optimal solutions obtained offline. In the proposed model,
we design a slack-aware normalization mechanism for a shared
encoder and task-specific decoders, ensuring permutation equiv-
ariance over variable-size wireless device (WD) sets. The learned
system produces near-optimal allocations with low inference time
and maintains permutation equivariance over variable-size device
sets. Our experimental results show that DeepSets-S attains high
tolerance-based accuracies on SP1/SP2 (Acc@1 = 95.26% and
95.67%) and improves multiclass offloading accuracy on SP3
(Acc = 0.7486; binary local/offload Acc = 0.8824). Compared to
exact solvers, the proposed approach reduces the execution time
by 86.1%, while closely tracking the optimal system cost (within
6.1% in representative regimes). Compared with baseline models,
DeepSets-S consistently achieves higher cost ratios and better
utilization across COIN/MEC resources.
Index Terms—Edge computing, Hierarchical learning, In-
network computing, Slice selection, Resource allocation
I. INTRODUCTION
The metaverse has attracted considerable attention from
academia and industry in the last few years, and significant
advancements have been in this technology owing to recent de-
velopments such as extended reality, 5G, and edge intelligence,
among others [1]. However, the extremely high demand for
This work was supported by the Institute of Information & communica-
tions Technology Planning & Evaluation(IITP) grant funded by the Korea
government(MSIT), Project Name: Development of digital twin-based net-
work failure prevention and operation management automation technology,
Project Number: RS-2025-00345030, Contribution Rate: 50%. This work
was also supported by the Institute of Information & Communications
Technology Planning & Evaluation(IITP)-Innovative Human Resource De-
velopment for Local Intellectualization program grant funded by the Korea
government(MSIT)(IITP-2025-RS-2022-00156287), Contribution Rate: 50%.
Sulaiman Muhammad Rashid, Ibrahim Aliyu, Jaehyung Park, Seung-
min Oh and Jinsul Kim are with the Department of Intelligent Electron-
ics and Computer Engineering, Chonnam National University, Gwangju
61186, South Korea (e-mails: msulaimanrashid@jnu.ac.kr; aliyu@jnu.ac.kr;
hyeoung@jnu.ac.kr; osm5252kr@gmail.com; jsworld@jnu.ac.kr).
resources (for example, computing, networking, and storage)
in the Metaverse is one of the major challenges that prevent
Metaverse deployment [2]. An enormous number of resources
is required to fulfill the Quality-of-Service (QoS) requirements
and meet user experience expectations in the Metaverse.
Metaverse, which can simultaneously host a hundred thousand
users, is expected to support millions of users concurrently [3].
To meet these demands, mobile edge computing (MEC) has
been widely adopted as a key enabler, bridging the gap be-
tween computational resources end-users to reduce latency and
improve service quality [4]. Although MEC offers remedies
through remote offloading (RO), it does not meet concurrent
user demands [5]. “Computing in the network” (COIN), some-
times termed ”in-network computing,” has emerged as a com-
plementary approach that extends computing resources closer
to the user by leveraging distributed nodes within the network
[6]. COIN processes tasks at various points along the data path,
reducing latency and improving resource utilization. The idea
of COIN is not to replace the MEC, but to collaborate with
the MEC [5], leveraging additional computational resources
distributed across the network. However, augmenting comput-
ing resources or enabling COIN leads to heightened power
consumption [7]. Segal et al. [8] have shown the potential of
in-network computing for reducing network utilization cost;
however, effectively allocating COIN resources in real-time
to adapt to continually shifting user demands, while ensuring
overall system availability, poses a critical challenge.
Network slicing allows for the creation of virtual networks
(slices) over a shared physical infrastructure, with each slice
designed to meet the specific requirements of different ap-
plications [9], [10]. In the context of the Metaverse, slicing
can provide tailored computational, bandwidth, and latency
conditions to accommodate diverse use cases (from gaming to
healthcare) [11]. However, the dynamic allocation of resources
across these slices is a challenging task; dynamic allocation
ensures that resources are optimally distributed between com-
munication and computation while adapting to the varying
demands of users and tasks.
Previous researchers [12], addressed joint network slicing
and in-network computing resource allocation using a water-
filling-based heuristic algorithm. However, their focus was
solely on managing resources between slices (inter-slice),
without considering the resource management issues within
the slices (intra-slice). Furthermore, heuristic algorithms can
achieve optimal solutions in a feasible amount of time, but
they are not easy to derive [13].
arXiv:2511.13313v3  [cs.DC]  2 Feb 2026


--- Page 2 ---
2
Recently, AI approaches as proposed in the concept of
intelligent edge and considered a key 6G enabler have been
used to determine how to allocate computing and communica-
tion resources across networks [14]. This methodology holds
promise by replacing complex mathematical modeling of the
system to derive mathematically tractable heuristics with a
data-driven understanding of the network. For example, the
authors of [15] focused on the allocation of network resources
to provide service function chains (SFCs). After proposing a
linear integer programming problem, they developed a hybrid
strategy combining the optimal approach with supervised
machine learning (ML) to find adequate network resources
while decreasing the resolution time.
In this paper, we address the joint network slicing, inter-slice
& intra-slice radio, and in-network resource management prob-
lems. We formulated the problem in [16] as a mixed-integer
non-linear programming problem (MINLP). The optimal solu-
tion achieved through a standard optimization solver is lever-
aged to train our DeepSet-S model by feeding it with informa-
tion about the user’s task requests and the state of the network.
Therefore, the optimal solutions do not need to be computed
online and instead are replaced with the model to provide
quicker resource allocation and task placement decisions,
albeit at the expense of heavy training procedures. DeepSets-S
introduces a distributed hierarchical encoder–decoder archi-
tecture that learns to approximate solver-generated optimal
policies for intra-slice, inter-slice, and offloading decisions.
The model incorporates a shared encoder and task-specific
decoders, ensuring permutation equivariance across variable-
size wireless device (WD) sets and enabling scalable inference
at both the slice and network levels. Specifically, our paper
makes the following key contributions:
• We decomposed the problem into three sub-problems:
we first derive the optimal intra-slice resource allocation
policy, then address the optimal inter-slice resource al-
location policies, and finally, find the optimal offloading
decision vector.
• We developed a set-based encoder–decoder model that
learns intra- and inter-slice allocation policies from solver
data through a shared permutation-equivariant encoder
and a novel slack-aware decoder that ensures feasible
bandwidth and computing allocations within capacity
limits.
• We employ a multi-head decoder to infer the optimal of-
floading decision vector. The architecture jointly predicts
whether to execute locally or offload.
• We performed an extensive evaluation to show that the
performance of the resulting system significantly outper-
forms baseline resource allocation schemes.
The rest of this paper is organized as follows. Section II
reviews related works. Section III presents the system model.
Section IV describes the optimization problem formulation.
Section V details the proposed DeepSets-S model. Section
VI reports experimental results and evaluations, Section VII
presents the discussions and limitations, and Section VIII
concludes the paper.
II. RELATED WORKS
A. Computing in the network (COIN) / In-Network Computing
Sapio et al [17] describe COIN as a dumb idea whose
time has come. It extends computing infrastructure closer
to the user, typically within proximity to end-users or IoT
devices [18]. Several studies have explored the potential of
COIN in various domains, including metaverse, holographic
applications, IoT, smart cities, and multimedia applications
[5], [7], [13], [19]–[21]. The authors in [13] considered the
problem of optimal placement of delay-constrained tasks to
COIN nodes in an intelligent edge based on specific require-
ments to minimize network resource usage for low-latency task
execution. Similarly, in a study conducted by [19], the authors
developed a task-offloading solution for delay-constrained
Metaverse systems to determine the optimal decision for
offloading rendering tasks to COIN nodes or edge servers.
The work in [20] proposes an SDN-based COIN framework to
place reusable, delay-sensitive computing tasks directly within
the data forwarding path. Aliyu et al. [7] propose a COIN-
assisted edge architecture for Industrial IoT to reduce compu-
tation latency via partial offloading over URLLC links. The
authors formulate a joint optimization of offloading decisions,
ratios, and resource allocations, leveraging a hybrid game-
theoretic approach combined with Double Deep Q-Networks
(DDQN) to support low-complexity and distributed resource
management. Wu et al. [21] optimized COIN performance by
adjusting the Computing Data Unit (CDU) size to reduce end-
to-end latency in multi-hop in-network computing systems.
These works have not addressed, however, the potential
impact of slicing on COIN nodes. So far, it is unclear how to
perform joint management of communication and computing
resources in a COIN-enabled system under network slicing.
B. ML-based Resource Management
Solving targeted optimization problems, such as minimiz-
ing energy consumption, latency, or bandwidth usage, either
individually or jointly, typically involves addressing compu-
tationally intensive NP-hard problems. According to [22],
machine learning (ML) techniques offer a promising alter-
native to traditional mathematical modeling of the system,
enabling the derivation of mathematically tractable heuristics
with a data-driven understanding of the system. For instance,
[23] proposed a collaborative ML resource allocation scheme
tailored for SDN-enabled fog computing, while [13] analyzed
four classes of supervised learning methods; Decision tree
(DT), Support vector machine (SVM), Multi-layer perceptron
(MLP), and Bagged trees (BT) for task placement optimization
at the network edge. In [24], the authors proposed a predictive
ML-based approach to monitor and guarantee the quality of
network slice service by analyzing throughput and packet loss
rate key quality indicators (KQI). Liu et al. [25] proposed
a learning-assisted end-to-end network slicing framework for
resource allocation and task completion time minimization
in heterogeneous networks. In [26], SVM and MLP were
employed for application placement in mobile edge computing
servers. By formulating the problem as a two-stage stochastic
optimization model, this study demonstrated the effectiveness


--- Page 3 ---
3
of ML models in improving solution times and decision-
making accuracy for user-to-server request allocation.
While previous works employing ML focus on instance
based inference, where each decision is derived for individual
users or requests in isolation, we addressed a set-structured/set
input problem. We consider groups of WDs jointly, treating
the task as a multiple instance learning problem. To capture
this structure, we employ a DeepSet-based encoder–decoder
architecture [27], enabling the model to learn permutation-
invariant representations of the WD sets.
III. SYSTEM MODEL
We consider a slice-enabled network edge domain char-
acterized by distinct application slices N = {1, 2, . . . , N},
which have combinations of computing resources optimized
for executing intensive tasks. We denote by I = {1, 2, . . . , I}
as set of Wireless Devices (WD) that generate computationally
intensive tasks each with varying computational demands.
Task i generated by I characterized with input size Si can
either be computed locally, or assigned to a slice n through
set A = {1, 2, . . . , A} of access points (AP).
In the case of assigning the task to slice, it goes through
exactly one AP and can either be computed within the network
on a set of COIN C = {1, 2, . . . , C}, or can be offloaded to
a set of MEC M = {1, 2, . . . , M}. For simplicity, we denote
N to be the set of all edge nodes (ENs), i.e C ∪M. The APs
and ENs form the set E ≜N ∪A of edge resorces. For all the
task generated, there is expected number of instructions Ri
required to perform the computation. Since the WD, COIN
and MEC have different instruction set of architectures, the
required number of instructions may also vary. Therefore,
for a task generated by WD i we denote by Li, Li,n as
the expected number of instructions locally and in slice n
respectively which we considered them to be estimated by
methods described in [28], [29].
We define set of decisions for task i as ∆i = {i} ∪
{(a, j, n) | a ∈A, j ∈N, n ∈N} and we will use δi ∈∆i
to indicate the decision for WD i’s task i.e δi = i indicates
that the task should be performed locally, and δi = (a, j, n)
indicates that task should be offloaded through AP a to node j
in slice n. Hence, we define a decision vector (δ) = (δi)i∈I as
the collection of the decisions of all WD’s and we define the
set ∆= ×i∈I∆i, i.e., the set of all possible decision vectors:
WD’s utilizing Access Point a within Slice n are captured
in Oa,n(δ), representing i ∈I where δi = (a, ·, n), spanning
across all available access points a and slices n. The aggrega-
tion of these sets across all slices yields Oa(δ), indicating all
WDs employing Access Point a for task processing. Similarly,
WD’s employing node j within Slice n are compiled in
Oj,n(δ), denoting i ∈I where δi = (·, j, n), with Oj(δ)
encompassing all WD’s utilizing node j across slices. The
singleton set Oi(δ) distinguishes whether a WD i performs
local computation (Oi(δ) = {i}) or not (Oi(δ) = ∅). Finally,
Ol(δ) represents all WDs performing local computation within
the given decision vector δ.
Fig. 1 shows an example of a slicing-enabled COIN-MEC
architecture with N = 3 slices, I = 6 WDs, A = 3 APs,
M = 1 MEC and C = 6 COINs.
A. Communication Resources
In the network, the communication resources are managed
both at the network level and at the slice level. At the network
level, the radio resources of each access point (AP) are
shared across the slices based on an interslice radio resource
allocation policy, denoted as Rω : ∆→R|A|×|N |
[0,1]
. This
policy determines the inter-slice radio resource provisioning
coefficients ωa
n, where ∀(a, n) ∈A × N, ωa
n ≤1.
At the slice level, the radio resources assigned to each
slice are shared among the WD’s according to an intraslice
radio resource allocation policy Rn
ϕa : ∆→R|A|×|I|
[0,1]
. This
policy determines the intra-slice radio resource provisioning
coefficients ϕn
i,a ∈[0, 1], where ∀a ∈A and ∀i ∈Oa,n(δ),
such that P
i∈Oa,n(δ) ϕn
i,a ≤1, ∀(a, n) ∈A × N.
The achievable Physical rate of a WD i at AP a, denoted
as Ri,a, captures the expected channel conditions, which can
be estimated through historical measurements. Given Ri,a and
the provisioning coefficients ωn
a and ϕn
i,a, the uplink rate of
WD i at AP a in slice n is expressed as:
Un
i,a(δ, Rb, Rn
ϕa) = ωn
aϕn
i,aRi,a
(1)
The uplink rate, along with the input data size Si, deter-
mines the transmission time of WD i in slice n at AP a:
T tx,n
i,a (δ, Rb, Rn
ϕa) =
Si
Un
i,a(δ, Rb, Rn
ϕa)
(2)
Fig. 1: Slicing enabled COIN-MEC System with N = 3 slices,
I = 6 WDs, A = 3 APs, M = 1 MEC and C = 6 COINs
B. Computing Resources
In our system model, we distinguish between two main
categories of computing resources: edge resources and local
resources. Within this framework, each slice n is equipped
with a specific combination of computing resources N equal
to C ∪M tailored for executing particular type of task,
encompassing CPUs, GPUs, NPUs, and FPGAs. We denote
by F n
j
the computing capability of node j in slice n. The
allocation of these computing resources among the WD’s is
controlled by intra-slice computing power allocation policies


--- Page 4 ---
4
Rn
ϕj : ∆→R|N|×|I|
[0,1]
. This policy determines the provi-
sioning coefficients ϕn
i,j ∈[0, 1],
∀i ∈Oj,n(δ), such that
P
i∈Oj,n(δ) ϕn
i,j ≤1,
∀(j, n) ∈N × N ensuring that each
WD receives a portion of the available computing power
within the slice. Specifically, the computing capability F n
j
allocated to WD i within the cloud in slice n is expressed
in the following equation:
F n
i,j(δ, Rn
ϕj) = ϕn
i,jF n
j
j ∈N
(3)
We assumed like in the literature [13], [19], and justified
by empirical studies [30], the arrival rate of requests of
task generated by WD i at node j of slice n follows a
Poisson distribution with parameter αi. The expected number
of instructions Li,n required to execute a task generated by
WD i in slice n is exponentially distributed. Therefore, all
nodes can form an M/M/1 queuing model to process their
corresponding computing tasks. The total request arrival rate
at node j, which still follows a Poisson distribution, can be
defined as:
X
i∈I
δijαi,
j ∈N
(4)
where δij is the binary decision variable. It is equal to 1 if
task generated by WD i is executed by node j and equal to 0
otherwise.
Thus, exploiting the queuing theory, the average computa-
tion time for a generic task at node j of slice n can be derived
as:
T ex
i,j (δ, Rn
ϕj) =
1
Fi,jn
Li,n −P
i∈I δijαi
,
j ∈N
(5)
To keep the queue stable, the average arrival rate, αi should
be smaller than the average service rate, as described by the
following equation:
Fi, jn
Li,n
−
X
i∈I
δijαi > 0,
j ∈N
(6)
In addition to the cloud resources, each WD possesses local
computing capabilities denoted by F l
i which may vary over
different devices. The local execution latency T ex
i
of WD i is
simply expressed as
T ex
i
= Li
F l
i
(7)
C. Cost Model
We define the system cost as the aggregate completion
time of all WD’s. Before providing a formal definition, we
introduce the shorthand notation:
T n
i,e =



Si
Ri,e
if i ∈I, e ∈E ∩A
1
Fi,jn
Li,n −P
i∈I δijαi
if i ∈I, e ∈E ∩N
(8)
For e ∈E ∩A we have that e is a communication resource
and T n
i,e is the minimum transmission time that WD i will
achieve if it is the only WD offloading its computation through
AP e in slice n. Similarly, for e ∈E ∩C we have that e is a
computing resource and T n
i,e is the minimum execution time
that WD i will achieve if it is the only WD offloading its
computation to Node j in slice n
To facilitate notation, we define the indicator function for
WD i:
I(δi, δ) =
(
1
if δi = δ
0
otherwise
(9)
The cost of WD i is then determined by the task completion
time, considering both local computation and offloading to
edge:
Ci(δ, Rω, Rϕa, Rϕj) =T ex
i I(δi, i)
+
X
n∈N
X
j∈N
X
a∈A
( T n
i,a
ωnaϕn
i,a
+T n
i,j
ϕn
i,j
!
I(δi, (a, j, n))
(10)
Here, (Rϕa, Rϕj) = ((Rn
ϕa, Rn
ϕj, ))n ∈N represents the
collection of slice policies.
The cost of each slice n is calculated as the sum of
transmission and execution times for all WD’s offloading their
tasks in slice n:
C(n)(δ, Rω, Rn
ϕa, Rn
ϕj) =
X
e∈E
X
i∈Oe,s(δ)
T n
i,e
ωne ϕn
i,e
(11)
Here, ωn
e = 1 if e is a computing resource.
Finally, the system cost is expressed as the sum of individual
WD costs and slice costs:
C(δ, Rω, Rϕa, Rϕj) =
X
i∈I
Ci(δ, Rω, Rn
ϕa, Rn
ϕj)
+
X
n∈N
C(n)(δ, Rb, Rn
ϕa, Rn
ϕj)
(12)
This system cost formulation accounts for both local and
offloaded computation across slices.
IV. OPTIMIZATION PROBLEM FORMULATION
Our goal is to minimize the system cost by finding the
optimal decision from vector d of offloading decisions. From
the above analytical results, the problem can be expressed
mathematically as a mixed-integer non linear programming
(MINLP) problem and is formulated as follows:
min
δ,Rω,Rϕa,Rϕj
C(δ, Rω, Rϕa, Rϕj)
(13)
s.t.


--- Page 5 ---
5
X
δ∈∆i
I(δi, δ) = 1,
i ∈I
(13a)
T ex
i,j (δ, Rn
ϕj) ≤T ex
i ,
i ∈I
(13b)
Fi, jn
Li,n
−
X
i∈I
δijαi > 0,
j ∈N
(13c)
X
n∈N
ωn
a ≤1,
a ∈A
(13d)
X
i∈Oe,n(δ)
ϕn
i,e ≤1,
n ∈N, e ∈E
(13e)
ωn
a ≥0,
a ∈A
(13f)
ϕn
i,e ≥0,
n ∈N, e ∈E
(13g)
The constraint 13a ensures that each WD performs a compu-
tation locally or offloads its task to exactly one logical resource
on the edge (a, j, n) | a ∈A, j ∈N, n ∈N. The constraint
13b indicates that the task completion time when offloading is
not greater than when computing locally. The constraint 13c
forces the average service rate of the edge nodes to be higher
than the average task arrival rate in the case of offloading.
Constraints 13d & 13e enforce limitations on the amount of
radio resources that can be provided to an AP in each slice,
and the amount of computing resources of an edge node that
can be provided to each WD in each slice. Constraints 13f
& 13g are non-negativity constraints that ensure the values of
the provisioning coefficients are non-negative.
V. DISTRIBUTED HIERARCHICAL DEEPSET-S MODEL FOR
RESOURCE MANAGEMENT AND TASK OFFLOADING
The MINLP problem formulated in equation 13 corresponds
to the Generalized Assignment Problem (GAP) [31], which
is an NP-hard problem in the combinatorial optimization
literature. Due to its complexity, resolving it by using a
standard optimization solver is not feasible; it would take
a long time to arrive at the optimal solution. Therefore, a
more dynamic solution is needed to solve the MINLP problem
efficiently, even at the expense of a suboptimal solution.
For this purpose, consistent with the recent studies [13],
[19], we decompose the MINLP into a sequence of N + 2
optimization subproblems, which are solved sequentially using
machine learning (ML)-based techniques.
User 
Request
Slice Manager
Slice Manager
Slice Manager
Slice
Resource
Orchestrator
(SRO)
Fig. 2: Distributed Hierarchical AI Model
Subproblem 1 (SP1): As a first step in the decomposition,
consider the problem of finding an optimal collection Rn
ϕa, Rn
ϕj
of slice resource allocation policies for fixed offloading deci-
sion vector δ and interslice policy Rω, for which constraint
13b can be satisfied. Then the solution to the problem is given
by:
min
Rϕa,Rϕj
X
n∈N
X
e∈E
X
i∈Oe,n(δ)
T n
i,e
ϕn
i,e
(14)
st.(13b), (13c), (13e), (13g)
(14a)
Set
Input
Encoder
Decoder
Fig. 3: DeepSets-S Model
Subproblem 2 (SP2): As a second step in the decom-
position, consider the problem of finding an optimal inter-
slice radio resource allocation policy Rω for fixed offloading
decision vector δ and the optimal collection Rn
ϕa, Rn
ϕj of the
slices policies, for which constraint 13b can be satisfied.
min
Rω
X
n∈N
X
a∈A
1
ωna


X
j∈Oa,n(δ)
τ n
i,a


2
(15)
st.(13b), (13c), (13d), (13f)
(15a)
Subproblem 3 (SP3): As the final step, let us consider
the problem of finding the optimal collection (Rω, Rn
ϕa, Rn
ϕj)
of resource allocation policies first, and finding an optimal
offloading decision vector δ second.
min
δ
min
Rω,Rn
ϕa,Rn
ϕj
C(δ, Rω, Rn
ϕa, Rn
ϕj)
(16)
st.(13a) −(13g)
(16a)
In what follows, we propose a hierarchical deepset model
in Figure 2 that solves SP1 for each slice, solves SP2 at the
network level, followed by SP3 to find the optimal offloading
decision vector.
The overall architecture follows a similar encoder to ensure
consistency across subproblems, while each subproblem is
equipped with a dedicated decoder tailored to its objective.
The encoder transforms set of WD indexed by i ∈I, where
the size of I varies from set to set. Each WD i contributes a
feature vector xi ∈OF . We combine the WDs features and
network status information into a single stacked input matrix
X =


x⊤
1
...
x⊤
I

∈OI×F ,
(17)


--- Page 6 ---
6
TABLE I: Symbol descriptions
Symbol
Description
N
Set of application slices
I
Set of Wireless Devices (WD)
A
Set of Access Points (AP)
C
Set of COIN nodes
M
Set of MEC nodes
Si
Input size of task i generated by WD i
Ri
Expected number of instructions required for task i
Li
Number of instructions to execute task i locally
Li,n
Number of instructions to execute task i in slice n
δi
Decision for task i, di ∈Di
∆i
Set of decisions for task i
Rω
Interslice radio resource allocation policy
ωa
n
Interslice radio resource provisioning coefficient
Rn
ϕa
Intraslice radio resource allocation policy
ϕn
i,a
Intraslice radio resource provisioning coefficient
Rn
ϕj
Intraslice computing resource allocation policy
ϕn
i,j
Intraslice computing resource provisioning coefficient
F n
j
Computing capability of node j in slice n
F n
i,j(δ, P n
ϕ )
Computing capability allocated to WD i in slice n
αi
Arrival rate of requests for task i
F l
i
Local computing capability of WD i
which is a set-valued representation: the row order carries no
semantic meaning and may be permuted without changing the
underlying set.
Since the WD count of I differs across sets, we pad each
X to a common set size Imax within a mini-batch. Let pad(·)
append all-zero rows as needed; the padded matrix is
¯X = pad(X) ∈OImax×F .
(18)
We define ¯X with a binary mask that indicates which rows
correspond to real WD and which are padding:
m = (m1, . . . , mImax)⊤∈{0, 1}Imax
(19)
mi =
(
1,
i = real WDi
0,
i = padding
(20)
This mask is used throughout the model to: (i) exclude padded
rows from set summaries and attention, and (ii) prevent padded
rows from receiving probability mass.
We standardize features to stabilize optimization. Let µ ∈
OF and σ ∈OF denote the per-feature mean and standard
deviation computed over the training set. We transform each
padded set by
˜Xi,: = ( ¯Xi,: −µ) ⊘σ ∈OF ,
i = 1, . . . , Imax
(21)
where ⊘denotes element-wise division; padded set remain
zeros after standardization.
Given ( ˜X, m) for a set with I real WD i and a fixed set of
allocation policy R indexed by e ∈{1, . . . , E}, our objective
is to learn a permutation-equivariant mapping that outputs, for
each R, a probability distribution over I plus a slack (unused
capacity) entry, summing to one per R. Formally,
fθ : OImax×F × {0, 1}Imax −→[0, 1](I+1)×E
(22)
I
X
u=0
Pu,e = 1 ∀e
(23)
where u = 1, . . . , I index real users and u = 0 denotes
slack. The mapping must respect user-set permutation sym-
metry and operate for arbitrary I ≤Imax.
A. DeepSet Encoder
Given the standardized and padded user matrix
˜X
∈
OImax×F and mask m ∈{0, 1}Imax from (18)–(21), the
encoder produces a contextual embedding for each WD row
while remaining permutation–equivariant in the WD dimen-
sion. The encoder follows a DeepSets-style architecture with a
row-wise embedding network ϕ and a context-fusing network
ρ.
A shared multilayer perceptron (MLP) ϕ : OF →RH maps
each user’s features to a hidden vector:
hi = ϕ
  ˜Xi,:

∈OH,
i = 1, . . . , Imax
(24)
Stacking
the
row-wise
outputs
yields
Hrow
=

h⊤
1 ; . . . ; h⊤
Imax

∈OImax×H
To capture global context from the set of (real) WD, we
compute a masked mean over the hidden vectors, excluding
padded rows:
c =
PImax
i=1 mi hi
PImax
i=1 mi + ε
∈OH,
(25)
where ε > 0 avoids division by zero in degenerate cases. The
same context vector c is broadcast to every row.
Fuse local and global information.: Each user combines
its local representation hi with the global context c via con-
catenation followed by a second shared MLP ρ : O2H →OD:
zi = ρ
 [ hi ; c ]

∈OD,
i = 1, . . . , Imax.
(26)
Stacking the resulting vectors forms the encoder output matrix
Z =


z⊤
1
...
z⊤
Imax

∈OImax×D.
(27)
Rows with mi = 0 correspond to padded users; these rows
are carried forward but ignored by all masked operations
downstream.
Let Π ∈{0, 1}Imax×Imax be a permutation matrix acting on
WD rows, and define Πm as the permuted mask. Because ϕ
and ρ act row-wise and the summary in (25) is a symmetric
(mean) operator, the encoder is permutation–equivariant:
Enc(Π ˜X, Πm) = Π Enc( ˜X, m).
(28)
B. Decoder
For SP1, given the encoder output Z ∈OImax×D in (27)
and the mask m ∈{0, 1}Imax, the decoder maps each WD i
embedding to per–resource scores and converts them into valid
WD–wise probability distributions for every O, augmented
with a slack term to capture unused capacity. Let the resource
index set be E = {1, . . . , E}.
For each e ∈E, the decoder maintains learned parameters
we ∈OD,
be ∈O,
se ∈O,
(29)


--- Page 7 ---
7
shared across all users. The WD logits and the slack logit are
li,e = w⊤
e zi + be,
i = 1, . . . , Imax,
l0,e = se
(30)
Stacking over WDs yields A ∈OImax×E with entries [A]i,e =
ai,e.
To ignore padded rows during normalization, we define
augmented masked logits ˜L ∈O(Imax+1)×E by
˜li,e =
(
li,e,
mi = 1,
−∞,
mi = 0,
i = 1, . . . , Imax,
˜l0,e = l0,e
(31)
For each e ∈E, we normalize along the augmented WD
axis:
pi,e =
exp
 ˜li,e

X
j∈{0,1,...,Imax}
exp
 ˜lj,e
,
(32)
Collecting all pi,e gives
P ∈[0, 1](Imax+1)×E,
Imax
X
i=0
pi,e = 1, ∀e ∈E.
(33)
The rows i = 1, . . . , Imax correspond to actual WDs; the row
i = 0 corresponds to slack.
By (33), each resource satisfies
Imax
X
i=1
ˆyi,e =
 1 −p0,e

≤1,
∀e ∈E,
(34)
thus enforcing constraint (13e) as proved in Lemma 1.
Moreover, since (30) is row-wise and the normalization (32)
acts symmetrically across WD rows (modulo masking), the
decoder is permutation–equivariant in the WD dimension;
combined with (28), the overall encoder–decoder mapping
preserves user permutations.
Let Y ∈[0, 1](Imax+1)×E denote the soft labels obtained by
scaling the outputs to [0, 1]. For each e ∈E, set
y0,e = max
n
0, 1 −
I
X
i=1
yi,e
o
,
Imax
X
i=0
yi,e = 1,
(35)
thus, the SP1 training objective is the masked cross-entropy
on the augmented simplex:
LSP1 = −
X
e∈E
Imax
X
i=0
¯mi yi,e log pi,e.
(36)
Lemma 1. For every slice n and resource e, the allocations
of resources per-WD {ϕn
i,e}i∈I produced by SP1 satisfy
X
i∈I
ϕn
i,e ≤1.
Proof. The SP1 decoder generates, for each resource e in
slice n, an augmented softmax distribution over the index
set {0} ∪I, where index 0 denotes a slack option corre-
sponding to unused capacity. Let the resulting probabilities be
p0, p1, . . . , p|I| with pk ≥0 and P
k pk = 1. Define ϕn
i,e = pi
for each user i. Then,
X
i∈I
ϕn
i,e =
X
i∈I
pi = 1 −p0 ≤1.
Hence, the total resource share allocated to users within
each slice never exceeds the available capacity of resource
e, satisfying constraint (13e).
For SP2, the outputs are set-level and identical for all WDs
in that set. We therefore first aggregate the encoder states by
a masked mean to obtain a single set embedding
g =
PImax
i=1 mi zi
PImax
i=1 mi + ε
∈OD
(37)
The SP2 decoder maintains learned parameters we
∈
OD,
be ∈O
for e ∈E,
s ∈O , and forms logits from
the pooled representation:
ae = w⊤
e g + be,
e ∈E,
a0 = s
(38)
A softmax over the augmented slice axis {0} ∪E yields a
normalized distribution
pk =
exp(ak)
P
ℓ∈{0}∪E exp(aℓ),
k ∈{0} ∪E
(39)
with predicted slice allocations ˆye = pe for e ∈E and unused
capacity p0. By construction,
X
e∈E
ˆye = 1 −p0 ≤1
(40)
as proved in Lemma 2, (40) enforces constraint (13d). Training
uses soft labels y = (ye)e∈E ∈[0, 1]E, augmented with a slack
target y0 = max

0, 1 −P
e∈E ye
	
. The loss is the cross-
entropy on the augmented simplex:
LSP2 = −
X
k∈{0}∪E
yk log pk.
(41)
Since (37)–(40) depend only on the pooled set embedding
g, the SP2 outputs are identical for every WD in the set,
as required, while the shared encoder and masked operations
preserve permutation equivariance in the WD dimension.
Lemma 2. For each Access Point a, the slice shares {ωn
a}n∈N
produced by SP2 satisfy
X
n∈N
ωn
a ≤1.
Proof. SP2’s decoder outputs an augmented softmax over the
set {0} ∪N, where index 0 is a slack option. Let the softmax
probabilities be p0, p1, . . . , p|N | with pk ≥0 and P
k pk = 1.
Define the usable slice shares as ωn
a := pn for each slice
n ∈N. Then
X
n∈N
ωn
a =
X
n∈N
pn = 1 −p0 ≤1.
Hence, the total per-AP allocation across slices never exceeds
the AP’s full capacity, and (13d) holds.
Finally, for SP3, each WD i is assigned an offloading
decision δi ∈∆i, which is either local execution or offloading
through AP a to node j in slice n. Given the encoder output
in (26), we use one joint head that scores the exact decision in
∆i. All heads share parameters across WDs and act row-wise.
With zi ∈OD, the WD logits and probabilities are
ℓi = W (δ)zi + b(δ) ∈O|∆i|,
(42)


--- Page 8 ---
8
pi = softmax(ℓi), 1⊤pi = 1,
(43)
and the predicted decision is the joint argmax
ˆδi = arg max
δ∈∆i [pi]δ,
(44)
which maps to a specific decision (n, a, j) when ˆδi ̸= local as
proved in Lemma 3.
To improve sample efficiency, we also include: (i) a binary
local/offload head
qi = σ
 w⊤
binzi + bbin

∈(0, 1),
(45)
and (ii) separate n/a/j heads
ni = W (n)zi + b(n) ∈O|N|,
p(n)
i
= softmax(ni) (46a)
ai = W (a)zi + b(a) ∈O|A|,
p(a)
i
= softmax(ai) (46b)
ji = W (j)zi + b(j) ∈O|J|,
p(j)
i
= softmax(ji) (46c)
We use the joint argmax over ∆i; an equivalent rule is
ˆδi =







local,
qi < 1
2,
(arg max p(n)
i
, arg max p(a)
i
,
arg max p(j)
i ),
otherwise.
(47)
Let yδ
i ∈{0, 1}|∆i| be the joint label, ybin
i
∈{0, 1} the
local/offload flag, and y(n)
i
, y(a)
i
, y(j)
i
the n/a/j labels for
offloaded WDs. With the padding mask mi from (20), we
minimize
Ljoint = −
X
i
mi

yδ
i , log pi

(48)
Lbin = −
X
i
mi
 ybin
i
log qi + (1 −ybin
i
) log(1 −qi)

(49)
Ln,a,j = −
X
i
mi ybin
i

y(n)
i
, log p(n)
i

+

y(a)
i
, log p(a)
i

+

y(j)
i , log p(j)
i

(50)
and combine them (weights λbin, λfac ≥0; set to 1 unless
stated otherwise):
LSP3 = Ljoint + λbin Lbin + λfac Ln,a,j.
(51)
Because all mappings above act row-wise with shared param-
eters and all normalizations respect the mask, the decoder is
permutation–equivariant in the WD dimension.
Lemma 3. Each WD i selects exactly one decision variable
δi from ∆i .
Proof. Let the SP3 classifier output a probability vector pi =
[p1
i , p2
i , . . . , pK
i ] ∈RK, where K = |∆i| is the number of
admissible offloading decisions for WD i. Since the final
decision is taken as bδi = arg maxk pk
i , exactly one index is
active while all others are inactive. Therefore,
K
X
k=1
bδk
i = 1,
satisfying constraint (13a).
TABLE II: Simulation Parameters
Parameter
Value
COINs node capacity
[5, 10] x 108 CPU cycles/s [13]
MEC capacity
1 x 1010 CPU cycles/s [13]
WD local computing capacity
2 x 107 CPU cycles/s [33]
Input task size
[1, 10] MB [32]
Bandwidth Ba per AP
18 MHz [34]
Transmit Power of WD’s
[10−6, 0.1]W [28]
distance
4
VI. EXPERIMENTS AND EVALUATION
A. Dataset Generation
The datasets used to train and evaluate the proposed
DeepSets-S model were generated by solving the optimization
problem formulated in Section IV using standard nonlinear
solvers. Each solution captures the interactions among wire-
less device (WD) requests, slice configurations, access points
(APs), and edge nodes (COIN and MEC). A total of 5,000
simulation runs were conducted under varying user sizes,
bandwidth distributions, and slice configurations, resulting in
three distinct datasets corresponding to the decomposed sub-
problems introduced in Section V:
• SP1 dataset: Takes the user request information as input
and produces the optimal intra-slice radio and computing
allocation coefficients for each slice as output.
• SP2 dataset: Uses the inputs and outputs from SP1 as
its input and yields the optimal inter-slice bandwidth
allocation coefficients across APs as output.
• SP3 dataset: Uses the inputs and outputs from SP2 as
its input and produces the optimal offloading decisions
as output.
For evaluation, we adopted a 10-fold cross-validation pro-
cedure to ensure robustness and prevent overfitting.
B. Experiment Environment
We consider a small-scale scenario for an edge application
with a square area of (500 x 500)m where 8 COINs, 1 MEC,
3 APs, and WDs are placed at random. The power spectral
density of Gaussian noise N0 is −174 dBm/Hz [32], and ac-
cording to [28], we represent the achievable physical rate Ri,a
from WD i to AP a as Ri,a = Balog (1+(distance)P t/N0),
where distance is the Euclidean distance between WD i and
AP a, and P t is the transmission power of WD i. Other
simulation parameters are summarized in table II.
We conducted a comprehensive evaluation of our DeepSets-
S model against other ablations. The models were trained on
three set of datasets. The data were generated by solving the
previously defined MINLP subproblems with standard opti-
mizers. We performed 300 iterations for each sample request
with a 90% confidence interval. Each dataset corresponds to
one of the subproblems introduced in Section V: SP1 dataset,
SP2 dataset, and SP3 dataset.
In Table III, we evaluate the performance of our DeepSets-S
model against its variant DeepSets which disables slack, and
apply normalization on the data to satisfy the resource alloca-
tion constraint, and other state-of-the-art multi-instance learn-
ing model; SetTransformer [35]. We evaluate using Acc@k,


--- Page 9 ---
9
where Acc@0.5, Acc@1, and Acc@2 measure the proportion
of predictions that fall within 0.5, 1, and 2 units of the ground
truth, respectively.
On SP1, DeepSets-S attains an Acc@0.5 of 76.76%, which
is higher than both the no-slack DeepSets baseline (76.74%)
and the SetTransformer variants (76.71–76.75%). At the
threshold of Acc@1, DeepSets-S records 95.26%, outperform-
ing DeepSets (95.21%) and SetTransformer (95.22–95.23%).
For the more relaxed Acc@2, DeepSets-S reaches 99.12%,
surpassing DeepSets (99.04%) and the SetTransformer models
(99.04–99.05%). However, the SetTransformer with 4 heads
achieves the lowest MAE (0.3918) and the highest R² (0.9059).
For SP2 also, DeepSets-S attains the best tolerance-based
accuracy across all thresholds. It achieves an Acc@0.5
of
81.85%,
slightly
higher
than
the
baseline
without
slack DeepSets (81.83%) and the SetTransformer models
(81.80–81.83%). At Acc@1, DeepSets-S records 95. 67%,
exceeding DeepSets (95. 64%) and close to the SetTransformer
results (95.66%). For the more relaxed Acc@2, DeepSets-S
achieves 99.08%, matching the best SetTransformer variant
and surpassing DeepSets (99.05%). In regression measures,
the four-head SetTransformer reports the lowest MAE (0.3474)
and the highest R² (0.9674), whereas DeepSets-S achieves
0.3480 and 0.9668.
Figures 4a and 4b present the absolute error of the
DeepSets-S model with respect to the number of WDs for
SP1 and SP2, respectively. For both SP1 and SP2, the error
is higher when the WD size is small, reflecting the limited
availability of input information. As the WD size increases, the
error decreases steadily and stabilizes at values close to zero,
indicating that the model becomes more reliable with larger
WD groups. This trend confirms that DeepSets-S generalizes
well across varying set sizes and maintains consistent accuracy
in large-scale scenarios.
For the SP3 dataset, we evaluate multiclass accuracy (Acc)
for the offloading decision vector δ and binary accuracy
(Acc bin) to distinguish between local and offload decisions.
The proposed DeepSets-S model achieves an Acc of 0.7486
and an Acc bin of 0.8824, showing improvements over the
no-slack DeepSets, which records an Acc of 0.7227 and an
Acc bin of 0.8802. The two-head SetTransformer obtains an
Acc of 0.7454 and an Acc bin of 0.8581, while the four-
head variant reaches the highest Acc of 0.7492 but a lower
Acc bin of 0.8733 compared with DeepSets-S. These results
highlight that the slack mechanism in DeepSets-S provides a
more balanced trade-off.
In what follows, we present the results of the proposed
DeepSets-S solution compared to some benchmark resource
allocation models. Specifically, we employ the following mod-
els for evaluation:
• Optimization Solvers (OS): We solve SP1 and SP2
through Ipopt optimization solver [36], and SP3 through
Gurobi optimization solver [37] to achieve the optimal
offloading decision vector δ.
• Ours DeepSets-S: Employs DeepSets-S model that trains
on the solution achieved through OS to solve SP1, SP2
and SP3.
TABLE III: Performance of DeepSets-S Models on SP1 and
SP2 against other ablations (best results are bold).
Models
MAE (%)
Acc@0.5
Acc@1
Acc@2
R2
SP1 Dataset
DeepSets-S
0.3924
0.7676
0.9526
0.9912
0.9057
DeepSets
0.3920
0.7674
0.9521
0.9904
0.9057
SetTransformer (2 heads)
0.3922
0.7671
0.9522
0.9904
0.9055
SetTransformer (4 heads)
0.3918
0.7675
0.9523
0.9905
0.9059
SP2 Dataset
DeepSets-S
0.3480
0.8185
0.9567
0.9908
0.9668
DeepSets
0.3480
0.8183
0.9564
0.9905
0.9668
SetTransformer (2 heads)
0.3475
0.8180
0.9566
0.9905
0.9673
SetTransformer (4 heads)
0.3474
0.8183
0.9566
0.9908
0.9674
TABLE IV: Performance of DeepSets-S model against other
ablations on SP3 (best results are bold). Acc (Multiclass
accuracy for offloading decision vector δ), Acc bin (Binary
accuracy for local and offload decisions)
Models
Acc
Acc bin
DeepSets-S
0.7486
0.8824
DeepSets
0.7227
0.8802
SetTransformer (2 heads)
0.7454
0.8581
SetTransformer (4 heads)
0.7492
0.8733
5
10
15
20
25
30
35
40
45
50
WD size
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Absolute error (%)
(a) SP1 dataset
5
10
15
20
25
30
35
40
45
50
WD size
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Absolute error (%)
(b) SP2 dataset
Fig. 4: Absolute error of DeepSet-S model against WD size.
• Proportional Resource Allocation Policy (PRAP): We
define the policies Rpr
ω , which share the bandwidth of
each AP a to each slice n proportionally, Rpr
ϕa which
gives propotional share of the bandwidth of each AP a
in slice n to each WD i, and finally Rpr
ϕj which gives
proportional share of the computing resource of node j


--- Page 10 ---
10
in slice n to each WD i.
• Equal Resource Allocation Policy (ERAP): We define
the policies Req
ω , which gives equal share of the band-
width of each AP a to each slice n, Req
ϕa which gives
equal share of the bandwidth of each AP a in slice n to
each WD i, and finally Req
ϕj which gives equal share of
the computing resource of node j in slice n to each WD
i.
To evaluate the practical computational complexity of the
solution, we conducted an empirical analysis by executing
each model type with varying user request rates. The ex-
periments were performed using the Python programming
language, and the computation time was measured as the
elapsed time between the start and end of execution.
Figure 5 illustrates the computation time (on a logarithmic
scale) as a function of the request rate. As shown, the OS
exhibits the highest computational burden, with computation
time increasing with the number of requests. This is due
to the exhaustive search to achieve the optimal solution by
the standard solvers. In contrast, the DeepSets-S model, once
trained, achieves significantly lower execution time, resulting
in a 86.1% reduction in computational time compared to the
OS. Evethough, the ERAP and PRAP make quicker resource
allocations, they still have to rely on the solver for maing
offloading decisions, and hence more computation time than
the DeepSets-S model.
The simulations were conducted on a system equipped with
a 12th Generation Intel(R) Core(TM) i5-12400F processor
running at 2.50 GHz, 16 GB of RAM, and a 500 GB hard
drive.
10
20
30
40
50
Number of WD
101
102
103
Algorithm computation time (ms)
86.1%
OS
DeepSets-S
ERAP
PRAP
Fig. 5: Algorithm computation time
To evaluate the overall efficiency of our proposed frame-
work, we define the system cost ratio CR as a key performance
metric. The CR quantifies the ratio between the system cost
reached using the optimization solver (COS) and the system
cost reached under the baseline model (Cm).
CR = COS
Cm
,
m ∈{DeepSets-S, ERAP, PRAP}
(52)
A higher CR indicates that the model is more effective
at minimizing system costs and is performing closer to the
2
3
4
5
Number of AP
0.2
0.4
0.6
0.8
1.0
Cost Ratio
DeepSets-S
ERAP
PRAP
WD=15
WD=25
Fig. 6: Cost Ratio vs Number of APs
optimal solution.
Figure 6 illustrates the CR as a function of the number of
APs for WD sizes of 15 and 25. In both scenarios, the proposed
DeepSets-S model consistently achieves higher cost ratios than
the baselines ERAP and PRAP, confirming its ability to ap-
proximate the optimal solution more closely. The performance
gap is more pronounced for larger workloads (WD = 25),
where DeepSets-S maintains a substantial advantage.
10
20
30
40
50
WD size
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
Average System Cost
N = 0
N = 2
N = 4
N = 6
N = 8
DeepSets-S
OS
25
30
35
0.900
0.925
0.950
6.1%
Fig. 7: System Cost vs WD size for Different COIN Size
Next, Figure 7 presents the average system cost by WD size
for different numbers of COINS. As expected, the system cost
increases with the number of WDs due to the higher aggregate
workload in the network. Across all COIN configurations, the
proposed DeepSets-S model closely follows the performance
of the OS, demonstrating its ability to generalize to larger set
of data. The inset plot highlights that the deviation between
DeepSets-S and the optimizer remains small, within 6.1% even
at WD size of 30, confirming the effectiveness of the model in
approximating near-optimal allocations. Moreover, increasing
the number of COINs consistently lowers the system cost, as
COINs reduce the workload on the MEC in queueing and


--- Page 11 ---
11
transmission delays, and enables more favorable offloading
placements, thereby improving overall efficiency.
Figure 8 illustrates the variation of average system cost
with respect to the number of WDs under different slice
configurations for both the DeepSets-S model and the OS. As
the number of WDs increases, the system cost correspondingly
rises due to higher aggregated workloads and contention across
communication and computing resources. For DeepSets-S, the
increase follows a similar trend as the OS, showing that the
learned model maintains stable generalization as the task load
scales. In all slice configurations, the cost values of DeepSets-
S remain very close to those of the OS, with an average
difference of just 3.8% at 30-50 WDs, confirming the model’s
ability to approximate near-optimal allocations effectively.
10
20
30
40
50
WD size
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6
Average System Cost
= 1
= 2
= 3
DeepSets-S
OS
30
40
50
1.0
1.1
1.2
1.3
1.4
1.5
1.6
3.8%
Average DeepSets-S@
= 3
Average OS@
= 3
Fig. 8: System Cost vs WD size for Different Slice Size
Furthermore, the slight cost reduction observed when the
number of slices increases reflects the improved adaptability
of the slicing framework. With more slices, tasks can be more
evenly distributed across available COIN and MEC nodes,
reducing queuing delays and improving parallel resource uti-
lization.
Figure 9 presents the percentage of tasks offloaded to
the MEC out of all offloaded tasks as the number of WDs
increases, under different slice configurations. For both the
OS and the proposed DeepSets-S model, the percentage of
MEC-offloaded tasks gradually increases with the number of
WDs. This rise indicates that as system load grows, a larger
fraction of the offloaded workload is directed to the MEC.
DeepSets-S closely mirrors the OS trend in every slice
configuration, with only slight deviations at higher WD sizes,
confirming that the learned model replicates the optimizer’s
offloading pattern with high fidelity.
VII. DISCUSSIONS AND LIMITATIONS
So far, we have shown that the formulated MINLP problem
can be decomposed into three coupled subproblems—SP1,
SP2, and SP3—that can be solved sequentially. The proposed
decomposition into SP1, SP2, and SP3 aligns naturally with
the hierarchical control of the system, as illustrated in the
resource management model. Each Slice Manager (SM) is
responsible for intra-slice resource allocation (SP1), while the
Slice Resource Orchestrator (SRO) manages inter-slice alloca-
tion (SP2) and global offloading decisions (SP3). This design
10
20
30
40
50
WD size
0
5
10
15
20
25
30
35
40
Percentage Offloaded to MEC
S = 1
S = 2
S = 3
DeepSets-S
OS
Fig. 9: Percentage of tasks offloaded to MEC
enables distributed decision-making across the COIN–MEC
infrastructure while maintaining coordination.
In deployment, DeepSets-S operates at both the slice and
network levels. At the slice level, each SM hosts a local
DeepSets-S instance that executes the SP1 model to allocate
its wireless and computing resources among connected WDs.
This local inference allows slices to adapt rapidly to short-term
variations in workload and queue states without requiring cen-
tralized intervention. At the network level, the SRO runs the
global DeepSets-S components for SP2 and SP3, aggregating
summarized state information from all SMs.
Simulation results demonstrated the effectiveness of this
design. DeepSets-S achieved tolerance-based accuracies above
95% for SP1 and SP2, significantly improved multiclass
offloading accuracy for SP3, and reduced computation time by
86.1% compared to exact optimization solvers. At the system
level, the proposed approach maintained system cost devia-
tions within 6.1% across COIN configurations and 3.8% across
varying slice numbers, confirming its ability to approximate
optimal performance with substantially reduced overhead.
Practically, this framework offers a scalable foundation for
AI-native orchestration in future 6G edge systems, combin-
ing distributed learning with centralized oversight. Looking
ahead, several research directions arise. First, the present work
assumes static user and channel conditions, extending the
framework to dynamic or stochastic environments via rein-
forcement or continual learning would improve adaptability.
Second, as generating optimal labels through solvers is costly,
semi-supervised or self-supervised learning could reduce data
dependency and improve generalization to unseen scenarios.
Finally, evaluating DeepSets-S on real-time application work-
loads or public edge-computing datasets will be essential to
assess scalability and deployment feasibility.
Beyond Metaverse environments, the proposed framework
can be extended to other latency-sensitive domains such as
autonomous systems, holographic media streaming, and im-
mersive XR applications. Real-world implementation, how-
ever, will depend on the processing and memory capabilities
of COIN nodes, which must be carefully analyzed to ensure


--- Page 12 ---
12
efficient and stable on-device inference.
VIII. CONCLUSION
We have addressed the joint resource management and
task offloading problem in a slice-enabled in-network edge
system, where COIN and MEC nodes collaborate to support
delay-sensitive and computation-intensive tasks. The problem
was formulated as an MINLP model that jointly optimizes
wireless and computing resource allocations with optimal slice
selection to minimize overall system cost. As the formulated
problem is NP-hard, we decomposed it into three tractable
sub-problems, SP1 (intra-slice allocation), SP2 (inter-slice
allocation), and SP3 (offloading decision).
To overcome the limitations of online optimization, we pro-
posed a distributed hierarchical encoder-decoder framework
(DeepSets-S), which learns to approximate optimal resource
allocation and offloading policies from optimization solver-
generated data. The model incorporates a shared encoder and
task-specific decoders, ensuring permutation equivariance over
variable-size WD sets. Once trained, DeepSets-S provides
near-optimal inference with substantially reduced computa-
tional cost.
REFERENCES
[1] M. Zawish, F. A. Dharejo, S. A. Khowaja, S. Raza, S. Davy, K. Dev, and
P. Bellavista, “Ai and 6g into the metaverse: Fundamentals, challenges
and future research trends,” IEEE Open Journal of the Communications
Society, vol. 5, pp. 730–778, 2024.
[2] M. Xu, W. C. Ng, W. Y. B. Lim, J. Kang, Z. Xiong, D. Niyato,
Q. Yang, X. Shen, and C. Miao, “A full dive into realizing the edge-
enabled metaverse: Visions, enabling technologies, and challenges,”
IEEE Communications Surveys & Tutorials, vol. 25, no. 1, pp. 656–
700, 2023.
[3] P. Bhattacharya, D. Saraswat, D. Savaliya, S. Sanghavi, A. Verma,
V. Sakariya, S. Tanwar, R. Sharma, M. S. Raboaca, and D. L. Manea,
“Towards future internet: The metaverse perspective for diverse indus-
trial applications,” Mathematics, vol. 11, no. 4, p. 941, 2023.
[4] M. Ishtiaq, N. Saeed, and M. A. Khan, “Edge computing in the internet
of things: A 6g perspective,” IT Professional, vol. 26, no. 5, pp. 62–70,
2024.
[5] I. Aliyu, S. Oh, N. Ko, T.-W. Um, and J. Kim, “Dynamic partial
computation offloading for the metaverse in in-network computing,”
IEEE Access, 2023.
[6] S. Kianpisheh and T. Taleb, “A survey on in-network computing:
Programmable data plane and technology specific applications,” IEEE
Communications Surveys & Tutorials, vol. 25, no. 1, pp. 701–761, 2023.
[7] I. Aliyu, A. Arigi, S. Oh, T.-W. Um, and J. Kim, “Towards a partial
computation offloading in in-networking computing-assisted mec: A
digital twin approach,” in NOMS 2024-2024 IEEE Network Operations
and Management Symposium, pp. 1–9, 2024.
[8] R. Segal, C. Avin, and G. Scalosub, “Soar: Minimizing network utiliza-
tion cost with bounded in-network computing,” IEEE Transactions on
Network and Service Management, vol. 21, no. 2, pp. 1832–1851, 2024.
[9] S. Zhang, “An overview of network slicing for 5g,” IEEE Wireless
Communications, vol. 26, no. 3, pp. 111–117, 2019.
[10] M. Chahbar, G. Diaz, A. Dandoush, C. C´erin, and K. Ghoumid, “A
comprehensive survey on the e2e 5g network slicing model,” IEEE
Transactions on Network and Service Management, vol. 18, no. 1,
pp. 49–62, 2021.
[11] N. H. Chu, D. T. Hoang, D. N. Nguyen, K. T. Phan, E. Dutkiewicz,
D. Niyato, and T. Shu, “Metaslicing: A novel resource allocation
framework for metaverse,” IEEE Transactions on Mobile Computing,
pp. 1–18, 2023.
[12] Z. Sasan, M. Shokrnezhad, S. Khorsandi, and T. Taleb, “Joint network
slicing, routing, and in-network computing for energy-efficient 6g,”
arXiv preprint arXiv:2401.06306, 2024.
[13] G. Lia, M. Amadeo, G. Ruggeri, C. Campolo, A. Molinaro, and
V. Loscr`ı, “In-network placement of delay-constrained computing tasks
in a softwarized intelligent edge,” Computer Networks, vol. 219, 2022.
[14] H. Guo, J. Liu, and J. Lv, “Toward intelligent task offloading at the
edge,” IEEE Network, vol. 34, no. 2, pp. 128–134, 2020.
[15] S. M. Ara´ujo, F. S. de Souza, and G. R. Mateus, “A hybrid optimization-
machine learning approach for the vnf placement and chaining problem,”
Computer Networks, vol. 199, p. 108474, 2021.
[16] S. M. Rashid, I. Aliyu, A. Isah, J. Lee, S. Oh, M. Hahn, and J. Kim,
“Joint wireless and computing resource management with optimal slice
selection in in-network-edge metaverse system,” in 2024 15th Inter-
national Conference on Information and Communication Technology
Convergence (ICTC), pp. 922–926, 2024.
[17] A. Sapio, I. Abdelaziz, A. Aldilaijan, M. Canini, and P. Kalnis, “In-
network computing is a dumb idea who’s time has come,” Proceedings
of Hot-Nets, 2017.
[18] I. Kunze, R. Glebke, J. Scheiper, M. Bodenbenner, R. H. Schmitt, and
K. Wehrle, “Investigating the applicability of in-network computing to
industrial scenarios,” in 2021 4th IEEE international conference on
industrial cyber-physical systems (ICPS), pp. 334–340, IEEE, 2021.
[19] S. Muhammad Rashid, I. Aliyu, I.-K. Jeong, T.-W. Um, and J. Kim,
“Graph neural network for in-network placement of real-time metaverse
tasks in next-generation networks,” IEEE Access, vol. 13, pp. 110999–
111010, 2025.
[20] M. Amadeo, C. Campolo, G. Lia, A. Molinaro, and G. Ruggeri,
“In-network placement of reusable computing tasks in an sdn-based
network edge,” IEEE Transactions on Mobile Computing, vol. 23, no. 2,
pp. 1456–1471, 2024.
[21] H. Wu, J. He, J. Weng, G. T. Nguyen, M. Reisslein, and F. H. P.
Fitzek, “Optcdu: Optimizing the computing data unit size for coin,”
IEEE Transactions on Network and Service Management, vol. 21, no. 6,
pp. 6095–6111, 2024.
[22] T. K. Rodrigues, K. Suto, H. Nishiyama, J. Liu, and N. Kato, “Machine
learning meets computation and communication control in evolving edge
and cloud: Challenges and future perspective,” IEEE Communications
Surveys & Tutorials, vol. 22, no. 1, pp. 38–67, 2020.
[23] J. Singh, P. Singh, M. Hedabou, and N. Kumar, “An efficient machine
learning-based resource allocation scheme for sdn-enabled fog comput-
ing environment,” IEEE Transactions on Vehicular Technology, vol. 72,
no. 6, pp. 8004–8017, 2023.
[24] F. S. D. Silva, S. N. Silva, L. M. Da Silva, A. Bessa, S. Ferino,
P. Paiva, M. Medeiros, L. Silva, J. Neto, K. Costa, et al., “Ml-based inter-
slice load balancing control for proactive offloading of virtual services,”
Computer Networks, vol. 246, p. 110422, 2024.
[25] W. Liu, M. A. Hossain, N. Ansari, A. Kiani, and T. Saboorian,
“Reinforcement learning-based network slicing scheme for optimized
ue-qos in future networks,” IEEE Transactions on Network and Service
Management, vol. 21, no. 3, pp. 3454–3464, 2024.
[26] T.-H. Hejazi, Z. Ghadimkhani, and A. Borji, “A learning-based solution
approach to the application placement problem in mobile edge comput-
ing under uncertainty,” arXiv preprint arXiv:2403.11259, 2024.
[27] M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R. Salakhutdinov,
and A. J. Smola, “Deep sets,” Advances in neural information processing
systems, vol. 30, 2017.
[28] S. Joˇsilo and G. D´an, “Joint wireless and edge computing resource man-
agement with dynamic network slice selection,” IEEE/ACM Transactions
on Networking, vol. 30, no. 4, pp. 1865–1878, 2022.
[29] J. L. D. Neto, S.-Y. Yu, D. F. Macedo, J. M. S. Nogueira, R. Langar, and
S. Secci, “Uloof: A user level online offloading framework for mobile
edge computing,” IEEE Transactions on Mobile Computing, vol. 17,
no. 11, pp. 2660–2674, 2018.
[30] M. Zukerman, “Introduction to queueing theory and stochastic teletraffic
models,” arXiv preprint arXiv:1307.2968, 2013.
[31] D. G. Cattrysse and L. N. Van Wassenhove, “A survey of algorithms for
the generalized assignment problem,” European journal of operational
research, vol. 60, no. 3, pp. 260–272, 1992.
[32] I. Aliyu, A. M. Arigi, T.-W. Um, and J. Kim, “Digital twinning of a
pressurized water reactor startup operation and partial computational of-
floading in in-network computing-assisted multiaccess edge computing,”
arXiv preprint arXiv:2407.12011, 2024.
[33] S. Sardellitti, G. Scutari, and S. Barbarossa, “Joint optimization of radio
and computational resources for multicell mobile-edge computing,”
IEEE Transactions on Signal and Information Processing over Networks,
vol. 1, no. 2, pp. 89–103, 2015.
[34] S. Ahmadi, “An overview of 3gpp long-term evolution radio access net-
work,” New Directions in Wireless Communications Research, pp. 431–
465, 2009.
[35] J. Lee, Y. Lee, J. Kim, A. Kosiorek, S. Choi, and Y. W. Teh, “Set trans-
former: A framework for attention-based permutation-invariant neural


--- Page 13 ---
13
networks,” in International conference on machine learning, pp. 3744–
3753, PMLR, 2019.
[36] A. W¨achter and L. T. Biegler, “On the implementation of an interior-
point filter line-search algorithm for large-scale nonlinear programming,”
Mathematical programming, vol. 106, pp. 25–57, 2006.
[37] Gurobi Optimization, LLC, “Gurobi Optimizer Reference Manual,”
2023.
