--- Page 1 ---
LEARNING TO SOLVE ABSTRACT REASONING PROBLEMS WITH
NEUROSYMBOLIC PROGRAM SYNTHESIS AND TASK
GENERATION
A PREPRINT
Jakub Bednarek *
Institute of Computing Science
Poznan University of Technology
Poland
jakub.bednarek@put.poznan.pl
Krzysztof Krawiec
Institute of Computing Science
Poznan University of Technology
Poland
krzysztof.krawiec@cs.put.poznan.pl
ABSTRACT
The ability to think abstractly and reason by analogy is a prerequisite to rapidly adapt to new
conditions, tackle newly encountered problems by decomposing them, and synthesize knowledge to
solve problems comprehensively. We present TransCoder, a method for solving abstract problems
based on neural program synthesis, and conduct a comprehensive analysis of decisions made by the
generative module of the proposed architecture. At the core of TransCoder is a typed domain-specific
language, designed to facilitate feature engineering and abstract reasoning. In training, we use the
programs that failed to solve tasks to generate new tasks and gather them in a synthetic dataset.
As each synthetic task created in this way has a known associated program (solution), the model
is trained on them in supervised mode. Solutions are represented in a transparent programmatic
form, which can be inspected and verified. We demonstrate TransCoder’s performance using the
Abstract Reasoning Corpus dataset, for which our framework generates tens of thousands of synthetic
problems with corresponding solutions and facilitates systematic progress in learning.
Keywords Neurosymbolic systems · Program synthesis · Abstract reasoning
1
Introduction
Abstract reasoning tasks have a long-standing tradition in AI (e.g. Bongard problems Bongard [1967], Hofstadter’s
analogies Hofstadter [1995]). In the past, they have been most often approached with algorithms relying exclusively
on symbolic representations and typically involving some form of principled logic-based inference. While this can
be successful for problems posed ‘natively’ in symbolic terms (e.g. Hofstadter [1995]), challenges start to mount up
when a symbolic representation needs to be inferred from a low-level, e.g. visual, representation Bongard [1967]. The
recent advances in deep learning and increasing possibilities of their hybridization with symbolic reasoning (see Sec.
4) opened the door to architectures that combine ‘subsymbolic’ processing required to perceive the task with sound
symbolic inference.
This study introduces TransCoder, a neurosymbolic architecture that relies on programmatic representations to detect
and capture relevant patterns in low-level representation of the task, infer higher-order structures from them, and
encode the transformations required to solve the task. TransCoder is designed to handle the tasks from the Abstract
Reasoning Corpus (ARC, Chollet [2019]), a popular benchmark that epitomizes the above-mentioned challenges. Our
main contributions include (i) the original neural architecture that synthesizes programs that are syntactically correct by
construction, (ii) the ‘learning from mistakes’ paradigm to provide itself with a learning gradient by synthesizing tasks
of adequate difficulty, (iii) an advanced perception mechanism to reason about small-size rasters of variable size, and
(iv) empirical assessment on the ARC suite.
∗Alternative email: jakub.bednarek.g@gmail.com
arXiv:2410.04480v1  [cs.AI]  6 Oct 2024


--- Page 2 ---
Learning from Mistakes with TransCoder
A PREPRINT
Figure 1: Examples from the Abstract Reasoning Corpus Dataset.
2
Abstract Reasoning Corpus
Abstract Reasoning Corpus (ARC) Chollet [2019] is a collection of 800 visual tasks, partitioned into 400 training
tasks and 400 testing tasks.2 Each task comprises a few (usually 3, maximally 6) demonstrations and a test (Fig. 1).
A demonstration is a pair of raster images, an input image and an output image. Images are usually small (at most
30 by 30 pixels) and each pixel can assume one of 10 color values, represented as a categorical variable (there is no
implicit ordering of colors). The test is also a raster image, meant to be interpreted as yet another input for which the
corresponding output is unknown to the solver.
For each ARC task, there exists a unique processing rule (unknown to the solver) that maps the input raster of each
demonstration to the corresponding output raster. The solver is expected to infer3 that rule from the demonstrations and
apply it to the test raster to produce the corresponding output. The output is then submitted to the oracle which returns a
binary response informing about the correctness/incorrectness of this solution.
The ARC collection is very heterogeneous in difficulty and nature, featuring tasks that range from simple pixel-wise
image processing, re-coloring of objects, to mirroring of the parts of the image, to combinatorial aspects (e.g. counting
objects), to intuitive physics (e.g. an input raster to be interpreted as a snapshot of moving objects and the corresponding
output presenting the next state). In quite many tasks, the black color should be interpreted as the background on
which objects are presented; however, there are also tasks with rasters filled with ‘mosaics’ of pixels, with no clear
foreground-background separation (see e.g. the left example in Fig. 1). Raster sizes can vary between demonstrations,
and between the inputs and outputs; in some tasks, it is the size of the output raster that conveys the response to the
input. Because of these and other characteristics, ARC is widely considered extremely hard: in the Kaggle contest
accompanying the publication of this benchmark4, which closed on the 28th of May 2020, the best contestant entry
algorithm achieved an error rate of 0.794, i.e. solved approximately 20% of the tasks from the (unpublished) evaluation
set, and most entries relied on a computationally intensive search of possible input-output mappings.
3
The proposed approach
The broad scope of visual features, object properties, alternative interpretations of images, and inference mechanisms
required to solve ARC tasks suggest that devising a successful solver requires at least some degree of symbolic
processing. It is also clear that reasoning needs to be compositional; e.g. in some tasks objects must be first delineated
from the background and then counted, while in others objects need to be first counted, and only then the foreground-
2https://github.com/fchollet/ARC
3Or, more accurately, induce, as the demonstrations never exhaust all possible inputs and outputs.
4https://www.kaggle.com/c/abstraction-and-reasoning-challenge
2


--- Page 3 ---
Learning from Mistakes with TransCoder
A PREPRINT
Workspace 1
Workspace 1
?
Demonstration
Test
Perception
Solver
Task
Workspace 1
Workspace Template
Program Generator
Flip(scene, Horizontal)
Execution
Figure 2: The overall architecture of TransCoder.
background distinction becomes possible. It is thus essential to equip the solver with the capacity to rearrange the
inference steps in an (almost) arbitrary fashion.
The above observation is a strong argument for representing the candidate solutions as programs and forms our main
motivation for founding TransCoder on program synthesis, where the solver can express a candidate solution to the
task as a program in a Domain-Specific Language (DSL), a bespoke programming language designed to handle the
relevant entities. Because (i) the candidate programs are to be generated in response to the content of the (highly visual)
task, and (ii) it is desirable to make our architecture efficiently trainable with gradient to the greatest degree possible, it
becomes natural to control the synthesis using a neural model. Based on these premises, TransCoder is a neurosymbolic
system that comprises (Fig. 2):
• Perception module, a neural network that maps demonstrations to a latent vector z of fixed dimensionality,
• Solver, a (stochastic) network that maps the latent representation of the task z to the latent representation z′ of
the to-be-synthesized program,
• Program generator, (Generator for short) a recurrent network that maps z′ to the program p represented as
an Abstract Syntax Tree,
• Program interpreter, (Interpreter for short) which executes p, i.e. applies it to rasters.
In training, the Interpreter applies p independently to each of the input rasters of demonstrations and returns the
predicted output rasters, which are then confronted with the true output rasters using a loss function. In testing, p is
applied to the test raster and the resulting raster is submitted to the oracle that determines its correctness.
We detail the components of TransCoder in the following sections. For technical details, see Appendix A.
3.1
The Perception Module
The perception module comprises the raster encoder and the demonstration encoder.
The raster encoder is based on an attention module that allows processing rasters of different sizes, which is required
when solving ARC tasks (see, e.g., the task shown in Fig. 2). However, raster sizes need to be taken into account, as
they often convey crucial information about the task. To convey it to the model, we tag each pixel with the color and its
(x, y) coordinates, the latter acting as a positional embedding. The image is flattened to a tagged sequence of tokens
representing pixels (see the left part of Fig. 3). The tensor resulting from the Reduce block forms the fixed-length
representation of the raster, subsequently fed into the demonstration encoder.
The raster encoder is pre-trained within an autoencoder framework, where the raster encoder is combined with a
compatible decoder that can reproduce varying-length sequences of pixels (and thus the input raster) from a fixed-
3


--- Page 4 ---
Learning from Mistakes with TransCoder
A PREPRINT
2 x Convolution 1D
N x Self-Attention block
Reduce
K x Cross-Attention block
(0,0)
(0,1)
(0,2)
(0,3)
(2,0)
(2,3)
(1,0)
(1,1)
(1,2)
(1,3)
(2,1)
(2,2)
(0,0) (0,1) (0,2) (0,3) (1,0) (1,1) (1,2) (1,3) (2,0) (2,1) (2,2) (2,3)
(0,0) (0,1) (0,2) (0,3) (1,0) (1,1) (1,2) (1,3) (2,0) (2,1) (2,2) (2,3)
Prediction
(0,0)
(0,1)
(0,2)
(0,3)
(1,0)
(1,1)
(1,2)
(1,3)
(2,0)
(2,1)
(2,2)
(2,3)
Classification
Loss
Latent Vector
Position & Label Embedding
Position Embedding
(0,0) (0,1) (0,2) (0,3) (1,0) (1,1) (1,2) (1,3) (2,0) (2,1) (2,2) (2,3)
Context
Encoder
Decoder
Input raster
Predicted raster
Figure 3: The autoencoder architecture used to pre-train the raster encoder in Perception. Left: the encoder (used in
TransCoder after pre-training). Right: the decoder (used only in pre-training and then discarded).
dimensionality latent (the right part of Fig. 3). The pre-training is intended to make feature extraction invariant to
permutations of colors, while accounting for the black color serving the special role of background in a large share
of tasks. To this end, the rasters derived from the ARC are treated as dynamic templates colored on the fly during
training while preserving the distinctions of colors. As a result of pre-training, the raster encoder achieves the per-pixel
reconstruction accuracy of 99.98% and the per-raster accuracy of 96.36% on the testing part of the original ARC.
The demonstration encoder concatenates the latent vectors obtained from the raster encoder for the input and output
raster of a demonstration and passes them through a two-layer MLP. This is repeated for all demonstrations, and
the output vectors produced by the MLP are chained into a sequence, which is then subject to processing with
four consecutive self-attention blocks. The sequence of vectors produced in this process is averaged, resulting in a
fixed-dimensionality (independent of the number of demonstrations) vector z representing a task.
3.2
Solver
The latent z produced by Perception forms a compressed representation of raster images in an ARC task. As it has
been almost perfectly pre-trained via auto-association (see previous section), we expect it to contain the entirety of
information about the content of the input raster. However, this does not mean that it conveys the knowledge sufficient
for solving the task. The role of the Solver is to map z to a latent representation z′ of the program to be generated.
Technically, Solver is implemented as a two-layer MLP.
However, as in most programming languages, the relationship between the programs written in our DSL and their
input-output behaviors is many-to-one, i.e. the same mapping from the input to output raster can be implemented with
more than one program. As a result, the relationship between DSL programs and ARC tasks is many-to-many, i.e. a
given task can be solved with more than one DSL program, and this very program can be a solution to more than one
ARC task.
To account for this absence of one-to-one correspondence, we make the Solver stochastic by following the blueprint of
the Variational Autoencoder (VAE, Kingma and Welling [2022]): the last layer of the Solver does not directly produce
z′, but parameterizes the normal distribution with two vectors zµ and zσ and then calculates z′ = zµ +zσN(0, 1) where
N(0, 1) is generated by the random number generator. The intent is to allow zµ to represent the centroid of the set of
programs that solve a given task, while zσ to model the extent of that set in the latent space.
4


--- Page 5 ---
Learning from Mistakes with TransCoder
A PREPRINT
3.3
Workspace
As many ARC tasks involve qualitative and combinatorial concepts (e.g. counting objects), we supplement the
information provided by Perception with selected symbolic percepts inferred from the task independently from
Perception, via direct ‘procedural parsing’ of images. We provide two data structures for that purpose:
• Workspace Template that contains the abstract placeholders for entities that appear in all demonstrations of a
given task,
• Workspaces that ‘instantiate‘ that template with concrete values derived from particular demonstrations.
The entries in a Workspace Template act as keys that index specific values (realizations) in the Workspace of a
specific demonstration. For instance, the Scene symbol in the Workspace Template may have a different value in each
Workspace. For the task shown in Fig. 2, the Workspace Template contains the Scene symbol, and its values in the first
two Workspaces are different:
scene_0 = Region (
#
f i r s t
demonstration
p o s i t i o n s = [ [ 0 , 0 ] ,
[ 0 , 1 ] ,
[ 0 , 2 ] ,
. . . ] ,
c o l o r s =[ Green ,
Green ,
Blue ,
. . . ]
)
scene_1 = Region (
# second
demonstration
p o s i t i o n s = [ [ 0 , 0 ] ,
[ 0 , 1 ] ,
[ 0 , 2 ] ,
. . . ] ,
c o l o r s =[Brown ,
Green ,
Orange ,
. . . ]
)
The list of workspace keys is predefined and includes constants (universal symbols shared between all tasks), local
invariants (values that repeat within a given task, e.g. in each input raster), and local symbols (information specific to a
single demonstration pair, e.g. an input Region). For a complete list of available keys, see Appendix.
The workspaces require appropriate ‘neural presentation’ for the Generator of DSL programs. For a given task, all
symbols available in the Workspace Template are first embedded in a Cartesian space, using a learnable embedding
similar to those used in conventional DL. This representation is context-free, i.e. each symbol is processed independently.
We then enrich this embedding with the information in the latent z′ produced by the Solver (Sec. 3.2) by concatenating
both vectors and processing them with a two-layer MLP, resulting in a contextual embedding of the symbol.
Moreover, the DSL’s operations are also included in the Workspace; each of them is also embedded in the same Cartesian
space so that the Generator can choose from them alongside the symbols from the workspace. In this way, the elements
of the DSL are presented to the Generator (on the neural level) in the context of the given task, and symbols (such as
‘red‘) may have a different embedding depending on the perception result. This is expected to facilitate alternative
interpretations of the roles of particular percepts; for instance, while the black pixels should often be interpreted as the
background, some tasks are exceptions to this rule.
3.4
The Domain-Specific Language
The DSL we devised for TransCoder is a typed, functional programming language, with leaves of AST trees fetching
input data and constants, and the root of the tree producing the return value. Each operation (an inner AST node) is a
function with a typed signature and implementation. The DSL features concrete (e.g. Int, Bool, or Region) and generic
(e.g. List[T]) data types.
A complete DSL program has the signature Region →Region, i.e. it can be applied to the input of an ARC demonstration
(or the query) and produce the corresponding output.
The current version of the DSL contains 40 operations, which can be divided into data-composing operations (form
a more complex data structure from constituents, e.g. Pair, Rect), property-retrieving operations (fetch elements or
extract simple characteristics from data structures, e.g. Width, Area or Length), data structure manipulations (e.g. Head
of the list, First of a Pair, etc.), arithmetics (Add, Sub, etc.), and region-specific operations (high-level transformations
of drawable objects, e.g. Shift, Paint, FloodFill). Our DSL features also higher-order functions known from functional
programming, for example, Map and Filter which apply an argument in the form of a subprogram to elements of a
compound data structure like a List. The complete definition of the DSL can be found in Appendix.
5


--- Page 6 ---
Learning from Mistakes with TransCoder
A PREPRINT
3.5
Program Generator
The Program Generator (Generator for short) is a bespoke architecture based on the blueprint of the doubly-recurrent
neural network (see Alvarez-Melis and Jaakkola [2017] for a simple variant of DRNN). The latent z′ obtained from the
Solver becomes the initial state of this network, which then iterates over the nodes of the Abstract Syntax Tree (AST)
of the program being generated in the breadth-first order. For the root node of the AST, the return type is Region for the
root node; for other nodes, it is determined recursively by the types of arguments required by DSL functions picked in
previous iterations.
In each iteration, the Generator receives the data on the current context of AST generation, including the current size
(the number of already generated nodes in the AST) and depth of the node in the AST, the parent of the current node,
and the return type of the node. It is also fed with the set of symbols available in the workspaces (including the elements
of the DSL), via the embedding described in the previous section. From this set, the Generator selects the symbols that
meet the requirements regarding the type and the maximum depth of the tree. Then, it applies an attention mechanism
to the embedded representations of the selected symbols. The outcome of attention is the symbol to be ‘plugged’ into
the AST at the current location.
The Generator also determines the hidden state of the DRNN to be passed to each of the child nodes. This is achieved
by merging the current state with a learnable embedding indexed with children’s indices, so that generation in deeper
layers of the AST tree is informed about node’s position in the sequence of parent’s children. The generation process
iterates recursively until the current node requests no children, which terminates the current branch of the AST (but not
the others). It is also possible to enforce termination by narrowing down the set of available symbols.
3.6
Training
TransCoder can be trained with reinforcement learning (RL) or supervised learning (SL). The RL mode is most natural
for handling ARC tasks: the program p synthesized by the Generator is applied to the query raster and returns an output
raster, which is then sent to the oracle. The oracle deems it correct or not and that response determines the value of the
reward (1 or 0, respectively), which is then used to update the Generator. In this mode, we rely on the REINFORCE
algorithm Williams [1992], Sutton et al. [2000].
Unfortunately, the a priori odds for a generated program to solve the given task are minuscule. As a result, training
TransCoder only with RL is usually inefficient, especially in the early stages, when the generated programs are almost
entirely random: most episodes lead to no reward and, consequently, no updates of TransCoder’s parameters. This
motivates considering the SL mode, in which we assume that the correct program (target) is known. This allows us to
directly confront the actions of the Generator (i.e. the AST nodes it produces) with the target program node-by-node,
and apply a loss function that rewards choosing the right symbols at individual nodes and penalizes the incorrect choices.
In SL, every training episode produces non-zero updates for the model’s parameters (unless the target program has been
perfectly generated).
In general, the specific program used as the target in this scenario will be one of many programs that implement the
input-output mapping required by the demonstrations of the presented task (see Sec. 2). Deterministic models are
fundamentally incapable of realizing one-to-many mappings, and the variational layer described in Sec. 3.2 is meant to
address this limitation. Upon the (unlikely in practice) perfect convergence of TransCoder’s training, we expect the
deterministic output of the Solver (corresponding to zµ) to abstractly represent the common semantic of all programs
that solve the presented task, and the variational layer to sample the latents that cause the Generator to produce concrete
programs with that very semantics.
The prerequisite for the SL mode is the availability of target programs; as those are not given in the ARC benchmark,
we devise a method for producing them online during training, presented in the next section.
3.7
Learning from mistakes
The programs produced by the Generator are syntactically correct by construction. Barring occasional run-time errors
(e.g., applying a function to an empty list), a generated program will thus always produce some output raster for a given
input raster; we refer to it as response. By applying such a program p (and arguably any syntactically correct program
with the Region →Region signature) to the list I of input rasters of some task T, we obtain the corresponding list of
responses O. We observe that the resulting raster pairs made of the elements of I and O can be considered as another
ARC task T ′, to which p is the solution (usually one of possible solutions, to be precise). The resulting pair (T ′, p)
forms thus a complete example that can be used to train TransCoder in SL mode, as explained in the previous section,
where T ′ is presented to TransCoder and p is the target program.
6


--- Page 7 ---
Learning from Mistakes with TransCoder
A PREPRINT
Exploration
Training
Reduction
Not enough
supervised examples
Sufficient supervised
examples collected
Supervised Learning
finished
Model not good enough
More supervised
examples needed
Figure 4: The state diagram of TransCoder’s training, including learning from mistakes.
This observation allows us to learn from mistakes: whenever the Generator produces a program p that fails the presented
training task T, we pair it with the task T ′ created in the above way, add the synthetic task (T ′, p) formed in this way to
the working collection S of solved tasks, and subsequently use them for supervised learning. Crucially, we expect T ′ to
be on average easier than T, and thus provide the training process with a valuable ‘learning gradient’. By doing so, we
intend to help the model make progress in the early stages of training, when its capabilities fall far behind the difficulty
of the ARC tasks.
To model the many-to-many relation between tasks and programs, we implement S as a relational database to facilitate
the retrieval of all programs (known to date) that solve a given task, and vice versa — of all tasks solved by a given
program. We disallow duplicates in S.
We start with S = ∅and L filled with the original ARC tasks, and stage learning into cycles of Exploration, Training,
and Reduction phases (Fig. 4).
Exploration. The purpose of this phase is to provide synthetic training examples needed in subsequent phases. A
random task T is drawn from L and the Generator is queried on it. If the generated program p solves T, the pair (T, p)
is added to S. Otherwise, it is checked whether the responses produced by p meet basic criteria of nontriviality, i.e.
are non-empty and depend on the input rasters (i.e. responses vary by demonstration). If T ′ passes this test, (T ′, p) is
added to the S and L. This continues until enough new tasks have been added to S.
Training consists in applying SL to a random subset of tasks drawn from S. The execution of this phase ends after
iterating through all training examples in the drawn subset.
Reduction starts with selecting a subset with known solutions (programs). Then, those tasks are grouped by solutions;
a group of tasks with the same solution forms a category. Next, n categories are drawn at random. Finally, k tasks are
drawn for each category. The tasks selected in this way form a working subset L′ ⊂L.
In the next step, TransCoder is evaluated on L′. If the program produced by the Generator solves a given task from L′,
the task is marked as learned and is removed from S (if present in S). Otherwise, the task is marked as not learned and
is added to S (if not present in S)5. Finally, the results are grouped according to the category from which the tasks
come and the average of solved tasks within each of them is calculated. If TransCoder reaches the average value of
solved categories above the set threshold in the last iterations and stagnation occurs, we switch to the Exploration phase;
otherwise, to the Training phase.
4
Related work
TransCoder engages programs to process and interpret the input data, and thus bears similarity to several past works on
neurosymbolic systems, of which we review only the most prominent ones. In synthesizing programs in response to
input (here: task), TransCoder resembles the Neuro-Symbolic Concept Learner (NSCL, Mao et al. [2019]). NSCL was
designed to solve Visual Query Answering tasks Johnson et al. [2016] and learned to parameterize a semantic parser that
translated a natural language query about scene content to a DSL program which, once executed, produced the answer
5In this way, we allow for re-evaluation of tasks marked previously as learned and removed from S.
7


--- Page 8 ---
Learning from Mistakes with TransCoder
A PREPRINT
Table 1: RateSynth and RateARC in consecutive training cycles.
Cycle
1
2
3
4
5
RateSynth
1.72% 4.23% 9.81% 13.95% 21.66%
RateARC
1.00% 0.25% 0.75% 1.50%
2.00%
to the question. The system was trained with RL. Interestingly, NSCL’s DSL was implemented in a differentiable
fashion, which allowed it to inform its perception subnetwork in training.
In using a program synthesizer to produce new tasks, rather than only to solve the presented tasks, TransCoder bears
some similarity to the DreamCoder Ellis et al. [2021]. DreamCoder’s training proceeds in cycles comprising wake,
dreaming, and abstraction phases which realize respectively solving the original problems, training the model on
‘replays’ of the original problems and on ‘fantasies’ (synthetic problems), and refactorization of the body of synthesized
programs. The last phase involves identification of the often-occurring and useful snippets of programs, followed by
encapsulating them as new functions in the DSL, which is meant to facilitate ‘climbing the abstraction ladder’. The
DreamCoder was shown to achieve impressive capabilities on a wide corpus of problems, ranging from typical program
synthesis to symbolic regression to interpretation of visual scenes. For a thorough review of other systems of this type,
the reader is referred to Chaudhuri et al. [2021].
5
Experimental evaluation
In the following experiment, we examine TransCoder’s capacity to provide itself with a ‘reflexive learning gradient’,
meant as continuous supply of synthetic tasks at the level of difficulty that facilitates further improvement. Therefore,
we focus on the dynamics of the learning process.
Setup. To ensure a sufficiently large pool of training examples, each Exploration phase lasts until the set S contains
at least 8192 tasks and 32 unique solutions. For the Reduction phase, we set the number of categories to be drawn
for L′ to n = 64, the number k of tasks to be drawn from each category to 32, the solving threshold of 30%, and the
number of stagnation iterations to 10. Moreover, generated programs are limited to a maximum number of nodes of 64,
a maximum depth of 8 and at most of 2 nestings of higher-order functions (each nesting is considered as a separate
program and is also required to meet the above limits).
Metrics. The primary metric is the percentage of tasks solved from the testing subset of the original ARC (RateARC).
However, because of the difficulty of this corpus, this metric is very coarse. To assess the progress in a more fine-grained
way, we prepare a collection of 183,282 synthetic tasks by collecting them from several past runs of the method. This
collection is fixed; the percentage of tasks solved from that collection will be referred to as RateSynth.
Results. Table 1 presents the metrics at the completion of consecutive training cycles (cf. Fig. 4). RateSynth
monotonously increases over time, indicating steady progress of TransCoder’s capacity of solving tasks. This positively
impacts the RateARC, which achieves the all-high value of 2% at the end of the run, suggesting that the skills learned
from the synthetic, easier tasks translate into more effective solving of the harder original ARC tasks.
Figure 5 shows the percentage of tasks solved estimated from a random sample drawn from the current S. Because S
varies dynamically along training, this quantity is not objective, yet illustrates the dynamics of training. The sudden
drops in performance occur right after the completion of the Exploration phase, which augments S with new tasks that
the method cannot yet solve. Figure 6 shows examples of generated tasks with solutions, i.e. the (T, p) pairs added to S
during training.
Table 2 provides yet another perspective: the performance of the snapshots of TransCoder trained for a given number of
cycles (in rows) on Ss collected in particular cycles (in columns).6 Similarly to previous results, the table demonstrates
overall consistent improvement of the model’s performance. Furthermore, the metric decreases only twice within
columns, which suggests that losing the capacity to solve tasks that were solved in the past occurs only occasionally.
6
Conclusions and future work
This study summarized our preliminary findings on TransCoder and illustrated its overall capacity to provide itself with
a learning gradient. Crucially, the generative aspect of this architecture, combined with expressing candidate solutions
in a DSL, allows the method to obtain concrete target DSL programs and so gradually transform an unsupervised
6Calculated off-line, after the completion of the run.
8


--- Page 9 ---
Learning from Mistakes with TransCoder
A PREPRINT
Figure 5: Solving rate after each Reduction phase for TransCoder runs with different exploration and reduction
parameters. The graph shows runs with different thresholds of the solved problem rate that trigger the transition from
Reduction to Exploration.
Table 2: Performance of the snapshot of the model from a given cycle (row) on the synthetic examples collected in a
given cycle (column). For instance, the model preserved in cycle 2 solves 0.47% of synthetic tasks created in cycle 3.
Synthetic task set S from cycle
TransCoder’s snapshot from cycle
1
2
3
4
5
1
35.08%
0.56%
0.05%
0.00%
0.01%
2
33.35% 29.68%
0.47%
0.11%
0.11%
3
43.06% 30.44% 34.18%
1.35%
0.65%
4
43.53% 28.11% 30.33% 24.33%
1.84%
5
49.03% 31.22% 31.40% 30.74% 24.74%
learning problem into a supervised one. As evidenced by the experiment, supervised learning facilitated in this way
provides more informative learning guidance than reinforcement learning.
The modularity of the proposed architecture allows the model to be adapted for other types of data. In particular, the
Solver and Generator modules are independent of the input data type, while the only type-specific module is Perception.
Future work will include applying the approach to other benchmarks in different domains, developing alternative
interchangeable DSLs, transferring abstraction and reasoning knowledge between datasets, and prioritizing the search
in the solution space to solve the original ARC tasks.
Acknowledgements
This research was supported by TAILOR, a project funded by EU Horizon 2020 research and innovation program under
GA No. 952215, by the statutory funds of Poznan University of Technology and the Polish Ministry of Education and
Science grant no. 0311/SBAD/0726.
9


--- Page 10 ---
Learning from Mistakes with TransCoder
A PREPRINT
Figure 6: Examples of (task, program) pairs synthesized by the model.
10


--- Page 11 ---
Learning from Mistakes with TransCoder
A PREPRINT
Appendix
Specification of the DSL
Table 3: The list of types available in the DSL.
Name
Description
Arithmetic
An abstract type that implements basic arithmetic operations such as addition and subtraction
Bool
Logical type; accepts True/False values
Color
Refers to the categorical value of pixels. It can take one of ten values
Comparable
An abstract type that implements basic operations that allow objects to be compared with each
other
Int
Simple integer type
Loc
A location consisting of two integers
Connectivity
The type of neighborhood used by the FloodFill operation; possible values are n4 and n8
Direction
The type of direction used by the Rotate operation; possible values are cw (clockwise) and cww
(counterclockwise)
Orientation
The type of direction used by the Flip operation; possible values are vertical and horizontal
Region
An object representing any list of pixels and their colors
List[T]
A generic type representing a list of objects of a compatible type
Pair[T, L]
A generic type representing a pair of objects of a compatible type
Table 4: The list of predefined symbol keys available in the DSL. The keys Zero, One, Horizontal, Vertical, N4, N8, Cw,
and Ccw represent constant values and are always present in a Workspace. Colors are only available if they appear
within a given task. Scene is a key relative to a specific pair of demonstrations. FunctionalInput is a special key used by
higher-order functions.
Name
Type
Description
Zero
Int
A constant ‘0‘
One
Int
A constant ‘1‘
Horizontal
Orientation
A categorical value used for the Flip operation
Vertical
Orientation
A categorical value used for the Flip operation
N4
Connectivity
A categorical value used for the FloodFill operation
N8
Connectivity
A categorical value used for the FloodFill operation
Cw
Direction
A categorical value used for the Rotate operation
Ccw
Direction
A categorical value used for the Rotate operation
Black
Color
A categorical value of color from ARC
Blue
Color
A categorical value of color from ARC
Red
Color
A categorical value of color from ARC
Green
Color
A categorical value of color from ARC
Yellow
Color
A categorical value of color from ARC
Grey
Color
A categorical value of color from ARC
Fuchsia
Color
A categorical value of color from ARC
Orange
Color
A categorical value of color from ARC
Teal
Color
A categorical value of color from ARC
Brown
Color
A categorical value of color from ARC
Scene
Region
A Region representing input raster from an input-output demonstration pair
Functional Input
-
A special key available only during execution/generation of functional operation
subprogram
11


--- Page 12 ---
Learning from Mistakes with TransCoder
A PREPRINT
Table 5: Definitions of the operations available in the DSL.
Name
Signature
Description
Add
(A: Arithmetic, A: Arithmetic) ->A: Arithmetic
Adds two objects of the same type inheriting from Arithmetic
Area
(Region) ->Int
Calculates the surface area of a region
Crop
(Region, Loc, Loc) ->Region
Cuts a subregion based on the top left and bottom right vertices
Deduplicate
(List[A]) ->List[A]
Removes duplicates from the list
Diff
(List[A], List[A]) ->List[A]
Performs a difference operation on two lists
Draw
(Region, Union[Region, List[Region]]) ->Region
Overlays a Region or list of Regions on the given input region
Equals
(A, A) ->Bool
Compares two objects of the same type
Filter
(List[A], (A->Bool)) ->List[A]
Filters the list of input objects based on the result of the subroutine run on each input
element
First
(Pair[A, Type]) ->A
Gets the first element of the input pair
Flip
(Region, Orientation) ->Region
Performs a vertical or horizontal flip of the input region
FloodFill
(Region, Color, Connectivity) ->List[Region]
Performs segmentation of the input Region using the Flood Fill algorithm and the back-
ground color and neighborhood type (n4 or n8)
GroupBy
(List[A], (A->B)) ->List[Pair[B, List[A]]]
Groups objects from the input list based on the results of the subroutine
Head
(List[A]) ->A
Gets the first element of the input list
Height
(Region) ->Int
Returns the height of the region
Intersection
(List[A], List[A]) ->List[A]
Returns the intersection of two lists
LBC
(Region) ->Loc
Returns the location of the left bottom corner
LTC
(Region) ->Loc
Returns the location of the left top corner
Len
(List[Type]) ->Int
Returns the length of the input list
Line
(Loc, Loc, Color) ->Region
Creates a single-color Region that represents a line between two points
Loc
(Int, Int) ->Loc
Location object constructor
Map
(List[A], (A->B)) ->List[B]
Performs the transformation operation of each element of the input list using a subroutine
MostCommon
(List[A], (A->B)) ->B
Returns the most frequently occurring object from the input list based on the value returned
by the subroutine applied to the list elements
Neg
(Union[A, B: Bool]) ->Union[A, B: Bool]
Performs a negation operation on the input object
Paint
(Region, Color) ->Region
Colors the input region a solid color
Pair
(A, B) ->Pair[A, B]
The constructor of an object of type Pair
Pixels
(Region) ->List[Region]
Returns a list of pixels of the input region
RBC
(Region) ->Loc
Returns the location of the right bottom corner
RTC
(Region) ->Loc
Returns the location of the right top corner
Rect
(Loc, Loc, Color) ->Region
Creates a single-color Region representing a rectangle bounded by the input locations
Reverse
(List[A]) ->List[A]
Reverses the input list
Rotate
(Region, Direction) ->Region
Rotates the Input Region clockwise or counterclockwise
Scale
(Region, Union[Int, Pair[Int, Int]]) ->Region
Scales the input Region according to the integer argument
Second
(Pair[Type, A]) ->A
Returns the second element of the input pair
Shift
(Region, Union[Loc, Pair[Int, Int]]) ->Region
Shifts the input Region by an integer argument
Sort
(List[A], (A->Comparable) ->List[A]
Sorts the input list based on the result of the subroutine applied to the list
12


--- Page 13 ---
Learning from Mistakes with TransCoder
A PREPRINT
Table 5: Definitions of the operations available in the DSL.
Name
Signature
Description
Sub
(A: Arithmetic, A: Arithmetic) ->A: Arithmetic
Subtracts two objects of the same type inheriting from Arithmetic
Tail
(List[A]) ->A
Gets the last element of the input list
Union
(List[A], List[A]) ->List[A]
Returns the sum of two input lists
Width
(Region) ->Int
Returns the width of the region
Zip
(List[A], List[B]) ->List[Pair[A, B]]
Creates a list of pairs of corresponding elements in the input lists
13


--- Page 14 ---
Learning from Mistakes with TransCoder
A PREPRINT
References
Mikhail M Bongard. The problem of recognition. M.: Nauka, 1967.
Douglas R. Hofstadter. Fluid concepts & creative analogies : computer models of the fundamental mechanisms of
thought. Basic Books, New York, 1995. ISBN 0465051545.
François Chollet. On the measure of intelligence. CoRR, abs/1911.01547, 2019. URL http://arxiv.org/abs/
1911.01547.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes, 2022.
David Alvarez-Melis and Tommi S. Jaakkola. Tree-structured decoding with doubly-recurrent neural networks.
In International Conference on Learning Representations, 2017. URL https://openreview.net/forum?id=
HkYhZDqxg.
R. J. Williams. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine
Learning, 8:229–256, 1992.
R. S. Sutton, D. Mcallester, S. Singh, and Y. Mansour. Policy gradient methods for reinforcement learning with function
approximation. In Advances in Neural Information Processing Systems 12, volume 12, pages 1057–1063. MIT Press,
2000.
Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B. Tenenbaum, and Jiajun Wu. The neuro-symbolic concept
learner: Interpreting scenes, words, and sentences from natural supervision. arXiv:1904.12584 [cs], April 2019.
URL http://arxiv.org/abs/1904.12584. arXiv: 1904.12584.
Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Lawrence Zitnick, and Ross B. Girshick.
CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning. CoRR, abs/1612.06890,
2016. URL http://arxiv.org/abs/1612.06890.
Kevin Ellis, Catherine Wong, Maxwell Nye, Mathias Sablé-Meyer, Lucas Morales, Luke Hewitt, Luc Cary, Armando
Solar-Lezama, and Joshua B. Tenenbaum. Dreamcoder: bootstrapping inductive program synthesis with wake-
sleep library learning. In Proceedings of the 42nd ACM SIGPLAN International Conference on Programming
Language Design and Implementation, PLDI 2021, page 835–850, New York, NY, USA, June 2021. Association for
Computing Machinery. ISBN 978-1-4503-8391-2. doi:10.1145/3453483.3454080. URL https://doi.org/10.
1145/3453483.3454080.
Swarat Chaudhuri, Kevin Ellis, Oleksandr Polozov, Rishabh Singh, Armando Solar-Lezama, and Yisong Yue. Neu-
rosymbolic programming. Foundations and Trends® in Programming Languages, 7(3):158–243, December 2021.
ISSN 2325-1107, 2325-1131. doi:10.1561/2500000049. URL https://www.nowpublishers.com/article/
Details/PGL-049.
14
