--- Page 1 ---
Even with AI, Bijection Discovery is Still Hard: The
Opportunities and Challenges of OpenEvolve for
Novel Bijection Construction
Davis Brown1,3, Jesse He1,2, Helen Jenne*1, Henry Kvinge1,4, and Max Vargas1
1 Pacific Northwest National Laboratory, 2 University of California San Diego,
3 University of Pennsylvania, 4 University of Washington
Abstract.
Evolutionary program synthesis systems such as AlphaEvolve, OpenEvolve, and
ShinkaEvolve offer a new approach to AI-assisted mathematical discovery. These systems utilize
teams of large language models (LLMs) to generate candidate solutions to a problem as human
readable code. These candidate solutions are then ‘evolved’ with the goal of improving them
beyond what an LLM can produce in a single shot. While existing mathematical applications
have mostly focused on problems of establishing bounds (e.g., sphere packing), the program
synthesis approach is well suited to any problem where the solution takes the form of an explicit
construction. With this in mind, in this paper we explore the use of OpenEvolve for combinatorial
bijection discovery. We describe the results of applying OpenEvolve to three bijection construction
problems involving Dyck paths, two of which are known and one of which is open. We find that
while systems like OpenEvolve show promise as a valuable tool for combinatorialists, the problem
of finding novel, research-level bijections remains a challenging task for current frontier systems,
reinforcing the need for human mathematicians in the loop. We describe some lessons learned for
others in the field interested in exploring the use of these systems.
Keywords: AI for math, Combinatorial bijections, LLM program synthesis, Dyck paths, lattice
paths, pattern avoidance
1
Introduction
Evolutionary systems have recently emerged as powerful tools for scientific discovery,
leveraging the ability of large language models (LLMs) to generate and modify code. For
example, FunSearch was successfully applied to problems in combinatorial optimization
such as the cap set problem [8, 17]. Its successor AlphaEvolve discovered faster matrix
multiplication algorithms, improvements to the minimum overlap problem, and an
improved construction of kissing numbers in dimension 11 [15]. These successes were
extended in [9] to include advances in finite field Kakeya and Nikodym sets, Crouzeix’s
conjecture, and the moving soft problem. These and other evolutionary systems [5, 11, 12]
have also been applied to problems in systems research and algorithmic design.
*helen.jenne@pnnl.gov
arXiv:2511.20987v1  [math.CO]  26 Nov 2025


--- Page 2 ---
2
Evolutionary program synthesis approaches use LLMs to mutate and recombine
previously generated code. Using code as a medium to develop machine learning-driven
solutions facilitates interpretability and may bias towards simpler solutions. Current
systems of this kind can be applied to problems satisfying two requirements: (1) the
problem can be formulated so that candidate solutions are expressible in a common
programming language (e.g., Python), and (2) candidates can be verified automatically.
Compared to other areas of math, problems in algebraic combinatorics are particularly
well suited for such systems. The objects of interest are often straightforward to represent
on a computer, and the software library Sage [22] simplifies their manipulation and
analysis. Furthermore, the likely presence of Sage in LLM training data means models
may be able to leverage this code. In this paper, we focus on the problem of bijection
discovery: given finite sets A and B (often parameterized by a positive integer n),
the goal is to produce a mathematically meaningful Python function defining an
algorithmic bijection between A and B. We choose problems where the sets A and B are
easily generated in Python to enable automatic verification of the proposed bijections.
There is reason for optimism that evolutionary systems could successfully discover
bijections. LLM training sets likely contain extensive descriptions of key combinatorial
bijections in both natural language (via arXiv and MathOverflow) and code (via Sage),
providing prototypes for the kinds of constructions that mathematicians value. Fur-
thermore, LLMs can iterate through potential solutions far more rapidly than humans
and draw from a vast breadth of mathematical knowledge. However, whether they are
sufficiently creative for this type of discovery remains an open question.
In this paper we present case studies applying the system OpenEvolve [19] to three
bijection discovery problems: two with known solutions and one open problem. All
problems involve Dyck paths, chosen because their numerous bijections with other
objects counted by the Catalan numbers are well-documented in both literature and code,
ensuring strong representation in model training data. The problems are:
(1) Bijection between odd-diagonal avoiding paths and Dyck paths: North East lattice
paths from (0, 0) to (2n, 2n) that avoid the points (2i −1, 2i −1), 1 ≤i ≤n are
enumerated by the Catalan number C2n [21, Problem A4]. Stanley [21] rates this
problem as difficulty 2+, which he describes as “about the hardest problem that
could be reasonably assigned to a class of graduate students”. While a bijective
proof is known, direct LLM prompting failed to produce the solution, making it an
appropriate benchmark for evolutionary methods.
(2) Bijection between 321-avoiding permutations and Dyck paths: Although there are
at least three known bijections between Dyck paths to 321-avoiding permutations
[4], they are nontrivial. We selected this problem based on preliminary experiments
where we prompted LLMs to produce bijections between Catalan objects without
evolutionary refinement. While even weaker models successfully generated some


--- Page 3 ---
3
bijections (such as between Dyck paths and 213-avoiding permutations), only GPT-5
produced a bijection with 321-avoiding permutations (the Billey–Jockusch–Stanley
bijection [3]). The difficulty of this problem suggests it could be a useful case study
for OpenEvolve when used with other LLMs.
(3) Area-bounce exchanging bijection on Dyck paths: A recent paper [2] defines
an area-bounce exchanging bijection on a subset of Dyck paths. This problem is
well-suited for OpenEvolve because the existing implementation [23] serves as a
starting point, and extending this bijection to a broader class of Dyck paths would
be progress on an open research question.
Our experiments yield mixed but instructive results. OpenEvolve successfully dis-
covers the known bijection for problem (1), but surprisingly fails to find a bijection for
problem (2) under a variety of different configurations (despite GPT-5 finding a bijection
when prompted directly). Similarly, for problem (3), the system does not find a solution.
These failures provide guidance for future applications and inform this paper’s focus
on synthesizing lessons for mathematicians considering using evolutionary approaches
in combinatorics research. The paper is organized as follows: Section 2 describes the
OpenEvolve framework, Section 3 presents our case studies, and Section 4 discusses
lessons learned for problem selection, objective function design, and realistic expectations
when using these tools in mathematical research.
2
Background
2.1
Evolutionary program synthesis
Evolutionary program synthesis systems like OpenEvolve use LLMs to generate computer
programs to optimize a specific objective function. For example, if the objective is sphere
packing, each generated program might specify a configuration of spheres which can
each be judged by their sphere density. A population of these program is generated
and then evolves as sub-optimal solutions are discarded, solutions are mutated (also
via LLMs) to introduce novel features, and new programs are generated. Given the
power of modern machine learning, it is reasonable to ask why one should go through
the intermediary of code rather than optimizing for a solution directly. Forcing AI
systems to produce solutions as computer programs leads to intrinsic interpretability
since an expert can directly examine the code, a critical feature when mathematical
discovery is the goal. Being able to run a solution as a computer program also allows for
verification of correctness (though not at the level of a proof), thus avoiding the common
situation where LLMs produce extremely plausible sounding natural language solutions
that contain subtle errors. Moreover, requiring solutions to be written in code injects a


--- Page 4 ---
4
powerful simplicity bias which avoids ‘bag of heuristic’ solutions where a model simply
enumerates an exhaustive list of conditions that offer no mathematical insight [14].
The basic OpenEvolve algorithm proceeds as follows:
(1) Start with an initial Python program that takes as input an elements of a set A(n)
for n ∈Z>0, and outputs an object in set B(n).
(2) Evaluate this program using an objective function designed to measure how close it
is to being a bijection.
(3) Add the program and evaluation to a database (‘population’) of programs.
(4) Prompt an LLM to generate modifications to the program aimed at improving its
evaluation.
(5) Apply the LLM’s modifications to create a new program and evaluate it.
(6) Repeat steps (4) and (5) for a user-specified number of iterations so as to evolve new
solutions.
The initial Python program.
For each problem, we started with multiple initial Python
programs, evolved in parallel using independent populations (called ‘islands’). We
obtained the initial Python programs by prompting an LLM with a description of the
problem, sampling with the default hyperparameters in the chat interface.
Program evaluation.
We evaluated programs by (1) running the program on all objects in
set A(n) and measuring statistics that quantified how closely it approximated a bijection
and (2) prompting an LLM to evaluate the program.
Empirical evaluation for a fixed n. For a small n, we scored each program f by its
proximity to being a bijection. To quantify nearness of a map to being a surjection we
calculate the surjectivity score which we define as the ratio | f (A(n))|/|B(n)|. To calculate
nearness of a map to be being injective we calculate the injectivity score, which we define
as the ratio of unique elements in f (A(n)) to the total elements in f (A(n)). Finally, to
penalize f that mapped to the wrong domain we also calculated the fraction of f (A(n))
that actually belong to B(n). We call this the validity score. We averaged the three scores
to obtain a single combined score.
LLM evaluation. While we use the word “bijections” in this work and in the broader
community, it is understood that what we actually mean is something more specific.
Assigning a random pairing between elements in two sets is of limited value. What we
really want is a map A(n) →B(n) that both generalizes to most n and also yields insight
into A(n) and B(n). To get at these less quantifiable properties, we used an LLM judge
to perform additional checks:


--- Page 5 ---
5
(1) Check for “cheating”. We observed that LLMs readily exploit shortcuts to achieve
high scores. For example, models sometimes generated all objects from sets A(n)
and B(n) and established a one-to-one correspondence using an index-based map-
ping. The LLM evaluator was instructed to give scores of 0.0 in these cases.
(2) Evaluate whether the code implemented the algorithm described in the program’s
docstring1. The purpose of this evaluation was to differentiate programs that scored
low in the empirical evaluation due to a flawed algorithm, and programs that scored
low due to implementation errors. The LLM was instructed to give a score on a
scale of 0.0 to 1.0 along with an argument that the code matches the description in
the docstring, or a counterexample.
(3) To impose a simplicity prior (on a scale of 0.0 to 1.0), the LLM was prompted
to give high scores to programs that are simple, intuitive, and reveal a structural
correspondence between the two paths, and low scores to programs that seemed
convoluted, arbitrary, or involved a lot of case work.
The LLM was also prompted to provide reasoning for its scores and suggestions for
improvement. These responses were used in the prompts in the evolution step, in order
to give more guidance than a numeric score. The program’s final score was a weighted
average of the averaged LLM scores and the empirical evaluation.
Prompt for revision.
In the evolution step, an LLM is given a prompt that explains the
desired bijection (including details around A(n) and B(n)), provides hints, describes the
evaluation criteria, specifies the program to edited, and highlights other high-scoring
and/or diverse programs in the current database to take inspiration from.
Program sampling
OpenEvolve uses the Multi-Dimensional Archive of Phenotypic
Elites (MAP-Elites) algorithm [13] to sample programs. The purpose of applying MAP-
Elites in this context is to maintain a diverse population of programs to sample from,
reducing the likelihood that the system will get stuck in local minima. The algorithm
works by discretizing user-defined features, (such as code complexity or difficulty mea-
sures) to create a grid of cells, with each cell containing at most one program. When a
new program is produced, its corresponding grid cell is determined, and it replaces any
existing program in that cell if the new one achieves a higher combined score from the
empirical and LLM evaluations. We select a program to evolve by randomly sampling
from the MAP-Elites grid, but more sophisticated sampling strategies are also possible.
1When generating programs, LLMs must produce a docstring describing what the program does.


--- Page 6 ---
6
2.2
Related Work
A number of recent works have applied evolutionary program synthesis tools to problems
in research-level mathematics. In a follow-on to [15], [9] applied AlphaEvolve (the
closed-source inspiration for OpenEvolve) to 67 different problems in mathematics with
impressive success: in many cases the system was able to discover the best known result
and sometimes improved upon it. Notably however, most problems in this work amount
to establishing tighter upper or lower bounds on a numerical quantity. Several of their
observations are applicable to our use-case and will be discussed further in Section 4.
There are other computational tools to assist mathematicians with bijection discovery,
including databases like the OEIS [16] and FindStat [18], and more recently the Bijec-
tionist’s Toolkit [10]. These tools have been applied to study homomesy [6, 7] and cyclic
sieving [1]. We see these approaches as complementary and envision a future iteration
where LLMs can use these tools in their search for bijections.
3
Case studies
3.1
Odd-diagonal avoiding paths and Dyck paths
Problem.
Produce a program implementing a bijective map from NE lattice paths from
(0, 0) to (2n, 2n) that avoid the points (2i −1, 2i −1) to Dyck paths from (0, 0) to (2n, 2n).
Results.
An evolving population of programs generated by OpenEvolve (including
a valid solution) is visualized in Figure 1. The top left plot shows the progression of
program metrics: the system discovers the bijection after 60 iterations, but the combined
scores of new introduced programs are very noisy. The best program validity score within
the population is maximized early in evolution, indicating that the LLMs are easily able
to generate programs that reliably output Dyck paths. On the other hand, surjectivity and
injectivity take many more generations to optimize, with some understandable trade-offs
occurring between these. The program defining the valid bijection which is generated at
iteration 60 can be found in Figure 1, right. This is the same as the known bijection from
[21]. Notably, the docstring was over 600 words and included a sketch of invertibility (see
Figure 3 in the Appendix), illustrating how the docstring produced by the system could
aid a human mathematician in proving a bijection, provided that it is carefully checked.
How much variation is there is proposed solutions?
Surprisingly, we found limited
variation in injectivity, surjectivity, and validity scores suggesting that models tend to
gravitate toward a handful of different candidate maps. Further analysis showed that
these metrics were not granular enough to always differentiate distinct mappings – the 73
programs produce 26 functionally different mappings but only 10 different surjectivity


--- Page 7 ---
7
scores. To further understand the variability among programs with the same metrics
and even the same empirical mappings, we plot the text embeddings2 of all 73 programs
after dimensionality reduction (Figure 1, bottom left), giving programs defining the same
mapping the same color. We find that programs with the same surjectivity score and
even those that functionally correspond to the same map could have very different text
embeddings (for example, the two orange upside down triangles that are the exact same
program are distant on the plot). This highlights an axis of variation that can be easy to
overlook: a significant amount of variation introduced by LLMs can relate to program
implementation rather than program functionality.
def
avoiding_path_to_dyck_path (path , m):
# Find
the
first
return to the
diagonal:
smallest t>0 with
height h(t) = 0.
h = 0
t = -1
for i, step in
enumerate(path , start =1):
h += 1 if step == 1 else
-1
if h == 0:
t = i
break
if t ==
-1:
raise
ValueError ("No return to
diagonal
found; invalid
input.")
U = path [:t]
V = path[t:]
# Determine
the
Dyck
interior X of the
primitive
excursion U.
if U[0] == 1:
X = U[1: -1]
# interior
is a Dyck
path
R = avoiding_path_to_dyck_path (V, m-t
//2)
return
[1] + X + [0] + R
else:
# U = 0 Y 1 with Y a co -Dyck
interior
# take X = complement (Y) which is Dyck
Y = U[1: -1]
X = [1 - s for s in Y]
R = avoiding_path_to_dyck_path (V, m-t
//2)
return
[1] + R + [0] + X
Figure 1: Left, top: Progression of the best program metrics over 70 iterations for different terms
in the scoring function. Left, bottom: Text embedding of all programs, after applying
dimensionality reduction using PCA. Each functionally distinct mapping is given a different color
(the bijection is black). The surjectivity score is indicated by the relative size of the points. Right:
The valid bijection produced after 60 iterations.
2We map programs into R3072 using OpenAI’s text-embedding-3-large model. Vector proximity reflects
textual semantic similarity; programs with similar structure, variable names, and comments will be close.


--- Page 8 ---
8
3.2
321-avoiding permutations and Dyck paths
Problem.
Produce a program that implements a bijective map from Dyck paths of
semilength n to 321-avoiding permutations in Sn.
Results.
We applied OpenEvolve with a variety of configurations, but no run yielded a
bijection. Figure 2 shows results from two runs, one where the team of LLMs included
more large models and one where the team included more small models3.
In the
former case, the best program mapped onto the subset of permutations that is both 321-
avoiding and 3142-avoiding. For n = 4, this program produces 13/14 target permutations,
a significant improvement over the initial program which produces only 8/14 target
permutations.
In contrast, the team of smaller models failed to improve upon the
empirical scores of the best initial program. In this case, we also tried evaluating on
n = 5 but found no improvement. Interestingly, in both runs some responses mention the
Billey–Jockush–Stanley bijection [3] by name, but attribute it to the wrong map.
LLMs can struggle when there are several closely related problems.
In addition to
being in bijection with 321-avoiding permutations, Dyck paths are in bijection with stack-
sortable (231-avoiding) permutations, and 132-, 213-, and 312-avoiding permutations.
Bijections to 132-, 213-, and 312-avoiding permutations can be obtained from the bijection
to stack-sortable permutations by simple operations (reversing the permutation, replacing
each value x in the permutation by n + 1 −x, or combining these operations, respectively).
The prominence of these known bijections appears to be a major barrier preventing the models from
generating the bijection to 321-avoiding permutations. The existence of these few prototypical
solutions may partly explain the more densely clustered program text embeddings in
Figure 2 compared to Figure 1.
3.3
Area-bounce exchanging bijection
Problem.
Produce a program that implements a bijective map from Dyck paths to Dyck
paths that exchanges the area and bounce statistics.
Set-up details.
Since this is an open problem, we seeded the population with a map
from Ayyer and Sundaravaradan [2, 23]. The system is instructed that the map provided
is a valid bijection that exchanges area and bounce on a subset of Dyck paths, and is asked
to analyze its failures and propose a targeted modification to generalize it. Programs
were scored using paths of semilength 4. The Ayyer-Sundaravaradan mapping hits 8 of
3Smaller, cheaper models allow for more iterations (and therefore more candidate solutions) for the
same cost.


--- Page 9 ---
9
def map(path):
n = len(path) // 2
if n == 0:
return []
perm = []
S = []
current_num = 1
for
step in path:
if step == 1:
S.append( current_num )
current_num
+= 1
elif
step == 0:
last = perm [-1] if perm
else
-1
to_move = []
while S and S[-1] < last:
to_move.append(S.pop ())
if S:
perm.append(S.pop ())
perm.extend(reversed(to_move))
while S:
perm.append(S.pop ())
return
perm
Figure 2: Left: Text embeddings of all programs, after dimensionality reduction using PCA (using
more large models (top) or more smaller models (bottom)). Functionally equivalent programs are
given the same color. Surjectivity score is indicated by the relative size of the points. Right: The
best program produced for the 321-avoiding permutation problem. The docstring and comments
have been omitted for space.
the 14 Dyck paths, is injective, and doesn’t produce any out-of-domain outputs, since it
returns None if the Dyck path input is not one of the paths the map works for.
LLMs can struggle when constructions in the problem look similar to constructions
seen during pretraining.
Concepts that seem very salient in LLM’s training data in-
terfered with its ability to make progress on this problem. For example, the definition
of bounce used in [2] is formulated in a way that is slightly non-standard, so the initial
feedback from the LLM evaluators was focused on re-defining the bounce statistic. We
encountered a similar issue due to the prominence of the zeta map in related literature.
The zeta map sends the statistics (area, dinv) to (bounce, area). While this does not solve
the problem, the models frequently stated that it did and replaced the entire program
with a program that used it. We addressed both of these issues with careful prompting.
Ultimately, the model produced a higher scoring solution but not using an algorithmic
bijection, which we discuss further in Section 4.


--- Page 10 ---
10
4
Lessons learned
Challenge #1: Designing an objective function
A primary challenge in applying evolutionary search for bijection discovery is objective
function design. Combinatorial bijections are all-or-nothing constructions: either a map
is a bijection or it is not. As such, the community has spent much less time thinking
about how to quantify the extent to which an arbitrary map is a bijection. The ability
to construct granular scoring functions (ideally continuous) was identified as a crucial
ingredient to finding solutions with AlphaEvolve in [9]. In our case studies, programs that
defined distinct mappings yielded identical surjectivity and injectivity scores, resulting in
a plateaued objective landscape.
It may be that the problem of bijection discovery is simply less amenable to incremental
improvement than problems like sphere packing, as the discovery of a correct mapping can
require a single critical insight that resolves multiple structural flaws at once. Alternatively,
program evaluation may simply need refinement with more granular objective functions,
such as a score that differentiates between a mapping with many 2-way collisions and
one with a single k-way collision. It’s also possible that a more fundamental change may
be necessary. In [9], they evolved programs that search for a construction rather than
programs that directly generate a construction. Perhaps performance in our context could
similarly be improved by evolving programs whose purpose is to search for bijections
rather than evolving programs that define bijections.
Challenge #2: Aligning the objective with mathematical intent
Models often discover “loopholes” in the objective function, producing programs that
achieve high scores but are not useful from the perspective of mathematical discovery.
This is referred to as the “cheating phenomenon” [9] or “reward hacking” [11, 20], and
occurs when the solution satisfies the literal constraints but violates the spirit of the
problem. As we discussed in Section 2, one cheating behavior that we observed was LLMs
exhaustively enumerating all objects from the sets A and B in order to construct a trivial
index-based mapping. To prevent this kind of solution, we added explicit instructions not
to generate all of the objects in A and B. Additionally, we instructed the LLM evaluator
to check for cheating, giving specific examples of what this might look like.
While these steps successfully prevented this particular instance of reward hacking,
we found that it was difficult to anticipate all of the different ways a model might reward-
hack. For instance, in evolving the area-bounce exchanging bijection (Problem 3), the
system implemented a function that, given a Dyck path, first found its area and then used
breadth-first search to find a path with the same bounce. While this program resulted in
a near-perfect evaluation score, a mathematician would immediately disqualify such a


--- Page 11 ---
11
solution, since it is a search algorithm rather than an algorithmic bijection and fails to
provide any structural insight.
For the foreseeable future, we believe that in bijection discovery problems an expert-
in-the-loop is essential. Their role is not just to define the initial problem and objective,
but also to periodically inspect the top-performing solutions for pathological behavior
and evaluate whether the system is capturing the intention of the problem.
Challenge #3: The limitations of LLMs as evaluators
The success of these systems currently depends on having objective, machine-verifiable
evaluation metrics. While LLMs can be used to evaluate programs, two issues pre-
vent them from being reliable evaluators in this context: the difficulty of capturing
mathematical nuances in prompts, and the inconsistency of their responses.
Aside from the case studies described in this paper, we also attempted to apply
OpenEvolve to the problem of discovering a combinatorial interpretation: given a formula,
produce a program that constructs a family of combinatorial objects counted by this
formula. While we could automatically verify the correctness of the counts of candidate
programs, we were not able to get reliable LLM evaluations of the quality of the inter-
pretations. This was likely because (1) it is difficult to define what it means to be an
interesting and useful combinatorial interpretation, making the evaluation prompt diffi-
cult to write, and (2) the candidate programs are not easy to evaluate even for a human.
The candidate programs often contained long docstrings with elaborate definitions that
seemed promising, but were ill-defined or nonsensical once one tried to actually construct
an example of the object. This highlights a point that is perhaps obvious but still worth
stating: given that these systems generate hundreds of programs, it is crucial to set up
the problem and evaluation in such a way that doesn’t require manual reading of LLM
responses.
Beyond the challenge of defining subjective criteria, we also observed that LLM-based
scoring was not consistent. While it might be expected that numerical evaluations vary
depending on the model, we were surprised to find that even when the model was fixed,
repeated evaluations of the exact same program gave scores spanning the entire possible
range. This unreliability made it challenging to weight the LLM-based portion of the
evaluation. When the LLM evaluation is weighted too low, pathological solutions are
not sufficiently penalized, but when it is weighted too high, scores that are spuriously
high due to inherent randomness interfere with the search. Given these issues, we think
a better use of LLMs in the evaluation pipeline would be as filters (for instance, to
automatically remove “cheating” programs) rather than as scorers.


--- Page 12 ---
12
Challenge #4: LLMs favor solutions to well-known problems
Beyond the observation that evolutionary program synthesis works best on problems
with a smooth objective landscape, a more subtle challenge arises from biases in the
LLM’s training data. Our case studies illustrate that models have a tendency to get stuck
on famous mathematical results that are associated with key words in the problem, even
when they repeatedly prove to be unhelpful. For instance, when tasked with discovering
a bijection between Dyck paths and 321-avoiding permutations (Problem 2) the model
repeatedly produced programs that involved stack-sorting, which is used in well-known
bijections with Dyck paths for four other pattern-avoiding permutations. Similarly, in
Problem 3, the model was drawn to using the zeta map. These observations suggest that
in problem selection and prompt writing, one should consider potential “gravitational
pulls” and make efforts to steer models away from unproductive paths.
Challenge #5: Overhead of setup
Practical barriers to entry include the robustness and usability of the available software,
and the overhead of problem formulation. The technical barrier is gradually lowering
as codebases like OpenEvolve are regularly updated and new options are released. As
the available software improves, the primary overhead will likely be problem selection,
designing the objective function, and prompt engineering. The latter might be the least
familiar for mathematicians new to using these tools, and we found that generating good
prompts required significant iteration at first. In general, our experience was that getting
these systems set up with a new problem requires at least a few hours even when you
are familiar with the system and the problem, and longer otherwise.
Cost. Finally, since these systems work best with frontier models requiring paid API
calls, cost is an obvious concern. Fortunately, cost-per-token at time of writing means
that significant compute is within reach of most mathematicians. For example, one run
for Problem 2 used Gemini-2.5-flash, o4-mini, Gemini-2.5-pro, and Claude-3.7-sonnet for
evolution and Gemini-2.5-flash for evaluation. A run of 200 iterations cost about $10,
with each iteration using two API calls: one for evolution (11,000 tokens on average) and
one for evaluation (6,000 tokens on average).
In summary, we remain optimistic about the application of evolutionary systems for
bijection discovery, but successful application will require the right kind of problem
with a well-designed objective function along with human expertise and guidance. One
interesting additional consequence of working with these systems is that they force
a mathematician to very directly confront what they value in a mathematical artifact.
Monitoring LLMs that have an endless ability to produce mathematics that aligns with
our literal instructions but not with what we want has the potential to sharpen our focus
on the value of what we produce in our profession.


--- Page 13 ---
13
5
Acknowledgements and Disclosure of Funding
This work was conducted under the Laboratory Directed Research and Development
Program at PNNL, a multi-program national laboratory operated by Battelle for the U.S.
Department of Energy under contract DE-AC05-76RL01830.
References
[1] A. Adams, J. Elder, N. Lafreniere, E. McNicholas, J. Striker, and A. Welch. Cyclic siev-
ing on permutations: an analysis of maps and statistics in the FindStat database, 2024.
arXiv:2402.16251.
[2] A. Ayyer and N. Sundaravaradan. An area-bounce exchanging bijection on a large subset of
Dyck paths. Annals of Combinatorics, pages 1–29, 2025.
[3] S. Billey, W. Jockusch, and R. P. Stanley. Some combinatorial properties of Schubert polyno-
mials. Journal of Algebraic Combinatorics, 2(4):345–374, 1993.
[4] D. Callan.
Bijections from Dyck paths to 321-avoiding permutations revisited, 2007.
arXiv:0711.2684.
[5] A. Cheng, S. Liu, M. Pan, Z. Li, B. Wang, , A. Krentsel, T. Xia, M. Cemri, J. Park, S. Yang, et al.
Barbarians at the gate: How AI is upending systems research, 2025.
[6] W. Dowling and N. Lafreniere. Homomesy on permutations with toggling actions. Involve,
18:829–854, 2025.
[7] J. Elder, N. Lafrenière, E. McNicholas, J. Striker, and A. Welch. Homomesies on permutations:
An analysis of maps and statistics in the findstat database. Mathematics of Computation,
93(346):921–976, 2024.
[8] J. S. Ellenberg, C. S. Fraser-Taliente, T. R. Harvey, K. Srivastava, and A. V. Sutherland.
Generative modeling for mathematical discovery, 2025. arXiv:2503.11061.
[9] B. Georgiev, J. Gómez-Serrano, T. Tao, and A. Z. Wagner. Mathematical exploration and
discovery at scale, 2025. arXiv:2511.02864.
[10] A. Grosz, T. Kietreiber, S. Pfannerer, and M. Rubey.
A bijectionist’s toolkit.
Séminaire
Lotharingien de Combinatoire, 89, 2023.
[11] R. T. Lange, Y. Imajuku, and E. Cetin. ShinkaEvolve: Towards open-ended and sample-
efficient program evolution, 2025. arXiv:2509.19349.
[12] F. Liu et al. LLM4AD: A platform for algorithm design with large language model, 2024.
arXiv:2412.17287.
[13] J.-B. Mouret and J. Clune.
Illuminating search spaces by mapping elites,
2015.
arXiv:1504.04909.
[14] Y. Nikankin, A. Reusch, A. Mueller, and Y. Belinkov. Arithmetic without algorithms: Lan-
guage models solve math with a bag of heuristics, 2024. arXiv:2410.21272.
[15] A. Novikov, N. Vu, M. Eisenberger, E. Dupont, P.-S. Huang, A. Z. Wagner, S. Shirobokov,


--- Page 14 ---
14
B. Kozlovskii, F. J. R. Ruiz, A. Mehrabian, M. P. Kumar, A. See, S. Chaudhuri, G. Holland,
A. Davies, S. Nowozin, P. Kohli, and M. Balog. AlphaEvolve: A Gemini-powered coding
agent for designing advanced algorithms. 2025.
[16] OEIS Foundation Inc. The On-Line Encyclopedia of Integer Sequences. Published electroni-
cally at http://oeis.org.
[17] B. Romera-Paredes et al. Mathematical discoveries from program search with large language
models. Nature, 625(7995):468–475, 2024.
[18] M. Rubey, C. Stump, et al. FindStat - The combinatorial statistics database.
[19] A. Sharma. OpenEvolve: an open-source evolutionary coding agent. GitHub repository.
Accessed: 2025-08-10.
[20] J. Skalse, N. Howe, D. Krasheninnikov, and D. Krueger. Defining and characterizing reward
gaming. Advances in Neural Information Processing Systems, 35:9460–9471, 2022.
[21] R. P. Stanley. Catalan numbers. Cambridge University Press, 2015.
[22] W. Stein et al. Sage Mathematics Software (Version 10.6). The Sage Development Team.
[23] N. Sundar and A. Ayyer. qtcatalan-bijection. GitHub repository.


--- Page 15 ---
15
Appendix
A
The Billey-Jockush-Stanley bijection
We describe the Billey-Jockush-Stanley bijection [3], following the exposition in [4]. Given
a Dyck path defined as a sequence of N and E steps, the ascent sequence {ai} is the
sequence that gives the numbers of the consecutive N steps. The descent sequence {di} is
similarly defined by giving the numbers of consecutive E steps. Then, define the ascent
code (resp. descent code) to be the sequence of partial sums of the ascent lengths Ai :=
i
∑
j=1
aj
(resp. descent lengths Di :=
i
∑
j=1
dj). The last element of the ascent and descent codes
are omitted since it is always the length of the path. In a permutation σ, an excedance
location is a value i such that σ(i) > i, and σ(i) is called the excedance value. With these
definitions established, the bijection is straightforward to describe: given a Dyck path, let
A and D be its ascent and descent code, respectively. Let D be the excedance locations,
and let A + 1 be the excedance values. Fill in the remaining entries of the permutation in
increasing order.
B
Odd-diagonal avoiding paths and Dyck paths
B.1
Impact of model choice
Our initial run used an LLM ensemble for evolution with Gemini-2.5-pro, GPT-5, and
Gemini-2.5-flash. Since GPT-5 was the model that produced the bijection, we did another
run using just GPT-5 and found that using GPT-5 alone was sufficient, even with low
reasoning. We subsequently did several runs using just Gemini-2.5-pro and found that
the model produced the bijection as well when using high reasoning.
B.2
Docstring of best program


--- Page 16 ---
16
Direct , local
bijection
by first even -return
decomposition
with
signed
interior.
Input/Output:
- Steps
are
encoded
by 1 = North (N), 0 = East (E).
- The
input is an odd -diagonal -avoiding (ODA) path
from (0 ,0) to (m,m), i.e., it never
visits
any
diagonal
point (2i-1, 2i -1). Equivalently , if h(t) is the
prefix
height
(#1
- #0). Since
the
path
avoids
all
diagonal
points (2i-1, 2i -1) , any
return to the
diagonal
must
occur at an even -coordinate
point (2k, 2k).This
means
the
prefix
path to
that
point
has
length 4k, so any
return to zero
height
must
occur at a step
index t
that is a multiple
of 4.
- The
output
is a Dyck
path of
semilength m: a 0/1- list of length 2m whose
prefix
heights
are
never
negative.
Bijection
overview:
- Decompose
the
input
path P at its
first
return to the
diagonal (which
occurs at an index
t ≡0 (mod 4)
because P is ODA):
P = U · V,
with U a primitive
excursion (no
diagonal
touch
inside).
There
are
exactly
two
types of
primitive
excursions U from
the
diagonal
to itself:
(A) above -diagonal:
U = 1 X 0, with X a Dyck path ,
(B) below -diagonal:
U = 0 Y 1, with Y a ‘co -Dyck ’ (i.e., complement
of a Dyck
path).
In case (B), the
complemented
interior X := comp(Y) (swap 0 ↔1 in Y) is a Dyck
path.
Thus , in both
cases we have
canonically
associated a Dyck
path X to the
interior
of U.
Recursive
construction (phi):
- Base: if m = 0 (empty
path), return
[].
- Find t = first
index
with
height h(t) = 0.
Let U = path [:t], V = path[t:].
Let X be the
Dyck
interior
of U defined
as:
if U[0] == 1 then X = U[1: -1]
(above -diagonal
excursion)
if U[0] == 0 then X = comp(U[1: -1])
(below -diagonal
excursion)
Then
define
if U[0] == 1: phi(P) = 1 · X · 0 · phi(V)
if U[0] == 0: phi(P) = 1 · phi(V) · 0 · X
This
uses
only
local
data at the
first
even
return
and
recurses
on the
suffix V,
which is again
ODA ( concatenation
of ODA
excursions ).
Why the
output is Dyck:
- The
word 1 X 0 is a Dyck
excursion
because X is Dyck. Concatenating
Dyck
excursions
at
returns
preserves
the
Dyck
property , so both
constructions
yield
Dyck
paths.
Invertibility (sketch):
- Given a Dyck
path D, write
its
unique
first -return
decomposition D = 1 A 0 B with
Dyck A
, B. There
are two
mutually
exclusive
cases
coming
from
the
forward
map:
(i) D = 1 X 0 phi(V)
(above
case), where X = A and phi(V) = B,
(ii) D = 1 phi(V) 0 X
(below
case), where
phi(V) = A and X = B.
The
inverse
identifies
which
case
holds by
recursively
inverting
the
left (A) and
right (B
) Dyck
components
and
checking
which
reconstruction
produces
an ODA
primitive
excursion
first (length
of that
excursion
must be a multiple
of 4 and its
interior
must be , respectively , Dyck (above) or
complemented
Dyck (below)). This
test is local
and
deterministic , giving a two -way
inverse
and
hence a bijection.
Algorithmic
steps
implemented
here:
1)
Validate
length
and
balance.
2) If m == 0: return
[].
3) Scan
once to find
the
first
index t > 0 with
prefix
height h(t) = 0 (first
even
return)
.
4) Set U = path [:t], V = path[t:].
- If U starts
with 1: X = U[1: -1].
- If U starts
with 0: X = complement (U[1: -1]) (bitwise 1 - s).
5)
Recursively
compute R = phi(V).
6) Return
[1] + X + [0] + R if U[0] == 1, else
[1] + R + [0] + X.
Figure 3: The docstring of the program in Figure 1, describing the avoiding path to Dyck path
bijection.
