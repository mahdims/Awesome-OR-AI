--- Page 1 ---
Adversarial Generation and Collaborative Evolution
of Safety-Critical Scenarios for Autonomous Vehicles
Jiangfan Liu1, Yongkang Guo1, Fangzhi Zhong1, Tianyuan Zhang1, Zonglei Jing1,
Siyuan Liang2, Jiakai Wang3, Mingchuan Zhang4, Aishan Liu1âˆ—, Xianglong Liu1,3
1Beihang University 2Nanyang Technological University
3Zhongguancun Laboratory 4Henan University of Science and Technology
Abstract
The generation of safety-critical scenarios in simulation has become increasingly
crucial for safety evaluation in autonomous vehicles (AV) prior to road deployment
in society. However, current approaches largely rely on predefined threat patterns
or rule-based strategies, which limit their ability to expose diverse and unforeseen
failure modes. To overcome these, we propose SCENGE, a framework that can
generate plentiful safety-critical scenarios by reasoning novel adversarial cases
and then amplifying them with complex traffic flows. Given a simple prompt of a
benign scene, it first performs Meta-Scenario Generation, where a large language
model (LLM), grounded in structured driving knowledge (e.g., traffic regulations,
real-world accident records), infers an adversarial agent whose behavior poses a
threat that is both plausible and deliberately challenging. This meta-scenario is
then specified in executable code for precise in-simulator control. Subsequently,
Complex Scenario Evolution uses background vehicles to amplify the core threat
introduced by Meta-Scenario. It builds an adversarial collaborator graph to identify
key agent trajectories for optimization. These perturbations are designed to simulta-
neously reduce the ego vehicleâ€™s maneuvering space and create critical occlusions.
Extensive experiments conducted on multiple reinforcement learning (RL) based
AV models show that SCENGE uncovers more severe collision cases (+31.96%) on
average than SoTA baselines. Additionally, our SCENGE can be applied to large
model based AV systems and deployed on different simulators; we further observe
that adversarial training on our scenarios improves the model robustness. Finally,
we validate our framework through real-world vehicle tests and human evaluation,
confirming that the generated scenarios are both plausible and critical. We hope
our paper can build up a critical step towards building public trust and ensuring
their safe deployment. Our codes can be found at https://scenge.github.io.
1
Introduction
As autonomous vehicles (AVs) [17, 41, 37, 20] approach widespread deployment, ensuring their
safety and reliability to earn public trust has become critical [25, 24, 21, 34]. However, this endeavor
is challenging due to the scarcity of real-world data on rare yet critical incidents. Simulation-based
testing [2, 36] offers a controlled, reusable, and cost-effective way of evaluating behavior under
various conditions, particularly safety-critical scenarios that probe their safety capacity. Current
scenario generation approaches, which largely rely on predefined threat templates [58, 56, 50] or
rule-based strategies [6, 49, 5, 59], struggle to reveal the full spectrum of safety flaws. Due to these
weak risk exposure abilities, AVs retain undiscovered vulnerabilities from inadequate validation. This
challenge is closely related to the field of adversarial machine learning. In this domain, research
âˆ—Corresponding Author
Preprint. Under review.
arXiv:2508.14527v2  [cs.CV]  22 Aug 2025


--- Page 2 ---
focuses on exposing the vulnerabilities of deep neural networks through various attack methodologies.
Such work also involves evaluating model robustness and developing more resilient architectures
[48, 29, 33, 57, 44, 26, 23, 30, 28, 27, 35, 32, 15, 31, 22].
Occlusion
Ego Vehicle
Adversarial Agent
BEV
First-view
Figure 1: The illustration of the safety-critical sce-
narios generated by our SCENGE: a pedestrian
emerging from behind a parked truck, with the
threat amplified by a background vehicle obstruct-
ing the line-of-sight to the adversary.
To address these limitations,
we propose
SCENGE, a two-stage framework that exposes
safety vulnerabilities in AV by performing ad-
versarial threat generation and collaborative tra-
jectory evolution. Our first stage, Meta-Scenario
Generation, uses a LLM to creatively gener-
ate a core adversarial threat from a benign text
prompt. To ensure this threat is both plausible
and challenging, a retrieval augmented genera-
tion RAG [53] framework grounds the LLMâ€™s
reasoning in a structured knowledge base of traf-
fic regulations, driver qualification standards,
and realistic pre-crash scenarios. The generated
meta-scenario is then expressed as executable
Scenic code [11, 12], allowing for diverse and
scalable instantiation in the CARLA simulator
[8]. However, the threat created by a single
adversarial agent is often predictable and insuf-
ficient to create a truly critical dilemma for the
AV. Our second stage, Complex Scenario Evolution, therefore crafts more complex threats by coordi-
nating the surrounding background traffic. It first builds an adversarial collaborator graph to identify
the most influential vehicles. The trajectories of these key agents are then carefully optimized. Rather
than causing direct collisions or simple chaos, these optimizations intensify interaction complexity
by strategically limiting the egoâ€™s escape paths and obstructing its line-of-sight, ultimately increasing
the likelihood of a critical incident.
Extensive experiments on multiple RL-based AV models demonstrate that SCENGE uncovers more
severe collision cases (+31.96%) on average than state-of-the-art baselines. We also confirm its
broad generalizability: the scenarios effectively challenge advanced VLM models like LMDrive, are
transferable to the MetaDrive simulator. Beyond testing, we demonstrate the practical value of our
data through adversarial training. Models trained on our scenarios exhibit substantially improved
robustness. This improvement is validated on real-world nuScenes data, where the enhanced models
make demonstrably safer decisions. To bridge the sim-to-real gap, we further validate our approach
with real-world vehicle tests and human driver surveys, which confirm our generated scenarios
represent plausible and critical real-world risks. Our main contributions are:
â€¢ We propose SCENGE, a two-stage framework that generates safety-critical scenarios by
seamlessly combining knowledge-grounded LLM reasoning with multi-agent trajectory
optimization.
â€¢ We introduce two core components: Meta-Scenario Generation, which generates richly
detailed meta-scenarios by grounding an LLMâ€™s reasoning in knowledge priors; Complex
Scenario Evolution, which enhances the resulting threats by optimizing the trajectory of key
background vehicles identified via an Adversarial Collaborator Graph.
â€¢ Extensive experiments conducted on RL-based AV models show the effectiveness of
SCENGE (+31.96% collision rate on average) compared to state-of-the-art baselines.
2
Related Work
Simulation-Based Testing for AV. Simulation-based testing, facilitated by platforms such as CARLA
[8], MetaDrive [18], and LimSim [52], offers a cost-effective and controlled environment for evaluat-
ing AVs under diverse driving conditions. A key advantage is the ability to replicate rare yet critical
scenarios that are impractical or hazardous to test in the real world. This capability for controlled,
repeatable testing is critical for systematically identifying performance vulnerabilities and ultimately
validating the safety of AVs.
2


--- Page 3 ---
Meta-Scenario Generation
Driving Knowledge
Driving
Regulations
Driving
Licensing
Pre-crash
Scenarios
Base Scenario
The ego car is 
driving straight.
Safety-critical Description
The ego is driving straight when a 
pedestrian suddenly rushes out 
from a parked car by the roadside.
# Spawn the adversary !!"# "âˆ—, $âˆ—, %âˆ—, where &âˆ—is 'Pedestrian', 'âˆ—is 'right of IntPt by 
OPT_X_DIST', (âˆ—is 'AdvBehavior'.
AdvAgent = Pedestrian right of IntPt by OPT_X_DIST,
with heading IntSpawnPt.heading + 90 deg,
with behavior AdvBehavior()
behavior AdvBehavior():
do CrossingBehavior(ego, OPT_V, OPT_D) until (distance from self to egoTraj) < OPT_DIST
while True:
take SetWalkingSpeedAction(0)
IntPt = OrientedPoint following roadDirection from EgoPt for OPT_Y_DIST
Executable Simulation Code 
Perturbed Traffic 
Flow
a!"#
a$%&
a'
a(
âˆ—
ðœ'
LLM Reasoning
Background Traffic Flow
t
Agent Selection
Collaborator Search
t
score
ðœÌ‚'âˆ—(ð‘¡'âˆ—âˆ—)
a(
âˆ—
ðœ!
a!"#
a$%&
â€¦
Trajectory Segment Selection
Adversarial Collaborator Graph
a(
Evolve
Black-box Optimization
Perturbed Traffic Flow
Complex Scenario Evolution
Figure 2: Framework overview. Given a simple description of base scenario, SCENGE first performs
Meta-Scenario Generationto generate an executable meta-scenario, grounded in violations of estab-
lished driving knowledge prior. Complex Scenario Evolution then perturbs the trajectories of key
agents within the complex traffic environment to maximize adversarial impact.
Safety-Critical Scenario Generation. The generation of safety-critical scenarios is crucial for
evaluating AV safety, with existing approaches including generative models that learn from real-world
data [6, 43, 42, 39, 9], optimization-based methods that synthesize scenarios via tailored objectives
[4, 49, 3, 54], and semantic-driven methods that incorporate high-level context [14, 62, 50, 51, 61].
More recent works leverage language models for generation from text or logs [19, 60], or enhance
coverage through semantic replay and trajectory compression [47, 10].
However, these approaches primarily focus on single-agent rule violations or replaying observed
patterns, thus failing to reveal novel, compound failure modes. Even recent LLM-based methods,
while improving semantic coverage, still lack fine-grained control over multi-agent interactions.
These limitations motivate SCENGE, our framework that addresses semantic novelty and emergent
risk through structured generation and collaborative perturbation.
3
SCENGE Approach
SCENGE is designed to target AV system failures stemming from explicit rule violations and subtle
multi-agent interactions. An overview is illustrated in Fig. 2.
3.1
Problem Definition
Let Smeta = {aego, aadv | R, L} denote the meta scenario, which includes an ego vehicle aego and
a single adversarial agent aadv operating within an environmental context defined by road type R and
traffic light state L. The adversarial agent is further specified by semantic properties (c, p, b), denoting
its type, position, and behavior. To construct such scenarios, we start from a simple prompt of a benign
scene Î¦base, augmented by a fixed instruction prompt Î¦inst to induce safety-violating behavior. A
retrieval function fR selects relevant entries from a knowledge base D, and the resulting context is
used by an LLM fLLM to produce semantic descriptions âŸ¨Î¦c, Î¦p, Î¦b, Î¦R, Î¦LâŸ©for adversarial agent
and environment properties. These are subsequently parsed into structured values (c, p, b, R, L) and
instantiated to define Smeta.
We define the adversarial scenario as Sadv = Smeta âˆª{a1, . . . , aN}, where N denotes the number
of background vehicles. Each background vehicle ai follows a trajectory Ï„i = {(xt, yt)}T
t=0,
representing its simulated coordinates over T frames, where iâˆˆ{1, . . . , N}. A subset of background
3


--- Page 4 ---
vehicles, indexed by K âŠ‚{1, . . . , N}, is selected for perturbation. Their trajectory segments are
optimized to induce collaborative risky behaviors that increase the threat level of Smeta. Specifically,
for each selected vehicle aiâ‹†with iâ‹†âˆˆK, we identify a keyframe tâ‹†
iâ‹†as the most influential frame,
and define the corresponding perturbable segment ËœÏ„iâ‹†âŠ‚Ï„iâ‹†as a temporal window centered at this
keyframe. These segments are perturbed by optimizing the objective function L, yielding the final
adversarial scenario Sadv with optimized segments {ËœÏ„ â‹†
iâ‹†}iâ‹†âˆˆK.
3.2
Meta-Scenario Generation
Given a simple prompt Î¦base, which typically specifies a normal traffic situation without threats (e.g.,
the ego car is driving across the corner), our goal is to construct a meta-scenario Smeta
in which aadv introduces a safety-critical threat. The process comprises two main components: â¶
constructing a structured driving knowledge base via RAG, and â·generating an executable scenario
description using an LLM informed by that prior.
Safety Driving Knowledge Construction. The knowledge base D = {Dr, Dl, Dc} consists of three
components, each representing a distinct aspect of driving knowledge essential for simulating norma-
tive and adversarial traffic behavior. â¶Dr contains 27 driving regulations segmented from official
manuals in the USA, Germany, and China, covering behaviors such as lane merging, overtaking, and
other maneuvers. â·Dl includes 100 standardized driverâ€™s license test questions and answers that
assess traffic rule knowledge, situational awareness, and safe behavior selection. Together, Dr and
Dl provide normative behavioral priors intentionally violated to construct safety-critical adversarial
behaviors. In contrast, â¸Dc comprises 14 pre-crash scenarios drawn from taxonomies in the NHTSA
Pre-Crash Typology Report [38] (e.g., unprotected left turns, red-light violations), providing concrete
adversarial patterns for scenario construction. Collectively, these components inform the synthesis of
plausible threat scenarios and support the generation of critical adversarial conditions.
LLM-Driven Scenario Generation. Given a simple prompt Î¦base of a benign scene, the LLM is
prompted to generate a detailed, safety-critical scenario by introducing one main adversarial agent
aadv into the scenario. It infers the agentâ€™s properties and the associated environmental context
through in-context learning [7]. However, simply adopting an LLM may lead to unsafe or unrealistic
critical scenarios; thus, we ground the reasoning process in structured driving knowledge. To this
end, relevant knowledge is retrieved from the database D and combined with the instruction prompt
Î¦inst to form the input to the LLM fLLM. The generation process is formalized as:
âŸ¨Î¦c, Î¦p, Î¦b, Î¦R, Î¦LâŸ©= fLLM (aego, Î¦base, fR(D, Î¦base) | Î¦inst) ,
(3.1)
where each Î¦âˆ—represents a text description of a scenario element, including the adversarial agentâ€™s
properties and environmental context. The instruction prompt Î¦inst explicitly guides the model to
generate rule-violating yet plausible actions, grounded in retrieved safety knowledge. Although
expressed in textual form, the generation is controlled through few-shot prompting and slot-based
templates, ensuring the outputs remain structured and scenario-compatible.
The generated descriptions are then parsed into structured values (c, p, b, R, L) and populated into
a predefined Scenic template. This template encodes scenario-level semantics while enforcing
syntactic and physical constraints, bridging language-driven generation and executable simulation.
The resulting program is run in the simulator to instantiate Smeta.
3.3
Complex Scenario Evolution
Building on the generated meta-scenario, Complex Scenario Evolution enhances its complexity by
introducing background vehicles {a1, . . . , aN} with collaborative risky trajectories. To that end, their
interactions with aadv and aego are adjusted to create a more challenging scenario for the AV. This
process comprises two main components: â¶Collaborator Search, which identifies the background
vehicles that can most amplify the adversarial nature of the scenario, and â·Trajectory Perturbation,
which adjusts the selected vehicles to maximize the adversarial impact.
Collaborator Search. To identify influential background vehicles, we construct an Adversarial
Collaborator Graph G, where each node corresponds to an agent in the scenario, and the edges reflect
directional behavioral relevance, particularly emphasizing the impact of background vehicles on the
ego vehicle and adversarial agent. This graph is derived from a frame-wise attention matrix Ma that
4


--- Page 5 ---
models trajectory-level dependencies using ego and adversarial trajectories as queries and background
trajectories as keys. Specifically:
Ma = (Ï„ego, Ï„adv) Â· (Ï„1, . . . , Ï„N)âŠ¤
âˆš
d
+ Mm + log Md,
(3.2)
where d is the dimension of Ï„, Mm enforces causality by preventing attention to future frames, and
Md introduces a temporal decay bias to emphasize recent interactions.
Based on Ma, we perform Collaborator Search in two stages. First, we aggregate attention scores
across frames to estimate each background vehicleâ€™s relevance to the ego vehicle and the adversarial
agent. This process identifies the Top-k most influential vehicles, which form the collaborator set
K. Then, for each iâ‹†âˆˆK, we locate the keyframe tâ‹†
iâ‹†receiving the highest attention score for
vehicle aiâ‹†, and extract a local temporal window ËœÏ„iâ‹†centered at keyframe as its perturbable trajectory
segment. These segments serve as the input to the subsequent trajectory perturbation module.
Trajectory Perturbation. We optimize the perturbable segments {ËœÏ„iâ‹†}iâ‹†âˆˆK of selected collaborators
(indexed by K) to maximize the adversarial impact on the ego vehicle. This is formulated as the
following objective:
{ËœÏ„ â‹†
iâ‹†}iâ‹†âˆˆK = arg max
{ËœÏ„iâ‹†}iâ‹†âˆˆK
L(ËœÏ„ego, ËœÏ„adv, {ËœÏ„iâ‹†}iâ‹†âˆˆK),
(3.3)
The optimization follows an iterative, gradient-based procedure. Specifically, for each perturbable
segment, we compute the gradient of L w.r.t the trajectory coordinates and update them in the
direction that increases the loss. Each update step uses a small, fixed step size and is projected back to
the feasible space to ensure realism. The process continues until convergence or a predefined number
of steps is reached.
L = Î»1 âˆ¥ËœÏ„iâ‹†âˆ’ËœÏ„egoâˆ¥2
|
{z
}
Lego
+Î»2 âˆ¥(ËœÏ„iâ‹†âˆ’ËœÏ„ego) Ã— (ËœÏ„adv âˆ’ËœÏ„ego)âˆ¥âŠ¥
|
{z
}
Locc
+Î»3 âˆ¥âˆ†2ËœÏ„iâ‹†âˆ¥2
2
|
{z
}
Lsmooth
.
(3.4)
The objective function L comprises three components, as shown in Eq. (3.4). â¶Lego minimizes the
Euclidean distance between the perturbed background trajectory ËœÏ„iâ‹†and the ego trajectory ËœÏ„ego within
a temporal window. â·Lsmooth penalizes second-order differences âˆ†2ËœÏ„iâ‹†to reduce abrupt motion
changes. â¸Locc minimizes the normalized perpendicular distance via a 2D cross product, promoting
alignment along the egoâ€“adversary line-of-sight. From a behavioral modeling perspective, Lego
encourages spatial proximity to induce planning hesitation, Lsmooth ensures kinematic feasibility via
smoothness constraints, collectively balancing adversarial strength with physical plausibility, and Locc
amplifies perceptual ambiguity through occlusion. Finally, the optimized perturbations {ËœÏ„ â‹†
iâ‹†}iâ‹†âˆˆK
replace the corresponding segments of the original trajectories, yielding the final adversarial scenario
Sadv, which poses a significant threat to the ego vehicleâ€™s safe driving.
3.4
Overall Generation Workflow
Our workflow begins with the Meta-Scenario Generation module. This module takes a benign text
description as input. First, an LLM generates a detailed textual description of a safety-critical threat.
This generation process is grounded in a structured driving knowledge base. The LLM then translates
this textual description into a parameterized Scenic script. Finally, this script is instantiated within
the CARLA simulator to create the executable meta-scenario.
Next, we process the background traffic for the meta-scenario. We use CARLAâ€™s Traffic Manager to
generate a flow of background vehicles and record their baseline trajectories. The Complex Scenario
Evolution module then analyzes these trajectories offline. It builds an Adversarial Collaborator Graph
to identify the most influential background vehicles to act as collaborators. The module selects critical
segments of their trajectories and optimizes them to maximize the overall threat. This optimization
aims to restrict the ego vehicleâ€™s maneuvering space and create critical occlusions. For the final
evaluation, we replay the complete scenario in a closed-loop simulation. The optimized background
5


--- Page 6 ---
Table 1: Evaluation of adversarial scenario generation methods across CR, and OS metrics.
Performance is assessed on eight base scenarios in CARLA, averaged across PPO, SAC, and TD3
models. Best results are highlighted in bold. Higher CR and lower OS values, indicate better
adversarial effectiveness.
Metric
Algo.
Base Traffic Scenarios
Straight
Obstacle
Turning
Obstacle
Lane
Changing
Vehicle
Passing
Red-light
Running
Unprotected
Left-turn
Right-
turn
Crossing
Negotiation
Avg.
CR â†‘
LC
0.241
0.159
0.736
0.792
0.317
0.325
0.321
0.313
0.401
AS
0.451
0.399
0.726
0.832
0.177
0.335
0.115
0.303
0.417
CS
0.391
0.679
0.756
0.812
0.237
0.325
0.411
0.333
0.493
AT
0.441
0.379
0.646
0.782
0.317
0.315
0.321
0.353
0.440
ChatScene
0.750
0.647
0.660
0.907
0.833
0.620
0.743
0.850
0.751
Ours
0.860
0.773
0.837
0.897
0.823
0.747
0.763
0.863
0.820
OS â†“
LC
0.789
0.816
0.566
0.530
0.799
0.790
0.692
0.717
0.712
AS
0.694
0.687
0.561
0.506
0.866
0.775
0.841
0.721
0.706
CS
0.726
0.552
0.549
0.513
0.839
0.787
0.649
0.708
0.665
AT
0.696
0.706
0.599
0.528
0.805
0.795
0.689
0.698
0.690
ChatScene
0.559
0.572
0.607
0.472
0.544
0.656
0.511
0.459
0.548
Ours
0.503
0.526
0.504
0.457
0.507
0.519
0.498
0.477
0.499
vehicles execute their new adversarial trajectories as scripted events, forcing the ego vehicle to react
to the coordinated, high-risk situation.
4
Experiment and Evaluation
4.1
Experimental Setup
Simulation environment and benchmark. We utilise the CARLA simulator [8], an open-source
and highly customizable urban driving simulator, to create a closed-loop simulation environment.
We adopt SafeBench [55] as the benchmarking framework, which supports diverse RL-based AV
agents and standardized evaluation. Following [58], we use 8 base traffic scenarios (e.g., Straight
Obstacle, Lane Changing) curated from the NHTSA Pre-Crash Typology Report [38], each
containing 10 diverse driving routes. For each route, 10 adversarial scenarios are generated, resulting
in 800 challenging scenarios for evaluation and comparison per method.
AV algorithms. Following [58], we mainly employ 3 representative RL-based AV algorithms as
testing agents, including Proximal Policy Optimization (PPO) [40], Soft Actor-Critic (SAC) [16],
and Twin Delayed Deep Deterministic Policy Gradient (TD3) [13].
Compared baselines. We compare our SCENGE with several existing scenario generation methods,
including Learning-to-Collide (LC) [6], AdvSim (AS) [49], Carla Scenario Generator (CS) [5],
Adversarial Trajectory Optimization (AT) [59], and ChatScene [58]. For fair comparisons, each
method is applied on the same 8 base scenarios and routes to generate 800 challenging scenarios
under consistent generation logic and evaluation settings.
Metrics. Following SafeBench [55], we adopt a set of key metrics to evaluate AV performance in
generated scenarios. Two core indicators are used: the collision rate (CR â†‘) measures the frequency of
collisions and reflects safety risk, and the overall score (OS â†“) aggregates system-level performance.
In addition, we evaluate three additional dimensions: the safety level (frequency of running red lights
(RR â†‘), frequency of running stop signs (SS â†‘), and average distance driven out of road (OR â†‘),
the functionality level (route following stability (RF â†“), average percentage of route completion
(Comp â†“), and average time spent to complete the route (TS â†‘)), and the etiquette level (average
acceleration (ACC â†‘), average yaw velocity (YV â†‘), and frequency of lane invasion (LI â†‘). Higher
(â†‘) values indicate worse performance, while â†“indicates the contrary.
Implementation details. All experiments were conducted on a server with an Intel(R) Core(TM)
i9-14900K CPU and two NVIDIA GeForce RTX 4090 GPUs with 24GB memory. The LLM
used for Meta-Scenario Generationis qwq-32b [46], the reasoning model from the Qwen series.
In the Complex Scenario Evolution module, we construct 10 background vehicles and perturb the
trajectories of 4 selected ones, each over 60% of their trajectory. The 4 perturbed vehicles are selected
6


--- Page 7 ---
based on the highest attention relevance to ego and adversarial agents. The 60% perturbation window
is centered around each vehicleâ€™s most relevant keyframe. We set Î³ in the decay matrix to 0.8. In the
loss calculation, we set Î»1 = 0.3, Î»2 = 0.2, and Î»3 = 0.5.
4.2
Main Results
Our main results, presented in Tab. 1 and Tab. 2, compare SCENGE against baseline methods across
eight base scenarios. To ensure a robust and generalizable evaluation, all metrics are averaged over
three distinct RL agents, as detailed in Sec. 4.1. This approach validates that our scenarios pose a
universal challenge to a range of modern driving policies, rather than merely exploiting agent-specific
flaws. The tables offer complementary views: Tab. 1 details the CR and OS for each individual
scenario, whereas Tab. 2 assesses the overall impact on AV behavior from the three key aspects of
safety and risk exposure, functionality under stress, and driving etiquette, with all results averaged
across the scenarios.
Table 2: Aggregated evaluation results across safety, func-
tionality, and etiquette dimensions. Each value represents
the average over three RL-based AV agents and eight base
scenarios.
Algo.
Safety Level
Functionality Level
Etiquette Level
RR â†‘
SS â†‘
OR â†‘
RF â†“
Comp â†“
TS â†‘
ACC â†‘
YV â†‘
LI â†‘
LC
0.325
0.165
0.039
0.884
0.807
0.224
0.225
0.231
0.087
AS
0.299
0.167
0.032
0.901
0.821
0.269
0.217
0.233
0.102
CS
0.312
0.168
0.043
0.880
0.817
0.252
0.229
0.235
0.106
AT
0.311
0.167
0.035
0.883
0.802
0.287
0.233
0.236
0.112
ChatScene
0.228
0.145
0.018
0.890
0.571
0.074
0.281
0.225
0.064
Ours
0.231
0.125
0.009
0.838
0.472
0.124
0.402
0.359
0.179
Safety and Risk Exposure.
As
shown in Tab. 1, SCENGE achieves
the highest average CR. Notably, this
high collision rate is not achieved by
forcing simplistic rule violations. In
fact, the scores for RR, SS, and OR
are not the highest, as seen in Tab. 2.
This outcome is a direct result of our
design philosophy. We avoid creat-
ing simplistic, predictable setups that
rely on obvious rule violations. In-
stead, SCENGE focuses on generat-
ing high-pressure situations from com-
plex multi-agent interactions. These plausible scenarios challenge the predictive and planning ca-
pabilities under pressure. They force the vehicle to navigate moments where no single, simple rule
applies. Consequently, the resulting collisions expose more profound and subtle vulnerabilities in the
AVâ€™s core logic, rather than surface-level failures in rule compliance.
Functionality Challenges. As shown in Tab. 1, SCENGE achieves the lowest average OS. Addi-
tionally, Tab. 2 shows a 4.96% drop in RF and a 29.16% reduction in Comp. The moderate TS is
caused by early collisions, which demonstrates that SCENGE induces rapid and decisive failures by
persistently disrupting the AVâ€™s planning.
0.76
Collision Rate
0.48
0.54
Overall Score
Best Config
w/o D_r
w/o D_l
w/o D_c
GPT-4o
2 Agents
6 Agents
No Mask
No Decay
Perturb 50%
Perturb 70%
w/o L_ego
w/o L_occ
w/o L_smooth
Module Category
Best Config
Knowledge Prior
LLM
Collaborator Graph
Temporal Modeling
Perturbation Ratio
Loss
Figure 3: Scatter plot of CR â†‘vs. OS â†“across
ablation settings. Each color denotes an ablation
type, and each point represents a specific variant.
Points closer to the bottom-right indicate stronger
adversarial effects.
Driving Etiquette.
As shown in Tab. 2,
SCENGE increases ACC, YV, and LI by 16.5%,
12.7%, and 8.48% respectively. These results
suggest that SCENGE causes AV to behave less
smoothly and more erratically in ways that re-
main socially plausible. Introducing temporally
coordinated perturbations across multiple agents
disrupts fine-grained control and social driving
compliance, revealing limitations that simpler,
single-agent or rule-based methods fail to ex-
pose.
4.3
Ablation Studies
We perform ablation experiments by selectively
disabling key modules and observing the effect
on performance. Otherwise specified, this part
keeps the same setting as the main experiment.
Fig. 3 reports the results under different settings.
â¶Knowledge Prior. Removing Dr yields CR 79.4% and OS 52.3%, reflecting its role in guiding rule-
focused violations. Removing Dl gives CR 77.4% and OS 55.2%, showing its effect on enhancing
7


--- Page 8 ---
logical consistency in behavior. Removing Dc results in CR 80.5% and OS 52.1%, confirming its
importance in producing realistic and high-risk scenarios.
â·LLM. Both GPT-4o and qwq-32b demonstrate strong capabilities, yielding similar CRs of 81.3%
and 82.0%, respectively. This suggests that the performance is not critically sensitive to the specific
choice of a powerful LLM.
â¸Collaborator Graph. We ablate the number of perturbed agents by selecting 2, 4, and 6 collaborators.
Perturbing 4 agents performs best with CR 82% and OS 49.9%, balancing adversarial strength and
scenario plausibility. Interestingly, perturbing 6 agents (CR 78.1%) is less effective than perturbing
2 (CR 80.3%). We hypothesize that this occurs because an excessive number of agents transforms
our intended coordinated, precise threat into easily avoidable chaos. Their mutual interference and
abnormal behavior likely prompt the AV to adopt a conservative policy. This hypothesis is also
supported by OS, where the 6-agent setting yields a higher score (56.1%) compared to the 2-agent
setting (55.1%).
â¹Temporal Modeling. The full setting (with both mask and decay) yields the best result with CR 82%
and OS 49.9%. Removing the temporal mask reduces temporal causality in collaborator selection,
leads to CR 79.3% and OS 55.6%, while removing the temporal decay results in CR 78.2% and OS
57.3%. These results highlight the complementary role of both components in capturing temporally
coherent influence.
âºPerturbation Ratio. We compare three perturbation ratios centered around the selected keyframe:
50%, 60%, and 70%. Perturbing 60% of the segment achieves the best result with CR 82% and OS
49.9%. 50% leads to CR 80.2% and OS 53.4%, indicating insufficient behavioral deviation, while
70% causes CR 81.1% and OS 52.1% due to over-modification and reduced plausibility. These results
shows moderate ratio balances realism and adversarial effect.
â»Loss. We ablate each component in L to assess its contribution. Removing Lego leads to CR
78.6% and OS 55.3%, reflecting reduced collision targeting. Excluding Lsmooth yields CR 80.2% and
OS 54.3%, with trajectories becoming visibly unstable. Removing Locc results in CR 79.4% and
OS 56.8%, indicating weaker alignment between adversary and ego. The full loss yields the best
trade-off, and ablating any term consistently reduces CR and increases OS.
4.4
Generalization Ability Analysis
Table 3: Performance of LMDrive under generated ad-
versarial scenarios across eight base traffic tasks.
Algo.
Benign Scenario
Meta-Scenario
Adversarial Scenario
RC
92.2 Â± 2.9
92.9 Â± 2.7
89.9 Â± 5.1
IS
0.97 Â± 0.01
0.9 Â± 0.05
0.89 Â± 0.04
DS
87.7 Â± 2.4
83.7 Â± 4.7
80.4 Â± 5.5
We study the generalizability of SCENGE:
â¶effectiveness on other AV models; and
â·applicability on other simulators.
Model Generalization. Beyond RL-based
AV models, we further evaluate our gen-
erated scenarios on LMDrive [41], a large
vision-language model for AV deployed on
the CARLA Leaderboard [45]. LMDrive
navigates by following natural language in-
structions sequentially, using the multi-view camera and Lidar perception for scene understanding
and planning. To accommodate its instruction-driven execution mode, we redesign the test routes
into multi-instruction sequences. Evaluation follows LMDriveâ€™s original metrics: Route Completion
(RC), Infraction Score (IS), and Driving Score (DS). We evaluate LMDrive under three increas-
ingly challenging settings: â¶ego-only benign routes as a baseline, â·meta-scenarios with a single
adversarial agent, and â¸full adversarial scenarios generated by our framework, including the per-
turbed background vehicle. As shown in Tab. 3, LMDriveâ€™s performance drops from 87.7 DS in the
benign case to 83.7 in meta-scenarios and further to 80.4 under full adversarial conditions. These
results demonstrate that our generated scenarios significantly stress LMDriveâ€™s planning capability,
especially under rare or occluded interactions.
Simulator Generalization. We validated the generalizability of SCENGE in MetaDrive [18] sim-
ulator, a lightweight platform for RL research. Despite substantial differences in rendering and
physics, SCENGEâ€™s modular design facilitated a successful port. As shown in Fig. 4, our framework
successfully generated effective safety-critical scenarios that induced high CR in MetaDrive. This
result demonstrates the broad applicability of our approach.
8


--- Page 9 ---
4.5
Training on the Generated Scenarios
Figure 4: Applicability of SCENGE on MetaDrive simulator.
This section evaluates the utility of
our SCENGE in enhancing AV robust-
ness by adversarial training on the gen-
erated scenarios. Specifically, we eval-
uate the robustified RL agent on both
simulated data and real-world data.
Robustness evaluation in simula-
tion. We adversarially train the SAC-
based ego vehicle across eight base
traffic scenarios using scenes from
the first eight routes per scenario, and
evaluate on unseen scenes from the remaining two routes. The training process uses 500 epochs
with a learning rate of 0.0001. As shown in Tab. 4, adversarial training with SCENGE-generated
scenarios yields the best results among methods, reducing the CR by 3.1% while increasing the OS
by 94.7%. These results demonstrate that our method generates scenarios missing from standard AV
training. Adversarial training on these data remedies the AV vulnerabilities, leading to a significant
improvement in robustness.
Table 4: Evaluation of adversarially trained ego vehicle.
Metric
LC
AS
CS
AT
ChatScene
Ours
CR â†‘
0.210
0.216
0.176
0.135
0.043
0.031
OS â†“
0.813
0.806
0.825
0.864
0.905
0.947
Robustness
evaluation
on
real-
world data. We further evaluated our
adversarially trained model on real-
world data from the nuScenes dataset
[1] to address the visual domain gap
between simulation and reality. In par-
ticular, we first manually select 140
scenario segments (2700 images) with
latent risks, such as a pedestrian standing by the roadside; subsequently, we evaluate both the original
RL model and the enhanced model on these real-world image sequences. The enhanced model
achieved a 21.7% lower Euclidean distance to the ground truth trajectory than the original model,
indicating safer and more stable decisions. This result demonstrates that the robustness gained from
our scenarios transfers effectively to real-world perception data.
4.6
Real-world Experiments
Benign Scenario
Background Traffic
Adversary
Risky Scenario First-view
Risky Scenario Side-view
Risky Scenario Rear-view
Figure 5: Real-World Experiments.
Here, we conducted real-world ex-
periments in a closed road, where
we arranged a layout that is similar
to our generated scenario and tested
a real-world vehicle (Fig. 5).
Due
to commercial confidentiality, the ap-
pearance of our test vehicle has been
obscured. Under strict safety proto-
cols, we recreated and repeated two
challenging scenarios 15 times each:
a pedestrian suddenly emerging from
an occlusion, and an unprotected left-
turn challenged by an accelerating
scooter. Despite safety measures de-
signed to lower the scenariosâ€™ diffi-
culty (e.g., limiting vehicle speed),
the AV exhibited critical failures. In
73.3% of the pedestrian tests, the vehicle failed to react to the pedestrianâ€™s emergence in a timely
manner. Similarly, in 60% of the left-turn tests, it failed to alter its trajectory to avoid the conflicting
scooter, exposing a decisive vulnerability. These results provide definitive, physical-world evidence
that our generated scenarios identify physical risks for autonomous systems, not just simulation
artifacts.
9


--- Page 10 ---
1
2
3
4
5
6
7
8
Base Scenario
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Results
Safety-OS
Task-OS
Comfort-OS
(a) Metric scores of the SAC-based ego vehicle across
8 adversarial scenarios.
BEV
First-view
(b) Representative frames highlight how the agents are
jointly leading to a collision.
Figure 6: Model performance and case visualization.
4.7
Discussion and Analysis
Computational Cost. We compare the per-scenario generation cost of SCENGE against the baselines
in Sec. 4.1. When generating in batches (e.g., 5 Scenic scripts, each instantiating 20 variations), our
framework averages approximately 0.024 GPU hours per scenario. In contrast, AS requires 0.06
GPU hours, AT needs 0.13 GPU hours, and LC takes 0.17 GPU hours. Our approach thus reduces
the required generation time by 60% compared to AS, 81.5% compared to AT, and 85.9% compared
to LC. Furthermore, methods like CS and ChatScene are bottlenecked by non-scalable expert effort.
This demonstrates SCENGEâ€™s superior efficiency and scalability for large-scale AV testing.
Human Evaluation. We conducted a human study with 30 licensed drivers to assess the real-world
plausibility and perceived danger of our generated scenarios. In the study, participants viewed 40
unique videos and rated them using a 5-point scale. The survey covered all eight base scenarios
used in our experiments, with five distinct variations selected for each. To mitigate order effects and
learning biases, the videos were presented in a fully randomized sequence. An analysis of 1,200
responses revealed high average scores for both plausibility (4.765 out of 5) and perceived risk (4.934
out of 5). This confirms that human drivers consider the scenarios to be both highly realistic and
critically dangerous.
Case Study. As shown in Fig. 6a, we evaluate the SAC-based ego vehicle across three composite
metrics: safety, task completion, and comfort. These metrics summarize AV behavior by aggregating
relevant low-level indicators. We select Scenario 1 for detailed analysis because its scores lie near the
median across all three dimensions, making it a representative failure case. In Fig. 6b, we show some
frames from the final adversarial scenario. This scenario involves a pedestrian emerging from an
occlusion. The threat is amplified by background vehicles: one occupies the adjacent lane to restrict
maneuvering space (a behavior promoted by Lego), while another obstructs the line-of-sight to the
adversary (guided by Locc). These compounded interactions prevent the ego vehicle from executing a
safe evasive action. This case effectively illustrates how SCENGE uses subtle, coordinated behaviors
of background traffic to expose critical AV vulnerabilities.
5
Conclusion and Future Work
In this paper, we introduce SCENGE, a two-stage framework for generating safety-critical scenarios
to expose vulnerabilities in AV. From a benign scene description, SCENGE introduces Meta-Scenario
Generation and Complex Scenario Evolution to generate scenarios that are more likely to cause
failures. Experiments on multiple RL-based AV models show that SCENGE reveals more severe
collision cases. Future work: A primary direction is to collaborate with automotive manufacturers,
integrating our SCENGE to evaluate the safety of their proprietary, real-world AV algorithms and
systems.
10


--- Page 11 ---
References
[1] Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu,
Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuscenes: A multimodal
dataset for autonomous driving. In Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition, pages 11621â€“11631, 2020.
[2] Xuan Cai, Xuesong Bai, Zhiyong Cui, Danmu Xie, Daocheng Fu, Haiyang Yu, and Yilong Ren.
Text2scenario: Text-driven scenario generation for autonomous driving test. arXiv preprint
arXiv:2503.02911, 2025.
[3] Yulong Cao, Chaowei Xiao, Anima Anandkumar, Danfei Xu, and Marco Pavone. Advdo:
Realistic adversarial attacks for trajectory prediction. In European Conference on Computer
Vision, pages 36â€“52. Springer, 2022.
[4] Baiming Chen, Xiang Chen, Qiong Wu, and Liang Li. Adversarial evaluation of autonomous
vehicles in lane-change scenarios. IEEE transactions on intelligent transportation systems,
23(8):10333â€“10342, 2021.
[5] Scenario Runner Contributors.
Carla Scenario Runner.
https://github.com/
carla-simulator/scenario_runner, 2019.
[6] Wenhao Ding, Baiming Chen, Minjun Xu, and Ding Zhao. Learning to collide: An adaptive
safety-critical scenarios generating method. In 2020 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS), pages 2243â€“2250. IEEE, 2020.
[7] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan Ma, Rui Li, Heming Xia, Jingjing
Xu, Zhiyong Wu, Tianyu Liu, Baobao Chang, Xu Sun, Lei Li, and Zhifang Sui. A survey
on in-context learning. In Proceedings of the 2024 Conference on Empirical Methods in
Natural Language Processing, pages 1107â€“1128, Miami, Florida, USA, 2024. Association for
Computational Linguistics.
[8] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen Koltun.
CARLA: An open urban driving simulator. In Proceedings of the 1st Annual Conference on
Robot Learning, pages 1â€“16, 2017.
[9] Lan Feng, Quanyi Li, Zhenghao Peng, Shuhan Tan, and Bolei Zhou. Trafficgen: Learning
to generate diverse and realistic traffic scenarios. In 2023 IEEE international conference on
robotics and automation (ICRA), pages 3567â€“3575. IEEE, 2023.
[10] Shuo Feng, Haowei Sun, Xintao Yan, Haojie Zhu, Zhengxia Zou, Shengyin Shen, and Henry X
Liu. Dense reinforcement learning for safety validation of autonomous vehicles. Nature,
615(7953):620â€“627, 2023.
[11] Daniel J Fremont, Tommaso Dreossi, Shromona Ghosh, Xiangyu Yue, Alberto L Sangiovanni-
Vincentelli, and Sanjit A Seshia. Scenic: a language for scenario specification and scene
generation. In Proceedings of the 40th ACM SIGPLAN Conference on Programming Language
Design and Implementation, pages 63â€“78, 2019.
[12] Daniel J Fremont, Edward Kim, Tommaso Dreossi, Shromona Ghosh, Xiangyu Yue, Alberto L
Sangiovanni-Vincentelli, and Sanjit A Seshia. Scenic: A language for scenario specification
and data generation. Machine Learning, pages 1â€“45, 2022.
[13] Scott Fujimoto, Herke van Hoof, and David Meger. Addressing function approximation error in
actor-critic methods. In Proceedings of the 35th International Conference on Machine Learning,
volume 80, pages 1587â€“1596, 2018.
[14] Ruiyuan Gao, Kai Chen, Enze Xie, Lanqing Hong, Zhenguo Li, Dit-Yan Yeung, and Qiang
Xu. MagicDrive: Street view generation with diverse 3d geometry control. In International
Conference on Learning Representations, 2024.
[15] Jun Guo, Wei Bao, Jiakai Wang, Yuqing Ma, Xinghai Gao, Gang Xiao, Aishan Liu, Jian Dong,
Xianglong Liu, and Wenjun Wu. A comprehensive evaluation framework for deep model
robustness. Pattern Recognition, 2023.
11


--- Page 12 ---
[16] Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. Soft actor-critic: Off-policy
maximum entropy deep reinforcement learning with a stochastic actor. In Proceedings of the
35th International Conference on Machine Learning, volume 80, pages 1861â€“1870, 2018.
[17] Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima, Xizhou Zhu, Siqi Chai, Senyao
Du, Tianwei Lin, Wenhai Wang, Lewei Lu, Xiaosong Jia, Qiang Liu, Jifeng Dai, Yu Qiao,
and Hongyang Li. Planning-oriented autonomous driving. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, 2023.
[18] Quanyi Li, Zhenghao Peng, Zhenghai Xue, Qihang Zhang, and Bolei Zhou. Metadrive: Com-
posing diverse driving scenarios for generalizable reinforcement learning. arXiv preprint
arXiv:2109.12674, 2021.
[19] Shuyang Li, Talha Azfar, and Ruimin Ke. Chatsumo: Large language model for automating
traffic scenario generation in simulation of urban mobility. IEEE Transactions on Intelligent
Vehicles, 2024.
[20] Zhiqi Li, Wenhai Wang, Hongyang Li, Enze Xie, Chonghao Sima, Tong Lu, Yu Qiao, and
Jifeng Dai. Bevformer: Learning birdâ€™s-eye-view representation from multi-camera images
via spatiotemporal transformers. In European Conference on Computer Vision, pages 36â€“52.
Springer, 2022.
[21] Siyuan Liang, Longkang Li, Yanbo Fan, Xiaojun Jia, Jingzhi Li, Baoyuan Wu, and Xiaochun
Cao. A large-scale multiple-objective method for black-box attack against object detection. In
European Conference on Computer Vision, 2022.
[22] Siyuan Liang, Jiawei Liang, Tianyu Pang, Chao Du, Aishan Liu, Mingli Zhu, Xiaochun Cao,
and Dacheng Tao. Revisiting backdoor attacks against large vision-language models from
domain shift. In Proceedings of the Computer Vision and Pattern Recognition Conference,
pages 9477â€“9486, 2025.
[23] Siyuan Liang, Wei Wang, Ruoyu Chen, Aishan Liu, Boxi Wu, Ee-Chien Chang, Xiaochun Cao,
and Dacheng Tao. Object detectors in the open environment: Challenges, solutions, and outlook.
arXiv preprint arXiv:2403.16271, 2024.
[24] Siyuan Liang, Xingxing Wei, Siyuan Yao, and Xiaochun Cao. Efficient adversarial attacks for
visual object tracking. In Computer Visionâ€“ECCV 2020: 16th European Conference, Glasgow,
UK, August 23â€“28, 2020, Proceedings, Part XXVI 16, 2020.
[25] Siyuan Liang, Baoyuan Wu, Yanbo Fan, Xingxing Wei, and Xiaochun Cao. Parallel rect-
angle flip attack: A query-based black-box attack against object detection. arXiv preprint
arXiv:2201.08970, 2022.
[26] Siyuan Liang, Mingli Zhu, Aishan Liu, Baoyuan Wu, Xiaochun Cao, and Ee-Chien Chang.
Badclip: Dual-embedding guided backdoor attack on multimodal contrastive learning. arXiv
preprint arXiv:2311.12075, 2023.
[27] Aishan Liu, Jun Guo, Jiakai Wang, Siyuan Liang, Renshuai Tao, Wenbo Zhou, Cong Liu,
Xianglong Liu, and Dacheng Tao. X-adv: Physical adversarial object attacks against x-ray
prohibited item detection. In USENIX Security Symposium, 2023.
[28] Aishan Liu, Tairan Huang, Xianglong Liu, Yitao Xu, Yuqing Ma, Xinyun Chen, Stephen J
Maybank, and Dacheng Tao. Spatiotemporal attacks for embodied agents. In ECCV, 2020.
[29] Aishan Liu, Xianglong Liu, Jiaxin Fan, Yuqing Ma, Anlan Zhang, Huiyuan Xie, and Dacheng
Tao. Perceptual-sensitive gan for generating adversarial patches. In AAAI, 2019.
[30] Aishan Liu, Xianglong Liu, Hang Yu, Chongzhi Zhang, Qiang Liu, and Dacheng Tao. Training
robust deep neural networks via adversarial noise propagation. TIP, 2021.
[31] Aishan Liu, Shiyu Tang, Xinyun Chen, Lei Huang, Haotong Qin, Xianglong Liu, and Dacheng
Tao. Towards defending multiple lp-norm bounded adversarial perturbations via gated batch
normalization. International Journal of Computer Vision, 2023.
12


--- Page 13 ---
[32] Aishan Liu, Shiyu Tang, Siyuan Liang, Ruihao Gong, Boxi Wu, Xianglong Liu, and Dacheng
Tao. Exploring the relationship between architecture and adversarially robust generalization. In
CVPR, 2023.
[33] Aishan Liu, Jiakai Wang, Xianglong Liu, Bowen Cao, Chongzhi Zhang, and Hang Yu. Bias-
based universal adversarial patch attack for automatic check-out. In ECCV, 2020.
[34] Ming Liu, Siyuan Liang, Koushik Howlader, Liwen Wang, Dacheng Tao, and Wensheng Zhang.
Natural reflection backdoor attack on vision language model for autonomous driving. arXiv
preprint arXiv:2505.06413, 2025.
[35] Shunchang Liu, Jiakai Wang, Aishan Liu, Yingwei Li, Yijie Gao, Xianglong Liu, and Dacheng
Tao. Harnessing perceptual adversarial patches for crowd counting. In ACM CCS, 2022.
[36] Qiujing Lu, Xuanhan Wang, Yiwei Jiang, Guangming Zhao, Mingyue Ma, and Shuo Feng.
Multimodal large language model driven scenario testing for autonomous vehicles. arXiv
preprint arXiv:2409.06450, 2024.
[37] Yingzi Ma, Yulong Cao, Jiachen Sun, Marco Pavone, and Chaowei Xiao. Dolphins: Multimodal
language model for driving. In European Conference on Computer Vision, pages 403â€“420.
Springer, 2024.
[38] Wassim G Najm, John D Smith, Mikio Yanagisawa, et al. Pre-crash scenario typology for
crash avoidance research. Technical report, United States. National Highway Traffic Safety
Administration, 2007.
[39] Davis Rempe, Jonah Philion, Leonidas J Guibas, Sanja Fidler, and Or Litany. Generating useful
accident-prone driving scenarios via a learned traffic prior. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pages 17305â€“17315, 2022.
[40] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal
policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.
[41] Hao Shao, Yuxuan Hu, Letian Wang, Guanglu Song, Steven L Waslander, Yu Liu, and Hong-
sheng Li. Lmdrive: Closed-loop end-to-end driving with large language models. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 15120â€“15130,
2024.
[42] Simon Suo, Sebastian Regalado, Sergio Casas, and Raquel Urtasun. Trafficsim: Learning
to simulate realistic multi-agent behaviors. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pages 10400â€“10409, 2021.
[43] Shuhan Tan, Kelvin Wong, Shenlong Wang, Sivabalan Manivasagam, Mengye Ren, and Raquel
Urtasun. Scenegen: Learning to generate realistic traffic scenes. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition, pages 892â€“901, 2021.
[44] Shiyu Tang, Ruihao Gong, Yan Wang, Aishan Liu, Jiakai Wang, Xinyun Chen, Fengwei
Yu, Xianglong Liu, Dawn Song, Alan Yuille, et al. Robustart: Benchmarking robustness on
architecture design and training techniques. ArXiv, 2021.
[45] CARLA team. Carla autonomous driving leaderboard. https://leaderboard.carla.org/,
2020. Accessed: 2021-02-11.
[46] Qwen Team. Qwq-32b: Embracing the power of reinforcement learning, March 2025.
[47] Haoxiang Tian, Xingshuo Han, Guoquan Wu, Yuan Zhou, Shuo Li, Jun Wei, Dan Ye, Wei Wang,
and Tianwei Zhang. Lmm-enhanced safety-critical scenario generation for autonomous driving
system testing from non-accident traffic videos. arXiv preprint arXiv:2406.10857, 2024.
[48] Jiakai Wang, Aishan Liu, Zixin Yin, Shunchang Liu, Shiyu Tang, and Xianglong Liu. Dual
attention suppression attack: Generate adversarial camouflage in physical world. In CVPR,
2021.
13


--- Page 14 ---
[49] Jingkang Wang, Ava Pun, James Tu, Sivabalan Manivasagam, Abbas Sadat, Sergio Casas,
Mengye Ren, and Raquel Urtasun. Advsim: Generating safety-critical scenarios for self-
driving vehicles. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pages 9909â€“9918, 2021.
[50] Xiaofeng Wang, Zheng Zhu, Guan Huang, Xinze Chen, Jiagang Zhu, and Jiwen Lu. Drive-
dreamer: Towards real-world-drive world models for autonomous driving. In European Confer-
ence on Computer Vision, pages 55â€“72. Springer, 2024.
[51] Yuqi Wang, Jiawei He, Lue Fan, Hongxin Li, Yuntao Chen, and Zhaoxiang Zhang. Driving into
the future: Multiview visual forecasting and planning with world model for autonomous driving.
In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
pages 14749â€“14759, 2024.
[52] Licheng Wen, Daocheng Fu, Song Mao, Pinlong Cai, Min Dou, Yikang Li, and Yu Qiao. Limsim:
A long-term interactive multi-scenario traffic simulator. In 2023 IEEE 26th International
Conference on Intelligent Transportation Systems (ITSC), pages 1255â€“1262. IEEE, 2023.
[53] Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang,
Xue Liu, Tei-Wei Kuo, Nan Guan, et al. Retrieval-augmented generation for natural language
processing: A survey. arXiv preprint arXiv:2407.13193, 2024.
[54] Hao Xiang, Runsheng Xu, Xin Xia, Zhaoliang Zheng, Bolei Zhou, and Jiaqi Ma. V2xp-asg:
Generating adversarial scenes for vehicle-to-everything perception. In 2023 IEEE International
Conference on Robotics and Automation (ICRA), pages 3584â€“3591. IEEE, 2023.
[55] Chejian Xu, Wenhao Ding, Weijie Lyu, Zuxin Liu, Shuai Wang, Yihan He, Hanjiang Hu, Ding
Zhao, and Bo Li. Safebench: A benchmarking platform for safety evaluation of autonomous
vehicles. Advances in Neural Information Processing Systems, 35:25667â€“25682, 2022.
[56] Chejian Xu, Aleksandr Petiushko, Ding Zhao, and Bo Li. Diffscene: Diffusion-based safety-
critical scenario generation for autonomous vehicles. In Proceedings of the AAAI Conference
on Artificial Intelligence, volume 39, pages 8797â€“8805, 2025.
[57] Chongzhi Zhang, Aishan Liu, Xianglong Liu, Yitao Xu, Hang Yu, Yuqing Ma, and Tianlin
Li. Interpreting and improving adversarial robustness of deep neural networks with neuron
sensitivity. IEEE Transactions on Image Processing, 2021.
[58] Jiawei Zhang, Chejian Xu, and Bo Li. Chatscene: Knowledge-enabled safety-critical scenario
generation for autonomous vehicles. In Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pages 15459â€“15469, 2024.
[59] Qingzhao Zhang, Shengtuo Hu, Jiachen Sun, Qi Alfred Chen, and Z Morley Mao. On adversarial
robustness of trajectory prediction for autonomous vehicles. arXiv preprint arXiv:2201.05057,
2022.
[60] Yongqi Zhao, Wenbo Xiao, Tomislav Mihalj, Jia Hu, and Arno Eichberger. Chat2scenario:
Scenario extraction from dataset through utilization of large language model. In 2024 IEEE
Intelligent Vehicles Symposium (IV), pages 559â€“566. IEEE, 2024.
[61] Wenzhao Zheng, Weiliang Chen, Yuanhui Huang, Borui Zhang, Yueqi Duan, and Jiwen Lu.
Occworld: Learning a 3d occupancy world model for autonomous driving. In European
Conference on Computer Vision, pages 55â€“72. Springer, 2025.
[62] Ziyuan Zhong, Davis Rempe, Yuxiao Chen, Boris Ivanovic, Yulong Cao, Danfei Xu, Marco
Pavone, and Baishakhi Ray. Language-guided traffic simulation via scene-level diffusion. In
Conference on Robot Learning, pages 144â€“177. PMLR, 2023.
14
