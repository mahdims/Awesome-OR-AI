--- Page 1 ---
arXiv:2506.23924v1  [cs.AI]  30 Jun 2025
Performance of LLMs on Stochastic Modeling Operations
Research Problems: From Theory to Practice
Akshit Kumar, Tianyi Peng, Yuhang Wu, and Assaf Zeevi
Columbia Business School, Columbia University
This version: July 1, 2025
Abstract
Large language models (LLMs) have exhibited expert-level capabilities across various do-
mains. However, their abilities to solve problems in Operations Research (OR)—the analysis
and optimization of mathematical models derived from real-world problems or their verbal
descriptions—remain underexplored. In this work, we take a first step toward evaluating LLMs’
abilities to solve stochastic modeling problems, a core class of OR problems characterized by
uncertainty and typically involving tools from probability, statistics, and stochastic processes.
We manually procure a representative set of graduate-level homework and doctoral qualification-
exam problems and test LLMs’ abilities to solve them. We further leverage SimOpt, an open-
source library of simulation-optimization problems and solvers, to investigate LLMs’ abilities
to make real-world decisions under uncertainty.
Our results show that, though a nontrivial
amount of work is still needed to reliably automate the stochastic modeling pipeline in reality,
state-of-the-art LLMs demonstrate proficiency on par with human experts in both classroom
and practical settings. These findings highlight the potential of building AI agents that assist
OR researchers and amplify the real-world impact of OR through automation.
Keywords: Large language models, Automated problem solving, Research agents, Stochastic mod-
eling, Simulation optimization, Education with AI tools
1
INTRODUCTION
Large language models (LLMs) have showcased stunning capabilities across a wide spectrum of
tasks, from writing code and solving mathematical problems to understanding subtle context and
simulating human behavior. These breakthroughs have sparked a wave of innovation in autonomous
AI agents that can interact with dynamic environments and tackle complex decision-making tasks
(Shinn et al. (2023); Schick et al. (2023); Yao et al. (2023); see also Manus AI, Cursor Agent,
and Claude Code). As LLMs and agentic systems rapidly advance, the Operations Research (OR)
community faces an exciting opportunity: to harness these tools for automating core workflows,
accelerating discovery, and ultimately amplifying the reach and impact of OR in the real world.
As a field, OR is fundamentally concerned with decision-making through mathematical model-
ing. After all, the real world is full of complexity, but by encoding that complexity into mathematical
form, we gain a powerful language that liberates us from ad hoc reasoning and enables rigorous anal-
ysis and computational approaches for solving real-world problems. A typical OR pipeline begins
with identifying and abstracting real-world challenges—often encountered by industry stakeholders
and policy-makers—into a mathematical representation capturing essential data, objectives, and
1


--- Page 2 ---
constraints. This representation undergoes analysis, simulation, and optimization, to yield action-
able insights and viable solutions, subject to iterative refinement and practical validation prior
to deployment (see Figure 1). This comprehensive, principled approach has effectively addressed
numerous complex real-world issues, including those in supply chain management, transportation,
finance, retail, healthcare, and online platforms. A strong endorsement of this pipeline’s success is
the INFORMS Franz Edelman Award, which have delivered over $419 billion in cumulative benefits
(INFORMS, 2025).
But this pipeline does not come without cost. The OR workflow often requires researchers to
continuously refine models, carefully balancing analytical tractability with practical relevance, with
the guiding principle that all models are wrong, but some are more useful than others. This iterative
process demands profound domain expertise and technical proficiency. After identifying a solution,
researchers need to work with the stakeholders for testing and deployment and possibly circle back
to earlier stages to revise and improve the model.
All these steps are highly non-trivial, time-
consuming, and can be both an art and a science. The whole procedure can take years. Therefore,
we believe developing specialized OR agents that can assist researchers to automate this pipeline
could unlock significant productivity gains and transformative impacts.
Real-world
Problem
Industry Stakeholders,
Policy-makers, ...
Abstraction
& Modeling
Analysis &
Optimization
Testing &
Deployment
Iterate
OR Researcher
Collaboration
& Feedback
Figure 1: The standard pipeline of OR. Automating this pipeline with AI agents may significantly enhance
the power of OR and amplify its real-world impact.
1.1
Deterministic Optimization vs Stochastic Modeling
Recently, the OR community has begun to explore this direction with an emphasis on automat-
ing deterministic optimization problems (Ramamonjison et al., 2022; AhmadiTeshnizi et al., 2024;
Huang et al., 2025; Zhang and Luo, 2025). As a central pillar of OR, optimization problems have a
wide range of real-world applications, and the ability to properly formulate and solve them is a key
skill for OR practitioners. In contrast, the evaluation of LLMs’ ability to handle stochastic model-
ing problems, another pillar of OR, has been mostly absent in the literature. Stochastic modeling
problems cast the decision-making process in a framework of uncertainty, which is inherent to many
practical problems. Compared to optimization in a deterministic scenario, decision-making with un-
certainty is intrinsically harder because a “good” decision has to work for a range of possible outcomes
that are often unpredictable and may only be tractable en masse through an often unknown prob-
ability distribution. Consequently, stochastic modeling employs fundamentally different analytical
and numerical methods—such as stochastic processes and simulation-based optimization—distinct
from deterministic optimization methods (e.g., convex analysis and gradient-based algorithms). See
2


--- Page 3 ---
Figure 2 for a comparison between deterministic optimization and simulation-optimization.1
Decision variable x
Closed-form objective and
constraints f(x), g(x)
Optimizer (e.g.,
Gurobi, cvxpy)
Optimal solution x∗
Deterministic Optimization
Decision variable x
Simulator
Estimated objective and
constraints ˆf(x) and ˆg(x)
Optimizer (e.g., Random
search, Nelder-Mead)
iterate
Simulation-Optimization
Figure 2: Comparison of conventional deterministic optimization with simulation-optimization. In deter-
ministic setting, the objective f(x) and the constraints g(x) are known closed-form functions, enabling a
direct call to an optimizer. In simulation-optimization, the performance of a decision x is observed through a
stochastic simulator, producing noisy estimates of the objective and constraints ˆf(x) and ˆg(x) that must be
re-sampled until estimation error is acceptable. The optimizer then usually selects a new candidate decision
variable based on the estimated performance of the current decision variable. This process therefore operates
in a loop, trading off additional replications (to reduce estimation error) and searching unexplored promising
regions.
As an example, consider the Chess Matchmaking problem (detailed in Section 5.2 and Appendix
C). Players, whose Elo scores2 follow some probability distribution, arrive at the platform according
to some random process, and two players are matched if their Elo difference is below some pre-
determined threshold (i.e., the policy), while the average waiting time of the players should not
exceed a specified threshold. This may seem to be a straightforward online matching problem, but
there is no known analytical solution, and one must resort to numerical solutions, where the choice
of simulation-optimization solver is crucial. As illustrated by this example, the complexity of a
stochastic modeling problem scales up quickly as multiple sources of randomness become entangled,
and a real-world problem can easily become overly challenging. Another perhaps more well-known
class of complex stochastic modeling problems are stochastic processing networks (Dai and Harrison,
2020), notoriously challenging and often lacking general analytical solutions. Developing robust,
general-purpose numerical solutions remains a significant research challenge. Therefore, in parallel
to the effort of automating the deterministic optimization pipeline, we believe the automation of
the stochastic modeling pipeline is equally important and introduces unique challenges.
1A branch of OR known as robust optimization (Bertsimas et al., 2011) explicitly incorporates uncertainty into
otherwise deterministic optimization formulations. Evaluating LLMs on their ability to understand and apply such
techniques is also an interesting direction, which we leave for future exploration.
2A score that measures the relative skill levels of players.
3


--- Page 4 ---
1.2
This work
In this work, we take the first step towards building OR agents for assisting the stochastic modeling
pipeline by focusing on moving from “Abstraction & Modeling” to the “Analysis & Optimization”
step in Figure 1. In particular, we aim to assess LLMs’ capacities to solve formulated stochastic
modeling problems in a real-world context, addressing both theoretical comprehension and practical
numerical execution (see examples in the subsequent sections).
We view the ability to solve a
formulated problem in the stochastic modeling context as a core skill for assisting OR researchers
and is a necessary step towards automating the entire pipeline.
We also recognize that supporting the transition from an industry-level “Real-world Problem” to
the appropriate “Abstraction & Modeling,” as well as facilitating the iterative collaboration between
OR researchers and industry stakeholders, presents a unique challenging task for LLMs insofar as
solving OR problems. Addressing this may require substantial research effort, and even designing
a rigorous evaluation is highly non-trivial. While we view this as a promising direction for future
work, in this paper we focus our attention on the “Analysis & Optimization” stage, where evaluation
is more tractable.
Specifically, we evaluate LLM performance on two classes of stochastic modeling problems:
• Homework and exam problems. These problems are designed to educate and assess stu-
dents’ understanding of how to analyze a model. Students are expected to reason about the
model’s theoretical properties and grasp the characteristics of a policy that can achieve desirable
performance.
• Simulation-optimization problems. These problems are meant to mimic real-world prob-
lems that often require numerical methods. Students are expected to design and implement an
algorithm to simulate the model and optimize policy decisions accordingly.
Our key contributions and findings are as follows:
1. We construct a dataset of graduate-level stochastic modeling problems to test LLMs’ abilities
to solve them. We find strong performance overall with more open-ended modeling problems
presenting a greater challenge.
2. We procure a set of qualification-exam problems and manually grade LLMs’ answers to them.
Our results show that they demonstrate comparable performance to human PhD candidates in
the field.
3. Using the SimOpt library, we show that top-performing LLMs can match the best in-house solvers
on a range of simulation-optimization problems, underscoring their potential. However, our results
also indicate that off-the-shelf use of LLMs is not yet reliable for automating the full stochastic
modeling pipeline, suggesting the need for further adaptation and integration.
In summary, our findings demonstrate that LLMs hold significant promise across stochastic modeling
tasks—from analytical problem solving to simulation optimization—but realizing reliable end-to-end
automation will require targeted refinement beyond off-the-shelf use. We hope this work encourages
further research on automating stochastic modeling and contributes to building intelligent agents
capable of autonomously understanding, modeling, and solving complex real-world problems.
The rest of the paper is organized as follows. In Section 2, we review the related literature. In
Section 3, we evaluate LLMs’ performance on the homework problems dataset. In Section 4, we
assess LLMs’ performance on the qualifying exam problems. In Section 5, we discuss the simulation-
optimization problems and compare LLMs’ solutions with standard solvers. Finally, in Section 6,
we conclude the paper and discuss future directions.
4


--- Page 5 ---
2
LITERATURE REVIEW
LLMs have long been tested for their ability to solve math problems. GPT-3 was one of the first
large-scale generative models to demonstrate strong zero-shot and few-shot capabilities across many
tasks, including simple mathematical problems (Brown et al., 2020). Soon after, Hendrycks et al.
(2021) introduced the MATH dataset, which consists of over 12,500 competition-level math problems
covering algebra, geometry, number theory, and more, emulating the difficulty of middle and high-
school math competitions. Concurrently, Cobbe et al. (2021) released the GSM8K dataset that
contains over 8,000 short-answer math word problems (grade-school level) focusing on arithmetic
and multi-step reasoning. They also proposed a “verifier” model trained to check correctness of
solutions.
MATH and GSM8K datasets became widely used benchmarks to test reasoning and
multi-step solution correctness. Many later papers used them as primary testbed, including the
renowned chain-of-thought paper (Wei et al., 2023) and subsequent papers on LLM reasoning.
Clearly, these math-exam-style problems cannot adequately test LLMs’ abilities to solve complex
modeling problems.
One direction that is more specialized and more challenging is applying LLMs to the stricter
setting of formal logic and automated theorem proving (ATP). Unlike natural language math so-
lutions, where partial correctness is sometimes acceptable, formal theorem proving requires exact
logical derivations. Small mistakes are not tolerated by the proof checker. Early works on neural
theorem proving started almost a decade ago (Rocktäschel and Riedel, 2017; Kaliszyk et al., 2017;
Bansal et al., 2019; Yang and Deng, 2019) and typical theorem proving environments include Lean,
Coq, Isabelle, and Mizar. They laid the groundwork for using general-purpose LLMs for theorem
proving (Polu and Sutskever, 2020; Zheng et al., 2022; Jiang et al., 2022; Yang et al., 2023). Many
challenges remain in this direction. For example, high-quality proof corpora are relatively small
compared to internet-scale text. Theorem proofs can also be very long and even large LMs can
hallucinate or lose track of intermediate states. See Glazer et al. (2024) for an example of scenarios
where LLMs can still struggle. High-quality ATP abilities also do not translate directly to reliably
solving modeling problems, where (open-ended) theoretical analyses are not the end goal but tools
to design a policy that can achieve desirable performance in practice.
Another direction equips LLMs with code-writing to enhance their problem-solving abilities.
The LLM’s job is to write correct, logically consistent code, and then a downstream system (e.g., a
Python interpreter) executes that code to obtain the result. Gao et al. (2023) is a good example,
where the LLM’s chain-of-thought is effectively replaced by or augmented with a Python function
that solves each sub-step of the problem. Romera-Paredes et al. (2024) is another prime example,
where an LLM paired with a systematic evaluator pushed beyond the boundary of human knowledge
on the cap set problem and discovered an asymptotic lower bound that was the largest improvement
in 20 years. More broadly, this stream of literature is also related to code generation (Chen et al.,
2021; Li et al., 2022) and tool-use (Schick et al., 2023) by LLMs. Our work is broadly related to
the vast literature on LLM-based AI agents as well (Shinn et al. (2023); Schick et al. (2023); Wang
et al. (2023); Yao et al. (2023); Manus AI). More specifically, what we envision resembles a “research
agent” that can facilitate human scientists make new discoveries (e.g., Sakana AI).
As mentioned before, the rapid development of LLMs’ abilities to solve math problems generally
does not consider the aspect of modeling. A series of work, primarily by OR researchers, have
discussed successes in marrying LLMs with techniques of formulating optimization problems and
solving them (Ramamonjison et al., 2022; Li et al., 2023; Astorga et al., 2024; Xiao et al., 2024;
Mostajabdaveh et al., 2024; AhmadiTeshnizi et al., 2024; Huang et al., 2025; Jiang et al., 2025;
Zhang and Luo, 2025); valuable datasets and benchmarks have also been published. In contrast,
studies on LLMs’ abilities to solve stochastic modeling problems have been missing.
With this
5


--- Page 6 ---
paper, we aim to take the first step towards this direction and hope to inspire future research.
3
HOMEWORK PROBLEMS TEST CASE
3.1
Dataset
To the best of our knowledge, no dataset featuring a list of stochastic modeling problems and
solutions is publicly available. Ideally, the dataset should consist of a large number of mathematical
models and analytical results from academic papers on stochastic modeling, but as a start we will
focus on course settings as a prerequisite. Most textbooks available in digital forms do not have
readily available solutions, and there are also copyright issues. Therefore, we manually sourced
problems and solutions from related courses at our institution.
The first version of the dataset has 175 problems and solutions, divided into three categories:
probability, stochastic processes, and stochastic modeling. This categorization reflects both con-
ceptual boundaries and a natural progression of study. The probability category establishes the
theoretical foundation, covering topics such as measure-theoretic probability, convergence of ran-
dom variables, the laws of large numbers, the central limit theorem, and large deviations. Build-
ing on this, the stochastic processes category introduces dynamic models including random walks,
stopping times, martingales, Markov chains, and renewal and regenerative processes. Finally, the
stochastic modeling category focuses on applications of these processes to real-world systems, with
an emphasis on stochastic stability and queueing theory.
However, a quick inspection shows that a proportion of the problems are educative and not
suitable for evaluation; see Example 3.1 and 3.2 for two sample problems.
A classical result in probability theory
Example 3.1. Let X be a non-negative random variable with cumulative distribution function
F. Show that E[X] =
R ∞
0
¯F(x)dx, where ¯F(x) = 1 −F(x).
A classical result in stochastic processes
Example 3.2. Prove the backwards martingale convergence theorem.
We consider these problems to be “classic” and a quick test shows that LLMs can solve them
very well, likely because their solutions appear frequently on the Internet. To make our evalua-
tion more challenging and meaningful, we exclude these problems from consideration. The final
dataset contains 71 problems and solutions, where 37 are on probability theory, 23 are on stochastic
processes, and 11 are on stochastic modeling. Below are some examples:
A sample problem on probability
Example 3.3. Consider a sequence of i.i.d. random variables X1, X2, . . ., each having an
exponential distribution with parameter 1. Let Mn := max {X1, . . . , Xn}.
(a) Let Yn = Xn1 {Xn ≤log n} denote a truncated exponential, i.e., Yn = Xn if Xn ≤log n
and equals zero otherwise. Prove that Yn ̸= Xn, i.o., almost surely.
(b) Prove that Mn/ log n →1 almost surely as n →∞, where log denotes the natural loga-
rithm.
6


--- Page 7 ---
A sample problem on stochastic processes
Example 3.4. Consider an irreducible discrete-time Markov chain Xn on a finite state space.
Let p denote its transition probability matrix. A function f is said to be superharmonic if
f(x) ≥P
y p(x, y)f(y) or equivalently f (Xn) is a supermartingale. Show that the Markov
chain is recurrent if and only if every nonnegative superharmonic function is constant.
A sample stochastic modeling problem
Example 3.5. Consider an inventory model in which demand for a commodity arrives at the
end of each day. Successive demands are i.i.d. with distribution function F(·). The following
(s, S) policy is used: if the inventory level at the beginning of a day is less than or equal to
s, we order up to S, and if the level is greater than s no action is taken. Orders are assumed
to filled instantaneously. Let {Xn}n≥1 be the inventory level at the beginning of the nth day,
right after delivery of inventory (if any). Suppose that X1 = S.
(a) Prove that Xn is regenerative with points of regeneration that are given by the order epochs.
(b) Let {τn} denote the lengths of the regenerative cycles, derive an expression for Eτ1.
(c) Derive an expression for limn→∞P (Xn ≥k).
Naturally, these problems vary in difficulty and the knowledge required. Overall, we believe
this dataset is representative of the problems that students in a graduate-level stochastic modeling
course would encounter. See Appendix A for these example questions’ solutions, LLMs’ answers,
and the grading process.
3.2
LLMs, Prompt Template, and Solving the Problems
We consider 6 LLMs: GPT-4o, o1, and o3-mini from OpenAI; Claude 3.5 Sonnet from Anthropic
(calling the latest model Claude 3.7 Sonnet constantly generates server overload error); Llama 3.3
70B Instruct Turbo from Meta; DeepSeek-R1 from DeepSeek. While many other LLMs exist and
may be of interest, we believe the ones selected are representative of popular and state-of-the-art
LLMs. We use OpenAI API for OpenAI models, Claude API for Anthropic models, and Together
AI for Llama and DeepSeek models. For each LLM and each problem, we call the corresponding
API to obtain a solution by the following prompt template:
Prompt Template for HW Problems
You are given a problem from probability theory and stochastic modeling. You need to solve this
problem rigorously to the best of your ability. Please provide as many details and explanations as
you can. The problem is as follows:
{problem}
We use this prompt to evaluate the inherent capabilities of LLMs without additional enhance-
ments. Current LLMs (e.g., o1, o3-mini, DeepSeek-R1) already incorporate reasoning abilities and
advanced prompting and sampling techniques.
Therefore, we intentionally avoid using complex
prompts, chain-of-thought methods (Wei et al., 2023), or specialized sampling approaches in our
testing. While we acknowledge that fine-tuning and prompt engineering could potentially improve
performance, we reserve these approaches for future exploration.
7


--- Page 8 ---
3.3
Evaluating LLMs’ Solutions
Ideally, for a rigorous evaluation of LLMs’ solutions, we would have qualified human graders to grade
each of LLMs’ answers. However, due to budget constraint, a more scalable and valid alternative is
the “LLM-as-a-judge” approach (Zheng et al., 2023), where strong LLM models are used to evaluate
LLM performance. In our case, we use GPT-4o as the judge. For each problem-answer pair, we
obtain an evaluation from the judge by the following prompt template:
Prompt Template for Evaluating the Responses
You are given a problem in probability theory and stochastic modeling along with its solution. You
are also given a solution submitted by a student studying these topics. Your task is to evaluate the
student’s solution based on correctness and completeness. The score should be a number between 0
and 100, where 0 means completely incorrect and incomplete, and 100 means completely correct and
complete. You should also provide detailed reasons for the score you assign. For example, you should
indicate that some points are taken off because the student fails to use a key result or the student’s
reasoning is not rigorous enough. The problem is:
{problem}
The correct solution is:
{solution}
The student’s solution is:
{student_solution}
Please provide the final score at the beginning of your response in double brackets, e.g., [[50]].
By manually inspecting the judge’s scores and comments, we find the evaluations reasonable and
sometimes more comprehensive than those that would be provided by a human counterpart (see
Section A for examples). To make the evaluation process more robust, we sample three independent
scores from the judge (by calling the API three times) for each problem and take the average for the
final score. This procedure mimics pooling scores assigned by three independent human graders.
We found that, in general, the three scores do not differ much, underlining the reliability of using
an LLM as the judge. In Section 4, we also compare the LLM’s scores with human scores and show
further evidence for alignment.
3.4
Results
The LLMs’ average scores (and standard errors in parenthesis) are summarized in Table 1.
LLM
Prob theory
Stoch process
Stoch modeling
Total
GPT-4o
81.85 (1.95)
78.72 (2.65)
74.67 (1.57)
79.72 (1.39)
o1
95.46 (0.47)
95.28 (0.56)
90.61 (1.96)
94.65 (0.48)
o3-mini
96.97 (0.36)
96.25 (0.54)
92.58 (1.29)
96.05 (0.37)
Claude 3.5 Sonnet
88.74 (1.09)
86.96 (1.33)
73.48 (3.74)
85.80 (1.12)
Llama 3.3 70B
78.36 (2.47)
75.99 (2.70)
58.18 (3.49)
74.46 (1.85)
DeepSeek-R1
84.30 (2.00)
73.33 (4.44)
64.85 (5.03)
77.73 (2.13)
Table 1: LLMs’ scores on homework problems.
8


--- Page 9 ---
While we believe that these scores are generally reasonable, we caution against taking these
scores to be exact because they are, after all, generated by GPT-4o and thus may have certain bias
(Zheng et al., 2023). Nevertheless, several qualitative observations can be made:
1. First and foremost, if we set 60% as the cutoff for passing a stochastic modeling course, all models
would pass easily, with o1 and o3-mini being the top performing.
2. Secondly, models with higher scores seem to have smaller standard errors as well. This may be
because that they have been optimized to be more accurate and be more aligned with human
preferences, which may reduce the variability in their answers.
3. Lastly, for all models, stochastic modeling problems seem to be the hardest, perhaps due to their
more open-ended nature.
4
QUALIFICATION EXAM PROBLEMS
In light of the observations from the last section, we believe the state-of-the-art LLMs have abilities
on par with human PhD students in the field. To make the evaluation more rigorous, we next
procure a set of qualification-exam problems to test the LLMs. It is a common tradition in many
fields to test a PhD student’s ability with a qualification exam after the student has passed all
required courses. Only those who pass the exam will be allowed to proceed to the next stage of
their PhD and become PhD candidates. Since the LLMs exhibit superior performance in a course-
like setting, it would be interesting to see how they perform in a real exam. To ensure fairness, we
will manually grade the LLMs’ answers; we will also compare our scores with those generated by
GPT-4o to provide evidence for the validity of using GPT-4o as a grader.
Results from the last section suggest that o1 and o3-mini have the best performance. Therefore,
we will manually grade the answers generated by these two models. As a comparison, we will also
consider answers from Claude 3.5 Sonnet since it was the second runner-up. Recall that we observed
that stochastic modeling problems seem to be the most challenging for these models. By manually
inspecting the LLMs’ answers, we are also convinced that the LLMs can answer any probability
theory and stochastic process problems well in the exam. Therefore, we will focus on testing these
LLMs on stochastic modeling problems.
4.1
Dataset
We carefully select 8 stochastic modeling problems that have appeared in past qualification exams
in the Decision, Risk, and Operations Division at Columbia Business School. A common theme
of these problems is to model some real-life problem with an abstract model. The students are
asked to analyze the model to arrive at sensible decisions for the real-life problem.
Examples
include modeling the spread of a virus by a branching process, variants of the newsvendor problem,
optimizing assortment planning using Markov chains, and stability conditions for complex queueing
systems.
In other words, though these problems are still limited to clean models, they have a
practical footing and are representative of “analyzable” real-life stochastic modeling problems. Since
they are exam problems, they are also less open-ended compared to their counterparts in homework
to ensure fair grading. On average, these problems are designed to be challenging for junior PhD
students. Every year, a selected committee of faculty would design new qualification exam problems.
Since past problems and their solutions are private, it is unlikely that LLMs’ training set contains
the exact problems.
9


--- Page 10 ---
Due to departmental regulations, we are unable to share actual problems from past qualification
exams. To provide a sense of the exam’s format and style, we present below a sample stochastic
modeling problem that is made available to first-year PhD students as part of their preparation.
Since its primary purpose is to illustrate the structure and expectations of the exam, the problem is
on the easier end of the spectrum compared to typical qualification exam problems. See Appendix
B for the problem’s solution, an LLM’s answer, and the grading.
A sample qualification exam stochastic modeling problem
Example 4.1. Consider a non-preemptive FIFO queue with infinite buffer. Requests arrive
according to a Poisson process with rate λ, and each has i.i.d. workload w ∼Exp(µ). The
service proceeds as follows.
Each request is initially processed for up to θ time units.
If
completed within θ, it exits the system and the next request (if any) begins service. If not,
then the system restarts service in a mode that is divided into two steps: 1) the request
is broken into n sub-tasks that are executed in parallel by n servers, where the processing
times of the sub-tasks are i.i.d., uniformly distributed in the interval [0.5w/n, 1.5w/n]; and
2) the results of all n sub-tasks are combined to complete the service of the original request,
in a step that can only commence after all n sub-tasks are completed and its duration is
exponentially distributed with rate 2µ, independent of the processing times of the sub-tasks
and of the processing requirements of any other requests.
(a) What is the stability condition for the system?
(b) What is the steady-state expected sojourn time for a new request?
The sojourn time
includes the waiting time in the queue and the service time.
We want to emphasize that the qualification exams at Columbia Business School, especially the
stochastic modeling part, are not easy by any means. The core course that prepares students for
this exam is widely known to be hard in the community. Students often spend a significant amount
of time taking this class and preparing for this exam. Therefore, though we use a small dataset,
the evaluation remains meaningful: as educators and researchers in OR, we are genuinely curious
about how LLMs perform on these problems, and the results may inform how we teach and assess
students in the future.
4.2
Results
We obtain answers from the LLMs in the same fashion as before. We also obtain GPT-4o’s grading
for these answers.
The LLMs’ scores (average scores and standard error in parenthesis where
applicable) are summarized in Table 2. As evidenced by the scores, though stochastic modeling
problems seem to be more challenging for LLMs than other types of problems, with 60% being
the cutoff for passing, all three models can pass the qualification exam with flying colors.
As a
reference, though exact score distributions of past qualification exams at Columbia Business School
are unknown, across the years scores border-lining the 60% cutoff or lower consistently occurred.
In this sense, under the same evaluation framework for humans, these models have demonstrated
capabilities at least on par with PhD candidates in the field.
How well the top LLMs are solving these problems are indeed impressive! But of course, the
LLMs’ answers are not without flaws. Upon closely examining their answers, we found that, for
almost all problems, they have the right intuition and high-level arguments. Where points are taken
off, it was mostly because of missing calculations or proof steps. This finding suggests that these
LLMs can be helpful assistants for solving stochastic modeling problems, but they tend to generate
answers that might lack rigor.
10


--- Page 11 ---
Table 2: LLMs’ scores on qualification exam problems.
Problem
o1
o3-mini
Claude 3.5 Sonnet
Scored by
GPT-4o
human
GPT-4o
human
GPT-4o
human
Problem 1
95
94
93.33
94
81
74
Problem 2
95
96
96.67
96
85
88
Problem 3
95
91
95
94
86.67
85
Problem 4
98.33
100
100
100
95
88
Problem 5
96.67
95
96.67
100
91.67
100
Problem 6
95
95
98.33
95
78.33
85
Problem 7
94.67
85
98.33
87
85
80
Problem 8
96.67
100
93.33
100
73.33
77
Total
95.79 (0.43)
94.5 (1.61)
96.46 (0.80)
95.75 (1.47)
84.5 (2.31)
84.63 (2.66)
4.3
Grading Alignment
Given scores by humans, it is natural to ask whether the scores given by GPT-4o aligns well with
“real” scores.
Across the 24 scores, we calculated the Pearson correlation coefficient to be 0.77
(Figure 3, left panel). The distribution of score differences (GPT-4o’s scores minus human’s scores)
is approximately symmetric with a mean of 0.63 and standard error of 1.00 (Figure 3, right panel).
The absolute difference has a mean of 3.82 and a maximum of 11.33. Since the maximum score
possible is 100, we believe the alignment between GPT-4o’s grading and human’s is well and the
LLM-as-a-judge method is reliable in our context. We also acknowledge that a more comprehensive
and large-scale evaluation would be beneficial and leave it for the future work.
75
80
85
90
95
100
LLM Scores
75
80
85
90
95
100
Human Scores
(a) Scores given by GPT-4o vs. given by human.
7.5
5.0
2.5
0.0
2.5
5.0
7.5
10.0
LLM Scores - Human Scores
0
1
2
3
4
5
Count
(b) Distribution of grading differences.
Figure 3: Grading alignment.
5
SIMULATION-OPTIMIZATION PROBLEMS
Having shown that LLMs perform well in a classroom setting, in this section we discuss the ability
of different LLMs in solving and implementing simulation-optimization methods on a testbed of
problems that more closely resemble those encountered in practice.
The code are available at
https://github.com/AkshitKumar/simopt-llm-evals.
11


--- Page 12 ---
5.1
Dataset and Evaluation
We evaluate five LLMs—GPT-4o, o1, o3-mini, Claude 3.5 Sonnet, and DeepSeek-R1—on six op-
timization problems from the SimOpt library, a well-known benchmark suite for noisy simulation
optimization in OR (Eckman et al., 2024). Each model is prompted five times with problem de-
scriptions from SimOpt. We execute the Python code generated by the models and compare their
solutions to those produced by baseline algorithms implemented in SimOpt, including Random-
Search, ASTRO-DF, Nelder-Mead, STRONG, SPSA, ADAM, and ALOE (see Dong et al. (2017)
for algorithmic details and comparisons). For each problem, we report the objective values achieved
by the models and benchmark them against the best solver identified by Dong et al. (2017). These
values may differ considerably due to variations in the simulation environments implemented by
the different models. Consequently, we also focus on the algorithmic strategy that each model em-
ploys by manually analyzing the solutions they propose. Each model solution is allocated the same
computational budget, where the budget refers to the number of simulation replications over the
entire course of the search for optimal solutions (Eckman et al., 2024). To ensure consistency, we
use the same prompt template for all five LLMs. The prompt is crafted by merging the problem
descriptions from the SimOpt library with a prompt template, which is then refined using o1 and
manually verified for correctness. See Appendix C for an example of the prompt and LLM’s solution
for the Chess Matchmaking problem.
5.2
Results
In Figure 4, we showcase the performance of the solution proposed by the different models. If the
performance of a model is missing, it means that the model failed to produce reasonable code despite
multiple attempts. Below, we summarize our main findings, followed by problem-specific analyses.
1. Claude 3.5 Sonnet delivers the strongest overall performance, achieving near-optimal solutions
for five out of six problems. On the other hand, despite their theoretical exam prowess, GPT-4o
critically fails on the textbook Continuous Newsvendor problem and o1 can even fail to generate
numerical solutions.
2. Consistent methodological preferences surface: Claude leverages binary/differential evolution,
DeepSeek-R1 defaults to coordinate descent, and o1 employs domain-constrained grid searches.
3. The IronOre problem highlights implementation limitations, with all models producing incompa-
rable solutions.
As evidenced by comparing LLMs’ performance on paper-based exams and on these practical
problems, the top performer in one scenario may not be the best in the other. State-of-the-art
models like GPT-4o or o1 may even fail to reliably produce numerical solutions.
The IronOre
problem also suggests that the comparison between models still needs human supervision. Overall,
these observations suggest that more work is needed to reliably automate the stochastic modeling
pipeline.
Chess Matchmaking (ChessMM)
This problem involves matching players on an online chess platform to minimize the average Elo
difference between matched pairs, while ensuring that the average waiting time does not exceed
a specified threshold (δ = 5.0). In this setting, players arrive according to a Poisson process and
their Elo ratings are sampled from a truncated normal distribution over the interval [0, 2400]. No
12


--- Page 13 ---
(a) Chess Matchmaking
(b) Continuous Newsvendor
(c) Dual Sourcing
(d) Facility Sizing
Figure 4: Performance of different LLMs for simulation-optimization problems. We omit IronOre due to
differences in how LLMs implement the simulation environment, making the results incomparable. We also
exclude ParamEsti, as all LLMs converge to the optimal solution.
theoretical optimal solution is known, and SimOpt’s best-performing algorithm achieved an average
Elo difference of 45.1246. All evaluations are conducted with a fixed budget of 1000 function calls.
The different LLM approaches primarily differ in their search strategies for determining the optimal
allowable Elo difference threshold, x. For example, GPT-4o’s solution implements a line search over
the full range [0, 2400]. In contrast, o1’s approach confines its grid search to the interval [0, 300],
effectively focusing its limited budget on a more promising subset of the parameter space, which
results in better performance relative to the other methods.
Similarly, o3-mini’s approach uses
grid search but over a wider interval [10, 2400], which can lead to a less concentrated search and
suboptimal tuning. Meanwhile, Claude’s solution employs a binary search over [0, 2400], efficiently
honing in on the smallest threshold that meets the waiting time constraint, while DeepSeek also
utilizes grid search over the full range. These differences in search range and methodology underscore
how a more targeted exploration—such as the one adopted by o1—can yield superior performance
when the computational budget is fixed.
Continuous Newsvendor (CntNv)
This problem considers a vendor who orders a fixed quantity of liquid at the beginning of the
day. The liquid is sold to customers at a per-unit price and any unsold inventory is salvaged at a
lower per-unit price, while the vendor incurs a per-unit ordering cost. In this classic formulation
the optimal order quantity is known in closed form. In our evaluation, we compare ASTRO-DF
alongside LLM-derived solutions, all using a fixed budget of 1000 function evaluations. Among
13


--- Page 14 ---
the LLM solutions, GPT-4o failed to produce a reasonable solution, whereas o1 and o3-mini both
leveraged the closed-form solution to guide their search. Specifically, o1 combined the closed-form
reasoning with a random search strategy, while o3-mini employed a grid search over candidate
order quantities. In contrast, Claude utilized a Nelder-Mead algorithm to iteratively converge to
the optimum, and DeepSeek applied a grid search approach. The key difference in performance
across these methods can be largely attributed to the search strategy and the range over which the
optimization is performed.
Dual Sourcing (DualSourcing)
This problem requires choosing optimal order-up-to levels for two procurement channels—one reg-
ular (lower cost, longer lead time) and one expedited (higher cost, shorter lead time)—so as to
minimize the total expected daily cost (comprising holding, penalty, and ordering costs) over a sim-
ulation horizon of n periods. All the LLMs implemented a grid search style technique. Overall, the
differences in performance across these models can be traced to how they allocate their fixed eval-
uation budget. o3-mini, Claude, and DeepSeek restrict the search to a plausible, domain-informed
range and appropriately replicate the simulations.
In contrast, GPT-4o and o1 misinterpreted
and incorrectly implemented key aspects of the inventory dynamics—the correct handling of order
arrivals, backorders, and the inventory pipeline—leading them to absurd cost estimates.
Facility Sizing (FacSize)
This problem requires selecting nonnegative capacities xi for three facilities to minimize the total
installation cost while ensuring that the probability of a stockout (i.e., at least one facility expe-
riencing demand exceeding its capacity) remains below a certain level. GPT-4o uses a continuous
optimization approach with scipy.optimize.minimize, simulating demand samples and incorpo-
rating the stockout probability as an inequality constraint; however, its estimation of the constraint
is imprecise, leading to suboptimal solutions. In contrast, o1 employs a grid search over a discrete
range of candidate capacities and reuses pre-generated demand samples to estimate the stockout
probability for each candidate, ultimately selecting the lowest-cost solution that meets the risk con-
straint. o3-mini takes a different approach by parameterizing the capacities as x = µ + z σ and
performing a binary search on the scalar parameter z to efficiently identify the smallest safety mar-
gin that satisfies the stockout constraint. Claude also relies on an iterative binary search, starting
with bounds based on the mean and standard deviations of the demand distribution, and refines
these bounds through repeated simulations to robustly estimate the stockout probability, thereby
finding a cost-effective solution. DeepSeek initially derives a solution by setting baseline capacities
based on normal quantiles and then applies coordinate descent to iteratively lower each capacity
while ensuring that the overall stockout probability remains within acceptable limits.
Iron Ore Production with Exogenous Stochastic Price (IronOre)
This problem models a mine producing and selling an item (such as iron ore) on a spot market where
the daily price Pt follows a truncated mean-reverting random walk. Every day the decision maker
observes Pt and the current inventory level, then makes production and sales decisions according
to four thresholds: x1 is the price above which production starts or continues, x2 is the inventory
level above which production is halted, x3 is the price below which production is stopped, and x4
is the price above which the entire inventory is sold. Production is limited to a maximum daily
amount and capacity constraints, while holding costs apply to unsold inventory. Among the SimOpt
algorithms, ASTRO-DF performed the best in terms of maximizing profit. All the LLMs differ in the
14


--- Page 15 ---
way they implement the simulation environment for this problem, so their numerical results are not
directly comparable. Therefore, we describe only qualitatively the strategies each one uses: GPT-4o
performs a random search over the continuous threshold space using scipy.optimize.minimize;
o1 uses a grid search over a broad range of threshold candidates, applying pre-generated price paths
to evaluate each policy, but its ordering of decisions appears inconsistent; o3-mini parameterizes
the thresholds relative to the mean and standard deviations of the price process and uses a binary
search on a safety margin parameter combined with multiple replications to refine the candidate
solution; Claude employs differential evolution, running multiple simulation trials per evaluation to
iteratively improve the threshold values; and DeepSeek initiates its search with a Bonferroni-based
heuristic and then applies coordinate descent to iteratively adjust the thresholds.
Parameter Estimation (ParamEsti)
This is a classical textbook problem in which the objective is to recover the unknown parameter
vector x∗= (x∗
1, x∗
2) of a two-dimensional gamma distribution from i.i.d. observations, with the
density defined over [0, ∞) × [0, ∞). Both traditional SimOpt algorithms as well as those imple-
mented by the various LLMs converge to the optimal solution. GPT-4o adopts a standard numerical
optimization approach by constructing the negative log-likelihood function and minimizing it with
scipy.optimize.minimize (typically using an L-BFGS-B algorithm) starting from an initial guess;
this method directly maximizes the likelihood based on the observed data. In contrast, o1 takes a
partial closed-form approach by solving the MLE conditions using root-finding techniques such as
bisection to invert the digamma function for one parameter while using a moment condition for the
other, thereby leveraging analytical properties of the gamma distribution. o3-mini employs a direct
search strategy by randomly generating candidate solutions over a prescribed domain and evaluat-
ing their average log-likelihoods over multiple replications, ultimately selecting the candidate that
achieves the highest value. Claude uses a numerical optimization approach—employing methods
such as differential evolution or L-BFGS-B—and further refines its estimates by bootstrapping to
obtain confidence intervals. Finally, DeepSeek combines the use of analytical gradients, derived from
the log-likelihood function, with gradient-based optimization (again using L-BFGS-B) to efficiently
and robustly recover the parameters. Despite the different methodologies, all of these approaches
converge to the true parameter values as is expected in this classical problem.
6
CONCLUSIONS
In this work, we evaluated LLMs’ abilities to solve stochastic modeling problems through a series
of homework problems, qualification-exam problems, and simulation-optimization problems. Our
findings suggest that these models have the potential to automate the stochastic modeling pipeline
at a level comparable with human experts, and we hope this work will inspire future research in
developing intelligent OR agents that can help make real-world decisions reliably and at scale.
References
AhmadiTeshnizi, A., Gao, W., Brunborg, H., Talaei, S. and Udell, M. (2024). OptiMUS-
0.3: Using Large Language Models to Model and Solve Optimization Problems at Scale.
Astorga, N., Liu, T., Xiao, Y. and van der Schaar, M. (2024). Autoformulation of Mathe-
matical Optimization Models Using LLMs.
15


--- Page 16 ---
Bansal, K., Loos, S. M., Rabe, M. N., Szegedy, C. and Wilcox, S. (2019). HOList: An
Environment for Machine Learning of Higher-Order Theorem Proving.
Bertsimas, D., Brown, D. B. and Caramanis, C. (2011). Theory and applications of robust
optimization. SIAM review 53 464–501.
Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakan-
tan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger,
G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse,
C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., Mc-
Candlish, S., Radford, A., Sutskever, I. and Amodei, D. (2020). Language Models are
Few-Shot Learners.
Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. d. O., Kaplan, J., Edwards,
H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov,
M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M.,
Power, A., Kaiser, L., Bavarian, M., Winter, C., Tillet, P., Such, F. P., Cummings,
D., Plappert, M., Chantzis, F., Barnes, E., Herbert-Voss, A., Guss, W. H., Nichol,
A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saunders, W.,
Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford,
A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., McGrew, B.,
Amodei, D., McCandlish, S., Sutskever, I. and Zaremba, W. (2021). Evaluating Large
Language Models Trained on Code.
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M.,
Tworek, J., Hilton, J., Nakano, R., Hesse, C. and Schulman, J. (2021). Training Verifiers
to Solve Math Word Problems.
Dai, J. G. and Harrison, J. M. (2020). Processing Networks: Fluid Models and Stability. 1st ed.
Cambridge University Press.
Dong, N. A., Eckman, D. J., Zhao, X., Henderson, S. G. and Poloczek, M. (2017).
Empirically comparing the finite-time performance of simulation-optimization algorithms.
In
2017 Winter Simulation Conference (WSC). IEEE, Las Vegas, NV.
Eckman, D. J., Henderson, S. G., Shashaani, S. and Pasupathy, R. (2024).
SimOpt.
https://github.com/simopt-admin/simopt.
Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang, Y., Callan, J. and Neubig, G.
(2023). PAL: Program-aided Language Models.
Glazer, E., Erdil, E., Besiroglu, T., Chicharro, D., Chen, E., Gunning, A., Olsson,
C. F., Denain, J.-S., Ho, A., Santos, E. d. O., Järviniemi, O., Barnett, M., Sandler,
R., Vrzala, M., Sevilla, J., Ren, Q., Pratt, E., Levine, L., Barkley, G., Stewart, N.,
Grechuk, B., Grechuk, T., Enugandla, S. V. and Wildon, M. (2024). FrontierMath: A
Benchmark for Evaluating Advanced Mathematical Reasoning in AI.
Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D. and
Steinhardt, J. (2021). Measuring Mathematical Problem Solving With the MATH Dataset.
Huang, C., Tang, Z., Hu, S., Jiang, R., Zheng, X., Ge, D., Wang, B. and Wang, Z. (2025).
ORLM: A Customizable Framework in Training Large Models for Automated Optimization Mod-
eling.
16


--- Page 17 ---
INFORMS (2025).
Franz edelman award for achievement in advanced analytics, operations
research, and management science.
https://www.informs.org/Recognizing-Excellence/
INFORMS-Prizes/Franz-Edelman-Award. Accessed 20 June 2025.
Jiang, A. Q., Li, W., Tworkowski, S., Czechowski, K., Odrzygóźdź, T., Miłoś, P.,
Wu, Y. and Jamnik, M. (2022). Thor: Wielding Hammers to Integrate Language Models and
Automated Theorem Provers.
Jiang, C., Shu, X., Qian, H., Lu, X., Zhou, J., Zhou, A. and Yu, Y. (2025). LLMOPT:
Learning to Define and Solve General Optimization Problems from Scratch.
Kaliszyk, C., Chollet, F. and Szegedy, C. (2017). HolStep: A Machine Learning Dataset for
Higher-order Logic Theorem Proving.
Li, Q., Zhang, L. and Mak-Hau, V. (2023). Synthesizing mixed-integer linear programming
models from natural language descriptions.
Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., Eccles, T.,
Keeling, J., Gimeno, F., Lago, A. D., Hubert, T., Choy, P., d’Autume, C. d. M.,
Babuschkin, I., Chen, X., Huang, P.-S., Welbl, J., Gowal, S., Cherepanov, A., Mol-
loy, J., Mankowitz, D. J., Robson, E. S., Kohli, P., de Freitas, N., Kavukcuoglu,
K. and Vinyals, O. (2022). Competition-Level Code Generation with AlphaCode. Science 378
1092–1097.
Mostajabdaveh, M., Yu, T. T., Ramamonjison, R., Carenini, G., Zhou, Z. and Zhang,
Y. (2024). Optimization modeling and verification from problem specifications using a multi-
agent multi-stage LLM framework. INFOR: Information Systems and Operational Research 62
599–617.
Polu, S. and Sutskever, I. (2020). Generative Language Modeling for Automated Theorem
Proving.
Ramamonjison, R., Li, H., Yu, T. T., He, S., Rengan, V., Banitalebi-Dehkordi, A.,
Zhou, Z. and Zhang, Y. (2022). Augmenting Operations Research with Auto-Formulation of
Optimization Models from Problem Descriptions.
Rocktäschel, T. and Riedel, S. (2017). End-to-End Differentiable Proving.
Romera-Paredes, B., Barekatain, M., Novikov, A., Balog, M., Kumar, M. P., Dupont,
E., Ruiz, F. J. R., Ellenberg, J. S., Wang, P., Fawzi, O., Kohli, P. and Fawzi, A. (2024).
Mathematical discoveries from program search with large language models. Nature 625 468–475.
Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer, L., Can-
cedda, N. and Scialom, T. (2023). Toolformer: Language Models Can Teach Themselves to
Use Tools.
Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K. and Yao, S. (2023).
Reflexion:
Language agents with verbal reinforcement learning. Advances in Neural Information Processing
Systems 36 8634–8652.
Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L. and Anandku-
mar, A. (2023). Voyager: An open-ended embodied agent with large language models. arXiv
preprint arXiv:2305.16291 .
17


--- Page 18 ---
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le, Q. and
Zhou, D. (2023). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.
Xiao, Z., Zhang, D., Wu, Y., Xu, L., Wang, Y., Han, X., Fu, X., Zhong, T., Zeng, J.,
Song, M. and Chen, G. (2024). Chain-of-Experts: When LLMs Meet Complex Operations
Research Problems. ICLR .
Yang, K. and Deng, J. (2019). Learning to Prove Theorems via Interacting with Proof Assistants.
Yang, K., Swope, A. M., Gu, A., Chalamala, R., Song, P., Yu, S., Godil, S., Prenger,
R. and Anandkumar, A. (2023). LeanDojo: Theorem Proving with Retrieval-Augmented Lan-
guage Models.
Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K. and Cao, Y. (2023). React:
Synergizing reasoning and acting in language models. In International Conference on Learning
Representations (ICLR).
Zhang, B. and Luo, P. (2025).
Or-llm-agent:
Automating modeling and solving of oper-
ations research optimization problem with reasoning large language model.
arXiv preprint
arXiv:2503.10009 .
Zheng, K., Han, J. M. and Polu, S. (2022). MiniF2F: A cross-system benchmark for formal
Olympiad-level mathematics.
Zheng, L., Chiang, W.-L., Sheng, Y., Zhuang, S., Wu, Z., Zhuang, Y., Lin, Z., Li, Z., Li,
D., Xing, E. P., Zhang, H., Gonzalez, J. E. and Stoica, I. (2023). Judging LLM-as-a-Judge
with MT-Bench and Chatbot Arena.
18


--- Page 19 ---
A
Example Homework Problems
In this section, for the three example problems given in Section 3, we provide the reference solutions,
GPT-4o’s answers, and evaluations from the LLM judge.
A.1
Example 1: A Probability Theory Problem
Problem Statement
Consider a sequence X1, X2, . . ., of i.i.d. random variables, each having an exponential dis-
tribution with parameter 1. Let Mn := max {X1, . . . , Xn}.
(a) Let Yn = Xn1 {Xn ≤log n} denote a truncated exponential, i.e., Yn = Xn if Xn ≤log n
and equals zero otherwise. Prove that Yn ̸= Xn, i.o., almost surely.
(b) Prove that Mn/ log n →1 almost surely as n →∞, where log denotes the natural
logarithm.
Reference Solution
(a) Consider
∞
X
n=1
P {Xn > log n} =
∞
X
n=1
1
n = ∞.
By Borel-Cantelli Lemma, it follows that
P {Xn > log n i.o.} = 1
With Yn = Xn1 {|Xn| ≤log n}, it is clear that
{ω : Xn(ω) > log n i.o.} ⊆{ω : Yn(ω) ̸= Xn(ω) i.o.} .
Since the event on the left-hand side has probability one, so does the event on the righthand
side. That is, Yn ̸= Xn infinitely often, almost surely.
(b) Fix ε > 0. We first show that
{Mn ≤(1 + ε) log n ev.} = {Xn ≤(1 + ε) log n ev.}
For every ω ∈{Xn(ω) ≤(1 + ε) log n ev.}, we have
∃N(ω) ∈N,
Xn(ω) ≤(1 + ε) log n
for all n ≥N(ω).
It follows that
max
1≤i≤n Xi(ω) ≤(1 + ε) log n
for all n > max
n
N(ω), e
1
1+ε max1≤i≤N(ω) Xi(ω)o
.
In other words,
Mn(ω) ≤(1 + ε) log n, eventually.
Therefore, {Xn ≤(1 + ε) log n ev.} ⊆{Mn ≤(1 + ε) log n ev.}. It is trivial to see that
{Mn ≤(1 + ε) log n ev.} ⊆{Xn ≤(1 + ε) log n ev.} ,
19


--- Page 20 ---
so the two events are in fact equivalent. Consequently, their complements are equivalent, that
is,
{Mn > (1 + ε) log n i.o.} = {Xn > (1 + ε) log n i.o.} .
By Borel-Cantelli Lemma,
∞
X
n=1
P {Xn ≥(1 + ε) log n} =
∞
X
n=1
1
n1+ε < ∞⇒P {Xn ≥(1 + ε) log n i.o.} = 0.
Therefore,
P
 Mn
log n > 1 + ε i.o.

= 0,
∀ε > 0.
(A.1)
Recall that
P (Mn ≤x) = P

max
1≤i≤n Xi ≤x

=
n
Y
i=1
P (Xi ≤x) =
 1 −e−xn ,
so for large n,
P
 Mn
log n < 1 −ε

= P {Mn < (1 −ε) log n} =

1 −e−(1−ε) log nn
=

1 −
1
n1−ε
n
≈e−nε.
Therefore,
∞
X
n=1
P
 Mn
log n < 1 −ε

< ∞.
By Borel-Cantelli Lemma,
P
 Mn
log n < 1 −ε i.o.

= 0,
∀ε > 0.
(A.2)
Combining (A.1) and (A.2), we conclude that Mn/ log n →1 almost surely as n →∞.
GPT-4o’s Response
To solve this problem rigorously, we will work through each part separately, providing detailed
explanations and proofs.
(a) Yn ̸= Xn i.o., almost surely.
Definitions and Setup: The sequence {Xn}n≥1 consists of i.i.d. random variables following
an exponential distribution with parameter 1. The exponential distribution has a cumulative
distribution function (CDF) given by F(x) = 1 −e−x for x ≥0.
The random variable
Yn = XnI{Xn ≤log n} indicates that Yn = Xn if Xn ≤log n, and Yn = 0 otherwise. We
need to show that Yn ̸= Xn occurs infinitely often (i.o.), almost surely.
Approach: For Yn ̸= Xn, it must be that Xn > log n. We will use the Borel-Cantelli lemma
to show that this event ({Xn > log n}) happens infinitely often with probability 1.
Probability of Event: The probability that Xn > log n is given by:
P(Xn > log n) = 1 −P(Xn ≤log n) = e−log n = 1
n.
20


--- Page 21 ---
Series Sum: Consider the series:
∞
X
n=1
P(Xn > log n) =
∞
X
n=1
1
n,
which is the harmonic series and diverges.
Application of Borel-Cantelli Lemma: Since the series diverges, by the Borel-Cantelli lemma,
P(Xn > log n i.o.) = 1. Therefore, P(Yn ̸= Xn i.o.) = 1, which means Yn ̸= Xn happens
infinitely often almost surely.
(b) Mn/ log n →1 almost surely as n →∞.
Definitions and Setup: The random variable Mn = max{X1, X2, . . . , Xn} is the maximum of
the first n i.i.d. exponentially distributed random variables. We aim to show that
Mn
log n →1
almost surely as n →∞.
Distribution of Mn: The CDF of Mn is given by:
FMn(x) = P(Mn ≤x) = (P(X1 ≤x))n = (1 −e−x)n.
Probability for Mn: For large n and letting x = (1+ϵ) log n, the probability Mn ≤(1+ϵ) log n
is:
P(Mn ≤(1 + ϵ) log n) = (1 −n−(1+ϵ))n.
Using the approximation (1 −
1
n1+ϵ )n →e−n−ϵ ≈1 for large n, this probability approaches 0.
On the other hand, for x = (1 −ϵ) log n, the probability:
P(Mn ≤(1 −ϵ) log n) = (1 −n−(1−ϵ))n ≈e−nϵ,
which approaches 0 for any ϵ > 0.
Almost Sure Convergence: By this argument,
Mn
log n does not deviate from 1 as n becomes
large, meaning:
P
 Mn
log n ̸→1

= 0.
Thus, by the Squeeze Theorem and convergence in probability,
Mn
log n →1 almost surely as
n →∞.
This completes both parts of the problem, proving the required properties with detailed
reasoning.
LLM Judge’s Evaluation
[[80]] The student’s solution is largely correct and well-reasoned, but it does contain some
minor inaccuracies and lacks certain elements of rigor when compared to the model solution.
• Part (a):
– The student correctly identifies the application of the Borel-Cantelli Lemma for part
(a). However, in the explanation of the setup, they include some redundant elements by
trying to monotone equivalency between events, which although not incorrect, it is less
straightforward than the given sketch. This part generally follows the correct steps.
21


--- Page 22 ---
– They correctly derive the probability expressions and apply the Borel-Cantelli lemma to
show that Xn > log n occurs infinitely often. This part is well done.
• Part (b):
– The student accurately describes the setup by determining the distribution of Mn and
correctly states the CDF for Mn. Their computation matches the sketch solution pro-
vided.
– The reasoning involving limits and approximations is correct; however, when they claim
“this probability approaches 0,” the reasoning could be clearer, noting that it should be
shown that such events are complementary in the infinite sample space. The student
briefly discusses the probabilities but doesn’t firmly link it back to insights gained from
the Borel-Cantelli Lemma.
– They do not fully articulate that for convergence in almost sure sense, each of the com-
plementary sets in sequences pertaining to (1+ϵ) log n and (1−ϵ) log n should be treated
with an explanation similar to Borel-Cantelli (what happens with the tail distribution)
for more clarity.
– Their explanation involving the Squeeze Theorem is slightly confusing, but the conclusion
is correct.
They could improve by directly relating back to almost sure convergence
conditions and more clear application of inequalities.
Overall, both parts a and b are generally correct, and they exhibit a good understanding of
the underlying principles. Some points are taken off due to the slight lack of detail and clarity
when dealing with almost sure convergence and the rigorous tie to provided information from
Borel-Cantelli.
Remark 1. Overall, the judge’s evaluation is on track. Part (a) indeed deserves full scores, while
part (b), depending on how harsh the grader is, may receive a lower score than that given by the
judge. Though part (b)’s answer is a bit different from the expected solution, the judge is correct
that this approach is not wrong and the conclusion is correct. We think this is a good evaluation
with a slight inflation of the score.
A.2
Example 2: A Stochastic Process Problem
Problem Statement
Consider an irreducible discrete-time Markov chain Xn on a finite state space.
Let p
denote its transition probability matrix.
A function f is said to be superharmonic if
f(x) ≥P
y p(x, y)f(y) or equivalently f (Xn) is a supermartingale. Show that the Markov
chain is recurrent if and only if every nonnegative superharmonic function is constant.
Reference Solution
Suppose that p is recurrent. For any nonnegative superharmonic function f, we know that
f (Xn) is a nonnegative supermartingale. By martingale convergence theorem, we get that
f (Xn) has a limit. If there exist i ̸= j such that f(i) ̸= f(j), then f (Xn) cannot converge
almost surely since the chain visits both i and j infinitely often. Thus, f must be constant.
22


--- Page 23 ---
Now we suppose that p is transient.
We fix a state x.
Then we know that
Px (∃n > 0, Xn = x) < 1. We define f(y) = Py (∃n > 0, Xn = x) and f(x) = 1. It is eas-
ily verified that f is a nonnegative superharmonic function.
However, f is not constant.
Otherwise, we have that f(y) = 1, ∀y ̸= x, and hence Px (∃n > 0, Xn = x) = 1, which is a
contradiction.
GPT-4o’s Response
To prove this statement, we will analyze both directions of the logical equivalence:
1. If p is recurrent, then every nonnegative superharmonic function is constant.
Recurrence implies that every state x is visited infinitely often with probability 1. A Markov
chain with a finite state space is irreducible and recurrent if each state is positive recurrent,
i.e. the expected return time to the state is finite.
Consider any nonnegative superharmonic function f. By definition, a function f is superhar-
monic if:
f(x) ≥
X
y
p(x, y)f(y)
for all states x.
Since the Markov chain is recurrent, every state x is visited infinitely often. Denote by Ex
the expectation starting from x, and consider the process f(Xn). By the optional stopping
theorem applied to the bounded stopping times (since f is nonnegative and superharmonic,
so the process is a supermartingale), for any state x and any stopping time τ with finite
expectation, we have:
Ex[f(Xτ)] ≤f(x).
For recurrence, if we let τ be the hitting time of any given state y, then:
Ex[f(Xτ)] = f(y) ≤f(x).
Since the chain is irreducible and recurrent, we can choose such τ such that every state is
recurrently revisited. Therefore, for any distinct points x and y, the expected values should
balance out, i.e. the only way for the inequality to hold every time is for f(y) = f(x). Since
this applies for any pair of states, f must take the same constant value at every state.
2. If every nonnegative superharmonic function is constant, then p is recurrent.
Conversely, assume every nonnegative superharmonic function is constant. We need to show
this implies recurrence of p.
Assume toward contradiction that p is transient. In a transient Markov chain, there exist
states x such that the expected number of visits to x is finite. Define f(x) as the expected
number of visits to state x starting from state x. For transient states, this function f(x) is
finite.
The function f(x) is indeed nonnegative superharmonic:
f(x) = 1 +
X
y
p(x, y)f(y),
which implies:
f(x) ≥
X
y
p(x, y)f(y).
23


--- Page 24 ---
The form of f(x) does not imply constancy unless all states are visited infinitely often,
contradicting transience.
Thus, if every nonnegative superharmonic function is forced to be constant, then p cannot be
transient and must therefore be recurrent.
This completes the proof, showing that p is recurrent if and only if every nonnegative super-
harmonic function is constant.
LLM Judge’s Evaluation
[[85]] The student’s solution demonstrates a good understanding of the problem and manages
to provide a coherent argument for both directions of the proof. Here is a breakdown of the
evaluation:
• Correctness:
– The student correctly identifies the relationship between superharmonic functions and
recurrence/transience.
– For the first direction (“If p is recurrent, then every nonnegative superharmonic function is
constant”), the student effectively employs characteristics of recurrence and the optional
stopping theorem to justify why f must be constant.
– For the second direction (“If every nonnegative superharmonic function is constant, then p
is recurrent”), the student constructs a correct argument using the definition of transience
and proposes a function f which, under transience, would not be constant, thus obtaining
a contradiction.
• Completeness:
– The student does a good job covering the logical implications in both directions of the
proof.
– There is subtlety in the use of the optional stopping theorem, which is treated with
reasonable rigor, although some parts could be slightly clearer in terms of explaining the
choice of stopping times and their finiteness.
– A minor omission is the lack of explicit consideration of infinite state spaces as the
student implicitly assumes the state space might be finite. In the context of finite state
spaces, the argument holds strongly.
• Rigor and Clarity:
– The arguments are well structured but could be improved in rigor by explicitly addressing
any assumptions such as the potential boundedness of certain functions or convergence
issues.
– The explanation of why f must remain constant is solid, relying on fundamentals of
supermartingale properties under the recurrence condition.
– In the second part, while the argument against transience by showing f(x) = 1 +
P
y p(x, y)f(y) and using superharmonic properties is effective, it would benefit from
a more explicit illustration of why this function is indeed not constant under transient
conditions.
24


--- Page 25 ---
Overall, the student provides a strong solution that would only benefit from slight clarifica-
tions and improvements in detailing certain steps comprehensively.
Remark 2. Overall, the judge’s evaluation is decent. It is clear that this answer is better than the
previous one, and indeed the judge’s score is higher. However, the judge made a mistake in saying
that the student “implicitly assumes the state space might be finite,” while the problem explicitly
states that the Markov chain is on a finite state space. In this case, we think the answer deserves a
slightly higher score than the judge’s evaluation.
A.3
Example 3: A Stochastic Modeling Problem
Problem Statement
Consider an inventory model in which demand for a commodity arrives at the end of each
day. Successive demands are i.i.d. with distribution function F(·). The following (s, S) policy
is used: if the inventory level at the beginning of a day is less than or equal to s, we order
up to S, and if the level is greater than s no action is taken. Orders are assumed to filled
instantaneously. Let {Xn}n≥1 be the inventory level at the beginning of the nth day, right
after delivery of inventory (if any). Suppose that X1 = S.
(a) Prove that Xn is regenerative with points of regeneration that are given by the order
epochs.
(b) Let {τn} denote the lengths of the regenerative cycles, derive an expression for Eτ1.
(c) Derive an expression for limn→∞P (Xn ≥k).
Reference Solution
(a) Let T0, T1, T2, . . . be the days we make orders. Since the inventory level at the beginning of
each period [Ti, Ti+1) is S and the demands arriving at the end of each day are independent
and identically distributed, the evolution of the process {Xn} during period [Ti, Ti+1) has
the same probabilistic behavior for all periods. That is, Xn is regenerative with respect to
{Tn}n∈N0.
(b.) Let Dn be the demand arriving at the end of the nth day. Assume that the inventory
level at the beginning of day 1 is X1 = S. The day we make an order (day (τ1 + 1)th) is the
first day we find our inventory level below or equal to s. That is,
τ1 = inf
(
n : S −
n
X
i=1
Di ≤s
)
= 1 + sup
(
n :
n
X
i=1
Di < S −s
)
= 1 +
∞
X
n=1
1{
Pn
i=1 Di<S−s}.
Since the indicator functions are nonnegative, Fubini’s Theorem gives
Eτ1 = 1 +
∞
X
n=1
E
h
1{
Pn
i=1 Di<S−s}
i
= 1 +
∞
X
n=1
P
( n
X
i=1
Di < S −s
)
.
25


--- Page 26 ---
Let F1(·) = F(·) and for n ≥2 let Fn(x) = P {Pn
i=1 Di ≤x} = (F ∗Fn−1) (x). Assuming
that Fn(x) is continuous at x = S −s for all n, we have P {Pn
i=1 Di < S −s} = Fn(S −s).
Therefore,
Eτ1 = 1 +
∞
X
n=1
Fn(S −s).
If for some n, Fn(x) has a jump at x = S −s, then the above expression can be corrected by
replacing Fn(S −s) with limx↑(S−s) Fn(x).
(c) Consider first the case where k ∈(s, S]. During a cycle, the length of time that the
inventory level stays above k is
τ1
X
n=1
1{Xn≥k} = sup
(
n : S −
n−1
X
i=1
Di ≥k
)
= 1 + sup
(
n :
n
X
i=1
Di ≤S −k
)
= 1 +
∞
X
n=1
1{
Pn
i=1 Di≤S−k}
)
.
Since the inventory level never goes above S, we have Pτ1
n=1 1{Xn≥k} = 0 for all k > S.
And since our order policy is to always keep the inventory level above s, it follows that
Pτ1
n=1 1{Xn≥k} = τ1 for all k ≤s. From the regenerative ratio formula,
lim
n→∞P {Xn ≥k} =
1
Eτ1
E
" τ1
X
n=1
1{Xn≥k}
#
=







0,
k > S
1+P∞
n=1 Fn(S−k)
1+P∞
n=1 Fn(S−s),
s < k ≤S
1,
k ≤s
GPT-4o’s Response
To tackle this problem, we need to understand the dynamics of the inventory system under
the given (s, S) policy and analyze it using the concept of regenerative processes.
Part (a)
To prove that Xn is regenerative with points of regeneration given by the order epochs, we
need the definition of a regenerative process. A process is regenerative if there exist random
points in time, called regeneration points, where the process probabilistically starts anew.
In the given inventory system, at the beginning of each day, if the inventory level is less than
or equal to s, an order is placed to bring the inventory up to S. Therefore, every time an
order is placed, the inventory level is reset to S. These order epochs, or times when an order
is placed, naturally serve as regeneration points because the system probabilistically starts
anew with the inventory level at S.
26


--- Page 27 ---
At any time the inventory level Xn is less than or equal to s, an order is made to replenish
the inventory to the level S. Let {Tk} denote the times when ordering occurs. At each Tk, we
have XTk = S. After this time, the future evolution of Xn is independent of the past given
XTk = S, due to the identical independent distribution of demands each day. Hence, {Tk}
serve as regeneration points for {Xn}, making the process Xn regenerative.
Part (b)
Let {τn} be the lengths of the regenerative cycles. We need to derive an expression for E[τ1],
where τ1 is the time between two consecutive order epochs or regenerative points.
The cycle begins at time Tk when XTk = S. The cycle ends at the next time Tk+1 when Xn
falls to or below s, triggering a new order. The length of the cycle τ1 is the first time n such
that the sum of the demands from time Tk to Tk + n −1 brings the inventory to s or below.
Formally, τ1 = min{n ≥1 : S −Pn
i=1 Di ≤s}, where Di are i.i.d. demands with distribution
F. The key is to determine when the cumulative demand Pn
i=1 Di reaches S −s.
To calculate E[τ1], use the fact that τ1 can be seen as a stopping time, the expected number
of demands needed until the cumulative demand reaches the target level S −s. If µ is the
expected demand (µ = E[Di]), then heuristically:
E[τ1] ≈S −s
µ
.
For exact calculation, a recursive method or taking the distribution F into account for the
precise requirement is necessary. However, in simple terms, if {Yn} represents the cumulative
demand, this stopping rule calculation illustrates the expected time until (S −s) units are
demanded.
Part (c)
We are asked to derive limn→∞P(Xn ≥k).This involves studying the limiting distribution of
Xn as the system evolves.
Since Xn is a regenerative process, it has a steady-state distribution as n approaches infinity.
The steady-state probability limn→∞P(Xn ≥k) can be found by considering the proportion
of time Xn spends in states greater than or equal to k relative to a regenerative cycle.
Using the renewal reward theorem for regenerative processes, if the inventory is at level k
or greater at the start of a day, then there was either no demand the previous cycle or the
demands were sufficiently low to not lower it beyond k.
This proportion is influenced by F, the demand distribution, and:
lim
n→∞P(Xn ≥k) =
R S−k
0
(S −x −k)f(x) dx
E[τ1]
,
where f(x) is the probability density function of the demand. The numerator integrates the
probability of the demand being low enough to maintain the inventory level at or above k.
This provides a framework to solve the problem. The exact form relies on integration reflecting
the conditional expectation structure influenced by F.
LLM Judge’s Evaluation
[[74]]
27


--- Page 28 ---
• Part (a): The student’s solution correctly identifies the points of regeneration as times
when orders are made, and outlines why these points serve as regeneration points. They
clearly articulate that after each order epoch, the process probabilistically starts anew with
inventory reset to S, making a strong case for the regenerativity of the process. Overall,
their explanation aligns with the correct reasoning but could have benefited from slightly
more mathematical rigor by explicitly stating the independence criteria and how it leads
to identical behavior in each cycle. This part deserves a high score but loses minor points
for lacking this detail.
• Part (b): The student provides a reasonable explanation of the length of a regenerative
cycle, correctly identifying it as the duration it takes for cumulative demand to reach
(S −s). However, the presented heuristic E[τ1] ≈S−s
µ
lacks the precision and rigor found
in the model solution, which uses an infinite series to find the exact expected cycle length.
The student misses out on formally addressing how E [Pn
i=1 Di < (S −s)] forms part of
the calculation. While they gesture towards a stopping rule approach, their explanation
lacks the necessary formal justification using precise mathematical expressions. There is a
significant gap between the student’s intuition and the detailed formal solution.
• Part (c):
The student’s response is quite vague regarding the actual derivation of
limn→∞P(Xn ≥k). They generically reference the use of a renewal reward theorem and
general integrals but fail to mention or correctly implement the regenerative reward formula
applied to this context, as shown in the correct solution. While the approach mentioned
could be construed broadly correct, it misses formal steps and mathematical justification,
which are critical for reaching the conclusion correctly. Therefore, this section misses key
steps and thus scores lower.
Conclusion: The student demonstrates a fair understanding of the general problem dynamics
and concepts of regenerative processes but lacks the rigor and exactitude seen in the correct
solution as especially for parts (b) and (c). Their interpretations and heuristic approaches,
while correct in spirit, do not suffice for exact derivations required, particularly in a stochastic
modeling context.
Thus, the student’s solution, though containing correct concepts and
intuition, needs further refinement and depth to reach a perfect score.
Remark 3. Overall, the judge’s evaluation is reasonable. This answer is clearly worse than the
previous two, and the judge’s score is lower. Depending on how harsh the grader is, the score may
be lower, but the judge is correct in identifying where the answer is lacking.
B
Example Qualification Exam Problem
Problem Statement
Consider a non-preemptive FIFO queue with infinite buffer. Requests arrive according to a
Poisson process with rate λ, and each has i.i.d. workload w ∼Exp(µ). The service proceeds
as follows. Each request is initially processed for up to θ time units. If completed within θ, it
exits the system and the next request (if any) begins service. If not, then the system restarts
service in a mode that is divided into two steps: 1) the request is broken into n sub-tasks that
are executed in parallel by n servers, where the processing times of the sub-tasks are i.i.d.,
28


--- Page 29 ---
uniformly distributed in the interval [0.5w/n, 1.5w/n]; and 2) the results of all n sub-tasks are
combined to complete the service of the original request, in a step that can only commence
after all n sub-tasks are completed and its duration is exponentially distributed with rate 2µ,
independent of the processing times of the sub-tasks and of the processing requirements of
any other requests.
(a) What is the stability condition for the system?
(b) What is the steady-state expected sojourn time for a new request? The sojourn time
includes the waiting time in the queue and the service time.
Reference Solution
We have a M/G/1 queue, so the problem boils down to understanding the service time
distribution and using the Pollaczek-Khinchine formula. The service time S satisfies
S =
(
W,
W ≤θ,
θ + max1≤i≤n Ui + D,
W > θ,
where W ∼Exp(µ), Ui ∼Unif[0.5W/n, 1.5W/n] are i.i.d., and D ∼Exp(2µ).
We first consider the stability condition. Since we have a M/G/1 queue, the system is stable
if and only if λE[S] < 1, so we need to calculate E[S]. Conditioned on W = w,
Ui ∼a + (b −a)Xi,
a = 0.5w
n
, b = 1.5w
n
, Xi ∼Unif[0, 1].
So, conditioned on W = w,
Mn := max
1≤i≤n Ui = a + (b −a)Yn,
Yn := max
1≤i≤n Xi.
By elementary calculations, E[Yn] =
n
n+1. So,
E[ max
1≤i≤n Ui|W = w] = Cw,
C =
3n + 1
2n(n + 1).
Since D is independent of W, the expected service time is
E[S] =
Z θ
0
wµe−µwdw +
Z ∞
θ
θµe−µwdw +
Z ∞
θ
Cwµe−µwdw +
Z ∞
θ
1
2µµe−µwdw.
By integration-by-parts, we have
E[S] = 1 −e−µθ
µ
+ e−µθ

Cθ + C
µ + 1
2µ

.
Hence, the system is stable if and only if
λ
1 −e−µθ
µ
+ e−µθ

Cθ + C
µ + 1
2µ

< 1.
This answers part (a).
29


--- Page 30 ---
For part (b), by the Pollaczek-Khinchine formula, the average sojourn time is
E[S] +
λE[S2]
2(1 −λE[S]).
So, it suffices to calculate E[S2]. We have
E[S2] =
Z θ
0
w2µe−µwdw +
Z ∞
θ

θ + 1
2µ + Cw
2
µe−µwdw.
Again using integration-by-parts, we arrive at
E[S2] = 2
µ2 +(C2−1)e−µθ µ2θ2 + 2µθ + 2
µ2
+2C

θ + 1
2µ
 
θe−µθ + e−µθ
µ

+

θ + 1
2µ
2
e−µθ.
GPT-4o’s Response
Let’s rigorously analyze the problem by decomposing the dynamics and computing the nec-
essary quantities step by step.
(a) Stability Condition
Let us first compute the expected service time for a request, which includes two possibilities:
Service Modes:
1. Fast Completion: The request completes within time θ, i.e., workload w ≤θ.
2. Slow Path (with Parallel Sub-tasks): The request exceeds θ, i.e., w > θ, and is
processed via parallel sub-tasks and an additional final combination step.
Step 1: Probability of Fast vs Slow Path
Since w ∼Exp(µ), we have:
P(w ≤θ) = 1 −e−µθ,
P(w > θ) = e−µθ
Step 2: Expected Service Time for Each Path
Let us compute the expected service time S by conditioning on whether w ≤θ or w > θ.
Fast Completion (w ≤θ):
In this case, the actual service time is just w, conditioned on w ≤θ. So the expected service
time in this case is:
E[w | w ≤θ] = 1
µ −
θe−µθ
1 −e−µθ .
This follows from the standard formula for the conditional expectation of an exponential
distribution:
E[w | w ≤θ] = 1
µ −
θe−µθ
1 −e−µθ ,
So the contribution from this branch is:
(1 −e−µθ) · E[w | w ≤θ].
30


--- Page 31 ---
Slow Path (w > θ): This includes:
1. Initial serial processing of time θ (before branching).
2. Parallel stage: Sub-tasks with uniform durations.
• Each sub-task is uniform over [0.5w/n, 1.5w/n].
• Since sub-tasks are run in parallel, total processing time is the maximum of n i.i.d.
uniforms over this interval.
• The interval is of length w/n, and the max of n i.i.d. Unif(a, b) has mean:
E[max Ui] = b −b −a
n + 1 ⇒E[max Ui] = 1.5w
n
−
w
n(n + 1).
Hence:
E[max subtask time | w] = 1.5w
n
−
w
n(n + 1) = w
n

1.5 −
1
n + 1

.
3. Final combination stage: Exponential with rate 2µ, so mean 1/(2µ).
Now, take the expectation over w, conditioned on w > θ. The conditional density is:
f(w | w > θ) = µe−µ(w−θ),
w > θ.
Then the total expected service time for the slow path is:
θ + E
w
n

1.5 −
1
n + 1
 w > θ

+ 1
2µ.
We compute:
E[w | w > θ] = θ + 1
µ ⇒E
w
n

1.5 −
1
n + 1
 w > θ

= 1
n

1.5 −
1
n + 1
 
θ + 1
µ

.
So total contribution from this branch:
e−µθ

θ + 1
n

1.5 −
1
n + 1
 
θ + 1
µ

+ 1
2µ

.
Step 3: Total Expected Service Time
Add contributions from both paths:
E[S] = (1 −e−µθ)
 1
µ −
θe−µθ
1 −e−µθ

+ e−µθ

θ + 1
n

1.5 −
1
n + 1
 
θ + 1
µ

+ 1
2µ

.
Simplify the first term:
(1 −e−µθ)
 1
µ −
θe−µθ
1 −e−µθ

= 1
µ(1 −e−µθ) −θe−µθ,
31


--- Page 32 ---
So the full expression is:
E[S] = 1
µ(1 −e−µθ) −θe−µθ + e−µθ

θ + 1
n

1.5 −
1
n + 1
 
θ + 1
µ

+ 1
2µ

.
Stability Condition
A queue is stable if the arrival rate is less than the service capacity:
λ · E[S] < 1.
So the stability condition is:
λ ·
 1
µ(1 −e−µθ) −θe−µθ + e−µθ

θ + 1
n

1.5 −
1
n + 1
 
θ + 1
µ

+ 1
2µ

< 1.
(b) Steady-State Expected Sojourn Time We use Pollaczek-Khinchine (P-K) formula
for an M/G/1 queue:
E[T] = E[S] +
λE[S2]
2(1 −λE[S]).
We already computed E[S]. Now we compute E[S2]. This requires computing:
E[S2] = E[S2 | w ≤θ] · P(w ≤θ) + E[S2 | w > θ] · P(w > θ).
This is algebraically heavy but doable. For w ≤θ, S = w, so
E[S2 | w ≤θ] = E[w2 | w ≤θ] = 2
µ2 −
2θe−µθ
µ(1 −e−µθ) −
 1
µ −
θe−µθ
1 −e−µθ
2
.
For w > θ, you need to square the expression from the slow path (sum of constants and
linear in w), then take expectation over exponential tail w > θ. It’s complicated but follows
standard techniques.
In practice, we can either:
• Leave the answer in terms of E[S] and E[S2] and note that they can be computed as above.
• If only E[S] is known, we can approximate or simulate E[T] if needed.
LLM Judge’s Evaluation
[[92]] Evaluation of the Student’s Solution
Correctness and Completeness Breakdown
Part (a): Stability Condition
• The student correctly identifies that this is an M/G/1 queue and that stability is charac-
terized by the condition λE[S] < 1.
32


--- Page 33 ---
• The decomposition of the service time into the two branches based on whether w ≤θ or
w > θ is done properly.
• The student correctly computes the probabilities P(w ≤θ) and P(w > θ) for exponential
w.
• In the fast path case, the student uses the conditional expectation of w given w ≤θ:
E[w | w ≤θ] = 1
µ −
θe−µθ
1 −e−µθ ,
which is correct.
• In the slow path case, the student computes the expected maximum of n i.i.d. uniforms
via the standard result:
E[max Ui] = b −b −a
n + 1.
This matches the correct derivation in the reference solution and shows a correct under-
standing of order statistics.
• The conditional expectation E[w | w > θ] = θ + 1/µ is correctly derived from the memory-
less property of exponentials.
• The final expression for E[S] is carefully constructed, clearly explained, and algebraically
correct.
• Minor deduction (-3 pts): The student did not write the full simplified expression for E[S]
in a compact closed-form like in the official solution. While this is a matter of presentation,
it is slightly less complete than the reference solution.
• Minor deduction (-1 pt): The student does not explicitly name the constant C =
3n+1
2n(n+1),
even though they compute its equivalent as
1.5−
1
n+1
n
. It would have made comparisons more
straightforward.
Part (b): Steady-State Expected Sojourn Time
• The student correctly cites the Pollaczek-Khinchine (P-K) formula:
E[T] = E[S] +
λE[S2]
2(1 −λE[S]),
and outlines the plan to compute E[S2].
• For the w ≤θ case, the student correctly computes E[w2 | w ≤θ] and provides the correct
formula for a truncated exponential second moment. That’s mathematically valid.
• For w > θ, the student notes that the expression is more involved and does not carry out
the full derivation, but provides a roadmap of how to do it: square the expression, expand
terms, and integrate over exponential tail.
33


--- Page 34 ---
• Deduction (-4 pts): The student does not complete the derivation of E[S2] explicitly. While
this is algebraically demanding, the reference solution does carry it through. Thus, the stu-
dent’s solution is not fully complete. However, the student does recognize how to approach
it and signals the necessary steps, which shows understanding.
Overall Strengths
• Clear structure, good use of notation and conditioning.
• Sound probabilistic reasoning throughout.
• Full derivation of E[S], which is the most important part of the problem.
• Strong and correct application of standard queueing theory formulas.
Suggestions for Improvement
• Provide closed-form expressions where possible for comparison and simplification.
• Carry through all integrals explicitly when required (as in E[S2]), even if tedious.
• Clarify constants (like C) for ease of checking against known solutions.
Final Score: [[92]] The student’s solution is mathematically correct and logically clear, with
only minor deductions for not simplifying fully and not completing the computation of the
second moment.
Remark 4. We largely agree with the judge that the student did a good job overall. We would
give a lower score for not carrying out the calculation of E[S2], but we think the judge correctly
identifies the student’s answer’s strengths and weaknesses.
C
Example SimOpt Problem: Chess Matchmaking (ChessMM)
C.1
Problem and Prompt
This problem involves matching players on an online chess platform to minimize the average Elo
difference between matched pairs, while ensuring that the average waiting time does not exceed a
specified threshold (delta=5.0). In this setting, players arrive according to a Poisson process and
their Elo ratings are sampled from a truncated normal distribution over the interval [0,2400]. The
prompt for this problem is as follows (adapted for better exposition):
Prompt Template for SimOpt Problems
You’re an expert in stochastic modeling and you’re tasked to solve the following problem.
—————————————— Objective ——————————————
Minimize the average Elo difference between matched players, subject to the constraint that the
average waiting time does not exceed a specified threshold delta (or upper_time).
34


--- Page 35 ---
—————————————— Problem Description ——————————————
We have an online chess platform where players arrive according to a stationary Poisson process with
rate lambda. Each player has an Elo rating drawn from a truncated normal distribution with mean
1200 and standard deviation 1200/(sqrt(2)*erfcinv(1/50)). This distribution is truncated at 0
and 2400, giving approximately 0 as the 1st percentile and 2400 as the 99th percentile.
When a new player arrives, the platform attempts to match them with a waiting player whose Elo
rating differs by at most x (the allowable_diff parameter). If no such waiting player exists, they
join the waiting pool until a new arrival (or an existing waiting player) matches with them. We
simulate the process for num_players players.
—————————————— Model Factors (Defaults) ——————————————
• elo_mean = 1200.0
• elo_sd = 1200/(sqrt(2)*erfcinv(1/50))
• poisson_rate = 1.0
• num_players = 1000
• allowable_diff = 150.0 (default matching threshold)
• delta = 5.0 (average waiting time upper bound)
—————————————— Responses ——————————————
• avg_diff: The average Elo difference between all matched pairs.
• avg_wait_time: The average waiting time to get matched.
—————————————— Requirements ——————————————
1. Analytical / Closed-Form Approach
• If possible, derive or approximate an analytical expression for the average Elo difference under
a given matching threshold x, subject to the arrival rate and rating distribution. Discuss any
assumptions or simplifying approximations.
2. Simulation-Based Approach
• If an analytical formula is difficult, develop a simulation:
– Generate num_players ratings from the truncated normal distribution.
– Players arrive according to a Poisson process with rate lambda.
– Use a matching policy that pairs any new arrival with a waiting player whose rating is within
x, if such a player exists.
– Record the waiting times and the Elo differences for each matched pair.
• You have a budget [BUDGET] (e.g., 1000) for how many candidate x values you can test or how
many simulations you can run.
3. Performance Measures & Validation
• The main objective is to minimize avg_diff.
• However, we also have a constraint: avg_wait_time ≤delta (or some upper_time threshold).
• Compare your final solution to baseline x=150 or other naive thresholds to show improvement.
—————————————— Deliverables ——————————————
1. Solution Explanation
35


--- Page 36 ---
• Summarize how you decide an optimal or near-optimal allowable_diff (x).
• If you use a simulation approach, explain your search or optimization strategy within the
[BUDGET] limit.
2. Code (if provided)
• Put it in a single fenced block:
```python
# ...your code...
```
• Must be self-contained, using only standard libraries (e.g., random, numpy).
3. Results
• Recommend an allowable_diff value.
• Report the resulting avg_diff and avg_wait_time, plus any confidence intervals or variance
estimates.
—————————————— Testing Notes ——————————————
• We will test your approach with different budgets (100, 500, 1000).
• We may also vary the arrival rate lambda or the rating distribution slightly.
• If you simulate, ensure it runs within feasible time for the given number of players.
—————————————— Success Criteria ——————————————
• Feasibility: The solution respects 0 ≤x ≤2400.
• Constrained: The average wait time must be ≤delta.
• Improvement: The average Elo difference is reduced compared to naive solutions like x=150, while
meeting wait time constraints.
—————————————— Final Instructions ——————————————
• If an analytical approach is too complex, propose heuristics or approximate solutions.
• If simulating, detail your method for generating arrivals and ratings, matching logic, and measuring
performance.
C.2
GPT-4o’s Solution
Below is GPT-4o’s solution to the problem. In short, it implements a line search over the full range
[0, 2400]. Although this strategy is comprehensive, searching over such a broad range may dilute
the effectiveness of each function call, leading to a higher average Elo difference.
import numpy as np
from scipy.stats import truncnorm
# Define parameters
elo_mean = 1200.0
elo_sd = 515.8299897407918
poisson_rate = 1.0
num_players = 1000
36


--- Page 37 ---
delta = 5.0
budget = 1000 # Adjust this as needed for testing different budgets
min_x, max_x = 0, 2400
# Truncated normal distribution for ratings
a, b = (0 - elo_mean) / elo_sd, (2400 - elo_mean) / elo_sd
def simulate_matching_process(x, num_players, lambda_rate, elo_mean, elo_sd, a, b):
# Generate player ratings
ratings = truncnorm.rvs(a, b, loc=elo_mean, scale=elo_sd, size=num_players)
# Generate arrival times as a Poisson process
arrival_times = np.cumsum(np.random.exponential(1 / lambda_rate,
size=num_players))
# Initialize waiting pool and performance metrics
waiting_pool = []
total_elo_diff = 0
total_wait_time = 0
num_matches = 0
for i in range(num_players):
current_player = (ratings[i], arrival_times[i])
# Try to find a match from the waiting pool
match_found = False
for j, (waiting_rating, waiting_time) in enumerate(waiting_pool):
if abs(waiting_rating - current_player[0]) <= x:
# Match found
total_elo_diff += abs(waiting_rating - current_player[0])
total_wait_time += current_player[1] - waiting_time
num_matches += 1
# Remove the matched player from the pool
waiting_pool.pop(j)
match_found = True
break
# If no match was found, add player to the waiting pool
if not match_found:
waiting_pool.append(current_player)
avg_diff = total_elo_diff / num_matches if num_matches > 0 else float(’inf’)
avg_wait_time = total_wait_time / num_matches if num_matches > 0 else
float(’inf’)
return avg_diff, avg_wait_time
# Optimize x within budget
optimal_x = min_x
best_avg_diff = float(’inf’)
37


--- Page 38 ---
for x in np.linspace(min_x, max_x, num=budget):
avg_diff, avg_wait_time = simulate_matching_process(x, num_players,
poisson_rate, elo_mean, elo_sd, a, b)
if avg_wait_time <= delta and avg_diff < best_avg_diff:
best_avg_diff = avg_diff
optimal_x = x
print(f"Recommended allowable_diff (x): {optimal_x}")
print(f"Resulting avg_diff: {best_avg_diff}")
# run the above thing 1000 times to get mean and std for the best_avg_diff
num_trials = 1000
avg_diffs = []
for _ in range(num_trials):
avg_diff, _ = simulate_matching_process(optimal_x, num_players, poisson_rate,
elo_mean, elo_sd, a, b)
avg_diffs.append(avg_diff)
# print the mean and std dev for the avg_diff
mean_avg_diff = np.mean(avg_diffs)
std_avg_diff = np.std(avg_diffs)
best_avg_diff = mean_avg_diff
print(f"Mean avg_diff over {num_trials} trials: {mean_avg_diff:.4f}")
print(f"Standard deviation of avg_diff over {num_trials} trials:
{std_avg_diff:.4f}")
C.3
Claude’s Solution
Below is Claude’s solution to the problem. In short, it implements a binary search over the range
[0, 2400]. This strategy is more efficient than the line search used by GPT-4o, as it narrows down
the search space more quickly.
import numpy as np
from scipy.stats import truncnorm
import heapq
from collections import defaultdict
class ChessMatchingSimulator:
def __init__(self, elo_mean=1200.0, arrival_rate=1.0, num_players=1000):
self.elo_mean = elo_mean
self.elo_sd = 1200 / (np.sqrt(2) * -np.log(1/100)) # Approximating erfcinv
self.arrival_rate = arrival_rate
self.num_players = num_players
def generate_ratings(self):
a, b = (0 - self.elo_mean) / self.elo_sd, (2400 - self.elo_mean) /
self.elo_sd
38


--- Page 39 ---
ratings = truncnorm.rvs(a, b, loc=self.elo_mean, scale=self.elo_sd,
size=self.num_players)
return ratings
def simulate_matching(self, allowable_diff):
# Generate players and arrival times
ratings = self.generate_ratings()
arrivals = np.random.exponential(1/self.arrival_rate, self.num_players)
arrival_times = np.cumsum(arrivals)
waiting_players = [] # (rating, arrival_time, player_id)
matches = [] # (player1_id, player2_id, wait_time, elo_diff)
for i, (rating, arrival) in enumerate(zip(ratings, arrival_times)):
# Try to match with waiting player
best_match = None
best_diff = float(’inf’)
best_idx = -1
for j, (w_rating, w_arrival, w_id) in enumerate(waiting_players):
diff = abs(rating - w_rating)
if diff <= allowable_diff and diff < best_diff:
best_match = (w_id, w_arrival)
best_diff = diff
best_idx = j
if best_match is not None:
# Make the match
w_id, w_arrival = best_match
wait_time = max(arrival - w_arrival, 0)
matches.append((w_id, i, wait_time, best_diff))
waiting_players.pop(best_idx)
else:
# Add to waiting pool
waiting_players.append((rating, arrival, i))
# Calculate metrics
if not matches:
return float(’inf’), float(’inf’)
avg_diff = np.mean([m[3] for m in matches])
avg_wait = np.mean([m[2] for m in matches])
return avg_diff, avg_wait
def binary_search_threshold(self, target_wait_time, tolerance=0.1):
left, right = 0, 2400
best_x = None
best_metrics = None
while (right - left) > tolerance:
x = (left + right) / 2
39


--- Page 40 ---
avg_diff, avg_wait = self.simulate_matching(x)
if avg_wait <= target_wait_time:
# This is feasible, try to reduce x
if best_x is None or avg_diff < best_metrics[0]:
best_x = x
best_metrics = (avg_diff, avg_wait)
right = x
else:
# Need to increase x
left = x
return best_x, best_metrics
def optimize_matching(budget=1000):
simulator = ChessMatchingSimulator()
# Use binary search within budget
optimal_x, (final_diff, final_wait) = simulator.binary_search_threshold(
target_wait_time=5.0
)
return {
’recommended_threshold’: optimal_x,
’avg_elo_difference’: final_diff,
’avg_wait_time’: final_wait
}
# Example usage
if __name__ == "__main__":
result = optimize_matching(budget=1000)
print(f"Recommended allowable_diff (x): {result[’recommended_threshold’]:.2f}")
print(f"Resulting average Elo difference: {result[’avg_elo_difference’]:.2f}")
print(f"Resulting average waiting time: {result[’avg_wait_time’]:.2f}")
# run the code 1000 times to get mean and std for the best_avg_diff
num_trials = 1000
avg_diffs = []
for _ in range(num_trials):
simulator = ChessMatchingSimulator()
avg_diff, _ = simulator.simulate_matching(result[’recommended_threshold’])
avg_diffs.append(avg_diff)
mean_avg_diff = np.mean(avg_diffs)
std_avg_diff = np.std(avg_diffs) if len(avg_diffs) > 1 else 0.0
print(f"Mean average Elo difference over {num_trials} trials:
{mean_avg_diff:.4f}")
print(f"Standard deviation of average Elo difference: {std_avg_diff:.4f}")
40
