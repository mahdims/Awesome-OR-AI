--- Page 1 ---
1
Task-Oriented Computation Ofﬂoading for Edge
Inference: An Integrated Bayesian Optimization and
Deep Reinforcement Learning Framework
Xian Li, Senior Member, IEEE, Suzhi Bi, Senior Member, IEEE, and Ying-Jun Angela Zhang, Fellow, IEEE
Abstract—Edge intelligence (EI) allows resource-constrained
edge devices (EDs) to ofﬂoad computation-intensive AI tasks (e.g.,
visual object detection) to edge servers (ESs) for fast execution.
However, transmitting high-volume raw task data (e.g., 4K video)
over bandwidth-limited wireless networks incurs signiﬁcant la-
tency. While EDs can reduce transmission latency by degrading
data before transmission (e.g., reducing resolution from 4K to
720p or 480p), it often deteriorates inference accuracy, creating a
critical accuracy-latency tradeoff. The difﬁculty in balancing this
tradeoff stems from the absence of closed-form models capturing
content-dependent accuracy-latency relationships. Besides, under
bandwidth sharing constraints, the discrete degradation decisions
among the EDs demonstrate inherent combinatorial complex-
ity. Mathematically, it requires solving a challenging black-box
mixed-integer nonlinear programming (MINLP). To address this
problem, we propose LAB, a novel learning framework that
seamlessly integrates deep reinforcement learning (DRL) and
Bayesian optimization (BO). Speciﬁcally, LAB employs: (a) a
DNN-based actor that maps input system state to degradation
actions, directly addressing the combinatorial complexity of the
MINLP; and (b) a BO-based critic with an explicit model
built from ﬁtting a Gaussian process surrogate with historical
observations, enabling model-based evaluation of degradation
actions. For each selected action, optimal bandwidth allocation
is then efﬁciently derived via convex optimization. Numerical
evaluations on real-world self-driving datasets demonstrate that
LAB achieves near-optimal accuracy-latency tradeoff, exhibiting
only 1.22% accuracy degradation and 0.07s added latency com-
pared to exhaustive search. Notably, it outperforms conventional
DRL with 3.29% higher accuracy and 42.60% lower latency,
demonstrating its advantageous performance in handling black-
box optimization problems.
Index Terms—Edge intelligence, Bayesian optimization, deep
reinforcement learning, computation ofﬂoading.
I. INTRODUCTION
Edge inference (EI) enables resource-constrained edge de-
vices (EDs) to execute computation-intensive AI tasks (e.g.,
pedestrian detection for autonomous vehicles [1], [2]) through
task-oriented computation ofﬂoading. This paradigm ofﬂoads
computations from EDs to proximal edge servers (ESs) to opti-
mize task-speciﬁc performance metrics like detection accuracy.
However, transmitting high-ﬁdelity raw data over bandwidth-
limited wireless links incurs signiﬁcant latency. To address
Xian Li and Suzhi Bi are with The State Key Laboratory of Radio
Frequency Heterogeneous Integration (Shenzhen University), and also with
the College of Electronics and Information Engineering, Shenzhen University,
Shenzhen, China 518060.(email: {xianli, bsz}@szu.edu.cn).
Ying-Jun Angela Zhang is with the Department of Information En-
gineering, The Chinese University of Hong Kong, Hong Kong (email:
yjzhang@ie.cuhk.edu.hk).
Local Degradation
ED 1
...
0
1
Level
...
0
1
Edge Analytics
...
 
ED
...
...
...
...
...
...
...
...
...
...
...
Image
Offloading
ES
...
Task 
AI model
Level
Fig. 1: An example of task-oriented computation ofﬂoading in an EI system
for visual object detection.
this, EDs may perform data degradation before transmission.
As Fig. 1 illustrates for visual object detection, EDs can
select from multiple degradation levels and downsample high-
resolution (e.g., 4K) video streams to lower-resolution (e.g.,
720p or 480p). While this degradation reduces transmission
latency, it sacriﬁces inference accuracy, creating an inherent
accuracy-latency tradeoff. To achieve an optimal tradeoff un-
der time-varying channel and content, an adaptive ofﬂoading
scheme is required.
Designing adaptive ofﬂoading for edge-AI inference tasks
presents fundamental challenges. Crucially, AI inference qual-
ity is highly sensitive to the task content. Identical degrada-
tion operations (e.g., the same degradation level) may yield
divergent accuracy outcomes for different input contents. For
example, in visual object detection, sparse scenes (e.g., a
single vehicle on an empty street) often tolerate aggressive
degradation as critical features remain discernible, whereas
complex scenes (e.g., crowded pedestrian crossings) demand
high-ﬁdelity inputs to maintain recognition accuracy. Unlike
conventional data-centric metrics (e.g., computation rate and
energy consumption) which have explicit formulations, task-
speciﬁc metrics like accuracy exhibit strong content depen-
dency, making it difﬁcult to build closed-form analytical
models. Instead, it creates black-box optimization problems
that require computationally heavy experimental evaluations.
Besides, practical EI deployments typically involve multiple
EDs competing for limited bandwidth resources. Optimizing
system-wide performance thus requires joint coordination of
both discrete degradation choice per ED and continuous band-
width allocation across competing devices. The tight coupling
of hybrid decision variables, compounded by the absence of a
closed-form objective function, poses a challenging black-box
arXiv:2509.21090v1  [cs.IT]  25 Sep 2025


--- Page 2 ---
2
mixed-integer nonlinear programming (MINLP) problem.
Due to the black-box nature, conventional MINLP solvers
(e.g., branch-and-bound [3] and metaheuristics like particle
swarm optimization (PSO) [4]) are fundamentally unsuited for
dynamic EI environments. Their trial-based nature requires
on-device execution of multiple candidate actions to select
the best one. For instance, PSO requires EDs to transmit
numerous degraded versions to the ES to ﬁnd the best action
from its particle swarm candidates. Such trial-and-execute
operations consume substantial bandwidth and computational
resources, rendering them fundamentally incompatible with
latency-sensitive EI systems. Alternatively, Bayesian optimiza-
tion (BO) [5] overcomes this limitation by eliminating the on-
device execution of candidate actions. Speciﬁcally, it builds
probabilistic surrogate models of black-box objective function
from historical observations, and designs acqusition functions
to select proper actions [6]. However, standard BO becomes
computationally prohibitive for MINLP problems at practical
network scales, where the global optimization of the acquisi-
tion function is impeded by the combinatorial action selection.
While deep reinforcement learning (DRL) [7], [8] enables
rapid decision-making for adaptive ofﬂoading, its model-free
nature requires extensive environmental interactions to train its
policy. This results in poor sample efﬁciency and premature
convergence to ineffective polices, hindering its application in
dynamic EI environments.
In this paper, we propose a novel learning framework for
task-oriented computation ofﬂoading that combines the real-
time decision-making strength of DRL with the sample efﬁ-
ciency of BO. As shown in Fig. 1, we consider multiple EDs
performing visual object detection tasks, and aim to maximize
the long-term average detection accuracy while minimizing
inference latency. The main contributions are summarized as
follows:
• Task-oriented Joint Computation Ofﬂoading and Re-
source Allocation: We formulate a joint computation
ofﬂoading and resource allocation problem to optimize
task-speciﬁc objectives including detection accuracy and
latency. The major challenge lies in the lack of an explicit
closed-form function that maps optimization variables
to the objective. Besides, the combinatorial nature of
discrete degradation control variables across EDs pro-
hibits real-time adaptation to fast-varying wireless envi-
ronments.
• Integrated DRL and BO Framework: To solve the target
problem, we propose LAB, a novel learning framework
that seamlessly integrates the real-time decision-making
of DRL and the model-based evaluation of BO. Speciﬁ-
cally, LAB features a DNN-based actor that generates a
compact set of high-potential degradation actions given
an input system state, thereby overcoming the combina-
torial complexity. These candidate degradation actions
are then evaluated by a BO-based critic, which ﬁts
a probabilistic surrogate model on historical execution
data and analytically ranks candidate actions via closed-
form acqusition functions. For the selected highest-ranked
action, the optimal bandwidth allocation is derived via
convex optimization.
• Exploration-Efﬁcient
Actor
Design:
We
design
an
exploration-efﬁcient DNN-based actor that generates a
diverse yet high-quality set of candidate degradation
actions by sampling near high-preference regions of the
DNN’s output space. The actor dynamically adjusts the
candidate set size according to the distance between
empirically optimal actions and the DNN’s predicted
preference. Larger distances trigger expansion of the ex-
ploration range to discover potentially better actions, and
vice versa. Such a self-adjusting mechanism maintains
an efﬁcient exploration-exploitation trade-off, enabling
robust adaptation to dynamic visual environments without
compromising computational efﬁciency.
• Real-World Dataset Validation: We evaluate LAB on a
real-world self-driving dataset for object detection. The
LAB framework demonstrates: (a) Near-ideal accuracy
with merely 1.22% performance deﬁcit and only 0.07s
additional end-to-end inference latency versus exhaustive
search; (b) 3.29% higher accuracy with 42.60% lower
latency than conventional DRL approaches; (c) 32.96%
faster inference than standard BO at equivalent accuracy,
with computation overhead reduced to less than 1/2000
of the original.
II. RELATED WORKS
Computation ofﬂoading is a well-established technique in
mobile edge computing (MEC), enabling resource-constrained
EDs to leverage a nearby ES for executing demanding tasks.
Conventional MEC ofﬂoading strategies primarily follow two
paradigms: binary ofﬂoading [9]–[11], where tasks are ex-
ecuted entirely locally or remotely, and partial ofﬂoading
[12]–[16], which partitions computational workloads between
EDs and the ES. Despite effectively optimizing system-level
metrics (e.g., computation rate, energy consumption) using
explicit objectives, these data-centric approaches treat task data
as generic payloads, ignoring its critical role as content carrier
for AI performance. As a result, they disregard how processing
operations (e.g, resolution degradation) alter input content
and consequently degrade task-speciﬁc performance such as
inference accuracy. Conventional ofﬂoading strategies [9]–[16]
therefore fail to optimize the accuracy-latency tradeoff in EI
systems.
Emerging approaches mitigate this challenge by explic-
itly characterizing action-to-performance relationships through
empirical modeling. For example, Yang et al. [17] ﬁtted an
empirical model between synthesis accuracy and denoising
steps in diffusion models using DreamBooth simulations [18],
enabling the joint optimization of user scheduling and denois-
ing partitions to balance latency and accuracy. Similarly, Liu
et al. [19] leveraged pre-deployment proﬁling of DNNs (e.g.,
ResNet) to establish monotonic layer-to-accuracy relationships
in multi-user EI systems with early exiting. Building on this
foundation, they jointly optimized user scheduling and exit-
point selection to maximize system throughput under per-
user latency and accuracy constraints. While effective in static
environments, these empirical ﬁtting-based approaches [17],
[19] require substantial task-speciﬁc data collection to build


--- Page 3 ---
3
models, and their static mappings cannot adapt to dynamic
environments during operation.
To address environmental dynamics, researchers have devel-
oped online learning optimizers that continuously reﬁne deci-
sions through real-time feedback. Representative approaches
includes DRL frameworks [20] and BO-based strategies [21],
[22]. For instance, Wang et al. [20] proposes a real-time DRL
solution for joint frame-resolution adaptation and bandwidth
allocation in edge video analytics to balance latency and
detection accuracy. While standard DRL enables online policy
updates, its model-free treatment of action-to-performance re-
lationships demands intensive environmental interactions dur-
ing training. This ultimately undermines its resilience to rapid
changes and raises the risk of non-convergence in dynamic
environments. In contrast, BO-based approaches offer a com-
plementary solution by constructing sample-efﬁcient surrogate
models. For example, Galanopoulos et al. [22] pioneered an
AutoML framework for video analytics conﬁguration using
BO principles, avoiding costly trial executions through surro-
gate model-based evaluation. Similarly, Tang et al. [21] applied
BO to the identical joint adaptation problem addressed by [20],
achieving comparable accuracy-latency performance while
demonstrating superior temporal stability and user fairness.
Both BO strategies, however, face computational intractability
when optimizing hybrid discrete-continuous action spaces at
large network scales. Such intractability stems from the com-
binatorial explosion during acquisition function maximization,
incurring prohibitive decision latency incompatible with real-
time EI processing demands.
Given the advantages of both approaches, Gong et al.
[23] stand as one of the earliest and still rare attempts at
combining BO and DRL, demonstrated in the context of
UAV trajectory optimization. Crucially, their method treats BO
and the DRL actor as parallel action generators, producing
competing actions subsequently evaluated and selected by a
conventional DNN-based critic. This structure maintains a
black-box evaluation process and consequently inherits core
DRL limitations in adaptation speed and sample efﬁciency.
In contrast, our work introduces a fundamentally redesigned
DRL-BO framework. Within this architecture, a DNN-based
actor efﬁciently identiﬁes candidate solutions while a dedi-
cated BO-based critic performs rapid evaluation using closed-
form acquisition functions. This integrated design takes ad-
vantage of complementary strengths of BO and DRL to
efﬁciently tackle black-box optimization problems in dynamic
EI environments.
III. SYSTEM MODEL AND PROBLEM FORMULATION
A. System Model
As shown in Fig. 1, we consider an EI system consisting of
an ES supporting N ≥1 EDs. The system operates over T > 0
sequential time slots, with each ED performing an individual
object detection task per slot. Due to the constrained compu-
tational resources at the EDs, the task AI model supporting
multi-resolution inputs resides on the ES. Each ED collects
RGB images from its surrounding environment and relies on
the ES for edge processing. During each time slot t, the system
executes a sequential workﬂow comprising local degradation
at EDs, image ofﬂoading to the ES, and edge analytics at the
ES.
1) Local Degradation: At the beginning of time slot t, each
EDn (1 ≤n ≤N) captures a raw image at native resolution
ro
n = (ιw
n, ιh
n), where ιw
n and ιh
n denote the pixel dimensions
in width and height, respectively. To alleviate communication
overhead, EDn optionally applies local degradation techniques
to reduce transmission data volume. In this paper, we imple-
ment local degradation through Gaussian pyramid downsam-
pling [24], which utilizes dyadic spatial scaling for resolution
reduction. Speciﬁcally, EDn selects an integer degradation
level at,n from a ﬁnite discrete set A = {0, 1, · · · , A −1},
where A denotes the maximum available degradation levels.
Then, the ofﬂoading resolution of EDn during time slot t is
rt,n =
 ιw
n
2at,n ,
ιh
n
2at,n

,
(1)
where at,n = 0 preserves native resolution, and each integer
increment of at,n halves spatial dimensions. The computa-
tional latency τd
t,n required for this resolution adaptation is
given by:
τ d
t,n = fd(ro
n, at,n; ψd
n),
(2)
where fd(·) is a device-speciﬁc function and ψd
n characterizes
the computational efﬁciency parameter of the EDn [20].
2) Image Ofﬂoading: Following local degradation, each ED
transmits its processed image to the ES for inference. To avoid
co-channel interference among EDs, we implement frequency
division multiple access (FDMA) for uplink transmissions,
where the total system bandwidth W is dynamically allocated
to EDs. Let bt,nW represent the bandwidth allocated to the
EDn during time slot t, where bt,n ≥0 is the fractional
allocation variable satisfying that
N
X
n=1
bt,n ≤1, ∀t = 1, · · · , T.
(3)
The transmission rate for EDn is
Rt,n = bt,nW log2

1 + pnht,n
bt,nWδ2

,
(4)
where pn is the ﬁxed transmit power at the EDn. δ2 is
the power spectrum density of additive white Guassian noise
(AWGN) at the ES. ht,n denotes the channel gain between
the EDn and the ES during time slot t. We consider a block
fading scenario where ht,n remains constant during time slot
t but varies independently across time slots.
Given the ofﬂoading resolution rt,n in (1), the ofﬂoading
data size dt,n in bits for an RGB image with 24 bits/pixel (i.e.,
3 color channels/pixel × 8 bits/channel) is computed as
dt,n =
ιw
n
2at,n ×
ιh
n
2at,n × 24.
(5)
The corresponding ofﬂoading time is
τ o
t,n = dt,n
Rt,n
.
(6)


--- Page 4 ---
4
3) Edge Analytics: Upon receiving the preprocessed image
from EDn, the ES performs object detection using a pre-
deployed AI model (e.g., YOLO [25]). The model outputs
a set of bounding boxes ˆBt,n deﬁning object locations with
conﬁdence values, alongside the edge computational latency
τ c
t,n. Since the degradation level at,n determines the input
resolution rt,n, the model outputs ˆBt,n and τ c
t,n critically
depend on at,n.
In this paper, we quantify the edge analytics performance
through two primary metrics: detection accuracy and edge
computational latency. The detection accuracy is quantiﬁed by
comparing the predicted bounding boxes ˆBt,n against ground
truth BGT
t,n [20]. Speciﬁcally, for each ground truth bounding
box β ∈BGT
t,n , we compute its maximum Intersection over
Union (IoU) with predicted boxes ˆβ ∈ˆBt,n as:
Γ(β, ˆBt,n) = max
ˆβ∈ˆ
Bt,n
|β ∩ˆβ|
|β ∪ˆβ|
,
(7)
where | · | represents set cardinality. The detection accuracy
ct,n is then deﬁned as the proportion of ground truth boxes
exceeding an IoU threshold γth:
ct,n =
1
|BGT
t,n |
X
β∈BGT
t,n
I

Γ(β, ˆBt,n) ≥γth

,
(8)
where I(·) denotes the indicator function.
The edge computational latency τ c
t,n depends primarily on
the original resolution ro
n and the degradation level at,n, but
also reﬂects the computational efﬁciency ψ at the ES. We
model this relationship through a device-speciﬁc function fc(·)
as:
τ c
t,n = fc(ro
n, at,n; ψ).
(9)
After completing inference tasks (e.g., generating bounding
boxes), the ES returns the results directly to the originating
EDs. Given the substantially smaller data volume of these
inference outputs compared to original and degraded input
images, we omit feedback latency in our analysis.
B. Problem Formulation
In this paper, we address an online ofﬂoading control
problem to simultaneously maximize the long-term average
detection accuracy of EDs and minimize end-to-end inference
latency. We deﬁne the utility for EDn in time slot t as
ut,n = ct,n −wnτt,n,
(10)
where wn ≥0 is an accuracy-latency tradeoff weighting factor
and
τt,n = τd
t,n + τ o
t,n + τc
t,n
(11)
is the end-to-end inference latency. Our objective is to maxi-
mize the long-term average utility through joint optimization
of degradation levels and bandwidth allocation:
max
at,bt,∀t
1
T
T −1
X
t=0
N
X
n=1
ut,n
(12a)
s. t.
XN
n=1bt,n ≤1, ∀t,
(12b)
at,n ∈A, bt,n ≥0, ∀n, t.
(12c)
Here, at = {at,n, ∀n} denotes the discrete degradation ac-
tions, and bt = {bt,n, ∀n} represents the bandwidth allocation
ratios, respectively. (12b) ensures feasible bandwidth alloca-
tion, while (12c) enforces variable boundaries.
During real-time inference, the detection accuracy ct,n
remains unavailable due to the absence of ground truth BGT
t,n .
To address this limitation, we leverage the conﬁdence val-
ues associated with predicted bounding boxes ˆBt,n from the
object detection model. The cumulative conﬁdence metric
αt,n, deﬁned as the sum of conﬁdence values across all
predicted bounding boxes ˆBt,n, provides a real-time accuracy
proxy strongly correlated with actual detection performance
[22]. This enables us to reformulate the following alternative
optimization problem:
max
at,bt,∀t
1
T
T −1
X
t=0
Ut(ht, at, bt)
(13a)
s. t. (12b), (12c),
(13b)
where ht = {ht,n, ∀n} denotes the channel state of time slot
t. Ut(ht, at, bt) = PN
n=1 ˜ut,n is the total utility of all EDs,
with per-ED utility deﬁned as
˜ut,n = αt,n −wnτt,n.
(14)
At the start of time slot t, the ES has perfect knowledge of
ht and employs centralized control to determine at and bt.
Despite the temporal decoupling in (13) allows independent
optimization per slot t, solving each per-slot subproblem (i.e.,
(13) for ﬁxed t) faces three interconnected challenges:
• Lack of Content Awareness: The conﬁdence value αt,n
exhibits signiﬁcant content-dependent variations, yet the
dynamic task content (i.e., image content) governing αt,n
remains unknown at the ES during optimization. While
each ED could evaluate all degradation options to de-
termine the optimal choice, this requires pre-transmitting
every possible degraded image version to the ES, which
is impractical as it induces prohibitive latency through
excessive transmissions.
• Absence of Explicit Utility Model: Even with perfect
task content knowledge, the reformulated utility function
Ut lacks an analytical model. Speciﬁcally, cumulative
conﬁdence αt,n depends on complex objective detection
model behaviors that defy close-form formulation. Mean-
while, degradation latency τ d
t,n and edge computational
latency τ c
t,n depend on the implicit hardware efﬁciency
of individual ED and ES, respectively. These empirical
relationships must be learned through system measure-
ments, preventing direct gradient-based optimization or
analytical solutions.
• Combinatorial Explosion: The tight coupling between
discrete degradation actions at and continuous bandwidth
allocation bt renders (13) an NP-hard MINLP. A conven-
tional MINLP approach would ﬁx discrete actions and
optimize continuous variables using established solvers
(e.g., CVX [26]), then select the optimal discrete action
through enumeration. However, exhaustive search over
the AN combinations incurs combinatorial explosion.
This approach becomes computationally prohibitive for


--- Page 5 ---
5
Update BO
Customized
Bandwidth
Allocation
via
Solving (27)
...
...
...
...
...
DNN-based
Action Generation
Input state
...
DNN-Based Actor
Module
BO-Based Critic
Module
Policy Update
Module
DNN
Repaly
Memory
Labeled Sample
Train DNN
BO
Observation
Cache
GP-based
Action
Evaluation
QTZ
See
Fig.3
...
...
Fig. 2: The schematics of the proposed LAB framework.
large edge deployments, as complexity grows exponen-
tially with the number of EDs N.
C. Solution Framework Overview
In this paper, we propose an integrated deep reinforcement
Learning and Bayesian optimization framework (LAB) to
solve (13). As shown in Fig. 2, LAB comprises three intercon-
nected modules: a DNN-based actor parameterized by θdnn, a
BO-based critic modeled by θbo, and a policy update module
that enables continuous adaptation. During time slot t, the
actor module ﬁrst processes the input state st (including chan-
nel states and history experiences, formally deﬁned in Section
V) to generate Kt candidate degradation actions {a(k)
t
}Kt
k=1,
where a(i)
t
is the i-th candidate. These candidates undergo
evaluation by the critic module using Gaussian process (GP)
modeling, which characterizes utility Ut as a probabilistic
function of degradation actions. Building on this probabilistic
characterization, the critic computes an acquisition function
(detailed in Section IV) to select the optimal candidate a∗
t
that maximizes the acquisition value. Following this selection,
it then determines the corresponding bandwidth allocation b∗
t
by solving subproblem, thereby establishing the joint action-
resource solution (a∗
t , b∗
t ). Concluding the operational cycle,
the policy update module periodically reﬁnes both θdnn and
θbo using accumulated historical execution data.
As an seamless integration of BO and DRL, the proposed
LAB framework delivers three key innovations that directly
address the challenges outlined below (14):
• GP Surrogate for Content Uncertainty Mitigation: The
BO-based critic employs GP to construct a probabilistic
utility surrogate from historical observations, which cap-
tures the relationship between degradation actions and
their expected utility across diverse task contents. By
optimizing the acquisition function over this surrogate,
LAB selects optimal degradation actions at without re-
quiring real-time content knowledge or pre-transmission
of degraded task images.
• Co-Adaptive Optimization of Implicit Utility: LAB co-
ordinates a DNN-based actor and a BO-based critic for
online utility optimization. The BO-based critic pinpoints
high-value actions from history observations to guide
the actor’s policy updates. In turn, the DNN-based actor
generates candidate actions that focus the GP model
on high-potential regions, enhancing BO efﬁciency. This
co-adaptation enables derivative-free optimization of the
utility without an explicit formulation.
• Exponential-to-Linear Complexity Reduction: LAB gen-
erates a focused set of Kt ≪|A|N candidate degradation
actions via the DNN actor. This enables the BO critic
to evaluate only Kt options via acquisition computation,
avoiding the intractable combinatorial action selection.
Consequently, the framework solves the bandwidth al-
location subproblem (27) only once for the optimal
candidate, collectively achieving linear-scale complexity.
In the following sections, we ﬁrst present the critic module
(Section IV) to establish the action evaluation framework.
Building upon this foundation, we then introduce the actor
module (Section V) to generate candidates speciﬁcally for this
evaluation process. Finally, the policy update module (Section
VI) completes the operational cycle of LAB by reﬁning the
parameters of both actor and critic.
IV. BO-BASED CRITIC MODULE
To address the dual challenges of content uncertainty and
utility implicitness in (13), the BO-based critic module em-
ploys GP surrogates to evaluate candidate actions. Crucially,
we observe that for a ﬁxed degradation action at, the utility
Ut becomes an explicit function of bt. As shown in Fig. 2, this
structural insight enables us to decompose the critic module
into two sequential stages: 1) GP-based action selection via ac-
quisition function maximization, and 2) customized bandwidth
optimization for the selected degradation action. We introduce
these two stages in Sections IV-A and IV-B, respectively.
A. GP-based Action Selection
Let Ct = {a(k)
t
}Kt
k=1 denote the candidate action set pro-
duced by the DNN-based actor in time slot t. For each
candidate degradation action at ∈Ct, there exists an optimal
bandwidth allocation b∗
t that maximizes the utility Ut (as
formally established in Section IV-B). We therefore deﬁne
the maximum achievable utility for action at as Ut(ht, at) ≜
maxbt Ut(ht, at, bt). This allows us to formulate the degra-
dation action selection problem for time slot t as:
max
at
Ut(ht, at)
(15a)
s. t. at ∈Ct.
(15b)
Despite this formulation, (15) faces two persistent chal-
lenges identiﬁed in Section III-B: Ut(ht, at) remains content-
dependent and model-free, while exhaustive evaluation of Ut
would require executing all Kt candidates, incurring pro-
hibitive latency. To address these limitations, we develop a GP
surrogate that enables efﬁcient model-based evaluation for any
given at without on-device execution. The GP-based action
selection stage contains two sequential operations: probabilis-
tic modeling of the utility function Ut(ht, at) through GP
regression, and acquisition function optimization leveraging
the GP posterior distribution.


--- Page 6 ---
6
1) Probabilistic GP Modeling: To start with, we construct
an augmented input vector zt = (ht, at, t) and express the
utility compactly as U(zt) := Ut(ht, at). Here, the time index
t is explicitly included in zt to account for temporal dynamics
introduced by time-varying channel conditions and task con-
tent. The observed utility yt constitutes a noisy measurement
of the true utility U(zt):
yt = U(zt) + ǫt,
(16)
where ǫt
∼
N(0, δ2
ǫ ) is an independent and identically
distributed (i.i.d) Gaussian noise with variance δ2
ǫ. Crucially, δǫ
is a learnable parameter that quantiﬁes the uncertainty arising
from content variations and channel randomness.
Let DB
t−1 = {(zi, yi)}t−1
i=t−JB denote all observations accu-
mulated from the last JB time slots, where JB ∈{1, · · · , t −
1}. Our goal is to infer the utility value U(zt) at the start of
a new time slot t using historical data DB
t−1. To achieve this,
we use a zero-mean GP prior to model the utility function:
U(z) ∼GP(0, κ(z, z′)),
(17)
where
the
covariance
kernel
function
κ(·, ·)
quantiﬁes
the similarity between any pair of inputs. Consequently,
the
joint
prior
distribution
of
utility
evaluations
Ut−1
:=
[U(zt−JB), · · · , U(zt−1)]⊤
at
inputs
Zt−1 := [zt−JB, · · · , zt−1]⊤follows a multivariate Gaussian:
q (Ut−1|Zt−1) = GP(0JB×1, Kt−1),
(18)
where 0JB×1 is a JB × 1 zero vector and Kt−1 is a JB × JB
covariance matrix with elements [Kt−1]j,j′ = κ(zt−j, zt−j′)
for j, j′ = 1, · · · , JB. For the observed outputs Yt−1 :=
[yt−JB, · · · , yt−1]⊤, the likelihood function given Ut−1 and
Zt−1 is
q (Yt−1 | Ut−1, Zt−1) = GP(Ut−1, δ2
ǫ IJB×JB),
(19)
where IJB×JB denotes a JB × JB identity matrix. Combining
this likelihood with the prior in (18) via Bayes’ theorem, we
obtain the posterior distribution for a new input zt as [5]
q
 U(zt)|DB
t−1

= N
 µt−1(zt), σ2
t−1(zt)

.
(20)
The posterior mean µt−1 and variance σ2
t−1 are given in closed
form by
µt−1(zt) = κ⊤
t−1
 Kt−1 + δ2
ǫIJB×JB
−1 Yt−1,
(21)
and
σ2
t−1(zt)=κ(zt, zt)−κ⊤
t−1
 Kt−1+δ2
ǫIJB×JB
−1κt−1, (22)
respectively, where κt−1 := [κ(zt−JB, zt), · · · , κ(zt−1, zt)]⊤
is the covariance vector between zt and the historical inputs.
The effectiveness of the above GP model critically depends
on the kernel function κ(·, ·), which encodes prior information
about the structure of utility function U(zt). To capture the
complex interactions across the heterogeneous components
of zt
=
(ht, at, t), we design a composite kernel that
strategically combines three specialized kernels: a radial basis
function (RBF) kernel κrbf
θh with parameter θh for continuous
channel states ht, a categorical kernel κcat
υa
with parameter
υa for discrete degradation actions at, and a temporal kernel
κtmp
ρ
with parameter ρ for temporal dynamics. The complete
mathematical deﬁnitions of these kernels and their parameters
are provided in Appendix A. The resulting kernel structure of
κ(·, ·) is formulated as:
κ(zi, zi′) = κtmp
ρ
(i, i′) ·

κrbf
θh (hi, hi′) + κcat
υa (ai, ai′)
+κrbf
θh (hi, hi′) · κcat
υa (ai, ai′)

, (23)
where i, i′ ∈{t −JB, · · · , t −1} are time indices.
2) Acquisition Optimization: Building upon the GP model
above, we now deﬁne the acquisition function that guides the
selection of degradation actions at at time slot t. We adopt
the upper conﬁdence bound (UCB) criterion [6] to balance
exploration of uncertain actions against exploitation of known
high-utility actions. Given the posterior distribution in (20),
the UCB acquisition function of input zt is formulated as
Qθbo(zt) = µt−1(zt) + ζ · σt−1(zt),
(24)
where θbo = {θh, υa, ρ, δǫ} denotes the parameters of the
BO-based critic. ζ > 0 is an exploration coefﬁcient that
controls the trade-off between exploration and exploitation.
The ﬁrst term µt−1(zt) encourages exploitation by favoring
actions expected to yield high utility, while the second term
ζσt−1(zt) promotes exploration of actions with high predictive
uncertainty.
At the start of time slot t, given channel state information
ht at the ES, we optimize at by solving
a∗
t = arg max
at∈Ct
Qθbo (ht, at, t) .
(25)
Given the ﬁnite candidate set Ct = {a(i)
t }Kt
i=1 where Kt ≪
|A|N, we exhaustively evaluate Qθbo over all at
∈
Ct
to obtain the optimal degradation action a∗
t . This selected
action is subsequently deployed for image ofﬂoading, with the
optimal bandwidth allocation b∗
t to be determined in the next
subsection.
B. Customized Optimal Bandwidth Allocation under Fixed
Degradation Action
Given a selected degradation action a∗
t, the utility Ut in
(13a) depends on bandwidth allocation bt only through the
ofﬂoading time τo
t,n, as αt,n, τ d
t,n, and τ c
t,n are invariant to
bt. This motivates introducing τ o
t,n’s as auxiliary variables
constrained by:
dt,n
τ o
t,n
≤bt,nW log2

1 + pnht,n
bt,nWδ2

, τ o
t,n ≥0, ∀n.
(26)
Consequently, the per-slot subproblem of (13) reduces to the
following convex bandwidth allocation problem:
min
bt,τ o
t
N
X
n=1
wnτ o
t,n
(27a)
s. t.
dt,n
τ o
t,n
≤bt,nW log2

1 + pnht,n
bt,nWδ2

,
(27b)
PN
n=1bt,n ≤1,
(27c)
at,n ∈A, bt,n ≥0, τ o
t,n ≥0, ∀n,
(27d)


--- Page 7 ---
7
where τ o
t = {τ o
t,n, ∀n}. While standard convex optimization
methods (e.g., interior point method [26]) efﬁciently solve
(27), we derive a semi-closed-form solution using Lagrangian
duality to characterize optimal resource allocation. Let φ =
{φn, ∀n} ≥0 and η ≥0 denote Lagrangian multipliers
for constraints (27b) and (27c), respectively. The partial aug-
mented Lagrangian of (27) is
L(bt, τ o
t , φ, η)
=
XN
n=1wnτ o
t,n + η
XN
n=1bt,n −1

+
XN
n=1φn
dt,n
τ o
t,n
−bt,nW log2

1 + pnht,n
bt,nWδ2

.
(28)
The optimum of (27) is obtained through alternately solving
the following bi-level optimization:
1) Obtain the dual function K(φ, η) by solving:
K(φ, η) = min
bt,τ o
t
L(bt, τ o
t , φ, η)
(29a)
s. t. bt,n, τ o
t,n ≥0, ∀n.
(29b)
2) Solve the dual problem:
max
φ,η K(φ, η),
s. t.
φ, η ≥0.
(30)
Let {η∗, φ∗
n, ∀n} denote the optimal dual variables. The op-
timal solution to (27) is then characterized by the following
proposition.
Proposition 1. The optimal solution to (27), denoted as
{b∗
t,n, τ o∗
t,n}, has the following closed-form structure:
τ o∗
t,n =
r
φ∗ndt,n
wn
,
(31)
b∗
t,n =
−pnht,n
Wδ2
"
1 +

W

−
1
exp

η∗ln 2
φ∗nW +1

−1#,
(32)
where W(·) is the Lambert-W function and exp(·) is the
exponential function.
Proof. Please see Appedix B for detail.
Proposition 1 yields two key insights: First, φ∗
n
> 0
necessarily holds because φ∗
n = 0 implies τo∗
t,n = 0, leading
to unrealizable inﬁnite data rates. Second, η∗> 0 must
obtain since η∗
=
0 causes b∗
t,n
→
∞, violating the
bandwidth constraint (27c). These conditions ensure equality
holds in both (27b) and (27c) at optimality, indicating that
full utilization of bandwidth resource minimizes ofﬂoading
time. The Lambert-W function has two real branches: the
principal branch W0(z) ∈(−1, 0) and the secondary branch
W−1(z) ∈(−∞, −1). Given φ∗
n > 0 and η∗> 0, the
argument −
1
exp

η∗ln 2
φ∗nW +1
 ∈(−1
e, 0). Within this interval,
W−1(·) yields negative values. To guarantee a non-negative
b∗
t,n, we take W0(·) as the Lambert-W function in (32).
V. DNN-BASED ACTOR MODULE
The BO-based critic in Section IV provides probabilistic
action evaluation through GP modeling with acquisition func-
tion optimization. While theoretically capable of evaluating all
AN actions, the exponential growth of the action space with
N makes exhaustive evaluation computationally prohibitive
for real-time edge systems. Critically, even in computationally
tractable cases (e.g., small N where exhaustive search is
feasible), the action maximizing the acquisition function would
not guarantee optimality for the true utility Ut in (13a), as
the acquisition function (e.g., UCB in (24)) is a surrogate
designed for exploration-exploitation balance rather than direct
utility optimization. These dual limitations motivate our DNN-
based actor module, which generates a targeted candidate set
Ct through adaptive history distillation. This approach main-
tains computational feasibility while focusing critic evaluation
on high-potential actions, thereby enhancing decision quality
beyond standalone acquisition optimization. As shown in Fig.
2, the actor module decomposes into two sequential stages:
1) DNN-based approximation and 2) customized quantization
(QTZ) for candidate generation. We detail these two stages in
Sections V-A and V-B, respectively.
A. DNN-based Action Approximation
We begin by formalizing the input state st of the DNN.
At the start of time slot t, we deﬁne the system observation
as ot = (ht, αt−1, τt−1, at−1, bt−1, Ut−1), where αt−1 =
{αt−1,n, ∀n} and τt−1 = {τt−1,n, ∀n} denote the conﬁdence
and the end-to-end inference latency of time slot t −1,
respectively. The input state aggregates the most recent l obser-
vations, forming the history sequence st = (ot−l+1, . . . , ot).
For initialization at t = 1, we set α0 = 0N×1, τ0 = 0N×1,
a0 = 0N×1, b0 = 0N×1, and U0 = 0, where 0N×1 denotes
an N-dimensional zero vector.
To enhance the exploration capacity of the DNN, we em-
ploy one-hot encoding for the integer degradation action. For
each user n, the degradation level at,n is represented as an
A-dimensional binary vector ωt,n = [ωt,n,0, · · · , ωt,n,A−1],
where each element ωt,n,i, ∀i ∈A, is deﬁned by the indicator
function:
ωt,n,i = I(at,n = i) =
 1,
at,n = i,
(33a)
0,
otherwise.
(33b)
The degradation action at
= {at,n}N
n=1 is consequently
encoded as an NA×1 binary vector Ωt = [ωt,1, · · · , ωt,N]⊤.
The DNN, parameterized by θdnn and denoted fθdnn, approx-
imates a continuous mapping from the input state st to a
relaxed preference
ˆΩt = fθdnn(st).
(34)
Here, ˆΩt maintains identical NA-dimensional concatenated
structure as Ωt, but with real-valued elements ˆωt,n,i ∈[0, 1]
representing preference scores for each n ∈{1, . . ., N} and
i ∈A.


--- Page 8 ---
8
0,   0,   …,   1
0,   1,…,   0
0.75, 0.92,…, 0.13
Probabilistic
sampling
Softmax
Guassian
noise
+
arg max
Probabilistic
sampling
Softmax
Element-wise mapping
...
...
...
...
...
...
...
...
...
...
Fig. 3: The quantizer in the DNN-based actor module.
B. Customized Quantization for Candidates Generation
Building upon the continuous approximation ˆΩt gener-
ated by the DNN in Section V-A, this subsection de-
velops a customized QTZ mechanism to produce feasible
discrete candidate actions {a(k)
t
}Kt
k=1. We denote ˆωt,n =
[ˆωt,n,0, · · · , ˆωt,n,A−1] and ˆΩt = [ˆωt,1, · · · , ˆωt,N]. The QTZ
process addresses dual objectives: converting the preference
scores ˆωt,n into valid integer degradation levels at,n ∈A,
while generating diverse high-quality candidates that maintain
real-time computational efﬁciency. Our solution integrates two
coordinated operations: 1) quantizing the preference ˆΩt into
Kt binary actions {Ω(k)
t
}Kt
k=1 followed by transformation to
Ct = {a(k)
t
}Kt
k=1, and 2) dynamically adjusting Kt to balance
exploration and computational load. We now formalize these
two operations sequentially.
1) Preference-Guided Candidate Generation: To translate
preference scores into executable actions, we generate ⌊Kt/2⌋
candidates through direct interpretation of ˆΩt, reserving the re-
maining Kt −⌊Kt/2⌋actions for noise-enhanced exploration.
• Direct
Interpretation: The
ﬁrst
candidate
Ω(1)
t
=
[ω(1)
t,n, · · · , ω(1)
t,N]⊤is constructed deterministically by se-
lecting the maximum preference score per device. For
each binary vector ω(1)
t,n, the element ω(1)
t,n,i = 1 at
i = arg maxj∈A ˆωt,n,j, with other elements set to 0. As
an example in Fig. 3, when ˆωt,N = [0.75, 0.92, · · · , 0.13]
with ˆωt,N,1 = 0.92 as the maximum, we have ω(1)
t,N =
[0, 1, · · · , 0]. Subsequent candidates {Ω(k)
t
}⌊Kt/2⌋
k=2
are
generated through ⌊Kt/2⌋−1 independent probabilis-
tic samplings. For each EDn, we convert the prefer-
ence scores ˆωt,n to a categorical distribution ˆqt,n =
{ˆqt,n,i}A−1
i=0 via softmax normalization:
ˆqt,n,i =
eˆωt,n,i
PA−1
i=0 eˆωt,n,i .
(35)
We then sample the degradation level i for each EDn
from the categorical distribution ˆqt,n, setting ω(k)
t,n,i = 1
for the selected level and all other elements to 0.
• Noise-Enhanced
Exploration:
The
remaining
Kt −
⌊Kt/2⌋candidates leverage Gaussian noise perturbations
to explore novel action combinations:
ˆΩǫ
t = ˆΩt + ǫt,
(36)
where ǫt
∈
N(0NA×1, INA×NA) denotes an NA-
dimensional Gaussian distribution with zero mean and
unit variance. Each candidate is generated by applying
identical softmax normalization and categorical sampling
as in direct interpretation, but to the noise-perturbed
outputs ˆΩǫ
t.
The generated binary candidates {Ω(k)
t
}Kt
k=1 are then trans-
formed into executable degradation actions Ct = {a(k)
t
}Kt
k=1
through element-wise mapping. For each candidate k and
ED n, the degradation level a(k)
t,n is determined by the active
position in its one-hot representation ω(k)
t,n:
a(k)
t,n = i · I(ω(k)
t,n,i = 1),
(37)
where i ∈A = {0, . . ., A −1}. This yields candidate vectors
a(k)
t
= [a(k)
t,1 , . . . , a(k)
t,N]⊤. As exempliﬁed in Fig. 3 for ENN,
when ω(1)
t,N = [0, 0, . . ., 1], the transformation gives a(1)
t,N = 1.
Remark 1. The preference-guided candidate generation bal-
ances exploitation and exploration via a dual-stream archi-
tecture, enabled by one-hot encoding. It expands the integer
action space into a higher-dimensional binary domain, en-
hancing candidate diversity while enforcing action feasibility
[27]. Within this expanded space, the direct interpretation
stream exploits DNN knowledge to sample top-preference
actions that concentrates on high-value solutions. Simulta-
neously, The noise-enhanced stream discovers novel actions
via controlled perturbations, focusing exploration near high-
conﬁdence predictions. The coordinated interaction between
expanded representation and dual-stream mechanisms enables
efﬁcient solution exploration and exploitation.
2) Adaptive Candidate Set Adjustment: The candidate set
size Kt critically inﬂuences the efﬁcacy of LAB framework.
While larger candidate sets theoretically enable more com-
prehensive exploration of the action space, they substantially
increase the evaluation time of acquisition function. Further-
more, expansion of Kt does not guarantee monotonic per-
formance improvement since the acquisition function serves
as a surrogate optimizer rather than directly maximizing the
true utility Ut. This calls for an adaptive mechanism that dy-
namically balances exploration breadth against computational
burden.
In this paper, we implement an adaptive Kt mechanism
updated every ∆K > 0 time slots. We begin by quantifying the
alignment between candidate actions and the DNN preference
through the L2-distance metric:
v(k)
t
= ∥Ω(k)
t
−ˆΩt∥2.
(38)
The candidates are sorted in ascending order of v(k)
t
, yielding
an ordered sequence {Ω(1)
t , Ω(2)
t , . . . , Ω(Kt)
t
}, where Ω(1)
t
denotes the action closest to the DNN preference. The optimal
candidate a∗
t is then determined by solving (25) over this
ordered set. Let k∗
t ∈{1, . . ., Kt} represent the position index


--- Page 9 ---
9
of a∗
t within the sorted sequence. For time slot t, we update
Kt as
Kt =





K1,
t = 1,
(39a)
min

max

{k∗
i }∆K
i=t−1

+1, K1

, t mod ∆K=0, (39b)
Kt−1,
otherwise,
(39c)
where K1 is initialized as a positive integer at time slot t = 1.
Intuitively, Kt is primarily determined by k∗
t . A higher k∗
t
indicates that optimal actions reside in less explored regions
farther from current preferences, suggesting the need for can-
didate set expansion; a lower k∗
t suggests high-utility actions
are clustered near existing preferences, enabling potential set
reduction.
VI. POLICY UPDATE MODULE
The policy update module facilitates continuous perfor-
mance enhancement in LAB by dynamically optimizing the
parameters for both the actor (DNN) and critic (BO) modules.
Leveraging accumulated historical execution data, it periodi-
cally retrains the DNN-based action generator and re-calibrates
the GP model underpinning the BO acquisition function.
The following subsections detail the parameter optimization
procedures for both the actor and critic modules.
A. Parameters update of DNN
We implement an experience replay mechanism to update
the DNN policy. Upon completion of time slot t, the optimal
state-action pair (st, a∗
t) is stored in a ﬁnite-capacity replay
memory of size JD > 0. Once the memory reaches capacity,
older samples are replaced by newer entries. The training
of DNN commences when the memory contains at least
JD/2 samples and recurs periodically every ∆D > 0 slots.
When t mod ∆D = 0, we uniformly sample a minibatch
{(sν, Ω∗
ν), ν ∈T D
t } from the memory, where Ω∗
ν is the
binary representation of a∗
ν and T D
t
denotes selected temporal
indexes, respectively. The DNN parameter θdnn is updated
by minimizing the binary cross-entropy loss via the Adam
optimizer:
Loss(θdnn) = −1
Js
D
X
ν∈TD
h
(Ω∗
ν)⊤log fθdnn (sν)
+ (1 −Ω∗
ν)⊤log (1 −fθdnn (st))
i
,
(40)
where log denotes the element-wise logarithm, and Js
D = |T D
t |
is the minibatch size. Following parameter update, the actor
module utilizes the new θdnn to generate candidate actions.
This procedure enables the DNN to continuously assimilate
high-quality state-action mappings from recent experiences,
progressively improving decision effectiveness.
B. Parameters update of BO
The BO parameter θbo = {θh, υa, ρ, δǫ} is updated through
a dedicated observation cache of size JB > 0. At the end of
time slot t, the optimal degradation action a∗
t, channel state ht,
and temporal index t collectively form the augmented input
z∗
t = (ht, a∗
t , t). While the solution to the degradation action
selection problem (15) yields an exact value U ∗
t for the input
z∗
t , this value represents a noisy observation y∗
t of the utility
function due to the unknown system dynamics. Consequently,
we set y∗
t ←U ∗
t and store the tuple (z∗
t , y∗
t ) in the BO cache,
with older entries evicted upon overﬂow. Periodically every
∆B time slots, i.e., when t mod ∆B = 0, the parameter
θbo is re-optimized by maximizing the log marginal likelihood
over the cached dataset DB
t = {(z∗
i , U ∗
i )}t
i=t−JB+1 [5]:
θbo ←arg max
θ
log q (Yt | Zt) ,
(41)
where q (Yt | Zt) ∼N(0, Kt + δ2
ǫI) integrates the GP prior
(17) and likelihood (19), and has the following closed-from
log expression:
log q (Yt | Zt) = −1
2 (Yt)⊤ Kt + δ2
ǫ IJB×JB
−1 Yt
−1
2 log |Kt + δ2
ǫIJB×JB|.
(42)
By maximizing (42) via gradient-based method (e.g., quasi-
Newton method), we obtain the optimized BO parameter θbo.
This updated parameter is then used in the acquisition function
during the next time slot t+1 to select the optimal degradation
action.
Remark 2. LAB fundamentally redeﬁnes the actor-critic
paradigm through a hybrid architecture that integrates DRL
with BO. Unlike conventional actor-critic frameworks where
both components utilize DNNs, LAB employs a BO critic to
guide a DNN-based actor. Speciﬁcally, the BO critic lever-
ages GP posterior with estimated mean and uncertainty to
derive high-value actions, thereby enabling uncertainty-aware
explorations which is unavailable in conventional DNN critics.
Concurrently, the DNN actor learns from these high-value
actions to progressively improve its action generation, and thus
achieving data-efﬁcient policy update.
VII. SIMULATION RESULTS
In this section, we evaluate the system performance through
numerical simulations, considering an EI system comprising
one ES and N
= 3 EDs by default. The ES employs
YOLOv11x [28] for object detection tasks, processing images
from the UrbanRoad Self-Driving dataset [29]. This dataset
contains M = 15, 000 RGB video frames at native resolution
(ιw
n, ιh
n) = (1920, 1200), where each frame represents an input
image. At the time slot t = 0, each EDn initializes with a
uniform random starting frame index m0,n ∼U[0, M −1],
then sequentially advances through the dataset such that
mt,n = (m0,n + t) mod M each time slot. For each image,
EDn applies Guassian pyramid downsampling across A = 4
degradation levels. The IoU threshold is set as γth = 0.5.
To model autonomous driving scenarios, ED mobility fol-
lows a 100 m × 50 m rectangular trajectory centered at
the ES location. The system operates over T
= 3, 000
discrete time slots. At t = 0, initial positions of EDs are
randomly distributed along a designated 100-meter edge of
the rectangle. Between consecutive time slots, ED positions
progress in discrete 2.5-meter increments counterclockwise
along the rectangular trajectory. We adopt Rayleigh fading


--- Page 10 ---
10
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6
1.8
Long-term average latency ¯τ (s)
4.2
4.4
4.6
4.8
5.0
5.2
Long-term average conﬁdence ¯α
w = 0
w = 1
w = 2
w = 3
Fig. 4: The conﬁdence-latency trade-off of LAB.
channels for wireless communications between EDs and ES.
The channel gain for EDn at time slot t is modeled as
ht,n = ς · ¯ht,n, where ς follows an exponential distribution
with unit mean. The average channel gain ¯ht,n is deﬁned as
¯ht,n = GA

3×108
4πfcdt,n
λ
, where GA = 4.11 denotes antenna
gain, fc = 2.4 GHz is the carrier frequency, dt,n represents
the Euclidean distance between EDn and ES at time t, and
λ = 2.4 by default is the path-loss exponent. We consider
homogeneous EDs with identical transmit power pn = 0.1
watt, and weighting factors wn = w = 1 by default, ∀n. The
total bandwidth is W = 5 MHz. The noise power spectrum
density at the ES is δ2 = −174 dBm/Hz.
For the proposed framework LAB, the actor module em-
ploys a Transformer-based DNN consisting of three core
components: a fully-connected input embedding layer that
generates 64-dimensional embeddings, a 2-layer Transformer
encoder with 4 attention heads per layer and 256-dimensional
feed-forward networks, and a fully-connected output layer
using sigmoid activation to produce ˆΩt. The default param-
eters of DNN include: input state history length l = 1,
replay memory size JD = 512, minibatch size Js
D = 128,
initial number of candidates K0 = min{8N, AN} with update
interval ∆K = 32, DNN training interval ∆D = 20, and the
Adam optimizer learning rate ξ = 0.01. The critic module
employs the L-BFGS-B method to update the BO parameters,
with defaults including observation cache size JB = 256
and BO update interval ∆B = 20. All the simulations are
conducted on an Intel(R) Xeon(R) Silver 4110 (2.10 GHz)
machine with a Tesla P40 GPU. The complete source code
for LAB will be published on GitHub upon acceptance.
A. Parameter Sensitivity Analysis of LAB
In Fig. 4, we demonstrate the conﬁdence-latency trade-
off of LAB under different delay weighting factors. Specif-
ically, we compute the long-term average conﬁdence ¯α =
1
T
PT −1
t=0
PN
n=1 αt,n and the long-term average latency ¯τ =
1
T
PT −1
t=0
PN
n=1 τt,n. As w increases from 0 to 3, LAB in-
creasingly prioritizes latency reduction, resulting in lower ¯τ at
the expense of reduced ¯α. Notably, increasing w from 0 to 1
reduces ¯τ dramatically by 68.3% (from 1.83 s to 0.58 s) while
only decreasing ¯α by 6.9% (from 5.21 to 4.85). Therefore, we
0
1000
2000
Time slot t
0.2
0.3
0.4
Optimality gap
(a)
UCB
PI
EI
0
1000
2000
Time slot t
0.2
0.3
0.4
Optimality gap
(b)
JB = 128
JB = 256
JB = 512
0
1000
2000
Time slot t
0.2
0.3
0.4
0.5
Optimality gap
(c)
l = 1
l = 5
l = 10
0
1000
2000
Time slot t
0.2
0.4
0.6
Optimality gap
(d)
∆D = ∆B = 10
∆D = ∆B = 20
∆D = ∆B = 50
Fig. 5: Optimality gap under different LAB parameters: (a) acqusition func-
tion; (b) BO cache size; (c) history length of input sate; and (d) update interval.
select w = 1 for all subsequent simulations as it maintains
high conﬁdence without incurring substantial latency penalties.
In Fig. 5, we analyze parameter sensitivity of LAB through
the optimality gap metric U ∗
t −Ut, where U ∗
t
represents
the theoretical maximum utility obtained through exhaus-
tive search over all AN degradation actions for (15), with
results window-averaged over 500 time slots. Fig. 5(a) re-
veals that UCB acquisition function consistently outperforms
expected improvement (EI) and probability of improvement
(PI) alternatives by more effectively balancing exploration-
exploitation trade-offs. For the BO cache in Fig. 5(b), a size
of JB = 256 achieves the minimal optimality gap, while
a smaller cache (JB = 128) exhibits degraded performance
due to insufﬁcient historical data utilization, and a larger
cache (JB = 512) introduces noisy temporal correlations
that compromise decision quality. State history conﬁguration
in Fig. 4(c) reveals that l = 1 (current state only) delivers
optimal performance, whereas extended histories (e.g., l = 10)
provides only marginal asymptotic improvement at increased
computational overhead. Besides, we notice from Fig. 4(d)
that while reducing ∆D and ∆B generally lowers optimality
gaps, the improvement plateaus below 20 time slots. Further
reduction to ∆D = ∆B = 10 provides only marginal gains
while substantially increasing computational load. To balance
system performance with implementation efﬁciency, we adopt
UCB acquisition, JB = 256, l = 1, and ∆D = ∆B = 20 as
the default conﬁguration.
B. System Performance Comparison
To validate the efﬁcacy of LAB, we evaluate it against ﬁve
representative benchmarks:
• IDEAL: Selects degradation actions by exhaustive search
over all AN possibilities per slot to directly maxi-
mize utility Ut. While providing the theoretical perfor-
mance upper bound for problem (13), its requirement of
completing full action-space evaluation before decision-
making makes it computationally infeasible for practical
implementation.


--- Page 11 ---
11
0
200
400
600
800
1000
Time slot t
1
2
3
4
5
6
7
8
Utility Ut
MOSEK
DNN
Fig. 6: Per-slot utility of DNN-based solver for bandwidth allocation.
• Standard BO (BO) [22]: Generates degradation actions by
maximizing the acquisition function (24) per slot through
full enumeration of all AN possibilities.
• DBAG [20]: A state-of-art (SOTA) DRL method that
formulates problem (13) as an MDP and applies soft
actor-critic for degradation action optimization.
• Delay-oblivious ofﬂoading (DelayObli): A detection-
optimal strategy where all EDs persistently select the
lowest degradation level at,n = 0, transmitting original
full-resolution images without degradation.
• Delay-minimizing ofﬂoading (DelayMin): An ofﬂoading-
latency-optimal approach where all EDs consistently se-
lect the highest degradation level at,n = A −1, transmit-
ting minimally-sized images to the ES.
Following discrete degradation action selection, all benchmark
methods derive optimal bandwidth allocations by solving
subproblem (27). While commercial CVX solvers such as
MOSEK [30] guarantee optimal solutions for (27), they incur
substantial computational overhead when deployed on an ES
equipped with low-frequency CPU. This limitation is espe-
cially pronounced for the IDEAL method, which requires
solving (27) for AN times per slot due to exhaustive search.
To mitigate computational complexity, we implement a DNN-
based bandwidth allocation solver following [20], which ef-
ﬁciently approximates solutions to (27). Fig. 6 compares the
performance of MOSEK and our DNN solver when imple-
menting the IDEAL method over 1,000 time slots. The results
demonstrate that the DNN solver achieves almost identical per-
slot utility to the optimal solution. Based on this validation, we
employ the DNN solver for all subsequent method evaluations.
We conduct Monte Carlo simulations across all methods using
10 random seeds. Each simulation spans T = 3, 000 time slots,
with ﬁnal results averaged over all seeds.
We ﬁrst evaluate the system performance under varying
path-loss exponent λ in Fig. 7. As shown in Fig. 7(a),
the long-term average utility ¯U =
1
T
PT −1
t=0 Ut decreases
monotonically with λ across all methods due to deteriorating
channel conditions. Non-adaptive strategies (DelayObliv and
DelayMin) yield the lowest utilities as they fail to balance
detection quality against transmission latency. LAB achieves
an average of 7.98% optimality gap of utility relative to
IDEAL, outperforming BO and DBAG by 6.95% and 15.55%
2.2
2.3
2.4
2.5
2.6
Path-loss exponent λ
2.0
2.5
3.0
3.5
Long-term average utility ¯U
(a)
2.2
2.3
2.4
2.5
2.6
Path-loss exponent λ
0
1
2
Long-term average latency ¯τ (s)
(b)
IDEAL
LAB
BO
DBAG
DelayObli
DelayMin
2.2
2.3
2.4
2.5
2.6
Path-loss exponent λ
3.0
3.5
4.0
4.5
Long-term average conﬁdence ¯α
(c)
2.2
2.3
2.4
2.5
2.6
Path-loss exponent λ
0.50
0.55
0.60
Long-term average accuracy ¯c (%)
(d)
Fig. 7: The system performance under various path-loss exponent λ.
1
3
5
7
Number of EDs N
0
1
2
3
Long-term average utility ¯U
(a)
1
3
5
7
Number of EDs N
0
1
2
3
4
Long-term average latency ¯τ (s)
(b)
IDEAL
LAB
BO
DBAG
DelayObli
DelayMin
1
3
5
7
Number of EDs N
2.5
3.0
3.5
4.0
4.5
Long-term average conﬁdence ¯α
(c)
1
3
5
7
Number of EDs N
0.45
0.50
0.55
0.60
Long-term average accuracy ¯c (%)
(d)
Fig. 8: The system performance under various number of EDs N.
in gap reduction, respectively. Fig. 7(b) presents the long-
term average latency ¯τ. As expected, DelayMin maintains
minimal latency through persistent highest-degradation trans-
missions, while DelayObli incurs maximum latency due to
full-resolution image ofﬂoading without any degradation. LAB
exhibits marginally higher latency than IDEAL (within 0.07
s across all λ values), yet reduces latency by 32.96% and
42.60% on average compared to BO and DBAG. Figs. 7(c)
and (d) simultaneously depict long-term average conﬁdence ¯α
and accuracy ¯c = 1
T
PT −1
t=0
PN
n=1 ct,n, both exhibiting similar
trends across λ variations. Focusing on practical detection
performance, LAB achieves near-ideal accuracy with only
1.22% average deﬁcit relative to IDEAL, while surpassing
BO and DBAG by 0.7% and 3.29%, respectively. Collec-
tively, these results demonstrate the ability of LAB to provide
enhanced detection accuracy while simultaneously reducing
latency compared to both BO and DBAG.
In Fig. 8, we examine the system scalability under varying
numbers of EDs N. In Fig. 8(a), we observe a notable
crossover between DelayObliv and DelayMin at N = 3.
This occurs because ﬁxed total bandwidth allocation reduces


--- Page 12 ---
12
1
3
5
7
Number of EDs N
2
3
4
5
6
7
Long-term average candidates number ¯K
LAB
Fig. 9: The average number of candidates under various number of EDs K.
available bandwidth per ED as N increases, causing De-
layObliv’s full-resolution transmissions to incur prohibitive
latency. Simultaneously, DBAG exhibits diminishing utility
with network expansion, ultimately performing below De-
layMin at N = 7. In contrast, LAB achieves an average
optimality utility gap of 9.94% relative to IDEAL, improving
upon BO and DBAG by 8.21% and 14.58% on average,
respectively. Fig. 8(b) reveals escalating latency across all
methods with rising N. LAB maintains latency comparable to
IDEAL (0.04 s higher on average), while achieving substantial
latency reductions relative to BO (35.08% lower) and DBAG
(47.35% lower) at N = 7. Figs. 8(c) and (d) demonstrate
similar conﬁdence and accuracy trends under network scaling.
Among all the considered methods, DelayObliv maintains the
highest accuracy by consistently transmitting full-resolution
images, while DelayMin yields the lowest accuracy through
persistent high-level degradation. LAB maintains an average
of 1.75% accuracy below IDEAL. Besides, it matches BO’s
accuracy within 0.15% and surpasses DBAG by 2.25% on
average. These results verify the ability of LAB to scale across
different network sizes.
To quantify the computational efﬁciency of LAB, Fig. 9
illustrates the long-term average number of candidate actions
¯K =
1
T
PT −1
t=0 Kt across varying numbers of EDs N. The
result shows that ¯K increases almost linearly with N. Unlike
BO which exhaustively evaluates all AN actions to maximize
the acquisition function, LAB drastically reduces computa-
tional overhead especially at large N. For example, when
N = 7 and A = 4, BO requires 47 = 16, 384 evaluations per
slot. In contrast, LAB maintains ¯K ≈7.7, reducing per-slot
evaluations by 3 orders of magnitude (over 2,000 times). This
near-linear scaling of ¯K with N underscores the suitability
of LAB for large-scale networks where standard BO becomes
computationally prohibitive.
VIII. CONCLUSION
This paper investigated task-oriented computation ofﬂoad-
ing in a multi-device EI system for visual object detection,
aiming to maximize long-term accuracy of all EDs while min-
imizing end-to-end inference latency under ﬁxed bandwidth
constraints. We formulated the problem as a black-box MINLP,
where the challenges lie in the content-dependent accuracy, ab-
sence of analytical models, and combinatorial complexity. To
solve this problem, we proposed LAB, a novel learning frame-
work that seamlessly integrates DRL and BO. Speciﬁcally,
LAB employed a DNN-based actor to generate degradation
actions and a BO-based critic with Gaussian process surro-
gates for optimal action selection, complemented by convex
optimization for bandwidth allocation. Extensive evaluations
on a real-world self-driving dataset demonstrated that LAB
achieves near-ideal accuracy-latency trade-offs. Crucially, it
outperforms conventional DRL in both accuracy and latency
performance, while surpassing standard BO with equivalent
accuracy yet signiﬁcantly faster inference and substantially
reduced computational overhead.
APPENDIX A
DEFINITIONS OF THE CONSTITUENT KERNELS
To effectively model the composite structure of the input
vector zt = (ht, at, t), we consider three specialized kernels
to capture the distinct nature of each component. In the
following, the subscript i and i′ denote time indices.
1) Channel State Kernel: To capture the similarity in con-
tinuous channel states ht, we utilize an automatic relevance
determination (ARD) radial basis function (RBF) kernel:
κrbf
θh (hi, hi′)= υh ·exp

−1
2 (hi−hi′)⊤diag(ℓ)−2(hi−hi′)

,
(43)
where θh = {υh, ℓ}. υh is an output-scale parameter weighting
channel state similarity. The diagonal matrix diag(ℓ), formed
from the length-scale vector ℓ= [ℓ1, · · · , ℓN]⊤, captures the
relevance of each dimension in ht for predicting Ut.
2) Degradation Action Kernel: To handle discrete degrada-
tion actions at, we implement a categorical kernel [31]:
κcat
υa (ai, ai′) = υa
N
N
X
n=1
I (ai,n = ai′,n) ,
(44)
where υa is an output-scale parameter weighting categorical
similarity.
3) Temporal Dynamics Kernel: To model time-varying cor-
relations arising from evolving channel conditions and content
characteristics, we employ a temporal kernel [31]:
κtmp
ρ
(i, i′) = (1 −ρ)
|i−i′|
2
,
(45)
where ρ ∈(0, 1) denotes the decay rate parameter con-
trolling correlation persistence over time. This formulation
ensures more recent observations exert stronger inﬂuence on
predictions and especially suitable for non-stationary system
behavior.
APPENDIX B
PROOF OF PROPOSITION 1
By taking the derivative of L in (28) with respect to τo
t,n
and bt,n, respectively, we have
∂L
∂τo
t,n
= wn −φndt,n
 τ o
t,n
2 ,
(46)
∂L
∂bt,n
=−φnW
ln 2

ln

1+ pnht,n
bt,nWσ2

−
pnht,n
bt,nWσ2+pnht,n

+η.
(47)


--- Page 13 ---
13
By setting (46) to 0, we obtain
τ o∗
t,n =
r
φ∗ndt,n
wn
.
(48)
By setting (47) to 0, we have

1+ pnht,n
bt,nWσ2

exp


1
1+ pnht,n
bt,nWσ2

=exp

1+ η ln 2
φnW

.
(49)
By solving (49), we obtain that
b∗
t,n =
−pnht,n
Wδ2
"
1 +

W

−
1
exp

η∗ln 2
φ∗nW +1

−1#,
(50)
where W(·) is the Lambert-W function.
REFERENCES
[1] L. Bai, J. Cao, M. Zhang, and B. Li, “Collaborative Edge Intelligence for
Autonomous Vehicles: Opportunities and Challenges,” IEEE Network,
vol. 39, no. 2, pp. 52–60, Mar. 2025.
[2] B. Yang, X. Cao, K. Xiong, C. Yuen, Y. L. Guan, S. Leng, L. Qian, and
Z. Han, “Edge Intelligence for Autonomous Driving in 6G Wireless
System: Design Challenges and Solutions,” IEEE Wireless Commun.,
vol. 28, no. 2, pp. 40–47, Apr. 2021.
[3] D. R. Morrison, S. H. Jacobson, J. J. Sauppe, and E. C. Sewell, “Branch-
and-Bound Algorithms: A Survey of Recent Advances in Searching,
Branching, and Pruning,” Discrete Optim., vol. 19, pp. 79–102, Feb.
2016.
[4] T. M. Shami, A. A. El-Saleh, M. Alswaitti, Q. Al-Tashi, M. A.
Summakieh, and S. Mirjalili, “Particle Swarm Optimization: A Compre-
hensive Survey,” IEEE Access, vol. 10, pp. 10 031–10 061, Feb. 2022.
[5] E.
Brochu,
V.
M.
Cora,
and
N.
de
Freitas,
“A
Tutorial
on
Bayesian
Optimization
of
Expensive
Cost
Functions,
with
Ap-
plication
to
Active
User
Modeling
and
Hierarchical
Reinforce-
ment Learning,” http://arxiv.org/abs/1012.2599, Dec. 2010. [Online]
http://arxiv.org/abs/1012.2599.
[6] X. Wang, Y. Jin, S. Schmitt, and M. Olhofer, “Recent Advances in
Bayesian Optimization,” ACM Comput, Surv,, vol. 55, no. 13s, pp.
287:1–287:36, Jul. 2023.
[7] K. Arulkumaran, M. P. Deisenroth, M. Brundage, and A. A. Bharath,
“Deep Reinforcement Learning: A Brief Survey,” IEEE Signal Process
Mag., vol. 34, no. 6, pp. 26–38, Nov. 2017.
[8] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Sil-
ver, and D. Wierstra, “Continuous Control with Deep Reinforcement
Learning,” Jul. 2019. [Online] http://arxiv.org/abs/1509.02971.
[9] L. Huang, S. Bi, and Y. J. A. Zhang, “Deep reinforcement learning
for online computation ofﬂoading in wireless powered mobile-edge
computing networks,” IEEE Trans. Mob. Comput., vol. 19, no. 11, pp.
2581–2593, Nov. 2020.
[10] T. T. Nguyen, V. N. Ha, L. B. Le, and R. Schober, “Joint Data
Compression and Computation Ofﬂoading in Hierarchical Fog-Cloud
Systems,” IEEE Trans. Wireless Commun., vol. 19, no. 1, pp. 293–309,
Jan. 2020.
[11] S. Bi, L. Huang, H. Wang, and Y.-J. A. Zhang, “Lyapunov-Guided Deep
Reinforcement Learning for Stable Online Computation Ofﬂoading in
Mobile-Edge Computing Networks,” IEEE Trans. Wireless Commun.,
vol. 20, no. 11, Nov. 2021.
[12] X. Li, S. Bi, Y. Zheng, and H. Wang, “Energy-Efﬁcient Online Data
Sensing and Processing in Wireless Powered Edge Computing Systems,”
IEEE Trans. Commun., vol. 70, no. 8, pp. 5612–5628, Aug. 2022.
[13] X. Li and S. Bi, “Optimal AI Model Splitting and Resource Allocation
for Device-Edge Co-Inference in Multi-User Wireless Sensing Systems,”
IEEE Trans. Wireless Commun., vol. 23, no. 9, pp. 11 094–11 108, Sep.
2024.
[14] F. Zhou, Y. Wu, R. Q. Hu, and Y. Qian, “Computation Rate Max-
imization in UAV-Enabled Wireless-powered Mobile-edge Computing
Systems,” IEEE J. Sel. Areas Commun., vol. 36, no. 9, pp. 1927–1941,
Aug. 2018.
[15] F. Wang, J. Xu, and Z. Ding, “Multi-antenna NOMA for Computation
Ofﬂoading in Multiuser Mobile Edge Computing Systems,” IEEE Trans.
Commun., vol. 67, no. 3, pp. 2450–2463, Mar. 2019.
[16] M. Gao, R. Shen, L. Shi, W. Qi, J. Li, and Y. Li, “Task Partitioning and
Ofﬂoading in DNN-Task Enabled Mobile Edge Computing Networks,”
IEEE Trans. Mob. Comput., vol. 22, no. 4, pp. 2435–2445, Apr. 2023.
[17] W. Yang, Z. Xiong, S. Guo, S. Mao, D. I. Kim, and M. Debbah,
“Efﬁcient Multi-User Ofﬂoading of Personalized Diffusion Models: A
DRL-Convex Hybrid Solution,” IEEE Trans. Mob. Comput., vol. 24,
no. 9, pp. 9092–9109, Sep. 2025.
[18] N. Ruiz, Y. Li, V. Jampani, Y. Pritch, M. Rubinstein, and K. Aberman,
“DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-
Driven Generation,” Mar. 2023 [Online] http://arxiv.org/abs/2208.12242.
[19] Z. Liu, Q. Lan, and K. Huang, “Resource Allocation for Multiuser
Edge Inference With Batching and Early Exiting,” IEEE J. Sel. Areas
Commun., vol. 41, no. 4, pp. 1186–1200, Apr. 2023.
[20] S. Wang, “Edge Video Analytics With Adaptive Information Gathering:
A Deep Reinforcement Learning Approach,” IEEE Trans. Wireless
Commun., vol. 22, no. 9, pp. 5800–5813, Sep. 2023.
[21] H. Tang, S. Bi, S. Wang, X. Lin, Y. Gu, and Z. Quan, “A Bayesian
Optimization Approach for Online System Conﬁguration of Edge Video
Analytics,” in proc. International Conference on Wireless Communica-
tions and Signal Processing (WCSP), Hefei, China, Oct. 2024, pp. 1–6.
[22] A. Galanopoulos, J. A. Ayala-Romero, D. J. Leith, and G. Iosiﬁdis,
“AutoML for Video Analytics with Edge Computing,” in proc. IEEE
Conference on Computer Communications (INFOCOM), Vancouver,
BC, Canada, May 2021, pp. 1–10.
[23] S. Gong, M. Wang, B. Gu, W. Zhang, D. T. Hoang, and D. Niyato,
“Bayesian Optimization Enhanced Deep Reinforcement Learning for
Trajectory Planning and Network Formation in Multi-UAV Networks,”
IEEE Trans. Veh. Technol., vol. 72, no. 8, pp. 10 933–10 948, Aug. 2023.
[24] P. Burt and E. Adelson, “The Laplacian Pyramid as a Compact Image
Code,” IEEE Trans. Commun., vol. 31, no. 4, pp. 532–540, Apr. 1983.
[25] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You Only
Look Once: Uniﬁed, Real-Time Object Detection,” May 2016. [Online]
http://arxiv.org/abs/1506.02640.
[26] S. P. Boyd and L. Vandenberghe, Convex Optimization.
Cambridge:
Cambridge University Press, 2004.
[27] S. Okada, M. Ohzeki, and S. Taguchi, “Efﬁcient Partition of Integer
Optimization Problems with One-hot Encoding,” Sci. Rep., vol. 9, no. 1,
p. 13036, Sep. 2019.
[28] G.
Jocher,
J.
Qiu,
and
A.
Chaurasia,
“Ultralytics
YOLO,”
https://github.com/ultralytics/ultralytics, accessed: Aug. 11, 2025.
[29] “Self
Driving
Car
Dataset,”
https://public.roboﬂow.com/object-
detection/self-driving-car, accessed: Aug. 11, 2025.
[30] “MOSEK
Optimization
Toolbox
for
MATLAB,”
https://docs.mosek.com/11.0/toolbox.pdf, accessed: Aug. 11 2025.
[31] J. Yan, Q. Qin, and G. B. Giannakis, “Bayesian Optimization for
Online Management in Dynamic Mobile Edge Computing,” IEEE Trans.
Wireless Commun., vol. 23, no. 4, pp. 3425–3436, Apr. 2024.
