--- Page 1 ---
1
Stochastic Modeling and Resource Dimensioning
of Multi-Cellular Edge Intelligent Systems
Jaume Anguera Peris, Joakim Jaldén
School of Electrical Engineering and Computer Science
KTH Royal Institute of Technology, Stockholm, Sweden
Email: {jaumeap, jalden}@kth.se
Abstract
Edge intelligence enables the execution of AI inference tasks on computing platforms at the network edge, typically
co-located with or near the radio access network rather than in centralized clouds or on mobile devices. This approach is
particularly well suited for data analytics of low-latency and resource-constrained applications, where large data volumes
and stringent latency constraints require tight integration of wireless access and on-site computational resources.
However, the performance and cost-eﬀiciency of such systems fundamentally depend on the joint dimensioning of
wireless and computational resources prior to deployment, specially amid spatial and temporal uncertainties. Prior
works largely emphasizes run-time resource allocation or employs simplified network models that decouple radio access
from computing infrastructure, overlooking end-to-end correlations in large-scale deployments. This paper introduces a
unified stochastic framework for dimensioning multi-cellular edge-intelligent systems. We model network topology via
a Poisson point process to capture randomness in user and base-station locations, incorporating inter-cell interference,
distance-proportional fractional power control, and peak-power constraints. Integrating this with queueing theory and
empirical profiling of AI inference workloads, we derive tractable expressions for the end-to-end offloading delay. These
enable a non-convex joint optimization problem for minimizing deployment costs while enforcing statistical quality-
of-service guarantees, defined not merely by averages, but by strict tail-latency and inference accuracy constraints.
We prove decomposability into convex sub-problems, ensuring global optimality with zero gap. Through numerical
evaluations in noise-limited and interference-limited regimes, we identify parameter regions that yield cost-eﬀicient
designs versus those that lead to severe under-utilization or unfairness across users. Key insights include the following:
smaller cells reduce transmission delay but cause higher per-request computing cost due to reduced multiplexing at the
servers, while larger cells exhibit the opposite trend. Moreover, network densification reduces computational costs only
when frequency reuse scales with base-station density; otherwise, sparse deployments enhance fairness and eﬀiciency in
interference-limited scenarios. Overall, our analysis provides system designers with principled guidelines for scalable,
QoS-aware provisioning of edge-intelligent video analytics in next-generation cellular networks.
I. Introduction
Edge intelligence has emerged as a paradigm shift in next-generation wireless networks, enabling the deployment of
learning-based models on computing platforms at the network edge, typically co-located with or near the radio access
network. This architecture is attractive for applications with latency stringent budgets and large data volumes, since
it reduces reliance on centralized clouds or resource-constrained mobile devices, alleviates backhaul congestion, and
arXiv:2601.16848v1  [cs.NI]  23 Jan 2026


--- Page 2 ---
2
enhances data privacy. For 5G and beyond-6G systems, these properties have made edge intelligence a key enabler
for AI video analytics sector [1], with recent market projections indicating it is expected to grow from 15.15 billion
USD in 2025 to 71.30 billion USD by 2033, at a compound annual growth rate of 21.4%, fueled by the expansion of
IP-based surveillance in smart cities, industrial automation, and public safety infrastructure [2]. As such, realizing the
full potential of edge-intelligent systems demands a precise dimensioning of the baseline resources (wireless spectrum
and computational capacity) required to statistically guarantee performance before a network is even deployed.
Despite this critical need for network planning, the existing literature on edge video analytics has primarily
concentrated on run-time optimizations. In this domain, where edge servers extract features to assist mobile users in
real-time decision-making, mobile users benefit from edge intelligence if the gains of processing their images at the
edge server are larger than the costs of transmitting the images through the wireless link. Consequently, significant
progress has been made in operational strategies to maximize these gains, such as selecting adequate edge servers
for fast response times [3], identifying and transferring only the most informative image regions [4], adapting image
formats to fluctuating network conditions [5], or partitioning the deep leaning models between mobile users and edge
servers to distribute image-processing workloads [6]. More recently, the work in [7] has introduced a framework to
manage computational redundancy and meet the strict tail-latency constraints required by safety-critical applications.
However, while these works emphasize the increasing interest in edge video analytics, they only provide effective
run-time strategies and do not address the dimensioning problem, which determines how many resources should be
deployed a priori to ensure stability and cost-eﬀiciency before these algorithms are even active.
Complementing these application-specific optimizations, a significant body of work addresses the operational phase
more broadly, formulating the trade-off between network latency, computational latency, and accuracy. The work
in [8] proposed a multi-objective optimization problem to dynamically select the optimal edge server and video frame
resolution. Extensions of this work account for the energy consumption of the entire offloading process, utilizing queuing
theory to address the dynamic decisions in the system [9]. Based on a similar idea, the authors in [10] employed two-
stage tandem queues to model transmission and computation, optimizing wireless and computing resources under
statistical QoS guarantees. More recently, the work in [11] further analyzed optimal resource provisioning for servers
accommodating diverse deep learning models and configurations. These foundational works represented a critical
advancement, moving from adapting parameters to understanding the cost-performance trade-offs of the physical
infrastructure itself. However, they are still operational strategies that overlook the infrastructure dimensioning and
planning stage, where the cost-eﬀiciency of the system is determined by the initial deployment of spectral and hardware
resources.
When shifting the focus to network planning and dimensioning, the challenge lies in modeling the inherent
stochasticity of large-scale deployments. Network traﬀic is driven by spatially random user events, wireless channels are
subject to path loss, fading, and interference, and edge servers face fluctuating inference workloads. Early works in this
domain formulated multi-objective optimization problems to find optimal edge server locations to balance workloads
and minimize latency [12]. Besides, the work in [13] analyzed the trade-off between the average computation latency
and the network connectivity in a more realistic scenario by considering the inherent aspects of noise, fading, and
interference in wireless communications. This was later extended in [14] to minimize energy consumption for statistical
guarantees of the joint success of wireless transmission and task computation. With this latter work, the integration
of stochastic geometry with edge intelligence has gained traction. The work in [1] derived performance metrics for


--- Page 3 ---
3
task-oriented heterogeneous networks, emphasizing the need for semantic-aware resource planning. In the context of
vehicular networks, the work in [15] applied stochastic geometry to model computation offloading under high mobility
and interference. Furthermore, the authors in [16] utilized stochastic geometry to model partial offloading reliability
in distributed edge-AI systems.
Despite these significant advances in joint communication and computation schemes, a critical gap remains in
the literature regarding the dimensioning of large-scale infrastructure. Existing single-cell frameworks predominantly
optimize resources under the assumption of homogeneous network conditions, failing to capture the spatial randomness
inherent in realistic deployments. On the other hand, while advanced multi-cellular systems incorporate the stochastic
nature of wireless communication, they face two distinct limitations regarding infrastructure dimensioning. First,
many frameworks decouple resource planning: radio access networks are dimensioned based on coverage capabilities or
spectral eﬀiciency metrics, while computing infrastructure are sized using independent queueing approximations. This
isolation fails to capture the end-to-end joint trade-off, where a spectral bottleneck can induce upstream starvation at
compute nodes, while under-provisioned servers with excessive queuing or inference delays can render high-capacity
wireless links ineffective. Second, even when resources are dimensioned jointly, existing approaches predominantly
rely on average performance metrics to ensure tractable convex optimization problems, failing to address the strict
tail-latency constraints required by next-generation applications.
To bridge this gap, we introduce a unified stochastic modeling framework for resource dimensioning in multi-
cellular edge-intelligent systems. By integrating stochastic geometry, queueing theory, and statistical modeling of AI
inference workloads, we model the end-to-end performance of edge-intelligent systems within a spatially random network
topology. While the framework is designed to be versatile and generalizable to various edge-intelligent workloads, we
illustrate the key concepts through the lens of edge video analytics as a representative high-bandwidth and latency-
critical use case. This allows us to formulate a joint optimization problem that determines the minimum cost-eﬀicient
bandwidth and computing capacity required to satisfy statistical quality-of-service guarantees, defined not merely by
averages, but by strict tail-latency and inference accuracy constraints.
A. Our contribution
This paper addresses the resource-dimensioning problem for a multi-cell system supporting edge video analytics
through rigorous performance modeling and analytical evaluation. In particular, the novelty of this work lies in the
development an optimization framework that enable precise performance analysis and evaluation of computing systems
under uncertainty, as follows:
• We present a stochastic geometry framework for the network topology of a single-input multiple-output (SIMO)
communication system, derive closed-form expressions for the ergodic capacity of the uplink transmission in both
noise-limited and interference-limited regimes, and provide design guidelines regarding key network parameters,
such as base station density, frequency reuse factor, and power control coeﬀicient.
• We characterize the dynamics of the task offloading process for both the noise-limited and interference-limited
systems using queueing theory, and we model the inherent relationship between the bandwidth and the compu-
tational resources as a function of the supported arrival rate of tasks at the edge server, the maximum permitted
end-to-end delay in the system, and the density of base stations in the network.


--- Page 4 ---
4
• We formulate a non-convex optimization problem to jointly optimize the communication and computing resources
such that a given set of users and a given set of edge servers meet the accuracy constraints of the video analytics
and satisfy a minimum probability of successfully completing the end-to-end process within a delay requirement.
• We break down the non-convex optimization problem into a series of convex sub-problems and provide a theoretical
analysis of the guarantees under which the sequential evaluation of these sub-problems leads to a globally optimal
solution of the large-scale resource-dimensioning problem.
• We evaluate the optimal solution of the non-convex optimization problem through simulation-based analysis and
discuss the trade-off between the different parameters of the system, with special focus on how the system scales
for varying density of base stations in the network, traﬀic intensity, per-user power control settings, and cellular
reuse factors.
By the end of this paper, readers will have a comprehensive understanding of the importance of resource dimensioning
for edge-intelligent, multi-cellular systems supporting video analytics, and the key factors that must be considered for
the joint optimization of wireless and computing resources under statistical QoS constraints.
B. Document organization
The remainder of this paper is organized as follows. Section II presents the stochastic geometry framework for
the network topology, derives the closed-form ergodic capacity for the uplink transmission, and provides design
guidelines regarding key network parameters. Section III characterizes the end-to-end latency, modeling the frame
arrival process, edge-server queueing dynamics, and the AI inference workload. In Section IV, we formulate the
joint resource-dimensioning optimization problem, define the statistical quality-of-service requirements, and provide
a theoretical analysis of the global optimality of the solution. Section V presents the numerical evaluation of the
proposed strategies in both noise-limited and interference-limited regimes. Finally, we summarize the main findings
and the concluding remarks in Section VI.
II. Network model
A. Base station deployment and user association
Consider a large-scale cellular network where the location of the base stations are modelled as a two-dimensional
homogeneous Poisson point process (PPP) with intensity λb. This stochastic geometry approach captures the spatial
randomness inherent in real-world cellular deployments, enabling tractable analysis of key network parameters while
aligning with established empirical observations [17]. As a direct consequence of this PPP model, we derive three
fundamental parameters of interest, illustrated in Figure 2(a), which characterize the geometric relationships between
users and base stations.
The first parameter of interest is the distance r between a typical user and its nearest serving base station, a critical
factor in determining coverage and signal quality. The cumulative distribution function (CDF) of the normalized
distance, defined as ¯r = √λbr, can be derived from the null probability of a two-dimensional PPP and follows a
Rayleigh distribution:
P(¯r ≤x) = 1 −e−πx2,
x ≥0.
(1)
This distribution captures the probabilistic nature of user-base station associations, providing a foundation for analyzing
the reliability of uplink transmissions.


--- Page 5 ---
5
The second parameter on interest is the maximum distance rmax from any user in a cell to its serving base station,
which defines the extent of Voronoi cells and informs of coverage limits for cell-edge users. For the normalized maximum
distance ¯rmax = √λbrmax, extensive numerical studies in the literature have established that its CDF is well-represented
by a Gamma distribution [18]:
P(¯rmax ≤x | α, β, γ) = αβγ/α
Γ(γ/α)
Z x
0
tγ−1e−βtα dt,
x ≥0,
(2)
with parameters (α, β, γ) = (1.719, 5.528, 9.482), where Γ(z) =
R ∞
0
tz−1e−tdt is the Gamma function. This form
captures the tail behavior of cell radii in random deployments, ensuring accurate modeling of the worst-case user
experience.
Lastly, the third parameter of interest is the area A of the Voronoi cells formed by the base stations, which governs
the spatial distribution of traﬀic and computational load across the network. For the normalized cell area ¯A = λbA,
prior analyses have established that its CDF is effectively approximated by a Gamma distribution [19]:
P( ¯A ≤x | α, β, γ) = αβγ/α
Γ(γ/α)
Z x
0
tγ−1e−βtα dt,
x ≥0,
(3)
with parameters (α, β, γ) = (1, 3.5, 3.5). This distribution accounts for the variability in cell sizes, enabling realistic
modeling of traﬀic distribution for different network densities.
Note that these three measures (r, rmax, and A) all scale inversely to the density of base station per unit area for
any arbitrary λb > 0, yet remain independent of other system variable. Besides, these geometric characterizations
form the basis for modeling uplink transmissions in the multi-cell environment, where user distances and cell areas
directly influence signal quality and interference, as explored next.
B. Uplink transmission model
Consider a large-scale multi-cell SIMO network where each base station is equipped with M ≥1 antennas and
is co-located with an edge server supporting AI-based applications for video analytics. Mobile users are uniformly
distributed over the network area and are associated with the base station that provides the maximum received power
averaged over fading. Each video-analytics user is allocated a dedicated bandwidth B for uplink frame transmission
through a high-priority dynamic network slice that guarantees immediate wireless access [20]. Within each slice, base
stations employ frequency-division multiple access with frequency reuse factor δ, resulting in inter-cell interference
but eliminating intra-cell interference. Furthermore, each base station schedules exactly one active user per frequency
sub-band, selected uniformly at random from the users within its Voronoi cell.
The signals between any pair of transmitter and receiver antennas experience independent and identically distributed
(i.i.d.) Rayleigh fading with path-loss exponent α > 2. The effective scalar channel gain after maximum-ratio combining
at the base station is modeled as ∥g∥2 = PM
m=1 |gm|2, where |gm|2 ∼exp(γ) is an Exponential random variable
representing the small-scale fading, γ = (λc/(4π))2 denotes the distance-dependent path loss, and λc is the wavelength
of the carrier frequency. Consequently, the channel gain ∥g∥2 for M co-located antennas follows a Gamma distributed
with shape parameter M and scale parameter γ.
Users implement distance-proportional fractional power control of the form Prαϵ, where P is the reference power
at 1 kilometer, r is the distance to its serving base station, and ϵ ∈[0, 1] is the power control coeﬀicient. To account
for the finite peak power of mobile devices, the transmit power is capped by the maximum transmit power ¯P. The


--- Page 6 ---
6
0
0.5
1
1.5
2
2.5
3
3.5
4
x
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Cumulative Distribution Function, F(x)
(a)
(b)
Fig. 1.
(a) Cumulative distribution function of the normalized distance between any user and its associated base station, and best-fit
approximations to the cumulative distribution functions of the normalized maximum distance squared (2) and the normalized area of the
Voronoi cells in two dimensions (3), taken from [18] and [19], respectively. (b) Multi-cell system with reuse factor δ = 1, where the user of
interest is located at the Voronoi cell of the base station on the right, and the interfering users are located elsewhere. The straight lines
show the different distances r, rz, and dz defined in Section II-B. The dashed lines show the signal of interest (blue) and the interfering
signals (red) at one of the M antennas at the receiver, characterized by the different Rayleigh fading coeﬀicients of the channel |g|2, and
|gz|2, respectively.
resulting distance-dependent transmit power function, incorporating both fractional power control and the peak-power
constraint, is therefore defined as
ℓ(r, α, ϵ) = min(Prαϵ, ¯P).
(4)
The additive receiver noise is white Gaussian with power σ2.
Inter-cell interference arises from the set Z of co-channel users active in other cells. Let rz denote the distance
from interferer z ∈Z to its serving base station, and dz the distance from interferer z to the base station of interest
(see Figure 1(b)). Note that the distances {rz}z∈Z are identically distributed but not necessarily independent. The
dependence arises from the structure of the Poisson-Voronoi tessellation and the single-user-per-band scheduling.
However, [21] demonstrates that this dependence is weak, allowing the distances rz to be approximated as i.i.d. As
such, and following the same null-probability argument as for the desired link distance r, we can model the marginal
distribution of rz as Rayleigh with cumulative distribution function given in (1). Lastly, we consider the interfering
signals to be projected onto the beamforming space in the direction of the signal of interest via Πg = ggH/∥g∥2. The
resulting effective interference channel gain is ∥Πggz∥2 ∼exp(γ) due to the isotropic nature of Rayleigh fading in the
projected subspace.
Under this transmission model, the uplink signal-to-interference-plus-noise ratio (SINR) for a typical user at distance
r from its serving base station is:
SINR =
∥g∥2
2 ℓ(r, α, ϵ) r−α
σ2 + P
z∈Z ∥Πg gz∥2
2 ℓ(rz, α, ϵ) d−α
z
.
(5)
This SINR expression lays the foundation for analyzing the trade-offs between spectral resources, base-station
density λb, and reuse factor δ. To evaluate the performance of the uplink transmission, we adopt the ergodic capacity


--- Page 7 ---
7
of the channel as the achievable uplink transmission rate, reflecting the system’s ability to enable fast or low-power
transmission for video-analytics users. In particular, depending on the different network parameters, the system may
operate in a noise-limited or interference-limited regime. We derive next the ergodic capacity for these cases separately,
for a user with allocated bandwidth B transmitting at a distance r from the base station.
Lemma II.1 (Noise-limited system). Consider a noise-limited uplink transmission in a single-input multiple-output
system with M ≥1 receiver antennas at the base station. Let a user at distance r (in kilometers) from its serving
base station transmit with power ℓ(r, α, ϵ) = min(Prαϵ, ¯P) over a bandwidth B (in Hz). Moreover, let the small-scale
fading channel gain ∥g∥2 follow a Gamma distribution with shape parameter M and scale parameter γ, as established
in the channel model, and let the noise power spectral density be N0 = σ2/B, where σ2 is the receiver noise power.
Then, the ergodic capacity (in bits per second) is given by
CNL(B, r) =
B
log(2) exp
 BN0 rα
γℓ(r, α, ϵ)
 M−1
X
i=0
Ei+1
 BN0 rα
γℓ(r, α, ϵ)

(6)
where Ei(x) =
R ∞
1
exp(−xt)/ti dt is the generalized exponential integral function for i ≥1.
Proof. Appendix A.
Lemma II.2 (Interference-limited system). Consider an interference-limited uplink transmission in a multi-cell single-
input multiple-output system with M ≥1 receiver antennas at the base station, operating under frequency-division
multiple access with reuse factor δ. Let a user at distance r (in kilometers) from its serving base station transmit with
power ℓ(r, α, ϵ) = min(Prαϵ, ¯P) over a bandwidth B (in Hz). Let the small-scale fading channel gain ∥g∥2 follow a
Gamma distribution with shape parameter M and scale parameter γ, and let the maximum-ratio combining vector for
beamforming projection onto the channel of interest be Πg = ggH/∥g∥2. Let base stations be distributed according
to a homogeneous Poisson point process with density λb (base stations per unit area), and let inter-cell interference
arise from a set Z of active co-channel users, each with distance dz to the base station of interest and distance rz
to their serving base station, where {rz}z∈Z are i.i.d. Rayleigh distributed. Then, the ergodic capacity (in bits per
second) is given by
CIL(B, r) =
B
log(2)
Z ∞
0

1 −
1
(1 + sγℓ(r, α, ϵ) r−α)M
L(s)
s
ds,
(7)
where the Laplace transform of the interference is
L(s) = exp

−2π λb
δ
Z ∞
r
β(x, s) x dx

,
(8)
with
β(x, s) = 1 −
Z ∞
0
2πλbu e−πλbu2
1 + sγℓ(u, α, ϵ)x−α du.
(9)
Proof. Appendix B.
For convenience, Table I summarizes the system parameters and notation used throughout the network, offloading,
and inference models. Scenario-dependent parameters and baseline parameter values are specified in Section V.


--- Page 8 ---
8
TABLE I
System parameters and notation for the multi-cell edge video analytics model
Symbol
Description
Network geometry and spectrum
λb
Spatial density of base stations in the network
δ
Number of orthogonal sub-bands for inter-cell interference mitigation
α
Power-law exponent of the large-scale path-loss model
fc
Center frequency of the uplink transmission band
Uplink transmission and power control
ϵ
Fractional compensation of path loss in uplink power control
P
Nominal transmit power normalized to unit distance
¯P
Maximum allowable uplink transmit power per user
N0
Noise power spectral density at the receiver
M
Number of receive antennas at each base station
Video frame and traﬀic model
s2
Frame resolution of a video frame (pixels)
θ
Number of bits per pixel after encoding
ξ
Video compression factor applied before transmission
λ
Frame arrival intensity of video frame generation requests
Edge inference and computing model
H
Total available computing resources at an edge server
Hf
Computing resources allocated per processed frame
Ts
Inference processing time for a video frame
a(s)
Accuracy of the AI model as a function of frame size
c1, c2
Latency model constants of the inference service-time model
c3, c4, c5
Accuracy model constants of the inference accuracy model
QoS constraints and optimization
D
End-to-end latency constraint for offloading and inference
ρ
Utilization factor of the edge server queue
ωmin
Minimum success probability of meeting the delay constraint
ηr
Cell-edge coverage (reliability constraint for worst-case user)
ηA
Cell-area coverage (reliability constraint over large Voronoi cells)
amin
Minimum inference accuracy
β1, β2
Cost weights of wireless and computing costs
ϑ
Regularization parameter in the optimization problem


--- Page 9 ---
9
C. Performance insights and design guidelines
The closed-form ergodic capacities derived in Lemmas II.1 and II.2 enable a systematic exploration of uplink
performance in edge-enabled multi-cell networks. While some trends align with intuition, several new insights that are
not readily available in prior stochastic-geometry literature emerge due to the combined consideration of fractional
power control with peak-power constraint, dynamic frequency reuse, and realistic distance distributions in Poisson–
Voronoi cells. With that in mind, we now evaluate their implications through numerical studies, uncovering trade-offs
in the different network design parameters.
From the analysis in Section II-B, notice that the power control coeﬀicient ϵ plays and important role on the
transmitted power. When ϵ = 0, the fractional power control provides an energy-preserving solution in which all users
transmit at the same power, and when ϵ = 1, the fractional power control aims to compensate for the propagation
losses, but, because of that, it is easier that users further from their serving base station reach their peak power
constraint. At the same time, since we are considering that mobile users operate with isotropic antennas, higher
transmitted powers also lead to potentially higher interference. The two most important parameters to control the
interference in our model are the density of base stations λb and the reuse factor δ. For our specific case scenario,
we consider λb to determine the density of base stations per unit area, and consequently, the density of edge servers
in the network, and consider δ to determine the number of different frequency bands used in the network, with just
one band assigned per base station. Hence, to aim for a fair comparison, the ratio λb/δ must remain constant, as this
leads to a system in which the total number of frequency bands, and hence interferers, remain the same, and the only
thing that changes is the way in which these bands are distributed over the network. Considering this, we analyze the
noise-limited and interference-limited scenarios separately.
Figure 2(a) shows the ergodic capacity of a noise-limited system as a function of the user–base-station distance r
for different fractional power control coeﬀicients ϵ when B = 1 MHz and M = 1. As we can see, the choice of ϵ ∈[0, 1]
significantly changes the ergodic capacity experienced by the users within the same cell. Small ϵ favors cell-center users
but severely penalizes cell-edge users, whereas high ϵ equalizes performance up to the threshold rth = ( ¯P/P)1/(αϵ),
beyond which users hit the peak-power limit and the capacity drops. When overlaid with the CDF of user distances
(dashed lines), it becomes evident that dense networks (λb ↑) benefit from low ϵ, whereas sparse networks require
higher ϵ to support users farther away. The density of base stations is therefore determinant when selecting the
optimal value of ϵ. For more information on the selection of ϵ, and why selecting a single network-wide power control
coeﬀicient is better than having multiple user-based power control coeﬀicients, one can read [21]. For our case scenario,
we simply consider ϵ = 0.5, as it provides a robust compromise between the benefits of ϵ = 0 and ϵ = 1, and results
in an acceptable ergodic capacity for the majority of users in the network.
Figure 2(b) shows the ergodic capacity of a noise-limited system as a function of the distance r for different number
of receiver antennas M when B = 1 MHz. As is the case in SIMO systems, users benefit from the spatial multiplexing
at the receiver, resulting in higher ergodic capacities for increasing M. Specially, notice that we have purposely selected
four powers of 4 for the different values of M. This is to show that the ergodic capacity increases logarithmically for
M, as the multiplexing gain comes from the effective scalar channel gain, which appears inside the logarithm when
calculating the ergodic capacity.
Figure 2(c) shows the ergodic capacity of an interference-limited system as a function of the distance r for different


--- Page 10 ---
10
density of base stations λb and for different number of receiver antennas M when B = 1 MHz and δ = 4. Notice that
higher values of λb represent denser networks, characterized by smaller coverage areas and shorter distances between
users and their serving base stations. Specially, since δ is not adjusted proportionally to λb, higher ratios of λb/δ lead
to higher interference and lower ergodic capacities. If we also consider the CDF of the maximum distance between
the users and their serving base station, we observe that denser networks exhibit larger capacity disparities among
cell-edge users (up to 1.5 Mbps spread for λb = 2 BS/km² compared to less than 1 Mbps for λb = 0.5 BS/km²). This
results highlights a fairness–throughput trade-off, where denser networks lead to higher disparities among cell-edge
users, whereas sparser networks lead to a more uniform experience among cell-edge users.
Figure 2(d) shows the ergodic capacity of an interference-limited system as a function of distance r for different
number of receiving antennas M when the reuse factor scales proportionally with base-station density (δ ∝λb) and
B = 1 MHz. Under this adaptive reuse strategy, the ratio λb/δ = 0.25 is held constant, so increasing λb yields
denser deployments with smaller cells and shorter average user–base-station distances, while the number of co-channel
interferers remains unchanged. The results reveal that ergodic capacity grows with λb and increases further with the
number of receive antennas M. Notably, a denser network equipped with fewer antennas per base station outperforms
a sparser network with more antennas when δ and λb are scaled proportionally. Moreover, comparing Figures 2(c)
and 2(d) reveals that the ergodic capacity is considerably more sensitive to the reuse factor δ than to base-station
density λb alone, underscoring the pivotal role of spectrum partitioning in interference-limited edge-intelligent networks.
Finally, Figures 2(e) and 2(f) show the ergodic capacity of an interference-limited system as a function of the distance
r for varying fractional power control coeﬀicients ϵ and different combinations of λb and δ. Notice that we have selected
the power control coeﬀicients in the range ϵ ∈[0, 0.5], as these are the values for which our interference-limited model
applies; other values outside this range would correspond to a system where the received signals are equally dominated
by noise and interference. Notice also that systems with the same ratio λb/δ and ϵ = 0 are analytically equivalent and
exhibit identical capacity curves. Considering both figures, we observe that higher ϵ provides high ergodic capacities for
users in small cells but degrades the ergodic capacities for users farther away. Again, ϵ = 0.5 emerges as a compromise
for fairness in interference-limited cases without sacrificing average throughput.
III. End-to-end offloading model
Having established the network model in Section II and analyzed its dependence on key network parameters, such
as base station density λb, frequency reuse factor δ, power-control coeﬀicient ϵ, and number of receive antennas
M, we now characterize the end-to-end delay experienced by video-analytics users. As illustrated in Figure 3, the
offloading process consists of three interdependent stages reflecting both wireless and computational dynamics: the
uplink transmission of each frame, the queueing at the edge server, and the execution of the AI inference task. To
enable a tractable analysis of this multi-stage process, we decompose the end-to-end delay as
Tul + Tw + Ts
(10)
where Tul is the time to transmit a frame, Tw is the time spent in the queue, and Ts is the time to process the frame.
We derive below closed-form expressions for each of these delay components.
The offloading process begins with the uplink transmission of a compressed video frame. Each user transmits frames
of resolution s × s pixels, originally encoded at θ bits per pixel and compressed by a factor ξ : 1. This yields a


--- Page 11 ---
11
0.5
1
1.5
2
2.5
3
3.5
4
Distance to the serving BS (km)
0
2
4
6
8
10
12
14
16
18
20
Ergodic capacity (Mbps), Noise limited
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
CCDF of the location of the users
(a)
0.5
1
1.5
2
2.5
3
3.5
4
Distance to the serving BS (km)
0
2
4
6
8
10
12
14
16
18
20
Ergodic capacity (Mbps), Noise limited
(b)
0.5
1
1.5
2
2.5
3
3.5
4
Distance to the serving BS (km)
1
2
3
4
5
6
7
Ergodic capacity (Mbps), Interference limited
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
CCDF of the maximum distance to the serving BS
(c)
0.5
1
1.5
2
2.5
3
3.5
4
Distance to the serving BS (km)
1
2
3
4
5
6
7
Ergodic capacity (Mbps), Interference limited
(d)
0.5
1
1.5
2
2.5
3
3.5
4
Distance to the serving BS (km)
0
1
2
3
4
5
6
7
8
9
Ergodic capacity (Mbps), Interference limited
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
CCDF of the maximum distance to the serving BS
(e)
0.5
1
1.5
2
2.5
3
3.5
4
Distance to the serving BS (km)
0
1
2
3
4
5
6
7
8
9
Ergodic capacity (Mbps), Interference limited
(f)
Fig. 2.
(a)-(f) Ergodic capacity for the noise-limited and the interference-limited systems as a function of the distance r between any
randomly selected user and its serving base station. Figure (a) analyzes the effect of the power control coeﬀicient ϵ while taking into
consideration the distribution of r. Figure (b) evaluates the ergodic capacity for different number of receiver antennas M. Figure (c)
analyzes the effect of the density of base stations λb for a constant reuse factor δ while taking into consideration the distribution of the
maximum distance between cell-edge users and their serving base station rmax. Figure (d) evaluates the ergodic capacity for different λb and
δ, with proportional ratios of λb/δ. Finally, Figures (c) and (d) analyzes the effect of ϵ for different λb and δ while taking into consideration
the distribution of rmax.


--- Page 12 ---
12
s
s
θs2/ξ bits
T ul
B
λA frames/s
T w
T s
H
Fig. 3.
End-to-end offloading timeline for a video-analytics task. Parameters in red correspond to the wireless and computing resources
that need to be optimized to satisfy the network, user, and video analytic requirements. Parameters in blue represent (from left to right)
the uplink, waiting, and service times of the end-to-end offloading process.
payload of θs2/ξ bits per frame. Therefore, for a user located at distance r from its serving base station and allocated
bandwidth B, the uplink transmission time is
Tul =
θs2
ξ ϕ(B, r),
(11)
where ϕ(B, r) is the achievable transmission rate. Depending on the operating regime, ϕ(B, r) is given by either of
the ergodic capacities derived in Section II-B:
ϕ(B, r) =





CNL(B, r)
Noise-limited, defined in (6),
CIL(B, r)
Interference-limited, defined in (7).
(12)
Having derived the uplink transmission delay Tul, we now characterize the arrival process at the edge server, which
depends on the spatial distribution of these delays. The frame generation by user devices is modeled as a spatio-
temporal Poisson point proces with intensity λ

frames · s−1 · km−2
. This assumes that frame generation events
occur independently across space and time, a standard abstraction in large-scale wireless networks with uncoordinated
users [22]. Since users are uniformly distributed within Voronoi cells and transmit independently, the uplink transmission
delays Tul are i.i.d. conditional on user locations. By the displacement theorem for Poisson point processes [23,
Theorem 1.3.9], independent random displacements in time preserve the Poisson structure of the arrival process.
Consequently, for an edge server whose Voronoi region has random area A, the aggregate arrival process is Poisson
distributed with intensity λA.
Once a frame is fully received at the base station, it is forwarded to the co-located edge server over a high-speed
internal link, whose propagation delay is negligible relative to the uplink transmission and inference times. Upon
arrival at the server, each frame is placed in an infinite buffer and processed according to a first-come–first-served
basis. The processing time Ts is deterministic and is determined by the resolution of the transmitted frames and the
available computational resources at the edge server. In particular, to perform the video-analytics inference on the
offloaded frames, the edge server utilizes a YOLOv5-based convolutional neural network [24], selected for its eﬀiciency
in real-time object detection on resource-constrained edge servers. Since YOLOv5 is capable of handling frames of
different resolutions without changing its associated learnable parameters, it allows parameterization of the inference
time. Following well-established profiling results for YOLOv5-based inference [8], the service time is
Ts = c1s3 + c2
H
,
(13)
where H is the available computational processing frequency at the server (in TFLOPS/s), and c1, c2 are positive
architecture-specific constants. The cubic dependence arises because the dominant operations (convolutions on feature


--- Page 13 ---
13
maps) scale nearly cubically with the input frame resolution. This model is widely used in performance evaluation of
edge-based deep learning and has been validated on both GPU- and accelerator-based edge servers [25].
Similarly, it is possible to parameterize the accuracy of the object detection algorithm as
a(s) = c3 −c4e−c5s,
(14)
for some other architecture-specific positive constants c3, c4, and c5, where the accuracy of the detection is measured
as the mean average precision of the object detection algorithm for a predefined threshold of the intersection over
union [8]. For more information on the parameterization of the deep learing algorithm and the effect of the learning
and inference processes on the constants c1, . . . , c5, refer to [26].
The combination of Poisson arrivals and deterministic service yields a M/D/1 queueing system with load ρ =
λA Ts < 1 required for stability. Considering this M/D/1 queue, the complementary cumulative distribution function
(CCDF) of the waiting time Tw can be derived from the state probabilities using the Erlang’s principle of statistical
equilibrium [27, Sections 10.4.2 and 10.4.4]. Specially, for a given load ρ and service time Ts, the CCDF of the waiting
time is
P(Tw > T) = 1 −(1 −ρ)
˜T
X
ν=0
[ρ(ν −t)]ν
ν!
e−ρ(ν−t),
(15)
for any T ≥0, where t =
T
Ts , and ˜T = ⌊t⌋is the greatest integer that is less than or equal to t. This function is
continuous and smooth, increasing monotonically for increasing ρ (higher loads lead to longer queues), and decreasing
monotonically for increasing Ts (faster service reduces queue backlog). Notably, it is concave in T ∈[0, Ts) and convex
in T ∈[Ts, ∞). These curvature transitions are critical when embedding (15) into the resource-dimensioning problem,
as they create non-convex feasible sets that must be handled with care.
Overall, these closed-form expressions for Tul, Tw, and Ts provide a tractable yet realistic framework for system
optimization. In the next section, we leverage this model to formulate and solve a joint resource-dimensioning problem,
minimizing deployed compute H and bandwidth B resources while satisfying probabilistic delay and minimum accuracy
constraints under spatial randomness.
Remark 1. Even though (15) is derived under Poisson arrivals (yielding an M/D/1 queue), real deployments may
exhibit some degree of burstiness due to protocol aggregation, scheduler coupling, or correlated sensing. A standard way
to capture such temporal correlation is to model the arrival stream by a Markovian Arrival Process, resulting instead
in an MAP/D/1 queue. Importantly, the qualitative curvature transition of (15) around the deterministic service time
Ts is induced by deterministic service rather than by the Poisson assumption itself. Accordingly, under MAP/D/1
the waiting-time distribution retains an analogous Ts-induced piece-wise structure, with burstiness primarily affecting
the magnitude of P(Tw > T) for a given load. Consequently, the M/D/1 queue serves as a representative baseline
that yields a tractable closed form and makes explicit the Ts-driven behavior, and burstiness can be incorporated by
replacing (15) with the corresponding MAP/D/1 waiting-time tail without changing the fundamental structure of the
offloading framework.
IV. Resource-dimensioning problem
In this section, we address the resource-dimensioning problem for the considered multi-cell edge video-analytic
system. Our goal is to determine the optimal bandwidth B allocated per frame transmission and the optimal computing


--- Page 14 ---
14
capacity H allocated at each edge-intelligent server, such that the system minimizes the costs per unit area while
satisfying statistical quality-of-service requirements. These requirements serve as key benchmarks for 5G/6G networks
and encompass latency, coverage for cell-edge users and servers, and accuracy of the video analytics. This focus is
essential because inadequate dimensioning of resources in edge computing systems can result in excessive operational
costs, degraded performance for delay-sensitive applications, and reduced energy eﬀiciency [28]. Considering this, we
first outline the quality-of-service requirements that guide our approach, followed by the formulation of the optimization
problem, and conclude with a theoretical analysis of its properties.
A. Quality-of-service requirements
In the considered edge-analytic systems, all frames receive the same bandwidth resources, all servers are equipped
with the same computing resources, and all users use the same power control coeﬀicient. Besides, all users can transmit
their frames, even those who are very far away from their base station and could know that their associated server
would process their frames late. As a result, the users that experience the largest Tul are the ones located at the cell
edge, and the users that experience the largest Tw and Ts are the ones located in large cell areas. Notice, however,
that these types of users are not necessarily mutually exclusive, as the Voronoi cells adopt irregular shapes, with users
being far from the base station, but nonetheless within large or small cell areas. Therefore, the optimization problem
is formulated under the constraints that the frames from the users at the cell edge and in large Voronoi cells satisfy
the quality requirements. That means, if the quality requirements of these users are satisfied for some B and H, then
the quality requirements of all the other users at closer distances to the base station and/or in smaller cell areas will
be satisfied as well for the same B and H. This worst-case approach ensures comprehensive coverage and QoS across
the network, preventing scenarios where central users benefit at the expense of edge users, which could otherwise lead
to unfair service distribution and potential system instability under high loads.
As for the entire end-to-end offloading process, we define the following:
Latency requirement: The delay of the entire offloading process, which starts when a user begins offloading a frame
and ends when the server finishes processing that frame, should be less than the maximum delay requirement D with
a minimum probability ωmin for all frames of all covered users. Formally,
P (Tul + Tw + Ts ≤D) ≥ωmin.
(16)
From the analysis in Section III, it follows that this probability can be calculated from the CCDF of the waiting time,
and the mathematical expression for uplink transmission time and service time, defined in (11) and (13), respectively.
For simplicity, we consider that all users in the network have the same delay requirements D and ωmin for all frames and
the same payload for all image processing tasks. Other cases are possible, but allowing for different delay requirements
or payloads in the system requires a more intricate network and server model, a topic we recognize as a potential
future research.
To ensure coverage,
QoS cell-edge users: The optimal bandwidth resources should ensure that at least ηr of the users located the furthest
from their serving base station have enough wireless resources to satisfy the latency requirement. Focusing on cell-
edge users is justified because they experience the highest path losses and lowest signal strengths, making them the
bottleneck for network performance. Thus, addressing their needs guarantees adequate service for all users. Formally,


--- Page 15 ---
15
we consider that the optimal bandwidth should be calculated considering that the maximum distance between any
user and its serving base station, rmax, satisfies
P

rmax ≤
p
λb x
 α, β, γ

≥ηr.
(17)
QoS servers: The optimal computing resources should ensure that at least ηA of the servers in the system have
enough computational resources to process the incoming traﬀic from its associated users and satisfy the latency
requirements. This server-centric QoS is crucial in multi-cell scenarios where cell sizes vary due to the PPP model,
leading to uneven load distribution. Ensuring a high percentage of servers meet the requirements prevents overload in
densely populated areas and maintains overall system reliability. Formally, we consider that the optimal computing
capacity should be calculated considering that the cell area from which an edge server processes its incoming traﬀic,
A, satisfies
P
 A ≤λb x
 α, β, γ

≥ηA.
(18)
Finally, considering the inference of the video analytics,
Accuracy requirement: The accuracy of the AI-based object detection algorithm should be above a minimum
threshold amin for all frames of all covered users. Maintaining high accuracy is imperative because suboptimal resource
allocation could force compromises in image quality, directly impacting the utility of edge intelligence applications.
Formally, we consider from the expression in (14) that the resolution of the transmitted frames should satisfy
s ≥1
c5
ln

c4
c3 −amin

.
(19)
Altogether, these latency, QoS, and accuracy requirements affect the entire offloading process, and they are crucial
to determining the optimal wireless and computing resources. By incorporating these constraints, our formulation
provides a balanced and justifiable framework that aligns with practical deployment needs and mitigates risks of
under-provisioning or over-provisioning wireless and computational resources.
B. Optimization problem
After formalizing the QoS requirements, we are now ready to formulate the resource-dimensioning problem. Our
objective is to minimize the total cost of wireless and computing resources per unit area in the multi-cell edge video-
analytic system. To achieve this, we adopt the weighted sum method [29] via the trade-off parameter β1 ∈[0, 1] to
balance the relative costs of bandwidth and computing capacity, assuming normalized units via a positive parameter
β2. This approach is justified as it allows for flexible weighting based on deployment-specific cost factors, such as
spectrum licensing fees versus hardware expenses, ensuring the model’s applicability across diverse scenarios without
loss of generality.
The problem is formulated as a joint optimization over the bandwidth B, computing capacity H, auxiliary variable
T, distance to the serving base station r, cell area A, and frame width/length s for a fixed arrival rate of tasks λ,
base station density λb, frequency reuse factor δ, delay requirement D, minimum success probability ωmin, coverage
probabilities ηr and ηA, and minimum accuracy amin. Specifically, the optimization problem is given by
minimize
{B,H,T,r,A,s}
β1λB + (1 −β1)β2λbH + ϑA
(20a)
subject to
P(Tw > T) ≤1 −ωmin,
(20b)


--- Page 16 ---
16
s2κ1
ϕ(B, r) + T + c1s3 + c2
H
= D,
(20c)
A (c1s3 + c2)κ2 ≤H,
(20d)
B > 0, H > 0, T ≥0,
(20e)
r ≥κ3, A ≥κ4, s ≥κ5,
(20f)
where ϕ(B, r) is defined in (12), and
κ1 = θ
ξ ,
κ2 =
λ
ρmax
,
κ3 = P−1
¯rmax(ηr)
√λb
,
κ4 = P−1
¯
A (ηA)
λb
,
κ5 = 1
c5
ln

c4
c3 −amin

,
(21)
are constants that depend on the network parameters defined in Section II.
Constraint (20b) ensures the queuing delay meets the probabilistic latency requirement, derived from the M/D/1
queue analysis in Section III. Constraint (20c) enforces the deterministic end-to-end delay bound, incorporating the
uplink transmission time Tul (which differs for noise-limited and interference-limited cases as per
(11)) and service
time Ts (13). Constraint (20d) guarantees that the server satisfies the demands of all users and does not overload.
Constraint (20e) limits the domain of the optimization variables. Finally, constraint (20f) guarantees coverage for
cell-edge users and servers using the inverse CDFs from stochastic geometry models in (17) and (18), and secures the
minimum accuracy via the resolution-accuracy relationship in (19).
This formulation is non-convex because constraints (20b), (20c), and (20d) are non-convex. To tackle this eﬀiciently,
we resort to breaking down the resource-dimensioning problem into a series of sub-problems, each containing only
a small set of optimization variables and constraints. Then, by solving these sub-problems sequentially, we aim to
establish feasibility and optimality guarantees for the original problem.
C. Theoretical analysis
We now delve into a more detailed theoretical analysis of the non-convex constraints of the optimization problem to
establish its structural properties and derive conditions under which the global optimum can be eﬀiciently obtained
through convex reformulation.
First, for the waiting time constraint (20b), recall from the analysis in Section III that the CCDF of the waiting
time is monotonically increasing for increasing ρ, monotonically decreasing for increasing Ts, concave in T ∈[0, Ts),
and convex in T ∈[Ts, ∞). Besides, if we combine the mathematical expression of the server load, ρ = λA Ts, with
the definition of the service time (13),
ρ = λA c1s3 + c2
H
,
(22)
we can further conclude that the CCDF of the waiting time is monotonically increasing for increasing A and s, and
monotonically decreasing for increasing H.
For the end-to-end delay constraint (20c), the ergodic capacities in both the noise-limited and interference-limited
regimes (defined in (6) and (7), respectively) are concave in B. Considering this, let us define the following functions,
f(x) = h(g(x)),
h(x) = 1
x,
g(x) = ϕ(x, r),
x > 0,
where f(x) represents the multiplicative inverse function of the ergodic capacity in terms of B, and g(x) represents
the ergodic capacity of the system for a given distance r. Since h(x) is convex and non-increasing, and g(x) is concave


--- Page 17 ---
17
in B, it follows from [30, Section 3.2.4] that f(B) is convex in B. Note also that the ergodic capacities are convex in
r. Considering this, let us define another set of functions,
˜f(x) = ˜h(˜g(x)),
˜h(x) = −1
x,
˜g(x) = −ϕ(B, x),
x > 0
where ˜f(x) represents the multiplicative inverse function of the ergodic capacity in terms of r, and ˜g(x) represents
the negative ergodic capacity of the system for a given bandwidth B. Since ˜h(x) is concave and non-decreasing, and
˜g(x) is concave in r, it follows from [30, Section 3.2.4] that ˜f(r) is concave in r. From this analysis, we can conclude
that constraint (20c) is convex in B, T, and H, and concave in r. Besides, if we consider the terms in the numerators
of the first and third summands, we can further conclude that constraint (20c) is convex in s.
For constraint (20c), note that the non-convexity comes from the multiplication of the two optimization variables
A and s. Otherwise, for a fixed s, the constraint is convex.
The above monotonicity properties imply that the CCDF of the waiting time (20b) and the delay of the entire
offloading process (20c) are monotonically increasing for increasing r and s. Conversely, both of these constraints are
monotonically decreasing for increasing B and H. Since we are minimizing the overall network resources, that optimal
solutions for r and s are given by their corresponding boundaries, defined in (20f). We therefore fix r = rmax = κ3 and
s = κ5, where κ3 and κ5 are constants obtained by inverting the corresponding CDFs and the accuracy-log-resolution
relationship.
With r and s fixed, the only remaining source of non-convexity is the equality in (20c) and the piece-wise definition
of the power control scheme in ℓ(r, α, ϵ). We address the equality in (20c) by relaxing it with an inequality, and
address the pice-wise dependence of the ergodic capacity on the peak power constraint (4) by utilizing the epigraph
representation of the min operator. For the latter, we specifically introduce two separate delay constraints: one for the
fractional power control regime (ϕlow) and one for the peak-power capped regime (ϕpeak), both of which are convex
in the optimization variables as the epigraph is an operation that preserve convexity [30, Section 3.2.3].
Putting all together, the reformulated optimization problem can be expressed over the bandwidth B, computing
capacity H, auxiliary variable T, and cell area A for a fixed arrival rate of tasks λ, base station density λb, frequency
reuse factor δ, delay requirement D, minimum success probability ωmin, coverage probabilities ηr and ηA, and minimum
accuracy amin as
minimize
{B,H,T,A}
β1λB + (1 −β1)β2λbH + ϑA
(23a)
subject to
P(Tw > T) ≤1 −ωmin,
(23b)
κ2
5 κ1
ϕlow(B, κ3) + T + c1κ3
5 + c2
H
≤D,
(23c)
κ2
5 κ1
ϕpeak(B, κ3) + T + c1κ3
5 + c2
H
≤D,
(23d)
A (c1κ3
5 + c2)κ2 ≤H,
(23e)
B > 0, H > 0, T ≥0, A ≥κ4,
(23f)
where
ϕlow(B, κ3) = ϕ(B, κ3)
when
ℓ(r, α, ϵ) = Prαϵ,


--- Page 18 ---
18
ϕpeak(B, κ3) = ϕ(B, κ3)
when
ℓ(r, α, ϵ) = ¯P,
are the ergodic capacities in the fractional and peak-power regimes evaluated at r = κ3.
Lemma IV.1. The solution to the reformulated convex problem (23) is globally optimal for the original non-convex
resource-dimensioning problem (20) if at least one of the following conditions holds:
T ∗≥c1κ3
5 + c2
H∗
or
ρ∗≥1 + W

−ωmin
e

,
(24)
where e = 2.718281 . . . is the Euler’s number, and W(·) is the principal branch of the Lambert function.
Proof. The only non-convexity in (23) is the concavity of the CCDF for T ∈[0, Ts). If the optimal solution satisfies
T ∗≥T ∗
s , the CCDF of the waiting time is convex in the relevant region, and thus the solution is globally optimal.
Here T ∗can be derived from the definition of the service time (13) and the optimal solution to the frame width/height,
κ5, given in (21). Alternatively, note that,
max
T ≥Ts P(Tw > T) = P(Tw > Ts) = 1 −(1 −ρ)eρ.
Thus, whenever 1 −ωmin ≤1 −(1 −ρ)eρ, the feasible set of the waiting-time constraint lies entirely in the convex
region T ≥Ts. Solving the inequality for ρ yields the second condition in (24). In both cases, the non-convex portion
of the feasible set is inactive, and the solution to (23) coincides with the global optimum of the original problem. This
concludes the proof.
Remark 2. Whenever the global-optimality conditions of Lemma IV.1 are satisfied, varying the trade-off parameter
β1 ∈(0, 1) in the objective function (23a) generates the complete Pareto frontier of communication cost per unit area
λbB versus computation cost per unit area λbH under the original statistical QoS constraints.
V. Numerical results
This section evaluates the resource-dimensioning problem for the multi-cellular SIMO system formulated in Sec-
tion IV. To provide a comprehensive assessment, we decouple the analysis into the noise-limited and interference-limited
regimes and examine how key network parameters influence the design of cost-eﬀicient strategies. The optimization
problem (23) is solved using the optimization solver from the SciPy library in Python. Regarding the generalized
exponential integral Ei(·) in the noise-limited ergodic capacity, we utilize the rational expressions and recurrence
relations provided in [31, Eq. 5.1.11, Eq. 5.1.14].
Unless stated otherwise, all results adopt the system parameters in Table II, which reflect the standard technical
specifications for a typical 5G urban/suburban [32] and a YOLOv5-based edge video-analytics application [8]. The
computation-accuracy trade-off (14) and service-time model (13) adopt the profiling methodology established in [8],
parameterized by c1 = 7·10−10, c2 = 0.083, c3 = 1, c4 = 1.578, and c5 = 6.5·10−3. These constants yield a root-mean-
square fitting error below 0.03 for both inference latency and accuracy.
A. Noise-limited system
Figures 4(a) and 4(b) shows the optimal per-frame bandwidth B, and the optimal per-frame computing capacity
Hf =
H
λA, and the resulting server load as a function of density of base stations λb, for different traﬀic intensities
λ. Increasing traﬀic intensity yields a clear statistical multiplexing gain at the edge servers, reducing the required


--- Page 19 ---
19
TABLE II
Baseline parameter values used in the numerical evaluations.
Path-loss exponent α
4
Power control coeﬀicient ϵ
0.5
Peak transmission power ¯P
23 dBm (200 mW)
Transmission power per unit distance P
10 dBm/km (10 mW/km)
Noise power spectral density N0
-174 dBm/Hz
Carrier frequency fc
2.4 GHz
Frame encoding rate θ
24 bits/pixel
Frame compression rate ξ
2
Number of receiver antennas M
16
Maximum load at the server ρmax
0.99 Erlangs
Maximum delay requirement D
500 ms
Minimum probability of success ωmin
0.8
Ratio of successful cell-edge users ηr
0.999
Ratio of successful cell areas ηA
0.999
Minimum object detection accuracy amin
0.9
Trade-off parameter objective function β1
0.5
Scaling parameter objective function β2
10−6
Regularization parameter objective function ϑ
1
wireless and computing resources per processed frame. Densification of base stations primarily benefits the wireless
link by shortening propagation distances and lowering path loss, thereby reducing the bandwidth needed to satisfy
latency constraints. In contrast, denser deployments reduce the average Voronoi cell area and hence the aggregation of
arrivals per server, which increases the computing capacity required to maintain tail-delay guarantees. Consequently,
the noise-limited regime exhibits a fundamental trade-off: wireless resources benefit from dense deployments, while
computational eﬀiciency improves in sparser deployments.
Figure 4(b) further shows that under low traﬀic load and high base-station density, servers may operate in an
under-utilized regime, increasing the cost per processed frame. In this region, the optimizer compensates by allocating
additional bandwidth (despite favorable propagation) to relax the computational constraints imposed by the end-to-end
latency requirement. At the same time, notice that all operating points in Figure 4(b) satisfy the global-optimality
condition in Lemma 4.1 based on server load, i.e., ρ∗≥ρmin = 1 + W (−ωmin/e). For ωmin = 0.8 (Table II),
the corresponding minimum load threshold is ρmin = 0.528, and the loads remain above this threshold across all
configurations. This confirms that the convex reformulation (23) attains the global optimum of the original non-
convex dimensioning problem (20).
Figure 4(c) characterizes the optimal dimensioning as a function of the trade-off parameter β1 for different traﬀic
intensities λ when λb = 2 BS/km2. Varying β1 ∈(0, 1) continuously shifts the resource dimensioning between
bandwidth-dominant and compute-dominant provisioning, producing a monotone trade-off between the two resource


--- Page 20 ---
20
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
100
150
200
250
300
350
400
450
500
Optimimal bandwidth and compute per frame
(a)
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
40
50
60
70
80
90
100
Server load (%)
(b)
0
0.2
0.4
0.6
0.8
1
300
400
500
600
700
800
900
1000
1100
1200
Optimal wireless resources per frame
100
150
200
250
300
350
400
450
Optimal cpmputational resrouces per frame
(c)
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
10-1
100
101
102
103
Optimimal offloading parameters (log-scale)
(d)
Fig. 4. (a)–(b) Optimal wireless and computing resources per frame, optimal server load, and total cost of the resource-dimensioning (in
millions) per unit area for a noise-limited system as a function of the density of base stations per unit area λb. (c) Effect of the trade-off
parameter β1 on the optimal resources for a noise-limited system with density λb = 2 BS/km2. (d) Optimal offloading parameters r, A,
and s for which the optimal B and H satisfy all the statistical QoS requirements. In all cases, the results are compared for different traﬀic
intensities λ, with Figure (d) yielding the same results for any λ.
dimensions. Moreover, since Lemma IV.1 holds, this parametric sweep generates the complete Pareto frontier of
communication versus computation cost per unit area, as stated in Remark 2. At the extremes β1 →0 and β1 →1,
the resource with vanishing weight in the objective can grow large, while the other resource approaches the minimal
provisioning required to satisfy the statistical latency and accuracy constraints. The near-symmetry of the curves
around β1 = 0.5 corroborates the adequate choice of the scaling parameter β2, which is selected to keep the bandwidth
and compute terms in (23a) on comparable magnitude.
Finally, Figure 4(d) confirms that optimal values of the auxiliary parameters r, A, and s are given by their lower
bounds, reflecting the monotonicity of the binding constraints. Any user farther from the optimal r would require
more wireless resources to avoid large propagation delays; any MEC server serving frames from users within a Voronoi
cell area bigger than the optimal A would require more computational resources to avoid overloading the server; and
any user offloading frames with any resolution higher than s would require more wireless and computational resources


--- Page 21 ---
21
to satisfy the latency requirements. Hence, there no cost-optimal incentive to serve users beyond the selected r, to
aggregate arrivals over areas larger than A, or to offload frames at higher resolution than s, since each of these changes
strictly tightens the QoS constraints and increases the required provisioning.
B. Interference-limited system
Figures 5(a) and 5(b) shows the optimal per-frame bandwidth B and the optimal per-frame computing capacity
Hf =
H
λA in the interference-limited regime as function of the base-station density λb under two different spectrum-
reuse strategies. In either case, we observe again that the communication and computational resources both benefit
from statistical multiplexing gain; that is, the higher the traﬀic in the system, the lower the number of resources
required per frame. However, in Figure 5(a), the reuse factor δ is kept constant while the network is densified. In
this case, increasing λb leads to a higher density of co-channel interferers, which offsets the benefits of shorter link
distances. As a result, the required bandwidth per frame does not decrease with densification. This behavior highlights
that densification under fixed reuse is fundamentally ineﬀicient in interference-limited systems, as it simultaneously
aggravates interference and reduces server-side aggregation gains.
In contrast, Figure 5(b) considers a proportional reuse strategy in which δ scales with λb, keeping the ratio
λb/δ = 0.25 constant. Under this interference-aware design, densification restores its effectiveness: shorter propagation
distances translate directly into reduced transmission delays, allowing both bandwidth and computing resources
per frame to decrease with increasing base-station density. The comparison between Figures5(a) and 5(b) therefore
demonstrates that network densification is only cost-eﬀicient in interference-limited regimes when accompanied by
appropriate spectrum partitioning. If such adaptation is not considered, denser deployments leads to higher overall
provisioning costs and degraded eﬀiciency.
These results emphasize that interference management, either through frequency reuse or equivalent coordina-
tion mechanisms, is a first-order design parameter in large-scale edge-intelligent networks. Unlike the noise-limited
regime, where densification inherently improves wireless performance, interference-limited systems require coordinated
spectrum scaling to unlock the potential benefits of dense deployments.
VI. Conclusions
This work established a comprehensive stochastic framework for the dimensioning of wireless and computational
resources in large-scale multi-cellular edge-intelligent systems. By jointly modeling spatial network randomness, uplink
transmission dynamics, queueing behavior at edge servers, and AI inference workloads, we characterized the end-to-end
performance of edge video analytics under realistic deployment conditions. Unlike prior work that focuses primarily on
run-time adaptation or average performance metrics, our approach addresses the planning-stage problem of resource
provisioning under strict statistical guarantees on latency, coverage, and inference accuracy.
A key analytical contribution is the derivation of closed-form expressions for the ergodic uplink capacity in both
noise-limited and interference-limited regimes, explicitly accounting for Poisson–Voronoi cell geometry, fractional power
control with peak-power constraints, and frequency reuse. These results expose how base-station density, reuse factor,
power-control parameters, and receiver antenna count jointly shape throughput, fairness, and interference. In particular,
we showed that densification of cellular radio access network alone does not universally improve performance: while


--- Page 22 ---
22
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
100
150
200
250
300
350
400
450
500
550
Optimal resources per frame (fixed reuse factor)
(a)
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
100
150
200
250
300
350
400
450
500
550
Optimal resources per frame (proportional ratio)
(b)
Fig. 5. (a)–(b) Optimal wireless and computing resources per frame for an interference-limited system as a function of the density of base
stations per unit area λb. Figures (a) and (b) analyze the effect of having a constant reuse factor δ, or adjusting δ in proportion to λb,
respectively. All the results are also compared for different traﬀic intensities λ.
shorter link distances benefit noise-limited systems, interference-limited networks can experience increased throughput
disparity and higher provisioning costs unless interference is explicitly managed.
Building on end-to-end offloading model, we formulated a global optimization problem that jointly dimensions
bandwidth and edge-computing hardware to minimize deployment cost while satisfying statistical guarantees on
latency and inference accuracy. In particular, the inherent relationship between the wireless and computing resources
is captured as a function of the supported arrival rate of tasks at the edge server, the maximum permitted end-to-end
delay in the system, the density of base stations in the network, and two intrinsic methods to manage the inter-cell
interference in large-scale networks: the cellular reuse factor and the per-user power control. Despite the inherent
non-convexity of the joint optimization, we provided a theoretical analysis to demonstrate that the problem can be
decomposed into a sequence of convex sub-problems, guaranteeing zero optimality gap under specific load conditions.
This result enables practical and reliable optimization of large-scale edge deployments without resorting to heuristic
approximations.
Our numerical results reveal fundamental trade-offs between wireless and computational eﬀiciencies in network
design. In noise-limited regimes, wireless resources benefit from network densification due to reduced path loss, whereas
computational eﬀiciency improves in sparser deployments that allow greater statistical multiplexing at edge servers.
In interference-limited regimes, however, densification is only cost-eﬀicient when accompanied by proportional scaling
of the frequency reuse factor; otherwise, fixed reuse leads to excessive interference, reduced fairness among cell-edge
users, and increased computational over-provisioning. These findings underscore that interference management is a
first-order design parameter for edge intelligence and must be considered jointly with compute provisioning.
Overall, this work demonstrates that cost-effective edge intelligence cannot be achieved by dimensioning radio access
and edge computing in isolation. Instead, it requires a holistic, stochastic design methodology that captures spatial
variability, traﬀic aggregation, and workload characteristics. Moreover, our proposed framework provides network
operators and system designers with quantitative guidelines for balancing spectrum allocation, hardware investment,
and quality-of-service guarantees in future 5G and beyond-6G edge-intelligent networks.


--- Page 23 ---
23
References
[1] X. Li, A. Liu, N. N. Chen, H. Dai, X. Wang, Z. Li, and X. S. Shen, “Task-oriented and semantic-aware heterogeneous networks for
artificial intelligence of things: Performance analysis and optimization,” IEEE Journal on Selected Areas in Communications, vol. 41,
no. 12, pp. 3761–3776, 2023.
[2] Grand View Research, “Ai video analytics market size & share | industry report 2033,” https://www.grandviewresearch.com/
industry-analysis/ai-video-analytics-market-report, 2025, accessed November 24, 2025.
[3] R. Hamadi, A. Khanfor, H. Ghazzai, and Y. Massoud, “A hybrid artificial neural network for task offloading in mobile edge computing,”
in IEEE Midwest Symposium on Circuits and Systems, 2022.
[4] B. Chen, Z. Yan, and K. Nahrstedt, “Context-aware image compression optimization for visual analytics offloading,” in Proceedings
of the 13th ACM Multimedia Systems Conference, 2022.
[5] H. Sun, Q. Li, K. Sha, and Y. Yu, “ElasticEdge: An intelligent elastic edge framework for live video analytics,” IEEE Internet of
Things Journal, vol. 9, no. 22, pp. 23 031–23 046, 2022.
[6] M. A. Khan, R. Hamila, A. Erbad, and M. Gabbouj, “Distributed inference in resource-constrained IoT for real-time video surveillance,”
IEEE Systems Journal, vol. 17, no. 1, pp. 1512–1523, 2022.
[7] J. Shokhanda, U. Pal, A. Kumar, S. Chattopadhyay, and A. Bhattacharya, “Safetail: eﬀicient tail latency optimization in edge service
scheduling via computational redundancy management,” arXiv preprint arXiv:2408.17171, 2024.
[8] Q. Liu, S. Huang, J. Opadere, and T. Han, “An edge network orchestrator for mobile augmented reality,” in IEEE Conference on
Computer Communications, 2018.
[9] C. Wang, S. Zhang, Y. Chen, Z. Qian, J. Wu, and M. Xiao, “Joint configuration adaptation and bandwidth allocation for edge-based
real-time video analytics,” in IEEE Conference on Computer Communications, 2020.
[10] Y. Wang, X. Tao, Y. T. Hou, and P. Zhang, “Effective capacity-based resource allocation in mobile edge computing with two-stage
tandem queues,” IEEE Transactions on Communications, vol. 67, no. 9, pp. 6221–6233, 2019.
[11] K. Zhao, Z. Zhou, X. Chen, R. Zhou, X. Zhang, S. Yu, and D. Wu, “EdgeAdaptor: Online configuration adaption, model selection and
resource provisioning for edge DNN inference serving at scale,” IEEE Transactions on Mobile Computing, 2022.
[12] S. Wang, Y. Zhao, J. Xu, J. Yuan, and C.-H. Hsu, “Edge server placement in mobile edge computing,” Journal of Parallel and
Distributed Computing, vol. 127, pp. 160–168, 2019.
[13] S. Ko, K. Han, and K. Huang, “Wireless networks for mobile edge computing: Spatial modeling and latency analysis,” IEEE Transactions
on Wireless Communications, vol. 17, no. 8, pp. 5225–5240, 2018.
[14] S. Mukherjee and J. Lee, “Edge computing-enabled cell-free massive MIMO systems,” IEEE Transactions on Wireless Communications,
vol. 19, no. 4, pp. 2884–2899, 2020.
[15] J. Yang, Z. Lin, Y. Chen, X. Lu, and Y. Fang, “Game-based computation offloading and resource allocation in stochastic geometry-
modeling vehicular networks,” Science China Information Sciences, vol. 67, no. 12, p. 229301, 2024.
[16] H. Saeedi and A. Nouruzi, “Stochastic geometric-based modeling for partial offloading task computing in edge-ai systems,” Sensors,
vol. 25, no. 22, p. 6892, 2025.
[17] S. N. Chiu, D. Stoyan, W. S. Kendall, and J. Mecke, Stochastic geometry and its applications.
John Wiley & Sons, 2013.
[18] J. Anguera-Peris and J. Jaldén, “Extreme distance distributions of Poisson Voronoi cells,” arXiv preprint arXiv:2405.07371, 2024.
[19] J.-S. Ferenc and Z. Néda, “On the size distribution of Poisson Voronoi cells,” Physica A: Statistical Mechanics and its Applications,
vol. 385, no. 2, pp. 518–526, 2007.
[20] P. Rost, C. Mannweiler, D. S. Michalopoulos, C. Sartori, V. Sciancalepore, N. Sastry, O. Holland, S. Tayade, B. Han, and D. Bega,
“Network slicing to enable scalability and flexibility in 5G mobile networks,” IEEE Communications magazine, 2017.
[21] T. D. Novlan, H. S. Dhillon, and J. G. Andrews, “Analytical modeling of uplink cellular networks,” IEEE Transactions on Wireless
Communications, vol. 12, no. 6, pp. 2669–2679, 2013.
[22] J. G. Andrews, F. Baccelli, and R. K. Ganti, “A tractable approach to coverage and rate in cellular networks,” IEEE Transactions on
communications, vol. 59, no. 11, pp. 3122–3134, 2011.
[23] F. Baccelli and B. Błaszczyszyn, “Stochastic geometry and wireless networks, volume i—theory, volume 3, no 3–4 of foundations and
trends in networking,” 2009.
[24] J. Redmon and G. Jocher, YOLOv5, 2021. [Online]. Available: https://github.com/ultralytics/yolov5
[25] Z. Wang and J. Anguera-Peris, “Performance evaluation of serverless edge computing for AI applications: Implementation, evaluation
and modeling of an object-detection application running on a serverless architecture implemented with Kubernetes,” 2022.
[26] A. Bochkovskiy, C.-Y. Wang, and H.-Y. M. Liao, “Yolov4: Optimal speed and accuracy of object detection,” arXiv preprint
arXiv:2004.10934, 2020.


--- Page 24 ---
24
[27] V. B. Iversen, “Teletraﬀic engineering and network planning,” Technical University of Denmark, p. 270, 2010.
[28] G. Premsankar and B. Ghaddar, “Energy-eﬀicient service placement for latency-sensitive applications in edge computing,” IEEE
internet of things journal, vol. 9, no. 18, pp. 17 926–17 937, 2022.
[29] R. T. Marler and J. S. Arora, “The weighted sum method for multi-objective optimization: New insights,” Structural and
multidisciplinary optimization, vol. 41, no. 6, pp. 853–862, 2010.
[30] S. P. Boyd and L. Vandenberghe, Convex optimization.
Cambridge university press, 2004.
[31] M. Abramowitz, I. A. Stegun, and R. H. Romer, Handbook of mathematical functions with formulas, graphs, and mathematical tables.
American Association of Physics Teachers, 1988.
[32] 3rd Generation Partnership Project (3GPP), “Study on channel model for frequencies from 0.5 to 100 GHz,” 3GPP, Technical Report
TR 38.901, Dec. 2020. [Online]. Available: https://www.3gpp.org/DynaReport/38901.htm
[33] K. A. Hamdi, “A useful lemma for capacity analysis of fading interference channels,” IEEE Transactions on Communications, vol. 58,
no. 2, pp. 411–416, 2010.
Appendix
A. Ergodic capacity of noise-limited systems
Recall the uplink SINR expression in (5). In a noise-limited regime, where inter-cell interference is negligible, the
interference term in the denominator of (5) vanishes and the SINR reduces to the signal-to-noise ratio (SNR):
SNR = ∥g∥2
2 ℓ(r, α, ϵ) r−α
σ2
.
(25)
For a user with allocated bandwidth B transmitting at distance r from the base station, all quantities in (25) are
deterministic except for the small-scale fading gain ∥g∥2
2. Hence, the only source of randomness in the SNR is the
channel gain. In this setting, the ergodic capacity for such a user can be calculated as
¯CNL(B, r) = E[B log2(1 + SNR)]
(a)
=
B
log(2)
Z ∞
0
P (log(1 + SNR) ≥t) dt
(b)
=
B
log(2)
Z ∞
0
P

∥g∥2
2 ≥
(et −1) σ2
ℓ(r, α, ϵ) r−α

dt
where (a) follows from the fact that the expectation of any positive random variable X can be calculated in the sense
of Lebesgue-Stieltjes as E[X] =
R ∞
0
P (X ≥t) dt, and (b) follows from the definition of the SNR in (25). If we further
define the variable θ =
σ2rα
γℓ(r,α,ϵ), make the substitution y = (et −1)θ, and consider that ∥g∥2
2 follows the Gamma
distribution
P(∥g∥2 ≤x) = 1 −exp

−x
γ
 M−1
X
i=0
1
i!
x
γ
i
,
x > 0,
(26)
we can express the ergodic capacity as
¯CNL(B, r) =
B
log(2)
M−1
X
i=0
1
i!
Z ∞
0
yi
y + θe−ydy
(d)
=
B
log(2)
M−1
X
i=0
1
i!
Z ∞
0
yi−1e−ydy −θ
Z ∞
0
yi−1
y + θe−ydy

(e)
=
B
log(2)
M−1
X
i=0
eθEi+1(θ)
where (d) follows from partial fraction decomposition, and (e) follows from iteratively applying the same principle as
in (d) and using the fact that the generalized exponential integral function, defined as Ei(x) =
R ∞
1
e−xt
ti
dt, satisfies
the recursion
Ei+1(x) = 1
i

e−x −xEi(x)

,
∀i ≥1.


--- Page 25 ---
25
Lastly, after substituting back the expression for θ and expressing the noise power σ2 as the product of the power
spectral density of the noise N0 and the allocated bandwidth B, the final closed-form solution of the ergodic capacity
results in
¯CNL(B, r) =
B
log(2) exp
 BN0 rα
γℓ(r, α, ϵ)
 M−1
X
i=0
Ei+1
 BN0 rα
γℓ(r, α, ϵ)

.
B. Ergodic capacity of interference-limited systems
Starting from the uplink SINR expression in (5), the interference-limited regime corresponds to neglecting thermal
noise in the denominator. The SINR therefore reduces to the signal-to-interference ratio (SIR):
SIR =
∥g∥2
2 ℓ(r, α, ϵ) r−α
P
z∈Z ∥Πg gz∥2
2 ℓ(rz, α, ϵ) d−α
z
.
(27)
For a user with allocated bandwidth B transmitting at distance r from the base station, the sources of randomness
in the SIR in (27) are the channel coeﬀicients, the distances between the interfering users and their serving base
stations, and the distances between the interfering users and our base station of interest. The ergodic capacity can
then be calculated as
¯CIL(B, r) = E[B log2(1 + SIR)]
(a)
=
B
log(2) E
"Z ∞
0
1
s

1 −e−s∥g∥2
2 ℓ(r,α,ϵ) r−α
exp
 
−s
X
z∈Z
∥Πg gz∥2
2 ℓ(rz, α, ϵ) d−α
z
!
ds
#
(b)
=
B
log(2)
Z ∞
0
1
s

1 −E
h
e−s∥g∥2
2 ℓ(r,α,ϵ) r−αi
E
"
exp
 
−s
X
z∈Z
∥Πg gz∥2
2 ℓ(rz, α, ϵ) d−α
z
!#
ds
(c)
=
B
log(2)
Z ∞
0
1
s

1 −(1 + s γℓ(r, α, ϵ) r−α)−M
L(s)ds,
where (a) follows from the proof in [33, Lemma 1] and the definition of the SIR, (b) follows from the independence
between the signal of interest and the interfering signals, and (c) follows from the Laplace transform of the Gamma
distribution of ∥g∥2
2 in (26) and the definition of the Laplace transform of the interference, L(s).
Now, to derive L(s), we need to calculate Laplace transform of the aggregate interference experienced in the serving
base station of the user of interest. For that, recall that the set Z is the point process of co-channel interferers. Given
the frequency reuse factor δ, the effective density of co-channel base stations is λb/δ. The locations of the interfering
users are displaced from their serving base stations by distances rz, considered here to be Rayleigh distributed.
Moreover, using the approximation that the rz are i.i.d. and independent of dz, and modeling the interfering base
station locations as a PPP with density λb/δ outside the guard radius r (since the serving base station is the nearest,
there can be no interferers closer than r), we have:
L(s) = E
"
exp
 
−s
X
z∈Z
∥Πg gz∥2
2 ℓ(rz, α, ϵ) d−α
z
!#
= E
" Y
z∈Z
exp
 −s∥Πg gz∥2
2 ℓ(rz, α, ϵ) d−α
z

#
(d)
= E
" Y
z∈Z
Z ∞
0
2πλbu e−πλbu2 exp
 −s∥Πg gz∥2
2 ℓ(u, α, ϵ) d−α
z

du
#
(e)
= E
" Y
z∈Z
Z ∞
0
2πλbu e−πλbu2
1 + s γℓ(u, α, ϵ) d−α
z
du
#


--- Page 26 ---
26
(f)
= exp
 
−2π λb
δ
Z ∞
r
 
1 −
Z ∞
0
2πλbu e−πλbu2
1 + s γℓ(u, α, ϵ) x−α du
!
x dx
!
,
where (d) follows from the i.i.d. Rayleigh distributions of rz, (e) follows from the Laplace transform of the Exponential
distribution of ∥Πg gz∥2
2, and (f) follows from the probability generating function of the PPP that models the location
of the interfering users [17] when considering polar coordinates.
To ease the notation, we define the function
β(x, s) = 1 −
Z ∞
0
2πλbu e−πλbu2
1 + s γℓ(u, α, ϵ) x−α du
to represent the probability that an interferer at distance x from the serving base station contributes to the aggregate
interference, with the integral taken over the Rayleigh-distributed displacement rz = u of the interfering users from
their own base station. This compact form leads directly to the expression for L(s) as stated in Lemma II.2.
