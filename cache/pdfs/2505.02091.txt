--- Page 1 ---
LLM-OptiRA: LLM-Driven Optimization of
Resource Allocation for Non-Convex Problems in
Wireless Communications
Xinyue Peng∗, Yanming Liu†, Yihan Cang∗, Chaoqun Cao∗, Ming Chen∗§
*National Mobile Communications Research Laboratory, Southeast University, Nanjing, China
†ZheJiang University, Hangzhou, China
§Pervasive Communication Research Center, Purple Mountain Laboratories, Nanjing, China
Email:{xinyuepeng, yhcang, chqcao, chenming}@seu.edu.cn, {oceann24}@zju.edu.cn
Abstract—Solving non-convex resource allocation problems
poses significant challenges in wireless communication systems,
often beyond the capability of traditional optimization tech-
niques. To address this issue, we propose LLM-OptiRA, the
first framework that leverages large language models (LLMs)
to automatically detect and transform non-convex components
into solvable forms, enabling fully automated resolution of non-
convex resource allocation problems in wireless communication
systems. LLM-OptiRA not only simplifies problem-solving by
reducing reliance on expert knowledge, but also integrates error
correction and feasibility validation mechanisms to ensure ro-
bustness. Experimental results show that LLM-OptiRA achieves
an execution rate of 96% and a success rate of 80% on GPT-
4, significantly outperforming baseline approaches in complex
optimization tasks across diverse scenarios.
Index Terms—Non-convex optimization, large language mod-
els, resource allocation, wireless communications
I. INTRODUCTION
In wireless communication systems, resource allocation,
which includes spectrum allocation, power control, and in-
terference management, is crucial and widely applicable [1].
Convex optimization offers stable and efficient solutions,
especially when closed-form solutions are available. For in-
stance, fractional programming effectively optimizes metrics
like signal-to-interference-plus-noise ratio (SINR) and energy
efficiency in applications such as wireless power control and
beamforming [2]. However, many real-world problems are
non-convex. In multi-cell interference scenarios, for example,
non-convexity arises from coupled variables like transmit
power, bandwidth, and discrete user scheduling, complicating
optimal resource allocation. Addressing these issues often re-
quires complex modeling, transformation, and relaxation tech-
niques to convert non-convex problems into convex ones [3],
typically depending on expert knowledge such as advanced
mathematical optimization, signal processing principles, and
wireless network design strategies.
To reduce reliance on expert knowledge, recent research
shows that large language models (LLMs) show significant
potential in tackling complex mathematical problems. For
instance, LLMs achieve 97.1% accuracy in solving mathe-
matical challenges with zero-shot prompting on the GSM8K
dataset [4]. They can also address classical optimization
problems, such as linear regression and the traveling salesman
problem, through iterative methods [5]. Moreover, LLMs can
leverage existing solvers like Gurobi and CVXPY for opti-
mization tasks [6]. For example, the gurobi.abs function en-
ables direct modeling of ℓ1-norm objectives, allowing LLMs
to avoid redundant auxiliary constraints and variables, thus
accelerating the solving process [7]. However, these solvers
primarily handle convex problems, limiting their ability to
solve non-convex challenges directly, so LLMs must draw
on their own capabilities to transform and solve non-convex
challenges.
To enable more effective handling of complex optimization
problems, prompt engineering techniques [8] are introduced
to enhance their reasoning capabilities of LLMs. By adopting
structured prompts, LLMs can engage in multi-step opti-
mization processes, where techniques like chain-of-thought
and tree-of-thought significantly improve their performance in
solving complex mathematical issues [9]. Additionally, few-
shot or zero-shot learning methods [10] maximize the ap-
plication effectiveness of LLMs under limited computational
resources [11].
Recent studies show that LLMs effectively address opti-
mization complexities. The authors in [12] demonstrate that
LLMs can identify infeasible constraints and suggest methods
to relax or remove them, streamlining the solution process.
Additionally, LLMs have been applied in [7] for modeling,
code generation, and solving convex optimization problems.
However, while these studies have predominantly focused on
convex problems, the authors in [13] highlight LLMs’ poten-
tial in non-convex optimization within wireless communica-
tions. But their approach is limited to a simple communication
scenario and teaches LLMs only the numerical input-output
relationships instead of solving the underlying mathematical
problems, which undermines generalizability to more complex
non-convex problems.
To address the existing gap in applying LLMs to non-
convex optimization problems in wireless communication
systems, we introduce the LLM-OptiRA framework, which
leverages advancements in mathematical reasoning, prompt
arXiv:2505.02091v2  [cs.CL]  26 Sep 2025


--- Page 2 ---
Fig. 1: Overview of the LLM-OptiRA framework, which is designed to optimize various scenarios for wireless resource
allocation. It demonstrates the framework’s key steps through the example of user-beam allocation in a GEO satellite system.
engineering, and few-shot learning. The main contributions
of this paper are summarized as follows.
• We propose the LLM-OptiRA framework, the first ap-
plication to LLMs to address the non-convex resource
allocation problems in wireless communications. The
framework automatically detects non-convex components
and efficiently transforms them into convex problems,
significantly reducing reliance on expert knowledge and
enabling automated non-convex problem solving.
• We introduce Error Correction Loops (ECL) and Feasi-
bility Domain Correction (FDC) as refine stage within the
LLM-OptiRA framework. These enhancements not only
boost the reliability and performance of LLM-OptiRA’s
solutions but also improve other existing advanced meth-
ods, demonstrating the framework’s robustness in opti-
mizing resource allocation problems.
• Experimental results show that LLM-OptiRA achieves
an execution rate of 96% and a success rate of 80% on
the GPT-4 model, significantly outperforming baseline
methods. These results highlight LLM-OptiRA’s effec-
tiveness and robustness in solving non-convex problems
in wireless communication systems.
Our implementation is openly available for research here:
https://github.com/Tibbers0310/LLM-OptiRA
II. LLM-OPTIRA FRAMEWORK
This section details the specific steps of the LLM-OptiRA
framework, as illustrated in Fig. 1, with explanations based
on the GEO satellite user-beam allocation example [14].
A. Problem Description
In this step, users need to provide the LLM with a “problem
description” that includes the communication system back-
ground, optimization objectives, and the resource allocation
requirements. Given that the LLM has foundational commu-
nication knowledge, users can present the problem in natural
language without needing detailed formulas or specialized
modeling languages.
B. Mathematical Model Construction
After the user inputs the problem, the LLM first analyzes
the text and applies Named Entity Recognition (NER) meth-
ods [15] to identify entities related to optimization. Through
this approach, the model extracts key optimization variables
x = {x1, x2, . . . , xn}, such as power, time slots, and carriers.
Building on the extraction of optimization variables, the
model identifies the objective function by analyzing the text
for sentences that express the optimization goal. For example,
if the goal is to maximize sum rate Rtotal, the model locates
relevant terms and identifies associated variables, such as
transmit power x1 and time slots x2. This allows the model
to create a set of objectives O = {Rtotal, x1, x2, . . .}. With the
objective set O defined, the model synthesizes this informa-
tion to derive the mathematical expression for the objective
function f(x).
Next, the modeling of the constraints is conducted, for
which the model needs to recognize the types of variables
and the constraints. First, the model identifies the type of
each variable ti (e,g. integer or continuous), forming a set
of extracted optimization variables E = {(xi, ti)}. Next, the
model identifies the numerical values cj(where cj ∈C, C is
the set of constraint values) related to the constraints and then
analyzes the text to determine which optimization variable xi
corresponds to each cj. Following this, the model extracts
the sentences rij that mention these constraint relationships.
Finally, these correspondences are placed into the set of
constraint relationships Rc, defined as
Rc =
[
xi∈E, cj∈C
{(xi, cj, rij)}.
(1)
Once the sets E and Rc are established, the LLM utilizes
its expertise in communication theory and mathematical mod-


--- Page 3 ---
eling to convert the elements of these sets into specific math-
ematical expressions, with the inequality constraints denoted
as g(x) and the equality constraints represented as h(x).
Finally, to unify the representation of the optimization
problem into a standard form, the optimization problem P
can be expressed as
P :
minimize f(x)
s.t.
gi(x) ≤0,
i = 1, 2, . . . , m,
hj(x) = 0,
j = 1, 2, . . . , n,
(2)
where m represents the total number of inequality constraints,
while n denotes the total number of equality constraints.
C. Transformation from Non-Convex to Convex
In this step, the model first identifies non-convex compo-
nents from the objective function and constraints. This process
involves curvature analysis and assess the second derivative
(or Hessian matrix). If the entire optimization problem is
already convex, the model can proceed directly to the next
solving step.
For identified non-convex components, the model selects
suitable convex transformation methods for approximation or
relaxation, typically employing methods such as Semidefinite
Relaxation (SDR), Successive Convex Approximation (SCA),
or Lagrangian Relaxation [2]. For example, in maximizing
system sum rate problem, the coupling of SINR with log-
arithmic expressions results in non-convexity. This can be
addressed using SCA, which employs a first-order Taylor
expansion, allowing for the construction of a local convex
surrogate around the current solution xm. Consequently, the
convexified objective function fconvex(x) can be expressed as
fconvex(x) = fSCA(x) = f(xm) + ∇f(xm)T (x −xm), (3)
where fSCA(x) represents the sequential convex approxima-
tion, xm is the current solution, f(xm) is the the objective
function value at that point, and ∇f(xm) is the gradient.
Constraints gi(x) and hj(x) are adjusted according to
changes in the objective function. If they contain other non-
convex features, they can be convexified utilizing the same
principles. Ultimately, a complete convex optimization prob-
lem is obtained, allowing for the next steps in the solution
process.
D. Code Generation and Error Correction
With respect to the convex optimization problems, the
LLM generates corresponding Python code, denoted as Cgen,
to implement the optimization model. This code utilizes
optimization solvers, denoted as S, to efficiently solve the
optimization problem. While both solvers can handle convex
problems, CVXPY [6] is typically used for standard convex
optimization, whereas Gurobi excels in handling large-scale
and complex linear programming and mixed-integer problems.
Next, the code is executed, and to check execution success,
the metric Q is defined: if the code runs without errors,
Q = 1; if errors occur, Q = 0. Then if Q = 1, the solu-
tion y∗is obtained by minimizing the convexified objective
function using the code Cgen and the solver S, expressed as
y∗= minx fconvex(x∗; Cgen, S), where x∗is the optimized
variable. If the code execution fails, an error report R is
generated by the program, triggering the Error Correction
Loop (ECL), a component of the LLM-OptiRA framework
designed to resolve errors.
The principle of ECL is to systematically analyze and
adjust the reasons for code execution failure. In the k-
th iteration, ECL examines the error report R to identify
specific types of errors, such as incorrect parameter settings,
mismatched constraints, or logical errors. Based on these
findings, ECL then references the previously used solver S
to modify Cgen, ensuring it meets the required conditions for
successful execution. The updated code is re-executed until
it runs successfully, at which point the new solution y∗is
obtained, or the maximum iteration count K is reached. This
entire process, is represented as FECL(R, Cgen, S, k).
Consequently, the solution y∗is expressed as
y∗=
(
minx fconvex(x∗; Cgen, S)
if Q = 1,
FECL(R, Cgen, S, k)
if Q = 0 and k < K,
(4)
E. Result Validation
Based on the solution of the optimization problem, verifica-
tion is crucial for ensuring accuracy and effectiveness, which
can be divided into two parts.
1) Theoretical Consistency Validation: This validation is
set after the step of Mathematical Model Construction in II-B.
We utilize different criteria to evaluate various aspects of the
generated formulas. The first criterion, denoted as ξ1, checks
if the constructed formulas align with the problem description,
confirming that the objective function is appropriately set for
maximization or minimization. The second criterion, ξ2, en-
sures that no key variables or constraints are omitted. The third
criterion, ξ3, verifies that the types of optimization variables
match correctly. Finally, the criterion ξ4 assesses the accuracy
of numerical values, including necessary measurement unit
conversions.
LLM analyzes the problem context and the mathematical
formulas to evaluate the four criteria, which can be collec-
tively represented as the theoretical consistency metric T ,
expressed as
T = H(ξ1) · H(ξ2) · H(ξ3) · H(ξ4),
(5)
where each H(·) is an indicator function that takes the value
1 if the corresponding condition is met, and 0 otherwise.
2) Feasibility Validation: This validation is conducted after
successfully running the code and obtaining the solution y∗.
While transforming a non-convex problem into a convex
one, the model may relax constraints, potentially resulting
in a solution that does not satisfy the original constraints.
To ensure feasibility, the model substitutes the optimized
variable x∗into the original constraints, verifying gi(x∗) ≤0
and hj(x∗) = 0. This process enhances the reliability of


--- Page 4 ---
optimization results in practical applications, improving the
utility of the LLM-OptiRA framework.
Consequently, the feasibility validation metric V can be
expressed as follows
V = Fval(y∗| gi(x∗) ≤0, hj(x∗) = 0),
(6)
where Fval is the evaluation function that returns 1 if the
solution meets the original constraints and 0 otherwise.
F. Feasibility Domain Correction
If the optimized variable x∗is not within the feasible
domain, the Feasibility Domain Correction (FDC) program
is executed within the LLM-OptiRA framework. The process
is divided into two stages based on the maximum iteration
count L: in the first stage, the initial values of the optimiza-
tion variables are adjusted; if no feasible solution is found
after
 L
2

iterations, the second stage begins, reanalyzing the
original optimization problem.
In the first stage, the FDC program gradually adjusts the ini-
tial values x0 using the correction function Fadj(x0, ∆x, γ).
The adjustment ∆x and γ, representing the step size for
each adjustment, ensure gradual convergence to a feasible
solution. After each iteration, the current solution’s feasibility
is checked using the metric V. If feasible (i.e., V = 1), the
process stops, yielding the final solution y(final).
If no feasible solution is found after
 L
2

iterations, the
model transits to the second stage, utilizing the reanalysis
function Fre(P, l). Specifically, the model returns to the
convexification process outlined in II-C, where it analyzes
the original problem P, applies alternative methods for re-
convexification. It then generates new solving code and ex-
ecutes it to obtain a new solution. If this solution is still
infeasible, the process continues iterating until it either reaches
the maximum count L or identifies a feasible solution, which
then becomes the final solution y(final).
The entire process can be summarized by the following
equations
y(F DC)
l
=
(
Fadj(x0, ∆x, γ)
if V = 0 and l <
 L
2

,
Fre(P, l)
if V = 0 and
 L
2

≤l ≤L,
y(final) = y(F DC)
l
if V = 1.
(7)
Through this adaptive correction mechanism, the LLM-
OptiRA framework effectively resolves complex optimization
problems.
III. EXPERIMENT AND ANALYSIS
A. Dataset
To evaluate the performance of LLMs in solving non-
convex optimization problems in wireless communication
resource allocation, we need a corresponding dataset for
training. Since no existing dataset addresses this issue in
this field, we create the WireOpt dataset, which includes 100
optimization problems across various wireless communication
scenarios. This dataset serves as the experimental input for
assessing the performance of the LLM-OptiRA framework.
The dataset comprises 50 resource allocation problems ex-
tracted from textbooks, research papers, and Matlab documen-
tation [2] [16] [17], covering communication backgrounds,
optimization formulations, and simulation parameters. To ex-
pand the dataset, the LLM learns core patterns and generates
50 additional problems in diverse contexts.
B. Baseline Methods
To evaluate our method holistically, we compare LLM-
OptiRA with the baseline methods as
OptiMUS [7], a framework utilizing LLMs to formulate
and solve Mixed Integer Linear Programming (MILP) prob-
lems from natural language descriptions.
Chain-of-Thought (CoT) [18], generates a step-by-step
reasoning process, which encourages the model to break down
complex problems into smaller steps.
Plan-and-Solve (PS) [19], enhances LLMs’ reasoning by
dividing problem-solving into the model “plans” and “solves”.
CoT+Refine: Using the CoT method to solve optimization
problems, along with the refine stage from LLM-OptiRA
framework, which includes the ECL and FDC process.
PS+Refine:Using the PS method along with the refine stage
from LLM-OptiRA framework.
C. Evaluation Metrics
The methods are evaluated based on two primary metrics:
Success Rate and Execution Rate [7]. For each optimization
problem P ∈D, a total of N = 10 evaluations are conducted
using both models (GPT-4 and GPT-3.5), and the rates are
computed as the average of these evaluations.
• Success Rate is defined as the proportion of outputs
that yield an optimal solution based on code execution
and lie within the feasible domain while satisfying all
constraints, expressed as
Success Rate =
1
|D|
X
P∈D
 
1
N
N
X
i=1
VP
!
,
(8)
where VP = 1 indicates the solution of problem P is
feasible, and VP = 0 otherwise.
• Execution Rate measures the proportion of generated
code that successfully executes and produces outputs,
expressed as
Execution Rate =
1
|D|
X
P∈D
 
1
N
N
X
i=1
QP
!
,
(9)
where QP = 1 represents the code of problem P is
successful executed, and QP = 0 otherwise.
D. Performance Analysis of LLM-OptiRA
Fig.2 reveals the key insights into the performance of
the LLM-OptiRA framework, particularly in comparison to
baseline methods, highlighting the execution and success rates
across different configurations.
LLM-OptiRA
significantly
outperforms
other
baseline
methods in both success and execution rates. It achieves an


--- Page 5 ---
Fig. 2: Comparison of execution and success rates for different schemes using GPT-4 and GPT-3.5 models.
execution rate of 96%, surpassing OptiMUS’s 80% in GPT-
4, due to its robust code and effective error correction. Its
success rate of 80% in solving non-convex problems far
exceeds OptiMUS’s 50%, thanks to its specialized non-convex
to convex transformation module. Additionally, it outperforms
CoT and PS schemes, with a success rate exceeding PS’s 34%
and CoT’s 40%, highlighting its robustness and adaptability
in complex optimization tasks.
Even on the GPT-3.5 model, LLM-OptiRA demonstrates
impressive stability. The execution rate of LLM-OptiRA is
55%, surpassing OptiMUS’s 42% and significantly outpacing
CoT+Refine and PS+Refine, which stand at 33% and 36%,
respectively. Although its success rate drops to 50%, it still
outperforms OptiMUS at 24%, as well as CoT+Refine and
PS+Refine, which achieve only 22% and 20%. This perfor-
mance indicates that LLM-OptiRA remains effective even in
models with lower capabilities.
The Refine mechanism, powered by the robust optimization
capabilities of the LLM - OptiRA framework, significantly
boosts the performance of CoT and PS. For instance, the
execution rate of CoT rises from 53% to 70%, a remarkable
increase. Alongside this, the success rate also experiences a
significant improvement, clearly demonstrating that the struc-
tural advantages of our framework can effectively enhance the
overall performance of other models in multiple aspects.
E. Analysis of Ablation Experiments on LLM-OptiRA Frame-
work Components
The LLM-OptiRA framework consists of key processes,
evaluating the impact of removing components on model per-
formance. We now examine how these modifications compare
to the complete framework and affect outcomes. The o-convex
approach removes the convexification process. The o-ECL
approach omits ECL process, while o-FDC does not include
FDC process.
As shown in the Fig.3, o-convex significantly reduces both
the success and execution rates, highlighting the importance of
convexification within the LLM-OptiRA framework. Specifi-
cally, GPT-4’s success rate drops from 0.803 to 0.15, reflecting
a 79.8% decline, while the execution rate decreases from 0.96
to 0.616. This highlights the critical need for convexification
to transform non-convex problems into solvable forms.
Fig. 3: Impact of omitting key components of the LLM-
OptiRA framework on success and execution rates across
GPT-4 and GPT-3.5
o-ECL negatively impacts the execution rate, which subse-
quently lowers the success rate. For GPT-4, the execution rate
drops from 0.96 to 0.65, a 32.3% decrease, and the success
rate declines from 0.803 to 0.6, reflecting a 25.3% reduction.
This decrease in execution rates leads to an increase in failed
attempts to generate correct solutions, ultimately damaging
the overall success rate.
o-FDC primarily decreases the success rate, emphasizing
its role in ensuring solution feasibility. Experiments show that
without FDC, GPT-4’s success rate drops to 0.187, a 76.7%
reduction, while GPT-3.5’s falls to 0.062, an 87.6% decrease.
Although GPT-4’s execution rate remains at 0.75, the lack of
FDC means that many solutions may not be within feasible
regions, rendering them ineffective.
In summary, the absence of each component severely im-
pacts the LLM’s performance, demonstrating the importance
of every step in the LLM-OptiRA framework for improving
success and execution rates.
F. Maximum Iteration Count Analysis of ECL and FDC
The previous section highlights the significant roles that
ECL and FDC play in the performance of the LLM-OptiRA
framework. Therefore, this section delves deeper into their


--- Page 6 ---
Fig. 4: Success and execution rates for LLM-OptiRA under
different maximum iteration counts for ECL and FDC.
maximum iteration counts K and L, respectively, examining
their effects on the success and execution rates, as illustrated
in Fig.4.
ECL significantly improves success and execution rates,
especially in early iterations. For success rate, ECL rapidly
identifies and corrects key errors, boosting GPT-4’s success
rate from 60% to 82% and GPT-3.5’s from 25% to 58%,
surpassing PS+Refine when K = 4, , indicating that ECL
is effective for both high- and low-performance models. Exe-
cution gains are concentrated in initial iterations, with GPT-4
reaching 96% by the fourth iteration. Despite GPT-3.5’s lower
baseline, ECL raises its execution rate from 25% to 62%.
To balance performance and computation, the framework sets
K = 4.
FDC demonstrates notable improvements in success rate
and maintains steady execution rate enhancements with in-
creasing iterations. GPT-4’s success rate increases from 19%
to 81%, and GPT-3.5’s from 6% to 52%, outperforming
CoT and PS Refine. These gains stem from FDC’s iterative
adjustment mechanism, which corrects solutions early and re-
examines the problem at
 L
2

iterations to fix infeasibility.
Although FDC primarily focuses on ensuring solution feasi-
bility, FDC also indirectly boosts execution rates by stabilizing
the solving process, even under low initial performance. The
framework sets L = 5 to balance correction depth and
efficiency.
ACKNOWLEDGMENT
This work has been supported by the key research
and development plan projects of Jiangsu Province under
BE2022316 and Key R&D Program of the National Ministry
of Science and Technology (2023YFB2905603)
IV. CONCLUSION
In this paper, we propose LLM-OptiRA, a groundbreaking
framework that leverages LLMs to tackle non-convex resource
allocation problems in wireless communication systems. Our
experimental analysis shows that LLM-OptiRA achieves an
execution rate of 96% and a success rate of 80% on the
GPT-4 model, significantly outperforming baseline methods.
The framework’s success hinges on its integrated components
as convexification, error correction, and feasibility checking,
each of which plays a critical role in enhancing solution
quality and overall robustness. Ultimately, LLM-OptiRA sets
a new standard for automated resource allocation, demonstrat-
ing its capabilities in complex optimization scenarios.
REFERENCES
[1] H. Zhou, M. Erol-Kantarci, Y. Liu, and H. V. Poor, “A survey on model-
based, heuristic, and machine learning optimization approaches in ris-
aided wireless networks,” IEEE Communications Surveys & Tutorials,
2023.
[2] K. Shen and W. Yu, “Fractional programming for communication
systems—part i: Power control and beamforming,” IEEE Transactions
on Signal Processing, vol. 66, no. 10, pp. 2616–2630, 2018.
[3] H. Zhou, C. Hu, Y. Yuan, Y. Cui, Y. Jin, C. Chen, H. Wu, D. Yuan,
L. Jiang, D. Wu et al., “Large language model (llm) for telecommu-
nications: A comprehensive survey on principles, key techniques, and
opportunities,” arXiv preprint arXiv:2405.10825, 2024.
[4] Q. Zhong, K. Wang, Z. Xu, J. Liu, L. Ding, B. Du, and D. Tao,
“Achieving¿ 97% on gsm8k: Deeply understanding the problems makes
llms perfect reasoners,” arXiv preprint arXiv:2404.14963, 2024.
[5] C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le, D. Zhou, and X. Chen,
“Large language models as optimizers,” in The Twelfth International
Conference on Learning Representations, 2024. [Online]. Available:
https://openreview.net/forum?id=Bb4VGOWELI
[6] S. Diamond and S. Boyd, “Cvxpy: A python-embedded modeling lan-
guage for convex optimization,” Journal of Machine Learning Research,
vol. 17, no. 83, pp. 1–5, 2016.
[7] A. AhmadiTeshnizi, W. Gao, and M. Udell, “Optimus: Optimization
modeling using mip solvers and large language models,” arXiv preprint
arXiv:2310.06116, 2023.
[8] O. Rubin, J. Herzig, and J. Berant, “Learning to retrieve prompts for in-
context learning,” in Proceedings of the 2022 Conference of the North
American Chapter of the Association for Computational Linguistics:
Human Language Technologies, 2022, pp. 2655–2671.
[9] J. He-Yueya, G. Poesia, R. E. Wang, and N. D. Goodman, “Solving math
word problems by combining language models with symbolic solvers,”
arXiv preprint arXiv:2304.09102, 2023.
[10] T. B. Brown, “Language models are few-shot learners,” arXiv preprint
arXiv:2005.14165, 2020.
[11] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large lan-
guage models are zero-shot reasoners,” Advances in neural information
processing systems, vol. 35, pp. 22 199–22 213, 2022.
[12] H. Chen, G. E. Constante-Flores, and C. Li, “Diagnosing infeasible op-
timization problems using large language models,” INFOR: Information
Systems and Operational Research, pp. 1–15, 2024.
[13] W. Lee and J. Park, “Llm-empowered resource allocation in wireless
communications systems,” arXiv preprint arXiv:2408.02944, 2024.
[14] X. Peng, H. Du, C. Cao, and M. Chen, “Flexible user mapping and
resource allocation for enhanced system capacity in multi-beam geo
satellite systems,” 2024, in press.
[15] S. Wang, X. Sun, X. Li, R. Ouyang, F. Wu, T. Zhang, J. Li, and G. Wang,
“Gpt-ner: Named entity recognition via large language models,” arXiv
preprint arXiv:2304.10428, 2023.
[16] Y. T. Hou, Y. Shi, and H. D. Sherali, Convex programming and
applications.
Cambridge University Press, 2014, p. 38–60.
[17] T. M. Inc., “Matlab version: 9.13.0 (r2022b),” Natick, Massachusetts,
United States, 2022. [Online]. Available: https://www.mathworks.com
[18] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le,
D. Zhou et al., “Chain-of-thought prompting elicits reasoning in large
language models,” Advances in neural information processing systems,
vol. 35, pp. 24 824–24 837, 2022.
[19] L. Wang, W. Xu, Y. Lan, Z. Hu, Y. Lan, R. K.-W. Lee, and E.-P.
Lim, “Plan-and-solve prompting: Improving zero-shot chain-of-thought
reasoning by large language models,” arXiv preprint arXiv:2305.04091,
2023.
