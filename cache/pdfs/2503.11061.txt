--- Page 1 ---
i
i
“main” — 2025/3/18 — 1:26 — page 701 — #1
i
i
i
i
i
i
ADV. THEOR. MATH. PHYS.
Volume NN, Number 1, 701–722, 2025
Generative Modeling for Mathematical
Discovery
Jordan S. Ellenberga, Cristofero S. Fraser-Talienteb, Thomas R. Harveyc,d,
Karan Srivastavaa, and Andrew V. Sutherlandc
aUniversity of Wisconsin-Madison
bUniversity of Oxford
cMassachusetts Institute of Technology
dThe NSF Institute for Artificial Intelligence and Fundamental Interactions
We present a new implementation of the LLM-driven genetic algo-
rithm funsearch, whose aim is to generate examples of interest to
mathematicians and which has already had some success in prob-
lems in extremal combinatorics. Our implementation is designed
to be useful in practice for working mathematicians; it does not re-
quire expertise in machine learning or access to high-performance
computing resources. Applying funsearch to a new problem involves
modifying a small segment of Python code and selecting a large
language model (LLM) from one of many third-party providers.
We benchmarked our implementation on three different problems,
obtaining metrics that may inform applications of funsearch to
new problems. Our results demonstrate that funsearch successfully
learns in a variety of combinatorial and number-theoretic settings,
and in some contexts learns principles that generalize beyond the
problem originally trained on.
1. Introduction
Funsearch is a computational method for mathematical discovery that ex-
ploits the apparent coding expertise of large language models (LLMs) [1].
The structure of funsearch is that of a genetic algorithm, where the popula-
tion is a large collection of candidate Python scripts. These scripts are scored
by an external evaluator, and future generations of scripts are generated by
inputting some of the previous generation’s scripts into the prompts of an
LLM. The scripts selected for constructing the prompts are chosen based on
their scores, while ensuring diversity within the overall population to avoid
701
arXiv:2503.11061v2  [cs.LG]  17 Mar 2025


--- Page 2 ---
i
i
“main” — 2025/3/18 — 1:26 — page 702 — #2
i
i
i
i
i
i
702
Generative Modeling for Mathematical Discovery
convergence to local minima. This basic structure is shown in Figure 1, and
we proceed to describe each stage in further detail, but more exact specifi-
cations can be found in the appendices of the original paper [1].
Prompt
LLM
Scripts
Evaluator
Figure 1. The basic structure of funsearch.
funsearch is most effectively applied to inverse problems, where it is
relatively easy (typically solvable in polynomial time) to verify or score a
proposed solution, but significantly more challenging (often requiring super-
polynomial time) to discover such a solution in the first place. This approach
is particularly suited to combinatorial optimization problems, such as the cap
set problem introduced in Section 3.1. In practice, the authors of [1] discov-
ered that the most effective results are obtained by formulating the problem
using a priority function. In the simplest instance, the priority function dic-
tates the order in which elements should be assembled from a larger set to
create a special subset. A deterministic function ensures that the special
subset is always valid by preventing invalid elements from being added. The
priority function should therefore be thought of as a heuristic guiding rigor-
ous subset selection. It is the opinion of the authors that funsearch is likely
to be most useful in such ‘hard-soft’ settings, where the program designed by
the language model is allowed to be ‘imprecise’ in some appropriate sense,
because it is monitored by a rigorous evaluation function. As an example im-
plementation, Appendix A provides a straightforward funsearch specification
file for determining whether a number is prime1.
1This example turns out to be too simple for useful benchmarking, where the
correct program is frequently found within the first generation; it is worth noting
that funsearch has much more trouble when asked to determine whether a number
is five less than a prime, a question which is formally of the same level of complexity.


--- Page 3 ---
i
i
“main” — 2025/3/18 — 1:26 — page 703 — #3
i
i
i
i
i
i
Generative Modeling for Mathematical Discovery
703
The specification includes three functions: evaluate, solve, and priority.2
The evaluate function assesses and scores a given proposed solution. A pro-
posed solution consists of both the solve and priority functions. funsearch
evolves a population of priority functions, keeping the solve function con-
stant, in an effort to maximize the score provided by the evaluate function.
The distinction between priority and solve can best be understood by an
example. Suppose, for instance, we were trying to construct a large graph
on N vertices with no 4-cycles. The priority function might be a function
that assigns a real number to each pair of vertices, which we think of as a
potential edge. Then we might define the solve function as follows:
• start with the empty graph;
• check whether the highest-priority edge among those not only in the
graph would create a 4-cycle if added;
• if so, add it; if not, move on to the next highest-priority edge;
• if there are no more edges you can add without creating a 4-cycle,
terminate and return the current 4-cycle-free graph.
In other words, this version of solve is a greedy algorithm and priority
tells us in what order we should present the greedy algorithm with the edges.
(In this case, evaluate would just return the number of edges in the graph
returned by solve.)
There are many other ways we could set up solve. For instance, we could
have solve terminate the first time the highest-priority edge would create a 4-
cycle, instead of skipping on to the next highest-priority edge. Or solve could
start with the complete graph and remove edges in order of priority, skipping
any edges that aren’t contained in a 4-cycle, terminating when there are no
more 4-cycles left to remove. We could also define priority to be a function
which takes as input a graph and a pair of vertices, rather than just a pair
of vertices; then solve could take into account the current graph Γ, calling
priority(Γ, edge) in order to determine the priority of an edge given Γ.
A priority function is not intrinsically good or bad for a given problem;
it is only good or bad with reference to a specific choice of solve, which is
always held constant over the course of evolution.
The utility of the separation of priority and solve is that solve is under
the full control of the human operator, so if there are constraints we wish to
impose on the solutions (for instance, that they obey a certain symmetry) we
can accomplish that by putting a restriction in solve. The priority function,
2For clarity, we will always call the evolving function the ‘priority’ function.


--- Page 4 ---
i
i
“main” — 2025/3/18 — 1:26 — page 704 — #4
i
i
i
i
i
i
704
Generative Modeling for Mathematical Discovery
by contrast, is the one evolved by the LLM; we have very little control over
its features other than information provided in comments or the docstring
of the function that will be included in the prompt to the LLM.
The population of priority functions consists of valid Python scripts,
which are evolved according to an island model from genetic algorithms [2, 3].
The population is split into sub-populations, called islands, which evolve in-
dependently. For selection, an island is chosen first, followed by the random
selection of a program within that island weighted by its score. We period-
ically discard the half of the islands where the highest score is least, and
reinitialise these islands with scripts from the remaining islands.
By the above sample procedure, we select N scripts from a single island
to create the prompt for a pre-trained LLM3. These n scripts are sorted by
their score, and the kth entry is renamed to “priority_v⟨k −1⟩”. The prompt
is then of the same format as the specification (see Appendix [1]), but with
all N priority functions listed along with the header for priority_vN. This
prompt is then fed into the LLM, which generates a suggestion for a new
potential priority function. This stage is akin to the breeding and mutation
phases of a traditional genetic algorithm.
2. Implementation
Our implementation of funsearch is available in the GitHub repository [4]
https://github.com/kitft/funsearch
One can easily apply funsearch to a problem by writing a configuration
file such as that in Appendix A. Other configuration files can be found in
the examples folder of the GitHub repository [4]; this includes the three
problems we used in our benchmarks, which are discussed in the next sec-
tion. We introduce a number of new features not available in the original
implementation of funsearch [1]:
• support for non-priority-function program search (i.e. searching for a
function with arbitrary type signature);
• integration with Weights & Biases [5] for real-time monitoring and
logging;
• support for multiple LLM platforms or OpenRouter, as well as mixing
models within runs;
3We, and the authors of [1], set n = 2.


--- Page 5 ---
i
i
“main” — 2025/3/18 — 1:26 — page 705 — #5
i
i
i
i
i
i
Generative Modeling for Mathematical Discovery
705
• parallel processing: produced functions are evaluated across multiple
CPU cores and asynchronous API calls;
• improved safety features: code produced by the LLM is checked before
runtime for potentially dangerous operations (e.g. calls to the shell),
and sandboxing is supported at both the process and container level.
OpenRouter is a convenient service that provides API access to a vari-
ety of large language models from different providers. It acts as a routing
layer; we can use a single API endpoint instead of having to separately inte-
grate each provider’s API. This simplifies the process of experimenting with
different LLMs in the funsearch implementation.
3. Problems
In this section we present the three problems we used to test our new imple-
mentation of funsearch: cap-set, narrow-admissible-tuple, and no-isosceles.
3.1. Cap sets
The cap-set problem [6] was the original problem considered for funsearch
in [1], which found the largest known cap set of size 512 in 8 dimensions. As
such, it makes sense to include this problem. However, we must acknowledge
that any model trained after the release of the original funsearch article may
have incorporated the record-breaking program into its training data. This
presents a potential issue that is likely to become a general concern in the
future when benchmarking LLMs on mathematical tasks.
The baseline priority–solve setup for cap-set is as follows.
• priority takes as input an integer n and an element of (Z/3Z)n, and
outputs a real number.
• solve takes n as input, starts with an empty subset of (Z/3Z)n and
adds points in order of priority, skipping any points that would create
a set of three vectors summing to zero. Terminate when no more points
can be added without violating this constraint. The evaluate function
returns the size of the resulting set.
The cap-set problem is one of combinatorial optimization: the task is to
find the largest possible set of vectors in Zn
3 such that no three vectors sum
to zero. Exact results are known up to n = 6, but the exponential growth


--- Page 6 ---
i
i
“main” — 2025/3/18 — 1:26 — page 706 — #6
i
i
i
i
i
i
706
Generative Modeling for Mathematical Discovery
of the environment with n quickly leads exhaustive searches intractable. At
n = 8, the environment consists of roughly 10760 combinations.
3.2. Narrow admissible tuples
An increasing sequence t of k integers that do not occupy every residue class
modulo any prime p is called an admissible k-tuple. If t = (t1, . . . , tk) is an
admissible k-tuple, then so are its translates t + a = (t1 + a, . . . , tk + a) by
integers a, so we assume without loss of generality that t1 = 0. Examples of
admissible k-tuples are (0, 2), (0, 2, 6), and (0, 4, 6), while (0, 1) and (0, 2, 4)
are nonexamples. The diameter of an admissible k-tuple (t1, . . . , tk) is tk −t1.
For positive integers j ≤k the Dickson–Hardy–Littlewood conjecture
DHL[k, j] states that every admissible k-tuple has infinitely many trans-
lates that contain at least j-primes; DHL[2, 2] implies the twin prime conjec-
ture via the admissible 2-tuple (0, 2), a conjecture that remains open. Yitang
Zhang [7] proved that DHL[3500000, 2] holds, which was eventually improved
by the Polymath8 [8] project on prime gaps to DHL[50, 2]. James Maynard
[9] (and independently Terence Tao) proved that for every positive j there
exists a k for which DHL[k, j] holds, and the Polymath8 project proved
DHL[k, j] for j = 2, 3, 4, 5, 6 and explicit values of k, including k = 35410
for j = 3. Julia Stadlmann [10] recently proved DHL[k = 35265, 3], which is
currently the best known result for j = 3.
Once DHL[k, j] is known, every admissible k-tuple of diameter d implies
the existence of infinitely many intervals of width d that contain j primes.
This motivates the narrow-admissible-tuple problem: given an integer k, find
an admissible k-tuple whose diameter is as small as possible.
Minimal diameters are known for all k ≤342, and for k = 50 this opti-
mal diameter is 242, which implies that there are infinitely many pairs of
adjacent primes separated by a gap of at most 242. For k = 35265 the nar-
rowest admissible k-tuple known has diameter d = 396504, but this diameter
is almost surely not minimal. The discovery of any 35265-tuple of smaller
diameter would improve the least d for which one can prove that there are
infinitely many triples of primes separated by a gap of at most d.
For k ≤5000 examples of the narrowest known admissible k-tuples can
be found at [11]. This database was constructed as part of the Polymath8
project using a variety of methods [12], including some genetic algorithms.
While many CPU-years of computation were invested in the construction of
this database, it remains likely that many of these tuples can be improved,
especially for larger values of k. For k = 35265 and d ≈396504 there are
more than 1050000 k-tuples whose admissibility one might want to consider.


--- Page 7 ---
i
i
“main” — 2025/3/18 — 1:26 — page 707 — #7
i
i
i
i
i
i
Generative Modeling for Mathematical Discovery
707
To search for narrow admissible tuples using funsearch, rather than fix-
ing k, we fix a bound n on the diameter and construct an admissible tuple by
sieving the integers in [0, n], removing one residue class for each prime p ≤n.
The k integers that remain will form an admissible k-tuple of diameter at
most n. The priority function takes integer inputs p and n, with p ≤n prime,
and returns an integer r specifying the residue class r + pZ to remove. The
starting priority function simply returns 1 on all inputs.
We note that with this setup the starting priority function and all con-
stant priority functions will yield only an admissible 2-tuple at best, so there
is a strong selection pressure toward nonconstant priority functions. We view
this as a feature for the purpose of testing the evolutionary capability of fun-
search, although it may make it more difficult to obtain record-breaking
results. An alternative approach along the lines of cap-set would have the
priority function rank the integers in [0, n] while the solve function builds
an admissible tuple by adding integers in order by rank, skipping those that
violate the admissibility condition. With this alternative setup a constant
priority function would already produce a fairly narrow admissible tuple
that is close to optimal for small values of n.
3.3. Subsets of the grid with no isosceles triangles
We say that a subset S of the regular n × n grid is no-isosceles if no three
distinct points form an isosceles triangle. (This constraint includes collinear
triples, in which an isosceles triangle is just a three-term arithmetic progres-
sion.) The problem of producing a large no-isosceles subset is an appealing
one for machine learning methods. As with the capset problem, the differ-
ence between the best known upper and lower bounds is very large. The best
known lower bound is on the order of n/√log n [13, Appendix A], while for
upper bounds the best we can do is n2−ϵ, arising from the easy observation
that the intersection of S with any column of the grid is a subset of the in-
terval with no three-term arithmetic progression. Applying funsearch to this
problem allows for direct comparison with another transformer-based exam-
ple generation protocol, PatternBoost [13, §4.1]. When n = 64, the largest
set of points found by any of our models in our benchmark has size 96; by
contrast, PatternBoost found a no-isosceles set of size 110 (starting from a
large population of sets of size 108 generated by non-LLM methods.)
We note that the no-isosceles problem, like the well-known no-three-in-
line problem, asks for large subsets of the grid that do not contain a triple
of points (x1, y1), (x2, y2), (x3, y3) for which a certain quadratic polynomial


--- Page 8 ---
i
i
“main” — 2025/3/18 — 1:26 — page 708 — #8
i
i
i
i
i
i
708
Generative Modeling for Mathematical Discovery
Q(x1, y1, x2, y2, x3, y3) vanishes. Automated approaches to these two prob-
lems and other problems in this family will likely be valuable in understand-
ing what happens for general quadratic forms Q.
By contrast with the other two problems discussed here, our main focus
in no-isosceles will not be comparing different models; beyond the baseline
benchmark, the work on no-isosceles here is centered on comparing differ-
ent ways of presenting funsearch with the same combinatorial problem, and
about how funsearch behaves when presented with variants of the problem.
A crucial thing mathematicians need to keep in mind when working with
machine learning is that distinctions which do not seem important to us can
have rather large effects on an algorithm’s performance.
4. Benchmarking
4.1. Baseline tests and reproducibility
We now present benchmarks of funsearch that we performed using the three
problems mentioned above. Specifically, we will evaluate the reproducibil-
ity of funsearch for the cap-set, narrow-admissible-tuple, and no-isosceles
problems, as shown in Tables 1, 2, and 3, respectively, across a range of dif-
ferent available models (LLMs). We also consider the effect of much longer
funsearch runs, using the gemini-2.0-flash model as an example, in Table. 4.
As a useful measure for these benchmarks, we define relative tokens for
a given model/provider via:
(4.1)
nR = pO
pI
nI + nO,
where nO and nI are the number of output and input tokens used, while
pO and pI are the current prices of the tokens. All the benchmarks that we
present here keep the number of relative tokens fixed, independent of the
model, cost, or running time. The authors believe that this measure is less
likely to be influenced by fluctuations in the cost per token or latency of
available models.
Our first observation is that there is little correlation between the model’s
cost and its effectiveness for funsearch. For instance, the most expensive
model we tested, gpt4o, performed the best on average for the no-isosceles
problem, was in the middle of the pack on the cap-set problem, and one of
the worst performers on the narrow-admissible-tuple problem.
Additionally, as can be inferred from Table 4, extended searches with fun-
search show little to no improvement. Indeed, for all three of the problems we


--- Page 9 ---
i
i
“main” — 2025/3/18 — 1:26 — page 709 — #9
i
i
i
i
i
i
Generative Modeling for Mathematical Discovery
709
tested using the gemini-2.0-flash model, the best score achieved during 8 in-
dependent runs using 2 × 106 relative tokens (total cost $4) was substantially
better than that achieved during a single run using 108 relative tokens (total
cost $25). One possible explanation for this is a path-dependence caused by
LLMs being more influenced by their previous choices (which are included in
the prompt) than is ideal; increasing the temperature might ameliorate this,
but this might also decrease the performance at early stages of the run and
reduce the proportion of viable responses (all the models will occasionally
return responses that are not valid Python programs).
In Tables 1–3 below, each run used a 2 × 106 relative tokens, with 16
samplers, 16 evaluators, and an island reset time of 15 minutes. There is
large variation in the cost of the open source models (indicated with a star)
when accessed via open router, depending on the provider. We therefore state
the average cost we paid for our benchmarks (run in February 2025).
Table 1. Results for 8 runs of the cap-set problem with n = 8 using 2 × 106
relative tokens in each run. The best known score is 512.
model
ave best
min best
max best
#max
$/run
mistral-tiny
387
366
448
1
0.8
deepseek-chat
368
354
394
1
3∗
gpt4o
388
376
397
1
20
llama-3.3-70b-instruct
375
354
392
1
0.88∗
codestral-mamba
390
364
448
2
0.5
claude-3.5-haiku
382
366
396
1
8
gemini-2.0-flash
348
316
379
1
0.5
Table 2. Results for 8 runs of the narrow-admissible-tuple problem with
n = 5000 using 2 × 106 relative tokens in each run; best known score is 672.
model
ave best
min best
max best
#max
$/run
mistral-tiny
558
532
575
1
0.8
deepseek-chat
558
421
561
4
3∗
gpt4o
510
410
563
1
20
llama-3.3-70b-instruct
541
499
561
4
0.88∗
codestral-mamba
510
469
560
1
0.5
claude-3.5-haiku
561
560
564
1
8
gemini-2.0-flash
503
434
582
1
0.5


--- Page 10 ---
i
i
“main” — 2025/3/18 — 1:26 — page 710 — #10
i
i
i
i
i
i
710
Generative Modeling for Mathematical Discovery
Table 3. Results for 8 runs of the no-isosceles problem with n = 64 using
2 × 106 relative tokens in each run; best known score is 110.
model
ave best
min best
max best
#max
$/run
mistral-tiny
88.5
86
90
2
0.8
deepseek-chat
88.5
86
90
2
3∗
gpt4o
89.3
86
96
1
20
llama-3.3-70b-instruct
87.5
86
88
5
0.88∗
codestral-mamba
87.8
86
92
1
0.5
claude-3.5-haiku
88.8
88
90
3
8
gemini-2.0-flash
86.6
84
90
1
0.5
Table 4. Results for single runs of gemini-2.0-flash on varying problems using
108 relative tokens in each run. Each run cost $25, and the islands reset every
15 minutes for the short reset time, and every hour for the long reset time.
The change in best score as a function of relative tokens spent is shown in
Figure 2 on a logarithmic scale.
problem
n
short reset best
long reset best
cap-set
8
370
349
narrow-admissible-tuple
5000
498
561
no-isosceles
64
90
86
4.2. Problem variants and generalization:
experiments with no-isosceles
The basic priority-solve setup we use for the no-isosceles problem is as follows:
• priority takes as input an integer n and a point on the n × n grid, and
outputs a real number.
• solve takes n as input, starts with an empty n × n grid, and adds points
in order of priority, skipping any points that would create an isosceles
triangle. Terminate when no more points can be added without creat-
ing an isosceles triangle. The evaluate function returns the size of the
resulting set.
A fundamental difference between funsearch and a more traditional ma-
chine learning protocol is that, solve being fixed and priority being learned,
we are free to run the code on values of n other than the value on which we


--- Page 11 ---
i
i
“main” — 2025/3/18 — 1:26 — page 711 — #11
i
i
i
i
i
i
Generative Modeling for Mathematical Discovery
711
Figure 2. The best score as a logarithmic function of relative token uses for
the longer runs from Table 4.
trained, and see what kind of no-isosceles subsets of n are produced. In other
words, we can ask to what extent training on a grid of one size generalizes
to grids of a different size.
For that matter, we are also not restricted to training on grids of only
one size. This is simply a matter of replacing evaluate; instead of returning
the size of solve(n) for a single n, we ask it to return the sum of the sizes of
(solve(n)/n) as n ranges over some set of values or just (solve(n)/n) when
training on random values of n in [8, 50].
For the rest of this section, we will evaluate approaches based on training
on individual values of n, a range of values of n, and on a random sampling
of values of n. For models trained on individual n, we report only the models
which performed the best in our experiments. All the models were run on
mistral-tiny, with 10 islands, 10 samplers, and 8 evaluators for 30 minutes
with the top priority functions were sampled at the end.
Whether we train on a single n or on multiple values of n, we can run
the resulting trained programs through solve for larger n and record the size
of the resulting no-isosceles sets. We record the results in Figure 3


--- Page 12 ---
i
i
“main” — 2025/3/18 — 1:26 — page 712 — #12
i
i
i
i
i
i
712
Generative Modeling for Mathematical Discovery
Figure 3. Graph of length of isosceles-free sets gener-
ated by models trained on different values of n.
Figure 4. Isosceles-free subset
of size 46 for a 32 × 32 grid and
heatmap representing the prior-
ities assigned to each point by
a model trained on n = 9. The
true largest subset has size 56.
These priority functions were trained on the basic priority-solve setup
described at the start of this section. Some remarks on these results:
• The “random priority” line represents the result when priority assigns
a random value to each point in the n × n grid. This is a proxy for how
well the greedy algorithm does without any training at all.
• All the trained priority functions outperform random priority, even
for values of n well outside the training range. This indicates that
generalization between grid sizes is occurring.
• On the other hand, training on multiple values of n does not seem to
improve generalization. One might have thought multiple-n training
would differentially favor attributes of priority functions that enhance
performance in ways that don’t depend on n; but we did not find any
such effect in this experiment.
• None of our basic priority functions are generating optimal no-isosceles
sets, even on the n for which they are trained, for n ≥12. For n up
to around 32, the size of the largest no-isosceles set can be computed
exactly by SAT solvers. The largest no-isosceles set in the 16 × 16 grid
has size 28, while the largest set found by the basic model trained on
n = 16 had size 26. (But see Table 5 below: modifying it solve can
extent the range in which funsearch achieves best possible results.) For
n outside this range, our funsearch experiments do not achieve results


--- Page 13 ---
i
i
“main” — 2025/3/18 — 1:26 — page 713 — #13
i
i
i
i
i
i
Generative Modeling for Mathematical Discovery
713
as strong as those of PatternBoost [13]. Note, though, that we are
devoting substantially less computational resources to each experiment
than were used in that paper.
Direct examination of the priority function helps illuminate the results
above.
Figure 4 shows the priority function on the 32 × 32 grid learned by train-
ing on n = 9, together with a no-isosceles set obtained by running solve with
that priority. The priority function visibly favors points near the edge of the
grid; indeed, trained priority functions almost invariably have this feature,
no matter what size or sizes of grids they train on, and produce no-isosceles
sets in which most of the points are near the boundary. In fact, every machine
learning approach we have tried on the no-isosceles problem yields point sets
which favor the boundary. With a little thought, one can make sense of this.
The condition that a triangle P, Q, R is isosceles is given by the vanishing
of a quadratic function in the coordinates of the integer vectors Q −P and
Q −R. The larger these coordinates, the smaller the heuristic probability
that this quadratic function will evaluate to 0. And so it’s reasonable that
placing the points far away from each other is helpful in reducing the number
of triangles, and arranging the points near the boundary of the grid tends to
increase those pairwise distances. This is obvious once observed, but we will
admit it did not occur to us until we saw what outputs of machine approaches
to the problem looked like. Figure 4 also includes scores for the hand-built
priority function that assigns points their distance from the center to the
center under an l2 norm. We can see in the plot that while the l2 priority
function does also perform better than the random model, the model trained
on n = 9 seems to generalize slightly better still.
It seems possible that the no-isosceles problem splits into a generalizable
part (tactics that work well for all n, or at least an infinite class of n) and a
non-generalizable part (tactics that are specific to an individual n or finite
range of n.) In the no-isosceles, training on even one n is sufficient to capture
a tactic in the generalizable part. One then might ask: is anything about the
no-isosceles problem generalizable besides the importance of staying near the
boundary? The apparent slight superiority of the n = 9 trained priority to
l2 priority suggests a positive answer.
One way to approach this question is to consider a variant of the prob-
lem, in which we search for subsets of the torus (Z/NZ) × (Z/NZ) with no
isosceles triangles. In other words, we connect the opposite edges of the grid
to form a surface with no boundary; in so doing, we eliminate the one gen-
eralizable tactic we know about. The results of training priority on small n


--- Page 14 ---
i
i
“main” — 2025/3/18 — 1:26 — page 714 — #14
i
i
i
i
i
i
714
Generative Modeling for Mathematical Discovery
Figure 5. Graph of length of isosceles-free sets on
a lattice embedded on a torus generated by models
trained on different values of n.
Figure 6. Isosceles-free subset
of size 30 for a 32 × 32 grid em-
bedded on a torus and heatmap
representing the priorities as-
signed to each point.
and testing on larger n are shown in Figure 5. We see that the advantage of
trained models over random priority is much reduced; but it is still visible.
Something is being learned by the model trained on n = 9 that generalizes to
much larger grids. But we are not sure what it is. The priority function (Fig-
ure 6) seems to be clustered around the center. The best generalizing model
here was also the trained on random values of n in [0, 50] and unlike the
previous case, training on more values of n does improve the generalizability
of the model outside its training range.
The separation between evaluate, solve, and priority gives the researcher
a great deal of flexibility in modifying the problem, or funsearch’s approach
to the problem; this is very useful in a context like this one where we have
very little intuition about what approach is likely to be effective.
For instance, instead of having solve start with the empty grid and add
points in priority order, skipping any that would create an isosceles triangle,
we could start with every point in the grid included, and remove points in
order of priority, stopping as soon as we have a subset that is isosceles free.
The results of evolving priority with this solve function are shown in Figure 7,
with a specific example of a model trained on n = 16 shown in Figure 8 for
a 32 × 32 lattice. Notice that this set is not maximal! There are many points
that can be added to this set while remaining isosceles free. These points were
prioritized to be removed earlier and therefore do not survive. We see that
although the problem of prioritizing which points to add as opposed to which


--- Page 15 ---
i
i
“main” — 2025/3/18 — 1:26 — page 715 — #15
i
i
i
i
i
i
Generative Modeling for Mathematical Discovery
715
Figure 7. Size of isosceles-free subsets when having
priority decide which points to remove rather than
add. We see that on average, randomly choosing points
to remove is a better protocol than the learned ones.
Figure 8. Isosceles-free subset
of size 8 for a 32 × 32 grid
generated by removing points
chosen by a model trained on
n = 16. High priority indicates
points to be removed here.
to remove is mathematically equivalent in formulation, we get significantly
different results.
In other experiments with no-isosceles, it has sometimes been found to
be useful to impose on the learned solution some group of symmetries (in
particular some subgroup of the group of symmetries of the problem, which
is dihedral of order 8.) Again, this is easy to implement in funsearch. As an
example, we impose a two different symmetry groups: (Z/2Z)2 and Z/2Z.
We then assign priorities like in the basic model to only a part of the grid
and solve adds one orbit of points at a time in order of priority, skipping any
that would create isosceles triangles. We tested on grids that are symmetric
under the following transformations:
• flips over the central x and y axes - (Z/2Z)2 symmetric symmetry.
• flips over the line x = y - Z/2Z symmetric.
• flips across both x = y and x = −y.
The generalization results for all of these models are shown in Figure 9
and a specific example shown in Figure 10. We compare this to the best
generalizing model from the basic functions as well as a priority function
that assigns random values. As we see, adding symmetry to the mix improved
generalization across all models and the generalization is comparable to the
best basic model trained on n = 9.


--- Page 16 ---
i
i
“main” — 2025/3/18 — 1:26 — page 716 — #16
i
i
i
i
i
i
716
Generative Modeling for Mathematical Discovery
Figure 9. Generalization graph for various models
trained on both different values of n and different sym-
metries.
Figure 10. Isosceles-free subset
of size 64 for a 48 × 48 grid with
symmetry over the lines x = ±y
While the generalization graphs show that the best models we have found
so far have similar generalizability, it is important to remember that this
represents the performance of each priority function outside its training data.
If we train on different values of n and look at the performance of priority
on the trained values, we see a difference in performance between the basic
and symmetric models, as seen in Table 5.
Table 5. Comparison of Basic Models and Symmetric Model
problem setup
n
12
13
16
21
23
25
27
32
64
maximum known
20
22
28
36
40
44
48
56
110
basic models
20
20
26
34
36
40
40
46
86∗
symmetric models
20
22
28
36
40
40
44
52
96
We see the symmetric models perform slightly better on the values they
have been trained on. *We also note that the 86 achieved by the basic model
can be improved to 96 with more compute as seen in Table 3, but setting up
the problem symmetrically saves on computational cost.
A very small change can create a whole new experiment of interest. For
instance, suppose we evaluate by the negative of the size of the set returned
by solve, instead of its size. That is, we reward priority functions which re-
sult in an output of solve (necessarily a maximal no-isosceles set) which are
as small as possible. The smallest such sets found by funsearch are shown
in Figure 11 with a particular example of a good generation shown in Fig-
ure 12. Note that the model trained on n = 16 is sensitive to parity, with


--- Page 17 ---
i
i
“main” — 2025/3/18 — 1:26 — page 717 — #17
i
i
i
i
i
i
Generative Modeling for Mathematical Discovery
717
Figure 11. Size of small maximal isosceles-free subsets
of an n × n lattice vs n. Points added in order of prior-
ity but preference given to smaller sets - being further
below random is better here.
Figure
12. Small
maximal
isosceles-free subset of size 28
for a 41 × 41 grid.
substantially better performance for even n; when studying generalization it
is probably best to make sure the test parameters don’t all lie in an arith-
metic progression. The problem of small maximal no-isosceles subsets has
not been considered before, as far as we know, and it may be that human
effort could improve these bounds without much difficulty. The analogous
problem for no-three-in-line (finding small subsets of the grid with no three
in a line, and which cannot be enlarged without violating this condition) is,
on the other hand, an old one [14].
Finally: one surprising feature of the baseline funsearch setup is that the
priority function is determined in advance. That is, when we choose which
grid point to add, we are not taking into account which points we’ve already
added, except insofar as we forbid isosceles creation. This is very strange! A
chess engine that ranked all possible moves in advance, and then from each
board state played the highest-priority move legal from that position, would
play very bad chess. Changing this feature is, again, easy. We recast priority
so that, instead of taking a grid point as input and returning a number,
it takes a subset of the grid as input and returns a point. Then solve, at
each step, adds the point chosen by priority, skipping over suggested points
that would result in isosceles triangles. Given that, in theory, priority can
repeat suggestions or suggest points outside the lattice, we have a budget for
the number of suggestions priority is allowed to make. One could think that
given the trends observed with the best subsets generated so far, the largest
subset grows on the order of O(n) and specifically around ∼1.7n. So we first
keep a budget of 3n as an upper bound but find that we get a better result


--- Page 18 ---
i
i
“main” — 2025/3/18 — 1:26 — page 718 — #18
i
i
i
i
i
i
718
Generative Modeling for Mathematical Discovery
Figure 13. Size of isosceles-free subsets of an n × n
lattice when predicting the next point instead of as-
signing priorities to each point.
Figure 14. Large isosceles-free
subset of size 39 for a 32 × 32
grid. No heatmap since the pri-
ority function is directly pre-
dicting the points!
with a budget of on the order O(n2). The generalization of these models is
shown in Figure 13 with a particular example in Figure 14. These models
have a wider range of performance, but perhaps counter-intuitively still do
worse than the basic models!
Overall, we tested four methods of generating isosceles free sets: with the
basic solve-priority setup, symmetric generation, removing points from a full
grid, and suggesting points directly instead of assigning priorities. We saw
that we get different results from mathematically equivalent formulations
of the same problem. And we saw that with small changes to the code, we
can test different problems entirely — embedding the isosceles-free subset
problem onto a torus as well as looking for small, maximal isosceles-free
sets.
5. Conclusion
In this article, we benchmarked funsearch against a variety of mathematical
problems, specifically the cap-set, narrow-admissible-tuple, and no-isosceles
problems. One key insight that emerged is that models with different costs
sometimes yielded similar results, underscoring the importance of using mul-
tiple models for comprehensive searches. It can also be observed that little is
gained from extended searches with funsearch. It appears far more beneficial
to run a large number of shorter searches. In the context of the no-isosceles
problem, we demonstrated that funsearch can be easily deployed on many


--- Page 19 ---
i
i
“main” — 2025/3/18 — 1:26 — page 719 — #19
i
i
i
i
i
i
Generative Modeling for Mathematical Discovery
719
variants of the same problem, and in fact can be deployed on different pre-
sentations of the same problem, often with very different performance.
We also provide an implementation of funsearch in the GitHub reposi-
tory [4]. Building on the original design, we add support for searches beyond
the traditional priority-function framework, enabling searches for programs
with arbitrary type signature. We also add the ability to use multiple mod-
els simultaneously, or easily switch between models using Openrouter. Fi-
nally, the repository also contains many quality-of-life improvements, such
as Weights-and-Biases integration, which makes monitoring progress much
more straightforward.
The authors believe that the work, and implementation of funsearch, pre-
sented here, demonstrate that LLM-driven genetic methods like funsearch
can be brought to bear on a wide range of mathematical problems of inter-
est at only modest cost and without any requirement that mathematicians
retrain in implementation of machine learning methods. We hope this will
be beneficial to mathematicians seeking innovative computational solutions
for mathematical discovery.
Acknowledgments
This project was started at the Harvard CMSA Mathematics and Machine
Learning Program held in fall 2024. The authors would like to thank Mistral
AI for generously providing credits for their large language models. CSFT
would like to acknowledge the hospitality of IAIFI at the Massachusetts
Institute of Technology, where a portion of this research took place.
CSFT is supported by the Gould-Watson Scholarship. TRH is supported
by the National Science Foundation under Cooperative Agreement PHY-
2019786 (The NSF AI Institute for Artificial Intelligence and Fundamen-
tal Interactions, http://iaifi.org/). AVS is supported by Simons Foundation
grant 550033. JSE is supported by NSF grant DMS-2301386, and by the
Office of the Vice Chancellor for Research and Graduate Education at the
University of Wisconsin-Madison with funding from the Wisconsin Alumni
Research Foundation. Some of the computations in this paper were run on
the FASRC Cannon cluster supported by the FAS Division of Science Re-
search Computing Group at Harvard University.
Appendix A. Example Specification
### SYSTEM PROMPT
"""<<<system prompt can be specified here>>>"""


--- Page 20 ---
i
i
“main” — 2025/3/18 — 1:26 — page 720 — #20
i
i
i
i
i
i
720
Generative Modeling for Mathematical Discovery
### END SYSTEM PROMPT
"""Finds sets.
On every iteration, improve the priority_v# function over
the priority_v# methods from previous iterations.
Make only small changes. Try to make the code short.
"""
import itertools
import numpy as np
import funsearch
import math
@funsearch.run
def evaluate(n: int) -> int:
return solve(n)
def solve(n: int) -> int:
"""Returns the count of numbers between 5
and n-1 where is_prime(m) matches (m)."""
final_count = 0
for m in range(5, n):
is_prime = True
if m <= 1:
is_prime = False
else:
for i in range(2, int(math.sqrt(m)) + 1):
if m % i == 0:
is_prime = False
break
pr = priority(m)>0.5
if is_prime == pr:
final_count = final_count + 1
return final_count
@funsearch.evolve
def priority(n: int) -> bool:
"""Returns 1 if add to set, 0 otherwise.
n is an int.
"""
return True
The system prompt can optionally be specified at the start of the speci-
fication file. If it is not specified, the default in config.py is be used. If the
default is used, the system prompt will be adjusted to describe whichever


--- Page 21 ---
i
i
“main” — 2025/3/18 — 1:26 — page 721 — #21
i
i
i
i
i
i
Generative Modeling for Mathematical Discovery
721
function @funsearch.evolve decorates. The API prompt constructed
from this specification file then looks like:
=== SYSTEM PROMPT ===
<<<specified system prompt>>>
=== END SYSTEM PROMPT ===
=== PROMPT ===
"""Finds sets.
On every iteration, improve the priority_v# function over
the priority_v# methods from previous iterations.
Make only small changes.
Try to make the code short.
"""
import itertools
import numpy as np
import funsearch
import math
@funsearch.run
def priority_v0(n: int) -> bool:
"""Returns 1 if add to set, 0 otherwise.
n is an int.
"""
return True
def priority_v1(n: int) -> bool:
"""Improved version of ‘priority_v0‘.
"""
=== END PROMPT ===
References
[1] B. Romera-Paredes, M. Barekatain, A. Novikov, M. Balog, M. P.
Kumar, E. Dupont, F. J. Ruiz, J. S. Ellenberg, P. Wang, O. Fawzi,
et al., “Mathematical discoveries from program search with large
language models,” Nature 625 no. 7995, (2024) 468–475.
[2] E. Cantú-Paz et al., “A survey of parallel genetic algorithms,”
Calculateurs paralleles, reseaux et systems repartis 10 no. 2, (1998)
141–171.


--- Page 22 ---
i
i
“main” — 2025/3/18 — 1:26 — page 722 — #22
i
i
i
i
i
i
722
Generative Modeling for Mathematical Discovery
[3] D. Goldberg, Genetic Algorithms in Search, Optimization, and
Machine Learning. Addison Wesley series in artificial intelligence.
Addison-Wesley, 1989.
https://books.google.com/books?id=3_RQAAAAMAAJ.
[4] “Funsearch.” https://github.com/kitft/funsearch.
[5] “Weights & biases.” https://wandb.ai/.
[6] J. Grochow, “New applications of the polynomial method: the cap set
conjecture and beyond,” Bulletin of the American Mathematical
Society 56 no. 1, (2019) 29–64.
[7] Y. Zhang, “Bounded gaps between primes,” Ann. of Math. (2) 179
no. 3, (2014) 1121–1174.
https://doi.org/10.4007/annals.2014.179.3.7.
[8] D. H. J. Polymath, “Variants of the Selberg sieve, and bounded
intervals containing many primes,” Res. Math. Sci. 1 (2014) Art. 12,
83. https://doi.org/10.1186/s40687-014-0012-7.
[9] J. Maynard, “Small gaps between primes,” Ann. of Math. (2) 181
no. 1, (2015) 383–413.
https://doi.org/10.4007/annals.2015.181.1.7.
[10] J. Stadlmann, “On primes in arithmetic progressions and bounded
gaps between many primes,” 2023.
https://arxiv.org/abs/2309.00425.
[11] “Narrow admissible tuples.”
https://math.mit.edu/~primegaps/.
[12] “Finding narrow admissible tuples.”
https://michaelnielsen.org/polymath/index.php?
title=Finding_narrow_admissible_tuples.
[13] F. Charton, J. S. Ellenberg, A. Z. Wagner, and G. Williamson,
“Patternboost: Constructions in mathematics with a little help from
ai,” arXiv preprint arXiv:2411.00566 (2024) .
[14] O. Aichholzer, D. Eppstein, and E.-M. Hainzl, “Geometric dominating
sets-a minimum version of the no-three-in-line problem,”
Computational Geometry 108 (2023) 101913.
