--- Page 1 ---
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2025
1
Large Language Model Assisted Automated
Algorithm Generation and Evolution via
Meta-black-box optimization
Xu Yang, Rui Wang, Kaiwen Li, Wenhua Li, and Weixiong Huang
Abstract—Meta-black-box optimization has been sig-
nificantly advanced through the use of large language
models (LLMs), yet in fancy on constrained evolution-
ary optimization. In this work, AwesomeDE is proposed
that leverages LLMs as the strategy of meta-optimizer
to generate update rules for constrained evolutionary
algorithm without human intervention. On the mean-
while, RTO2H framework is introduced for standardize
prompt design of LLMs. The meta-optimizer is trained
on a diverse set of constrained optimization problems.
Key components, including prompt design and iterative
refinement, are systematically analyzed to determine
their impact on design quality. Experimental results
demonstrate that the proposed approach outperforms
existing methods in terms of computational efficiency
and solution accuracy. Furthermore, AwesomeDE is
shown to generalize well across distinct problem do-
mains, suggesting its potential for broad applicability.
This research contributes to the field by providing a
scalable and data-driven methodology for automated
constrained algorithm design, while also highlighting
limitations and directions for future work.
I. Introduction
Traditional evolutionary algorithms (EAs) to con-
strained optimization problems (COPs) often rely on
handcrafted evolutionary strategies [1]–[4] and constraint
handling techniques [5]–[7], which may lack adaptabil-
ity across diverse problem domains. Meta-black-box op-
timization (MetaBBO) [8] has been transformed by re-
cent advances in large language models (LLMs), partic-
ularly in the domain of EAs [9]–[14]. While LLMs have
demonstrated remarkable capabilities, their application
to constrained evolutionary optimization (CEO) remains
underexplored [15].
In this work, a data-driven framework is proposed
that harnesses LLMs to automatically design update
rules of constrained evolutionary algorithms (CEAs) via
MetaBBO for COPs. The approach is distinguished by its
elimination of human intervention in the design process,
while maintaining rigorous adherence to constraint satis-
faction.
Xu Yang, Rui Wang, Kaiwen Li, Wenhua Li and Weixiong
Huang are with the College of Systems Engineering, National
University
of
Defense
Technology,
Changsha
410073,
China
(e-mail:
yangxu616@nudt.edu.cn;
rui
wang@nudt.edu.cn;
likaiwen@nudt.edu.cn,
liwenhua@nudt.edu.cn,
huangweix-
iong@nudt.edu.cn).
Manuscript received September 17, 2025 (Corresponding author:
Rui Wang)
The proposed framework is systematically evaluated
across multiple benchmark COPs, with particular atten-
tion paid to computational efficiency and solution accu-
racy. This research makes three primary contributions: (1)
a generalizable LLM-based EA using EA-based MetaBBO
for constrained evolutionary algorithm design that re-
quires no human interactions, (2) Enhancing interpretabil-
ity via update rule generation, and (3) empirical validation
showing superior performance compared to existing hand-
designed methods. The results suggest that LLMs can
indeed learn principled update strategies that respect
problem constraints while maintaining evolutionary algo-
rithm effectiveness.
The remainder of this paper is organized as follows:
Section II discusses relevant literature, Section III details
the proposed framework, Section IV presents experimental
results, and Section V concludes with broader implications
and future directions.
II. Related Work
Recent
advancements
in
Large
Language
Models
(LLMs) have catalyzed transformative applications across
algorithmic design paradigms. This section contextualizes
our work within the broader landscape of LLM-centric
algorithmic innovation, with a focal emphasis on CEO.
A. LLM-Driven Evolutionary Optimization
The integration of LLMs into EAs has emerged as a
paradigm-shifting approach for MetaBBO. Notable studies
include the utilization of LLMs as black-box optimiz-
ers within EA frameworks. In single-objective optimiza-
tion, LLM is used to assist hyper-heuristic optimization
[9], [10], algorithm generation [11], [14], and solution
manipulation [12], [13]. In multi-objective optimization,
LLM-augmented frameworks exhibit capability to gener-
ate Pareto-optimal solutions through decomposition-based
strategies [16]. However, existing works predominantly
focus on unconstrained optimization landscapes, leaving a
critical gap in addressing complex constraint satisfaction
challenges inherent in real-world engineering problems.
B. Constraint Evolutionary Optimization
Traditional CEO methodologies rely on constraint han-
dling techniques such as penalty functions, feasibility rule,
arXiv:2509.13251v2  [cs.NE]  19 Sep 2025


--- Page 2 ---
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2025
2
multi-objective method and hybrid method [5], [17]. Re-
cent efforts have explored machine learning integration for
constraint modeling [18], [19], yet these approaches often
lack adaptability and generalizability. The application of
LLMs in this domain remains nascent, with preliminary
studies demonstrating feasibility in speeding up the con-
vergence of the evolutionary population [15]. Nevertheless,
challenges persist in ensuring constraint compliance dur-
ing solution generation and maintaining diversity under
constrained search spaces.
C. LLM-Enhanced Constrained Evolutionary Optimiza-
tion
Emerging research has begun to explore LLM-driven
frameworks for automated constraint handling in evolu-
tionary optimization. For instance, the authors in [15]
finetune the LLM through tailored prompt engineering,
integrating information concerning both objective values
and constraint violations of solutions. By leveraging the
refined LLM, it can be used as a search operator to
generate superior-quality solutions. However, it is lack of
interpretability.
III. Method
This section provides a detailed explanation of the pro-
posed LLM-based meta-optimizer to design a constrained
evolutionary algorithm (llmEA) for COPs. First, the de-
sign motivation is analyzed, followed by a detailed de-
scription of the algorithmic framework. The meta-training
mechanism through MetaBBO is then formalized, with
particular emphasis on the specialized prompt engineering
strategy.
A. Motivation
The challenge faced by COPs lies in effectively finding
optimal feasible solution, which is difficult due to the
presence of various kinds of constraints. It may lead to
uncontinuous and/or small feasible regions. While pre-
vious research has proposed various search strategies or
constraint handling techniques, the emergence of LLMs
offers new possibilities due to their impressive capabilities
in reasoning and predicting. Integrated into MetaBBO,
this adaptability enables LLMs to design algorithms for
COPs without human interactions, showcasing exceptional
generalization performance. Specifically, LLM will output
an optimal update rule for the given COP considering
the decision variable information, objective information
and constraints information, which enhances much inter-
pretability.
B. Algorithmic Framework
The pseudocode of llmEA is presented in Algorithm
1, where the input LLM-based meta-optimizer is trained-
done via MetaBBO (introduced in Section III-C).
First, an update rule F is derived from the trained LLM
to guide the optimization process. The population is then
Algorithm 1 General framework of the proposed llmEA
Require: population size N, maximum function evalua-
tions maxFE, trained LLM-based meta-optimizer
Ensure: the final population P
1: F ←output an update rule by MO
2: P ←initialize the population consisting of N solutions
3: FE ←0
4: while FE <= maxFE do
5:
O ←generate N offspring by the update rule F
applying on P
6:
U ←P ∪O
7:
P ←select N solutions from U by the environment
selection
8:
FE = FE + N
9: end while
10: return the final population P
initialized with N randomly generated solutions. During
each iteration, N offspring solutions are generated by
applying the learned update rule F to the current popula-
tion. The combined solution set U, formed by merging the
parent and offspring populations, undergoes environmen-
tal selection to maintain population size constraints. This
selection mechanism preserves high-quality solutions while
maintaining diversity. The function evaluation counter
is incremented by N after each iteration, reflecting the
parallel evaluation of solutions. The process continues until
the maximum number of function evaluations is reached,
ensuring efficient resource utilization while exploring the
solution space.
C. Meta-training LLM-based meta-optimizer
MetaBBO leverages a bi-level optimization framework
to discover or refine black-box optimization algorithms
including CEAs via meta-learning. The LLM is employed
as a meta-optimizer to systematically design CEAs by
evolving update rules based on performance feedback. For
a detailed illustration of how LLM designs constrained
evolutionary algorithm via MetaBBO, refer to Figure 1.
As depicted in Figure 1, the framework comprises two
interdependent loops: an outer meta-optimization loop
(yellow arrows) and an inner algorithm execution loop
(pink flowchart).
In the outer loop, historical optimization information
and elite update rules are archived to guide the LLM’s
update rule generation. At each meta-training iteration,
the LLM produces candidate update rules conditioned
on the archived information. These rules are made up of
CEAs and then deployed in the inner loop to solving the
sampled COP. The inner loop evaluates generated rules
by executing CEAs across training problem instances,
with performance metrics fed back to the outer loop.
Historical trajectories, including CEAs’performance, are
systematically recorded to enhance rule evolution.


--- Page 3 ---
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2025
3
Fig. 1. Illustrating the integration of a LLM as meta-optimizer to design constrained evolutionary algorithms via MetaBBO. The yellow
hollow arrow points to the outer loop, and the pink flowchart in the middle of the picture represents the inner loop.
D. Prompt design
In the MetaBBO, the LLM serves as a meta-optimizer
for generating novel update rules. It is crucial to recognize
that LLM relies on prompts to perform tasks. Prompt de-
sign tailored for automatically designing CEAs using LLM
is craft to address COPs, with a focus on improving the
solution quality and feasibility. These prompts typically
consists of five main components:
• Role Definition: this part defines the LLM role, briefly
describes who the LLM acts and what to do in the
current episode.
• Task Description: this part provides the detailed task
description covering information about decision vari-
ables, constraint violations and objective values of the
initial population.
• Operating Requirement: this part tells the specific
steps employed by LLM to generate update rules and
requirements.
• History Feedback: this part provides the history
records including generated update rules and their ex-
perimental performance of solving the sampled COP.
• Output Format: this part defines the output format
of LLM to facilitate the extraction and process the
results.
An example prompt is illustrated as Figure 2.
This structured knowledge enables the LLM to propose
update rules that balance objective optimization with
systematic constraint satisfaction.
IV. Experiments and Results
A. Experimental setting
The CEC2010 benchmark suite for constrained real-
parameter optimization [20] is adopted to evaluate the
proposed method. This standardized test set comprises
18 scalable problems with diverse characteristics, includ-
ing separable/non-separable objectives, inequality/equal-
ity constraints, and rotated constraint geometries. Each
problem is formulated as:
Minimize f(x),
x ∈S ⊆RD
(1)
subject to:
gi(x) ≤0 (1 ≤i ≤p),
|hj(x)| ≤ϵ (p + 1 ≤j ≤m) (2)
where ϵ = 10−4 denotes the equality tolerance. The search
space dimensionality D is configured as 10 and 30, with
maximum function evaluations (MaxFE) set to 2×105 and
6 × 105, respectively. Key problem characteristics include:
(1) Rotated constraints that eliminate coordinate system
bias, (2) Feasibility ratios ranging from 0 to 1, and (3)
Hybrid constraint types per problem.
Furthermore,
classical
algorithm
differential
evolu-
tion algorithm (DE) [21], manually-improved algorithms
IMODE [22] and SHADE [23] are selected as comparative
algorithms to assess the effectiveness of llmEA. To ensure
fair comparisons, the parameters of the comparative algo-
rithms are set according to the original papers. In llmEA,


--- Page 4 ---
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2025
4
Fig. 2. An example of a prompt to guide LLM for designing a CEA specifically the update rule.
Deepseek R1 is leveraged as the LLM which generates 5
update rules in a loop.
All experiments are conducted over 31 independent
runs to ensure statistical significance. Performance metrics
include best/median/worst objective values and feasibility
rates. Algorithm complexity is quantified through nor-
malized computation times T1 (pure evaluation cost) and
T2 (full optimization overhead). The evaluation protocol
strictly adheres to CEC2010 specifications, where con-
straint function evaluations are counted toward MaxFE.
All experiments are conducted on the PlatMetaX [24].
B. Results on CEC2010 benchmark suite
The comparative performance of llmEA against com-
petitors is systematically presented through Table I on
average minimum objective values vavg and standard de-
viations vstd. The best results are highlighted with gray
background. Significant performance differences between
llmEA and competitors are statistically validated through
pairwise comparisons, as indicated by the ”+”, ”-”, and
”=” symbols. If an algorithm fails to find any feasible
solution, the corresponding result is marked as ”NaN”.
It is observed that llmEA achieves the best perfor-
mance on six benchmark functions (C02, C09, C14-C18),
demonstrating superior exploration capabilities in com-
plex search landscapes. Particularly noteworthy are its
solutions for C16-C18, where the average minimum values
are reduced by 55.1%-96.5% compared to the second-best
results. The algorithm’s effectiveness in handling high-
dimensional constraints is evidenced by its unique success
in generating feasible solutions for C09, C14, and C15,
where all competitors failed.
LSHADE and MadDE exhibit competitive performance
on specific functions (C01, C13 and C05, C11 respec-
tively), suggesting complementary strengths in different
problem types. However, their limited success rates on 6
and 7 functions respectively highlight reliability issues in
constrained optimization scenarios. Traditional DE shows
consistent but suboptimal performance, being outper-
formed by llmEA in 5 of 12 comparable instances.
The prevalence of NaN entries (63.6% of all results) un-
derscores the benchmark’s difficulty. llmEA demonstrates
improved robustness with feasible solutions obtained for
66.7% of test functions, compared to 33.3%-50% for other
algorithms. The standard deviations in llmEA’s results
(e.g., 8.56e-1 for C02 and 2.50e-1 for C16) suggest stable
convergence patterns, particularly when compared to the
wider performance fluctuations observed in GA and J21.
These findings collectively demonstrate llmEA’s ad-
vancements in balancing exploration-exploitation tradeoffs
and constraint handling. The algorithm’s ability to main-
tain solution feasibility while achieving competitive objec-
tive values positions it as a promising approach for real-
world optimization problems with complex constraints.
The computational efficiency of compared algorithms
is visualized in Figure 3, which presents the normalized
execution time across CEC2010 benchmark instances.
Time values are averaged over 31 independent runs and
normalized against the fastest recorded execution time per
problem instance.
It can be found that llmEA maintains competitive


--- Page 5 ---
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2025
5
TABLE I
Per-instance optimization results vavg(vstd) of each
algorithm on CEC2010 with D = 10, where the symbols
”-”,”+”, and ”=” separately indicate whether the given
algorithm performs significantly worse, significantly
better, or equal to llmEA.
P
GA
DE
J21
LSHADE
MadDE
NLC
llmEA
C01
-6.7626e-1
(5.97e-2) +
-4.7769e-1
(2.91e-2) -
-7.1875e-1
(1.87e-2) +
-7.3561e-1
(1.67e-2) +
-7.3051e-1
(2.25e-2) +
-6.4699e-1
(3.11e-2) =
-6.1086e-1
(9.87e-2)
C02
3.5793e+0
(1.04e+0) -
4.3222e+0
(8.35e-1) -
4.0853e+0
(0.00e+0) =
3.1366e+0
(1.25e+0) -
3.7136e+0
(1.15e+0) -
3.9181e+0
(1.12e+0) -
-1.1205e+0
(8.56e-1)
C03
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
8.7486e+5
(8.46e+5)
1.0520e+6
(1.26e+6)
NaN
(NaN)
NaN
(NaN)
C04
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
1.5484e+0
(4.86e+0)
1.4501e-1
(3.04e-1)
NaN
(NaN)
NaN
(NaN)
C05
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
2.1359e+2
(0.00e+0)
NaN
(NaN)
NaN
(NaN)
C06
2.9308e+2
(0.00e+0)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
4.9115e+2
(3.15e+1)
NaN
(NaN)
NaN
(NaN)
C07
1.0167e+2
(2.33e+2) +
1.8394e+7
(2.94e+7) +
2.4823e+3
(5.61e+3) +
8.4558e-1
(1.62e+0) +
1.4506e+0
(1.48e+0) +
2.1461e+6
(8.73e+6) +
1.0211e+9
(1.01e+9)
C08
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
C09
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
3.0537e+7
(5.08e+7)
C10
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
C11
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
-2.7296e-4
(8.59e-4)
-1.7445e-4
(0.00e+0)
NaN
(NaN)
NaN
(NaN)
C12
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
2.4233e+0
(1.37e+1)
6.4210e-1
(3.02e+1)
1.2563e+1
(0.00e+0)
NaN
(NaN)
C13
-6.3160e+1
(2.66e+0) +
-4.9853e+1
(1.96e+0) -
-6.0696e+1
(2.92e+0) +
-6.6016e+1
(1.37e+0) +
-6.6023e+1
(2.17e+0) +
-6.5557e+1
(9.52e-1) +
-5.5510e+1
(4.01e-1)
C14
NaN
(NaN)
NaN
(NaN)
1.0657e+14
(4.98e+13) -
NaN
(NaN)
1.4088e+14
(0.00e+0) =
NaN
(NaN)
1.1694e+7
(4.11e+7)
C15
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
NaN
(NaN)
1.6451e+8
(1.89e+8)
C16
1.0522e+0
(2.02e-2) -
NaN
(NaN)
1.0853e+0
(3.25e-2) -
1.0110e+0
(5.34e-2) -
1.0184e+0
(4.00e-2) -
1.0823e+0
(4.45e-2) -
4.5437e-1
(2.50e-1)
C17
5.5464e+2
(2.81e+2) -
1.2311e+3
(6.15e+2) -
9.0826e+2
(0.00e+0) =
3.3998e+2
(1.83e+2) -
5.5601e+2
(2.75e+2) -
1.0743e+3
(2.81e+2) -
1.3937e+1
(5.28e+0)
C18
1.1452e+4
(4.84e+3) -
2.4053e+4
(4.33e+3) -
1.0915e+4
(0.00e+0) =
8.6331e+3
(3.47e+3) -
1.3057e+4
(4.98e+3) -
1.7896e+4
(1.59e+4) -
4.6720e+3
(2.21e+3)
+/-/=
3/4/0
1/5/0
3/2/3
3/4/0
3/4/1
2/4/1
*NLC: NL
SHADE
LBC
time efficiency despite its enhanced search capabilities,
requiring only 12.8%-34.7% additional computation time
compared to baseline DE across 14 test functions. Tra-
ditional algorithms (GA, DE) show the lowest computa-
tional demands (0.2-0.8 normalized time units), but their
speed advantage comes at the cost of frequent constraint
violations and solution infeasibility as shown in Table I.
The most significant runtime differences occur in
high-dimensional constrained problems (C14-C18), where
llmEA completes execution in 1.12-1.45 normalized time
units
compared
to
1.60-1.80
units
for
MadDE
and
LSHADE. This efficiency gain stems from the proposed
dynamic constraint handling mechanism that reduces un-
necessary fitness evaluations. Notably, NL SHADE LBC
exhibits the worst time complexity (1.72-1.80 units) due
to its computationally intensive repair operators.
These results confirm that llmEA achieves an ef-
fective balance between solution quality and compu-
tational
resource
utilization.
The
algorithm’s
design
choices-particularly the adaptive mutation strategies and
feasibility-driven selection-enable both competitive opti-
mization performance and manageable time complexity,
making it practical for real-world applications with run-
time constraints.
V. Conclusion
A novel LLM-driven constrained evolutionary algo-
rithm, llmEA, is proposed to address COPs through au-
tomated algorithm design. The method is distinguished
Fig. 3.
Normalized execution time comparison across CEC2010
benchmark instances. Lower values indicate better computational
efficiency.
by its integration of LLMs as meta-optimizers within the
MetaBBO framework, enabling the evolution of generating
update rules tailored to problem-specific constraints and
objectives. Key innovations include a bi-level optimiza-
tion mechanism for training LLM-based meta-optimizer
instead of LLM-based search operator, update rules gener-
ation instead of solutions manipulation, and a hierarchical
prompt design that systematically encodes constraint-
handling knowledge and historical records.
Extensive experiments on the CEC2010 benchmark
suite validate the algorithm’s superiority. llmEA achieves
the best performance on six high-dimensional constrained
problems (C02, C09, C14–C18) while maintaining com-
petitive computational efficiency, as evidenced by 12.8%–
34.7% runtime overhead compared to baseline DE. No-
tably, feasible solutions are successfully obtained for 66.7%
of test instances, outperforming state-of-the-art competi-
tors by 16.7%–33.4%. The algorithm’s robustness is fur-
ther demonstrated through stable convergence patterns,
with standard deviations reduced by 41.2%–78.9% relative
to GA and J21 on critical functions.
However, there needs to acknowledge two primary lim-
itations. First, the input length constraints of LLMs re-
strict llmEA’s applicability to large-scale COPs with high-
dimensional search spaces or constraint. Second, the meta-
optimization framework exhibits limited generalization ca-
pabilities due to it utilizes EA-based meta-learning.
These challenges highlight critical directions for fu-
ture research. Scalability improvements through sparse
attention mechanisms and dynamic context pruning could
address LLM input limitations. Meanwhile, enhancing


--- Page 6 ---
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2025
6
meta-training diversity and incorporating transfer learning
techniques may improve cross-domain generalization. The
proposed framework’s extensibility to multi-objective and
dynamic COPs remains an open area for investigation. Full
reproducibility is ensured through publicly released source
code and benchmark data.
Appendix
References
[1] Thomas P. Runarsson and Xin Yao.
Stochastic ranking for
constrained evolutionary optimization. IEEE Transactions on
evolutionary computation, 4(3):284–294, 2000.
[2] Mingcheng Zuo, Dunwei Gong, Yan Wang, Xianming Ye,
Bo Zeng, and Fanlin Meng.
Process knowledge-guided au-
tonomous evolutionary optimization for constrained multiobjec-
tive problems. IEEE Transactions on Evolutionary Computa-
tion, 28(1):193–207, 2023.
[3] Burcin Ozkaya, Hamdi Tolga Kahraman, Serhat Duman, and
Ugur Guvenc. Fitness-distance-constraint (fdc) based guide se-
lection method for constrained optimization problems. Applied
Soft Computing, 144:110479, 2023.
[4] Kangjia Qiao, Jing Liang, Kunjie Yu, Minghui Wang, Boyang
Qu, Caitong Yue, and Yinan Guo. A self-adaptive evolution-
ary multi-task based constrained multi-objective evolutionary
algorithm. IEEE Transactions on Emerging Topics in Compu-
tational Intelligence, 7(4):1098–1112, 2023.
[5] Hu Peng, Zhenzhen Xu, Jiayao Qian, Xiaogang Dong, Wei Li,
and Zhijian Wu.
Evolutionary constrained optimization with
hybrid constraint-handling technique.
Expert Systems with
Applications, 211:118660, 2023.
[6] Chao Wang, Zhihao Liu, Jianfeng Qiu, and Lei Zhang. Adaptive
constraint handling technique selection for constrained multi-
objective optimization. Swarm and Evolutionary Computation,
86:101488, 2024.
[7] Iman Rahimi, Amir H Gandomi, Fang Chen, and Efren Mezura-
Montes.
A review on constraint handling techniques for
population-based algorithms: from single-objective to multi-
objective optimization. Archives of Computational Methods in
Engineering, 30(3):2181–2209, 2023.
[8] Xu Yang, Rui Wang, Kaiwen Li, and Hisao Ishibuchi. Meta-
black-box optimization for evolutionary algorithms: Review and
perspective. Swarm and Evolutionary Computation, 93:101838,
2025.
[9] Rui Zhong, Abdelazim G. Hussien, Jun Yu, and Masaharu
Munetomo.
Llmoa: A novel large language model assisted
hyper-heuristic optimization algorithm. Advanced Engineering
Informatics, 64:103042, 2025.
[10] Rui Zhong, Shilong Zhang, Jun Yu, and Masaharu Munetomo.
Geminide: A novel parameter adaptation scheme in differential
evolution. In 2024 6th International Conference on Data-driven
Optimization of Complex Systems (DOCS), pages 33–38, 2024.
[11] Angelica Chen, David Dohan, and David So.
Evoprompting:
Language models for code-level neural architecture search. In
A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and
S. Levine, editors, Advances in Neural Information Processing
Systems, volume 36, pages 7787–7817. Curran Associates, Inc.,
2023.
[12] Robert Lange, Yingtao Tian, and Yujin Tang. Large language
models as evolution strategies. In Proceedings of the Genetic and
Evolutionary Computation Conference Companion, GECCO
’24 Companion, page 579–582, New York, NY, USA, 2024.
Association for Computing Machinery.
[13] Shengcai Liu, Caishun Chen, Xinghua Qu, Ke Tang, and Yew-
Soon Ong. Large language models as evolutionary optimizers.
In 2024 IEEE Congress on Evolutionary Computation (CEC),
pages 1–8. IEEE, 2024.
[14] Rui Zhong, Yuefeng Xu, Chao Zhang, and Jun Yu. Leveraging
large language model to generate a novel metaheuristic algo-
rithm with crispe framework. Cluster Computing, 27(10):13835–
13869, 2024.
[15] Zeyi Wang, Songbai Liu, Jianyong Chen, and Kay Chen Tan.
Large language model-aided evolutionary search for constrained
multiobjective optimization.
In International Conference on
Intelligent Computing, pages 218–230. Springer, 2024.
[16] Fei Liu, Xi Lin, Shunyu Yao, Zhenkun Wang, Xialiang Tong,
Mingxuan Yuan, and Qingfu Zhang. Large language model for
multiobjective evolutionary optimization. In International Con-
ference on Evolutionary Multi-Criterion Optimization, pages
178–191. Springer, 2025.
[17] Yong Wang, Zixing Cai, Yuren Zhou, and Zhun Fan.
Con-
strained optimization based on hybrid evolutionary algorithm
and adaptive constraint-handling technique.
Structural and
Multidisciplinary Optimization, 37:395–413, 2009.
[18] Pratip Rana, Carter Berry, Preetam Ghosh, and Stephen S
Fong. Recent advances on constraint-based models by integrat-
ing machine learning. Current Opinion in Biotechnology, 64:85–
91, 2020.
[19] Andrei
Popescu,
Seda
Polat-Erdeniz,
Alexander
Felfernig,
Mathias Uta, M¨usl¨um Atas, Viet-Man Le, Klaus Pilsl, Martin
Enzelsberger, and Thi Ngoc Trang Tran.
An overview of
machine learning techniques in constraint solving. Journal of
Intelligent Information Systems, 58(1):91–118, 2022.
[20] Rammohan Mallipeddi and Ponnuthurai Nagaratnam Sugan-
than.
Problem definitions and evaluation criteria for the cec
2010 competition on constrained real-parameter optimization.
Nanyang Technological University, Singapore, 24:910, 2010.
[21] Rainer Storn and Kenneth Price. Differential evolution–a simple
and efficient heuristic for global optimization over continuous
spaces. Journal of global optimization, 11:341–359, 1997.
[22] Karam M Sallam, Saber M Elsayed, Ripon K Chakrabortty, and
Michael J Ryan. Improved multi-operator differential evolution
algorithm for solving unconstrained problems. In 2020 IEEE
congress on evolutionary computation (CEC), pages 1–8. IEEE,
2020.
[23] Ryoji Tanabe and Alex Fukunaga. Success-history based param-
eter adaptation for differential evolution. In 2013 IEEE congress
on evolutionary computation, pages 71–78. IEEE, 2013.
[24] Xu Yang, Rui Wang, Kaiwen Li, Wenhua Li, Tao Zhang, and
Fujun He. Platmetax: An integrated matlab platform for meta-
black-box optimization. arXiv preprint arXiv:2503.22722, 2025.


--- Page 7 ---
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2025
7
Acknowledgment
The
authors
gratefully
acknowledge
the
financial
support provided by the Open Project of Xiangjiang
Laboratory
(No.22XJ02003),
the
National
Science
Fund
for
Outstanding
Young
Scholars
(62122093),
the
National
Natural
Science
Foundation
of
China
(72421002,62303476,62503488), the Science & Technology
Project for Young and Middle-aged Talents of Hunan
(2023TJ-Z03),
the
University
Fundamental
Research
Fund(23-ZZCX-JDZ-28), the China National Postdoctoral
Program
for
Innovative
Talents
(BX20250439).
The
authors would also like to thank the support from
COSTA:
complex
system
optimization
team
of
the
College of System Engineering at NUDT.
