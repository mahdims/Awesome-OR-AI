--- Page 1 ---
From Large Language Models and Optimization to Decision Optimization
CoPilot: A Research Manifesto
Segev Wasserkrug 1 Leonard Boussioux 2 3 4 Dick den Hertog 5 Farzaneh Mirzazadeh 6 Ilker Birbil 5
Jannis Kurtz 5 Donato Maragno 5
Abstract
Significantly simplifying the creation of optimiza-
tion models for real-world business problems has
long been a major goal in applying mathematical
optimization more widely to important business
and societal decisions.
The recent capabilities of Large Language Models
(LLMs) present a timely opportunity to achieve
this goal. Therefore, we propose research at the
intersection of LLMs and optimization to create a
Decision Optimization CoPilot (DOCP) - an AI
tool designed to assist any decision maker, inter-
acting in natural language to grasp the business
problem, subsequently formulating and solving
the corresponding optimization model.
This paper outlines our DOCP vision and identi-
fies several fundamental requirements for its im-
plementation. We describe the state of the art
through both a literature survey and experiments
using ChatGPT. We show that a) LLMs already
provide substantial novel capabilities relevant to a
DOCP, and b) major research challenges remain to
be addressed. We also propose possible research
directions to overcome these gaps.
We also see this work as a call to action to bring
together the LLM and optimization communities
to pursue our vision, thereby enabling much more
widespread improved decision-making.
1. Introduction
Many important real-world decision-making problems can
be modeled and solved using mathematical optimization -
1IBM Research - Israel 2Michael G. Foster School of Business,
University of Washington, Seattle, WA, USA 3Allen School of
Computer Science and Engineering, University of Washington,
Seattle, WA, USA 4Laboratory for Innovation Science at Harvard,
Cambridge, MA, USA 5Amsterdam Business School, University of
Amsterdam, 1018TV Amsterdam, Netherlands 6MIT-IBM Watson
AI Lab, IBM Research, Cambridge, MA.
Copyright 2023 by the author(s).
a formal technique in which the problem is modeled by a
set of decision variables subject to constraints, with the goal
of optimizing some objective function. Mathematical opti-
mization has provided huge financial and societal benefits
in many cases, including more efficient food delivery by the
United Nations (Peters et al., 2022), millions of dollars in
savings for e-commerce sites (Deng et al., 2023), and better
radiotherapy treatment for cancer patients (Zarepisheh et al.,
2022). However, most decision-makers currently lack the
necessary mathematical skills and/or access to the experts
required to apply mathematical optimization. Consequently,
it has been a long-standing goal to make optimization acces-
sible to a broad range of decision-makers.
Large Language Models (LLMs) such as ChatGPT (Ope-
nAI, 2023a) have democratized access to AI, making ad-
vanced AI skills accessible to almost anyone through natural
language and significantly simplifying many tasks such as
document and code generation. This technology has also re-
sulted in the creation of a variety of intelligent copilots that
help users be much more effective and productive in their
professional and personal lives (for example, the GitHub
Copilot (GitHub Inc., 2021) helps developers significantly
accelerate software development through natural language
interaction).
Given the AI advancements enabled by LLMs, we believe
the time is right to realize the vision of widely accessible
optimization by bringing together LLMs with mathemat-
ical optimization. We propose the creation of a Decision
Optimization CoPilot (DOCP): an AI at the disposal of ev-
ery decision-maker that interacts with the user in natural
language and utilizes the human’s knowledge and feedback
to create and solve a problem-specific optimization model,
thereby leading to better decision making.
This article is organized as follows: after establishing the
background in Section 2, we detail our DOCP vision and
some required core capabilities in Section 3. In Section 4,
we summarize the state of the art and relevant gaps based
on a literature survey and experiments with ChatGPT. We
suggest research directions to address existing gaps to create
a DOCP in Section 5. Section 6 ends with a summary and a
call to action to realize our DOCP vision.
1
arXiv:2402.16269v1  [cs.AI]  26 Feb 2024


--- Page 2 ---
Decision Optimization CoPilot
2. Background
2.1. Large Language Models
A language model is mainly a model for conditional prob-
ability distributions over word sequences. LLMs are deep
neural network auto-regressive language models with bil-
lions or trillions of parameters, typically based on a specific
architecture, transformers, utilizing the attention mecha-
nism (see (Bahdanau et al., 2015; Vaswani et al., 2017)).
In contrast to previous language models, which had to be
handcrafted for specific tasks such as entity recognition or
translation, LLMs are initially pre-trained on huge datasets,
resulting in a general understanding of language captured in
their large number of weights. They can then be adapted to a
wide variety of tasks, including document generation, code
generation, entity recognition, translation, and question-
answering. There are now many LLMs, both open source
(e.g. Flan-T5 (Chung et al., 2022), Llama 2 (Touvron et al.,
2023), Mixtral (Jiang et al., 2024)) and proprietary (GPT-3.5
with 175 billion parameters (Brown et al., 2020), and GPT-4
(OpenAI et al., 2023) with 1.76 trillion parameters underly-
ing ChatGPT (OpenAI, 2023a); and Gemini Pro with 137
billion parameters underlying Bard (Google, 2024)).
Adapting an LLM to a specific downstream task can be done
in a variety of ways, including: fine-tuning (Dai & Le, 2015;
Dodge et al., 2020; Wei et al., 2022a) - updating (some) of
the network weights with additional, more domain-specific
information, Reinforcement Learning with Human Feedback
(RLHF) (Ziegler et al., 2019; Stiennon et al., 2020; Ouyang
et al., 2022), in which a reward model is trained by human
feedback on the output of the LLM, and is then used to
update the models weights, and prompting (Brown et al.,
2020; Sanh et al., 2021; Khot et al., 2022) - giving the LLM
natural language instructions as part of the request.
Some LLM applications include a workflow of steps exter-
nal to the LLM, in some of which an LLM is used. Common
workflow patterns of such LLM applications include Tree-
of-thoughts (Yao et al., 2023; Long, 2023) and Graph of
thought (Besta et al., 2023), both of which explore the so-
lution space through a tree or graph like process, using
backtracking and cycles when needed, thereby enabling
a complex reasoning process mimicking human problem-
solving patterns.
2.2. Mathematical Optimization
Mathematical optimization requires formally modeling a
decision-making problems as:
minimize
f(x)
subject to
g(x) ≤0,
h(x) = 0,
(1)
where x ∈ℜn is the decision variables vector (representing
the possible decisions), f(·) is the objective function or goal
to optimize, and the vector-valued functions g(·) and h(·)
are used to define constraints on the acceptable solutions of
the problem.
Once modeled as an optimization problem, there are many
possible algorithms for finding a solution to the decision
problem. The algorithms that can be used depend on the ex-
act type of optimization model created. Efficient algorithms
exist for Linear optimization (LO), which is appropriate
when all functions in (1) are linear. Nonlinear optimization
extends this concept to situations where the objective or
the constraint functions can be nonlinear functions. Mixed
integer linear optimization (MILO) deals with problems of
the form (1) where the objective and constraint functions
are linear, but some or all decision variables are constrained
to be integer. MILO is crucial in practical applications and
is widely used in logistics, manufacturing, and supply chain
management. However, unlike LO, most real-world MILO
problems are NP-hard, making it computationally difficult
to find exact solutions for large-scale real-world instances.
Therefore, as there could be different optimization formula-
tions for the same decision problem, an important modeling
skill is finding the most efficient model. In addition, several
advanced techniques have been developed to handle MILO
problems efficiently. These strategies include, among oth-
ers, decomposition or branch-and-bound methods, which
break down complex problems into simpler subproblems,
and cut generation techniques, which iteratively add con-
straints to simplify the solution search procedure (Wolsey
& Nemhauser, 1988). As implementing these techniques is
often problem-dependent, this also requires significant skill.
Finally, due to the complexity of solving real-world prob-
lems using MILO, the use of optimization engines such
as Gurobi (Gurobi Optimization, LLC, 2024) and CPLEX
(IBM, 2024) has become common among practitioners.
These engines receive a mixed integer linear optimization
problem and solve the problem by employing the latest al-
gorithms. In addition, they have many parameters that can
provide additional efficiencies when fine-tuned for specific
models.
2.3. Optimization Modeling
Creating an optimization solution for a real-world business
problem is a complex process requiring multiple steps. This
is because applying optimization requires a skilled optimiza-
tion practitioner to work with the decision-maker using the
process depicted in Figure 1.
As depicted in this process, the optimization practitioner
needs to understand the problem and available data in suf-
ficient detail and with enough precision to create a formal
optimization model (in the form of Equation (1)). The prac-
2


--- Page 3 ---
Decision Optimization CoPilot
Understand
decision-
making problem
Create mental
model of decision-
making problem
Translate into
optimization model
Tune for efficiency
Validate the
optimization model
Figure 1. Optimization Modeling Process
titioner then creates the model, attempting to find the most
efficient formulation. The next step is often to apply ad-
vanced techniques such as problem decomposition, adding
cuts and column generation, and correctly setting the pa-
rameter of the optimization engine so that the problem can
be efficiently solved. Finally, the resulting optimization
problem and solutions must be validated against the actual
decision-making problem, with discrepancies resulting in
additional iterations of this process. Moreover, all of these
steps have to be carried out through constant interaction
between the optimization modeler and the decision-maker,
with the optimization modeler thinking in terms of math-
ematical formulations and the decision-maker communi-
cating in terms of the problem domain. As a result, often
multiple iterations of this process have to be carried out,
3. Decision Optimization CoPilot
We envision a Decision Optimization CoPilot (DOCP): A
friendly AI, incorporating an LLM, accessible to any busi-
ness decision-maker who needs to make a decision that can
benefit from optimization modeling. The DOCP will guide
the decision-maker through deciding by interacting with
the user in natural language and carrying out, behind the
scenes, the process depicted in Figure 1, ultimately resulting
in an optimization model that provides good solutions to the
specific business work.
As a concrete example of such a decision problem, consider
Example 3.1 (based on a real-world use case [Anonymous
2023]).
Example 3.1. A company wants to have a methodology to
identify optimal locations for their bike rental hubs. A hub is
a parking facility where users (commuters and tourists) can
park their cars, and bicycles are available for rental. The
methodology should optimize the maximum coverage of the
users’ needs in the cities targeted to maximize the number
of users and minimize the number of kilometers driven in
the city.
The user would begin by providing the DOCP with the
natural language description of the decision problem as in
the example. The DOCP, through conversational interac-
tion with the decision-maker, should first understand the
precise objectives and constraints of the problem and the
available data. Subsequently, the DOCP should validate that
optimization is the right approach and which type of opti-
mization model is required (e.g., LO model, MILO model,
etc.) based on the problem characteristics (if optimization
is not the right approach, the DOCP should notify the user
and stop). The DOCP would then create the optimization
model (possible models for the problem in Example 3.1
appear in Appendix C) and run an appropriate algorithm
(typically through an optimization engine) to solve it and
provide actionable recommendations to the user.
The DOCP would also need to be able to receive appropriate
feedback from the user at any stage and course-correct or
update the models and pipelines based on this feedback. Fi-
nally, the DOCP would need to communicate in a language
understandable to the business decision-maker.
3.1. Core Capabilities Required by a DOCP
Requirement #1 - Translating a Business Level problem
definition to an Optimization Model: A significant part
of the optimization modeling process (Figure 1) is the cre-
ation of a mental model of the decision-making problem
at a sufficient level of detail and precision so that a formal
optimization model can be created. Therefore, a DOCP
would need to be able to guide the decision-maker through
the modeling process that starts from (often a high-level)
business problem definition and ends with the level of detail
required for optimization model creation. Moreover, the
DOCP would need to understand what data is available and
decide what type of optimization model is required: Can it
be modeled using an LO model, or does it require discrete
decision variables, which would both require a MILO model
(which would be much harder to solve)? Should uncertainty
be considered, in which cases techniques such as Robust or
Stochastic optimization (Vladimirou & Zenios, 1997) would
be required?
Requirement #2 - Enabling the Decision Maker to Verify
Optimization Model Correctness: As LLMs can produce
erroneous output, the optimization model generated by the
DOCP could contain errors. While some generated model
errors could manifest as runtime errors, there are often many
much more subtle errors that would therefore be harder to
detect. Such errors could include the generated objective
not corresponding to the real-world decision objective or
a missing or erroneous constraint. Using such erroneous
formulations could result in the model being infeasible or
3


--- Page 4 ---
Decision Optimization CoPilot
generate solutions that, while optimal for the generated
optimization problem, are not good solutions for the actual
decision-making problem. When optimization experts are
using LLMs, the onus of validating the generated models
can be placed on these experts. However, decision-makers
who do not have optimization expertise cannot be expected
to validate the model. Therefore, a DOCP must both a) take
whatever steps are possible to reduce the number of errors in
the model and b) provide sufficient tools appropriate for the
business decision-maker not only to validate the model but
also provide feedback in a way that will enable correction
of the optimization model.
Requirement #3 - Creating Efficient Optimization Mod-
els: Creating an optimization model that captures the real
problem’s constraints and objectives is insufficient. As de-
scribed in Section 2.2 many times the resulting optimization
problems are NP-hard. In such cases, many correct optimiza-
tion models can still not provide useful solutions within a
reasonable time frame. Therefore, advanced modeling tech-
niques such as finding equivalent, more efficient models,
problem decomposition, column generation, and approxi-
mations must often be introduced. Moreover, when using
off-the-shelf engines such as CPLEX (see section 2.2) to
solve such models, optimization engine parameters such
as cuts, branching variable selection, and primal/dual algo-
rithms must be selected. As the most effective advanced
modeling techniques or engine parameter values are often
problem-specific, a DOCP must be able to apply these suit-
ably to the specific problem.
4. State-of-the-Art with regards to DOCP
Requirements
To understand the state-of-the-art capabilities relevant to a
DOCP, we carried out a survey of related work and experi-
mented with ChatGPT (OpenAI, 2023a), a state-of-the-art
LLM, as described below.
4.1. Related work
An increasing amount of work has leveraged LLMs to con-
vert natural language descriptions into mathematical models
and formalizations (Zhang et al., 2019; Meadows & Fre-
itas, 2022; Wu et al., 2022). Of these, many works have
used LLMs to generate optimization models with the goal
of making optimization more widely accessible. The work
of Amarasinghe et al. (2023) states as a goal the ability to
“leverage LLMs to support non-expert users to carry out
business optimizations without having to consult experts”.
Focusing on production scheduling, this work constructed
an open-source dataset consisting of relatively precise natu-
ral language problem descriptions and corresponding model
formulations and used it to fine-tune a code-generating LLM
to generate optimization models. This approach achieved
good performance as measured by running the generated
models, ensuring that they run correctly, and then comparing
both execution time and obtained solution to the “ground
truth” models. However, it does not address model valida-
tion by non-experts, nor explicitly how to generate efficient
models.
OptiMUS (AhmadiTeshnizi et al., 2023) uses an LLM to
generate and code a mathematical model. It then uses an op-
timization engine to solve the model and run some feasibility
tests to evaluate the correctness of the generated solutions.
These unit tests can be automatically generated or suggested
by optimization modeling experts. Despite showcasing the
capability of integrating LLMs and optimization engines
for automated optimization problem-solving, OptiMUS is
contingent on a structured input representation (SNOP) and
expert-created unit testing, presenting difficulties for users
lacking proficiency in mathematical optimization.
Li et al. (2023b) propose a framework for automatic formula-
tion from unstructured text descriptions of MILO problems.
It utilizes a constraint classification scheme and constraint
templates to guide the LLMs in creating MILO models from
natural language descriptions. The authors assess the quality
of the LLM by the quality of the generated models. In this
work, the evaluation is entirely conducted by OR experts
who must understand the correctness of the model.
There are additional works that have used LLMs to gen-
erate optimization models (Jang, 2022; Almonacid, 2023;
Tsouros et al., 2023; Chen et al., 2023). In 2022, the NL4Opt
NeurIPS competition (Ramamonjison et al., 2023) garnered
significant attention in the realm of extracting linear opti-
mization (LO) models from natural language. The com-
petition was inspired by the pilot study of Ramamonjison
et al. (2022) where the authors introduced an automated
formulation method named OptGen, designed to handle LO
problem descriptions with diverse constraints. OptGen em-
ploys a two-step mapping strategy where, in the first step,
all problem entities of the optimization problem (e.g., ob-
jective function, decision variables, etc.) are detected. In
the second step, the problem description, together with the
labeled semantic problem entities, is used to generate the
final mathematical representation of the problem. For the
entity detection problem, Ning et al. (2023) achieved the
highest score, while Gangwar & Kani (2023) achieved the
highest accuracy in generating optimization models. This
work utilized BART (Lewis et al., 2020), a large encoder-
decoder model and enhanced the input by encapsulating
entities with XML-like tagging. In all of these works, the
quality of the solution was judged by how close the model
was to the “ground truth” model.
Inspired by the NL4OPT challenge, Tsouros et al. (2023)
propose a modular framework for problem modeling via
LLMs. The authors break down the modeling task into four
4


--- Page 5 ---
Decision Optimization CoPilot
subtasks, each implemented using prompting (Khot et al.,
2022). Beginning with a natural language description as
input, the system sequentially extracts problem entities, es-
tablishes relationships, formalizes the optimization problem,
and translates it into a constraint modeling language like
CPMpy. Following the modeling phase, the code is com-
piled, executed, and automatically debugged if necessary.
The system then engages in an interactive refinement pro-
cess with the user, offering a comprehensive and efficient
approach to problem modeling. In their survey paper, Fan
et al. (2024) assessed LLMs’ performance on textbook prob-
lems and real-world scenarios using the NL4OPT dataset
and evaluation metrics. LLMs demonstrated impressive pro-
ficiency in modeling textbook-level problems; however, in
the context of real-world problems, the generated models
exhibited errors such as incorrect constraints, extra con-
straints, and missing constraints. Nonetheless, pointing out
errors and prompting corrections proved effective, making
LLM-generated formulations more accurate.
To summarize, a lot of work has focused on generating
models from natural language descriptions. While good
progress has been made, there are still many errors in the
generated models. In addition, all works require quite a
precise natural language description of the problem and not
a high-level description, such as in Example 3.1, and only a
few have gone beyond model generation to actually solve
the generated models and analyze the results. Moreover,
only AhmadiTeshnizi et al. (2023) addresses the need to
generate efficient models, and this also in a limited, implicit
fashion (by having execution time as one of the measure-
ment metrics). Finally, none of the above works address
the need of a business user to verify the correctness of the
model or the need to update the model as a result of business
user feedback.
Unrelated to optimization, some works have attempted to
use LLMs directly for complex reasoning tasks such as
mathematical problem solving (Cobbe et al., 2021; Wei
et al., 2022b; Lightman et al., 2023; Trinh et al., 2024). Fol-
lowing this approach, Yang et al. (2023) employed LLMs
to generate solutions for optimization problems, attempting
to bypass the need for problem modeling and optimization
engines. They applied this method to various Traveling
Salesmen Problem (TSP) instances. In these instances, the
LLM received node locations as input and produced a se-
quence as output. If the generated solution was not optimal,
the authors provided the optimality gap as input and asked
the model to refine its output iteratively. The approach
adopted by the authors relies on the availability of an “ora-
cle” that can generate the optimality gap and feasibility for
a given solution.
However, previous works trying to use LLMs directly for
reasoning (including (Bubeck et al., 2023)) have shown that
while the reasoning capabilities of LLMs are impressive,
they still seem severely lacking. For example, in the afore-
mentioned study of optimizing TSP problems, the perfor-
mance of the LLM significantly deteriorates when dealing
with large-sized problems. As the problem size increases
beyond 10 nodes, the optimality gaps escalate rapidly, and
optimization heuristics begin to surpass all LLMs. Further-
more, when a problem involves multiple constraints and
nonlinear functions, the LLM is susceptible to generating
solutions that are either infeasible or significantly distant
from the optimum. In general, the work of Gao et al. (2023)
showed for that for multiple reasoning tasks, an LLM that
first generates Python code and then runs that code to carry
out the actual reasoning does much better than an LLM that
directly tries to reason. This reinforces our proposed DOCP
workflow: first generating an optimization model and then
solving it externally to the LLM to find good solutions.
There are also other works at the intersection of LLMs and
optimization whose learning may be incorporated into a
validation capability for the business user. Li et al. (2023a)
uses an LLM to provide a natural language interface to an
existing optimization model. This interface can be used
to query the model and its results and also provides some
customization capabilities. Chen et al. (2023) develop a
chatbot to assist an optimization expert in identifying and
resolving infeasible optimization problems by taking Pyomo
code as input.
4.2. Experimentation Using ChatGPT
We conducted experiments specifically targeting the three
requirements described in Section 3.1. We did this using
prompting with ChatGPT 4 (OpenAI, 2023a) as described
below.
4.2.1. REQUIREMENT #1: FROM BUSINESS LEVEL
PROBLEM DEFINITION TO OPTIMIZATION MODEL
In this first set of experiments we played the role of a busi-
ness decision maker, trying to work with ChatGPT to gen-
erate an accurate optimization model for the problem in
Example 3.1 through a natural language conversation. We
provided ChatGPT with the appropriate context by creat-
ing personalized GPTs (see (OpenAI, 2023b)) - versions
of ChatGPT customized with natural language instructions.
We tried this with two GPTs with slightly different instruc-
tions, which explained to ChatGPT that its role is to have a
conversation with the business user to understand the busi-
ness problem, understand what type of optimization model
is required, and subsequently create both a mathematical
formulation of the problem and executable code suitable
for running and solving this model using an optimization
engine (the prompt for one of the GPT’s appear in Figure 2
and the full conversations in Appendix B.1).
5


--- Page 6 ---
Decision Optimization CoPilot
Figure 2. The Context Provided to the custom GPT
Figure 3. Optimization Models Generated by ChatGPT (Require-
ment #1)
Both conversations began with a brief description of the
problem as appearing in Example 3.1. In both cases, Chat-
GPT began correctly by asking for additional clarification
and generated, in the end, a mathematical formulation of
an optimization model. Moreover, in both cases, the opti-
mization model selected by ChatGPT was a mixed integer
linear optimization model, which is indeed appropriate for
this problem. (The full conversations appear in Appendix
B.1).
However, in both cases, the optimization problem formula-
tion generated by ChatGPT (see Figure 3) was both incom-
plete and unsuitable for the business problem. The model
was unsuitable as it incorrectly assigned a demand to a com-
bination of a point of interest and a potential hub location
(parameter Dp,h). However, the demand assigned to a hub
should be more granular, from a junction to a point of inter-
est. Moreover, it made this decision even though the user
mentioned explicitly that the available data is the demand
from a junction to a point of interest. The model was also
incomplete as it did not specify the constraints indicating
whether a hub could cover a specific demand or not. While
it asked for clarification to help it augment the constraints,
it simultaneously asked the user to give feedback on the
mathematical formulation. This is even though it was told
in the context (Figure 2) that it was interacting with a busi-
ness decision-maker. Finally, it did not directly generate
the code but waited first for feedback on the mathematical
formulation.
To summarize, the GPTs demonstrated impressive, relevant
capabilities: they interacted with the user to understand the
business problem and managed to get to the point of gener-
ating an optimization formulation. However, they did not
take sufficient time to fully understand the problem before
trying to generate a model, ending up with an unsuitable
and incomplete formulation. Moreover, after generating the
mathematical formulation and before continuing to code
generation, they asked the business user to confirm the cor-
rectness of the optimization model, which is not something
a business user can do.
4.2.2. REQUIREMENT #2: VERIFYING OPTIMIZATION
MODEL CORRECTNESS
In these experiments, we tested ChatGPT’s ability to gener-
ate correct models for optimization problems when given a
very precise description of the problem and not high-level
ones as in Example 3.1 (the full details of the experiments
appear in Appendix B.2). The optimization problems were
optimizing the location of vaccination clinics and optimizing
radiotherapy treatment for cancer patients (a problem similar
to the one in (Zarepisheh et al., 2022)). Because ChatGPT’s
outputs are non-deterministic, we ran each ChatGPT five
times on each problem. Overall, ChatGPT performed well,
providing correct models for both problems four out of five
times. However, for both problems, one of the five experi-
ments generated an incorrect objective function expression
(both correct and incorrect objective functions for both ex-
periments appear in Figure 4). For the vaccination clinic
optimization problem, it missed the essential term ri in the
objective function, which is required to modify the demand
by only assigning residents to clinics based on the area (see
Figure 4(a) and 4(b) for the correct and incorrect objective
function respectively). For radiotherapy treatment, one out
of the five times, it incorrectly provided a nonlinear formu-
lation of the problem, even though a linear formulation was
explicitly asked for by incorporating the BED nonlinear
6


--- Page 7 ---
Decision Optimization CoPilot
Figure 4. Objective Functions Generated by ChatGPT (Require-
ment 2)
function (see Figure 4(d)). In the other four times, it cor-
rectly provided a linear objective function by calculating the
values of the BED function for the input data and summing
over the values (Figure 4(c)). Both mistakes are relatively
subtle and difficult for a novice optimization modeler to spot.
This underscores the necessity for higher-quality model gen-
eration, validation mechanisms suitable for the business
decision-maker, and the ability to incorporate user feedback
to improve model accuracy.
4.2.3. REQUIREMENT #3: CREATING EFFICIENT
OPTIMIZATION MODELS
In this last set of experiments, our goal was to test whether
ChatGPT can create models that are more efficiently solv-
able by optimization solvers.
We began by assessing ChatGPT’s proficiency in transform-
ing a correct formulation of the bike hub optimization model
into a simpler one by prompting it to restructure the problem
into an equivalent form with fewer variables. In this test,
ChatGPT successfully produced an accurate version in only
one out of five attempts.
In the four instances where the formulations were incor-
rect, ChatGPT exhibited a variety of errors. These included,
among others, introducing nonlinear constraints or objective
functions and incorporating constraints that only include pa-
rameters without variables (for the full experiment and list
of errors, see Appendix D.1). Furthermore, ChatGPT could
not produce satisfactory reformulations without explicit in-
structions to maintain an equivalent form while minimizing
variables. In scenarios with more open-ended instructions,
ChatGPT struggled to deliver adequate solutions. It tended
to oversimplify the problem, either by omitting constraints
or by incorrectly redefining sets.
In another experiment, we offered ChatGPT a constraint
with absolute values and asked ChatGPT if this constraint
could be represented by linear constraint, which is much
more efficient. For the case of a convex ≤constraint, the an-
swer was always correct. However, for the case of a concave
≥constraint, ChatGPT did not use binary variables, and the
answer was incorrect. We observed similar results for the
case of ‘the sum of max of linear functions.’ Such compo-
nents often occur in, e.g., production-inventory problems,
and it is well known that linear constraints can reformulate
such a nonlinear constraint. ChatGPT also finds this refor-
mulation but again forgets to introduce binary variables for
the ≥constraint.
Overall, this set of experiments shows that there is a signif-
icant gap in ChatGPT’s ability to formulate efficient opti-
mization models.
4.3. Summary of State of the Art
As can be seen, LLMs already provide important capabil-
ities in realizing our DOCP vision. However, most of the
progress of previous works has been in using precise and
detailed natural language descriptions of a problem to gen-
erate correct optimization models (Requirement #2). Little
or no work has been done to generate optimization models
from a business-level problem description or to ensure the
creation of models that can be efficiently solved by solvers
(Requirement #1 and Requirement #3), and our experiments
show significant gaps in these areas. Even for requirement
#2, the current state of the art is such that often incorrect
models are generated, including subtle errors that are very
hard to detect. Therefore, much work remains for the DOCP
vision to be realized.
5. Research Directions for Creating a DOCP
In creating a DOCP, LLM adaptation can play a significant
part. As there are many ways in which an LLM can be
adapted to a specific task (see Section 2.1), an important re-
search direction is how best to combine the different adapta-
tion techniques - prompting, fine-tuning and RLHF. Specific
examples include: should LLMs be fine-tuned with specific
decision optimization knowledge? What can prompting
techniques (such as Chain of thoughts prompting (Wei et al.,
2022b) - a prompting technique found effective in reasoning
tasks) accomplish? What are the best prompting techniques
for each of the requirements? How should LLMs be adapted
to generate correct and efficient optimization models? How
best could LLMs be adapted to reduce the number of vari-
ables, reformulate nonlinear models into linear, and add
problem-specific decomposition and column generation?
Another important research direction is which parts of the
DOCP should be driven by the LLM, and which parts by
external workflows such as Tree of Thoughts (Yao et al.,
2023) or Graph of Thoughts (Besta et al., 2023)? For a con-
crete example, it may be possible to utilize existing method-
ological frameworks, such as CRISP-DM (CRoss Industry
Process for Data Mining (Wirth & Hipp, 2000)) that guide
an analytics practitioner through the process described by
Figure 1). Would a graph-of-thought DOCP implementation
7


--- Page 8 ---
Decision Optimization CoPilot
incorporating such methodologies yield good results?
Regarding Requirement #2, as there is always a chance that
an incorrect model will be generated, tools are required to
enable the business user to validate any solution provided
by a DOCP. Even today, business users often struggle to
validate and understand solutions provided by expert-created
optimization models, so tools such as what-if analysis are
used. Specifically, business users can change a solution or
provide an alternate one and see which model constraints
are violated and what the resulting objective function value
is. These existing techniques could be augmented by LLM
capabilities such as those in Li et al. (2023a), where the
user can ask questions about the model in natural language.
It may also be worthwhile to explore creating LLM-based
chatbots to whom the user can direct questions and have a
conversation to understand better and validate the models.
Another important research direction for Requirement #2
is how a specific generated model and the DOCP’s general
capabilities can be updated based on user feedback. For ex-
ample, during the validation of a model, the user may realize
that for specific solutions, the wrong objective has been cal-
culated, or a business constraint has been wrongly marked
as being violated. Similarly, the user may be able to provide
solutions that satisfy the business constraints, possibly along
with their objective function value. It would be important to
both correct the specific model and continuously improve
the DOCP based on this feedback.
Regarding requirement #3, when an optimization engine is
used to solve an optimization model, the parameter settings,
such as which heuristics to use, can have a significant ef-
fect. A large body of existing works known as Learning to
Optimize (Chen et al., 2022; Chi et al., 2022; Gupta et al.,
2022; Khalil et al., 2022) uses machine learning techniques
to find good heuristic settings for specific problem types
to reduce the solution time. Currently, such techniques are
used by optimization experts, tailoring them to specific prob-
lem instances. An interesting avenue of research would be
to see if LLMs could be adapted to select and customize the
appropriate learning to optimize techniques in a problem-
specific manner. As a final point, could the huge body of
knowledge on the internet about the theory and application
of optimization, including problem modeling and best prac-
tices (see, e.g., Williams (2013)), be better used to fine-tune
an LLM to generate more efficient optimization models and
optimization engine parameters’ settings?
5.1. Datasets and Benchmarks
Research towards a DOCP will require appropriate datasets
and well-defined quality metrics. Clearly, any such dataset
should consist of a set of optimization problems, each con-
taining a business-level description and a correct and effi-
cient “ground truth” optimization model. Creating these
parts of the datasets could utilize journals (e.g., IJA (2024))
and books (Williams, 2013) describing real-world case stud-
ies and their associated models. It may also be possible
to extend datasets created by existing works bringing to-
gether LLMs and optimization such as Amarasinghe et al.
(2023). However, in addition to the natural language prob-
lem descriptions and “ground truth” models, as the DOCP
is required to have a conversation with the business user to
understand the problem and create an appropriate model,
a component that can carry out the business user side of
the conversation is also required. An interesting avenue
of research is to see whether an LLM independent of the
DOCP can be used to emulate the business user’s side of the
conversation, to enable DOCP development and testing.
Regarding evaluation, measures used in most existing works
using LLMs to generate optimization models are based on
the syntactical accuracy of the generated model as compared
to the “ground truth” model (see Section 4.1). However, the
goal of a DOCP is to generate good solutions to the business
problem, and two very syntactically different models could
model the same identical set of constraint-satisfying opti-
mal solutions. Therefore, we posit that the metrics should
directly relate to solution quality. While we leave a precise
definition of these metrics to future work, we propose that
these metrics should be based on measures such as whether
the solutions generated by the DOCP satisfy the constraint
of the ground truth model, how good they are in terms of
ground truth objective value, and their execution time run-
ning time (possibly building on and extending the metrics
defined by Amarasinghe et al. (2023)).
6. Summary and call to action
We outlined our vision to combine LLMs and optimization
modeling to create a DOCP to widely democratize the use
of optimization for decision-making. We outlined three
core requirements, discussed the current state of the art,
and demonstrated the significant gaps to overcome. Due to
these gaps and the huge positive implications of realizing
this vision, we hope this work serves as a call for action to
mobilize the LLM and optimization research communities
around this goal.
We would also like to highlight that even intermediary tech-
niques and tools created on the path to a DOCP will already
significantly democratize the use of optimization by reduc-
ing the level of expertise required and enhancing accessi-
bility. For instance, the improved automatic generation of
efficient optimization models will empower novice modelers
to achieve greater effectiveness. An optimization modeler
could utilize a chatbot to facilitate discussions with business
users (per requirement #1), bridging the communication
gap between business decision-makers and optimization ex-
perts. Introducing a natural language interface tailored for
8


--- Page 9 ---
Decision Optimization CoPilot
business use will increase the acceptance and application of
these models in real-world scenarios. Such incremental ad-
vancements could already result in much more widespread
data and model-driven decision-making.
7. Statement of impact
The vision of DOCP, if realized, has the potential to make
decision-makers much more effective in their jobs and pro-
vide immense benefits by enabling optimization to be used
across a vastly larger number of real-world decision-making
problems, thereby leading to much more widespread better
decision-making. As can be seen in the use cases referenced
in the article, such optimization-driven decisions result in
significant monetary and societal benefits such as better
food utilization and healthcare.
Ethical implications
In any optimization solution, there are dangers if the rec-
ommendations are followed blindly and poorly understood
by the decision-maker whose responsibility is to make the
decision. Introducing a DOCP does not and should not
lessen the decision-maker’s responsibility. When collab-
orating with an optimization modeler, there’s the added
benefit of a knowledgeable professional who can provide
insights. This expert not only grasps the intricacies of the
model but can also elucidate the underlying assumptions
and its potential limitations for the business decision-maker.
Therefore, using a DOCP underscores the need for features
that allow the business decision-maker to understand the
proposed solution and its limitations deeply. In high-stakes
cases, the business decision-maker should still consult with
an optimization modeler to review the optimization model
created by the DOCP. In very high-risk cases, it may be
better for the business decision-maker to forgo the direct
use of a DOCP and instead engage with an optimization
modeler, who may then leverage the DOCP to accelerate
the creation of the optimization solution, ensuring a more
informed and cautious approach to decision-making.
The need for extra care and validation is an additional key
advantage of our proposed approach: having the LLM gen-
erate an optimization model rather than directly produce a
solution. This approach is beneficial because it is consider-
ably easier for an optimization modeler to review and un-
derstand the assumptions and limitations of a mathematical
optimization model than a solution directly generated by an
LLM. This step allows for a more transparent and reviewable
decision-making process, ensuring that the decision-maker
is fully informed of all aspects of the solution.
References
INFORMS Journal on Applied Analytics.
https:
//pubsonline.informs.org/loi/ijaa, 2024.
Accessed: 2024-01-21.
AhmadiTeshnizi, A., Gao, W., and Udell, M. Optimus: Opti-
mization modeling using MIP solvers and large language
models. arXiv preprint arXiv:2310.06116, 2023.
Almonacid, B. Towards an automatic optimisation model
generator assisted with generative pre-trained transformer.
arXiv preprint arXiv:2305.05811, 2023.
Amarasinghe, P. T., Nguyen, S., Sun, Y., and Alahakoon,
D. AI-copilot for business optimisation: A framework
and a case study in production scheduling. arXiv preprint
arXiv:2309.13218, 2023.
Bahdanau, D., Cho, K., and Bengio, Y. Neural machine
translation by jointly learning to align and translate. In
International Conference on Learning Representations
(ICLR), 2015.
Besta, M., Blach, N., Kubicek, A., Gerstenberger, R., Gi-
aninazzi, L., Gajda, J., Lehmann, T., Podstawski, M.,
Niewiadomski, H., Nyczyk, P., et al. Graph of thoughts:
Solving elaborate problems with large language models.
arXiv preprint arXiv:2308.09687, 2023.
Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D.,
Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,
Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G.,
Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J.,
Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M.,
Gray, S., Chess, B., Clark, J., Berner, C., McCandlish,
S., Radford, A., Sutskever, I., and Amodei, D. Language
models are few-shot learners. In Neural Information
Processing Systems, 2020.
Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J.,
Horvitz, E., Kamar, E., Lee, P., Lee, Y. T., Li, Y.,
Lundberg, S., et al. Sparks of artificial general intel-
ligence: Early experiments with gpt-4. arXiv preprint
arXiv:2303.12712, 2023.
Chen, H., Constante-Flores, G. E., and Li, C. Diagnosing
infeasible optimization problems using large language
models. arXiv preprint arXiv:2308.12923, 2023.
Chen, T., Chen, X., Chen, W., Wang, Z., Heaton, H., Liu,
J., and Yin, W. Learning to optimize: A primer and a
benchmark. J. Mach. Learn. Res., 23(1), Jan 2022. ISSN
1532-4435.
Chi, C., Aboussalah, A. M., Khalil, E. B., Wang, J., and
Sherkat-Masoumi, Z. A deep reinforcement learning
framework for column generation. In Neural Information
Processing Systems (NeurIPS), 2022.
9


--- Page 10 ---
Decision Optimization CoPilot
Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y.,
Fedus, W., Li, Y., Wang, X., Dehghani, M., Brahma,
S., et al. Scaling instruction-finetuned language models.
arXiv preprint arXiv:2210.11416, 2022.
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H.,
Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano,
R., et al. Training verifiers to solve math word problems.
arXiv preprint arXiv:2110.14168, 2021.
Dai, A. M. and Le, Q. V. Semi-supervised sequence learning.
In Neural Information Processing Systems, 2015.
Deng, Y., Zhang, X., Wang, T., Wang, L., Zhang, Y., Wang,
X., Zhao, S., Qi, Y., Yang, G., and Peng, X. Alibaba real-
izes millions in cost savings through integrated demand
forecasting, inventory management, price optimization,
and product recommendations. INFORMS Journal on
Applied Analytics, 53(1):32–46, 2023.
Dodge, J., Ilharco, G., Schwartz, R., Farhadi, A., Hajishirzi,
H., and Smith, N. Fine-tuning pretrained language mod-
els: Weight initializations, data orders, and early stopping.
arXiv preprint arXiv:2002.06305, 2020.
Fan, Z., Ghaddar, B., Wang, X., Xing, L., Zhang, Y., and
Zhou, Z. Artificial intelligence for operations research:
Revolutionizing the operations research process. arXiv
preprint arXiv:2401.03244, 2024.
Gangwar, N. and Kani, N. Highlighting named entities in
input for auto-formulation of optimization problems. In
International Conference on Intelligent Computer Mathe-
matics, pp. 130–141. Springer, 2023.
Gao, L., Madaan, A., Zhou, S., Alon, U., Liu, P., Yang,
Y., Callan, J., and Neubig, G. Pal: Program-aided lan-
guage models. In International Conference on Machine
Learning, pp. 10764–10799. PMLR, 2023.
GitHub Inc.
GitHub copilot, 2021.
URL https://
github.com/features/copilot. Accessed: 21
January 2024.
Google.
Gemini
AI,
2024.
URL
https:
//blog.google/technology/ai/
google-gemini-ai/.
Accessed:
25 January
2024.
Gupta, P., Khalil, E. B., Chet´elat, D., Gasse, M., Bengio,
Y., Lodi, A., and Kumar, M. P. Lookback for learning
to branch. Transactions of Machine Learning Research
(TMLR), 2022. URL https://openreview.net/
forum?id=EQpGkw5rvL.
Gurobi Optimization, LLC. Gurobi Optimizer Reference
Manual, 2024. URL https://www.gurobi.com.
IBM.
IBM
ILOG
CPLEX
Optimizer,
2024.
URL
https://www.ibm.com/products/
ilog-cplex-optimization-studio/
cplex-optimizer.
Jang, S.
Tag embedding and well-defined intermediate
representation improve auto-formulation of problem de-
scription. arXiv preprint arXiv:2212.03575, 2022.
Jiang, A. Q., Sablayrolles, A., Roux, A., Mensch, A.,
Savary, B., Bamford, C., Chaplot, D. S., de las Casas,
D., Hanna, E. B., Bressand, F., Lengyel, G., Bour, G.,
Lample, G., Lavaud, L. R., Saulnier, L., Lachaux, M.-
A., Stock, P., Subramanian, S., Yang, S., Antoniak, S.,
Scao, T. L., Gervet, T., Lavril, T., Wang, T., Lacroix, T.,
and Sayed, W. E. Mixtral of experts. arXiv preprint
arXiv:2401.04088, 2024.
Khalil, E. B., Morris, C., and Lodi, A. Mip-gnn: A data-
driven framework for guiding combinatorial solvers. In
The AAAI Conference on Artificial Intelligence, 2022.
Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K.,
Clark, P., and Sabharwal, A. Decomposed prompting:
A modular approach for solving complex tasks. arXiv
preprint arXiv:2210.02406, 2022.
Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mo-
hamed, A., Levy, O., Stoyanov, V., and Zettlemoyer,
L. BART: Denoising sequence-to-sequence pre-training
for natural language generation, translation, and com-
prehension. In Jurafsky, D., Chai, J., Schluter, N., and
Tetreault, J. (eds.), Proceedings of the 58th Annual Meet-
ing of the Association for Computational Linguistics, pp.
7871–7880, Online, July 2020. Association for Compu-
tational Linguistics. doi: 10.18653/v1/2020.acl-main.
703. URL https://aclanthology.org/2020.
acl-main.703.
Li, B., Mellou, K., Zhang, B., Pathuri, J., and Menache,
I. Large language models for supply chain optimization.
arXiv preprint arXiv:2307.03875, 2023a.
Li, Q., Zhang, L., and Mak-Hau, V. Synthesizing mixed-
integer linear programming models from natural language
descriptions. arXiv preprint arXiv:2311.15271, 2023b.
Lightman, H., Kosaraju, V., Burda, Y., Edwards, H., Baker,
B., Lee, T., Leike, J., Schulman, J., Sutskever, I., and
Cobbe, K. Let’s verify step by step. arXiv preprint
arXiv:2305.20050, 2023.
Long, J.
Large language model guided tree-of-thought.
arXiv preprint arXiv:2305.08291, 2023.
Meadows, J. and Freitas, A. A survey in mathematical
language processing. arXiv preprint arXiv:2205.15231,
2022.
10


--- Page 11 ---
Decision Optimization CoPilot
Ning, Y., Liu, J., Qin, L., Xiao, T., Xue, S., Huang, Z.,
Liu, Q., Chen, E., and Wu, J. A novel approach for auto-
formulation of optimization problems. arXiv preprint
arXiv:2302.04643, 2023.
OpenAI.
Chatgpt: Language model for conversational
agents, 2023a. URL https://www.openai.com/.
Accessed: 1 January 2024.
OpenAI.
Introducing GPTs, 2023b.
URL https:
//openai.com/blog/introducing-gpts. Ac-
cessed: 1 January 2024.
OpenAI, Achiam, J., Adler, S., Agarwal, S., Ahmad, L.,
Akkaya, I., et al. GPT-4 technical report, 2023.
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.,
Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A.,
Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M.,
Askell, A., Welinder, P., Christiano, P. F., Leike, J., and
Lowe, R. Training language models to follow instructions
with human feedback. In Advances in Neural Information
Processing Systems, 2022.
Peters, K., Silva, S., Wolter, T. S., Anjos, L., van Ettekoven,
N., Combette, E., Melchiori, A., Fleuren, H., den Hertog,
D., and Ergun, ¨O. Un world food programme: Toward
zero hunger with analytics. Informs Journal on Applied
Analytics, 52(1):8–26, 2022.
Ramamonjison, R., Li, H., Yu, T. T., He, S., Rengan, V.,
Banitalebi-Dehkordi, A., Zhou, Z., and Zhang, Y. Aug-
menting operations research with auto-formulation of
optimization models from problem descriptions. arXiv
preprint arXiv:2209.15565, 2022.
Ramamonjison, R., Yu, T., Li, R., Li, H., Carenini, G., Ghad-
dar, B., He, S., Mostajabdaveh, M., Banitalebi-Dehkordi,
A., Zhou, Z., et al. Nl4opt competition: Formulating
optimization problems based on their natural language
descriptions. In NeurIPS 2022 Competition Track, pp.
189–203. PMLR, 2023.
Sanh, V., Webson, A., Raffel, C., Bach, S. H., Sutawika, L.,
Alyafeai, Z., Chaffin, A., Stiegler, A., Scao, T. L., Raja,
A., et al. Multitask prompted training enables zero-shot
task generalization. arXiv preprint arXiv:2110.08207,
2021.
Stiennon, N., Ouyang, L., Wu, J., Ziegler, D., Lowe, R.,
Voss, C., Radford, A., Amodei, D., and Christiano, P. F.
Learning to summarize from human feedback. In Neural
Information Processing Systems, 2020.
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi,
A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P.,
Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen,
M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W.,
Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn,
A., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez,
V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P. S.,
Lachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y.,
Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog,
I., Nie, Y., Poulton, A., Jeremy, et al. Llama 2: Open
foundation and fine-tuned chat models. arXiv preprint
arXiv: 2307.09288, 2023.
Trinh, T. H., Wu, Y., Le, Q. V., He, H., and Luong, T. Solv-
ing olympiad geometry without human demonstrations.
Nature, 625(7995):476–482, 2024.
Tsouros, D., Verhaeghe, H., Kadıo˘glu, S., and Guns, T. Holy
grail 2.0: From natural language to constraint models.
arXiv preprint arXiv:2308.01589, 2023.
Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones,
L., Gomez, A. N., Kaiser, Ł., and Polosukhin, I. At-
tention is all you need. Advances in neural information
processing systems, 30, 2017.
Vladimirou, H. and Zenios, S. A.
Stochastic Program-
ming and Robust Optimization, pp. 395–447. Springer
US, Boston, MA, 1997. ISBN 978-1-4615-6103-3. doi:
10.1007/978-1-4615-6103-3 12. URL https://doi.
org/10.1007/978-1-4615-6103-3_12.
Wei, J., Bosma, M., Zhao, V., Guu, K., Yu, A. W., Lester,
B., Du, N., Dai, A. M., and Le, Q. V. Finetuned language
models are zero-shot learners. In International Confer-
ence on Learning Representations, 2022a. URL https:
//openreview.net/forum?id=gEZrGCozdqR.
Wei, J., Wang, X., Schuurmans, D., Bosma, M., ichter, b.,
Xia, F., Chi, E., Le, Q. V., and Zhou, D. Chain-of-thought
prompting elicits reasoning in large language models. In
Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D.,
Cho, K., and Oh, A. (eds.), Advances in Neural Informa-
tion Processing Systems, volume 35, pp. 24824–24837.
Curran Associates, Inc., 2022b.
Williams, H. P. Model Building in Mathematical Program-
ming, 5th Edition. Wiley, 2013. ISBN 978-1-118-44333-
0. doi: 10.2307/253935.
Wirth, R. and Hipp, J. Crisp-dm: Towards a standard pro-
cess model for data mining. In Proceedings of the 4th
international conference on the practical applications
of knowledge discovery and data mining, volume 1, pp.
29–39. Manchester, 2000.
Wolsey, L. and Nemhauser, G.
Integer and Com-
binatorial Optimization.
Wiley Series in Discrete
Mathematics and Optimization. Wiley, 1988.
ISBN
9780471828198.
URL https://books.google.
com.tr/books?id=uG4PAQAAMAAJ.
11


--- Page 12 ---
Decision Optimization CoPilot
Wu, Y., Jiang, A. Q., Li, W., Rabe, M. N., Staats, C., Jam-
nik, M., and Szegedy, C. Autoformalization with large
language models. In Koyejo, S., Mohamed, S., Agar-
wal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Neural
Information Processing Systems, 2022.
Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., and
Chen, X. Large language models as optimizers. arXiv
preprint arXiv:2309.03409, 2023.
Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao,
Y., and Narasimhan, K. R. Tree of thoughts: Deliberate
problem solving with large language models. In Neural
Information Processing Systems, 2023.
Zarepisheh, M., Hong, L., Zhou, Y., Huang, Q., Yang,
J., Jhanwar, G., Pham, H. D., Dursun, P., Zhang, P.,
Hunt, M. A., Mageras, G. S., Yang, J. T., Yamada, Y. J.,
and Deasy, J. O.
Automated and clinically optimal
treatment planning for cancer radiotherapy. INFORMS
Journal on Applied Analytics, 52(1):69–89, 2022. doi:
10.1287/inte.2021.1095. URL https://doi.org/
10.1287/inte.2021.1095.
Zhang, D., Wang, L., Zhang, L., Dai, B. T., and Shen, H. T.
The gap of semantic parsing: A survey on automatic
math word problem solvers. IEEE transactions on pat-
tern analysis and machine intelligence, 42(9):2287–2305,
2019.
Ziegler, D. M., Stiennon, N., Wu, J., Brown, T. B., Radford,
A., Amodei, D., Christiano, P. F., and Irving, G. Fine-
tuning language models from human preferences. CoRR,
abs/1909.08593, 2019.
12


--- Page 13 ---
Decision Optimization CoPilot
A. A note about optimization notation
In this work, we use the terms ‘Linear Optimization (LO)’ and ‘Mixed Integer Linear Optimization’ instead of, respectively,
‘Linear Programming’ and ‘Mixed Integer Linear Programming’, which are terms the optimization community now attempts
to avoid.
B. Experiments with ChatGPT
B.1. Experiments for Requirement #1
B.1.1. CONVERSATION WITH GPT #1
User Input
I work for Mobian, a company in the Netherlands, and I want to have a methodology to identify optimal locations for their
bike rental hubs. A hub is composed both of a parking facility, where users can park their cars, as well as bicycles available
for rentals. The methodology should optimize the service while offering a maximum coverage of the needs of the commuters
in the cities targeted.
GPT’s Response
To assist you with creating an optimization model for identifying optimal locations for bike rental hubs, let’s start by
understanding the problem in detail. This will involve clarifying the objectives, constraints, and the data you have available.
Here are some initial questions to guide our discussion:
1. Objectives:
• What is the primary goal for the placement of these hubs? Is it to maximize coverage, minimize cost, maximize
usage, or a balance of these factors?
• Are there specific targets or key performance indicators (KPIs) that Mobian aims to achieve with these hubs?
2. Constraints:
• Are there limitations on the number of hubs that can be opened?
• Are there budget constraints for establishing these hubs?
• Are there any geographical or regulatory constraints that need to be considered (e.g., certain areas where hubs
cannot be established)?
3. Data Availability:
• What data does Mobian currently have? This could include data on commuter patterns, existing transportation
networks, demographic information, current bike usage statistics, etc.
• Is there information available on potential sites for these hubs and their costs?
4. Cities Targeted:
• Which specific cities or areas in the Netherlands are being considered for this project?
• Is there a priority list among these cities based on market research or strategic importance?
Understanding these aspects will help us determine if optimization modeling is appropriate for this task and, if so, what type
of optimization model would be most suitable.
User Input
I want to maximize the covered demand, and have a bound on the number of opened hubs. I am first considering Amsterdam,
and the data that I have is the following:
1. Demand for POI p, coming from junction j
2. Distance from junction j to hub h (meters)
13


--- Page 14 ---
Decision Optimization CoPilot
3. Distance from hub h to POI p (meters)
4. Distance from junction j to POI p (meters)
5. Car travel time from junction j to hub h (min)
6. Car travel time from junction j to POI p (min)
7. Bike travel time from hub h to POI p (min)
8. Dataframe containing the names (Roads) and coordinates (Latitude and Longitude) of the different junctions
9. Dataframe containing the names (Name) and coordinates (Latitude and Longitude) of the different hubs
10. Dataframe containing the adress (Adress) and coordinates (Latitude and Longitude) of the different POIs
11. Dataframe contraining the expected values for the different, individual parameters
12. Geodataframe containing the road network accessible to bikers of Amsterdam
13. Geodataframe containing the road network accessible to cars of Amsterdam
GPT’s Response
Thank you for providing detailed information about your data and objectives for Mobian’s bike rental hub optimization
in the Netherlands. Based on what you’ve described, we can proceed with formulating an optimization model. Here’s a
step-by-step approach:
1. Understanding the Problem
• Objective: Maximize covered demand for bike rentals.
• Constraints: Bound on the number of hubs that can be opened.
2. Validating Optimization Appropriateness:
Given the goal to maximize demand coverage and the presence of constraints like the limit on the number of hubs, an
optimization model is appropriate for this problem.
3. Deciding the Type of Optimization Model
Given the nature of your problem, a Mixed Integer Linear Program (MILO) seems suitable. This is because:
• You have a binary decision to make (whether to open a hub at a particular location or not), which is an integer
decision.
• The objective and constraints can likely be expressed as linear functions of your decision variables.
4. Creating the Optimization Model
Decision Variables:
• xh: Binary variable where xh = 1 if a hub is established at location h and 0 otherwise.
Objective Function:
• Maximize total covered demand. Let Dph be the demand from POI p covered by hub h. The objective function is:
max P
p,h Dph × xh
Constraints:
• Hub Limit: If N is the maximum number of hubs, then:
P
h xh ≤N
• Coverage Constraint: A POI p can only be considered covered if it is within a certain distance or travel time from
an open hub. This can be represented by a set of constraints ensuring Dph is only counted if a hub h is open and
within the required distance travel time from pp.
14


--- Page 15 ---
Decision Optimization CoPilot
Data Integration:
• Your datasets will help define parameters like distances, travel times, and demand values.
5. Programmatic Model Using PuLP
Once the mathematical model is confirmed, we can translate it into a programmatic model using the PuLP library in
Python. This will involve defining the decision variables, objective function, and constraints in code, and then using
PuLP’s solver to find the optimal solution.
Before moving on to the next step, it’s important to confirm that the proposed model aligns with your understanding
and requirements. Additionally, if there are specific coverage criteria for a POI to be considered ”covered” by a hub,
please specify those as well.
B.1.2. CONVERSATION WITH GPT #2
User Input
I work for Mobian, a company in the Netherlands, and I want to have a methodology to identify optimal locations for their
bike rental hubs. A hub is composed both of a parking facility, where users can park their cars, as well as bicycles available
for rentals. The methodology should optimize the service while offering a maximum coverage of the needs of the commuters
in the cities targeted.
GPT’s Response
To develop an optimization model for identifying the optimal locations for Mobian bike rental hubs in the Netherlands, let’s
start by understanding your problem in more detail:
1. Objectives: The primary objective seems to be to optimize the placement of bike rental hubs to cover the maximum
needs of commuters. This could be further detailed as:
• Maximizing coverage: Ensuring the hubs are accessible to the largest possible number of potential users.
• Service optimization: Ensuring efficient operations, such as adequate bikes and parking spaces at each hub.
2. Constraints: These might include:
• Budget constraints for setting up and maintaining hubs.Geographic or zoning limitations.
• Capacity constraints for each hub (like the number of bikes or parking spaces).
3. Data Availability: What kind of data do you have or can acquire? This might include:
• Geographic data of the cities.
• Population density and commuter patterns.
• Existing transportation infrastructure.
• Potential costs associated with setting up and maintaining hubs.
Do these points accurately capture your problem? And could you provide more details on the constraints and available data?
This will help in ensuring that the optimization model is well-suited for your needs.
User Input I want to maximize the covered demand, and have a bound on the number of opened hubs. I am first considering
Amsterdam, and the data that I have is the following:
1. Demand for POI p, coming from junction j
2. Distance from junction j to hub h (meters)
3. Distance from hub h to POI p (meters)
4. Distance from junction j to POI p (meters)
5. Car travel time from junction j to hub h (min)
15


--- Page 16 ---
Decision Optimization CoPilot
6. Car travel time from junction j to POI p (min)
7. Bike travel time from hub h to POI p (min)
8. Dataframe containing the names (Roads) and coordinates (Latitude and Longitude) of the different junctions
9. Dataframe containing the names (Name) and coordinates (Latitude and Longitude) of the different hubs
10. Dataframe containing the address (Address) and coordinates (Latitude and Longitude) of the different POIs
11. Dataframe contraining the expected values for the different, individual parameters
12. Geodataframe containing the road network accessible to bikers of Amsterdam
13. Geodataframe containing the road network accessible to cars of Amsterdam
GPT’s Response
Based on the detailed data you have provided and your objectives, we can proceed to structure an optimization model for
Mobian’s bike rental hubs in the Netherlands. Here’s a step-by-step approach:
1. Confirming Optimization Suitability: Given your objective to maximize covered demand within a constraint on the
number of opened hubs, an optimization approach is appropriate. It will allow you to find the best locations for the
hubs considering the demand, distances, and travel times.
2. Model Type Decision: For your case, a Mixed Integer Linear Program (MILO) seems appropriate. This is because:
• You have linear relationships (like distances and times).
• The decision to open a hub at a location is binary (either a hub is opened or it’s not).
• You have a mix of continuous variables (distances, times) and integer variables (number of hubs).
3. Model Structure:
• Decision Variables:
– Binary variables indicating whether a hub is opened at a potential location.
– Other variables might include the number of bikes at each hub, though this seems secondary to your primary
objective.
• Objective Function:
– Maximize the total demand covered by the opened hubs. This will be a function of the demand at each POI
and the accessibility of those POIs from the opened hubs.
• Constraints:
– Limit on the total number of hubs that can be opened.
– Constraints ensuring that the demand is only considered covered if it’s within a certain travel time or distance
from an opened hub.
– Possibly, additional constraints based on your operational parameters.
4. Mathematical Formulation: Let xh be a binary variable where xh = 1 if a hub is opened at location h and 0 otherwise.
Let Dp,h be the demand at POI p that can be covered by hub h.
Objective Function:
max P
h
P
p Dp,h · xh
Constraints:
• P
h xh ≤MaxHubs (limit on the number of hubs)
• Other constraints based on distances and travel times as needed.
16


--- Page 17 ---
Decision Optimization CoPilot
5. PuLP Implementation:
The next step would be to translate this model into a programmatic form using Python and the PuLP library. This
involves defining the decision variables, objective function, and constraints in code, then solving the model using
PuLP’s solver.
Before moving forward to the PuLP implementation, do you confirm that this model structure aligns with your needs?
Additionally, if there are specific thresholds for travel times or distances that define whether a demand point is considered
covered by a hub, please provide these details.
B.2. Experiments for Requirement #2
B.2.1. VACCINATION CLINICS LOCATION OPTIMIZATION
The state of Massachusetts knows the legendary talent of the students at MIT, and the Covid task force decided to call the
Analytics for a Better World students for help. In case of a future pandemic, the state wants to be ready and plan for the
deployment of mass vaccination clinics in Eastern Mass.
Given available resources, you can build only 4 sites across the Boston area. You have identified 10 potential sites, each
with a fixed capacity (i.e., a maximum number of residents that can be vaccinated there). All residents will need to access
one of the clinics you will construct. You aim to determine which sites to build to optimize the vaccination service provided
to the population.
The area under consideration can be modeled as a 5 × 10 miles rectangle, with 50 major residential areas. We index
the residential areas by i = 1, . . . , 50 and the vaccination sites by j = 1, . . . , 10. We use the so-called “Manhattan
distance”: if area i’s coordinates are (xi, yi) and site j’s coordinates are in (xj, yj) , the distance from i to j is given by
dij = |xi −xj| + |yi −yj|.
You are provided with the following data:
Parameters
• ri : number of residents in area i = 1, . . . , 50;
• Cj : capacity of vaccination site j = 1, . . . , 10;
• dij : distance between area i = 1, . . . , 50 and site j = 1, . . . , 10.
You also have access to the following files:
• P1 areas.csv: A matrix of size 50 × 3 that indicates, for each area, (i) its x-coordinate, in miles (0 to 5), (ii) its
y-coordinate, in miles (0 to 10) and (iii) its number of residents.
• P1 clinics.csv: A matrix of size 10×3 that indicates, for each candidate clinic, (i) its x-coordinate, in miles (0 to 5), (ii)
its y-coordinate, in miles (0 to 10), and (iii) its capacity.
Formulate an integer optimization model that optimizes the selection of sites to minimize the total distance across all
residents required to access their assigned clinic.
Correct ChatGPT’s answer
To formulate an integer optimization model for selecting vaccination sites that minimizes the total distance for all residents
to access their assigned clinic, we define the decision variables, objective function, and constraints as follows:
Decision Variables
• Site Selection Variable (yj): A binary variable for each potential vaccination site j = 1, . . . , 10, where yj = 1 if site j
is selected and 0 otherwise.
17


--- Page 18 ---
Decision Optimization CoPilot
• Assignment Variable (xij): A binary variable for each pair of residential area i and vaccination site j, where xij = 1 if
area i is assigned to site j and 0 otherwise.
Objective Function
Minimize
50
X
i=1
10
X
j=1
ri · dij · xij
where ri is the number of residents in area i, and dij is the distance between area i and site j.
Constraints
1. Site Selection Limit: Only 4 sites can be selected.
10
X
j=1
yj = 4
2. Assignment Constraint: Each area must be assigned to exactly one clinic.
10
X
j=1
xij = 1
for all i = 1, . . . , 50
3. Capacity Constraint: The number of residents assigned to a clinic cannot exceed its capacity.
50
X
i=1
ri · xij ≤Cj
for all j = 1, . . . , 10
where Cj is the capacity of clinic j.
4. Assignment Only to Selected Sites: Residents can only be assigned to selected sites.
xij ≤yj
for all i = 1, . . . , 50, and j = 1, . . . , 10
Binary Nature of Decision Variables Both xij and yj are binary variables, taking values in {0, 1}.
Model Summary
• Objective: Minimize the total distance traveled by all residents to their assigned vaccination clinics.
• Constraints:
1. Site Selection: Exactly 4 sites should be chosen.
2. Assignment: Each residential area should be assigned to exactly one clinic.
3. Capacity: The total residents assigned to a clinic should not exceed its capacity.
4. Assignment Validity: Residents can only be assigned to selected clinics.
5. Binary Variables: Decision variables are binary.
This integer optimization model effectively captures the requirements for the optimal deployment of vaccination clinics
in the Boston area, aiming to minimize the total distance residents need to travel to get vaccinated while considering the
constraints of clinic capacity and site selection.
Comments on the formulation
The model presented by ChatGPT assumes that all residents in a given area are assigned
to the same vaccination clinic. This assumption eases modeling and interpretation and is fine by the question formulation, as
no constraint was specified. However, it is also possible to consider formulating the model at the individual resident level
rather than aggregating residents by area. ChatGPT was able to carry correct extensions when prompted.
18


--- Page 19 ---
Decision Optimization CoPilot
B.2.2. WRONG FORMULATION FROM CHATGPT
Correction to the Objective Function of the Integer Optimization Model
The following objective function in the
integer optimization model from ChatGPT is incorrect as it fails to include the term ri, representing the number of residents
in area i. The correct objective function should weigh the distance dij by the number of residents ri traveling to the site j.
Thus, the correct objective function to minimize the total distance traveled by all residents should be:
Minimize
50
X
i=1
10
X
j=1
ri × dij × Yij
This modification is crucial as it ensures that the model accurately reflects the total distance traveled by the entire population
rather than merely considering the distances between areas and clinics without regard to the number of residents in each
area.
Answer from ChatGPT
To formulate an integer optimization model for the problem of selecting optimal sites for
vaccination clinics in the Boston area, we consider decision variables, an objective function, and constraints.
Decision Variables
• Binary Site Selection Variable: Xj where j = 1, . . . , 10. Xj = 1 if site j is selected, and Xj = 0 otherwise.
• Assignment Variable: Yij where i = 1, . . . , 50 and j = 1, . . . , 10. Yij = 1 if residents of area i are assigned to site j,
and Yij = 0 otherwise.
Objective Function
Minimize the total distance traveled by all residents to their assigned clinics:
Minimize
50
X
i=1
10
X
j=1
dij × Yij
where dij is the distance between area i and site j.
Constraints
1. Site Selection Limit: Only four sites can be selected.
10
X
j=1
Xj = 4
2. Assignment to Selected Sites: Residents can only be assigned to selected sites.
Yij ≤Xj
for all
i, j
3. Capacity Constraint: The number of residents assigned to a clinic must not exceed its capacity.
50
X
i=1
ri × Yij ≤Cj × Xj
for all
j
4. Assignment of Each Area: Each residential area must be assigned to exactly one clinic.
10
X
j=1
Yij = 1
for all
i
5. Binary and Integer Constraints:
• Xj ∈{0, 1} for all j.
• Yij ∈{0, 1} for all i, j.
This model aims to determine the optimal selection and assignment of vaccination sites to minimize the total travel distance
for residents under the given constraints and assumptions.
19


--- Page 20 ---
Decision Optimization CoPilot
B.3. Radiotherapy Treatment
We are delighted to welcome you, our newest intern on the Analytics team of Massachusetts General Hospital! You have
been placed in a challenging role where you will be tasked with solving a real-world problem in the field of medical physics.
We are building a pilot program in Boston, and if successful, your work could be applied widely in hospitals with limited
capacity in many countries.
You are responsible for determining the best treatment plan for 17 patients who require radiotherapy. Your goal is to optimize
the use of two possible treatments: photon therapy and proton therapy. While proton therapy is known to target tumors more
precisely, it is also more expensive and has limited capacity in many countries. Therefore, you will need to balance the
benefits of proton therapy with its limitations and cost to create an effective treatment plan for each patient.
To determine the best course of action for each patient, you will use a scoring system called the Biological Equivalent Dose
(BED). This system allows you to calculate the effectiveness of each patient’s treatment plan by considering the number of
proton fractions that can be used while still achieving the highest possible BED.
We have n = 17 patients who need radiotherapy. Each patient i needs 15 fractions, which can be photon fractions, proton
fractions, or a mix of photon and proton fractions (e.g., 4 proton fractions and 11 photon fractions). We want to use the
limited proton therapy capacity as best as possible. We can calculate the BED score for each patient when p proton fractions
and 15 −p photon fractions are used, as BEDi(p,15 −p), i.e., the BED when p proton and 15 −p photon fractions are
delivered for patient i. The higher the score, the better.
The data file “outcome data.csv” on Canvas contains a matrix of 17 rows and 16 columns. In particular, the number at the
(i, j) position is BEDi(j −1,15 −j + 1)1.
Suppose that the total maximal capacity is C proton fractions. To maximize the total BED scores for all the patients, which
patients should get proton fractions, and how many should they get? Formulate an integer linear optimization model to solve
this problem. Assume you know the value BEDi(j,15 −j) for each patient i ∈[1, 17].
B.3.1. CORRECT ANSWER FROM CHATGPT
To formulate an integer linear optimization model for this problem, we define the decision variables, the objective function,
and the constraints. The goal is to maximize the total Biological Equivalent Dose (BED) scores for all patients, considering
the limited capacity of proton fractions.
Decision Variables
Define a matrix xi,p where:
• i is the patient index (i ∈{1, 2, ..., 17}).
• p is the number of proton fractions (p ∈{0, 1, ..., 15}).
• xi,p is a binary variable that takes the value 1 if patient i receives p proton fractions (and 15 −p photon fractions), and
0 otherwise.
Objective Function
The objective is to maximize the total BED across all patients. Therefore, the objective function is:
Maximize
17
X
i=1
15
X
p=0
BEDi(p, 15 −p) × xi,p
Constraints
1. Capacity Constraint: The total number of proton fractions used across all patients must not exceed the total capacity
C.
17
X
i=1
15
X
p=0
p × xi,p ≤C
1Notice Julia starts indexing at 1, hence this j −1, 15 −j + 1 as an adjustment.
20


--- Page 21 ---
Decision Optimization CoPilot
2. Treatment Constraint: Each patient should receive exactly one combination of proton and photon fractions.
15
X
p=0
xi,p = 1
for each patient i
3. Integer Constraint: The decision variables xi,p are binary.
xi,p ∈{0, 1}
Model Summary
• Objective: Maximize P17
i=1
P15
p=0 BEDi(p, 15 −p) × xi,p
• Subject to:
– Capacity Constraint: P17
i=1
P15
p=0 p × xi,p ≤C
– Treatment Constraint: P15
p=0 xi,p = 1 for each i
– Integer Constraint: xi,p ∈{0, 1}
This model can be solved using integer linear optimization techniques to determine the optimal distribution of proton and
photon fractions for each patient, given the total capacity C of proton fractions.
B.3.2. WRONG ANSWER FROM CHATGPT
Note: The model generated a nonlinear objective function using the term Maximize P17
i=1 BEDi(xi, 15 −xi). However,
the correct formulation should have included the term Maximize P17
i=1
P15
p=0 BEDi(p, 15 −p) × xi,p, as demonstrated
above. This represents a subtle error that can easily go unnoticed.
Indeed, both the incorrect and correct terms involve summations and the BED function, which could lead to a quick glance
overlooking the additional summation and variable in the correct term. Without a deep understanding of the context or the
specific requirements of the model, one might not realize that the additional summation and the xi,p term are necessary to
obtain an integer linear optimization model.
When prompted that the formulation
ChatGPT’s answer:
To formulate an integer linear optimization model for this problem, we need to consider the following elements:
• Decision Variables: Represent the number of proton fractions allocated to each patient.
• Objective Function: Maximize the total Biological Equivalent Dose (BED) score across all patients.
• Constraints: Include the total capacity of proton therapy and the requirement for each patient to receive 15 fractions in
total.
Decision Variables
Let xi be the number of proton fractions allocated to patient i, where i ranges from 1 to 17. xi is an
integer.
Objective Function
Maximize P17
i=1 BEDi(xi, 15 −xi) This function sums the BED scores for all patients, maximizing
the total effectiveness of the treatments.
Constraints
1. Proton Capacity Constraint: P17
i=1 xi ≤C The total number of proton fractions used should not exceed the
maximum capacity C.
2. Fraction Constraint for Each Patient: 0 ≤xi ≤15 for all i ∈[1, 17] Each patient must receive a total of 15 fractions,
which can be a mix of proton and photon fractions.
3. Integrality Constraint: xi are integers.
21


--- Page 22 ---
Decision Optimization CoPilot
Integer Linear Optimization Model
The final model can be represented as follows:
Maximize: P17
i=1 BEDi(xi, 15 −xi)
Subject to:
1. P17
i=1 xi ≤C
2. 0 ≤xi ≤15 for all i ∈[1, 17]
3. xi are integers.
This model will allocate the proton therapy fractions to the patients in a way that maximizes the overall effectiveness of the
treatments, considering the constraints of the total proton capacity and individual patient needs.
C. Human Crafted Optimization Models For Example 3.1
In this section, we give two hub location models developed for by an Optimization expert (without using ChatGPT) for the
problem of Example 3.1. The two models are equivalent. However, the second model is computationally more tractable
since it contains fewer variables. We first introduce sets, parameters, and variables that we use in the models.
Sets:
H : Set of hub indexes, where h = 1, ..., N refers to all existing hubs and
indexes h = N + 1, ..., M corresponds to all potential hub locations.
P : Index set of POIs (size n).
S : Index set of all junction roads (size q).
F = {s ∈S, h ∈H, p ∈P | csp + ∆< csh + bhp or bhp > T or dhp < D or dsp −dhp < τ}
Parameters:
vsp : Demand for POI p, coming from junction s
csp : Car travel time from junction s to POI p (min)
csh : Car travel time from junction s to hub h (min)
bhp : Bike travel time from hub h to POI p (min)
dsp : Distance from junction s to POI p (meters)
dhp : Distance from hub h to POI p (meters)
T : Longest accepted bike travel time from a hub to a POI (min)
N : Number of existing hub locations
U : Maximum number of new hubs planned to be opened
D : Minimum distance between a hub and a POI (meters)
∆: Maximum allowed extra travel time by bike from car travel time (min)
τ : Distance separating a hub lopcation from a POI (meters)
22


--- Page 23 ---
Decision Optimization CoPilot
Variables:
xshp =





1 if hub h is assigned to POI p from junction s and
csp + ∆> csh + bhp, dsp −dhp > τ, bhp < T and dhp > D
0 if not
yh =
(
1 if hub h is opened
0 else
Model 1
max
X
s∈S
X
h∈H
X
p∈P
vspxshp
s.t.
M
X
h=N+1
yh ≤U
Bound number of opened hubs
N
X
h=1
yh = N
Set the first N hubs to be open
M
X
h=1
xshp ≤1
∀s ∈S, p ∈P
Ensure every OD-pair travels via at most one hub
xshp ≤yh
∀s ∈S, p ∈P, h ∈H
An OD-pair can only travel via an opened hub
xshp = 0
∀s, h, p ∈F
All OD-pairs that are in the ’not allowed’ set F are set to 0
xshp, yh ∈{0, 1}
∀s ∈S, h ∈H, p ∈P
Domain constraints
The objective is to maximize the covered demand. The first constraint is an upper bound on the number of opened hubs. The
second constraint is to set the first m existing hubs to be open. The third constraint is to ensure that every junction-POI pair
can be assigned to at most one hub location. The fourth constraint is to ensure that every junction-POI pair can only travel
via an opened hub. The fifth constraint is to ensure that all junction-POI pairs that are in the ’not allowed’ set F are set to 0.
The last constraint ensures that the variables are binary.
Only one other set and variable are needed for the second model.
Set:
δh = {(s, p) ∈S × P | csp + ∆≥csh + bhp and bhp ≤T and dhp ≥D and dsp −dhp ≥τ}.
Variable:
xsp =





1 if ∃an opened hub h ∈H such that
csp + ∆≥csh + bhp, dsp −dhp > τ, bhp ≤T and dhp > D
0 otherwise.
Model 2
23


--- Page 24 ---
Decision Optimization CoPilot
max
X
s∈S
X
p∈P
vspxsp
s.t.
xsp ≤
X
h∈H:(s,p)∈δh
yh
∀s ∈S, p ∈P
Traveling from junction s to POI p is only possible if one of the nearby hubs is open
M
X
h=N+1
yh ≤U
No more than U locations can be opened
N
X
h=1
yh = N
Existing hubs are fixed to be opened
xsp, yh ∈{0, 1}
∀s ∈S, h ∈H, p ∈P
Domain constraints
Only the first constraint is new: this constraint ensures that the junction-POI pair (s, p) is ‘covered’ if one of the nearby
hubs is opened.
D. Experiments with Gap 3
D.1. Answer from ChatGPT to reduce the number of variables
The following is a correct answer from ChatGPT that was given the use case from Example 3.1 as before, to which we
appended Model 1 from Section B.2a nd tasked to: “Improve this formulation by reducing the number of variables and
making it more efficient. The formulation should be equivalent, but you must reduce the number of variables by modifying
the objective and constraints. Explain the reasoning first and then detail the equivalent reformulation.” For brevity, we only
include the new formulation given by ChatGPT below.
REVISED SETS, PARAMETERS, AND VARIABLES
Sets and Parameters: (Remain the same as in the original formulation)
Variables:
• yh: Binary variable. 1 if hub h is opened; 0 otherwise.
• zsp: Binary variable. 1 if Point of Interest (POI) p is assigned to any hub from junction s and satisfies the defined
constraints; 0 otherwise.
OBJECTIVE AND CONSTRAINTS
Objective:
• Maximize the total demand for POIs, considering the assignment to hubs:
Maximize
X
s∈S
X
p∈P
vspzsp
Constraints:
1. Bound the number of opened hubs:
M
X
h=N+1
yh ≤U
(Ensure the number of new hubs opened does not exceed the planned maximum.)
24


--- Page 25 ---
Decision Optimization CoPilot
2. Set the existing hubs to be open:
N
X
h=1
yh = N
3. Assign POI to a suitable hub:
zsp ≤
M
X
h=1
yh × I{h satisfies conditions for p from s}
∀s ∈S, p ∈P
(Here, I is an indicator function that checks if hub h satisfies the necessary conditions for POI p from junction s.)
4. Domain constraints for the binary variables:
zsp, yh ∈{0, 1}
∀s ∈S, p ∈P, h ∈H
EXPLANATION OF THE REFORMULATION
• This new formulation simplifies the model by reducing the number of binary variables. The complex variable xshp
from the original formulation is removed and replaced with zsp.
• The objective function is now more straightforward. It directly maximizes the demand coverage with a simpler
summation structure.
• Constraints are adjusted to incorporate the logic that was previously captured by xshp, using an indicator function
within the constraints.
• Overall, this reformulation aims to maintain the decision-making capability of the model while enhancing its computa-
tional efficiency by simplifying its structure.
D.2. Wrong formulation from ChatGPT
The model suggested by ChatGPT below is not correct. It contains a max operator and variables that indicate an index.
ChatGPT’s model is also not a mixed-integer linear optimization model.
SETS AND PARAMETERS (UNCHANGED)
• Sets: H, P, S, F as defined in the original model.
• Parameters: vsp, csp, csh, bhp, dsp, dhp, T, N, U, D, ∆, τ as defined in the original model.
MODIFIED VARIABLES
• yh: Unchanged, indicating if hub h is opened.
• zsp: Indicates the hub assigned to POI p from junction s. This variable takes a value from the set of possible hubs H.
OBJECTIVE FUNCTION
Maximize
X
s∈S
X
p∈P
vsp × score(zsp, s, p)
Where score(zsp, s, p) is a function that returns 1 if the hub zsp satisfies the conditions for the OD-pair (s, p) (i.e.,
csp + ∆> csh + bhp, dsp −dhp > τ, bhp < T, dhp > D), and 0 otherwise.
25


--- Page 26 ---
Decision Optimization CoPilot
CONSTRAINTS
1. PM
h=N+1 yh ≤U
• Bound the number of opened hubs.
2. PN
h=1 yh = N
• Set the first N hubs to be open.
3. zsp ≤M × max(yh) for all s ∈S, p ∈P
• An OD-pair can only travel via an opened hub.
4. zsp is not assigned to any hub in the ’not allowed’ set F for all s, p.
5. Domain constraints: yh ∈{0, 1} for all h ∈H; zsp ∈H for all s ∈S, p ∈P.
D.3. Wrong answer from ChatGPT
ChatGPT uses the indices hub and POI for the variables, which is not correct.
REVISED SETS AND PARAMETERS
Keeping the sets and parameters largely unchanged, but we introduce a new parameter to reduce variables:
H, P, S
(as defined earlier)
F
(as defined earlier)
vp
Aggregated demand for POI p from all junctions
REVISED VARIABLES
zhp =
(
1
if hub h is assigned to POI p and meets all constraints
0
if not
yh
(as defined earlier)
REVISED OBJECTIVE AND CONSTRAINTS
max
X
h∈H
X
p∈P
vpzhp
s.t.
M
X
h=N+1
yh ≤U
Bound number of opened hubs
N
X
h=1
yh = N
Set the first N hubs to be open
M
X
h=1
zhp ≤1
∀p ∈P
Ensure every POI is served by at most one hub
zhp ≤yh
∀p ∈P, h ∈H
A POI can only be served by an opened hub
zhp = 0
∀h, p ∈F ′
All POI-hub pairs that are in the ’not allowed’ set F ′ are set to 0
zhp, yh ∈{0, 1}
∀h ∈H, p ∈P
Domain constraints
26


--- Page 27 ---
Decision Optimization CoPilot
D.4. Wrong Formulation from ChatGPT
This model suggested by ChatGPT is not correct. The conditions are just put as constraints without variables.
SETS:
H : Set of hub indexes, where h = 1, ..., N refers to all existing hubs and
indexes h = N + 1, ..., M correspond to all potential hub locations.
P : Index set of POIs (Points of Interest), size n.
S : Index set of all junction roads, size q.
NEW PARAMETERS:
∆: Maximum allowed extra travel time by bike from car travel time (min).
VARIABLES:
yh =
(
1 if hub h is opened,
0 otherwise
zsp =
(
h if POI p from junction s is served by hub h,
0 if POI p from junction s is not served by any hub
OBJECTIVE FUNCTION AND CONSTRAINTS:
Objective:
Maximize
X
s∈S
X
p∈P
vsp · (zsp > 0)
Constraints:
M
X
h=N+1
yh ≤U
(Bound number of opened hubs)
N
X
h=1
yh = N
(Set the first N hubs to be open)
zsp ≤M · yh
∀s ∈S, p ∈P, h ∈H(A POI can only be served by an opened hub)
csp + ∆≥csh + bhp
∀s ∈S, p ∈P, h ∈H(Ensure travel time constraints)
dhp ≥D
∀h ∈H, p ∈P(Minimum distance between a hub and a POI)
yh, zsp ∈{0, 1, ..., M}
∀s ∈S, h ∈H, p ∈P(Domain constraints)
27
