--- Page 1 ---
1
Movable Antenna Enhanced Federated Fine-Tuning
of Large Language Models via Hybrid Client
Selection Optimization
Yang Zhao, Member, IEEE, Yue Xiu, Member, IEEE, Chengxiao Dai, Student Member, IEEE,
Dusit Niyato, Fellow, IEEE, Ning Wei, Member, IEEE
Abstract‚ÄîFederated fine-tuning of large language models
(LLMs) over bandwidth-limited 6G links must meet strict round-
time and energy budgets. Analog over-the-air (OTA) aggregation
reduces uplink cost but is sensitive to fading and interference,
which distort the aggregated gradient. We consider a two-
phase workflow, centralized pre-training followed by federated
fine-tuning, where the base station uses a movable antenna
(MA) array. In each round, MA element positions and the
receive/transmit beamformers are adjusted under minimum-
spacing constraints to reshape the channel and improve OTA
aggregation without increasing user transmit power. We formu-
late a mixed-integer, nonconvex resource-allocation problem that
jointly selects clients and optimizes the numbers of global rounds,
CPU frequencies, mini-batch sizes, MA positions, and analog
weights under end-to-end latency and energy limits. A successive
convex approximation‚Äìpenalty dual decomposition (SCA‚ÄìPDD)
routine alternates convex updates with oblique-manifold beam-
forming and spacing-aware MA placement. Experiments on
OpenLLaMA-v2 (3B) with LoRA and 4-bit quantization on Al-
paca and Dolly (10 clients) attain round-30 validation perplexities
as low as 2.94 (Alpaca, K=1) and 4.62 (Dolly, K=1). Relative
to the strongest non-MA baseline at the same concurrency, this
corresponds to 17.4% (Alpaca, K=1) and 54.4% (Dolly, K=1)
lower perplexity; at K=2 the reductions are 14.2% (Alpaca)
and 13.7% (Dolly). Participation fairness also improves across all
uplink concurrencies K ‚àà{1, 2, 4, 8} (where K is the number
of clients transmitting concurrently per OTA round), with the
largest margins when fewer clients transmit per round.
Index Terms‚ÄîFederated learning, large language models, over-
the-air aggregation, movable antennas.
I. INTRODUCTION
Large language models (LLMs) based on GPT-like archi-
tectures achieve strong performance on generation, question
answering, and summarization [1]. They are typically trained
in two stages: a phase of pre-training on massive, general-
purpose corpora [2], followed by fine-tuning on task- or
domain-specific data, for example, biomedical, legal, or med-
ical [3], [4]. In wireless edge settings targeted by 6G, fine-
tuning must respect tight round-time and energy budgets, mak-
Yang Zhao.(e-mail:zhao0466@e.ntu.edu.sg).
Yue Xiu and Ning Wei are with the National Key Laboratory of Sci-
ence and Technology on Communications, University of Electronic Sci-
ence and Technology of China, Chengdu 611731, China (e-mail: xi-
uyue12345678@163.com).
Chengxiao
Dai
is
with
the
University
of
Sydney,
Australia.
(e-
mail:cdai0023@uni.sydney.edu.au)
Dusit Niyato is with Nanyang Technological University, Singapore. (e-
mail:dniyato@ntu.edu.sg).
ing the joint management of communication and computation
a central challenge.
A common approach is to split training into (i) centralized
pre-training on a compute-rich server and (ii) federated fine-
tuning across many devices [5], [6]. Although this two-phase
design limits data movement, iterative model synchronization
remains a bottleneck under fading and interference. Ana-
log over-the-air (OTA) gradient aggregation reduces uplink
bandwidth by superposing waveforms, but it introduces two
physical-layer distortions: (i) an analog-sum mismatch be-
tween the received superposition and the desired weighted
gradient sum, and (ii) post-combining noise. Both degrade the
effective gradient used by SGD and can slow or destabilize
learning unless the wireless configuration is adapted round by
round.
To mitigate these distortions, we consider a base station
equipped with a movable antenna (MA) array. Unlike fixed
phased arrays or purely reflective surfaces, MAs physically
reposition radiating elements within a constrained region. By
adjusting element positions and beamformers slightly each
round, the base station can reshape the channel to better align
simultaneous uplink transmissions, thereby reducing analog-
sum mismatch and shaping post-combining noise without
increasing user transmit power. Realizing these gains re-
quires coordinating MA geometry with higher-layer training
choices under practical constraints such as minimum inter-
element spacing, limited displacement per round, motion la-
tency/actuator energy, and channel-estimation overhead.
Another key factor is the distribution shift: the domain-
specific fine-tuning data often differ statistically from the pre-
training corpus [7], [8]. We use a Wasserstein-based term to
quantify this shift and incorporate it in a convergence view that
clarifies how pre-training progress, OTA-induced distortions,
and domain mismatch jointly affect the final loss.
Classical wireless federated learning largely optimizes com-
munication rounds, device scheduling, and power control
under fixed array geometries, without geometry-aware channel
reshaping at the base station [9]‚Äì[12]. OTA aggregation papers
commonly adopt simplified channels (LoS or i.i.d. Rayleigh)
and static arrays; analyses typically model additive Gaussian
noise and do not couple it to array geometry or motion, and
most works omit motion, solver, or CSI-estimation overheads
from the end-to-end budget [13]‚Äì[16]. Meanwhile, MA studies
demonstrate that repositioning elements can reshape channels,
but integration with FL/OTA objectives remains limited [17]‚Äì
arXiv:2506.00011v2  [eess.SP]  26 Oct 2025


--- Page 2 ---
2
[19]. Finally, recent efforts on federated fine-tuning of LLMs
focus on privacy and communication aspects and do not
jointly design OTA aggregation with MA geometry under tight
latency/energy and distribution shift [20], [21].
Contributions. Our main contributions are as follows.
‚Ä¢ We equip the server with a movable-antenna array and
reconfigure element positions and receive/transmit beam-
formers each round to reduce analog-sum mismatch and
shape post-combining noise under minimum-spacing con-
straints.
‚Ä¢ We jointly optimize the numbers of global rounds, client
participation, CPU frequencies, mini-batch sizes, MA
positions, and analog weights under latency and energy
limits.
‚Ä¢ We present a bound in which OTA noise enters explicitly,
and a Wasserstein term accounts for the shift from pre-
training to on-device data.
‚Ä¢ A successive convex approximation‚Äìpenalty dual decom-
position (SCA‚ÄìPDD) scheme updates continuous vari-
ables with convex surrogates, refines beamformers on
an oblique manifold, and repositions MA elements with
spacing-aware updates.
‚Ä¢ Under a line-of-sight channel model, we benchmark
against fixed-array OTA, digital FedAvg/OFDMA, Top-
K SNR, Gibbs sampling, and an MA-greedy heuristic,
and report model quality and participation fairness in
OpenLLaMA-v2 (3B) with LoRA and 4-bit quantization
over Alpaca and Dolly.
The remainder of this paper is organized as follows. Sec-
tion II reviews the state of the art in MA technology, federated
fine-tuning of LLMs, and OTA aggregation. Section III details
the overall system model, including the two-phase training
workflow, the MA architecture, and the associated latency
and energy framework. Section IV formulates a mixed integer
non-convex resource allocation problem that couples learning,
communication, and antenna geometry decisions. Section V
describes a hybrid SCA-PDD to solve this problem. Sec-
tion VI presents numerical results that validate the proposed
framework, and Section VII concludes the article. Table I
summarizes all notation.
II. RELATED WORK
In this section, we present a review of recent advances in
movable antenna technology, communication-efficient feder-
ated fine-tuning of large language models, and OTA gradient
aggregation, to establish the foundation for our proposed
framework.
A. Movable Antenna Technology
Recent advances in reconfigurable antenna architectures
have led to the concept of MAs, which allow the physi-
cal repositioning of antenna elements to adapt to channel
variations [22], [23]. Unlike traditional phased arrays, MAs
offer a new degree of freedom in geometry, allowing dynamic
adaptation to environmental changes such as user movement,
blockage, or interference. By continuously adjusting the an-
tenna position, orientation or structure within a predefined
TABLE I: Notation Table.
Symbol
Description
Œ±2, ÀÜŒ±2
Gradient-variance bounds (pre-/fine-tuning).
Œ≤u,t
Complex path gain for user u at time t.
Œµ(n)
OTA noise in round n.
C
FLOPs per sample.
dw
Dimension of model parameters.
f(n)
u
CPU frequency of user u in round n.
gu,t
Effective channel gain for user u.
Œ≥, ÀÜŒ≥
Step sizes (pre-/fine-tuning).
i, j
Indices of movable-antenna elements.
Œ∫0
CPU power coefficient.
Lpre, Lfine
Population losses (pre-training, fine-tuning).
Œª
Carrier wavelength.
m ‚àà{0, . . . , M ‚àí1}
Index for pre-training rounds (Phase I).
M ‚ààZ+
Number of pre-training rounds.
n ‚ààN = {0, . . . , N ‚àí1}
Index for fine-tuning rounds (Phase II).
N ‚ààZ+
Number of fine-tuning rounds.
NT
Number of movable-antenna elements.
‚àáÀúLpre, ‚àáÀúLfine
Stochastic gradients in each phase.
Pa
Max transmit power per user.
œÅ, ÀÜœÅ
Smoothness constants (pre-/fine-tuning).
œÅdist
Lipschitz constant w.r.t. data domain.
œÉ2
Noise variance for OTA aggregation.
t
Time index in the channel model.
u ‚ààU = {1, . . . , U}
Index of distributed users/nodes.
U
Total number of distributed users.
a(¬∑)
Array response function.
gu,t
Local gradient from user u at time t.
hu,t
Channel vector from user u at time t.
qt
Beamforming vector at the server (norm-1).
w(m)
Model parameters after m-th pre-training round.
w(M+n)
Model parameters after n fine-tuning rounds.
xn,i
2D location of i-th antenna in round n.
zA, zB
Continuous vs. discrete variables in SCA‚ÄìPDD.
‚àÜpre, ‚àÜfine
Variance-related overhead in each phase.
Œ∑t
Reception-scaling factor.
E(¬∑)
Total time and energy consumption functions.
L(¬∑)
Total time and energy consumption functions.
Lmax, Qmax
Total time and energy limits.
Un ‚äÜ{1, . . . , U}
User set in fine-tuning round n.
W (m), b(n)
u
Mini-batch size.
W(Ppre, Pfine)
Wasserstein distance for distribution shift.
surface or volume, MAs can achieve highly flexible spatial
configurations that enhance the robustness of the link in non-
stationary [24].
Previous research indicates that even millimeter-level ad-
justments in antenna position can significantly enhance line-
of-sight (LoS) connectivity, reduce multipath fading, and lower
interference in dense or dynamic wireless environments [22],
[25]. These gains are particularly relevant in high-frequency
systems, where propagation conditions change rapidly and
coverage is highly sensitive to geometry.
Moreover, the integration of MAs with intelligent reflecting
surfaces (IRSs) has been explored as a means of further
enhancing spatial diversity and signal delivery [26]. Such
combinations can maximize coverage, improve spatial multi-
plexing capabilities, and mitigate signal blockage in complex
wireless environments. Compared to traditional designs that
treat antenna positioning and beamforming as decoupled prob-
lems [26] joint optimization strategies that use MA mobility
have demonstrated improved communication reliability and
spectrum efficiency.
Together, MAs represent a paradigm shift from static ar-


--- Page 3 ---
3
ray configurations to geometry-aware, environment-adaptive
architectures. This makes them a promising foundation for
next-generation wireless systems, particularly in applications
such as federated learning or OTA aggregation, where spatial
robustness and transmission precision are critical [27].
B. Federated Fine-Tuning of Large Language Models
Although LLMs have shown impressive capabilities in
generating fluent and contextually coherent natural language
text across a wide range of tasks, effectively deploying these
models in real-world scenarios often requires fine-tuning tai-
lored to specific tasks or domains [28], [29]. This requirement
is particularly pronounced in vertical applications such as
healthcare, law, or engineering, where vocabulary, syntax,
and knowledge distributions differ substantially from those
found in general-purpose corpora, often resulting in degraded
performance without domain-specific adaptation.
Then, FL has emerged as a promising paradigm for ad-
dressing data privacy and governance challenges, especially
in scenarios involving sensitive or proprietary data [30]‚Äì[32].
In such settings, data remain on the local device and only
model updates are communicated, which preserves privacy and
ensures compliance with locality-aware data regulations.
However, iterative model synchronization introduces high
communication overhead, which poses a significant bottle-
neck, particularly for LLMs that comprise billions of param-
eters [33]. Limited uplink bandwidth, heterogeneous device
capabilities, and unreliable wireless channels further exac-
erbate the problem, potentially causing slow convergence,
degraded model quality, or even training divergence [34].
These challenges underscore the urgent need for scalable,
communication-efficient, and resource-adaptive approaches to
the federated fine-tuning of LLMs.
C. Over-the-Air Gradient Aggregation
OTA aggregation exploits waveform superposition in wire-
less channels to merge gradients from multiple devices in a
single uplink resource block [35]. This technique dramatically
reduces transmission overhead in FL but is vulnerable to
fading and interference. Existing work addresses these issues
through power control and beamforming [36], yet few studies
have examined the use of MAs to enhance OTA performance.
In contrast to the existing literature that addresses MAs,
federated LLM fine-tuning, and OTA aggregation separately,
our work unifies these three directions. Specifically, we show
how the geometries of MAs can be jointly optimized with
model training schedules and OTA updates, leading to im-
proved convergence under stringent time and energy budgets.
III. SYSTEM MODEL
We consider a two-phase learning workflow that blends (1)
centralized pre-training of an LLM on an edge server with
ample compute and storage, and (2) wireless federated fine-
tuning on U clients that hold domain-specific data but face
bandwidth and energy constraints as shown in Figure 1. OTA
gradient aggregation is used in the second phase, and the
server is equipped with a geometry‚Äìreconfigurable MA array
that improves signal superposition without increasing transmit
power [37].
A. Phase I: Centralized Pre-Training
Let w(m) ‚ààRdw denote the model parameters after the m-
th pre-training round, where m ‚àà{0, . . . , M‚àí1} and dw is the
dimension of the parameter vector. Define Dpre as the server‚Äôs
dataset, which consists of samples drawn from a distribution
D. The population loss for pre-training is then given by
Lpre
 w(m)
= Ed‚àºD
h
‚Ñì
 w(m), d
i
.
(1)
In practice, an empirical approximation of (1) is used via a
mini-batch B(m) ‚äÜDpre of size W (m). Denoting the empirical
loss over this mini-batch by
ÀúLpre
 w(m), B(m)
=
1
W (m)
X
d‚ààB(m)
‚Ñì
 w(m), d

.
(2)
Subsequently, the model is updated via a mini-batch stochastic
gradient descent (SGD) step as follows:
w(m+1) = w(m) ‚àíŒ≥ ‚àáw(m) ÀúLpre
 w(m), B(m)
,
(3)
where Œ≥ is the (constant) step size for Phase I and ‚àáÀúLpre
denotes the stochastic gradient with respect to w(m). After M
such rounds, the final pre-trained model is
w(M) ‚â°wpre-train.
(4)
B. Phase II: Task-Specific Fine-Tuning
After centralized pre-training, the model is refined over N
fine-tuning rounds, each indexed by n ‚ààN. Let w(M+n)
denote the parameters in round n. Suppose U distributed users
participate in the fine-tuning process, each holding data drawn
from a possibly shifted distribution. For a given user u ‚ààU,
define
Lu
 w(M+n), B(n)
u

= Ed ‚àºÀÜ
Pu
h
‚Ñì
 w(M+n), d
i
,
(5)
where B(n)
u
is the mini-batch for user u in the round n, and
ÀÜPu denotes the local data distribution. An aggregate loss over
all users is then
Lfine
 w(M+n)
=
1
U
U
X
u=1
Lu
 w(M+n), B(n)
u

,
(6)
where SU
u=1 B(n)
u
comprises the overall mini-batch in round n.
The stochastic gradient of the local loss for user u is
computed by summing the sample-wise derivatives over B(n)
u
(of size b(n)
u ). Specifically,
‚àáÀúL(n)
u
 w(M+n), B(n)
u

=
1
b(n)
u
X
di‚ààB(n)
u
√ó ‚àáw(M+n) ‚Ñì
 w(M+n), di

.
(7)
Then, the fine-tuning gradient can be formed by weighting
each user‚Äôs gradient according to its mini-batch size :
‚àáLfine
 w(M+n), {B(n)
u }

=
U
X
u=1
b(n)
u
PU
v=1 b(n)
v
√ó ‚àáL(n)
u
 w(M+n), B(n)
u

,
(8)


--- Page 4 ---
4
ùê∫ùëíùëõùëíùëüùëéùëô ùëëùëéùë°ùëé
Phase I: Centralized Pre-Training 
‚Ä¶
ÔÄ±
ÔÅÖ
ÔÄ≤
ÔÅÖ
ÔÅï
ÔÅÖ
Base Station
ùê∑ùëúùëöùëéùëñùëõ‚àíùë†ùëùùëíùëêùëñùëìùëñùëê ùëëùëéùë°ùëé 1
ùê∑ùëúùëöùëéùëñùëõ‚àíùë†ùëùùëíùëêùëñùëìùëñùëê ùëëùëéùë°ùëé2
ùê∑ùëúùëöùëéùëñùëõ‚àíùë†ùëùùëíùëêùëñùëìùëñùëê ùëëùëéùë°ùëéùëå
Phase II: Task-Specific Fine-Tuning
Device 1
Device 2
Device 3
‚Ä¶
gradient
gradient
model
model
ùê∑ùëîùëíùëõ
ùëÄùëñùëõùëñùëöùëñùëßùëíùêøùëùùëüùëí(ùúÉ)
Decisions (Phase I)
ùëä(ùëö): batch size
ùëì(ùëö) : server freq
Contributes to 
budgets
ùêøùëöùëéùë•: time
ùëÑùëöùëéùë•: energy
Outputs
ùúÉ0 (init weights)
tokenizer / vocab
ckpt id: ùëêùëòùëùùë°ùëö
LLM
ùë†ùëíùëôùëíùëêùë°ùëíùëëùë†ùëíùë°ùëàùëõùëàùëõ‚â§ùëàùëöùëéùë•
OTA 
aggregation
+ ùëõùëúùëñùë†ùëíùúé2
round n ‚Üí n+1 
(N rounds)
Hybrid 
SCA‚ÄìPDD 
scheduler
UL gradient
DL model
Selected client
global update
ùõ¥
ùë•ùëõ
q‚ÅΩ‚Åø‚Åæ
w‚ÅΩ‚Åø‚Åæ
‚â•ùëëùëöùëñùëõ
Fig. 1: Movable antenna enhanced federated fine-tuning framework for LLMs. Phase I (left) shows centralized pre-training
in which an edge server trains a foundation LLM on a large, general-purpose dataset. Phase II (right) depicts task-specific
fine-tuning.
where ‚àáL(n)
u
is the empirical gradient for user u in round n.
Finally, the parameters are updated by
w(M+n+1) = w(M+n) ‚àíÀÜŒ≥ ‚àáLfine
 w(M+n), {B(n)
u }

, (9)
where ÀÜŒ≥ is the step size in Phase II. At the end of N such
rounds, one obtains w(M+N) as the fine-tuned model specific
to the task.
C. Communication Model
In the communication part of our system, we optimize the
position of the MA element within the container to maximize
channel gain or improve the signal-to-noise ratio under vary-
ing channel conditions. Additionally, we design a selection
strategy to determine the optimal antenna position at each
transmission instance to enhance communication reliability,
and we also jointly optimize the beamforming vector in
coordination with the MA‚Äôs location.
The uplink transmission rate for user u in round n is then
given by
R(n),u
ul
= Bu
ul log2

1 + (q(n))Hhu
ul(x(n)) p(n)
u
Bu
ul N n
ul

,
(10)
where q(n) is the combine beamforming in the BS. hu
ul(x(n))
denote the uplink channel gain for user u in round n. Based on
the field response theory [38], the uplink light-of-sight (Los)
channel hu
ul(x(n)) is modeled as
hu
ul(x(n)) = Œ±(n),l
u
au(x(n)).
(11)
The parameter Œ±(n),l
u
represents the gain in the path of the
uplink channel. The vector x(n) = [x(n)
1 , ¬∑ ¬∑ ¬∑ , x(n)
Nt ]T denotes
the MA position of the BS, where Nt is the number of MA
for the BS. The vector au(x(n)) is the response vector for
the uplink channel array. According to the movable antenna
model, the array response vector is expressed as
au(x(n)) = [ej 2œÄ
Œª x(n)
1
cos(œïu), ¬∑ ¬∑ ¬∑ , ej 2œÄ
Œª x(n)
Nt cos(œïu)]T ,
(12)
where œïu is the angle of arrival (AoA) of the u-th user. Bu
ul is
the available uplink bandwidth and N (n)
ul
is the noise spectral
density. The downlink rate can be expressed as
R(n),dl
u
= Bdl log2

1 + hH
dl,u(x(n)) w(n) ÀúP
Bdl ÀúN (n)
dl

,
(13)
in which Bdl is the bandwidth and ÀúP, ÀúN (n)
dl
denote the server‚Äôs
transmit power and downlink noise density for user u in
round n, respectively. Similarly, based on the field response
theory [25], the downlink LoS channel hdl,u(x(n)) is
hdl,u(x(n)) = Œ≤(n)
u au(x(n)).
(14)
The term Œ≤(n)
u
represents the gains in the uplink and downlink
channels. The vector au(x(n)) denotes the response vector of
the downlink channel array. Based on the MA model presented
in [38], the array response vector is expressed as
au(x(n)) = [ej 2œÄ
Œª x(n)
1
sin(Œ∏u), ¬∑ ¬∑ ¬∑ , ej 2œÄ
Œª x(n)
Nt sin(Œ∏u)]T ,
(15)
where Œ∏u is the departure of angle (AoD) from the BS to
the u user. Both (10) and (13) follow standard Shannon-
capacity formulas under Gaussian noise. In each round, the
superposition of uplink transmissions underlies the aggregation
of the OTA gradient. Beamforming or MA configurations can
be used at the server to improve signal-to-noise ratios.
Let u ‚ààU and n ‚ààN index users and fine-tuning rounds,
respectively. Let p(n)
u
denote the transmit power of user u
during the round n. The average and instantaneous power
constraints for each user become
1
N
N‚àí1
X
n=0
p(n)
u
‚â§pave
u ,
‚àÄu ‚ààU,
(16)


--- Page 5 ---
5
0 ‚â§p(n)
u
‚â§Pa,
‚àÄn ‚ààN,
‚àÄu ‚ààU,
(17)
where pave
u
is the average transmit power budget and Pa is the
maximum transmit power allowed per user.
D. Training Latency
The end-to-end training delay equals the sum of two
components: (i) server-side pre-training latency, the purely
computational time for the edge server to process M mini-
batches of size W (m) at frequencies f (m); and (ii) client-side
fine-tuning latency, dominated each round by the slowest user,
which combines downlink reception of the global model, local
SGD on a batch of size b(n)
u
at frequency f (n)
u
, and uplink
transmission of the resulting gradient. Specifically, during
Phase I, the total pre-training latency is
Lpre

M,

W (m)	
,

f (m)	
=
M‚àí1
X
m=0
W (m) C
f (m) c ,
(18)
where W (m) denotes the mini-batch size in the m-th pre-
training round, f (m) is the server‚Äôs CPU frequency, and C is
the number of FLOPs per sample. The constant c represents
additional overhead or cycle accuracy factors.
In Phase II, each user u ‚ààU trains locally on a mini-
batch of size b(n)
u
using the CPU frequency f (n)
u
. The local
computation latency at round n is
L(n),t
u
 b(n)
u

=
b(n)
u
C
f (n)
u
cu
,
(19)
where cu can be viewed as a user-specific overhead factor.
In addition to local training, each user also incurs uplink and
downlink latency for data transfer. Denoting respectively by
L(n),d
u
and L(n),u
u
(p(n)
u ) the one-way latencies associated with
downlink and uplink transmission, the overall training latency
for the two-stage system becomes
ÀúL

M, N, {W (m)}, {f (m)},

b(n)
u
	
,

f (n)
u
	
,

p(n)
u
	
,

x(n)	
,

q(n)	
,

w(n)	
= Lpre

M, {W (m)}, {f (m)}

+
N‚àí1
X
n=0
max
u‚ààU
h
L(n),d
u
+ L(n),t
u
 b(n)
u

+ L(n),u
u
 p(n)
u
i
=
M‚àí1
X
m=0
W (m) C
f (m) c
+
N‚àí1
X
n=0
max
u‚ààU

Œ≤
R(n),dl
u
+ b(n)
u
C
f (n)
u
cu
+
Œ≤
R(n),ul
u
 p(n)
u


,
(20)
where Œ≤ is the payload size (in bits) for transmitting model
updates, R(n),dl
u
and R(n),ul
u
 p(n)
u

represent the respective
downlink and uplink transmission rates (as in Section III-C),
and p(n)
u
is the user‚Äôs transmit power at round n.
IV. JOINT RESOURCE-ALLOCATION PROBLEM
FORMATION
We now present the unified optimization problem that
underpins our proposed two-phase, wirelessly aware LLM
training framework. The goal is to jointly allocate training
resources, communication strategies, and physical-layer pa-
rameters in order to achieve efficient and accurate model
convergence under realistic system constraints.
Let M and N denote the number of global rounds assigned
to Phase I (centralized pre-training) and Phase II (federated
fine-tuning), respectively. During Phase I, the server selects
a mini-batch size W (m) and CPU frequency f (m) in each
round m = 0, 1, . . . , M‚àí1. Similarly, in Phase II, each user
u ‚ààU selects a local mini-batch size b(n)
u
and a computation
frequency f (n)
u
for each round n = 0, 1, . . . , N‚àí1.
Then, we employ a reconfigurable MA array at the server.
In round n, the i-th antenna element is located at a spatial
coordinate xn,i ‚ààR2, and the receive beamforming vector is
q(n) ‚ààCNT , constrained to a unit norm. The set of users
participating in the round n is indicated by Un ‚äÜU.
Thus, we denote by Œ®(¬∑) the overall training objective,
which aims to minimize the loss of fine-tuning of the LLM
under time and energy constraints. Key constraints include:
‚Ä¢ Time and Energy: L(M, N, . . . ) and Q(M, N, . . . )
represent the total training time and energy usage in
both phases, respectively. The detailed expression of the
function can be found in [36]. Each is limited by a
practical budget, for example, Lmax, Qmax.
‚Ä¢ Antenna Spacing: A minimum gap v > 0 ensures
‚à•xn,i ‚àíxn,j‚à•‚â•v for all i, j, preventing interference
and coupling.
‚Ä¢ Beamforming Norm: ‚à•q(n)‚à•= 1 for each round n.
‚Ä¢ User Capacity: |Un| ‚â§Umax imposes a limit on how
many users can be scheduled in each round.
In summary, combining these components, we formulate
the joint optimization problem P1 (shown in problem 21).
This problem integrates decisions between layers that span
the geometry of the physical antenna, scheduling, and hy-
perparameters of machine learning. Because the selection of
Un directly influences the beamformer q(n), and thus energy
consumption, latency, and convergence speed, P1 is naturally
non-convex with integer and combinatorial aspects. Given
its high dimensionality and the heterogeneous nature of its
variables, we adopt an alternating optimization approach. This
strategy partitions the problem into manageable subproblems
dedicated to individual ‚Äúlayers‚Äù.
(P1) :
min
M, N‚ààZ+
{W (m), f (m)}, {b(n)
u
},{f (n)
u
}
{x(n)}, {q(n)}, {w(n)}, {Un}
Œ®

M, N, {W (m)}, {b(n)
u }

(21)
s.t.
L

M, N, {W (m)}, {f (m)},

b(n)
u
	
,

f (n)
u
	
,

p(n)
u
	
,

x(n)	
,

q(n)	
,

w(n)	
‚â§Lmax,
(P1a)
Q

M, N,

W (m)	
,

f (m)	
,

b(n)
u
	
,

f (n)
u
	
,

p(n)
u
	
,

x(n)	
,

q(n)	
,

w(n)	
‚â§Qmax,
(P1b)
‚à•x(n)
n1 ‚àíx(n)
n2 ‚à•‚â•v,
‚àÄn1, n2 ‚ààN,
(P1c)


--- Page 6 ---
6
‚à•q(n)‚à•= 1,
‚àÄn,
(P1d)
‚à•w(n)‚à•= 1,
‚àÄn,
(P1e)
Un ‚äÜU,
|Un| ‚â§Umax,
‚àÄn.
(P1f)
V. HYBRID SCA‚ÄìPDD ALGORITHM
To address the above problem, we propose a hybrid SCA-
PDD algorithm as shown in Algorithm 1. At the outer level,
we enumerate every feasible integer pair (M, N) that satisfies
the overall latency-energy envelope. For each such pair, an
inner loop alternates between two blocks: (i) an SCA step that
linearizes and optimizes smooth continuous variables and (ii)
a PDD step that resolves the discrete user selection decisions
and the geometry constraints of the MA array. The two blocks
iterate until the joint objective converges, after which the best
solution among all the enumerated pairs (M, N) is retained
as the final allocation of resources.
A. Enumerating (M, N)
Because M and N are integers and typically have an upper
bound in practice, we can scan all pairs
 M, N

in a discrete
set. For each pair, we fix M and N in problem P1 and solve
the resulting continuous/discrete optimization in the remaining
variables. Among all enumerated pairs, we select the one that
yields the best objective Œ®(¬∑).
B. Partitioning Variables for SCA vs. PDD
Let z =
n
W (m), f (m), b(n)
u , f (n)
u
, x(n), q(n), w(n), Un
o
.
Then,
we
split
z
into
two
blocks:
zA
(SCA block)
and
zB
(PDD block). In particular:
‚Ä¢ zA might include continuous variables that enter the
objective or constraints in a smooth but non-convex
manner (e.g. functions 1/W (m) and Œ∫0(f (m))3).
‚Ä¢ zB contains discrete/user-selection decisions {Un}, MA
geometry {xn,i} subject to minimum spacing constraints,
and beamforming vectors {q(n)} with ‚à•q(n)‚à•= 1. These
typically require specialized handling.
a) Iterative Procedure:
1) Block A: SCA Step. Fix the current values of zB (user
selections, antenna coordinates, beamforming). Then
linearize each non-convex but differentiable term in zA
around the old iterate, leading to a convex approxima-
tion. Solve this convex subproblem to update zA.
2) Block B: PDD Step. Fix the updated zA. Handle
discrete variables (Un) and geometry constraints (e.g.
‚à•xn,i ‚àíxn,j‚à•‚â•v) using a partial Lagrangian or penalty
approach. Update the dual multipliers for time/energy
constraints and other global coupling constraints.
This two-block iteration repeats until convergence (e.g.,
changes in z fall below a tolerance). Because (M, N) are
fixed in each run, these steps address only the continuous and
discrete variables in zA, zB.
Algorithm 1 Hybrid SCA‚ÄìPDD Algorithm.
1: Input: Candidate training rounds M, N; constraints
Lmax, Qmax; tolerances œµ, Œ¥; max iterations Tmax
2: Initialize: Best objective Œ®‚àó‚Üê‚àû; optimal solution z‚àó‚Üê
‚àÖ
3: for each (M, N) ‚ààM√óN do, all optimization variables
are partitioned into two sub-blocks.
4:
Initialize z(0)
A = {W (m), f (m), b(n)
u , f (n)
u
}
5:
Initialize z(0)
B = {x(n), q(n), w(n), Un}
6:
for t = 1 to Tmax do
7:
Step 1: SCA Update of Continuous Variables
zA
8:
for all m = 0, . . . , M‚àí1 do
9:
Approximate
1/f (m),
(f (m))3
from
latency/energy in Eq. (25), Eq. (34)
10:
end for
11:
for all n = 0, . . . , N‚àí1, u ‚ààU do
12:
Linearize 1/f (n)
u
, (f (n)
u
)2 and 1/b(n)
u
from
Eq. (26), Eq. (35)
13:
end for
14:
Solve convex surrogate program for z(t)
A
under
constraints:
‚Ä¢
ÀúL(¬∑) ‚â§Lmax (Eq. (25))
‚Ä¢
ÀúQ(¬∑) ‚â§Qmax (Eq. (34))
‚Ä¢ Bounds: f (m) ‚àà[fmin, fmax], b(n)
u
‚àà[bmin, bmax]
‚Ä¢ Optional: trust region ‚à•z(t)
A ‚àíz(t‚àí1)
A
‚à•‚â§Œ¥
15:
Step 2: PDD Update of Geometry Variables zB
16:
Fix z(t)
A , and repeat the following until conver-
gence:
17:
(a) Auxiliary Variables: Solve convex problem
for t1, t2, gul
u , gdl
u (Eq. (29)‚Äì(31))
18:
(b) Unit-Modulus Projection:
19:
Solve for Œ∏ul
u , Œ∏dl
u s.t. |Œ∏i| = 1 (Eq. (32)‚Äì(33))
using [39]
20:
(c)
Beamforming:
Optimize
q(n), w(n)
(Eq. (31)) via oblique manifold solver [40]
21:
(d) MA Positioning:
22:
Solve:
min
x(n)
X
u
‚à•‚à†Œ∏u ‚àí‚à†au(x(n))‚à•2
subject to spacing: ‚à•xi ‚àíxj‚à•‚â•v using SCA
(Eq. (37)‚Äì(39))
23:
(e) Penalty Update: If spacing or rate con-
straints violated, update dual variables
24:
if ‚à•z(t) ‚àíz(t‚àí1)‚à•< œµ then
25:
break
26:
end if
27:
end for
28:
if Œ®(M, N) < Œ®‚àóthen
29:
Update Œ®‚àó‚ÜêŒ®(M, N) and store solution z‚àó
30:
end if
31: end for
32: Return: Optimal (M ‚àó, N ‚àó, z‚àó
A, z‚àó
B)


--- Page 7 ---
7
Block A: SCA Details: Any non-convex function in zA
that is differentiable can be replaced by a first-order Taylor
approximation around the previous iteration. For example:
1
W (m) ‚âà
1
W (m)
old
‚àíW (m) ‚àíW (m)
old
 W (m)
old
2
.
(22)
Similarly, Œ∫0(f (m))3 is linearized around f (m)
old . Substituting
these linear approximations into P1 yields a convex subprob-
lem solvable by standard methods.
1) Block B: PDD Details: In this block, we optimize the
transmit beamforming w(n), the receive beamforming q(n),
and the MA position of the base station x(n). First, we
introduce the auxiliary variables t1,u and t2,u. Based on the
relaxation method, we have the following formulations
Œ≤
Bdl log2(1 +
hH
dl,u(x(n))w(n) Àú
P
Bdl Àú
N (n)
dl,u
)
‚â§t1,
(23)
Œ≤
Bu
ul log2(1 + (q(n))Hhu
ul(x(n))p(n)
u
Bu
ulN n
ul
)
‚â§t2.
(24)
The two terms (q(n))Hhu
ul(x(n)) and hu
dl,u(x(n))w(n) exhibit
a complex interdependency. Moreover, the channel model, as
presented in equations (11) and (14), can be reformulated as
(q(n))Hhu
ul(x(n)) = Œ±(n),l
u
(q(n))Haul
u (x(n)),
hH
dl,u(x(n))w(n) = (Œ≤(n)
u )H(adl
u (x(n)))Hw(n).
(25)
Since Œ±(n),l
u
and Œ≤(n)
u
are known, and the receive beamforming
vector q(n) is coupled with the receive array response vector
aul
u (x(n)), while the transmit beamforming vector w(n) is cou-
pled with adl
u (x(n)), we introduce auxiliary variables g(n),ul
u
and g(n),dl
u
to decouple the system, and the channel can be
reformulated using substituted variables
g(n),ul
u
= (q(n))Haul
u (x(n)),
g(n),dl
u
= (adl
u (x(n)))Hw(n).
(26)
Due to the coupling of antenna position variables in the array
response vectors aul
u (x(n)) and adl
u (x(n)), and the fact that
both of these response vectors satisfy a constant modulus
constraint, we introduce auxiliary variables Œ∏ul
u = aul
u (x(n))
and Œ∏dl
u = adl
u (x(n)), which also satisfy the constant mod-
ulus constraint. Consequently, we impose the following new
constraints
Œ∏ul
u = aul
u (x(n)), |Œ∏ul
u (i)| = 1,
Œ∏dl
u = adl
u (x(n)), |Œ∏dl
u (i)| = 1.
(27)
By introducing the auxiliary variables and constraints, Problem
A can be rewritten as follows.
min
Œ∏ul
u ,Œ∏dl
u ,t1,t2,g(n),ul
u
,
g(n),dl
u
,x(n),q(n),w(n)
Œ®(M, N, {W (m)}, {b(n)
u })
(28a)
s.t.
M‚àí1
X
m=0
W (m)C
f (m)c +
N‚àí1
X
n=0
(t1 + t2+
max
k‚ààK( b(n)
u C
ÀÜf (n)
u
cu
)) ‚â§ÀúL0,
(28b)
M‚àí1
X
m=0
Œ∑ W (m)C
c
œï[f (m)]2 +
N‚àí1
X
n=0
ÀúPt1+
N‚àí1
X
n=0
U
X
u=1
(Q(n),t
u
(b(n)
u , f (n)
u
) + p(n)
u t2) ‚â§ÀúE0,
(28c)
Œ∏ul
u = aul
u (x(n)), |Œ∏ul
u (i)| = 1,
(28d)
Œ∏dl
u = adl
u (x(n)), |Œ∏dl
u (i)| = 1,
(28e)
Œ≤
Bdl log2(1 + g(n),dl
u
(Œ≤(n)
u
)H Àú
P
Bdl Àú
N(n)
dl,u
)
‚â§t1,
(28f)
Œ≤
Bu
ul log2(1 + g(n),ul
u
Œ±(n),l
u
p(n)
u
Bu
ulN n
ul
)
‚â§t2,
(28g)
g(n),ul
u
= (q(n))HŒ∏ul
u ,
(28h)
g(n),dl
u
= (Œ∏dl
u )Hw(n).
(28i)
Therefore,
in
this
section,
the
optimization
variables
{Œ∏ul
u ,Œ∏dl
u ,t1,t2,g(n),ul
u
,g(n),dl
u
,x(n),q(n),w(n)} can be divided
into four sub-problems. The first sub-problem involves the
variables {t1, t2, g(n),ul
u
, g(n),dl
u
}, the second sub-problem in-
volves the variables {Œ∏ul
u , Œ∏dl
u }, the third sub-problem involves
the variables {q(n), w(n)}, and the fourth sub-problem in-
volves the variable {x(n)}. Next, we provide details on how
to solve these four subproblems.
The first sub-problem over {t1, t2, g(n),ul
u
, g(n),dl
u
}: Prob-
lem B is convex with respect to the four auxiliary variables,
and thus we can use CVX to solve the first subproblem.
The second sub-problem over {Œ∏ul
u , Œ∏dl
u }: The optimiza-
tion problem involving the constraints on variables Œ∏ul
u and
Œ∏dl
u can be reformulated as follows:
min
q(n)
d,k,qu
k
U
X
u=1
|g(n),ul
u
‚àí(q(n))HŒ∏ul
u |2 + |g(n),dl
u
‚àí(Œ∏dl
u )Hw(n)|2
+ ‚à•Œ∏ul
u ‚àíaul
u (x(n))‚à•2 + ‚à•Œ∏dl
u ‚àíadl
u (x(n))‚à•2,
(29a)
s.t. |Œ∏ul
u (i)| = 1,
(29b)
|Œ∏dl
u (i)| = 1.
(29c)
Due to non-convex constraints ‚à•q(n)
d,k‚à•= 1 and ‚à•qu,n
k
‚à•= 1,
solving this problem is challenging. However, the algorithm
proposed in [39], one iteration block coordinate descent type
algorithm, can address the above non-convex problem. The
details of this algorithm are omitted here.
The third sub-problem over {w(n), q(n)}: The optimiza-
tion problem involving the constraints on variables w(n) and
q(n) can be reformulated as follows:
min
q(n)
d,k,qu
k
U
X
u=1

|g(n),ul
u
‚àí(q(n))HŒ∏ul
u |2
+ |g(n),dl
u
‚àí(Œ∏dl
u )Hw(n)|2
(30a)
s.t.
‚à•w(n)‚à•2 = 1,
(30b)


--- Page 8 ---
8
‚à•q(n)‚à•2 = 1.
(30c)
Because non-convex constraints ‚à•w(n)‚à•2 = 1 and ‚à•q(n)‚à•2 =
1, solving this problem is challenging. However, the algorithm
proposed in [40], an oblique manifold algorithm, can address
the above non-convex problem. The details of the oblique
manifold algorithm can be found in [40].
The fourth sub-problem over {x(n)}: From the pre-
vious steps, we can determine the values of the auxiliary
variables Œ∏ul
u
and Œ∏dl
u . To satisfy the equality constraints
Œ∏ul
u = aul
u (x(n)) and Œ∏dl
u = adl
u (x(n)), we have
min
x(n)
U
X
u=1
‚à•‚à†Œ∏ul
u ‚àí‚à†aul
u (x(n))‚à•2 + ‚à•‚à†Œ∏dl
u ‚àí‚à†adl
u (x(n))‚à•2
(31a)
‚à•x(n)
n1 ‚àíx(n)
n2 ‚à•‚â•v.
(31b)
To solve for the MA position, we further reformulate the
problem using matrix norm operations as follows
min
x(n)
U
X
u=1
Nt
X
n1=1

|‚à†Œ∏ul
u (n1) ‚àíx(n)
n1 cos(œïu)|2
+ |‚à†Œ∏ul
u (n1) ‚àíx(n)
n1 sin(Œ∏u)|2
(32a)
|x(n)
n1 ‚àíx(n)
n2 | ‚â•v.
(32b)
We assume that x(n)
n2 is the initial MA position. Next, we apply
the SCA algorithm to solve for x(n)
n1 . Using the SCA algorithm,
the constraint |x(n)
n1 ‚àíx(n)
n2 | ‚â•v can be transformed into
q
(x(n)
n1 ‚àíx(n)
n2 )2 + x(n)
n1 ‚àíx(n)
n2
|x(n)
n1 ‚àíx(n)
n2 |
(x(n)
n1 ‚àíx(n)
n2 ) ‚â•v.
(33)
The problem (37) is then reformulated as
min
x(n)
U
X
u=1
Nt
X
n1=1

|‚à†Œ∏ul
u (n1) ‚àíx(n)
n1 cos(œïu)|2
+ |‚à†Œ∏ul
u (n1) ‚àíx(n)
n1 sin(Œ∏u)|2
(34a)
q
(x(n)
n1 ‚àíx(n)
n2 )2 + x(n)
n1 ‚àíx(n)
n2
|x(n)
n1 ‚àíx(n)
n2 |
(x(n)
n1 ‚àíx(n)
n2 )
‚â•v.
(34b)
Finally, we observe that the problem with respect to the MA
position x(n)
n,1 is convex. Therefore, we apply CVX to solve
the aforementioned problem. The complexity and convergence
analysis are in Appendix A and Appendix B.
VI. NUMERICAL RESULTS
This section presents a detailed numerical study that is
tailored to instruction-tuning benchmarks. Unless otherwise
noted, we average results over ten independent runs of the
wireless channel, with shaded areas in the figures indicating
standard deviations.
A. Experiment Setup
Experiment Settings. All experiments are conducted on a
server with Ubuntu 22.04, Python 3.12, CUDA 12.8 and
PyTorch 2.8.0. The hardware consists of one NVIDIA L20
GPU (48 GB VRAM), an Intel Xeon Platinum 8457C CPUs
(20 vCPUs), 100 GB system memory and a 500 GB disk.
In the federated fine-tuning simulation, we emulate 10 clients
using the Flower framework [41]. On the wireless side, we
use a Rician channel with carrier frequency fc = 28 GHz
and bandwidth B = 20 MHz (K-factor = 8 dB, number
of paths = 3, PLOS = 0.8, blockage probability = 0.03,
shadowing standard deviation = 4 dB, user speed = 0.2 m/s).
The transmit-power limit is Pmax = 0.2 W, and the noise
power spectral density is N0 = ‚àí174 dBm/Hz. Each client
link is equipped with a 16-element reconfigurable antenna. We
set fraction-fit=1.0.
Model Configuration. We adopt the 3B-parameter Open-
LLaMA v2 model [42], applying 4-bit quantization via
bitsandbytes (v0.45.4) [43] and LoRA (peft) [44] for
parameter-efficient fine-tuning (LoRA rank = 32, Œ± = 64,
dropout = 0.075). To reduce GPU memory, we enable gradient
checkpointing. We use HuggingFace‚Äôs SFTTrainer; the
maximum sequence length is 512 and the learning rate is
5 √ó 10‚àí5.
B. Baselines and Metrics
Baselines. We compare five schedulers :
Digital FedAvg (OFDMA). Orthogonal uplink with (as-
sumed) error-free digital aggregation; all selected clients up-
load over orthogonal resource blocks (RBs).
TopK-SNR. Each round selects the k clients with the highest
instantaneous post-combining SNR at the BS; uplink aggrega-
tion is digital.
Gibbs. Probabilistic client selection: sample k clients with
probability proportional to normalized link quality (no power
control); aggregation is digital.
OTA No-PC. Analog over-the-air (AirComp) aggregation
with a fixed BS array and no per-user power control; k clients
are superposed each round. When k=U (all clients), this
recovers the commonly used ‚ÄúSelect-All‚Äù variant.
MA (Greedy). Same OTA setting as above, but the BS mov-
able/reconfigurable array geometry and receive beamformer
are greedily updated each round; the client set follows TopK-
SNR.
Metrics. We report four metrics to capture fairness, inequality,
model quality, and radio link as follows.
Fairness. Fairness is measured by the Jain index over per-
client participation shares xu :
J =
  PU
u=1 xu
2
U PU
u=1 x2u
,
J ‚àà(0, 1].
(35)
J = 1 indicates perfectly equal participation; lower values
imply greater inequality.
Inequality. Inequality is measured by the Gini coefficient
over per-client participation shares xu:
G =
PU
u=1
PU
v=1|xu ‚àíxv|
2U PU
u=1 xu
,
G ‚àà[0, 1).
(36)


--- Page 9 ---
9
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Jain Index
(a) Alpaca Dataset (K=1)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Jain Index
(b) Alpaca Dataset (K=2)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Jain Index
(c) Alpaca Dataset (K=4)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Jain Index
(d) Alpaca Dataset (K=8)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Jain Index
(e) Dolly Dataset (K=1)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Jain Index
(f) Dolly Dataset (K=2)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Jain Index
(g) Dolly Dataset (K=4)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Jain Index
(h) Dolly Dataset (K=8)
Digital FedAvg
TopK-SNR
Gibbs
MA (Greedy)
OTA No-PC
SCA-PDD
Fig. 2: Jain Index comparison across different learning methods on Alpaca and Dolly datasets. (a)-(d) show results for Alpaca
dataset with K=1,2,4,8 clients per round, while (e)-(h) show corresponding results for Dolly dataset. Shaded regions represent
method-specific variations to distinguish overlapping performance curves.
Lower G indicates more equal participation and complements
the Jain index.
Model quality. The quality of the model at the R30 horizon
is reported as perplexity
PPL(R30) = exp
 ‚Ñì(Œ∏R30)

,
(37)
where ‚Ñìis the average validation NLL per token (use 2‚Ñìif
NLL is in bits). Lower PPL implies a better predictive fit /
faster convergence by R30.
Link quality and efficiency. We report the average post-
combining SNR at the BS in dB:
Avg SNR(dB) =
1
NR30
NR30
X
n=1
10 log10
 SNR(n)
.
(38)
Higher is generally better; under analog OTA aggregation, it
must be read alongside the analogue-sum mismatch.
C. Alpaca Experiments
The ALPACA corpus (52 k instruction‚Äìresponse pairs) [45]
is evenly sharded into ten non-overlapping subsets of ‚âà5,200
samples.
1) Fairness: SCA‚ÄìPDD achieves the highest Jain index
at all concurrency levels k as shown in Fig. 2 (a)-(d). At
k=1 the index is 0.789 versus 0.285 for the best baseline
(Gibbs), an absolute gain of 0.504; at k=2 it is 0.905 versus
0.449, a gain of 0.456. With larger concurrency, fairness
rises for all methods because more clients are active per
round, yet SCA‚ÄìPDD remains ahead: 0.969 versus 0.774
at k=4 (gain 0.195) and 0.985 versus 0.972 at k=8 (gain
0.013). These outcomes reflect that SNR-centric schedulers
tend to concentrate airtime on a few strong links, whereas
SCA‚ÄìPDD couples client selection with beamforming and
movable antenna geometry to keep the analog superposition
well aligned while rotating participation, thereby broadening
inclusion without compromising OTA stability, especially at
small k where fairness is most challenging.
2) Inequality: The Gini coefficient corroborates the fairness
gains and highlights how participation concentrates in the tail
as illustrated in Fig. 3 (a)-(d). With k=1, SCA‚ÄìPDD attains
0.287 compared to 0.640 for the best baseline (Gibbs), an
absolute decrease of 0.353 (55.2%). At k=2, the coefficient
falls to 0.177 versus 0.531 (decrease 0.354; 66.7%). The
advantage persists at k=4 with 0.100 versus 0.287 (decrease
0.187; 65.2%) and remains visible at k=8 with 0.069 versus
0.092 (decrease 0.023; 25.0%). The largest reductions occur at
small k, where SNR-driven policies most strongly concentrate
airtime. By rotating clients while adapting beamforming and
movable antenna geometry to maintain a well-aligned analog
superposition, SCA‚ÄìPDD shrinks the participation tail, weak
links appear more often without destabilizing aggregation,
consistent with the scheduling constraint in (P1f).
3) Model quality: In a fixed round budget, the clearest
gains appear in small‚Äìmoderate concurrency (Fig. 4). For k=1,
the perplexity is 2.94 compared to 3.56 for the best baseline
(Digital), an absolute reduction of 0.62 (17.4%). For k=2, the
result is 3.03 versus 3.53, a reduction of 0.50 (14.2%). These
improvements coincide with the strongest fairness gains and
are consistent with the analysis that the analog-sum mismatch
term, rather than SNR alone, dominates learning quality when
a few clients superpose.
When concurrency grows, alignment becomes intrinsically


--- Page 10 ---
10
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Gini Coefficient
(a) Alpaca Dataset (K=1)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Gini Coefficient
(b) Alpaca Dataset (K=2)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Gini Coefficient
(c) Alpaca Dataset (K=4)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Gini Coefficient
(d) Alpaca Dataset (K=8)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Gini Coefficient
(e) Dolly Dataset (K=1)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Gini Coefficient
(f) Dolly Dataset (K=2)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Gini Coefficient
(g) Dolly Dataset (K=4)
5
10
15
20
25
30
Round
0.0
0.2
0.4
0.6
0.8
1.0
Gini Coefficient
(h) Dolly Dataset (K=8)
Digital FedAvg
TopK-SNR
Gibbs
MA (Greedy)
OTA No-PC
SCA-PDD
Fig. 3: Gini coefficient evolution across different learning methods over 30 training rounds. Subplots (a)-(d) show results on
Alpaca dataset and (e)-(h) on Dolly dataset with K=1,2,4,8 clients selected per round. Shaded regions represent method-specific
variations for visual distinction.
Digital FedAvg
TopK-SNR
Gibbs
MA (Greedy)
OTA No-PC
SCA-PDD
Methods
4
6
8
10
Validation Perplexity (PPL)
4.53
3.73
3.84
3.73
3.73
3.06
10.81
7.25
6.92
6.93
6.92
6.13
PPL Performance Comparison
Alpaca
Dolly
Fig. 4: PPL performance comparison across different learning
methods on Alpaca and Dolly datasets at round 30.
harder. At k=4, SCA‚ÄìPDD attains 3.15 versus 3.12 (Gibbs), a
difference of 0.03 (0.96%), while requiring substantially less
energy up to R30 (252 J versus 364 J; 30.8% reduction), indi-
cating a stronger quality‚Äìenergy trade-off. At k=8, perplexity
is 3.97 versus 3.17 for the best baseline, reflecting the diffi-
culty of perfectly aligning many simultaneous transmissions.
Overall, the results point to small‚Äìmoderate k as a practical
operating region where geometry-aware scheduling most ef-
fectively translates into better fixed-budget model quality.
4) Link quality and efficiency: Average SNR summarizes
radio conditions but does not by itself predict learning
outcomes under analog aggregation (Fig. 5). At k=1, the
highest-SNR baseline (OTA No-PC) reports 24.2 dB, yet its
perplexity is worse than SCA‚ÄìPDD, which operates at 21.7 dB.
Fairness
(Jain Index)
Performance
(1/PPL√ó10)
Signal Quality
(SNR/30)
Energy Efficiency
(1/Energy√ó5)
Time Efficiency
(1/Time√ó100)
0.2
0.4
0.6
0.8
1.0
(a) Alpaca Dataset
Digital FedAvg
TopK-SNR
Gibbs
MA (Greedy)
OTA No-PC
SCA-PDD
Fig. 5: Performance comparison of different learning methods
on Alpaca dataset.
At k=2, the contrast is stronger: 28.5 dB (OTA No-PC) versus
19.7 dB (SCA‚ÄìPDD), while perplexity still favors SCA‚ÄìPDD
(3.03 vs. 3.53). Even at k=4, SCA‚ÄìPDD achieves competitive
perplexity at a lower average SNR (16.3 dB) than TopK/Gibbs
(18.7 dB).
D. Dolly Experiments
We evaluate on DOLLY 15k [46] under the same commu-
nication and training budgets as in Sec. VI-C. Ten clients
each hold a disjoint shard. We vary the per‚Äìround concurrency
k ‚àà{1, 2, 4, 8} and report all metrics at the R30 horizon.
1) Fairness: Fairness is most difficult when few clients
superpose per round as shown in Fig. 2 (e)-(h). In this regime,


--- Page 11 ---
11
SCA-PDD substantially widens participation: at k=1 the Jain
index is 0.789 versus 0.277 for the strongest comparator
(Gibbs), an absolute gain of 0.512 (relative 184.8%). At k=2
the index reaches 0.904 versus 0.441 (gain 0.463, 105.0%).
As concurrency increases, all methods approach the fairness
ceiling simply because more clients are active each round, but
SCA‚ÄìPDD remains competitive: 0.970 versus 0.774 in k=4
(gain 0.196, 25.3%) and 0.985 in k=8, within ‚âà0.2% of the
highest value (0.987 for MA Greedy). These results indicate
that geometry‚Äìaware scheduling counters the tendency of
SNR‚Äìcentric heuristics to concentrate airtime on a handful of
strong links, particularly where fairness is hardest (small k).
2) Inequality: The inequality view mirrors the fairness
gains and clarifies tail behavior in Fig. 3 (e)-(h). At k=1,
Gini falls to 0.286 from 0.666 (Gibbs), a reduction of 0.380
(57.1%). At k=2 it drops to 0.176 from 0.537 (0.361, 67.2%).
At k=4, SCA‚ÄìPDD attains 0.100 versus 0.286 (0.186, 65.0%).
At k=8, the methods converge towards uniformly high partic-
ipation; SCA‚ÄìPDD records 0.069 while the lowest baseline
is 0.064 (MA Greedy). In effect, coupling client rotation with
beamforming and MA geometry ‚Äúcompresses the tail‚Äù: weaker
links appear more frequently without destabilizing analog
aggregation.
3) Model quality: Quality improvements at a fixed round
budget are most pronounced at small‚Äìmoderate concurrency
(Fig. 4). At k=1, perplexity is 4.62 compared with 10.12
for the strongest comparator, an absolute reduction of 5.50
(54.3%). At k=2, PPL is 5.10 versus 5.85 (MA Greedy), a
reduction of 0.75 (12.8%). For k=4, SCA‚ÄìPDD is within 0.15
of the best value (5.29 vs. 5.14 for Gibbs, 2.9% difference),
while simultaneously delivering substantially higher fairness
(Jain 0.970 vs. 0.764‚Äì0.774) and lower inequality (Gini 0.100
vs. 0.286‚Äì0.297). At k = 8, Digital FedAvg achieves the
lowest PPL (4.75), reflecting the absence of analog mismatch;
SCA‚ÄìPDD reports 5.16 with nearly saturated fairness. In
general, the data suggest a practical operating region in
k=1‚Äì2, where minimizing the analog mismatch translates
more effectively into better fixed‚Äìbudget model quality.
4) Link quality and efficiency: Average post‚Äìcombining
SNR is informative about RF conditions but does not by
itself predict learning under analog aggregation (Fig. 6). At
k=1, SCA‚ÄìPDD operates at 21.8 dB while the highest‚ÄìSNR
comparator reaches 24.3 dB, yet SCA‚ÄìPDD more than halves
the perplexity. At k=2, the SNR gap widens (19.7 dB vs.
28.6 dB), with SCA‚ÄìPDD still attaining a lower PPL. Even
at k=4, where SCA‚ÄìPDD‚Äôs SNR is slightly higher (16.3 dB
vs. 15.6‚Äì15.7 dB), the best baseline keeps a small PPL edge.
This behavior is consistent with the analysis in Sec. B: the
effective learning signal depends on both noise and the vector
mismatch between the received analog sum and the desired
weighted gradient. Maximizing SNR alone is therefore not a
reliable proxy for downstream quality; controlling mismatch
through geometry and beamforming is decisive at small to
moderate k.
E. Discussion
Across datasets and concurrency levels, two consistent
observations emerge. First, client rotation coupled with
Fairness
(Jain Index)
Performance
(1/PPL√ó10)
Signal Quality
(SNR/30)
Energy Efficiency
(1/Energy√ó5)
Time Efficiency
(1/Time√ó100)
0.2
0.4
0.6
0.8
1.0
(b) Dolly Dataset
Digital FedAvg
Gibbs
MA (Greedy)
OTA No-PC
SCA-PDD
Fig. 6: Performance comparison of different learning methods
on Dolly dataset.
geometry-aware alignment yields both higher fairness and
lower perplexity within the same round budget, as seen by the
separation of the Jain/Gini curves and the PPL bars at R30.
Second, SNR alone is not predictive of model quality in the
analog regime: the radar plots show the proposed method can
outperform in PPL while not maximizing SNR, underscoring
that alignment of the received analog sum with the intended
weighted gradient is the key optimization target.
VII. CONCLUSION
A
movable-antenna
framework
was
integrated
with
over-the-air aggregation for federated fine-tuning of large
language models. The design jointly optimizes client participa-
tion, local computation and batching, MA element placement,
and analog beamforming under latency and energy constraints,
solved with a hybrid SCA‚ÄìPDD routine. The analysis accounts
for OTA-induced distortion and distribution shift between
pre-training and fine-tuning. Experiments show improvements
in model quality and participation fairness across multiple
uplink concurrencies, together with favorable latency‚Äìenergy
trade-offs. Aligning the received analog sum with the in-
tended weighted gradient is more decisive than maximizing
post-combining SNR when only a few clients transmit con-
currently.
REFERENCES
[1] A. Matarazzo and R. Torlone, ‚ÄúA Survey on Large Language Models
with some Insights on their Capabilities and Limitations,‚Äù 2025.
[2] L. Gao, S. Biderman, S. Black, L. Golding, T. Hoppe, C. Foster,
J. Phang, H. He, A. Thite, N. Nabeshima, S. Presser, and C. Leahy,
‚ÄúThe Pile: An 800GB Dataset of Diverse Text for Language Modeling,‚Äù
2020.
[3] O. Upadhyay, A. Saravanakumar, and A. Ismail, ‚ÄúSynLexLM: Scaling
Legal LLMs with Synthetic Data and Curriculum Learning,‚Äù 2025.
[4] J.-W. Lee, Z. Lipton, N. H. Shah, Y. Luo, Y. Peng, F. Wang, and
J. Leskovec, ‚ÄúThe Dawn of Medical Large Language Models,‚Äù npj
Digital Medicine, vol. 8, no. 1, p. 33, 2025.
[5] S. Ghiasvand, M. Alizadeh, and R. Pedarsani, ‚ÄúDecentralized Low-Rank
Fine-Tuning of Large Language Models,‚Äù 2025.
[6] Z. Lin, X. Hu, Y. Zhang, Z. Chen, Z. Fang, X. Chen, A. Li,
P. Vepakomma, and Y. Gao, ‚ÄúSplitLoRA: A Split Parameter-Efficient
Fine-Tuning Framework for Large Language Models,‚Äù 2024.


--- Page 12 ---
12
[7] F. J. Dorfner, A. Dada, F. Busch, M. R. Makowski, T. Han, D. Truhn,
J. Kleesiek, M. Sushil, L. C. Adams, and K. K. Bressem, ‚ÄúEvaluating
the Effectiveness of Biomedical Fine-tuning for Large Language Mod-
els on Clinical Tasks,‚Äù Journal of the American Medical Informatics
Association, p. ocaf045, April 2025.
[8] C. Ling, X. Zhao, J. Lu, C. Deng, C. Zheng, J. Wang, T. Chowdhury,
Y. Li, H. Cui, X. Zhang, T. Zhao, A. Panalkar, D. Mehta, S. Pasquali,
W. Cheng, H. Wang, Y. Liu, Z. Chen, H. Chen, C. White, Q. Gu, J. Pei,
C. Yang, and L. Zhao, ‚ÄúDomain Specialization as the Key to Make Large
Language Models Disruptive: A Comprehensive Survey,‚Äù 2024.
[9] C. T. Dinh, N. H. Tran, M. N. H. Nguyen, et al., ‚ÄúFederated learning
over wireless networks: Convergence analysis and resource allocation,‚Äù
IEEE/ACM Transactions on Networking, vol. 29, no. 1, pp. 398‚Äì417,
2021.
[10] T. Nishio and R. Yonetani, ‚ÄúClient selection for federated learning with
heterogeneous resources in mobile edge,‚Äù in Proc. ICC, 2019.
[11] H. Liu, X. Yuan, et al., ‚ÄúReconfigurable intelligent surface enabled
federated learning: A unified communication‚Äìlearning design approach,‚Äù
IEEE Transactions on Wireless Communications, vol. 20, no. 11,
pp. 7595‚Äì7610, 2021.
[12] Z. Yang et al., ‚ÄúFederated learning for 6g communications: Challenges,
methods, and future directions,‚Äù Engineering, vol. 18, pp. 141‚Äì160,
2022.
[13] K. Yang, T. Jiang, Y. Shi, and Z. Ding, ‚ÄúFederated learning via over-
the-air computation,‚Äù IEEE Transactions on Wireless Communications,
vol. 19, no. 3, pp. 2023‚Äì2038, 2020.
[14] B. Xiao et al., ‚ÄúOver-the-air federated learning: Status quo, open
problems and solutions,‚Äù Information Fusion, vol. 110, p. 102393, 2024.
[15] Y. Zeng and R. Zhang, ‚ÄúOver-the-air computation for wireless data
aggregation in massive iot,‚Äù IEEE Transactions on Wireless Commu-
nications, vol. 17, no. 12, pp. 7595‚Äì7609, 2018.
[16] S. Li, M. Chen, et al., ‚ÄúWireless data aggregation for iot via over-the-air
computation: Beamforming and power control,‚Äù IEEE Internet of Things
Journal, vol. 6, no. 3, pp. 4547‚Äì4560, 2019.
[17] W. Mei et al., ‚ÄúMovable-antenna position optimization: A graph-based
approach,‚Äù IEEE Wireless Communications Letters, vol. 13, no. 11,
pp. 2876‚Äì2880, 2024.
[18] Z. Wei et al., ‚ÄúMovable antennas meet intelligent reflecting surface:
Friends or foes?,‚Äù IEEE Transactions on Communications, 2025. Early
access.
[19] S. Zhu et al., ‚ÄúMovable-antenna enhanced multiuser communication
via antenna position optimization,‚Äù IEEE Transactions on Wireless
Communications, 2024. Early access.
[20] J. Zhang, S. Vahidian, et al., ‚ÄúTowards building the federated gpt:
Federated instruction tuning,‚Äù arXiv:2305.05644, 2024.
[21] X. Yao et al., ‚ÄúFederated large language models: A survey,‚Äù ACM
Computing Surveys, 2024. Early access.
[22] H. Wu, H. Ren, C. Pan, and Y. Zhang, ‚ÄúMovable Antenna-Enabled RIS-
Aided Integrated Sensing and Communication,‚Äù IEEE Transactions on
Cognitive Communications and Networking, pp. 1‚Äì1, 2025.
[23] L. Zhu, W. Ma, W. Mei, Y. Zeng, Q. Wu, B. Ning, Z. Xiao, X. Shao,
J. Zhang, and R. Zhang, ‚ÄúA Tutorial on Movable Antennas for Wireless
Networks,‚Äù 2025.
[24] J. Tang, C. Pan, Y. Zhang, H. Ren, and K. Wang, ‚ÄúSecure MIMO
Communication Relying on Movable Antennas,‚Äù IEEE Transactions on
Communications, vol. 73, no. 4, pp. 2159‚Äì2175, 2025.
[25] Y. Wang, H. Shen, C. Han, and M. Tao, ‚ÄúMovable Antennas: Channel
Measurement, Modeling, and Performance Evaluation,‚Äù 2024.
[26] Y. Liu, J. Zhao, and P. Wang, ‚ÄúReconfigurable Antennas for Dynamic
Channel Optimization in Wireless Networks,‚Äù IEEE Communications
Magazine, vol. 61, no. 3, pp. 45‚Äì51, 2023.
[27] Y. Zhao, Y. Xiu, M. Xu, and N. Wei, ‚ÄúMovable Antenna-Aided Fed-
erated Learning with Over-the-Air Aggregation: Joint Optimization of
Positioning, Beamforming, and User Selection,‚Äù 2025.
[28] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‚ÄúBERT: Pre-training
of Deep Bidirectional Transformers for Language Understanding,‚Äù In
Proc. of NAACL-HLT, pp. 4171‚Äì4186, 2019.
[29] A. Kopf, B. Zhao, and D. Li, ‚ÄúTwo-phase Adaptation of Large Language
Models for Domain-Specific Tasks,‚Äù IEEE Transactions on Cognitive
Communications and Networking, vol. 7, no. 3, pp. 870‚Äì882, 2021.
[30] Q. Yang, Y. Liu, T. Chen, and Y. Tong, ‚ÄúFederated Machine Learning:
Concept and Applications,‚Äù ACM Transactions on Intelligent Systems
and Technology, vol. 10, no. 2, p. 12, 2019.
[31] D. Yu, S. Naik, A. Backurs, S. Gopi, H. A. Inan, G. Kamath, J. Kulkarni,
Y. T. Lee, A. Manoel, L. Wutschitz, S. Yekhanin, and H. Zhang,
‚ÄúDifferentially Private Fine-tuning of Language Models,‚Äù 2022.
[32] L. Collins, H. Hassani, A. Mokhtari, and S. Shakkottai, ‚ÄúFedAvg with
fine tuning: local updates lead to representation learning,‚Äù in Proceedings
of the 36th International Conference on Neural Information Processing
Systems, NIPS ‚Äô22, (Red Hook, NY, USA), Curran Associates Inc., 2022.
[33] N. Alnaasan, H.-R. Huang, A. Shafi, H. Subramoni, and D. K. Panda,
‚ÄúCharacterizing Communication in Distributed Parameter-Efficient Fine-
Tuning for Large Language Models,‚Äù in Proceedings of the 21st IEEE
Symposium on High-Performance Interconnects (HOTI), pp. 11‚Äì19,
IEEE, Aug. 2024.
[34] J. Zhang, S. Vahidian, M. Kuo, C. Li, R. Zhang, T. Yu, Y. Zhou,
G. Wang, and Y. Chen, ‚ÄúTowards Building the Federated GPT: Federated
Instruction Tuning,‚Äù 2024.
[35] H. Zhu, B. Chen, and X. Wang, ‚ÄúOver-the-air computing for wireless
data aggregation: Strategies and performance analysis,‚Äù IEEE Transac-
tions on Wireless Communications, vol. 19, no. 10, pp. 6535‚Äì6548, 2020.
[36] J. Chen, J. Yang, and L. Shi, ‚ÄúBeamforming design for over-the-air
federated learning,‚Äù IEEE Transactions on Wireless Communications,
vol. 20, no. 9, pp. 5575‚Äì5589, 2021.
[37] K. Yang, T. Jiang, Y. Shi, and Z. Ding, ‚ÄúFederated Learning via Over-
the-Air Computation,‚Äù IEEE Transactions on Wireless Communications,
vol. 19, no. 3, pp. 2022‚Äì2035, 2020.
[38] L. Zhu, W. Ma, and R. Zhang, ‚ÄúModeling and Performance Analysis
for Movable Antenna Enabled Wireless Communications,‚Äù IEEE Trans-
actions on Wireless Communications, vol. 23, no. 6, pp. 6234‚Äì6250,
2024.
[39] Y. Cai, Y. Xu, Q. Shi, B. Champagne, and L. Hanzo, ‚ÄúRobust joint
hybrid transceiver design for millimeter wave full-duplex MIMO relay
systems,‚Äù IEEE Transactions on Wireless Communications, vol. 18,
no. 2, pp. 1199‚Äì1215, 2019.
[40] W. Guo, A.-A. Lu, X. Meng, X. Gao, and N. Ma, ‚ÄúBroad Coverage
Precoding Design for Massive MIMO With Manifold Optimization,‚Äù
IEEE Transactions on Communications, vol. 67, no. 4, pp. 2792‚Äì2806,
2019.
[41] D. J. Beutel, T. Topal, A. Mathur, X. Qiu, J. Fernandez-Marques, Y. Gao,
L. Sani, K. H. Li, T. Parcollet, P. P. B. de GusmÀúao, and N. D. Lane,
‚ÄúFlower: A Friendly Federated Learning Research Framework,‚Äù 2022.
[42] X. Geng and H. Liu, ‚ÄúOpenllama: An open reproduction of llama,‚Äù May
2023.
[43] T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettlemoyer, ‚ÄúQLORA:
efficient finetuning of quantized LLMs,‚Äù in Proceedings of the 37th
International Conference on Neural Information Processing Systems,
NIPS ‚Äô23, (Red Hook, NY, USA), Curran Associates Inc., 2023.
[44] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and
W. Chen, ‚ÄúLoRA: Low-Rank Adaptation of Large Language Models,‚Äù
2021.
[45] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, and
P. Liang, ‚ÄúStanford Alpaca: An Instruction-following LLaMA Model.‚Äù
https://github.com/tatsu-lab/stanford alpaca, 2023. Accessed: 2025-05-
09.
[46] Databricks, ‚ÄúFree Dolly: Introducing the World‚Äôs First Truly Open
Instruction-Tuned LLM.‚Äù https://www.databricks.com/blog/2023/04/12/
dolly-first-open-commercially-viable-instruction-tuned-llm, April 2023.
Accessed: 2025-05-09.
[47] S. U. Stich, ‚ÄúLocal SGD Converges Fast and Communicates Little,‚Äù
2019.
[48] I. Gulrajani and D. Lopez-Paz, ‚ÄúIn search of lost domain generalization,‚Äù
CoRR, vol. abs/2007.01434, 2020.
[49] J. Shen, Y. Qu, W. Zhang, and Y. Yu, ‚ÄúWasserstein Distance Guided
Representation Learning for Domain Adaptation,‚Äù 2018.


--- Page 13 ---
13
APPENDIX
A. Complexity Analysis
During each SCA‚ÄìPDD iteration, the Block A SCA sub-
problem is convex and can be solved in polynomial time
(e.g., O(pŒ±) for a problem dimension p). The PDD often uses
coordinate or projected gradient methods to handle discrete or
geometric constraints.
Because each
 M, N

is enumerated, the total complexity
is roughly
O

|M| √ó |N| √ó ISCA √ó pŒ±
,
(39)
where M and N are finite sets of candidate integer values for
M and N, ISCA is the typical number of SCA‚ÄìPDD iterations
and Œ± ‚àà[2, 3] depends on the solver. In practice, moderate
(M, N) ranges and a small number of SCA‚ÄìPDD iterations
often suffice, making the approach tractable.
B. Convergence Analysis
We analyze a two-phase LLM training procedure (PhasesÀúI‚Äì
II) under a potential distribution shift, with OTA gradient
aggregation in the fine-tuning phase. Concretely, our aim is to
characterize how the final fine-tuning loss depends on several
key parameters: (i) the number of pre-training rounds M and
fine-tuning rounds N, (ii) the variance bounds Œ±2 and ÀÜŒ±2
together with the smoothness constants œÅ and ÀÜœÅ [47], (iii) the
Wasserstein distance W(Ppre, Pfine) governing the distribution
shift [48], [49], and (iv) the OTA noise variance œÉ2, which is
affected by MA placements {xn,i} and beamforming vectors
{q(n)}.
To facilitate our analysis, we first assume that Lpre is œÅ-
smooth, meaning that for all w1, w2,
Lpre(w1) ‚â§Lpre(w2) + ‚àáLpre(w2)T  w1 ‚àíw2

+ œÅ
2‚à•w1 ‚àíw2‚à•2,
(40)
and that Lfine is ÀÜœÅ-smooth, i.e., for all w1, w2,
Lfine(w1) ‚â§Lfine(w2) + ‚àáLfine(w2)T  w1 ‚àíw2

+ ÀÜœÅ
2‚à•w1 ‚àíw2‚à•2.
(41)
In addition, each training phase has bounded gradient vari-
ance: E

‚à•‚àáÀúLpre(w) ‚àí‚àáLpre(w)‚à•2
‚â§Œ±2 during Phase
I,
and E

‚à•‚àáÀúLfine(w) ‚àí‚àáLfine(w)‚à•2
‚â§ÀÜŒ±2 during Phase
II.
To capture the distribution shift between the pretraining distri-
bution Ppre and the fine-tuning distribution Pfine, we use the
Wasserstein distance W(Ppre, Pfine). Specifically, if ‚Ñì(w, d) is
œÅdist-Lipschitz in d, then
 Lfine(w) ‚àíLpre(w)
 ‚â§œÅdist W(Ppre, Pfine).
(42)
Finally, in the fine-tuning phase (PhaseÀúII), the server ob-
serves aggregated gradients bG(n) = G(n) + Œµ(n), where Œµ(n)
denotes the OTA noise, satisfying E

‚à•Œµ(n)‚à•2
‚â§œÉ2. This
noise level œÉ2 can be mitigated by optimizing position of MA
and beamforming design.
1) Phase I: Pre-training Convergence: We first perform M
rounds of mini-batch SGD on Lpre. Specifically, the update
rule is
w(m+1) = w(m) ‚àíŒ≥ ‚àáÀúLpre
 w(m); Œ∂(m)
(43a)
m = 0, . . . , M ‚àí1
(43b)
where Œ∂(m) is a mini-batch drawn from the pre-training distri-
bution Ppre, and Œ≥ is the step size. Under the assumption that
Lpre is œÅ-smooth and that the stochastic gradient has variance
at most Œ±2, standard SGD analysis implies the following
bound:
1
M
M‚àí1
X
m=0
E

‚à•‚àáLpre(w(m))‚à•2
‚â§2
 Lpre(w(0)) ‚àíL‚àó
pre

Œ≥ M
+ œÅ Œ≥ Œ±2.
(44)
From this, one can equivalently derive an upper bound on
E[Lpre(w(M))] that depends on M, Œ≥, œÅ, and Œ±2. We denote
this dependency by ‚àÜpre(M, Œ≥, Œ±2, œÅ).
2) Distribution Shift Bound: Upon completion of Phase I,
the parameter vector is w(M). To account for the distribution
shift between Ppre and Pfine, we assume that there is a
bound on | Lfine(w)‚àíLpre(w)| proportional to the Wasserstein
distance W(Ppre, Pfine). Concretely,
Lfine
 w(M)
‚â§Lpre
 w(M)
+ œÅdist W(Ppre, Pfine). (45)
Taking expectation over the randomness of the SGD updates,
we obtain
E

Lfine(w(M))

‚â§E

Lpre(w(M))

+ œÅdist W.
(46)
Finally, by using our Phase I bound on E[Lpre(w(M))], we
obtain an upper bound on E[Lfine(w(M))] of the form
E

Lfine(w(M))

‚â§Lpre
 w(0)
+ ‚àÜpre
 M, Œ≥, Œ±2, œÅ

+ œÅdist W. (47)
3) Phase II: Fine-Tuning with OTA Noise: Next, in Phase II
we fine-tune the model for N additional rounds on Lfine,
but with OTA gradient aggregation subject to additive noise.
Concretely, each round n = 0, . . . , N ‚àí1 is
w(M+n+1) = w(M+n) ‚àíÀÜŒ≥ bG(n),
(48)
where bG(n) = G(n)+Œµ(n). Here, G(n) denotes the aggregated
user gradients (variance at most ÀÜŒ±2), and Œµ(n) represents OTA
noise with variance at most œÉ2 [37]. Thus, the total variance
in the fine-tuning phase is ÀÜŒ±2 + œÉ2.
Under the assumption that Lfine is ÀÜœÅ-smooth, a standard
SGD argument yields [47]:
1
N
N‚àí1
X
n=0
E

‚à•‚àáLfine(w(M+n))‚à•2
‚â§2
 Lfine(w(M)) ‚àíL‚àó
fine

ÀÜŒ≥ N
+ ÀÜœÅ ÀÜŒ≥
 ÀÜŒ±2 + œÉ2
.
(49)
By rearranging the above bound, we obtain a direct up-
per bound on E[Lfine(w(M+N))], which we denote by
‚àÜfine(N, ÀÜŒ≥, ÀÜŒ±2 + œÉ2, ÀÜœÅ).


--- Page 14 ---
14
In summary, the distribution-shift result (46), and the
Phase II analysis leads to the final convergence guarantee
E

Lfine(w(M+N))

‚â§Lpre(w(0))
|
{z
}
initial
+ ‚àÜpre(M, Œ≥, Œ±2, œÅ)
|
{z
}
Phase I
+ œÅdist W
| {z }
shift
+ ‚àÜfine(N, ÀÜŒ≥, ÀÜŒ±2 + œÉ2, ÀÜœÅ)
|
{z
}
Phase II
.
(50)
Intuitively, the total expected fine-tuning loss is bounded
by: (i) the initial loss Lpre(w(0)), (ii) the overhead of pre-
training convergence ‚àÜpre, (iii) the penalty for distribution
shift œÅdist W [48], [49], and (iv) the overhead of fine-tuning
convergence ‚àÜfine, which grows with both ÀÜŒ±2 and the OTA
noise variance œÉ2. This result cleanly reveals how each factor
influences the final performance.
