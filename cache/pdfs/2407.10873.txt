--- Page 1 ---
Understanding the Importance of Evolutionary
Search in Automated Heuristic Design with
Large Language Models
Rui Zhang1(B), Fei Liu1, Xi Lin1, Zhenkun Wang2,
Zhichao Lu1(B), and Qingfu Zhang1(B)
1 Department of Computer Science, City University of Hong Kong
2 School of System Design and Intelligent Manufacturing, Southern University of
Science and Technology
rzhang.cs@gmail.com, luzhichaocn@gmail.com, qingfu.zhang@cityu.edu.hk
Abstract. Automated heuristic design (AHD) has gained considerable
attention for its potential to automate the development of effective heuris-
tics. The recent advent of large language models (LLMs) has paved a
new avenue for AHD, with initial efforts focusing on framing AHD as
an evolutionary program search (EPS) problem. However, inconsistent
benchmark settings, inadequate baselines, and a lack of detailed com-
ponent analysis have left the necessity of integrating LLMs with search
strategies and the true progress achieved by existing LLM-based EPS
methods to be inadequately justified. This work seeks to fulfill these re-
search queries by conducting a large-scale benchmark comprising four
LLM-based EPS methods and four AHD problems across nine LLMs
and five independent runs. Our extensive experiments yield meaningful
insights, providing empirical grounding for the importance of evolution-
ary search in LLM-based AHD approaches, while also contributing to the
advancement of future EPS algorithmic development. To foster accessi-
bility and reproducibility, we have fully open-sourced our benchmark and
corresponding results.
Keywords: Automated heuristic design ¬∑ evolutionary program search
¬∑ large language model ¬∑ evolutionary computation.
1
Introduction
Automated heuristic design (AHD) aims to automatically select, refine, or con-
struct effective heuristics, thereby obviating the necessity for rich domain exper-
tise traditionally required in manual heuristic design [1‚Äì3]. Considerable effort
has been dedicated to employing machine learning techniques for AHD [4‚Äì6].
Among them, genetic programming (GP) [7] is one of the most widely used
techniques for handling AHD tasks, owing to its flexible representation and ef-
ficacy across various domains [3, 8‚Äì10]. However, GP necessitates specifying a
set of permissible primitives and mutation operations, which unfortunately are
non-trivial and problem-dependent [11].
arXiv:2407.10873v1  [cs.NE]  15 Jul 2024


--- Page 2 ---
2
R. Zhang et al.
ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõ0
¬∑¬∑¬∑
¬∑¬∑¬∑
LLM-based EPS: better heuristics are created via prompting LLMs over program codes.
evolve
¬∑¬∑¬∑
ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõ0
exchange sub-parts
¬∑¬∑¬∑
ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõ1
selection
Genetic Programming: better heuristics are created through genetic operations over trees.
¬∑¬∑¬∑
ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõùëõ
¬∑¬∑¬∑
selection
Generate a heuristic
inspired by the 
given examples
Prompting
Generated 
heuristic:
LLM
ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõùëò
¬∑¬∑¬∑
ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõ1
¬∑¬∑¬∑
ùëùùëúùëùùë¢ùëôùëéùë°ùëñùëúùëõ%&'
¬∑¬∑¬∑
Function set
add  sub
for  sum  
‚ãØ‚ãØ
Terminal set
bins items
true false
‚ãØ‚ãØ
specified by
human experts
def initial_heuristic(item: float, bins: list) -> list:
```Define priority with which we assign an item 
to each bin.
:param item: Size of item to be added to the bin.
:param bins: List of capacities for each bin.
:return: a list showing priority score of each bin.
```
return [0] * len(bins)
Fig. 1: An illustration of the LLM-based EPS paradigm, with respect to the GP-
based paradigm (top section), for automated heuristic design.
Recently, the advent of large language models (LLMs) has introduced novel
tools for AHD. Preliminary endeavors have been made to model AHD as a pro-
gram search problem, employing LLMs to aid the solution (i.e., heuristics) gener-
ation and optimization process within an evolutionary framework. For instance,
FunSearch [12] evolves heuristics for mathematical problems that outperform
existing solutions on cap set and admissible set problems [13]. EoH [14] and
ReEvo [15] evolve heuristics for combinatorial optimization (CO) problems and
consequently outperform existing AHD methods on traveling salesman problems
(TSPs) [16] and online bin packing (OBP) problems [17].
These methodologies essentially adopt a canonical paradigm, referred to as
LLM-based Evolutionary Program Search (EPS) in this work, that comprises the
following key aspects: (i) candidate solutions (i.e., heuristics) are represented as
executable computer programs, also referred to as codes; (ii) an evolutionary
computation (EC) paradigm is used to evolve toward better programs; and (iii)
LLMs are used as the main engine for driving the search, i.e., creating new pro-
grams, introducing variations to existing programs, etc. A pictorial illustration
of this paradigm is provided in Fig. 1.
Despite a steady stream of promising empirical results, we have noticed
three issues: (i) Inconsistent benchmark settings, where existing LLM-based EPS
methods exhibit variations in initialization, termination criteria, and choice of
LLMs; (ii) Inadequate baselines, where existing LLM-based EPS methods were
primarily evaluated against random search or simple heuristics derived through
human intuitions; (iii) Lack of detailed analysis on the relative contribution of
each component (e.g., choice of LLMs, prompt and search strategies, etc.) to the
overall success achieved by existing LLM-based EPS methods.


--- Page 3 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
3
To address these issues, we first develop a simple yet effective EPS baseline,
dubbed (1+1)-EPS, taking inspiration from (1+1)-ES [18] and few-shot prompt-
ing [19]; and we design a unified benchmark setup comprising four LLM-based
EPS methods (three existing methods and our baseline), four AHD problems,
and nine different LLMs. Then, curated experiments are designed around the
following two research queries: ‚ë†the necessity of coupling LLMs with search
strategies for AHD, and ‚ë°the current progress made by existing LLM-based
EPS methods on AHD. Detailed analyses are subsequently carried out for new
knowledge and insights.
Key takeaways: Through extensive experiments, we find that:
‚ó¶The inherent generative capability of LLMs alone is insufficient, providing
an empirical justification for coupling LLMs with a search mechanism, i.e.,
the LLM-based EPS paradigm, for tackling AHD problems effectively. (¬ß4.1)
‚ó¶The performance of existing LLM-based EPS methods varies significantly
across different AHD problems and LLM choices, suggesting more diverse
benchmarks and applications are needed to establish a better understanding
of this emergent paradigm for AHD. (¬ß4.2)
We summarize the primary contributions of this work as below:
1. Large-scale benchmark. This work examines all existing LLM-based EPS
methods along with the proposed baseline on four AHD problems under a
canonical benchmark setting. Each compared method is evaluated over nine
LLM choices and five independent runs.
2. Insights and implications for future research. With extensive results,
we provide the empirical grounding for the necessity of LLM-based EPS for
AHD and suggestions for future EPS algorithmic development.
3. Fair and reproducible evaluation. We open-source the implementations
of all compared LLM-based EPS methods, AHD problems, and interface to
both open- and closed-source LLMs at https://github.com/zhichao-lu/
llm-eps to foster future development.
2
Background
Automated Heuristic Design (AHD) is also known as hyper-heuristics [1,
2,20], aiming to search over a space of heuristics rather than the solutions to a
specific problem directly. Most of the AHD approaches incorporate a learning
mechanism [4,21], such as reinforcement learning [5], Bayesian learning [6], case-
based reasoning [22], and evolutionary computation methods [23‚Äì26].
In particular, genetic programming (GP) [7] has emerged as a promising
approach to automate the design of heuristics. In essence, GP maintains a set
of computer programs in the form of trees, instructions, graphs, etc., where
better programs are evolved through genetic operations, such as crossover and
mutation. GP-based AHD approaches have been applied in a number of differ-
ent application domains, such as combinatorial optimization [27‚Äì29], schedul-
ing [3,9], among other areas [30,31]. Although GP-based AHD approaches have


--- Page 4 ---
4
R. Zhang et al.
achieved promising results, they are often criticized for the need to explicitly
specify the function sets and primitive sets, which are not trivial and problem-
dependent [11]. A more in-depth discussion of the connection between GP and
the methods studied in this work is provided in Appx. ¬ßA.
Large Language Models (LLMs) typically refer to deep neural networks
with billions or even trillions of model parameters, built upon the Transformer
architecture [32]. The input query to LLMs can be any sequence of texts, such
as natural language, codes, mathematical expressions, etc. As output, the LLM
also provides a sequence of texts in response to the input query.
With the exponential growth in model size and training data, LLMs have im-
proved at an impressive pace in the recent past [19,33], leading to groundbreaking
performance across a wide range of tasks [34‚Äì37]. Notably, the synergy between
LLMs and evolutionary computation (EC) has been successfully applied to solve
various optimization problems, such as prompt optimization [38,39], algorithm
design [40‚Äì42], and neural architecture search [43], to name a few. Through the
lens of EC, LLMs can be viewed as an intelligent variation operator [44], yield-
ing more diverse and novel offspring compared to conventional means, such as
genetic operators, differential evolution, or particle swarm [45, 46]. This has in
turn translated to promising results in various domains [47‚Äì49].
Table 1: Existing LLM-based EPS methods for AHD along with the baseline,
(1 + 1)-EPS, proposed in this work.
Method
Prompt Strategy
LLM
Search Strategy
FunSearch [12]
Few-shot prompting [19]
Codey [50],
StarCoder [51]
Island model
with re-starts
EoH [14]
CoT [52]
GPT-3.5 [19], Gemini Pro,
DeepSeek [53], CodeLlama [54]
GA
ReEvo [15]
CoT [52] + Reflection [19]
2√óGPT-3.5 [19]
GA
(1 + 1)-EPS
(our baseline)
One-shot prompting
LLMs in Table 2
(1 + 1)-ES
Existing LLM-based EPS Methods exhibit variations mainly in the follow-
ing three aspects: (i) search strategy, (ii) prompt strategy, and (iii) choice of
LLMs. An overview comparison is provided in Table 1. Readers are referred to
Appx. ¬ßC for elaborated descriptions.
From the perspective of search strategy, many existing EPS methods [14,15]
adopt the standard genetic algorithm (GA) framework, where a population of
randomly initialized heuristics is made gradually better through genetic opera-
tors (i.e., crossover and mutation) and elitist selection [55]. Sophisticated mod-
ifications (to the standard GA framework) have also been tried, in particular,
FunSearch introduces an island model (in the form of multiple distinct popula-
tions) with a re-start mechanism to promote diversity among individuals [12].
From the perspective of prompt strategy, FunSearch [12] adopts a simple
strategy, i.e., few-shot prompting where the LLM outputs are conditioned on a
few provided examples of heuristics [19]. More sophisticated strategies, typically
variants of the chain of thought prompting (CoT) [52], have been adopted in the


--- Page 5 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
5
subsequent works. In particular, EoH [14] leverages linguistic descriptions of the
heuristics (referred to as thoughts) and develops five different prompt strategies
to balance the exploration and exploitation aspects of the evolutionary search;
ReEvo [15] applies the reflection technique [56] to verbalize trends from past
high-performant individuals into prompts.
From the choice of LLM perspective, most existing EPS methods are solely
evaluated with closed-source LLMs (e.g., GPT-3.5 [19] and Codey [50]) except
FunSearch which is also evaluated with an open-source LLM, i.e., StarCoder [51].
In addition, ReEvo [15] uses two LLMs ‚Äì one for generating prompts and the
other one for generating heuristics.
3
Preliminaries
In this section, we describe the experimental setup in terms of benchmark prob-
lems, baselines, and choices of LLMs, among other settings.
Benchmark Problems. We consider three types of applications for AHD.
‚ë†Admissible Set (AS) [13] is a variation of the cap set problem from math-
ematics [57]. Formally, admissible set problems, denoted as A(n, w), are collec-
tions of vectors in {0, 1, 2}n that satisfy: (1) Each vector has the same number
w of non-zero elements but a unique support. (2) For any three distinct vectors
there is a coordinate in which their three respective values are {0, 1, 2}, {0, 0, 1},
or {0, 0, 2}. The objective of the admissible set problem is to maximize the size
of the set while fulfilling all the aforementioned criteria. In this work, we set
n = 15 and w = 10, i.e., A(15, 10), to be consistent with prior works [12].
‚ë°Online Bin Packing (OBP). The objective of bin packing problems is to
allocate a collection of items with varying sizes into the fewest possible bins of
fixed capacity of C. We consider the online scenario where items are packed
as they arrive, in contrast to the offline scenario where all items are known
beforehand. In this work, we consider two widely used datasets for OBP: the
OR dataset [58] and the Weibull dataset [59]. To guide various LLM-based EPS
methods in designing heuristics, we use 20 instances where each comprises 250
items with sizes sampled from [20, 100] for the OR dataset [12]; and we use five
instances where each comprises 5K items with sizes sampled from a Weibull
distribution of f(45, 3) for the Weibull dataset [12,60]. The capacity C of each
bin is set to 150 and 100 for OR and Weibull datasets, respectively.
‚ë¢Traveling Salesman Problem (TSP) aims to find the shortest route to
visit all the given locations once and return to the starting location [16]. It is
considered one of the most important CO problems and a widely used test bed
for heuristic design approaches. We use a set of 64 TSP100 instances [61] where
the coordinates of locations to be visited are randomly sampled from [0, 1] to
guide the compared LLM-based EPS methods in designing heuristics [15,60].
Baseline. An adequate baseline is essential for understanding the relative im-
provements made by the various methods (at least empirically). Existing LLM-
based EPS methods were mostly compared against random search (i.e., uniform


--- Page 6 ---
6
R. Zhang et al.
sampling) or simple heuristics3 based on human intuitions, yielding promising
performance across diverse problems. However, we argue that a more adequate
baseline beyond random search and intuitive heuristics is needed for a meaning-
ful and representative comparison. To this end, inspired by the (1+1)-ES [18],
we develop a simple EPS baseline, dubbed (1 + 1)-EPS. The pseudocode of the
proposed baseline is provided in Algorithm 1. Given its simplistic design in both
the search and prompt strategies, we envision that (1 + 1)-EPS should simulate
the lower bound of the performance of the EPS paradigm.
Algorithm 1: (1 + 1)-EPS
Input
: fLLM: a LLM,
hT: a template heuristic,
T: max. # of gens.
1 hbest ‚ÜêhT // initialize the best
heuristic (found so far) to hT.
2 sbest ‚Üêevaluate(hbest) // evaluate
the performance score of hbest.
3 while t < T do
4
prompts ‚Üê
One-shot prompting(hbest)
//create inputs to fLLMby
converting hbest to prompts via
one-shot prompt engineering.
5
h ‚ÜêfLLM(prompts) // create
a heuristic via a LLM.
6
s ‚Üêevaluate(h) // evaluate
the performance of h.
7
if s < sbest then
8
// update the best heuristic
found so far and its score.
hbest ‚Üêh, sbest ‚Üês
9
end
10 end
11 Return hbest, sbest
One-shot Prompting
Idea: Create
input
prompts
(h) by providing the best
heuristic (hbest) found so
far as an example.
E.g.: The shaded texts below
are prompts created for an
online bin packing problem.
def hbest(
item: float ,
bins: list) -> list:
priority = </> #
omitted
for
brevity
return
priority
def h(
item: float ,
bins: list) -> list:
priority =
<...to be
filled by a LLM
...>
return
priority
Choice of LLMs. We consider a diverse set of LLMs to investigate the impact
of the choice of LLMs on the AHD performance. We include five open-source
LLMs that were fine-tuned on code-related tasks and three closed-source LLMs
developed for general purposes. In particular, we consider the most powerful
LLM currently available, i.e., Claude 3 Opus [65], and the most capable open-
source LLM for coding tasks, i.e., DeepSeek-Coder [53]. For completeness, we
also include the most powerful coding language model prior to the LLM era,
i.e., UniXcoder [64]. Table 2 provides an overview of the considered LLMs. For
open-source LLMs, we deploy these models locally on a server with 16 NVIDIA
V100 GPU cards; while for closed-source LLMs, we rely on the respective APIs
provided by OpenAI and Anthropic to get responses.
3 For instance, an intuitive heuristic for an OBP problem could be ‚Äúplace the item in
the first bin with available capacity remaining‚Äù.


--- Page 7 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
7
Table 2: Overview of the LLMs evaluated in this work. We use performance on
‚ÄúHumanEval‚Äù [62] and ‚ÄúMMLU‚Äù [63] to indicate the capabilities of LLMs on
code and general knowledge, respectively. Both metrics are greater the better.
Model
#P
Specialized
for Code
Open
Source
HumanEval (‚Üë)
[62]
MMLU (‚Üë)
[63]
UniXcoder [64]
0.3B
‚úï
‚úì
-
-
StarCoder [51]
15.5B
‚úì
‚úì
33.6%
-
CodeLlama [54]
7B
‚úì
‚úì
34.8%
42.1%
34B
‚úì
‚úì
48.8%
53.1%
DeepSeek-Coder [53]
6.7B
‚úì
‚úì
66.1%
34.6%
33B
‚úì
‚úì
69.2%
39.5%
GPT-3.5 [19]
-
‚úï
‚úï
60.3%
70.0%
GPT-4 [33]
1.76T
‚úï
‚úï
76.5%
86.4%
Claude 3 Opus [65]
137B
‚úï
‚úï
84.9%
86.8%
Evaluation Metric. To evaluate the AHD performance, we report the mean
relative distance (or gap) in performance, ‚àÜd, of the obtained heuristic with
respect to the performance of the best-known performance, mathematically as
follows.
‚àÜd = 100% √ó 1
Np
Np
X
p=1
1
Nm
Nm
X
m=1
(‚àí1)Ip(Mp,m ‚àíM ‚àó
p )
M ‚àóp
where Np is the number of compared problems, Nm is the number of considered
LLMs, Mp,m is the performance of a heuristic for the p-th problem with m-th
LLM. M ‚àó
p is the best-known performance for the p-th problem. And Ip is one
if a higher value indicates better performance for the p-th problem (i.e., for
maximization problems) and zero otherwise (i.e., for minimization problems).
Other Settings. We initialize all compared methods with the respective tem-
plate heuristic on each problem. The details of the template heuristics are pro-
vided in Appx. ¬ßB. For EoH [60], we initially incorporate a template heuristic
into the initial population, and repeatedly apply crossover and mutation oper-
ators to the existing individuals in the population to generate new individuals
until the desired population size is achieved. For both EoH [60] and ReEvo [15],
we increase the population size as well as the maximum number of evaluations.
We perform ablation studies on this in Appx. ¬ßC.1. Table 3 summarizes the
benchmark hyper-parameter settings.
4
Experimental Results and Analyses
4.1
Performance of Standalone LLMs on AHD
Motivation. Standalone LLMs have consistently showcased exceptional per-
formance across a diverse array of AI applications, reaching a point where the
research community has come to expect impressive results from them on new


--- Page 8 ---
8
R. Zhang et al.
Table 3: Summary of benchmark settings.
Description of Setting
Value
Maximum number of function evaluations (#FE)
10,000
Population size (for EoH and ReEvo)
100
# of islands, # of samples per prompt (for FunSearch)
10, 4
Number of independent runs per experiment
5
Maximum evaluation time for each heuristic
(to cope with invalid heuristics, such as infinite loops)
50 sec (TSP);
20 sec (others)
and challenging tasks. To this end, we wonder whether the inherent generative
capability of LLMs alone (without coupling with an evolutionary search mech-
anism) would suffice for AHD tasks. In this work, we attempt to answer this
question from the following two angles.
4.1.1
Angle I: Impact of Query Budget
Experimental Design. Firstly, we aim to validate the performance of stan-
dalone LLMs on AHD problems under different query budgets, i.e., maximum
# of queries allowed to be sent to LLMs. Given an AHD problem, we provide
the problem context along with the template heuristic (i.e., fT in Algorithm 1)
as prompts to a LLM, and we ask it to keep generating new heuristics until
query budgets are exhausted. Note that we do not proactively check for dupli-
cate heuristics simply because no effective tools for functionality-level duplicate
detection are readily available.
Results. Fig. 2 depicts the aggregated performance (i.e., mean ‚àÜd over four
AHD problems) of the heuristics generated by standalone GPT-3.5 with vari-
ous query budgets. We also include the performance of the heuristics obtained
by our baseline (1 + 1)-EPS as a reference. Due to space constraints, more de-
tailed results on individual AHD problems with different LLMs are discussed in
Appx. ¬ßC.2.
Our analysis reveals that while the performance of standalone LLMs on AHD
problems generally improves with increasing query budgets, several critical ob-
servations emerge:
‚ó¶There remains a significant gap between the performance of heuristics gen-
erated by standalone LLMs and the best-known performance (indicated by
‚àÜd = 0, i.e., x-axis in Fig. 2), even with a substantial query budget of
100,000.
‚ó¶Although there is a steady improvement in the mean performance of the top-
ranked heuristics, the performance of the best individual heuristics (repre-
sented by the lower bars of the boxes) shows minimal enhancement as query
budgets increase.


--- Page 9 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
9
500
 
500
1,000
2,000
3,000
4,000
5,000
6,000
7,000
8,000
9,000
10,000
20,000
50,000 100,000
Number of Trials
0
2
4
6
8
10
12
14
16
Relative Distance to Optimum
d (%)
(1+1)-EPS
|------------------------------------------------- Standalone LLM without Search ---------------------------------------------|
(a) Top-5‚Ä∞ heuristics
500
 
500
1,000
2,000
3,000
4,000
5,000
6,000
7,000
8,000
9,000
10,000
20,000
50,000 100,000
Number of Trials
0
2
4
6
8
10
12
14
16
Relative Distance to Optimum
d (%)
(1+1)-EPS
|------------------------------------------------- Standalone LLM without Search ---------------------------------------------|
(b) Top-1% heuristics
Fig. 2: Box plot comparison on the performance of the top-{(a) 5‚Ä∞, (b) 1%}
heuristics generated by GPT-3.5 under various query budgets. The performance
is measured as the relative distance to the best-known optimum (‚àÜd) aggregated
over four AHD problems and five independent runs. Lower ‚àÜd indicates better
performance. The performance of the simple baseline (1+1)-EPS with GPT-3.5
under a small query budget of 500 is also provided as a reference.
‚ó¶Standalone LLMs are highly ineffective4 on AHD problems, even when granted
an order of magnitude more queries.
In summary, these observations suggest that merely increasing the number of
attempts by a standalone LLM is insufficient for effectively addressing AHD
problems. This underscores the need to integrate LLMs with search methods to
enhance their efficacy in AHD contexts.
4.1.2
Angle II: Impact of More Capable LLMs
Experimental Design. Next, we attempt to understand the relationship be-
tween LLMs‚Äô capacity and their performance on AHD problems. In this work,
we consider the model size (in terms of # of parameters), the coding perfor-
mance (in terms of HumanEval scores [62]), and the general performance across
4 The ineffectiveness is in the sense that a simple EPS baseline achieves better mean
performance with much lower variances than standalone LLMs with an order of
magnitude more query budget, as depicted in Fig. 2.


--- Page 10 ---
10
R. Zhang et al.
CodeLlama7B
 
UniXcoder
StarCoder
CodeLlama7B
CodeLlama34B
DeepSeek6.7B
DeepSeek33B
 
GPT3.5
GPT4
Claude3Opus
0.0
2.5
5.0
7.5
10.0
12.5
15.0
Relative Distance to Optimum
d (%)
(1+1)-EPS
Standalone LLM without Search
Code LLM
General LLM
20
40
60
80
HumanEval
(
)
Fig. 3: Box plot comparison on the performance of the top-5‚Ä∞ heuristics gen-
erated by LLMs with varying capacities under 10,000 query budgets. We group
LLMs into two categories: (1) LLMs specialized for coding tasks (with back-
ground shaded in
) and (2) general-purpose LLMs (with background shaded
in
). Then, the LLMs are arranged in the order of ascending model size within
each group. The color scale of the boxes corresponds with the scores on Hu-
manEval [62]. The performance is measured as the relative distance to the best-
known optimum (‚àÜd) aggregated over four AHD problems and five independent
runs. Lower ‚àÜd indicates better performance. The performance of the simple
baseline (1 + 1)-EPS with CodeLlama-7B is also provided as a reference.
Table 4: The performance of the top-1 heuristics generated by LLMs with varying
capacities. The performance is measured as the relative distance to the best-
known optimum (‚àÜd) aggregated over four AHD problems and five independent
runs. Lower ‚àÜd indicates better performance.
UniXcoder DeepSeek
-6.7B
CodeLlama
-7B
StarCoder
15.5B
DeepSeek
-33B
CodeLlama
-34B
GPT-3.5 Claude 3
Opus
GPT-4
9.15%
4.24%
4.32%
4.21%
4.59%
4.48%
4.31%
4.63%
4.44%
many tasks (in terms of MMLU scores [63]) as proxy indicators for measuring a
LLM‚Äôs capacity. A diverse set of nine different LLMs is considered, with more
details provided in Table 2. Specifically, given an AHD problem, we provide the
problem context along with the template heuristic (i.e., fT in Algorithm 1) as
prompts to a LLM, and we ask it to keep generating new heuristics until the
query budget of 10,000 is exhausted.
Results. Fig. 3 depicts the aggregated performance (i.e., mean ‚àÜd over four
AHD problems) of the heuristics generated by LLMs with varying capacities. We
also include the performance of the heuristics obtained by our baseline (1 + 1)-
EPS with CodeLlama-7B (i.e., a small-capacity LLM) as a reference. In addition,
we provide the performance of the top-1 heuristics generated by various LLMs
in Table 4. Constrained by space, more elaborated results on individual AHD
problems with different thresholds on filtering top heuristics are provided in
Appx. ¬ßC.3. Evidently, we make the following observations:


--- Page 11 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
11
‚ó¶LLMs with more capacity (i.e., more # of model parameters, better Hu-
manEval and MMLU scores) do not necessarily lead to better performance
on AHD problems.
‚ó¶LLMs fine-tuned for coding tasks (i.e., the group with background shaded in
) are not statistically better than general purpose LLMs (i.e., the group
with background shaded in
).
‚ó¶Standalone LLMs with large overall model capacity are still highly ineffec-
tive5 on AHD problems.
‚ó¶Conventional LLMs, i.e., variants of BERT [66] such as UniXcoder [64], are
significantly inferior to modern LLMs (e.g., GPTs) on AHD problems.
In summary, the above observations suggest that simply importing more capable
LLMs is insufficient for tackling AHD problems, reinforcing the need to integrate
LLMs with search methods to enhance their efficacy in AHD contexts.
4.1.3
Summary and Implications
Observations from the previous sections have converged to a consensus that
the inherent generative capability of LLMs alone is insufficient for AHD
problems, which holds true under increased query budget (¬ß4.1.1 Angle I) and
model capacity (¬ß4.1.2 Angle II), suggesting the necessity of coupling LLMs
with a search strategy to tackle AHD problems effectively.
Given the modular yet flexible framework, we believe that the LLM-based
EPS paradigm, synergizing LLMs with an evolutionary search strategy,
is a meaningful approach to addressing the general AHD problems.
4.2
Performance of Existing LLM-based EPS Methods on AHD
We decompose our investigations into the following two angles to establish an
empirical understanding of the progress made by the existing LLM-based EPS
methods on AHD.
4.2.1
Angle I: Relative Improvements over Adequate Baseline
Motivation. Existing LLM-based EPS methods incorporate a variety of compli-
cations in the search and the prompt components (see ¬ß2 for more details). The
relative improvements contributed by these modifications are primarily evaluated
against random search or simple heuristics derived through human intuitions.
On the one hand, whether the observed improvements over these naive baselines
meaningfully capture the advancement in algorithmic design remains question-
able; while on the other hand, the general utility of the enhancements introduced
by various EPS methods also remains to be further evaluated.
5 The ineffectiveness is in the sense that a low-capacity LLM coupled with a simple
EPS baseline significantly standalone LLMs with orders of magnitude more model
capacities (e.g., GPT-4 and Claude 3 Opus), as depicted in Fig. 3.


--- Page 12 ---
12
R. Zhang et al.
500
1000
2000
3000
4000
5000
6000
7000
8000
9000 10000
Number of Trials
5
10
15
20
25
30
Relative Distance to Optimum
d (%)
FunSearch
EoH
ReEvo
(1+1)-EPS
(a) Admissible Set
500
1000
2000
3000
4000
5000
6000
7000
8000
9000 10000
Number of Trials
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.35
Relative Distance to Optimum
d (%)
FunSearch
EoH
ReEvo
(1+1)-EPS
(b) Travelling Salesman
500
1000
2000
3000
4000
5000
6000
7000
8000
9000 10000
Number of Trials
0.5
1.0
1.5
2.0
2.5
3.0
3.5
Relative Distance to Optimum
d (%)
FunSearch
EoH
ReEvo
(1+1)-EPS
(c) Online Bin Packing (Weibull)
500
1000
2000
3000
4000
5000
6000
7000
8000
9000 10000
Number of Trials
6.0
6.2
6.4
6.6
6.8
7.0
Relative Distance to Optimum
d (%)
FunSearch
EoH
ReEvo
(1+1)-EPS
(d) Online Bin Packing (OR)
Fig. 4: Convergence curve comparison on the performance of the top-1 heuristics
achieved by various EPS methods. The mean relative distances to the best-known
optimum (‚àÜd) averaged over five independent runs are denoted with markers,
while the standard deviations of ‚àÜd are shown with the shaded regions.
Experimental Design. We benchmark existing LLM-based EPS methods (i.e.,
FunSearch [12], EoH [60], and ReEvo [15]) against the proposed baseline (1+1)-
EPS on four AHD problems with seven LLMs6. We repeat each experiment five
times with different random seeds. All other benchmark settings are identical to
those described in ¬ß3 unless otherwise specified.
Results. Fig. 4 compares the aggregated performance (i.e., mean ‚àÜd over seven
LLMs and five independent runs) among existing EPS methods and the proposed
baseline on four AHD problems. Evidently, we observe that:
‚ó¶Performance varies significantly across different problems for all existing
LLM-based EPS methods, with no single method demonstrating consistent
superiority.
‚ó¶Specifically, the EoH method consistently outperforms all others in the TSP
problem throughout the search process, while the simple baseline (1+1)-EPS
shows competitive performance, except in the OBP (Weibull) problem.
6 We exclude UniXcoder and StarCoder from Table 2 as they are mainly designed for
code completion, which are not compatible with EoH and ReEvo that also require
comprehension of natural languages.


--- Page 13 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
13
CodeLlama-7B
CodeLlama-34B
DeepSeek-Coder-6.7B
DeepSeek-Coder-33B
GPT-3.5
GPT-4
Claude-3-Opus
CodeLlama-7B
4
8
12
16
FunSearch
EoH
ReEvo
(1+1)-EPS)
(a) Admissible Set
CodeLlama-7B
CodeLlama-34B
DeepSeek-Coder-6.7B
DeepSeek-Coder-33B
GPT-3.5
GPT-4
Claude-3-Opus
CodeLlama-7B
0.03
0.06
0.09
FunSearch
EoH
ReEvo
(1+1)-EPS)
(b) Travalling Salesman
CodeLlama-7B
CodeLlama-34B
DeepSeek-Coder-6.7B
DeepSeek-Coder-33B
GPT-3.5
GPT-4
Claude-3-Opus
CodeLlama-7B
0.4
0.8
1.2
1.6
FunSearch
EoH
ReEvo
(1+1)-EPS)
(c) Online Bin Packing (Weibull)
CodeLlama-7B
CodeLlama-34B
DeepSeek-Coder-6.7B
DeepSeek-Coder-33B
GPT-3.5
GPT-4
Claude-3-Opus
CodeLlama-7B
2
4
6
8
FunSearch
EoH
ReEvo
(1+1)-EPS)
(d) Online Bin Packing (OR)
Fig. 5: Radar plot comparison on the performance of the top-1 heuristics achieved
by various EPS methods with different choices of LLMs. The radius of each
vertex is calculated by the mean relative distances to the best-known optimum
(‚àÜd) averaged over five independent runs; hence, a smaller radius/enclosed area
indicates better performance.
These empirical findings suggest that there may not be universally effective
and efficient LLM-based EPS method for all AHD problems, reinforcing the
applicability of the ‚Äúno free lunch‚Äù (NFL) theorem to AHD.
4.2.2
Angle II: Dependency on the Choice of LLMs
Motivation. Existing LLM-based EPS methods are typically evaluated using
only one particular choice of LLMs [15,60,67]. This raises uncertainty regarding
the extent to which performance enhancements suggested by these methods can
be applied to other LLM choices. Compounding this issue, the predominant LLM
utilized in these EPS methods, i.e., GPT-3.5, is closed-source in nature. Should
the efficacy of existing EPS methods hinge significantly on closed-source LLMs,


--- Page 14 ---
14
R. Zhang et al.
the geographically restricted access to APIs may impede future development
built upon these methods.
Experimental Design. The experimental setup is identical to those described
in ¬ß4.2.1, except on the utilization of different LLMs. In this case, we do not
aggregate experiments across various LLMs. Instead, we aim to directly compare
the performance under different LLM choices for each EPS method.
Results. Fig. 5 compares the final performance of various EPS methods under
different LLMs across four AHD problems. From this comparison, we draw two
main observations:
‚ó¶There are significant variances in performance attributable to the choice of
LLM for all EPS methods, with the notable exception of the OBP (OR)
problem where this variance is marginal.
‚ó¶Specifically, the EoH method shows stable and robust performance on the
TSP problem across all LLMs, whereas the (1+1)-EPS‚Äôs performance varies
considerably due to its greedy nature.
These findings underscore the dependence of EPS methods‚Äô performance on the
specific LLMs employed.
4.2.3
Summary and Implications
The empirical observations from previous sections jointly suggest that the LLM-
based EPS algorithmic development is still in the early stages. We hypothesize
that more diverse benchmarks and applications are needed to establish a better
understanding of this emergent paradigm for AHD. Nevertheless, these prelim-
inary results also prompt us to (i) rethink the general efficacy of various com-
ponents (such as prompt engineering and search strategy) within the overall
paradigm, (ii) consider incorporating domain knowledge to LLM-based EPS al-
gorithm design, and (iii) use a variety of LLMs to gain a more robust evaluation
of the performance of EPS methods.
4.3
Search Cost
Computational Time. We present the computation time of each independent
run in Table 5. The computation time is estimated under the following settings:
1. Our evaluator for the admissible set and online bin packing problems uses
single-threaded evaluation, while for the TSP problem, we use eight CPU
processes to perform parallel acceleration at the TSP instance level.
2. We deploy and infer the open-source LLMs locally on a Tesla V100 GPU.
We load the LLM‚Äôs weights using float16 precision and generate responses
using the transformers library. We set the sampling temperature to the
default value of 1.0 and disable batch inference during text generation.
3. For each independent run, we use a single evaluator and LLM. The LLM
inference and function evaluation process is synchronous.


--- Page 15 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
15
Table 5: Approximate computational cost for various AHD tasks and LLM mod-
els. We use ‚ÄúCL‚Äù and ‚ÄúDS‚Äù to denote CodeLlama and DeepSeek-Coder models
respectively.
AHD Task
Open source LLMs
Close source LLMs
CL-7B DS-6.7B DS-33B CL-34B GPT-3.5 GPT-4 Claude3-Opus
AS
2.5 days
7 days
2 days
OBP (OR)
2.5 days
7 days
2 days
OBP (Weibull)
3 days
8 days
2.5 days
TSP
5 days
10 days
4.5 days
API Usage Pricing. Table 6 shows the official API prices for different closed-
source LLMs and the approximate cost of calling official APIs in each indepen-
dent run. Due to price fluctuations, the API usage prices should be based on
real-time prices or prices from third-party API resellers.
Table 6: Approximate API prices using different closed-source LLMs.
GPT-3.5 GPT-4 Claude 3 Opus
Model Input Prices (USD/K tokens)
0.001
0.01
0.015
Model Output Prices (USD/K tokens)
0.002
0.03
0.075
Prices for Each Independent Run (USD)
10
100
200
Summary. Existing LLM-based EPS methods still incur significant computa-
tional and API usage costs for the AHD task, indicating the need to conduct
further optimizations and studies to accelerate existing methods and reduce the
number of LLM queries.
5
Conclusion
This work presents a large-scale benchmark study comprising all existing LLM-
based EPS methods along with a new proposed baseline and four AHD problems
over (up-to) nine different LLMs and five independent runs. Based on the anal-
yses from multiple comparison angles, we reveal novel insights into the necessity
and the current progress of the LLM-based EPS paradigm for AHD. On top of
them, we summarize a few tangible implications for future research directions for
LLM-based EPS, along with the fully released source codes for fostering future
development.
Acknowledgments. The work described in this paper was supported by the Re-
search Grants Council of the Hong Kong Special Administrative Region, China (GRF
Project No. CityU11215622), the National Natural Science Foundation of China (Grant
No. 62106096), the Natural Science Foundation of Guangdong Province (Grant No.
2024A1515011759), the National Natural Science Foundation of Shenzhen (Grant No.
JCYJ20220530113013031).


--- Page 16 ---
16
R. Zhang et al.
A
Background Continued
A.1
Connection to Genetic Programming
Evolutionary program search (EPS) is conceptually similar to GP from the per-
spective of problem modeling (i.e., representing candidate solutions as executable
computer programs). One of the key differences between EPS and GP lies in the
representation of programs. GP uses relatively more abstract representations
(such as tree, graph, list, etc.) to encode programs, while EPS directly uses ex-
ecutable source codes to represent programs. Another key difference between
EPS and GP lies in the creation of new solutions. As the name suggested, GP
uses genetic operators (e.g., crossover, mutation, etc.) to generate new offspring
in an explicit manner; while EPS utilize large language models (LLMs) to drive
the search implicitly. This new way of using LLMs to create programs mitigates
several limitations regarding GP-based approaches [11]:
‚ó¶GP cannot leverage knowledge from descriptions or doc-string in natural
language that describes what the program is intended to do, and neither can
it generate language-based summarizations or hints to guide the following
evolution process [48]. However, LLMs have been trained on a number of
natural language data and can easily understand the given instructions as
well as do summarizations.
‚ó¶GP requires defining several problem-specific parameters, such as the func-
tion and the primitive sets. Designing such a set of operations is non-trivial
and requires domain knowledge about the problem. In contrast, vast amounts
of coding knowledge have been encoded within the LLM through pre-training
and finetuning on an extensive unlabeled code corpus. Therefore, LLM pos-
sesses the capability to design code akin to human-like proficiency.
‚ó¶Designing effective crossover and mutation operators for increasingly compli-
cated GP programs can be hard in practice [11,48]. Whereas state-of-the-art
LLMs can analyze code examples through in-context learning to generate
potentially improved code. Therefore, by combining parent programs as well
as contexts with reasonable prompting strategies, LLMs are able to generate
more diverse and effective programs.
Therefore, while modeling problems as computer programs are initially pioneered
by GP, the advent of LLM has significantly enhanced the ability to search under
this representation paradigm.
A.2
Existing EPS Methods
FunSearch [12] evolves heuristics for mathematical and combinatorial optimiza-
tion problems, achieving superior results compared to existing solutions on the
cap set [57] and admissible set problems [13]. The input to FunSearch consists
of a code template (called ‚Äúspecification‚Äù), which defines a template heuristic
to be evolved and a function for evaluating the searched heuristics. FunSearch


--- Page 17 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
17
employs an island-based evolution strategy with restart. Specifically, the island-
based population comprises multiple islands. Each island incorporates several
clusters, each of which collects heuristics with the same fitness scores.
During the evolutionary process, FunSearch selects a random island and
chooses k clusters (defaulting by two), then selects one function within each
cluster. In this process, shorter heuristic functions (with fewer lines) within the
cluster are preferred. FunSearch then samples N new heuristic functions based
on these heuristic examples. The predefined evaluator then evaluates the newly
obtained heuristics, and the valid (no errors or timeout in evaluation) heuristic
functions are then registered back to the same island. Periodically, FunSearch re-
moves half of the individuals from the worst-performing island (where the best
function has the worst fitness score) and replaces them with individuals from
other islands that perform better.
FunSearch utilizes few-shot prompt engineering while sampling new heuris-
tics from LLM. Specifically, the selected heuristic functions are renamed as func-
tion name v0, function name v1, ..., function name vk in order of increasing fit-
ness scores, providing an empty function call (function declaration without a
function body) def function name v(k+1) to let LLM complete the code. There-
fore, code completion models, such as StarCoder [51], can be used by FunSearch.
Evolution of Heuristic (EoH) [60] evolves heuristics for solving combina-
torial optimization problems, consequently outperforms heuristics generated by
automatic heuristic design (AHD) on traveling salesman (TSP) [16] and online
bin packing problems [17]. The input to the EoH is a task description including
a brief description of the AHD task, the input/output of the heuristic function,
and the goal of the heuristic function.
EoH employs the GA strategy, the initial population is obtained by sampling
from the LLM based on the task description, without the necessity of specifying
a template heuristic function. EoH proposes multiple crossover and mutation
strategies through various prompt settings, such as exploring new heuristics that
are completely different from existing heuristics, exploring new heuristics that
are based on the observation of existing heuristics, modifying the parameters for
one heuristic, etc.
EoH uses Chain of Thought (CoT) [52] prompt engineering and evolves not
only code but also thoughts of the heuristic function. The prompt content of
EoH is composed of ‚ë†genetic operator-related instructions, ‚ë°selected heuristic
functions (serve as ‚Äúparents‚Äù in crossover), and ‚ë¢corresponded ‚Äúthoughts‚Äù of
each selected heuristic function. During generation, LLM is asked not only to
implement the code of the function but also to describe the thought and the idea
of the code.
Reflective Evolution (ReEvo) [15] evolves heuristics for solving combinato-
rial optimization problems. ReEvo requires a template heuristic function and a
task description as the input.
Similar to EoH, ReEvo uses a GA framework. During initialization, the pop-
ulation is filled by performing mutation and crossover operators to the template
heuristic. The reflection mechanisms [19] are utilized in its crossover and muta-


--- Page 18 ---
18
R. Zhang et al.
tion operators. ReEvo proposes two types of reflection mechanisms, i.e., short-
term reflection and long-term reflection to let LLM analyze historical context.
The short-term reflection initially allows LLM to analyze the design rationale of
heuristic parents and provide generated hints, which are then encapsulated into
prompts to enable LLM to generate new individuals. The long-term reflection
summarizes clues generated by multiple short-term reflections and guides the
mutation operator.
Eureka [67] evolves reward function used in reinforcement learning, conse-
quently outperforms human experts on most tasks in tested RL environments.
Eureka is completely free of task-specific prompts, reward templates, as well as
few-shot examples. Eureka takes the source code of the RL environment and
task description as context, and zero-shot generates executable reward functions
from the LLM. Similar to EoH, multiple crossover and mutation operators are
proposed for editing reward functions, such as changing the hyperparameter of
existing reward components, changing the functional form of existing reward
components, and introducing new reward components. And a reward reflection
is also performed after evaluation to obtain feedback on how to optimize the
reward function design.
B
Template Heuristics
The template heuristic for the admissible set problem is illustrated in Listing 1.1.
Following the prior work [12], we employ a ‚Äúdummy‚Äù template heuristic that
simply returns a constant value. This inherently minimizes the influence of expert
knowledge in the design of the template heuristic function.
def
priority(el: tuple[int , ...] , n: int , w: int) -> float:
""" Returns
the
priority
with
which we want to add ‚Äòel‚Äô
to the set.
Args:
el: A vector
represents
possible
element of the set.
n : The
dimension of the ‚Äòel‚Äô vector.
w : Number of non -zero
elements in the ‚Äòel‚Äô vector.
Return:
The
priority of the ‚Äòel‚Äô vector.
"""
return 0.0
Listing 1.1: Template heuristic for admissible set problem.
The template heuristic for the online bin packing problem and the traveling
salesman problem is shown in Listing 1.2 and Listing 1.3. Since both functions
include array-type arguments and return values, it is challenging to design a
simple and valid template for relatively complex template heuristic functions.
Therefore, these templates are generated randomly by a large language model
(LLM) based on its function declaration and docstring. In our benchmark, we
make all LLM-based EPS methods use the same template for the same AHD
problem to guarantee fairness.


--- Page 19 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
19
import
numpy as np
def
priority(item: float , bins: np.ndarray) -> np.ndarray:
""" Returns
priority
with
which we want to add the item
to each bin.
Args:
item: Size of item to be added to the bin.
bins: Array of capacities
for each bin.
Return:
An array of the same size as bins with
priority
score
of each bin.
"""
penalty = np.arange(len(bins), 0,
-1)
scores = bins / (bins - item) - penalty
max_capacity_bins = np.where(bins == bins.max())[0]
for idx in max_capacity_bins :
scores[idx] = -np.inf
return
scores
Listing 1.2: Template heuristic for online bin packing (OR and Weibull).
import
numpy as np
def
priority(score_mat: np.ndarray , loc_opt: np.ndarray ,
edge_used:np.ndarray) -> np.ndarray:
""" Update the score of each edge in score_mat.
Args:
score_mat: Score matrix , each
element
represents
the ‚Äòscore ‚Äô of each edge.
loc_opt
: Local
optimal
solution
path.
edge_used: Matrix
representing
the number of
times
each edge is used.
Return:
updated_score_mat : the
updated
score_mat
"""
num_nodes = score_mat.shape [0]
updated_score_mat = np.copy(score_mat)
for i in range(num_nodes - 1):
cur_node = loc_opt[i]
next_node = loc_opt[i + 1]
updated_score_mat [cur_node , next_node] *= \
(1 + edge_used[cur_node , next_node ])
updated_score_mat [loc_opt [-1], loc_opt [0]] *= \
(1 + edge_used[loc_opt [-1], loc_opt [0]])
return
updated_score_mat
Listing 1.3: Template heuristic for travelling salesman problem.


--- Page 20 ---
20
R. Zhang et al.
C
More Results and Analysis
C.1
Ablation Study for EoH under Different Experimental Settings
In this section, we present an ablation study on the different experimental set-
tings of EoH. As mentioned in Sec. ¬ß3, we modified the default EoH settings to
standardize the initialization method across all EPS methods:
‚Äì The template program is not required for the default EoH settings, as it fills
the population by sampling from LLM according to the task-specific prompt.
In our benchmark, we initially incorporate a template heuristic into the
initial population, and repeatedly apply crossover and mutation operators
to the existing individuals in the population to generate new individuals
until the desired population size is achieved.
‚Äì We also increase the default population size from 20 to 100 considering that
more sampled heuristics are obtained (2,000 in default EoH settings and
10,000 in our benchmark).
Table 7 compares the performance using different experimental settings. We use
EoH-D to denote EoH with default settings, where the template heuristic is not
provided during initialization, and the population size is set to 20. However,
we maintain the maximum number of sampled heuristics to 10,000 to promise
consistency with our benchmark settings. We notice that the performance vari-
ation is notable in the admissible set problem, while it is marginal in the other
problems. This suggests that applying the default settings, i.e., initializing the
population by fully sampling from LLM, and a relatively smaller population size,
should be a more effective setting for EoH.
Table 7: The performance of the top-1 heuristics achieved by two EoH settings
with 10,000 query budgets. We use EoH and EoH-D to denote the benchmark
settings in this work, and the default settings in EoH‚Äôs paper, respectively. The
performance is measured as the mean relative distance to the best-known opti-
mum (‚àÜd) averaged over five independent runs using the GPT-3.5 model. Lower
‚àÜd indicates better performance.
EoH Setting Admissible Set Online Bin Packing Travelling Salesman (√ó10‚àí2)
EoH
7.89
3.81
3.26
EoH-D
6.85
3.82
3.20
C.2
More Results on the Impact of Query Budget
This section is a continuation of Sec. ¬ß4.1.1, where we demonstrate detailed
results on individual AHD problems and LLM choices under different query
budges. In Fig. 6 and Fig. 7, we visualize the performance of the top-5‚Ä∞ heuris-
tics achieved by standalone LLM under different query budgets. The standalone


--- Page 21 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
21
500
2000
5000
10000
Number of Trials
5
10
15
20
25
30
35
40
Relative Distance to Optimum
d (%)
Admissible Set
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
3.5
4.0
4.5
5.0
5.5
6.0
Online Bin Packing
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
0.0
0.5
1.0
1.5
2.0
2.5
Traveling Salesman
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
(a) CodeLlama-7B
500
2000
5000
10000
Number of Trials
5
10
15
20
25
30
35
40
Relative Distance to Optimum
d (%)
Admissible Set
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
3.5
4.0
4.5
5.0
5.5
6.0
Online Bin Packing
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Traveling Salesman
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
(b) CodeLlama-34B
500
2000
5000
10000
Number of Trials
5
10
15
20
25
30
35
40
Relative Distance to Optimum
d (%)
Admissible Set
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
3.0
3.5
4.0
4.5
5.0
5.5
6.0
Online Bin Packing
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
Traveling Salesman
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
(c) DeepSeek-Coder-6.7B
500
2000
5000
10000
Number of Trials
5
10
15
20
25
30
35
40
Relative Distance to Optimum
d (%)
Admissible Set
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
3.5
4.0
4.5
5.0
5.5
6.0
Online Bin Packing
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
Traveling Salesman
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
(d) DeepSeek-Coder-33B
Fig. 6: Convergence curve comparison on the performance of the top-5‚Ä∞ heuris-
tics generated by various LLMs. The mean relative distance to the best-known
optimum (‚àÜd) aggregated over five independent runs are denoted with markers,
while the standard deviations of ‚àÜd are highlighted with the shaded regions.
LLM is denoted as ‚ÄúRandomSample‚Äù in the caption. We also provide the results
of various LLM-based EPS for comparison.


--- Page 22 ---
22
R. Zhang et al.
500
2000
5000
10000
Number of Trials
5
10
15
20
25
30
35
40
Relative Distance to Optimum
d (%)
Admissible Set
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
3.75
4.00
4.25
4.50
4.75
5.00
5.25
5.50
Online Bin Packing
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
0.1
0.0
0.1
0.2
0.3
0.4
0.5
0.6
Traveling Salesman
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
(a) GPT-3.5
500
2000
5000
10000
Number of Trials
5
10
15
20
25
30
35
40
Relative Distance to Optimum
d (%)
Admissible Set
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
3.5
4.0
4.5
5.0
5.5
6.0
Online Bin Packing
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
0.0
0.2
0.4
0.6
0.8
Traveling Salesman
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
(b) GPT-4
500
2000
5000
10000
Number of Trials
5
10
15
20
25
30
35
40
Relative Distance to Optimum
d (%)
Admissible Set
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
3.5
4.0
4.5
5.0
5.5
Online Bin Packing
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
500
2000
5000
10000
Number of Trials
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
Traveling Salesman
RandSample
FunSearch
EoH
ReEvo
(1+1)-EPS
(c) Claude 3 Opus
Fig. 7: Convergence curve comparison on the performance of the top-5‚Ä∞ heuris-
tics generated by various LLMs. The mean relative distance to the best-known
optimum (‚àÜd) aggregated over five independent runs are denoted with markers,
while the standard deviations of ‚àÜd are highlighted with the shaded regions.
Extensive results on different LLMs and AHD problems demonstrate that
while the performance of standalone LLMs on AHD problems generally improves
with increasing query budgets, several observations are also obtained:
‚Äì We observe a noticeable performance gap between standalone LLM and EPS
methods across various AHD problems and LLM choices. By using only 2,000
query budgets, the performance of the heuristics obtained by EPS methods
can approach or even exceed that of the standalone LLMs using 10,000 query
budgets. This further underscores the significance of integrating evolutionary
search methods with LLMs in AHD tasks.
‚Äì The heuristic obtained by (1+1)-EPS with 500 query budgets can outperform
standalone LLM with 10,000 query budgets under most LLM choices and
AHD tasks.


--- Page 23 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
23
CodeLlama7B
 
UniXcoder
StarCoder
CodeLlama7B
CodeLlama34B
DeepSeek6.7B
DeepSeek33B
 
GPT3.5
GPT4
Claude3Opus
0.0
2.5
5.0
7.5
10.0
12.5
15.0
Relative Distance to Optimum
d (%)
(1+1)-EPS
Standalone LLM without Search
Code LLM
General LLM
20
40
60
80
HumanEval
(
)
Fig. 8: Box plot comparison on the performance of the top-1% heuristics gener-
ated by LLMs with varying capacities under 10,000 query budgets. We group
LLMs into two categories: (1) LLMs specialized for coding tasks (with back-
ground shaded in
) and (2) general-purpose LLMs (with background shaded
in
). Then, the LLMs are arranged in the order of ascending model size within
each group. The color scale of the boxes corresponds with the scores on Hu-
manEval [62]. The performance is measured as the relative distance to the best-
known optimum (‚àÜd) aggregated over four AHD problems and five independent
runs. Lower ‚àÜd indicates better performance. The performance of the simple
baseline (1 + 1)-EPS with CodeLlama-7B is also provided as a reference.
‚Äì We find that after using 2,000 query budgets, the convergence rate of the EPS
methods slows down, which is particularly evident in the traveling salesman
problem.
C.3
Performance in Each AHD Problem and LLM Choice
This section is a continuation of Sec. ¬ß4.1.2, we present more elaborated results
comparing the performance of various LLM choices on individual AHD prob-
lems. Fig. 8 demonstrates the aggregated performance of the top-1% heuristics
generated by LLMs with varying capacities. The performance proposed baseline
(1+1)-EPS with CodeLlama-7B is provided as a reference. In Fig. 9, we provide
the performance of top-5‚Ä∞ heuristics generated by different LLMs on individual
AHD problems.
Fig. 8 and Fig. 9 further support the results presented in Sec. ¬ß4.1.2 that
LLMs with more capacity do not promise better performance on AHD problems,
coupling a relatively small capacity LLM (i.e., CodeLlama-7B) with search strat-
egy can make a difference. We draw two new observations from the comparison
results on three AHD problems in Fig. 9 that:
‚Äì In the online bin packing problem, the performance differences between dif-
ferent LLMs are minimal. However, in the admissible set and especially in
traveling salesman problems, the disparities are more explicit.


--- Page 24 ---
24
R. Zhang et al.
CodeLlama7B
 
UniXcoder
StarCoder
CodeLlama7B
CodeLlama34B
DeepSeek6.7B
DeepSeek33B
 
GPT3.5
GPT4
Claude3Opus
0
2
4
6
8
10
12
Relative Distance to Optimum
d (%)
(1+1)-EPS
Standalone LLM without Search
Code LLM
General LLM
20
40
60
80
HumanEval
(
)
(a) Admissible Set
CodeLlama7B
 
UniXcoder
StarCoder
CodeLlama7B
CodeLlama34B
DeepSeek6.7B
DeepSeek33B
 
GPT3.5
GPT4
Claude3Opus
1.0
1.5
2.0
2.5
3.0
3.5
4.0
Relative Distance to Optimum
d (%)
(1+1)-EPS
Standalone LLM without Search
Code LLM
General LLM
20
40
60
80
HumanEval
(
)
(b) Online Bin Packing
CodeLlama7B
 
UniXcoder
StarCoder
CodeLlama7B
CodeLlama34B
DeepSeek6.7B
DeepSeek33B
 
GPT3.5
GPT4
Claude3Opus
0.0
0.2
0.4
0.6
0.8
1.0
Relative Distance to Optimum
d (%)
(1+1)-EPS
Standalone LLM without Search
Code LLM
General LLM
20
40
60
80
HumanEval
(
)
(c) Traveling Salesman
Fig. 9: Box plot comparison on the performance of the top-5‚Ä∞ heuristics gen-
erated by LLMs with varying capacities under 10,000 query budgets. The per-
formance is measured as the relative distance to the best-known optimum (‚àÜd)
aggregated over four AHD problems and five independent runs. Lower ‚àÜd in-
dicates better performance. We demonstrate detailed comparison results on (a)
admissible set, (b) online bin packing, and (c) traveling salesman problems.
‚Äì No single LLM demonstrates significantly superior performance across all
tasks. But conventional LM, such as UniXcoder, is consistently inferior to
modern LLMs on these three AHD tasks.


--- Page 25 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
25
C.4
Top-1 Performance Results
In this section, we present extensive experimental results comparing the perfor-
mance of the top-1 heuristics obtained by standalone LLMs and four LLM-based
EPS methods on four AHD tasks and seven LLM models. The performance is
measured by the relative distance to the best-known optimum (‚àÜd, lower is bet-
ter). Table 8 lists the average and standard deviation on the performance of
top-1 heuristics over five independent runs. Table 9 showcases the best perfor-
mance on the top-1 heuristics over five independent runs. The standalone LLM
is denoted by ‚ÄúRandSample‚Äù in these tables. We can conclude from both Table
8 and Table 9 that:
‚Äì Based on the mean and standard deviation results among five independent
runs (shown in Table 8), the LLM-based EPS methods generally outperform
the standalone LLM in the AS, OBP (Weibull), and TSP problems, with
the disparity being particularly notable in the TSP problem. However, in
the OBP (OR) problem, the LLM-based EPS methods do not demonstrate
a significant advantage.
‚Äì Similarly, the results based on the best performance among five independent
runs (shown in Table 9) also indicate that the LLM-based EPS methods
significantly outperform the standalone LLM in the AS, OBP (Weibull),
and TSP problems, but do not show a clear advantage in the OBP (OR)
problem.
‚Äì With a maximum query budget of 10,000, none of the existing EPS methods
demonstrate significant advantages over standalone LLMs in specific AHD
tasks, indicating the necessity of developing more effective EPS methods.
References
1. E. K. Burke, M. Gendreau, M. Hyde, G. Kendall, G. Ochoa, E. ¬®Ozcan, and R. Qu,
‚ÄúHyper-heuristics: A survey of the state of the art,‚Äù Journal of the Operational
Research Society, vol. 64, pp. 1695‚Äì1724, 2013.
2. T. St¬®utzle and M. L¬¥opez-Ib¬¥aÀúnez, ‚ÄúAutomated design of metaheuristic algorithms,‚Äù
Handbook of metaheuristics, pp. 541‚Äì579, 2019.
3. X. Wu, P. Consoli, L. Minku, G. Ochoa, and X. Yao, ‚ÄúAn evolutionary hyper-
heuristic for the software project scheduling problem,‚Äù in International Conference
on Parallel Problem Solving from Nature, 2016.
4. T. Chen, X. Chen, W. Chen, H. Heaton, J. Liu, Z. Wang, and W. Yin, ‚ÄúLearning
to optimize: A primer and a benchmark,‚Äù Journal of Machine Learning Research,
vol. 23, no. 189, pp. 1‚Äì59, 2022.
5. P. Cowling, G. Kendall, and E. Soubeiga, ‚ÄúA hyperheuristic approach to scheduling
a sales summit,‚Äù in Practice and Theory of Automated Timetabling, 2001.
6. J. Mockus, ‚ÄúApplication of bayesian approach to numerical methods of global and
stochastic optimization,‚Äù Journal of Global Optimization, vol. 4, pp. 347‚Äì365, 1994.
7. J. R. Koza, ‚ÄúGenetic programming as a means for programming computers by
natural selection,‚Äù Statistics and computing, vol. 4, pp. 87‚Äì112, 1994.


--- Page 26 ---
26
R. Zhang et al.
Table 8: The performance of the top-1 heuristics. The mean and standard de-
viation of the relative distance to the best-known optimum (‚àÜd) over five in-
dependent runs are reported. Lower ‚àÜd indicates better performance. We use
‚ÄúCL‚Äù and ‚ÄúDS‚Äù to denote the CodeLlama and DeepSeek model respectively.
We use ‚ÄúAS‚Äù, ‚ÄúOR‚Äù, ‚ÄúWEI‚Äù, and ‚ÄúTSP‚Äù to denote admissible set, online bin
packing (OR), online bin packing (Weibull), and traveling salesman problem,
respectively.
Task
Method
CL-7B
CL-34B
DS-6.7B
DS-33B
GPT-3.5
GPT-4
Claude 3
AS
RandSample 9.66¬±0.73 10.06¬±0.80 8.82¬±0.76
9.96¬±0.37 9.89¬±0.62 10.12¬±0.79 9.79¬±0.67
FunSearch
10.16¬±3.45 6.73¬±0.46
6.89¬±0.43
6.49¬±1.02 7.33¬±0.52 6.59¬±0.78 7.49¬±0.36
EoH
14.09¬±5.43 7.26¬±0.90
6.83¬±0.33
7.59¬±0.28 7.89¬±0.08 7.83¬±0.69 8.33¬±0.45
ReEvo
10.79¬±6.16 9.89¬±4.31 11.46¬±6.12 10.72¬±3.93 7.03¬±0.46 7.16¬±0.63 6.93¬±0.58
(1+1)-EPS
9.26¬±2.90 11.26¬±6.91 7.09¬±0.94
6.36¬±0.12 7.46¬±0.71 6.86¬±0.21 9.39¬±5.02
OR
RandSample 6.64¬±0.21
6.78¬±0.08
6.84¬±0.13
6.98¬±0.00 6.71¬±0.13 6.67¬±0.00 6.91¬±0.05
FunSearch
5.89¬±0.27
6.84¬±0.05
6.54¬±0.21
6.98¬±0.00 6.37¬±0.08 6.09¬±0.19 6.19¬±0.13
EoH
6.91¬±0.10
6.88¬±0.08
6.88¬±0.15
6.95¬±0.05 6.95¬±0.05 6.61¬±0.26 6.78¬±0.15
ReEvo
6.61¬±0.19
6.64¬±0.13
6.74¬±0.34
6.74¬±0.34 6.95¬±0.05 5.99¬±0.43 6.50¬±0.40
(1+1)-EPS
6.47¬±0.29
6.47¬±0.29
6.02¬±0.51
6.02¬±0.51 6.78¬±0.15 5.92¬±0.13 6.06¬±0.08
WEI
RandSample 0.99¬±0.08
1.07¬±0.21
1.33¬±0.01
1.34¬±0.01 1.43¬±0.37 0.94¬±0.07 1.75¬±0.32
FunSearch
0.64¬±0.04
0.63¬±0.03
0.64¬±0.01
0.77¬±0.06 0.72¬±0.05 0.63¬±0.03 0.72¬±0.09
EoH
0.75¬±0.01
0.73¬±0.03
0.74¬±0.04
0.69¬±0.06 0.67¬±0.03 0.70¬±0.03 0.69¬±0.01
ReEvo
0.71¬±0.05
0.70¬±0.01
0.92¬±0.27
0.87¬±0.07 0.65¬±0.03 0.76¬±0.07 0.64¬±0.04
(1+1)-EPS
0.83¬±0.23
0.80¬±0.08
0.67¬±0.06
0.89¬±0.20 1.56¬±1.03 0.79¬±0.08 0.68¬±0.05
TSP
(√ó10‚àí2)
RandSample 1.97¬±0.00
5.31¬±0.02 13.69¬±0.03 10.37¬±0.04 2.19¬±0.02 2.88¬±0.01 9.64¬±0.01
FunSearch
0.33¬±0.00
0.08¬±0.00
0.37¬±0.00
0.38¬±0.00 4.16¬±0.04 1.73¬±0.00 3.54¬±0.02
EoH
2.28¬±0.01
0.22¬±0.00
0.23¬±0.00
1.20¬±0.01 0.33¬±0.00 0.18¬±0.00 0.12¬±0.00
ReEvo
2.00¬±0.02
5.45¬±0.06
0.26¬±0.00
8.64¬±0.06 5.80¬±0.06 0.46¬±0.00 0.98¬±0.00
(1+1)-EPS
1.80¬±0.02
1.73¬±0.02
0.70¬±0.00
1.82¬±0.02 3.97¬±0.00 5.75¬±0.03 3.87¬±0.01
8. W. B. Langdon and R. Poli, Foundations of genetic programming. Springer Science
& Business Media, 2013.
9. F. Zhang, Y. Mei, S. Nguyen, and M. Zhang, ‚ÄúSurvey on genetic programming and
machine learning techniques for heuristic design in job shop scheduling,‚Äù IEEE
Transactions on Evolutionary Computation, vol. 28, no. 1, pp. 147‚Äì167, 2024.
10. F. Zhang, Y. Mei, S. Nguyen, and M. Zhang, ‚ÄúImportance-aware genetic program-
ming for automated scheduling heuristics learning in dynamic flexible job shop
scheduling,‚Äù in International Conference on Parallel Problem Solving from Nature,
2022.
11. M. O‚ÄôNeill, L. Vanneschi, S. Gustafson, and W. Banzhaf, ‚ÄúOpen issues in ge-
netic programming,‚Äù Genetic Programming and Evolvable Machines, vol. 11, no. 3,
pp. 339‚Äì363, 2010.
12. B. Romera-Paredes, M. Barekatain, A. Novikov, M. Balog, M. P. Kumar,
E. Dupont, F. J. Ruiz, J. S. Ellenberg, P. Wang, O. Fawzi, et al., ‚ÄúMathemati-
cal discoveries from program search with large language models,‚Äù Nature, vol. 625,
no. 7995, pp. 468‚Äì475, 2024.
13. T. Tao and V. H. Vu, Additive combinatorics. Cambridge University Press, 2006.
14. F. Liu, X. Tong, M. Yuan, X. Lin, F. Luo, Z. Wang, Z. Lu, and Q. Zhang, ‚ÄúEvo-
lution of heuristics: Towards efficient automatic algorithm design using large lan-


--- Page 27 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
27
Table 9: The performance of the top-1 heuristics. The minimum of the relative
distance to the best-known optimum (‚àÜd) over five independent runs is reported.
Lower ‚àÜd indicates better performance. We use ‚ÄúCL‚Äù and ‚ÄúDS‚Äù to denote the
CodeLlama and DeepSeek model respectively. We use ‚ÄúAS‚Äù, ‚ÄúOR‚Äù, ‚ÄúWEI‚Äù, and
‚ÄúTSP‚Äù to denote admissible set, online bin packing (OR), online bin packing
(Weibull), and traveling salesman problem, respectively.
Task
Method
CL-7B CL-34B DS-6.7B DS-33B GPT-3.5 GPT-4 Claude 3
AS
RandSample
9.09
9.49
7.79
9.49
9.09
9.29
8.89
FunSearch
6.49
6.09
6.49
5.09
6.59
5.59
6.99
EoH
7.29
5.99
6.39
7.19
7.79
6.99
7.69
ReEvo
5.89
6.69
6.59
7.79
6.39
6.29
6.29
(1+1)-EPS
6.29
5.59
5.99
6.19
6.49
6.59
4.50
OR
RandSample
6.37
6.67
6.67
6.98
6.57
6.67
6.88
FunSearch
5.65
6.78
6.26
6.98
6.26
5.95
6.06
EoH
6.78
6.78
6.67
6.88
6.88
6.26
6.57
ReEvo
6.47
6.47
6.26
6.26
6.88
5.54
5.95
(1+1)-EPS
6.26
6.26
5.34
5.34
6.67
5.75
5.95
WEI
RandSample
0.88
0.84
1.32
1.32
0.91
0.85
1.44
FunSearch
0.59
0.59
0.63
0.71
0.68
0.59
0.63
EoH
0.73
0.69
0.70
0.64
0.63
0.68
0.68
ReEvo
0.65
0.69
0.67
0.77
0.62
0.67
0.60
(1+1)-EPS
0.65
0.73
0.60
0.68
0.76
0.73
0.62
TSP
(√ó10‚àí2)
RandSample
1.56
2.38
11.26
4.47
0.56
1.40
8.78
FunSearch
0.14
0.03
0.19
0.29
1.28
1.32
1.69
EoH
0.49
0.08
0.19
0.41
0.16
0.06
0.04
ReEvo
0.36
0.35
0.22
0.45
0.33
0.28
0.58
(1+1)-EPS
0.24
0.08
0.32
0.64
3.37
3.87
2.47
guage model,‚Äù in International Conference on Machine Learning, 2024.
15. H. Ye, J. Wang, Z. Cao, and G. Song, ‚ÄúReevo: Large language models as hyper-
heuristics with reflective evolution,‚Äù arXiv preprint arXiv:2402.01145, 2024.
16. R. Matai, S. P. Singh, and M. L. Mittal, ‚ÄúTraveling salesman problem: an overview
of applications, formulations, and solution approaches,‚Äù Traveling salesman prob-
lem, theory and applications, vol. 1, no. 1, pp. 1‚Äì25, 2010.
17. S. S. Seiden, ‚ÄúOn the online bin packing problem,‚Äù Journal of the ACM, vol. 49,
no. 5, pp. 640‚Äì671, 2002.
18. N.
Hansen,
‚ÄúThe
cma
evolution
strategy:
A
tutorial,‚Äù
arXiv
preprint
arXiv:1604.00772, 2016.
19. T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Nee-
lakantan, P. Shyam, G. Sastry, A. Askell, et al., ‚ÄúLanguage models are few-shot
learners,‚Äù in Advances in neural information processing systems, 2020.
20. E. K. Burke, M. Hyde, G. Kendall, G. Ochoa, E. ¬®Ozcan, and J. R. Woodward, A
Classification of Hyper-heuristic Approaches, pp. 449‚Äì468. Boston, MA: Springer
US, 2010.
21. X. He, K. Zhao, and X. Chu, ‚ÄúAutoml: A survey of the state-of-the-art,‚Äù
Knowledge-based systems, vol. 212, p. 106622, 2021.


--- Page 28 ---
28
R. Zhang et al.
22. E. K. Burke, S. Petrovic, and R. Qu, ‚ÄúCase-based heuristic selection for timetabling
problems,‚Äù Journal of Scheduling, vol. 9, pp. 115‚Äì132, 2006.
23. H.-L. F. P. Ross and D. Corne, ‚ÄúA promising hybrid ga/heuristic approach for
open-shop scheduling problems,‚Äù in European conference on artificial intelligence,
1994.
24. E. Hart, P. Ross, and J. Nelson, ‚ÄúSolving a real-world problem using an evolving
heuristically driven schedule builder,‚Äù Evolutionary Computation, vol. 6, no. 1,
pp. 61‚Äì80, 1998.
25. H. Terashima-Mar¬¥ƒ±n, E. Flores-Alvarez, and P. Ross, ‚ÄúHyper-heuristics and clas-
sifier systems for solving 2d-regular cutting stock problems,‚Äù in annual conference
on genetic and evolutionary computation, 2005.
26. J. V. Rodr¬¥ƒ±guez, S. Petrovic, and A. Salhi, ‚ÄúA combined meta-heuristic with hyper-
heuristic approach to the scheduling of the hybrid flow shop with sequence de-
pendent setup times and uniform machines,‚Äù in Multidisciplinary International
Conference on Scheduling: Theory and Applications. MISTA: Paris, France, 2007.
27. E. K. Burke, M. R. Hyde, and G. Kendall, ‚ÄúEvolving bin packing heuristics with
genetic programming,‚Äù in International Conference on Parallel Problem Solving
from Nature, 2006.
28. G. Duflo, E. Kieffer, M. R. Brust, G. Danoy, and P. Bouvry, ‚ÄúA gp hyper-heuristic
approach for generating tsp heuristics,‚Äù in 2019 IEEE International Parallel and
Distributed Processing Symposium Workshops, 2019.
29. C. Rego, D. Gamboa, F. Glover, and C. Osterman, ‚ÄúTraveling salesman prob-
lem heuristics: Leading methods, implementations and latest advances,‚Äù European
journal of operational research, vol. 211, no. 3, pp. 427‚Äì441, 2011.
30. R. Drechsler and B. Becker, ‚ÄúLearning heuristics by genetic algorithms,‚Äù in ASP-
DAC‚Äô95/CHDL‚Äô95/VLSI‚Äô95 with EDA Technofair, 1995.
31. J. Branke, S. Nguyen, C. W. Pickardt, and M. Zhang, ‚ÄúAutomated design of
production scheduling heuristics: A review,‚Äù IEEE Transactions on Evolutionary
Computation, vol. 20, no. 1, pp. 110‚Äì124, 2015.
32. A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,  L. Kaiser,
and I. Polosukhin, ‚ÄúAttention is all you need,‚Äù Advances in neural information
processing systems, 2017.
33. J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida,
J. Altenschmidt, S. Altman, S. Anadkat, et al., ‚ÄúGpt-4 technical report,‚Äù arXiv
preprint arXiv:2303.08774, 2023.
34. W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,
J. Zhang, Z. Dong, et al., ‚ÄúA survey of large language models,‚Äù arXiv preprint
arXiv:2303.18223, 2023.
35. H. Tian, W. Lu, T. O. Li, X. Tang, S.-C. Cheung, J. Klein, and T. F. Bissyand¬¥e,
‚ÄúIs chatgpt the ultimate programming assistant‚Äìhow far is it?,‚Äù arXiv preprint
arXiv:2304.11938, 2023.
36. C. Yu, X. Liu, C. Tang, W. Feng, and J. Lv, ‚ÄúGpt-nas: Neural architecture search
with the generative pre-trained model,‚Äù arXiv preprint arXiv:2305.05351, 2023.
37. S. Zhang, C. Gong, L. Wu, X. Liu, and M. Zhou, ‚ÄúAutoml-gpt: Automatic machine
learning with gpt,‚Äù arXiv preprint arXiv:2305.02499, 2023.
38. Y. Zhou, A. I. Muresanu, Z. Han, K. Paster, S. Pitis, H. Chan, and J. Ba,
‚ÄúLarge language models are human-level prompt engineers,‚Äù arXiv preprint
arXiv:2211.01910, 2022.


--- Page 29 ---
Understanding the Importance of Evolutionary Search in AHD with LLMs
29
39. X. Wang, C. Li, Z. Wang, F. Bai, H. Luo, J. Zhang, N. Jojic, E. P. Xing, and
Z. Hu, ‚ÄúPromptagent: Strategic planning with language models enables expert-
level prompt optimization,‚Äù arXiv preprint arXiv:2310.16427, 2023.
40. E. Zelikman, E. Lorch, L. Mackey, and A. T. Kalai, ‚ÄúSelf-taught optimizer (stop):
Recursively self-improving code generation,‚Äù arXiv preprint arXiv:2310.02304,
2023.
41. S. Liu, C. Chen, X. Qu, K. Tang, and Y.-S. Ong, ‚ÄúLarge language models as
evolutionary optimizers,‚Äù arXiv preprint arXiv:2310.19046, 2023.
42. F. Liu, X. Lin, Z. Wang, S. Yao, X. Tong, M. Yuan, and Q. Zhang, ‚ÄúLarge
language model for multi-objective evolutionary optimization,‚Äù arXiv preprint
arXiv:2310.12541, 2023.
43. A. Chen, D. Dohan, and D. So, ‚ÄúEvoprompting: Language models for code-level
neural architecture search,‚Äù Advances in Neural Information Processing Systems,
2024.
44. E. Meyerson, M. J. Nelson, H. Bradley, A. Gaier, A. Moradi, A. K. Hoover, and
J. Lehman, ‚ÄúLanguage model crossover: Variation through few-shot prompting,‚Äù
arXiv preprint arXiv:2302.12170, 2023.
45. E. Hemberg, S. Moskal, and U.-M. O‚ÄôReilly, ‚ÄúEvolving code with a large language
model,‚Äù arXiv preprint arXiv:2401.07102, 2024.
46. C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le, D. Zhou, and X. Chen, ‚ÄúLarge language
models as optimizers,‚Äù arXiv preprint arXiv:2309.03409, 2023.
47. Q. Guo, R. Wang, J. Guo, B. Li, K. Song, X. Tan, G. Liu, J. Bian, and Y. Yang,
‚ÄúConnecting large language models with evolutionary algorithms yields powerful
prompt optimizers,‚Äù arXiv preprint arXiv:2309.08532, 2023.
48. J. Lehman, J. Gordon, S. Jain, K. Ndousse, C. Yeh, and K. O. Stanley, ‚ÄúEvolution
through large models,‚Äù 2022.
49. X. Wu, S.-h. Wu, J. Wu, L. Feng, and K. C. Tan, ‚ÄúEvolutionary computa-
tion in the era of large language model: Survey and roadmap,‚Äù arXiv preprint
arXiv:2401.10034, 2024.
50. ‚ÄúCode models overview,‚Äù 2023.
51. R. Li, L. B. Allal, Y. Zi, N. Muennighoff, D. Kocetkov, C. Mou, M. Marone,
C. Akiki, J. Li, J. Chim, et al., ‚ÄúStarcoder: may the source be with you!,‚Äù arXiv
preprint arXiv:2305.06161, 2023.
52. J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou,
et al., ‚ÄúChain-of-thought prompting elicits reasoning in large language models,‚Äù
Advances in neural information processing systems, 2022.
53. D. Guo, Q. Zhu, D. Yang, Z. Xie, K. Dong, W. Zhang, G. Chen, X. Bi, Y. Wu, Y. Li,
et al., ‚ÄúDeepseek-coder: When the large language model meets programming‚Äìthe
rise of code intelligence,‚Äù arXiv preprint arXiv:2401.14196, 2024.
54. B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu,
T. Remez, J. Rapin, et al., ‚ÄúCode llama: Open foundation models for code,‚Äù arXiv
preprint arXiv:2308.12950, 2023.
55. J. H. Holland, ‚ÄúGenetic algorithms,‚Äù Scientific american, vol. 267, no. 1, pp. 66‚Äì73,
1992.
56. N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, and S. Yao, ‚ÄúReflexion: Lan-
guage agents with verbal reinforcement learning,‚Äù Advances in Neural Information
Processing Systems, 2024.
57. J. Grochow, ‚ÄúNew applications of the polynomial method: the cap set conjecture
and beyond,‚Äù Bulletin of the American Mathematical Society, vol. 56, no. 1, pp. 29‚Äì
64, 2019.


--- Page 30 ---
30
R. Zhang et al.
58. J. E. Beasley, ‚ÄúOr-library: distributing test problems by electronic mail,‚Äù Journal
of the operational research society, vol. 41, no. 11, pp. 1069‚Äì1072, 1990.
59. I. CastiÀúneiras, M. De Cauwer, and B. O‚ÄôSullivan, ‚ÄúWeibull-based benchmarks for
bin packing,‚Äù in International Conference on Principles and Practice of Constraint
Programming, 2012.
60. F. Liu, X. Tong, M. Yuan, X. Lin, F. Luo, Z. Wang, Z. Lu, and Q. Zhang, ‚ÄúAn ex-
ample of evolutionary computation+ large language model beating human: Design
of efficient guided local search,‚Äù arXiv preprint arXiv:2401.02051, 2024.
61. W. Kool, H. Van Hoof, and M. Welling, ‚ÄúAttention, learn to solve routing prob-
lems!,‚Äù arXiv preprint arXiv:1803.08475, 2018.
62. M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards,
Y. Burda, N. Joseph, G. Brockman, et al., ‚ÄúEvaluating large language models
trained on code,‚Äù arXiv preprint arXiv:2107.03374, 2021.
63. D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Stein-
hardt, ‚ÄúMeasuring massive multitask language understanding,‚Äù arXiv preprint
arXiv:2009.03300, 2020.
64. D. Guo, S. Lu, N. Duan, Y. Wang, M. Zhou, and J. Yin, ‚ÄúUniXcoder: Unified cross-
modal pre-training for code representation,‚Äù in Annual Meeting of the Association
for Computational Linguistics, 2022.
65. Anthropic, ‚ÄúThe claude 3 model family: Opus, sonnet, haiku,‚Äù 2024.
66. J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‚ÄúBERT: Pre-training of deep
bidirectional transformers for language understanding,‚Äù in Conference of the North
American Chapter of the Association for Computational Linguistics, June 2019.
67. Y. J. Ma, W. Liang, G. Wang, D.-A. Huang, O. Bastani, D. Jayaraman, Y. Zhu,
L. Fan, and A. Anandkumar, ‚ÄúEureka: Human-level reward design via coding large
language models,‚Äù in International Conference on Learning Representations, 2024.
