--- Page 1 ---
arXiv:2504.14667v2  [cs.LG]  2 Jul 2025
1
Efficient Split Federated Learning for Large
Language Models over Communication Networks
Kai Zhao, Zhaohui Yang, Ye Hu, Mingzhe Chen, Senior Member, IEEE, Chen Zhu,
Zhaoyang Zhang, Senior Member, IEEE
Abstractâ€”Fine-tuning
pre-trained
large
language
models
(LLMs) in a distributed manner poses significant challenges on
resource-constrained edge networks. To address this challenge,
we propose SflLLM, a novel framework that integrates split fed-
erated learning with parameter-efficient fine-tuning techniques.
By leveraging model splitting and low-rank adaptation (LoRA),
SflLLM reduces the computational burden on edge devices.
Furthermore, the introduction of a federated server facilitates
parallel training and enhances data privacy. To accommodate
heterogeneous communication conditions and diverse compu-
tational capabilities of edge devices, as well as the impact of
LoRA rank selection on model convergence and training cost,
we formulate a joint optimization problem of both communica-
tion and computation resource. The formulated problem jointly
optimizes subchannel allocation, power control, model splitting
point selection, and LoRA rank configuration, aimed at mini-
mizing total training delay. An iterative optimization algorithm
is proposed to solve this problem efficiently. Specifically, a greedy
heuristic is employed for subchannel allocation, the power control
subproblem is reformulated as a convex optimization problem
using auxiliary variables, and an exhaustive search is adopted
for optimal split position and rank selection. Simulation results
demonstrate that the proposed SflLLM framework achieves com-
parable model accuracy while significantly reducing client-side
computational requirements. Furthermore, the proposed resource
allocation scheme and adaptive LoRA rank selection strategy
notably reduce the training latency compared to conventional
approaches.
Index Termsâ€”Split federated learning, large language models,
resource management, low-rank adaptation, edge intelligence.
I. INTRODUCTION
T
HE rapid advancement of pre-trained models has has
significantly advanced fields such as computer vision and
natural language processing [1], [2]. According to scaling
laws [3], increasing the number of model parameters and
training data volume typically leads to improved model per-
formance. Meanwhile, with the proliferation of lnternet of
things (IoT) devices and sensors within wireless networks,
edge devices have become capable of generating and collecting
vast amounts of data. Effectively leveraging this distributed
data can further enhance model performance. However, due
to privacy concerns and communication constraints [4], [5],
transmitting raw data to a central server is often impractical.
To overcome these challenges, federated learning (FL) has
emerged as a promising paradigm for the distributed fine-
tuning of large language models (LLMs) [6]â€“[8]. FL preserves
privacy and reduces communication overhead by transmitting
model parameters rather than raw data [9].
Nevertheless, as the size of models continues to increase,
fully loading and fine-tuning these large-scale models on
resource-limited edge devices remains computationally infea-
sible. To mitigate this challenge, split learning (SL) has been
proposed [10], which partitions the model and offloads compu-
tationally intensive tasks to a more resourceful server. Instead
of exchanging entire model parameters, SL allows clients
to transmit only intermediate activations and corresponding
gradients, thereby substantially reducing communication over-
head [11], [12]. However, a critical drawback of SL is its
dependence on sequential interactions between clients and
the server, severely restricting the overall training efficiency.
To address this limitation, split federated learning (SFL) has
been recently introduced, effectively combining the privacy
preservation and parallelization advantages of FL with the
communication efficiency of SL [13]. Consequently, SFL is
emerging as a highly promising framework for distributed
training across heterogeneous edge computing environments.
Fine-tuning pre-trained models on downstream tasks typi-
cally yields substantial improvements in performance. How-
ever, as the scale of model parameters increases, performing
full fine-tuning becomes computationally prohibitive due to
intensive resource requirements. While model quantization
provides a promising approach for reducing computational
overhead by compressing models, it typically requires spe-
cialized hardware capable of low-bit computations. A more
practical and hardware-compatible approach is low-rank adap-
tation (LoRA) [14], [15], which introduces trainable low-rank
modules into the existing model structure, significantly de-
creasing the number of trainable parameters while maintaining
comparable performance to full fine-tuning. When combined
with SFL, LoRA further reduces client-side computational
workload and the volume of uploaded data, enabling more
communication-efficient fine-tuning of large-scale models. Al-
though prior studies has explored the integration of FL with
LoRA, the combination of LoRA specifically with SFL re-
mains under-explored in existing literature [16].
Although resource-rich cloud environments can easily ac-
commodate the computational demands associated with large-
scale models, resource-constrained edge devices typically lack
such computational capacities. Therefore, minimizing compu-
tational overhead becomes essential for effective deployment
in these edge computing scenarios. Furthermore, the strag-
gler effect prevalent in SFL can significantly hinder training
progress, thus efficient resource allocation strategies are vi-
tal for reducing latency and maintaining training efficiency.
Additionally, existing studies often focus solely on a single
training round and neglecting the comprehensive impact of
model training hyperparameters on the total latency across
the entire training process. Moreover, SFL involves extensive


--- Page 2 ---
2
parameter exchanges between clients and two separate servers,
where computation and communication are inherently coupled.
Thus, jointly optimizing computation and communication pro-
cesses represents a necessary and promising perspective for
enhancing the efficiency of the training process [17].
In this paper, we propose SflLLM, a novel split feder-
ated learning framework specifically designed for efficiently
fine-tuning LLMs within resource-constrained edge networks.
SflLLM integrates LoRA and SFL techniques to achieve effi-
cient distributed training. The proposed framework leverages
distributed co-training mechanisms to securely and effectively
harness data dispersed across edge devices, while the use of
model splitting significantly alleviates local resource require-
ments. Moreover, the incorporation of efficient fine-tuning
techniques reduces both computational burden and commu-
nication overhead.
Nevertheless, due to the inherent heterogeneity in channel
conditions and computational capabilities among edge devices,
the emergence of stragglers can substantially degrade overall
training efficiency [18], [19]. A appropriately designed re-
source allocation and model splitting strategy can mitigate the
adverse impacts of stragglers and accelerate training speed,
thereby enhancing overall learning efficiency. Additionally, the
rank chosen for the LoRA module influences both computation
complexity and communication overhead, thereby affecting the
convergence speed of the training process. Proper selection of
LoRA rank strikes a balance between these overheads and can
significantly reduce total training delay.
To address these challenges, we formulate a comprehensive
optimization problem for SflLLM that involves subchannel
assignment, power control, split layer selection, and rank
selection. Subsequently, we develop an efficient algorithm
to solve the formulated optimization problem. The primary
contributions of this paper are summarized as follows:
â€¢ We propose the SflLLM framework for fine-tuning LLMs
in resource-constrained edge networks. Specifically, the
model is partitioned between the main server and clients,
significantly reducing computational load and memory
usage at the edge side. A federated server is introduced
to aggregate client models while effectively preserving
privacy. By employing LoRA techniques, the scale of
trainable parameters is minimized, substantially allevi-
ating the computational burden on edge devices and
reducing communication overhead for uploads to the
federated server, thus realizing a distributed framework
for fine-tuning LLMs with efficient communication and
computation.
â€¢ We theoretically analyze how the rank of the LoRA
module affects training overhead and convergence speed
within the SflLLM framework. To achieve efficient model
training, we design a joint optimization strategy for
resource allocation and task offloading, specifically tar-
geting subchannel allocation, power control, model split
location, and LoRA rank selection. The objective of this
strategy is to minimize the training latency while meeting
the total power budget requirements.
â€¢ To address this problem, we propose an iterative al-
gorithm that alternately solves subproblems related to
subchannel assignment, power control, split location, and
rank selection. Specifically, the subchannel assignment
subproblem is solved using a greedy algorithm, the
power allocation subproblem via convex optimization
techniques, and both the split location and rank selection
subproblems are addressed through exhaustive search
methods.
â€¢ Extensive simulation demonstrate that the proposed
SflLLM framework effectively accomplishes fine-tuning
tasks with high efficiency. Furthermore, the customized
resource allocation schemes and rank selection strategies
substantially reduce training latency compared to tradi-
tional methods.
The remainder of this paper is organized as follows: Section
II reviews related work. Sections III and IV introduce the sys-
tem model and framework of SflLLM, respectively. Sections
V and VI detail the formulation of the resource management
problem and the corresponding solution algorithm. Simulation
results and analysis are provided in Section VII. Finally, the
conclusions are drawn in Section VIII.
II. RELATED WORK
FL has emerged as a widely adopted distributed learning
framework, which effectively preserves data privacy while
maintaining communication efficiency. However, effectively
deploying FL in edge network, where client devices have
limited computational and communication resources, remains
a critical challenge for improving performance [20]. Extensive
research has addressed this limitations, focusing on model
compression techniques [21], optimized resource allocation
[22], hierarchical model aggregation [23], and effective client
selection strategies [24]. SL, another distributed learning
paradigm, mitigates some FL limitations [9] by offloading the
majority of the training workload to the server side [12]. This
significantly reduces computational cost and communication
overhead at the client. However, early SL implementations
[10] required clients to sequentially perform training, resulting
in low training efficiency. Split Federated Learning (SFL)
has been introduced to overcome this limitation [13]. By
combining the benefits of both SL and FL, SFL has become
a promising framework for distributed learning. Motivated
by its advantages, recent research has extensively explored
various aspects of SFL, including model splitting strategies
[25], model aggregation mechanisms [26], and client selection
methods tailored for wireless environments [27].
The effectiveness of SFL on small-scale models has been
demonstrated in several recent studies. For instance, a hi-
erarchical SFL framework was proposed in [28] to address
challenges such as single points of failure, fairness issues,
and slow convergence rates, achieving notable performance on
the MNIST dataset. For client heterogeneity, a ring-topology-
based SFL was developed in [29], which demonstrated better
convergence performance than benchmark methods on both
the independent and identically distributed (IID) and non-IID
datasets. This approach has been successfully applied to main-
stream networks, including ResNet18 [30], VGG16 [31], and
AlexNet [32], and also effectively prevents eavesdroppers from


--- Page 3 ---
3
recovering training data. However, SFL for LLMs remains
an area that has not been fully explored. Some research has
begun to focus on fine-tuning LLMs using FL architectures for
distributed collaborative training over wireless networks [6].
[33] introduces a low-parameter federated learning framework
employing cost-effective parameter construction, local model
fine-tuning, and global model aggregation using soft labeling
and LoRA modules. Additionally, [34] employs lightweight
adapters within LLMs to facilitate knowledge exchange be-
tween servers and clients, thereby maintaining data privacy
while minimizing overheads. Although these studies empha-
size lightweight techniques for efficient training and reduced
client workload, they fail to adequately address the resource
constraints on clients through model splitting techniques. In
this paper, we provide an efficient resource-constrained fine-
tuning approach for LLMs by combining SFL with LoRA.
SFL involves extensive parameter exchanges over wireless
networks, making it both a significant and challenging problem
to effectively utilize the resources available on edge devices
and central servers. In [35], the authors addressed a real-
world scenario with heterogeneous devices and a single split
point in a deep neural network. They formulated and solved a
joint optimization problem of split-point selection and band-
width allocation to minimize system latency. Additionally,
[36] proposed an efficient parallel split learning algorithm
that jointly optimizes client-side workloads and server-side
resource allocation while considering user heterogeneity. In
[28], the hierarchical SFL framework was introduced, solving
an optimization problem that accounted for device-relative
local accuracy, wireless resource allocation, task offloading,
and transmit power control, aiming to minimize latency and
energy consumption.Although these studies provide effective
solutions for resource allocation in traditional deep neural
network-based SFL, they do not specifically address the unique
requirements of fine-tuning LLMs or adapting pre-trained
models. To address this gap, in this paper, we propose an
optimization framework that jointly considers communication
resource allocation, task offloading, and fine-tuning hyperpa-
rameters for LLMs, explicitly accounting for the impact of
LoRA on SFL overheads.
III. SYSTEM MODEL
In this section, we describe the system model of the
proposed SflLLM framework, which lays the groundwork for
subsequent analysis and discussion. As depicted in Fig. 1, a
typical scenario for deploying SflLLM involves the following
three main components:
â€¢ Client: Clients typically consist of edge devices with
limited computational capabilities, such as medical IoT
devices. The first portion of the model is deployed on
these device, enabling each client to perform local for-
ward and backward propagation. Let K = {1, 2, . . . , K}
represent the set of participating clients, where K is the
total number of clients. The client k holds a local dataset
Dk = {xk,i, yk,i}Dk
i=1, where Dk denotes the number
of data samples. xk,i and yk,i represent the i-th input
and its corresponding label, respectively. We denote the
Encoder
Encoder
Encoder
â€¦
Ã— ğ‘™ğ‘
Encoder
Encoder
Encoder
â€¦
Encoder
Encoder
Encoder
â€¦
Encoder
Encoder
Encoder
â€¦
Add&Norm
Feed Forward
Add&Norm
Q
Client 1
Client 2
Client K
Main Server
Fed Server
Embedding
dataset
Encoder
Encoder
â€¦
Encoder
Original Pre-trained 
LLM Model
Softmax
Linear
Wğ‘
ğ‘Šğ‘ 
Î”ğ‘¾ğŸ
Ã— ğ‘™ğ‘ 
Activationsâ€™ 
gradients 
Embedding
dataset
Embedding
dataset
â€¦
Activations
Encoder
Softmax
Linear
Embedding
Î”ğ‘¾ğ‘
Î”ğ‘¾ğŸ
Î”ğ‘¾ğ‘²
Aggregation
Softmax
Linear
K
V
Encoder with LoRA
Inputs
Output 
Probabilities
Broadcast
Cut Layer
Fig. 1. Illustration of the proposed SflLLM framework over wireless networks.
pre-trained model parameters deployed on the client by
Wc, and the trainable parameters introduced through the
LoRA module as âˆ†Wc.
â€¢ Main Server: The main server is equipped with abundant
computational and communication resources. It is respon-
sible for executing the forward and backward propagation
for the latter portion of the model. The pre-trained model
parameters residing at the main server are denoted as
Ws, and the trainable parameters introduced by the LoRA
module are represented by âˆ†Ws.
â€¢ Federated Server: The federated server aggregates the
client-side trainable parameters after I rounds of local
training steps, subsequently updating them to form a
new global client model. For privacy enhancement, the
federated server and main server are typically maintained
by separate entities. This physical and logical separation
prevents attackers from easily reconstructing original
client data, even if parameters from both servers are
compromised simultaneously.
To evaluate the model performance across different learning
tasks, we define the loss function f(Wc/s, âˆ†Wc/s, xk,i, yk,i),
which measures the discrepancy between the model pre-
dictions
and
the
ground-truth
labels
for
a
given
in-
put
vector
xk,i
with
corresponding
label
yk,i,
under
the
current
model
parameters.
For
different
learning
tasks, the loss function will be different. For example,
f(Wc/s, âˆ†Wc/s, xk,i, yk,i) =
1
2(xT
k,i(Wc/s + âˆ†Wc/s)) âˆ’
yk,i)2 for linear regression and f(Wc/s, âˆ†Wc/s, xk,i, yk,i) =
âˆ’log(1+exp(âˆ’yk,ixT
k,i(Wc/s+âˆ†Wc/s))) for logistic regres-
sion. The loss function for the k-th client can be expressed as:
Fk(Wc, âˆ†Wc, Ws, âˆ†Ws) =
1
Dk
Dk
X
i=1
f(Wc, âˆ†Wc,


--- Page 4 ---
4
Ws, âˆ†Ws, xk,i, yk,i)
(1)
where Dk denotes the number of local data samples held by
client k.
The global learning objective of the proposed SflLLM
framework is to minimize the total loss aggregated across all
participating clients, which can be formulated as:
min
âˆ†Wc,âˆ†WsF(Wc, âˆ†Wc, Ws, âˆ†Ws)
= 1
D
K
X
k=1
Dk
X
i=1
f(Wc, âˆ†Wc, Ws, âˆ†Ws, xk,i, yk,i)
(2)
where D = PK
k=1 Dk denotes the total number of training
samples across all clients. For clarity and ease of reference,
the key notations used throughout this paper are summarized
in Table I.
IV. THE SFLLLM FRAMEWORK
This section presents a detailed description of the work-
flow for the proposed SflLLM framework. Before initiating
the model training, the central server initializes the model
by partitioning it into two distinct segments: the client-side
segment and the server-side segment. Each global training
round consists of two main phases: first, each client and the
main server conduct I rounds of local fine-tuning, followed
by the federated server aggregating local models from clients
to update the global model. This iterative process continues
until convergence is achieved.
A. Fine-Tuning Phase
The fine-tuning process conducted at each client and the
main server during a single training round can be detailed
through the following steps:
a) Client-Side Forward Propagation: In this step, each
participating client k randomly selects a mini-batch Bk âŠ†Dk
from its local dataset, where Bk contains Bk data samples.
Each client independently performs forward propagation (FP)
on its assigned portion of the model. After completing the
client-side forward propagation, activation vectors are gener-
ated at the split layer (i.e., the final layer of the client-side
model). The activation vector produced by the k-th client at
the t-th training step can be expressed as:
st
k = Ï†

Wc, âˆ†W tâˆ’1
c,k , xt
k

,
(3)
where Ï†(W , âˆ†W , x) denotes the mapping function between
input data x and the predicted output, given the pre-trained
parameters W and LoRA trainable parameters âˆ†W .
b) Uploading of Activation Vectors: After completing the
client-side forward propagation, all participating clients upload
their activation vectors st
k and the corresponding labels yt
k to
the main server via wireless communication channels. Subse-
quently, the main server leverages these collected activation
vectors to further fine-tuning the server-side model.
TABLE I
SUMMARY OF KEY NOTATIONS
Notation
Description
K, K
The number and set of participating clients
Dk, Dk
Local dataset of client k and its number
E(r)
Steps to reach target loss (depends on rank r)
I
Local steps per global round
b
Batch size
â„“c/â„“s
The number of layers deployed on client/main
server
Wc/Ws
Frozen pre-trained weights on client/main server
âˆ†Wc/âˆ†Ws
LoRA trainable weights on client/main server
r
LoRA rank
fk/fs
The computing capability of client k/main server
Îºk/Îºs
GPU cycles required per FLOP on client/main
server
Ïj/Ï–j
The FP/BP computation workload of pre-trained
weights at layer j per sample
âˆ†Ïj/âˆ†Ï–j
The
FP/BP
computation
workload
of
LoRA
weights at layer j per rank for one sample
Ïˆj
The data size of activations at layer j
Î¦F/B
c
, âˆ†Î¦F/B
c
Client-side FP/BP computation workload per sam-
ple for pre-trained and trainable weights
Î¦F/B
s
, âˆ†Î¦F/B
s
Server-side FP/BP computation workload per sam-
ple for pre-trained and trainable weights
Î“s
The data size of activations per sample
âˆ†Î˜c
The data size of client-side LoRA weights
M/N, M/N
The
number
and
set
of
subchannels
to
main/federated server
ri
k, pi, Âµj
Decision variables (explained in Section V)
Bs
i , Bf
i
The bandwidth of i-th subchannel
Gc/Gs/Gf
The
effective
antenna
gain
of
client/main
server/federated server
Î³(ds/f
k
)
The average channel gain from client k
to
main/federated server
(Ïƒs/f)2
The
PSD
of
the
noise
from
client
k
to
main/federated server
pmax
k
, ps/f
th
The maximum transmit PSD of client k and
main/federated server
Î¸s
k,Î¾, Î¸f
k,Î¾
Auxiliary rate variables after log-convexification
T1, T2, T3
Auxiliary variables: maxk(T F
k + T s
k), maxk T B
k ,
maxk T f
k
c) Server-Side Forward Propagation: Upon receiving the
activation vectors, the main server inputs these vectors into
the server-side model to perform forward propagation. Let
âˆ†W tâˆ’1
s
denote the LoRA trainable parameters of the server-
side model at the (t âˆ’1)-th training step. Thus, the predicted
output of the main server at the t-th step can be expressed as:
Ë†yt
k = Ï†
 Ws, âˆ†W tâˆ’1
s
, St
,
(4)
where St = [st
1; st
2; . . . ; st
K] represents the aggregated ac-
tivation vectors from all participating clients. After forward
propagation, the main server calculates the loss by comparing
the predicted outputs to their corresponding true labels across
all received samples.
d) Server-Side Backward Propagation: Based on the
computed loss, the main server executes backward propagation


--- Page 5 ---
5
(BP), starting from the output layer, to compute gradients for
the trainable parameters within the server-side LoRA module.
These parameters are updated according to:
âˆ†W t
s â†âˆ†W tâˆ’1
s
âˆ’Î·sGt
s,
(5)
where Gt
s represents the gradient of trainable parameters at
the t-th training step, and Î·s denotes the learning rate of the
server-side model.
e) Downloading of Activation Vector Gradients: After
completing the BP process, the main server transmits the
gradients of the activation vectors with respect to the client-
side trainable parameters, denoted by
âˆ‚st
k
âˆ‚âˆ†W t
c,k , back to the
corresponding client over the wireless network.
f) Client-Side Backward Propagation: Each client subse-
quently performs backward propagation to fine-tune its local
trainable parameters based on the received gradients of the
activation vectors. The parameter update rule for client k at
the t-th training step is described by:
âˆ†W t
k â†âˆ†W tâˆ’1
k
âˆ’Î·cGt
k,
(6)
where Gt
k represents the gradients of the trainable parameters
at the t-th training step on client k, and Î·c denotes the learning
rate for the client-side model.
B. Aggregation Phase
Once the clients and main server have completed I rounds
of fine-tuning, the federated server initiates the aggregation
phase to aggregate and update the local models collected from
all participating clients. This phase consists of the following
three sequential steps:
a) Uploading Client-Side LoRA Modules: Each partic-
ipating client uploads the trainable parameters of its client-
side LoRA module to the federated server through wireless
communication.
b) Aggregation of Client-Side LoRA Modules:
Upon
receiving the LoRA modules from all clients, the federated
server aggregates these modules to construct a new global
client-side model as described below:
âˆ†W t
c =
K
X
k=1
Dk
D âˆ†W t
k.
(7)
c) Broadcasting the Global Client-Side LoRA Module:
After completing the aggregation step, the federated server
broadcasts the newly aggregated global client-side LoRA
module to all participating clients over the wireless network.
Each client then updates its local LoRA module accordingly,
preparing for the subsequent fine-tuning round.
The complete training procedure of the proposed SflLLM
framework is summarized in Algorithm 1.
V. RESOURCE ALLOCATION FOR SFLLLM
This section formulates the resource allocation problem
within the proposed SflLLM framework, with the objective
of minimizing the total training delay. Due to heteroge-
neous local computing capabilities and dynamically varying
communication resources among different clients, significant
Algorithm 1: The SflLLM Training Framework.
Input: E, I, Î³c, Î³s, xt
k, yt
k, K, Wc, Ws, Dk, D
Output: âˆ†W âˆ—
c , âˆ†W âˆ—
s
1 Initialize âˆ†W 0
c ,âˆ†W 0
s
2 for t = 1, 2, . . . , E do
// Runs on clients
3
foreach k âˆˆK in parallel do
4
st
k = Ï†

Wc, âˆ†W tâˆ’1
c,k , xt
k

5
Send (st
k, yt
k) to main server
6
end
7
// Runs on main server
8
St = [st
1; st
2; ...; st
K]
9
Ë†yt
k = Ï†
 Ws, âˆ†W tâˆ’1
s
, St
10
Calculate loss function value F(Wc, âˆ†Wc, Ws, âˆ†Ws)
11
Calculate gradients of server-side model Gt
s
12
âˆ†W t
s â†âˆ†W tâˆ’1
s
âˆ’Î³sGt
s
13
Broadcast aggregated activationsâ€™ gradients
âˆ‚st
k
âˆ‚âˆ†W t
c,k to
all clients
14
// Runs on clients
15
foreach k âˆˆK in parallel do
16
Calculate gradients of client-side model Gt
k
17
âˆ†W t
k â†âˆ†W tâˆ’1
k
âˆ’Î³cGt
k
18
end
19
// Runs on fed server
20
if t mod I = 0 then
21
âˆ†W t
c = PK
k=1
|Dk|
|D| âˆ†W t
k
22
Broadcast the new global client-side LoRA adapter
âˆ†W t
c to all clients
23
end
24 end
discrepancies can arise in individual training speeds. These
variations often result in stragglers, substantially increasing the
overall training latency. Therefore, efficient resource allocation
is critical to mitigating delays by balancing workload and
communication resources among clients. Furthermore, the
choice of model split point directly impacts both the amount of
activation vector data exchanged and the computational load
at each client. Thus, selecting an optimal split point adapted
to the deployment environment is essential for minimizing
training delay.
With the integration of the LoRA module, both the com-
putational load and communication overhead increase pro-
portionally to the LoRA rank r. Within a certain range,
adjusting the rank significantly affects the convergence rate.
Specifically, increasing the LoRA rank generally reduces the
number of training steps required to reach the target accuracy,
thereby influencing the overall training latency. Consequently,
determining an optimal rank is vital for efficiently accelerating
model training and minimizing total latency.
To address these challenges comprehensively, we propose an
efficient resource allocation strategy that jointly optimizes split
layer selection, LoRA rank selection, subchannel assignment,
and transmit power control. By considering these factors
collectively, the proposed method effectively minimizes the
training delay within the SflLLM framework.


--- Page 6 ---
6
A. Training Delay Model
To rigorously formulate the resource allocation problem, we
first define the key resource variables involved as follows:
â€¢ r: Let binary variables ri,s
k
âˆˆ{0, 1} and ri,f
k
âˆˆ{0, 1}
represent the subchannel allocation decisions. Specifi-
cally, ri,s
k
= 1 indicates that the i-th subchannel be-
tween the client and the main server is allocated to
client k; otherwise, ri,s
k
= 0. Similarly, ri,f
k
= 1
indicates that the i-th subchannel between the client and
the federated server is allocated to client k; otherwise,
ri,f
k
= 0. The corresponding allocation vectors for client
k are denoted as rs
k = [r1,s
k , r2,s
k , . . . , rM,s
k
] and rf
k =
[r1,f
k , r2,f
k , . . . , rN,f
k
], where M and N denote the total
numbers of subchannels available for communications
between the clients and the main server, and between
the clients and the federated server, respectively. Hence,
rs = [rs
1, rs
2, . . . , rs
K] and rf = [rf
1 , rf
2 , . . . , rf
K] repre-
sent the complete subchannel allocation matrices.
â€¢ p: Let ps
i â‰¥0 denote the transmission power spectral
density (PSD) of the i-th subchannel used for uploading
activations or gradients from clients to the main server.
Similarly, pf
i â‰¥0 represents the transmission PSD of
the i-th subchannel used by clients when uploading
local model parameters to the federated server. ps =
[ps
1, ps
2, . . . , ps
M] and pf
= [pf
1, pf
2, . . . , pf
N] represent
transmission power allocation decisions.
â€¢ Âµ: Let binary variables Âµj âˆˆ{0, 1} represent the deci-
sion of the split point between client and main server
for each layer j. Specifically, Âµj = 1 indicates that the
j-th layer is deployed at the client side, and Âµj = 0
indicates deployment at the main server side. Thus, the
split configuration is expressed as a binary vector Âµ =
[Âµ1, Âµ2, . . . , Âµâ„“c+â„“s], where â„“c and â„“s denote the number
of layers available at the client and server, respectively.
â€¢ r: Let the integer variable r â‰¥1 denote the rank of the
LoRA module.
Split federated learning proceeds through multiple rounds
of training until the model reaches convergence. Each com-
plete forward and backward propagation process constitutes
a local iteration round, which is sequentially executed by
all participating clients and the main server. After I local
iteration rounds, clients upload their local model parameters
to the federated server for aggregation. Simultaneously, the
main server aggregates the local models from different clients
to generate a new global model. This process completes one
global iteration round, and convergence is achieved after E
global rounds.
For simplicity, we focus on analyzing a single local train-
ing round, omitting the index t for training rounds in the
subsequent discussion. The latency for transmitting activation
vector gradients from the main server to the client, as well
as for broadcasting the global model by the federated server,
is negligible due to the generally high transmission power of
servers and the relatively small size of the transmitted data.
Additionally, the aggregation latency on both the federated
server and the main server is also minimal and can be disre-
garded, as the computational requirements for these operations
are relatively low, and the servers have ample resources.
Consequently, we focus on the latency of the remaining six
phases within a training round.
Assuming a pre-trained weight matrix W âˆˆRdÃ—k, LoRA
approximates the weight update as the product of two matrices
through low-rank decomposition: W0 + âˆ†W = W0 + BA,
where A âˆˆRrÃ—k, B âˆˆRdÃ—r, and the rank r â‰ªmin(d, k).
During training, W0 remains frozen (i.e., no updates to the
weights), while A and B are the trainable weights. Therefore,
the number of parameters introduced by the LoRA module is
r Ã— (d + k), which scales linearly with r.
1) Clients Perform Forward Propagation: In this phase, all
clients perform FP in parallel. Let Î¦F
c (Âµ) = Pâ„“c+â„“s
j=1
ÂµjÏj rep-
resent the computational workload (in FLOPs) of the clientâ€™s
pre-trained model for processing each sample during the FP
phase. Here, Ïj indicates the computational workload for the
j-th layer of the pre-trained model. With the introduction
of the LoRA module, the number of trainable parameters
increases, resulting in an increased computational workload.
Let âˆ†Î¦F
c (Âµ, r) = Pâ„“c+â„“s
j=1
Âµjrâˆ†Ïj denote the computational
workload corresponding to the trainable parameters introduced
by the LoRA module, where âˆ†Ïj is the computational work-
load for the forward propagation of the trainable parameters
at the j-th layer for each data sample per rank.
Each client randomly selects a mini-batch of b samples for
processing during one round of forward propagation. The FP
delay for client k can be expressed as:
T F
k = bÎºk
 Î¦F
c (Âµ) + âˆ†Î¦F
c (Âµ, r)

fk
, âˆ€k âˆˆK,
(8)
where fk denotes the computational capability of client k
(i.e., the number of graphics processing unit (GPU) cycles
per second), and Îºk is the number of GPU cycles required to
complete a single floating-point operation on client k.
2) Transmission of Activation Vectors: After completing the
forward propagation, each client sends the activation vector
from the last layer to the main server over the wireless channel.
We consider a frequency division multiple access (FDMA)
communication scenario. The activation vectors output by the
LoRA module and the pre-training parameters are combined.
Therefore, the size of the activation vector data remains
unchanged despite the introduction of the LoRA module. Let
Î“s(Âµ) = Pâ„“c+â„“sâˆ’1
j=1
(Âµj âˆ’Âµj+1)Ïˆj denote the data size of the
activation vectors in bits, where Ïˆj is the data size for the
activation vectors at the j-th layer of the pre-trained model.
The uplink transmission rate from client k to the main server
can be expressed as:
Rs
k =
M
X
i=1
ri,s
k Bs
i log2

1 + ps
iGcGsÎ³(ds
k)
(Ïƒs)2

, âˆ€k âˆˆK,
(9)
where Bs
i is the bandwidth allocated to the i-th subchannel
between the client and the main server, Gc and Gs respectively
represent the effective antenna gains of the client and main
server, Î³(ds
k) is the average channel gain from client k to the
main server, ds
k is the communication distance between client
k and the main server, and (Ïƒs)2 is the PSD of the wireless


--- Page 7 ---
7
channel noise. The activation vector transmission delay for
client k can be expressed as:
T s
k = bÎ“s(Âµ)
Rs
k
, âˆ€k âˆˆK.
(10)
3) Main Server Performs Forward Propagation: In this
phase, the main server receives activation vectors from all
participating clients and performs forward propagation. Let
Î¦F
s (Âµ) = Pâ„“c+â„“s
j=1 (1 âˆ’Âµj)Ïj represent the computational
workload of the main serverâ€™s pre-trained model for processing
activation vectors from a single client, and âˆ†Î¦F
s (Âµ, r) =
Pâ„“c+â„“s
j=1 (1 âˆ’Âµj)râˆ†Ïj represent the computational workload
corresponding to the trainable parameters introduced by the
LoRA module. The main server uses the activation vectors
uploaded by all participating clients to perform forward prop-
agation. The forward propagation delay on the main server can
be expressed as:
T F
s = KbÎºs
 Î¦F
s (Âµ) + âˆ†Î¦F
s (Âµ, r)

fs
,
(11)
where fs denotes the computational capability of the main
server (i.e., the number of GPU cycles per second), and Îºs
denotes the number of GPU cycles required by the main server
to complete a single floating-point operation.
4) Main Server Performs Backward Propagation: After
completing forward propagation, the main server initiates
backward propagation. Let Î¦B
s (Âµ) = Pâ„“c+â„“s
j=1 (1 âˆ’Âµj)Ï–j
represent the total computational workload for backward prop-
agation of the pre-trained parameters for each data sample,
where Ï–j is the computational workload for the j-th layer of
the neural network. Let âˆ†Î¦B
s (Âµ, r) = Pâ„“c+â„“s
j=1 (1 âˆ’Âµj)râˆ†Ï–j
represent the total computational workload for backward
propagation of the trainable parameters in the main server,
where âˆ†Ï–j is the computational workload associated with
the trainable parameters at the j-th layer for each data sample
and rank. The backward propagation delay on the main server
can be expressed as:
T B
s = KbÎºs
 Î¦B
s (Âµ) + âˆ†Î¦B
s (Âµ, r)

fs
.
(12)
5) Client Performs Backward Propagation: In this phase,
each client receives the gradient of the activation vector and
performs the backward propagation process. Let Î¦B
c (Âµ) =
Pâ„“c+â„“s
j=1
ÂµjÏ–j denote the total computational workload for the
clientâ€™s pre-trained parameters during backward propagation
for each data sample. Let âˆ†Î¦B
c (Âµ, r) = Pâ„“c+â„“s
j=1
Âµjrâˆ†Ï–j
represent the computational workload for the trainable param-
eters. The backward propagation delay for client k can be
expressed as:
T B
k = bÎºk
 Î¦B
c (Âµ) + âˆ†Î¦B
c (Âµ, r)

fk
, âˆ€k âˆˆK.
(13)
6) Client Local Model Upload: After completing I rounds
of local training, each client uploads its trainable model
parameters to the federated server for aggregation into the
global model. While certain non-trainable parameters may be
aggregated locally, all trainable parameters from the client-
side model are transmitted to the federated server. The up-
dated global model is then broadcast to all clients to initiate
â€¦â€¦
FT
LA
Local fine-tuning steps
FT
Client-side LoRA adapter aggregation
LA
FT
â€¦
FT
global iteration 1
FT
LA
FT
â€¦
FT
global iteration 2  
FT
LA
FT
â€¦
FT
global iteration E(r)  
Time
Time
Client 1
Client 2
Client K
â€¦
Main Server
CF
AT
Client-side forward-propagation
CF
Activations transmissions
AT
Server-side forward-propagation
SF
Client-side back-propagation
CB
LoRA adapter upload
LU
Server-side back-propagation
SB
SF
SB
CB
CF
AT
CB
CF
AT
CB
Activationsâ€™ gradients 
transmissions
â‰ˆ0
Time
Client 1
Client 2
Client K
â€¦
LU
LU
LU
Fed Server aggregation 
and broadcasting
â‰ˆ0
Fig. 2. Illustration of SflLLM training procedure.
the next round of training. Since the number of trainable
parameters increases linearly with the rank r, we define the
total data volume of the client-side trainable parameters as
âˆ†Î˜c(Âµ, r) = Pâ„“c+â„“s
j=1
Âµjrâˆ†Î¾j, where âˆ†Î¾j denotes the data
volume corresponding to the trainable parameters at the j-th
layer.
The uplink transmission rate from client k to the federated
server is expressed as:
Rf
k =
N
X
i=1
ri,f
k Bf
i log2
 
1 + pf
i GcGfÎ³(df
k)
(Ïƒf)2
!
, âˆ€k âˆˆK,
(14)
where Bf
i denotes the bandwidth allocated to the i-th sub-
channel, Gf represents the effective antenna gain at the
federated server, Î³(df
k) is the average channel gain over the
communication distance df
k, and (Ïƒf)2 denotes the PSD of the
channel noise.
The transmission delay for client k to upload its model
parameters to the federated server is given by:
T f
k = âˆ†Î˜c(Âµ, r)
Rf
k
, âˆ€k âˆˆK.
(15)
B. Resource Allocation Problem Formulation
As depicted in Fig. 2, the total latency for one round of
local training is defined as:
Tlocal
 rs, rf, ps, pf, Âµ, r

= max
k {T F
k + T s
k} + T F
s
+ T B
s
+ max
k {T B
k }.
(16)
The total training delay across all global rounds is given by:
T
 rs, rf, ps, pf, Âµ, r

= E(r)(ITlocal + max
k {T f
k }), (17)
where E(r) as a function of the rank r denotes the number
of global iterations required to achieve the desired accuracy.
Time-varying and heterogeneous wireless channel condi-
tions, coupled with disparities in client computing capabil-
ities, can lead to significant dropout events. Furthermore,
the selection of the model split location has a pronounced
impact on both computational and communication latency.
Consequently, efficient communication resource allocation is


--- Page 8 ---
8
critical for accelerating the training process. Based on these
insights, we formulate the following optimization problem to
minimize the overall training delay:
P :
min
rs,rf ,ps,pf ,Âµ,r T
(18)
s.t.C1:rix,x
k
âˆˆ{0, 1}, âˆ€k âˆˆK, is âˆˆM, if âˆˆN, x âˆˆ{s, f},
C2 :
K
X
k=1
rix,x
k
= 1,
âˆ€is âˆˆM, if âˆˆN, x âˆˆ{s, f},
C3:Âµj âˆˆ{0, 1} , Âµj â‰¥Âµj+1,
âˆ€j âˆˆL,
C4:
M
X
i=1
ri,s
k ps
iBs
i â‰¤pmax
k
,
N
X
i=1
ri,f
k pf
i Bf
i â‰¤pmax
k
, âˆ€k âˆˆK,
C5:
M
X
i=1
K
X
k=1
ri,s
k ps
iBs
i â‰¤ps
th,
N
X
i=1
K
X
k=1
ri,f
k pf
i Bf
i â‰¤pf
th,
C6 : px
ix â‰¥0,
âˆ€is âˆˆM, if âˆˆN, x âˆˆ{s, f},
C7 : r âˆˆZ+.
where M = {1, . . . , M} and N = {1, . . . , N} denote the
sets of subchannels allocated to the main server and the
federated server, respectively. In addition, L = {1, . . . , â„“c+â„“s}
represents the set of all layers in the neural network.
Constraints C1 and C2 ensure that each subchannel is exclu-
sively assigned to a single edge device, thereby avoiding co-
channel interference. Constraint C3 guarantees the uniqueness
of the selected model split location. Constraint C4 imposes an
upper bound on the transmit power of each client, while C5
enforces the total uplink transmit power constraints at the main
and federated servers, characterized by thresholds ps
th and pf
th,
respectively. Constraint C6 ensures that the transmit power for
each subchannel remains non-negative, and C7 enforces that
the rank is a positive integer.
VI. ALGORITHM DESIGN
A. Subchannel Assignment
To address the optimization problem in (18), we begin by
fixing the other decision variables and focus on the subchannel
assignment subproblem. The resulting subproblem is formu-
lated as:
P1 : min
rs,rf T
(19)
s.t.C1, C2, C4, C5.
Problem (19) involves a non-convex objective function and
integer-valued decision variables, posing significant challenges
for direct optimization. As the objective is determined by the
maximum latency incurred by client dropouts during uplink
transmission to either the main or federated server, minimizing
training latency necessitates prioritizing subchannel allocation
to clients experiencing higher delays.
To this end, we propose a greedy subchannel allocation
algorithm. The key idea is to assign subchannels with higher
transmission rates to clients with weaker computational or
communication capabilities at the outset. In each iteration,
once every client has been assigned at least one subchannel,
Algorithm 2: Greedy Subchannel Allocation Ap-
proach.
Input: K, Bs
i , Bf
i , fk, df
k
Output: rsâˆ—, rfâˆ—
1 Initialization: Set rs, rf â†0
2 The set of remaining clients As, Af â†K
3 The set of subchannels to be allocated
M â†{1, 2, . . . , M}, N â†{1, 2, . . . , N}.
4 Phase 1: Ensure Each Client Receives at Least One
Subchannel
5 for j = 1, 2, . . . , K do
6
Find n â†arg minkâˆˆAs{fk},m â†arg maxiâˆˆM{Bs
i }
7
Let rm,s
n
â†1, As â†As âˆ’{n}, M â†M âˆ’{m}
8
Find n â†arg maxkâˆˆAf {df
k},m â†arg maxiâˆˆN {Bf
i }
9
Let rm,f
n
â†1, Af â†Af âˆ’{n}, N â†N âˆ’{m}
10 end
11 Phase 2: Allocate Remaining Subchannels
12 As, Af â†K
13 while M Ì¸= âˆ…do
14
Find n â†arg maxiâˆˆAs{T F
k + T s
k},
m â†arg maxiâˆˆM{Bs
i }
15
if rn does not meet C4 or C5 in (18) then
16
As â†As âˆ’{n}
17
end
18
else
19
rm
n â†1,Update T s
k, M â†M âˆ’{m}
20
end
21 end
22 while N Ì¸= âˆ…do
23
Find n â†arg maxiâˆˆAf {T f
k }, m â†arg maxiâˆˆN {Bf
i }
24
if rn does not meet C4 or C5 in (18) then
25
Af â†Af âˆ’{n}
26
end
27
else
28
rm
n â†1,Update T f
k , N â†N âˆ’{m}
29
end
30 end
the remaining unallocated subchannels are iteratively dis-
tributed to the lagging clientsâ€”those with the highest observed
latencyâ€”until all channels are allocated. The complete sub-
channel allocation procedure is detailed in Algorithm 2.
B. Power Control
After completing the subchannel assignment for each client,
we introduce auxiliary variables ps
k,Î¾ and pf
k,Î¾ to represent
the transmission PSD of the Î¾-th subchannel allocated to
client k for uplink transmissions to the main server and
the federated server, respectively. Likewise, Bs
k,Î¾ and Bf
k,Î¾
denote the bandwidth of the Î¾-th subchannel assigned to client
k for communication with the main and federated servers,
respectively. Given that the subchannel assignment variables
rs and rf are fixed, the original problem in (18) can be
reformulated as:
min
ps,pf ,Âµ,r T
(20)
s.t.C3
eC4 :
Mk
X
Î¾=1
ps
k,Î¾Bs
k,Î¾ â‰¤pmax
k
,
Nk
X
Î¾=1
pf
k,Î¾Bf
k,Î¾ â‰¤pmax
k
,
âˆ€k âˆˆK,


--- Page 9 ---
9
eC5 :
K
X
k=1
Mk
X
Î¾=1
ps
k,Î¾Bs
k,Î¾ â‰¤ps
th,
K
X
k=1
Nk
X
Î¾=1
pf
k,Î¾Bf
k,Î¾ â‰¤pf
th,
eC6 : px
k,Î¾x â‰¥0,
âˆ€k âˆˆK, Î¾s âˆˆMk, Î¾f âˆˆNk, x âˆˆ{s, f},
C7 : r âˆˆZ+,
where Mk = {1, 2, . . . , Mk} and Nk = {1, 2, . . . , Nk}
denote the sets of subchannels allocated to client k for com-
munication with the main and federated servers, respectively,
and Mk, Nk represent the corresponding numbers of allocated
subchannels.
The objective function in (20) is non-convex due to the
presence of the maximum delay terms, which introduces chal-
lenges in deriving an optimal solution. To facilitate tractable
optimization, we introduce auxiliary variables T1, T2 and T3,
which satisfy T1 â‰¥maxk{T F
k + T s
k}, T2 â‰¥maxk{T B
k }, and
T3 â‰¥maxk{T f
k }. With these substitutions, the problem in
(20) can be equivalently transformed into the following form:
min
ps,pf ,Âµ,r,T1,T2,T3
eT
(21)
s.t.C3, eC4, eC5, eC6, C7
C8 : bÎºk(Î¦F
c (Âµ) + âˆ†Î¦F
c (Âµ, r))
fk
+
bÎ“s(Âµ)
PMk
Î¾=1 Bs
k,Î¾log2

1 +
ps
k,Î¾GcGsÎ³(ds
k)
(Ïƒs)2
 â‰¤T1,
âˆ€k âˆˆK,
C9 : bÎºk(Î¦B
c (Âµ) + âˆ†Î¦B
c (Âµ, r))
fk
â‰¤T2,
âˆ€k âˆˆK,
C10 :
âˆ†Î˜c(Âµ, r)
PNk
Î¾=1 Bf
k,Î¾log2

1 +
pf
k,Î¾GcGf Î³(df
k)
(Ïƒf )2
 â‰¤T3,
âˆ€k âˆˆK,
where eT(ps, pf, Âµ, r, T1, T2, T3) = E(r)(I(T1 + T F
s + T B
s +
T2) + T3).
To minimize eT, it is necessary to determine the optimal
values of T1, T2, and T3. The optimal solution of problem (21)
must satisfy T1 = maxk{T F
k + T s
k}, T2 = maxk{T B
k }, and
T3 = maxk{T f
k } to ensure that the reformulated problem
in (21) remains equivalent to the original formulation in (20).
However, the non-convex nature of constraints C8 and C10
makes direct optimization intractable. To address this issue,
we introduce auxiliary variables Î¸s = {Î¸s
1,1, Î¸s
1,2, . . . , Î¸s
K,MK}
and Î¸f = {Î¸f
1,1, Î¸f
1,2, . . . , Î¸f
K,NK}, defined as:
Î¸x
k,Î¾ = Bx
k,Î¾ log2(1 +
px
k,Î¾GcGsÎ³(dx
k)
(Ïƒx)2
),
âˆ€x âˆˆ{s, f}. (22)
By substituting the auxiliary variables into problem (21),
the reformulated problem can be expressed as:
min
Î¸s,Î¸f ,Âµ,r,T1,T2,T3
eT
(23)
s.t.C3, C7, C9
Ë†C4 :
Mk
X
Î¾=1
Ïƒ2
sBs
k,Î¾
2
Î¸s
k,Î¾
Bs
k,Î¾ âˆ’1
GcGsÎ³(ds
k) â‰¤pmax
k
,
Nk
X
Î¾=1
Ïƒ2
fBf
k,Î¾
2
Î¸f
k,Î¾
Bf
k,Î¾ âˆ’1
GcGfÎ³(df
k)
â‰¤pmax
k
,
âˆ€k âˆˆK,
Ë†C5 :
K
X
k=1
Mk
X
Î¾=1
Ïƒ2
sBs
k,Î¾
2
Î¸s
k,Î¾
Bs
k,Î¾ âˆ’1
GcGsÎ³(ds
k) â‰¤ps
th,
K
X
k=1
Nk
X
Î¾=1
Ïƒ2
fBf
k,Î¾
2
Î¸f
k,Î¾
Bf
k,Î¾ âˆ’1
GcGfÎ³(df
k)
â‰¤pf
th,
Ë†C6 : Î¸x
k,Î¾x â‰¥0,
âˆ€k âˆˆK, Î¾s âˆˆMk, Î¾f âˆˆNk, x âˆˆ{s, f},
Ë†C8 : bÎºk(Î¦F
c (Âµ) + âˆ†Î¦F
c (Âµ, r))
fk
+
bÎ“s(Âµ)
PMk
Î¾=1 Î¸s
k,Î¾
â‰¤T1, âˆ€k âˆˆK,
Ë†C10 : âˆ†Î˜c(Âµ, r)
PNk
Î¾=1 Î¸f
k,Î¾
â‰¤T3,
âˆ€k âˆˆK,
We observe that if the decision variables Âµ and r are fixed,
the optimization problem (23) can be simplified to:
P2 :
min
Î¸s,Î¸f ,T1,T2,T3
eT
(24)
s.t.
Ë†C4, Ë†C5, Ë†C6, Ë†C8, C9, Ë†C10.
The objective function eT in problem (24) is a linear com-
bination of T1, T2, and T3, and thus is convex. Constraints
Ë†C4 and Ë†C5 are convex constraints since their left-hand sides
represent linear combinations of exponential functions with
respect to variables Î¸s and Î¸f. Constraints Ë†C6 and C9 are
obviously convex. Constraints Ë†C8 and Ë†C10 are convex as
well, since their left-hand sides involve inverse functions of
linear combinations of variables Î¸s and Î¸f, while their right-
hand sides are affine functions of T1 and T3. Therefore, the
optimization problem in (24) is convex and can be efficiently
solved by standard convex optimization solvers such as CVX.
C. Joint Splitting Point Selection and Rank Configuration
Similarly, if Î¸s, Î¸f, r, T1, T2, and T3 are fixed, problem (23)
reduces to:
P3 : min
Âµ
eT
(25)
s.t.
C3, Ë†C8, C9, Ë†C10.
Since the number of candidate split locations determined by
Âµ is generally equal to the number of layers in the network,
which is typically small, problem (25) can be solved via
exhaustive search.
Furthermore, by fixing Î¸s, Î¸f, Âµ, T1, T2, and T3, the
original problem (23) can be further simplified to:
P4 : min
r
eT
(26)
s.t.
C7, Ë†C8, C9, Ë†C10,
where the number of global training rounds E(r) can be esti-
mated offline through pretraining on a representative dataset.
Since the rank r is typically constrained to a small set of in-
tegers, exhaustive search is a practical and effective approach.
Based on the above decomposition, the original optimization
problem (18) is divided into four subproblems (i.e., P1, P2,
P3, and P4) each solvable independently. Leveraging this
structure, we propose a block coordinate descent (BCD)-based
algorithm utilizing an alternating optimization strategy to solve


--- Page 10 ---
10
Algorithm 3: BCD-Based Algorithm for Minimizing
Training Delay.
Input: convergence tolerance Ïµ, maximum iterations
Ï„max
Output: rsâˆ—,rfâˆ—,psâˆ—, pfâˆ—, Âµâˆ—, râˆ—
1 Initialization: Î¸s,0, Î¸f,0, Âµ0, r0, T 0
1 , T 0
2 , T 0
3
2 set iteration index Ï„ = 0
3 repeat
4
Ï„ â†Ï„ + 1
5
Solve P1 based on Algorithm 2 to obtain rs,Ï„,
rf,Ï„
6
Solve P2 with convex optimization tools to obtain
Î¸s,Ï„, Î¸f,Ï„, T Ï„
1 , T Ï„
2 , T Ï„
3
7
Solve P3 using exhaustive search to update ÂµÏ„
8
Solve P4 with exhaustive search to update rÏ„
9 until
 eT Ï„ âˆ’eT Ï„âˆ’1 â‰¤Ïµ or Ï„ = Ï„max
10 return rsâˆ—,rfâˆ—,psâˆ—, pfâˆ—, Âµâˆ—, râˆ—
the overall problem. The detailed procedure is outlined in
Algorithm 3. Although the non-convex, mixed-integer nature
of problem (18) precludes formal convergence guarantees,
extensive empirical evaluations demonstrate that the proposed
BCD algorithm reliably converges to a stable and effective
solution within a finite number of iterations, regardless of
initialization.
D. Complexity Analysis
The complexity of solving problem (18) arises from itera-
tively addressing four subproblems at each iteration. For the
subchannel assignment subproblem, the complexity is given by
O(K(M + N)). Regarding the power allocation subproblem,
its complexity is primarily determined by solving the convex
optimization problem (24). Specifically, the complexity of
problem (24) is O(X2
1X2) [37], where X1 = M + N + 3
denotes the number of optimization variables, and X2 =
5K + 2 is the number of constraints. Hence, the complexity
of solving the power control subproblem is O(K(M + N)2).
For the splitting point selection subproblem, the complexity is
O(â„“c + â„“s). For the rank selection subproblem, the complex-
ity is O(R), where R represents the predefined number of
candidate ranks for exhaustive search. Consequently, the total
complexity of the proposed resource allocation algorithm is
given by O
 Ï„max
 K(M + N)2 + (â„“c + â„“s) + R

,where Ï„max
denotes the number of outer iterations.Since M is typically
much larger than N, and KM 2 is significantly greater than
(â„“c + â„“s) and R, the complexity of the proposed resource
allocation algorithm can be simplified to O
 Ï„maxKM 2
.
VII. PERFORMANCE EVALUATION
This section presents simulation results to evaluate the
learning performance of the proposed SflLLM framework,
alongside the effectiveness of the proposed rank selection and
resource allocation strategies.
A. Simulation Setup
We simulate a system comprising K clients uniformly
distributed within a circular area of radius dmax = 20 m, with
a federated server positioned at the center and a main server
located 100 m from the centroid. Unless otherwise stated,
the number of clients is set to K = 5. Each client has a
computational capability randomly selected from [1, 1.6] GHz,
while the main server operates at a fixed capacity of 5 GHz.
The total bandwidth allocated for client communication
with both the federated and main servers is 500 kHz, equally
divided among subchannels. The noise power spectral density
is âˆ’174 dBm/Hz [38], and the maximum transmit power
per client is 41.76 dBm. Clients share a computing intensity
of 1/1024 cycles/FLOP, whereas the main server is set at
1/32768 cycles/FLOP.
The path loss is modeled by 128.1 + 37.6 log10(d), where
d is in kilometers, with a shadow fading standard deviation of
8 dB. Simulation parameters are summarized in Table II.
TABLE II
SIMULATION PARAMETERS
Parameter
Value
Parameter
Value
fs
5 GHz
fk
[1.0, 1.6] GHz
K
5
M, N
20
Î·c, Î·s
4 Ã— 10âˆ’4
GcGs
160
GcGf
80
Ïƒ2
s, Ïƒ2
f
âˆ’174 dBm/Hz
Îºs
1
32768 cycles/FLOP
Îºk
1
1024 cycles/FLOP
dmax
20 m
Bc, Bs
500 kHz
pmax
k
41.76 dBm
ps
th, pf
th
46.99 dBm
The performance of SflLLM is evaluated on a natural
language generation task using the E2E dataset [39], which
includes restaurant-domain data comprising approximately
42,000 training, 4,600 validation, and 4,600 test samples. The
GPT-2 architecture [40] is employed, using its smallest variant,
GPT2-S, featuring 12 Transformer decoder layers and ap-
proximately 124 million parameters. The training workload is
estimated by assuming the backward pass requires double the
computation of the forward pass; the embedding and positional
encoding are neglected due to their minimal complexity.
Unless otherwise specified, we adopt a mini-batch size of
16, a learning rate of 0.0004, and a maximum sequence length
of 512 for GPT2-S. For GPT2-M, the batch size is 12. LoRA
modules are applied to the query and value matrices across all
Transformer layers.
B. Performance Evaluation of the Proposed SflLLM Frame-
work
To assess the effectiveness of SflLLM, we compare its
performance against a centralized fine-tuning baseline, where
raw data is aggregated at the server and processed using
centralized LoRA training.
1) Convergence Rate: Fig. 3 shows convergence trends for
SflLLM on GPT2-S and GPT2-M. Validation performance
is measured every 12 steps. Generally, higher LoRA ranks
accelerate convergence, though benefits diminish beyond a
certain point due to increased parameter count. Notably, Fig. 4


--- Page 11 ---
11
TABLE III
COMPUTATIONAL COMPLEXITY ANALYSIS OF GPT2-S WITH LORA
Component
Parameters
FLOPs (GFLOP)
Token Embedding
38.6M
â€“
Position Encoding
0.786M
â€“
Transformer Block Ã—12
LayerNorm
1.5K
0.025
Multi-Head Attention
2.36M
257.7
LoRA Adapter (per rank)
1.5K
0.050
Feed-Forward
4.72M
309.2
Final LayerNorm
1.5K
0.025
LM Head
â€“
1264.1
0
2000
4000
6000
8000
10000
Steps
0.04
0.06
0.08
0.10
0.12
0.14
Validation loss
r = 1
r = 2
r = 4
r = 6
r = 8
r = 10
r = 12
r = 14
r = 16
r = 32
1
2
4
6
8
10
12
14
16
32
600
1200
1800
0.045
0.050
0.055
(a) Validation loss with GPT2-S.
0
2000
4000
6000
8000
10000
12000
14000
Steps
0.04
0.06
0.08
0.10
0.12
0.14
Validation loss
r = 1
r = 2
r = 4
r = 6
r = 8
r = 10
r = 12
r = 14
r = 16
r = 32
1
2
4
6
8
10
12
14
16
32
800
1600
0.040
0.048
0.056
(b) Validation loss with GPT2-M.
Fig. 3.
Validation loss on the E2E dataset with GPT2-S and GPT2-M for
different LoRA ranks.
shows that fewer steps are needed to achieve a given loss with
higher ranks. Rank selection directly impacts computational
cost, communication overhead, and convergence rate, hence
plays a vital role in minimizing training delay.
2) Converged Accuracy: Table IV compares final test Per-
plexity (PPL) values between SflLLM and centralized train-
ing for GPT2-S. SflLLM achieves comparable performance,
with maximal PPL deviation within 0.001. This demon-
strates SflLLMâ€™s robustness to data heterogeneity, owing to
its split model designâ€”server-side models aggregate knowl-
1
2
4
8
16
32
LoRA rank
0.0430
0.0435
0.0440
0.0445
0.0450
0.0455
Validation loss threshold
4704
2172
1944
1500
1488
1488
3648
2016
1740
1416
1416
1392
2772
1800
1488
1332
1332
1152
2172
1488
1416
1140
1140
1092
1800
1176
1152
1008
1008
1008
1500
1152
1008
900
864
864
1000
1500
2000
2500
3000
3500
4000
4500
Training steps required
Fig. 4. Steps required to achieve target validation loss under varying LoRA
ranks.
TABLE IV
CONVERGED TEST PERPLEXITY FOR E2E
Learning Framework
Rank
1
2
4
6
8
Centralized
1.0424
1.0407
1.0393
1.0388
1.0385
SflLLM
1.0433
1.0413
1.0399
1.0398
1.0392
edge across clients, while client-side components are locally
adapted. Higher ranks yield better PPL as they offer more
trainable parameters, enhancing model expressiveness.
C. Performance Evaluation of the Proposed Resource Man-
agement Strategy
We evaluate the proposed resource allocation and rank
selection strategy against four baselines:
â€¢ Baseline a: Random subchannel allocation and PSD,
random rank and split location.
â€¢ Baseline b: Random subchannel and PSD; proposed rank
and split location selection.
â€¢ Baseline c: Random split location; proposed subchannel,
power control, and rank selection.
â€¢ Baseline d: Proposed subchannel, power control, and
split location; random rank selection.
Fig. 5 illustrates the total training latency versus bandwidth.
Our approach achieves up to 60% latency reduction compared
to baseline a. As bandwidth increases, communication delay
decreases, shifting the bottleneck toward computation, hence
reducing the performance gap with baseline b. The comparison
with baseline d further emphasizes the importance of rank
optimization.
Fig. 6 shows latency as a function of the clientsâ€™ compu-
tational power (FLOPs per cycle). As expected, latency drops
with higher compute power. The gap between our approach
and baseline c narrows, highlighting that optimized split
location becomes less impactful as computation dominates.
Fig. 7 presents latency trends with respect to main server
computation power. Latency consistently improves with higher
server capacity. Notably, the gap between baselines b and


--- Page 12 ---
12
3
3.5
4
4.5
5
5.5
6
6.5
7
Bandwidth (MHz)
#105
0.5
1
1.5
2
2.5
3
Latency (s)
#105
Proposed solution
Baseline a
Baseline b
Baseline c
Baseline d
Fig. 5. Total latency versus total bandwidth of each client.
500
1000
1500
Floating-point operations per clock cycle (FLOPs/cycle)
0.5
1
1.5
2
2.5
3
3.5
4
Latency (s)
#105
Proposed solution
Baseline a
Baseline b
Baseline c
Baseline d
Fig. 6. The effect of LoRA rank on the number of steps required to reach
the target loss value.
d indicates rank optimization contributes more to latency
reduction than communication tuning in this setup.
Finally, Fig. 8 shows that higher transmit power reduces
delay across all schemes, with our proposed strategy offering
the lowest latency. The benefit of power optimization becomes
especially pronounced in bandwidth-limited scenarios.
VIII. CONCLUSION
In this paper, we have proposed a novel split federated
learning fine-tuned large language model framework (SflLLM)
designed for distributed training of large models on resource-
constrained edge devices. SflLLM reduces the client computa-
tional workload by splitting the model, introducing a federated
server for parallel training, and aggregating client models. The
computational and communication costs are further reduced
1
2
3
4
5
6
7
8
9
10
Computing capability of main server (cycles/s)
#109
0.5
1
1.5
2
2.5
3
3.5
Latency (s)
#105
Proposed solution
Baseline a
Baseline b
Baseline c
Baseline d
Fig. 7. The effect of LoRA rank on the number of steps required to reach
the target loss value.
0
10
20
30
40
50
Maximum link transmit power (dBm)
0.5
1
1.5
2
2.5
3
Latency (s)
#105
Proposed solution
Baseline a
Baseline b
Baseline c
Baseline d
Fig. 8. The effect of LoRA rank on the number of steps required to reach
the target loss value.
by LoRA, significantly accelerating training by decreasing
latency. Considering the heterogeneity of client communica-
tion conditions and computational capabilities, as well as the
substantial impact of rank on convergence speed and training
overhead, we proposed a joint resource allocation and rank
selection scheme. This scheme jointly optimizes subchannel
allocation, power control, split location, and rank selection to
enhance the training speed of SflLLM over wireless networks.
For the mixed-integer nonlinear programming delay minimiza-
tion problem, we decomposed it into four sub-problems based
on different decision variables and proposed solutions for each
sub-problem. Subsequently, we presented a BCD-based algo-
rithm to solve this optimization problem. Simulation results
demonstrated that SflLLM achieves performance similar to


--- Page 13 ---
13
centralized learning, and the proposed resource allocation and
rank selection schemes significantly reduced training latency
across different settings compared to traditional methods.
The findings of this paper highlight the potential of applying
split federated learning to large model fine-tuning. Future
research should focus on analyzing the effect of rank selection
on convergence through theoretical derivations. Additionally,
exploring an energy-efficient SflLLM framework and extend-
ing it to different types of pre-trained models are promising
directions for further investigation.
REFERENCES
[1] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman,
D. Almeida, J. Altenschmidt, S. Altman, S. Anadkat et al., â€œGpt-4
technical report,â€ arXiv preprint arXiv:2303.08774, 2023.
[2] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts,
P. Barham, H. W. Chung, C. Sutton, S. Gehrmann et al., â€œPalm: Scal-
ing language modeling with pathways,â€ Journal of Machine Learning
Research, vol. 24, no. 240, pp. 1â€“113, 2023.
[3] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,
S. Gray, A. Radford, J. Wu, and D. Amodei, â€œScaling laws for neural
language models,â€ arXiv preprint arXiv:2001.08361, 2020.
[4] A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F.
Tan, and D. S. W. Ting, â€œLarge language models in medicine,â€ Nature
medicine, vol. 29, no. 8, pp. 1930â€“1940, 2023.
[5] S. Wu, O. Irsoy, S. Lu, V. Dabravolski, M. Dredze, S. Gehrmann,
P. Kambadur, D. Rosenberg, and G. Mann, â€œBloomberggpt: A large
language model for finance,â€ arXiv preprint arXiv:2303.17564, 2023.
[6] T. Fan, Y. Kang, G. Ma, W. Chen, W. Wei, L. Fan, and Q. Yang, â€œFate-
llm: A industrial grade federated learning framework for large language
models,â€ arXiv preprint arXiv:2310.10049, 2023.
[7] W. Kuang, B. Qian, Z. Li, D. Chen, D. Gao, X. Pan, Y. Xie, Y. Li,
B. Ding, and J. Zhou, â€œFederatedscope-llm: A comprehensive package
for fine-tuning large language models in federated learning,â€ in Proceed-
ings of the 30th ACM SIGKDD Conference on Knowledge Discovery and
Data Mining, 2024, pp. 5260â€“5271.
[8] R. Ye, W. Wang, J. Chai, D. Li, Z. Li, Y. Xu, Y. Du, Y. Wang, and
S. Chen, â€œOpenfedllm: Training large language models on decentralized
private data via federated learning,â€ in Proceedings of the 30th ACM
SIGKDD conference on knowledge discovery and data mining, 2024,
pp. 6137â€“6147.
[9] J. KoneË‡cn`y, H. B. McMahan, F. X. Yu, P. RichtÂ´arik, A. T. Suresh, and
D. Bacon, â€œFederated learning: Strategies for improving communication
efficiency,â€ arXiv preprint arXiv:1610.05492, 2016.
[10] P. Vepakomma, O. Gupta, T. Swedish, and R. Raskar, â€œSplit learning
for health: Distributed deep learning without sharing raw patient data,â€
arXiv preprint arXiv:1812.00564, 2018.
[11] Z. Lin, G. Zhu, Y. Deng, X. Chen, Y. Gao, K. Huang, and Y. Fang,
â€œEfficient parallel split learning over resource-constrained wireless edge
networks,â€ IEEE Transactions on Mobile Computing, vol. 23, no. 10,
pp. 9224â€“9239, 2024.
[12] Z. Lin, G. Qu, X. Chen, and K. Huang, â€œSplit learning in 6g edge
networks,â€ IEEE Wireless Communications, 2024.
[13] C. Thapa, P. C. M. Arachchige, S. Camtepe, and L. Sun, â€œSplitfed: When
federated learning meets split learning,â€ in Proceedings of the AAAI
conference on artificial intelligence, vol. 36, no. 8, 2022, pp. 8485â€“
8493.
[14] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang,
W. Chen et al., â€œLora: Low-rank adaptation of large language models.â€
ICLR, vol. 1, no. 2, p. 3, 2022.
[15] Y. Sheng, S. Cao, D. Li, C. Hooper, N. Lee, S. Yang, C. Chou, B. Zhu,
L. Zheng, K. Keutzer et al., â€œS-lora: Serving thousands of concurrent
lora adapters,â€ arXiv preprint arXiv:2311.03285, 2023.
[16] Z. Lin, X. Hu, Y. Zhang, Z. Chen, Z. Fang, X. Chen, A. Li,
P. Vepakomma, and Y. Gao, â€œSplitlora: A split parameter-efficient
fine-tuning framework for large language models,â€ arXiv preprint
arXiv:2407.00952, 2024.
[17] Z. Zhao, Z. Yang, Y. Hu, C. Zhu, M. Shikh-Bahaei, W. Xu, Z. Zhang,
and K. Huang, â€œCompression ratio allocation for probabilistic semantic
communication with RSMA,â€ IEEE Trans. Commun., pp. 1â€“1, 2025.
[18] M. Chen, D. GÂ¨undÂ¨uz, K. Huang, W. Saad, M. Bennis, A. V. Feljan,
and H. V. Poor, â€œDistributed learning in wireless networks: Recent
progress and future challenges,â€ IEEE Journal on Selected Areas in
Communications, vol. 39, no. 12, pp. 3579â€“3605, 2021.
[19] K. Lee, M. Lam, R. Pedarsani, D. Papailiopoulos, and K. Ramchandran,
â€œSpeeding up distributed machine learning using codes,â€ IEEE Trans-
actions on Information Theory, vol. 64, no. 3, pp. 1514â€“1529, 2017.
[20] D. Shi, L. Li, R. Chen, P. Prakash, M. Pan, and Y. Fang, â€œToward energy-
efficient federated learning over 5g+ mobile devices,â€ IEEE Wireless
Communications, vol. 29, no. 5, pp. 44â€“51, 2022.
[21] R. Chen, D. Shi, X. Qin, D. Liu, M. Pan, and S. Cui, â€œService delay
minimization for federated learning over mobile devices,â€ IEEE Journal
on Selected Areas in Communications, vol. 41, no. 4, pp. 990â€“1006,
2023.
[22] Y. Jiao, P. Wang, D. Niyato, B. Lin, and D. I. Kim, â€œToward an
automated auction framework for wireless federated learning services
market,â€ IEEE Transactions on Mobile Computing, vol. 20, no. 10, pp.
3034â€“3048, 2020.
[23] X. Chen, G. Zhu, Y. Deng, and Y. Fang, â€œFederated learning over multi-
hop wireless networks with in-network aggregation,â€ IEEE Transactions
on Wireless Communications, vol. 21, no. 6, pp. 4622â€“4634, 2022.
[24] J. Xu and H. Wang, â€œClient selection and bandwidth allocation in
wireless federated learning networks: A long-term perspective,â€ IEEE
Transactions on Wireless Communications, vol. 20, no. 2, pp. 1188â€“
1200, 2020.
[25] W. Wu, M. Li, K. Qu, C. Zhou, X. Shen, W. Zhuang, X. Li, and W. Shi,
â€œSplit learning over wireless networks: Parallel design and resource
management,â€ IEEE Journal on Selected Areas in Communications,
vol. 41, no. 4, pp. 1051â€“1066, 2023.
[26] Z. Lin, G. Qu, W. Wei, X. Chen, and K. K. Leung, â€œAdaptsfl: Adaptive
split federated learning in resource-constrained edge networks,â€ arXiv
preprint arXiv:2403.13101, 2024.
[27] X. Liu, Y. Deng, and T. Mahmoodi, â€œWireless distributed learning: A
new hybrid split and federated learning approach,â€ IEEE Transactions
on Wireless Communications, vol. 22, no. 4, pp. 2650â€“2665, 2022.
[28] L. U. Khan, M. Guizani, A. Al-Fuqaha, C. S. Hong, D. Niyato, and
Z. Han, â€œA joint communication and learning framework for hierarchical
split federated learning,â€ IEEE Internet of Things Journal, vol. 11, no. 1,
pp. 268â€“282, 2023.
[29] J. Shen, N. Cheng, X. Wang, F. Lyu, W. Xu, Z. Liu, K. Aldubaikhy, and
X. Shen, â€œRingsfl: An adaptive split federated learning towards taming
client heterogeneity,â€ IEEE Transactions on Mobile Computing, vol. 23,
no. 5, pp. 5462â€“5478, 2023.
[30] K. He, X. Zhang, S. Ren, and J. Sun, â€œDeep residual learning for image
recognition,â€ in Proceedings of the IEEE conference on computer vision
and pattern recognition, 2016, pp. 770â€“778.
[31] K. Simonyan and A. Zisserman, â€œVery deep convolutional networks for
large-scale image recognition,â€ arXiv preprint arXiv:1409.1556, 2014.
[32] A. Krizhevsky, I. Sutskever, and G. E. Hinton, â€œImagenet classification
with deep convolutional neural networks,â€ Advances in neural informa-
tion processing systems, vol. 25, 2012.
[33] J. Jiang, H. Jiang, Y. Ma, X. Liu, and C. Fan, â€œLow-parameter federated
learning with large language models,â€ in International Conference on
Web Information Systems and Applications.
Springer, 2024, pp. 319â€“
330.
[34] T. Fan, Y. Kang, G. Ma, L. Fan, K. Chen, and Q. Yang, â€œFedcollm: A
parameter-efficient federated co-tuning framework for large and small
language models,â€ arXiv preprint arXiv:2411.11707, 2024.
[35] C. Xu, J. Li, Y. Liu, Y. Ling, and M. Wen, â€œAccelerating split federated
learning over wireless communication networks,â€ IEEE Transactions on
Wireless Communications, vol. 23, no. 6, pp. 5587â€“5599, 2023.
[36] G. Zhu, Y. Deng, X. Chen, H. Zhang, Y. Fang, and T. F. Wong, â€œEsfl: Ef-
ficient split federated learning over resource-constrained heterogeneous
wireless devices,â€ IEEE Internet of Things Journal, 2024.
[37] M. S. Lobo, L. Vandenberghe, S. Boyd, and H. Lebret, â€œApplications of
second-order cone programming,â€ Linear algebra and its applications,
vol. 284, no. 1-3, pp. 193â€“228, 1998.
[38] X. Hu, L. Wang, K.-K. Wong, M. Tao, Y. Zhang, and Z. Zheng, â€œEdge
and central cloud computing: A perfect pairing for high energy efficiency
and low-latency,â€ IEEE Transactions on Wireless Communications,
vol. 19, no. 2, pp. 1070â€“1083, 2019.
[39] J. Novikova, O. DuË‡sek, and V. Rieser, â€œThe e2e dataset: New challenges
for end-to-end generation,â€ arXiv preprint arXiv:1706.09254, 2017.
[40] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever et al.,
â€œLanguage models are unsupervised multitask learners,â€ OpenAI blog,
vol. 1, no. 8, p. 9, 2019.
