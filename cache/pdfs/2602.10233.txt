--- Page 1 ---
ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution
and Then Improvise
Alexey Kravatskiy
MIRIAI
Russia
kravatskii.a@miriai.org
Valentin Khrulkov
FusionBrain Lab
AXXX
Russia
Ivan Oseledets
Institute of Numerical Mathematics
AXXX
Russia
Abstract
Recent advances in LLM-guided evolutionary computation, partic-
ularly AlphaEvolve [11], have demonstrated remarkable success in
discovering novel mathematical constructions and solving challeng-
ing optimization problems. In this article, we present ImprovE-
volve, a simple yet effective technique for enhancing LLM-based
evolutionary approaches such as AlphaEvolve. Given an optimiza-
tion problem, the standard approach is to evolve program code that,
when executed, produces a solution close to the optimum. We pro-
pose an alternative program parameterization that maintains the
ability to construct optimal solutions while reducing the cognitive
load on the LLM. Specifically, we evolve a program (implementing,
e.g., a Python class with a prescribed interface) that provides the fol-
lowing functionality: (1) propose a valid initial solution, (2) improve
any given solution in terms of fitness, and (3) perturb a solution
with a specified intensity. The optimum can then be approached
by iteratively applying improve() and perturb() with a sched-
uled intensity. We evaluate ImprovEvolve on challenging problems
from the AlphaEvolve paper: hexagon packing in a hexagon and
the second autocorrelation inequality. For hexagon packing, the
evolved program achieves new state-of-the-art results for 11, 12, 15,
and 16 hexagons; a lightly human-edited variant further improves
results for 14, 17, and 23 hexagons. For the second autocorrelation
inequality, the human-edited program achieves a new state-of-the-
art lower bound of 0.96258, improving upon AlphaEvolveâ€™s 0.96102.
CCS Concepts
â€¢ Computing methodologies â†’Neural networks; Evolution-
ary algorithms; Optimization.
Keywords
genetic programming, optimization, evolutionary computation,
large language models, AlphaEvolve, mathematical discovery
1
Introduction
In the recent work AlphaEvolve [11], an approach for solving opti-
mization problems by combining powerful Large Language Models
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD â€™26, Jeju, Korea
Â© 2026 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-x-xxxx-xxxx-x/YYYY/MM
https://doi.org/10.1145/nnnnnnn.nnnnnnn
(LLMs) with the classical evolutionary algorithm MAP-Elites [10]
was proposed. The method operates as follows: given an optimiza-
tion task, the user specifies (1) a validation function to evaluate
candidate solutions, and (2) a set of initial programs. The solu-
tion to an optimization problem is then iteratively improved by
selecting promising parent programs and combining them via an
LLM-based mutation operator. While the original implementation
has not been released, several open-source reimplementations are
available [1, 8, 9, 13].
In this work, we investigate the ability of LLMs to generate opti-
mization code for problems with extremely rugged landscapes. Op-
timal solutions to such problems often exhibit intricate structureâ€”a
phenomenon observed across various packing problems. Devising
an effective optimization routine ab initio is challenging for an
LLM, which requires it to iteratively design an end-to-end opti-
mization algorithm along with an intricate initialization scheme.
In practice, generated programs typically rely on standard rou-
tines such as L-BFGS-B, which are inadequate for the non-convex,
non-smooth landscapes that arise once all constraints are imposed.
Consequently, LLM-generated programs combine mathematical
insights with heuristics rather than solving the optimization rigor-
ously.
When such an approach yields an imperfect solution, or when
a non-trivial solution has been previously constructed by domain
experts, this initial solution can often be improved through local
search. This motivates ImprovEvolve: rather than evolving a pro-
gram that directly outputs an optimal solution (as in AlphaEvolve),
we evolve a class implementing the following interface:
â€¢ improve(ð‘¥): returns an improved solution ð‘¥â€² with better
fitness than ð‘¥;
â€¢ perturb(ð‘¥, ðœŽ): performs random exploration of the solution
space, where ðœŽcontrols the perturbation intensity;
â€¢ generate_config(ð‘ ð‘’ð‘’ð‘‘): returns a feasible initial solution
for a given random seed.
By combining these three methods, we search for optimal solutions
as follows: we sample initial configurations via generate_config
and a subsequent improve to select the best initial configuration,
to which we then iteratively apply perturb and improve with
scheduled intensity to greedily search for an improved solution.
This decomposition offers several advantages. First, it reduces
the cognitive burden on the LLM by separating the distinct concerns
of initialization, local improvement, and exploration, providing a
natural interface for incorporating domain knowledge at each stage.
Second, the modular structure facilitates interpretability and debug-
ging of the evolved programs, both for humans and LLMs. Third
and most importantly, the evolved class can be applied to any given
arXiv:2602.10233v1  [cs.NE]  10 Feb 2026


--- Page 2 ---
KDD â€™26, Under review, Jeju, Korea
Kravatskiy et al.
â†’f â†‘fâ†’2
2 â†“C2â†’f â†‘fâ†’1â†’f â†‘fâ†’â†’
â†’f â†‘fâ†’2
2 â†“C2â†’f â†‘fâ†’1â†’f â†‘fâ†’â†’
Figure 1: Comparison of AlphaEvolve and ImprovEvolve. Top: In AlphaEvolve, the LLM evolves a program that directly outputs a
candidate solution, requiring the model to design an end-to-end optimization algorithm including initialization, search strategy,
and termination criteria. Bottom: In ImprovEvolve, the LLM evolves a class with three modular methodsâ€”generate_config
(initialization), improve (local optimization), and perturb (exploration)â€”which are combined via basin-hopping dynamics
with a scheduled perturbation intensity. This decomposition reduces the cognitive burden on the LLM by separating distinct
optimization concerns into tractable subproblems. The pseudocode shown for ImprovEvolve is simplified; see Algorithm 1 for
the full description.
starting solutionâ€”for instance, one provided by a domain expert
representing a sophisticated mathematical construction beyond the
LLMâ€™s immediate grasp.
We now discuss related work before proceeding with the algo-
rithmic details.
2
Related Work
The idea of utilizing evolutionary search for machine learning tasks
has a long history in the literature, spanning multiple diverse areas.
Recently, Novikov et al. [11], Romera-Paredes et al. [12] proposed
FunSearch and AlphaEvolve frameworks, respectively, leveraging
evolutionary algorithms to improve programs that solve mathe-
matical problems, with mutations guided by powerful LLMs, e.g.,
Gemini 2.5 Pro [2]. FunSearch evolves Python functions that con-
struct solutions; AlphaEvolve generalizes this by allowing arbitrary
code blocks to be mutated and by incorporating richer evolution-
ary feedback. AlphaEvolve was subsequently evaluated at scale by
Georgiev et al. [5], demonstrating its effectiveness on cutting-edge
mathematical challenges.
AlphaEvolve has inspired numerous open-source implementa-
tions and extensions [1, 8, 9, 13, 15â€“17]. Most of these works focus
on refining the evolutionary loop or replacing it with alternative
techniques, such as reinforced learning [15, 17]. In contrast, rather
than devising a new scheme for the evolutionary algorithm itself,
we address a more fundamental challenge: the difficulty of using
LLMs to generate effective optimization code. We achieve this by re-
formulating the optimization problem definition commonly adopted
in prior work. To the best of our knowledge, ours is the first work
to apply this reformulation in the context of LLM-guided evolution.
For our implementation, we adopt the open-source GigaEvo
framework1 of Khrulkov et al. [8] as the backbone of ImprovE-
volve, selected for its flexibility and comprehensive collection of
implemented mathematical problems.
3
Methodology
We now describe our approach, which reformulates the optimiza-
tion target to leverage LLM-evolved local search operators within
a classical global optimization framework.
Connection to Basin-Hopping. Basin-hopping [14] is a well-known
optimization technique that has proven particularly effective for
high-dimensional landscapes with many local minima separated
by large barriers. The algorithm iterates by (1) applying a random
perturbation to the current solution, (2) performing local optimiza-
tion from the perturbed point, and (3) accepting or rejecting the
new solution based on the Metropolis criterion with temperature
1https://github.com/FusionBrainLab/gigaevo-core


--- Page 3 ---
ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise
KDD â€™26, Under review, Jeju, Korea
parameter ð‘‡. When ð‘‡= 0, the algorithm becomes Monotonic Basin-
Hopping, accepting only moves that improve the objective.
ImprovEvolve can be viewed as a variant of basin-hopping where
the perturbation and local optimization subroutines are themselves
evolved by an LLM rather than being fixed generic operators. Specif-
ically:
â€¢ perturb(ð‘¥, ðœŽ) replaces the random coordinate perturbation
step, with ðœŽcontrolling intensity;
â€¢ improve(ð‘¥) replaces the local minimization step (e.g., L-
BFGS);
â€¢ We use ð‘‡= 0 (monotonic acceptance) to accelerate conver-
gence during validation.
This reformulation shifts the LLMâ€™s task from designing an end-to-
end optimization algorithm to designing domain-specific improve
and perturb operatorsâ€”a more tractable objective that leverages
the LLMâ€™s ability to encode mathematical structure and heuristics.
Validation Scheme. The validation scheme for ImprovEvolve is
presented in Algorithm 1 and proceeds in two stages. In Stage A,
ð¾candidate solutions are generated with distinct random seeds
and immediately refined via improve; the solution with the highest
fitness is retained as the starting point ð’™âˆ—. Since the quality of the
final solution depends heavily on the basin in which the search
begins, sampling multiple initial configurations and selecting the
best one reduces sensitivity to poor initializations. In Stage B, the
algorithm performs ð‘…rounds of iterative perturbation and improve-
ment. Within each round, the perturbation intensity ðœŽdecays from
ðœŽmax to ðœŽmin over ð‘€iterations, encouraging broad exploration early
(large perturbations to escape local minima) and fine-grained refine-
ment later (small perturbations to converge to a nearby optimum).
Each perturbed solution is refined via improve and accepted only
if it improves upon the current best (monotonic acceptance, corre-
sponding to basin-hopping with temperatureð‘‡= 0). The ðœŽschedule
is restarted in every round, allowing the search to repeatedly at-
tempt large jumps to new basins while still refining the current
best solution.
Initialization Strategy. Another important aspect of evolutionary
frameworks is the set of initial programs from which the evolution
starts. To accelerate the process without the assistance of human
experts, we use Gemini 3 Pro to generate a set of ð‘= 5 initial
programs that bootstrap evolution. We iteratively refine these pro-
grams in the same LLM chat to correct errors reported by the
validation function (e.g., out-of-bounds configurations). According
to Georgiev et al. [5], more capable LLMs achieve optimization
goals significantly faster than smaller models. However, running
experiments exclusively with high-capability models is prohibi-
tively expensive. We therefore adopt a two-tier approach: generate
the initial programs using Gemini 3 Pro and perform the evolution
itself with the faster Gemini 3 Flash Preview. We observe that the
initial programs produced by Gemini 3 Pro from the same prompt
exhibit a diverse set of approaches and yield competitive quality
out of the box, consistent with the findings of Gideoni et al. [6],
where competitive performance on various mathematical problems
was obtained by sampling LLM outputs without any evolution.
Evolutionary setup. We build on the open-source GigaEvo frame-
work [8], which provides a modular evolutionary engine built
Algorithm 1: Validation Scheme for ImprovEvolve
Input: Evolved class with methods generate_config,
improve, perturb; evaluation function fitness;
number of rounds ð‘…
Output: Solution ð’™âˆ—with highest fitness found
// Hyperparameters
1 ð¾â†10 ;
// number of initial seeds
2 ð‘€â†10 ;
// iterations per round
3 ðœŽmax â†100;
ðœŽmin â†0.001;
// Stage A: Initialization
4 for ð‘ â†1 to ð¾do
5
ð’™ð‘ â†improve(generate_config(ð‘ ));
6 end
7 ð’™âˆ—â†arg maxð‘ âˆˆ{1,...,ð¾} fitness(ð’™ð‘ );
// Stage B: Basin-hopping with scheduled
perturbation
8 for round â†1 to ð‘…do
9
for ð‘¡â†1 to ð‘€do
10
ðœŽâ†ðœŽmax Â· (ðœŽmin/ðœŽmax)(ð‘¡âˆ’1)/(ð‘€âˆ’1) ; // geometric
decay or another schedule
11
ð’™â€² â†improve(perturb(ð’™âˆ—, ðœŽ));
12
if fitness(ð’™â€²) â‰¥fitness(ð’™âˆ—) then
13
ð’™âˆ—â†ð’™â€² ;
// monotonic acceptance
14
end
15
end
16 end
17 return ð’™âˆ—
around four components: a Redis-backed storage layer for can-
didate programs, an asynchronous DAG execution engine for eval-
uation pipelines, a MAP-Elites evolution loop with configurable
island topologies, and an LLM-based mutation operator support-
ing multiple models and mutation modes. We employ a single-
island MAP-Elites configuration with a single behavior descriptorâ€”
fitnessâ€”discretized into 150 bins. This resolution was not specif-
ically tuned, yet proved sufficient to achieve state-of-the-art re-
sults across all considered benchmark problems. Our preliminary
experiments with the multi-island setup showed no apparent ben-
efit (e.g., when using program code complexity as an additional
behavior descriptor) and only increased system complexity. To sup-
ply the mutation operator with rich program context, we adopt
the default pipeline configuration provided by GigaEvo, which in-
cludes InsightsStage (generating suggestions for potential pro-
gram improvements), LineageInsights (analyzing parentâ€“child
transitions and providing causal feedback on fitness changes), and
aggregate evolutionary statistics. All system prompts were used
without modification as provided in the repository. It is important to
distinguish two nested levels of optimization in ImprovEvolve. The
outer loop (MAP-Elites) maintains a population of candidate pro-
gramsâ€”each implementing the generate_config, improve, and
perturb interface. The inner loop (Algorithm 1) executes a single
candidate program via basin-hopping to produce a solution and as-
signs the program a fitness score equal to the best solution quality


--- Page 4 ---
KDD â€™26, Under review, Jeju, Korea
Kravatskiy et al.
invalid (overlaps)
generate(seed=1)
L = 4.650
improve
invalid (overlaps)
generate(seed=2)
L = 4.647
improve
invalid (overlaps)
generate(seed=3)
L = 4.619
improve
L = 54.507
perturb( = 316.2)
L = 4.6188
improve
L = 10.926
perturb( = 56.2)
L = 4.6136
improve
L = 4.614
perturb( = 0.003)
L = 4.6136
improve
Stage A
improve
improve
improve
 best (L * = 4.619)
Stage B
improve
improve
improve
perturb
 final (L * = 4.6136)
Stage B initializes from the best Stage A result (L * = 4.619)  
Figure 2: Illustration of the two-stage validation scheme (Algorithm 1) on the HEX 17 problem. Stage A (top): generate proposes
initial configurations that typically contain overlapping hexagons (invalid); improve resolves these overlaps and produces valid
packings. The best result (ð¿âˆ—= 4.619, gold border) is selected. Stage B (bottom): basin-hopping alternates perturb (red border)
and improve. Even an extreme perturbation (ðœŽ= 316, round 4) that scatters hexagons across a vast enclosing hexagon (ð¿= 54.5)
is recovered by improve back to ð¿= 4.619. The breakthrough occurs at round 8 (ðœŽ= 56.2), where improve discovers a new, tighter
basin at ð¿= 4.6136â€”a structural improvement inaccessible from the Stage A initialization. Subsequent rounds with small ðœŽ
confirm stability.
found during that execution. For baseline comparisons using the
standard GigaEvo pipeline, each evolved program is invoked in a
single call to directly produce a candidate solution.
At each generation, ð‘elites programs are selected from the archive
with probability proportional to their fitness. Then, ð‘offspring off-
spring are produced as follows: ð‘parents programs are sampled uni-
formly at random from the elite set, and their source code, to-
gether with associated metrics and contextual information from
the pipeline stages described above, is passed to the LLM, which
produces a mutated offspring program. Each offspring is evaluated
by running Algorithm 1 and, if its fitness warrants inclusion, it is
inserted into the MAP-Elites archive.
The number of basin-hopping rounds ð‘…in Algorithm 1 controls
the trade-off between evaluation cost and solution quality. During
evolution we use a smaller value of ð‘…to enable rapid fitness es-
timation, while for final validation of the best evolved programs
we increase ð‘…to obtain higher-quality solutions. Problem-specific
values are reported in the respective benchmark sections below.
Several additional hyperparameters govern the evolutionary pro-
cess, including the choice of backbone LLM and timeout values for
code execution stages. These choices proved critical to performance
and are discussed in detail below. For a comprehensive description
of the GigaEvo framework, we refer the reader to [8].
Computational cost. The wall-clock time of a single evolutionary
run depends heavily on the problem complexity, specifically the
cost of each improve call. For hexagon packing, where the inner
optimization is a moderate-dimensional constrained problem (3ð‘›
variables), one full run takes approximately 10 hours on a single
machine. The second autocorrelation inequality is considerably
more expensive: each improve call performs high-dimensional L-
BFGS optimization over step functions with up to tens of thousands
of parameters, resulting in runs of approximately 40 hours.
4
Benchmark problems
We evaluate ImprovEvolve on two challenging optimization prob-
lems studied in Novikov et al. [11] and Georgiev et al. [5]: hexagon
packing and the second autocorrelation inequality.
For each problem, we describe the mathematical formulation
and the evaluation approach used in the original work. For thor-
ough descriptions and further background, we refer the reader to
Georgiev et al. [5]; here we only discuss the most important details.
As the backbone LLM, we use Gemini 3 Pro accessed via chat at
aistudio.google.com for generating initial programs and Gemini 3
Flash Preview at openrouter.ai with default settings for evolution, in-
cluding temperatureð‘‡= 1. Common evolution parameters for both
benchmark problems are: ð‘elites = 6, ð‘parents = 2, and ð‘offspring = 10.
All programs are executed on a CPU to allow parallelization. Dur-
ing evolution, if a programâ€™s improve function outputs an invalid
configuration, the program is discarded. However, this requirement
is relaxed during the final validation to allow extended evaluation,
as there is a small possibility that even the most reliable optimizers
diverge after an unlucky perturbation.
4.1
Hexagon packing
The hexagon packing (HEX ð‘›) problem asks to pack ð‘›unit regular
hexagons (circumradiusð‘Ÿ= 1) inside a flat-topped regular enclosing
hexagon of side length ð¿, so as to minimize ð¿, subject to a no-
overlap constraint. Each hexagon is parameterized by its center
(ð‘¥ð‘–,ð‘¦ð‘–) and rotation angle ðœƒð‘–, yielding a 3ð‘›-dimensional search


--- Page 5 ---
ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise
KDD â€™26, Under review, Jeju, Korea
Table 1: Comparison of best known results for hexagon
packing (HEX ð‘›) and the second autocorrelation in-
equality (ACI 2). Bold digits indicate improvement over
the prior state of the art.
Method
HEX 11 (â†“)
HEX 12 (â†“)
ACI 2 (â†‘)
Human
3.9434 [3]
4.0000 [3]
0.94136 [7]
AlphaEvolve
3.9301 [11]
3.9419 [11]
0.96102 [5]
ThetaEvolve[15]
â€“
â€“
0.94690
CodeEvolve[1]
3.9379
4.0000
0.88110
GigaEvo[8] (baseline)
3.9327
invalid1
0.94063
ImprovEvolve
3.9245
3.94162
0.9512
ImprovEvolve+E3
3.9245
3.9416
0.96258
1 Hexagon overlap encountered when validating program evolved forð‘›= 11
on ð‘›= 12.
2 Value obtained by validating code evolved for ð‘›= 11 on ð‘›= 12.
3 ImprovEvolve+E the evolved program was lightly edited by a human expert.
For HEX, the optimizer and convergence parameters were adjusted (see
Section A.2.1); for ACI 2, the program was modified to support an effective
start from AlphaEvolveâ€™s solution (see Section B.2.1).
Table 2: ImprovEvolve hyperparameters for HEX 11 and ACI
2 problems.
Parameter
HEX 11
ACI 2
Timeout
5 min
20 min
Init. seeds (ð¾)
10
3
BH rounds (ð‘…)
15
5
Iter. per round (ð‘€)
11
6
ðœŽschedule
[1e2, 5e1, 1e1, 5,
1, 5e-1, 1e-1, 5e-2,
1e-2, 5e-3, 1e-3]
[1e2, 1e1,
1, 1e-1,
1e-2, 1e-3]
space. Following Novikov et al. [11] and Georgiev et al. [5], we
evolve programs for ð‘›= 11, for which the best previously known
side length was ð¿= 3.9434 [3], later improved to ð¿= 3.9301 by
AlphaEvolve [11], and then validate the evolved programs across a
range of ð‘›values.
The fitness is defined as âˆ’ð¿; if containment or non-overlap con-
straints are violated, an exception is raised and the configuration is
discarded. The optimization landscape is highly non-convex: small
perturbations in position or rotation can introduce overlaps or con-
tainment violations, making this problem particularly challenging
for evolutionary search. At the same time, hexagon packing serves
as an effective testbed for our approach, since perturbations are
geometrically interpretable and configurations are easy to visualize.
The task description is formulated to be valid for any ð‘›from 1 to
25; however, evolution was run for a fixed value of ð‘›= 11, using the
ImprovEvolve hyperparameters listed in Table 2. We obtained two
novel state-of-the-art packings: the first (Figure 3b) is structurally
distinct from AlphaEvolveâ€™s packing (Figure 3a) and achieves a
noticeably shorter enclosing side, while the second (Figure 4a)
closely resembles AlphaEvolveâ€™s solution and appears to be near-
optimal. The existence of two qualitatively different high-quality
packings suggests that the fitness landscape contains multiple deep
basins, underscoring the importance of Stage A diversity.
(a) AlphaEvolveâ€™s solution (ð¿=
3.9301)
(b) Structurally distinct ImprovE-
volve solution (ð¿= 3.9269)
Figure 3: Two packings of ð‘›= 11 unit hexagons. (a) The
previous state-of-the-art by AlphaEvolve [11]. (b) A struc-
turally different packing found by ImprovEvolve that im-
proves upon AlphaEvolve but is not the overall best (cf. Fig-
ure 4a, ð¿= 3.9245).
Table 3: Enclosing hexagon side lengths for HEX 13â€“30. Im-
provEvolve+E denotes the evolved program with minor hu-
man edits to the optimizer and convergence parameters (see
Section A.2.1). Bold digits indicate improvement over the hu-
man baseline [3]. A dash (â€“) indicates no previously reported
packing.
Task
Human [3]
ImprovEvolve
ImprovEvolve+E
HEX 13 (â†“)
4.0000
4.0000
4.0000
HEX 14 (â†“)
4.2724
4.2724
4.2690
HEX 15 (â†“)
4.4541
4.4473
4.4473
HEX 16 (â†“)
4.5363
4.5275
4.5275
HEX 17 (â†“)
4.6188
4.6188
4.6136
HEX 18 & 19 (â†“)
4.6188
4.6188
4.6188
HEX 20 & 21 (â†“)
5.0000
5.0000
5.0000
HEX 22 (â†“)
5.2856
5.2857
5.2856
HEX 23 (â†“)
5.4286
5.4848
5.4000
HEX 24 (â†“)
5.4848
5.4848
5.4848
HEX 25 (â†“)
â€“
5.6510
5.6239
HEX 26 (â†“)
â€“
5.7142
5.7097
HEX 27 (â†“)
â€“
5.7142
5.7142
HEX 28 (â†“)
â€“
5.9723
5.9089
HEX 29 (â†“)
â€“
6.0000
6.0000
HEX 30 (â†“)
â€“
6.0045
6.0000
We then validated the evolved program on a GPU for all 11 â‰¤
ð‘›â‰¤24 with increased computational budgets: initial seeds ð¾= 100,
basin-hopping rounds ð‘…= 100, and a ðœŽschedule of np.geomspace(
1000, 0.001, 25). This yielded new state-of-the-art packings
for ð‘›= 12, 15, and 16 (see Table 3 for side lengths and Figure 4
for the discovered configurations). Crucially, the same program
evolved for ð‘›= 11 generalizes to unseen problem sizes without
any retraining or re-evolution, demonstrating the robustness of the
improve/perturb interface.
We also consider ImprovEvolve+E, a variant in which a hu-
man expert applies minor, targeted edits to the evolved program.
For the hexagon task, three changes were made (see Section A.2.1
for the annotated diff): (i) replacing the L-BFGS-B optimizer with


--- Page 6 ---
KDD â€™26, Under review, Jeju, Korea
Kravatskiy et al.
SLSQP, which solves a quadratic subproblem at each step and is
better suited to the constrained geometry but less numerically sta-
ble; (ii) softening the initial penalty weights to provide a gentler
warm-up; and (iii) relaxing the variable bounds and increasing the
iteration limit to allow finer convergence. These edits preserve the
overall algorithmic structure produced by the LLM while leverag-
ing human domain knowledge to improve robustness. With these
modifications, we obtained additional state-of-the-art packings for
ð‘›= 14, 17, and 23 (Table 3, Figure 4). We further evaluated the
edited program on 25 â‰¤ð‘›â‰¤30, for which no packings have previ-
ously been reported. As shown in Figure 4, structured, non-chaotic
packings can be found even for these values of ð‘›.
Overall, ImprovEvolve proved substantially more effective than
the GigaEvo baseline under identical evolutionary parameters and
time limits; see Figure 5 for the distribution of validation fitness
values across the evolution run. Moreover, validating the best Gi-
gaEvo program for ð‘›> 11 produced overlap errors, indicating that
the evolved solution was not transferable to other problem sizes.
This suggests that when the full complexity of an optimization
procedure is encoded in a single program, the LLM struggles to
produce a solution that generalizes reliably.
Further details, including the prompt and the evolved program,
are provided in Appendix A.
4.2
Second autocorrelation inequality
To test the applicability of ImprovEvolve to problems with highly-
parameterized constructions, we consider the second autocorre-
lation inequality (ACI 2) problem. For a non-negative function
ð‘“: R â†’R, define the autoconvolution as
(ð‘“âˆ—ð‘“)(ð‘¡) =
âˆ«
R
ð‘“(ð‘¡âˆ’ð‘¥) ð‘“(ð‘¥) ð‘‘ð‘¥.
Let ð¶2 be the smallest constant such that
âˆ¥ð‘“âˆ—ð‘“âˆ¥2
2 â‰¤ð¶2 âˆ¥ð‘“âˆ—ð‘“âˆ¥1 âˆ¥ð‘“âˆ—ð‘“âˆ¥âˆž
holds for all non-negative ð‘“. It is known that 0.88922 â‰¤ð¶2 â‰¤1 [5].
The goal is to tighten the lower bound by finding a function ð‘“that
maximizes the ratio ð¶(ð‘“) = âˆ¥ð‘“âˆ—ð‘“âˆ¥2
2
 âˆ¥ð‘“âˆ—ð‘“âˆ¥1 âˆ¥ð‘“âˆ—ð‘“âˆ¥âˆž
, which
serves as the fitness. The state-of-the-art solution discovered by
AlphaEvolve [5] achieves ð¶(ð‘“) = 0.96102 and is a highly irregu-
lar step function of 50 000 steps (Figure 7a), making this problem
substantially more complex than hexagon packing.
The evolved ImprovEvolve program achieved ð¶(ð‘“) = 0.9512,
which is close to AlphaEvolveâ€™s 0.96102 [5] and surpasses the results
of all other open-source frameworks [1, 15] (Table 1). The GigaEvo
baseline achieved ð¶(ð‘“) = 0.94063 under the same conditions (see
Figure 6 for the full fitness distribution). Figure 9 in Appendix B
visualizes the full optimization path, showing how both ð‘“and ð‘“âˆ—ð‘“
evolve across the two-stage validation scheme and how a single
perturbation at ðœ€= 10âˆ’3 triggers a large jump in ð¶(ð‘“).
A key advantage of ImprovEvolveâ€™s modular design is the built-in
flexibility to resume optimization from a given high-quality solu-
tion. We demonstrate this with ImprovEvolve+E: starting from
AlphaEvolveâ€™s solution (Figure 7a), we apply a human-edited ver-
sion of our evolved program with three changes (see Section B.2.1
for the annotated diff): (i) replacing the original multi-grid schedule
(resolutions up to 32 768) with a progressive schedule that starts
Table 4: Ablation study of the ImprovEvolve validation
scheme on the HEX 11 problem. ð¿: best enclosing-hexagon
side length (lower is better). ð¾: number of initial seeds in
Stage A.ð‘…: basin-hopping rounds in Stage B. The perturbation
schedule is ðœŽâˆˆ[100, 50, 10, 5, 1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001].
A only
B only
A + B
A + B + LLM1
Lattice + B2
Best ð¿
3.9282
3.9269
3.9245
3.9270
3.9310
Seeds ð¾
1000
1
100
100
100
Rounds ð‘…
0
100
5
100
100
1 Gemini 3 Pro was prompted to edit the evolved program (see Appendix C).
2 Using generate_config produced by Gemini 3 Proâ€™s edited program.
at the input resolution and scales up to 1.6 million steps, so that
the optimizer can meaningfully refine AlphaEvolveâ€™s 50 000-step
function; (ii) removing the lower clipping of 10âˆ’10 to preserve small
input function steps; and (iii) increasing the number of L-BFGS
iterations per stage to allow finer convergence at the higher res-
olutions. In just fifteen iterations of the improveâ€“perturb loop,
we obtain a new state-of-the-art lower bound of ð¶(ð‘“) = 0.96258
(Figure 7b). As with the hexagon task, this result highlights the
value of humanâ€“LLM collaboration: the LLM produces the core
algorithmic structure through evolution, while a domain expert
contributes targeted refinements that would be difficult for the
model to discover on its ownâ€”in this case, the knowledge that a
much finer discretization is needed to improve upon a 50 000-step
solution.
5
Ablation study & Variants
5.1
Stage ablation
Both Stage A (multi-seed initialization) and Stage B (basin-hopping)
are essential components of the validation scheme. Table 4 presents
an ablation study on the HEX 11 problem. Stage A alone can gener-
ate a prototype of the optimal solution (see Figure 2), but it cannot
refine it further. Stage B alone can polish a single initialization, yet
without a diverse set of starting points the probability of reaching
the global optimum remains low.
Although basin-hopping with acceptance temperature ð‘‡> 0
and a simulated-annealing schedule is theoretically preferable to
monotonic basin-hopping (ð‘‡= 0), its practical impact is limited.
High temperatures prevent the optimizer from fully refining a so-
lution, while low temperatures barely increase the probability of
escaping a local optimum. Moreover, ð‘‡> 0 introduces the risk
of abandoning a suboptimal configuration that lies on the path to
the global optimumâ€”for example, the ð¿= 4.6188 arrangement for
HEX 17 shown in Figure 2. Recovering such a configuration may
be prohibitively slow, particularly for problems like ACI 2 where
each call to improve is computationally expensive.
Can an LLM replace human tuning? The ImprovEvolve+E re-
sults benefited from expert-guided hyperparameter edits. A natural
question is whether an LLM can achieve similar improvements
autonomously. To test this, we prompted Gemini 3 Pro to make min-
imal modifications to the evolved programs for HEX 11â€”adjusting


--- Page 7 ---
ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise
KDD â€™26, Under review, Jeju, Korea
(a) ð‘›= 11
(b) ð‘›= 12
(c) ð‘›= 14
(d) ð‘›= 15
(e) ð‘›= 16
(f) ð‘›= 17
(g) ð‘›= 23
(h) ð‘›= 25
(i) ð‘›= 26
(j) ð‘›= 27
(k) ð‘›= 28
(l) ð‘›= 29 âˆ’30
Figure 4: State-of-the-art hexagon packings discovered by ImprovEvolve. New best-known configurations are shown for ð‘›= 11â€“17
and ð‘›= 23. For ð‘›= 25â€“30, no prior packings have been reported; the discovered configurations exhibit structured, non-chaotic
arrangements. The ð‘›= 30 packing (shown) achieves the same side length ð¿= 6.0 as ð‘›= 29: any single hexagon can be removed
to obtain a valid ð‘›= 29 packing with identical ð¿. Side lengths are listed in Table 1 and Table 3.
numerical constants, parameter values, or function argumentsâ€”
without restructuring the code (the full prompt is given in Appen-
dix C).
LLM edits for the GigaEvo program. The edits by Gemini 3 Pro
(marked LLM-EDIT in Section A.2.1) included increasing the batch
size and number of optimization steps, tightening the initialization
range for hexagon centers, and raising Langevin noise to escape
local minima. However, the edited program produced overlapping
hexagonsâ€”the same failure mode observed when validating the
unedited program on ð‘›> 11. In this case, Langevin noise should
be decreased, not increased; the LLMâ€™s suggestion was harmful.
LLM edits for the ImprovEvolve program. The edits (marked
LLM-EDIT in Section A.2.1) included reducing noise in the generate
_config method, softening initial penalty weights, and changing
the lattice orientation from point-topped to flat-toppedâ€”correcting
a geometric mismatch with the flat-topped hexagons. While this last
edit simplified the search for dense packings at ð‘›= 13, 21, 31, it inad-
vertently suppressed the stochastic exploration that Stage A relies
on. Consistent with our ablation study, both the LLM-edited pro-
gram and a hybrid variant that only adopted the edited generate
_config produced results inferior to the unedited version (Table 4).
Even the most advanced LLMs tend to suggest theoretically
plausible but empirically harmful changes. The damage from such
changes is exacerbated in monolithic programs and mitigated when
the program is modular and more interpretable. Evolution can
partially compensate by feeding validation results back into the
context, but this is not a silver bullet: models remain likely to pro-
pose harmful edits. More broadly, LLMs lack a reliable sense for
choosing optimization hyperparametersâ€”these depend heavily on


--- Page 8 ---
KDD â€™26, Under review, Jeju, Korea
Kravatskiy et al.
âˆ’8
âˆ’7
âˆ’6
âˆ’5
âˆ’4
Fitness (â†‘higher is better)
0.0
0.5
1.0
1.5
2.0
Density
max = âˆ’3.9327
max = âˆ’3.9247
GigaEvo (baseline)
ImprovEvolve
Figure 5: Distribution of validation fitness values (âˆ’ð¿) across
all valid programs produced during evolution for the ð‘›= 11
hexagon packing problem. ImprovEvolve consistently yields
higher-fitness programs compared to the GigaEvo baseline
under identical evolutionary parameters and time limits.
0.5
0.6
0.7
0.8
0.9
Fitness (â†‘higher is better)
0
2
4
6
8
10
12
14
Density
max = 0.9406
max = 0.9512
GigaEvo (baseline)
ImprovEvolve
Figure 6: Distribution of validation fitness values ð¶(ð‘“) across
all valid programs produced during evolution for the ACI 2
problem. ImprovEvolve yields consistently higher fitness than
the GigaEvo baseline.
0.3
0.2
0.1
0.0
0.1
0.2
0.3
0.0
0.2
0.4
0.6
0.8
1.0
(a) AlphaEvolve
0.3
0.2
0.1
0.0
0.1
0.2
0.3
0.0
0.2
0.4
0.6
0.8
1.0
(b) ImprovEvolve+E
Figure 7: Extremal functions ð‘“for the second autocorrelation
inequality. (a) AlphaEvolveâ€™s solution (ð¶(ð‘“) = 0.96102, 50 000
steps) [5]. (b) ImprovEvolve+E solution (ð¶(ð‘“) = 0.96258, 1.6M
steps), obtained by resuming optimization from (a). Despite
the small difference in fitness, the two functions are qualita-
tively different in structure.
problem specifics, and even human experts select them heuristically.
AI agents, however, can readily approximate suitable values by eval-
uating the program under different hyperparameter configurations.
0.3
0.2
0.1
0.0
0.1
0.2
0.3
0
2
4
6
8
(a) AlphaEvolve
0.3
0.2
0.1
0.0
0.1
0.2
0.3
0.0
0.5
1.0
1.5
2.0
2.5
3.0
(b) ImprovEvolve+E
Figure 8: Autoconvolutions ð‘“âˆ—ð‘“of the extremal functions
from Figure 7. The ImprovEvolve+E solution achieves a higher
ratio ð¶(ð‘“) = âˆ¥ð‘“âˆ—ð‘“âˆ¥2
2/(âˆ¥ð‘“âˆ—ð‘“âˆ¥1âˆ¥ð‘“âˆ—ð‘“âˆ¥âˆž).
6
Discussion and Conclusion
ImprovEvolve demonstrates that decomposing an optimization task
into modular subproblems substantially improves the output of
an evolutionary coding agent. Although decomposition is a well-
established principle, its significance in LLM-powered discovery
deserves emphasis: current models produce a complete response in a
single turn regardless of problem difficulty, and task decompositionâ€”
already a staple of AI-assisted code editorsâ€”can bring similar accel-
eration to AI for mathematics. Both human-guided and computer-
guided decomposition can contribute: researchers specify the mod-
ules a program should contain, while AI agents validate and debug
them so that the evolutionary LLM can focus on conceptual aspects.
Decomposition is especially critical in mathematics, where an
idea may fail entirely until its implementation is fully correct. For
example, reproducing the 592-sphere construction from Ganzhinov
[4] for the kissing number problem in 11D required approximately
20 chat exchanges with Gemini 3 Pro; intermediate versions pro-
duced fewer than 100 valid spheres. Such a construction is unlikely
to emerge through evolution alone, as the sparse reward signal
would cause the idea to be discarded before a correct implemen-
tation is found. An agentic approach could address this by setting
reproduction of the construction as a long-term goal while delegat-
ing debugging to auxiliary agents.
Incorporating human guidance is straightforward: domain ex-
perts can tailor the task decomposition, for instance delegating
non-local optimization to basin-hoppingâ€”a technique naturally
suited for evolutionary implementation. Looking ahead, combining
task decomposition with agentic workflowsâ€”where an AI agent
autonomously decides which modules to refine and when to invoke
external solversâ€”is a promising direction for scaling LLM-powered
mathematical discovery.
Limitations and Ethical Considerations
Limitations. Our evaluation is limited to two mathematical opti-
mization problems (hexagon packing and the second autocorrela-
tion inequality), both drawn from the AlphaEvolve benchmark suite.
While the results are strong on these tasks, the generalizability of
ImprovEvolve to other problem classes, such as combinatorial opti-
mization, scientific simulation, or machine learning pipeline design,
remains to be demonstrated. Our experiments report single-run
best results without confidence intervals, and the stochastic nature


--- Page 9 ---
ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise
KDD â€™26, Under review, Jeju, Korea
of both evolution and basin-hopping means that outcomes may
vary across runs.
Ethical considerations. This work addresses purely mathemati-
cal optimization problems and does not involve human subjects,
personal data, or sensitive information. The primary ethical consid-
eration is the computational cost of LLM-guided evolution: each run
consumes significant energy and API resources. We mitigate this by
using a two-tier LLM strategy (a capable model for initialization, a
lighter model for evolution) and by designing a modular framework
that reduces the number of evolutionary iterations needed to reach
competitive results.
GenAI Disclosure
In addition to the LLM-based code evolution that constitutes the
core contribution of this work (detailed in the main text), genera-
tive AI tools were used during the preparation of this manuscript.
Specifically, Gemini 3 Pro and Claude 4 Opus were used to assist
with polishing the text, generating plotting scripts for figures, and
writing boilerplate code. All AI-generated content was reviewed,
edited, and verified by the authors, who take full responsibility for
the final manuscript.
References
[1] Henrique AssumpÃ§Ã£o, Diego Ferreira, Leandro Campos, and Fabricio Murai. 2026.
CodeEvolve: an open source evolutionary coding agent for algorithm discovery
and optimization. arXiv:2510.14150 [cs.AI] https://arxiv.org/abs/2510.14150
[2] Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen
Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen,
et al. 2025. Gemini 2.5: Pushing the frontier with advanced reasoning, multi-
modality, long context, and next generation agentic capabilities. arXiv preprint
arXiv:2507.06261 (2025).
[3] Erich Friedman. 2015. Erichâ€™s Packing Center. https://erich-friedman.github.io/
packing/. Accessed: 2026-06-02.
[4] Mikhail Ganzhinov. 2022. Highly symmetric lines. arXiv:2207.08266 [math.FA]
https://arxiv.org/abs/2207.08266
[5] Bogdan Georgiev, Javier GÃ³mez-Serrano, Terence Tao, and Adam Zsolt Wag-
ner. 2025. Mathematical exploration and discovery at scale. arXiv preprint
arXiv:2511.02864 (2025).
[6] Yonatan Gideoni, Yujin Tang, Sebastian Risi, and Yarin Gal. 2025. Random
Baselines for Simple Code Problems are Competitive with Code Evolution. In
NeurIPS 2025 Fourth Workshop on Deep Learning for Code. https://openreview.
net/forum?id=rbVIpbmbTc
[7] Aaron Jaech and Alan Joseph. 2025. Further Improvements to the Lower Bound
for an Autoconvolution Inequality. arXiv:2508.02803 [math.CA] https://arxiv.
org/abs/2508.02803
[8] Valentin Khrulkov, Andrey Galichin, Denis Bashkirov, Dmitry Vinichenko, Oleg
Travkin, Roman Alferov, Andrey Kuznetsov, and Ivan Oseledets. 2025. GigaEvo:
An Open Source Optimization Framework Powered By LLMs And Evolution
Algorithms. arXiv:2511.17592 [cs.NE] https://arxiv.org/abs/2511.17592
[9] Robert Tjarko Lange, Yuki Imajuku, and Edoardo Cetin. 2025.
ShinkaE-
volve: Towards Open-Ended And Sample-Efficient Program Evolution.
arXiv:2509.19349 [cs.CL] https://arxiv.org/abs/2509.19349
[10] Jean-Baptiste Mouret and Jeff Clune. 2015. Illuminating search spaces by mapping
elites. arXiv:1504.04909 [cs.AI] https://arxiv.org/abs/1504.04909
[11] Alexander Novikov, NgÃ¢n VËœu, Marvin Eisenberger, Emilien Dupont, Po-Sen
Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Francisco JR
Ruiz, Abbas Mehrabian, et al. 2025. AlphaEvolve: A coding agent for scientific
and algorithmic discovery. arXiv preprint arXiv:2506.13131 (2025).
[12] Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov,
Matej Balog, M Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S
Ellenberg, Pengming Wang, Omar Fawzi, et al. 2024. Mathematical discoveries
from program search with large language models. Nature 625, 7995 (2024),
468â€“475.
[13] Asankhaya Sharma. 2025. OpenEvolve: an open-source evolutionary coding agent.
https://github.com/algorithmicsuperintelligence/openevolve
[14] David J. Wales and Jonathan P. K. Doye. 1997. Global Optimization by Basin-
Hopping and the Lowest Energy Structures of Lennard-Jones Clusters Contain-
ing up to 110 Atoms. The Journal of Physical Chemistry A 101, 28 (July 1997),
5111â€“5116. doi:10.1021/jp970984n
[15] Yiping Wang, Shao-Rong Su, Zhiyuan Zeng, Eva Xu, Liliang Ren, Xinyu Yang,
Zeyi Huang, Xuehai He, Luyao Ma, Baolin Peng, Hao Cheng, Pengcheng He,
Weizhu Chen, Shuohang Wang, Simon Shaolei Du, and Yelong Shen. 2025.
ThetaEvolve: Test-time Learning on Open Problems. arXiv:2511.23473 [cs.LG]
https://arxiv.org/abs/2511.23473
[16] Minghao Yan, Bo Peng, Benjamin Coleman, Ziqi Chen, Zhouhang Xie, Zhankui
He, Noveen Sachdeva, Isabella Ye, Weili Wang, Chi Wang, Ed H. Chi, Wang-Cheng
Kang, Derek Zhiyuan Cheng, and Beidou Wang. 2026. PACEvolve: Enabling
Long-Horizon Progress-Aware Consistent Evolution. arXiv:2601.10657 [cs.NE]
https://arxiv.org/abs/2601.10657
[17] Mert Yuksekgonul, Daniel Koceja, Xinhao Li, Federico Bianchi, Jed McCaleb,
Xiaolong Wang, Jan Kautz, Yejin Choi, James Zou, Carlos Guestrin, et al. 2026.
Learning to Discover at Test Time. arXiv preprint arXiv:2601.16175 (2026).


--- Page 10 ---
KDD â€™26, Under review, Jeju, Korea
Kravatskiy et al.
A
Hexagon Packing Problem: Task Description and Evolved Solution
A.1
Prompts
A.1.1
Baseline. TASK DEFINITION â€“ HEXAGON PACKING
PROBLEM
Challenge: Implement a Python function that minimizes the side
length of a flat-topped regular enclosing hexagon required to con-
tain ð‘non-overlapping unit regular hexagons.
Specific Benchmark: ð‘= 11.
General Requirement: The code should be valid for any ð‘from
1 to 25, defaulting to 11.
GEOMETRIC SPECIFICATIONS
(1) Unit Hexagons (Items):
â€¢ Regular hexagons with circumradius ð‘Ÿ= 1.0.
â€¢ Side length = 1.0.
â€¢ May be arbitrarily placed (ð‘¥,ð‘¦) and rotated (ðœƒ).
(2) Enclosing Hexagon (Container):
â€¢ Regular, flat-topped, centered at (0, 0).
â€¢ â€œFlat-toppedâ€ vertices are located at angles [0â—¦, 60â—¦, 120â—¦,
180â—¦, 240â—¦, 300â—¦] relative to the center.
â€¢ Objective: Minimize the enclosing hexagonâ€™s side length
ð¿(which is equal to its circumradius).
OBJECTIVE FUNCTION
Maximize Fitness: âˆ’ð¿(Minimize side length ð¿).
Target for ð‘= 11: ð¿â‰¤3.92.
CONSTRAINTS
(1) Containment: All vertices of every unit hexagon must lie
inside or on the boundary of the enclosing hexagon.
(2) Non-overlap: The intersection area between any pair of
unit hexagons must be zero (touching is allowed).
(3) Count: Exactly hex_num unit hexagons must be placed.
IMPLEMENTATION REQUIREMENTS
Libraries:
Use numpy, scipy, sklearn, jax, optax, jaxopt or standard Python
libraries.
Function Interface:
You must implement the following function structure exactly:
import numpy as np
def entrypoint(hex_num=11, seed=0) -> tuple[np.ndarray, np.ndarray]:
"""
Calculates the optimal packing configuration.
Args:
hex_num: Number of hexagons to pack.
seed: Random seed for reproducibility.
Returns:
centers: np.ndarray of shape (hex_num, 2) representing (x, y)
coordinates.
angles: np.ndarray of shape (hex_num,) in radians [0, 2pi).
"""
# Implement optimization logic here
pass
CRITICAL FAILURE MODES
â€¢ Wrong Shapes: Returning arrays of shape (12, ...) when
hex_num=11.
A.1.1
With Improver. TASK DEFINITION â€“ HEXAGON PACK-
ING OPTIMIZER
Challenge: Implement a Python class that minimizes the side
length of a flat-topped regular enclosing hexagon required to con-
tain ð‘non-overlapping unit regular hexagons.
Specific Benchmark: ð‘= 11.
General Requirement: The code must be valid for any ð‘from 1
to 25.
GEOMETRIC SPECIFICATIONS
(1) Unit Hexagons (Items):
â€¢ Regular hexagons with circumradius ð‘Ÿ= 1.0.
â€¢ Side length = 1.0.
â€¢ May be arbitrarily placed (ð‘¥,ð‘¦) and rotated (ðœƒ).
(2) Enclosing Hexagon (Container):
â€¢ Regular, flat-topped, centered at (0, 0).
â€¢ â€œFlat-toppedâ€ vertices are located at angles [0â—¦, 60â—¦, 120â—¦,
180â—¦, 240â—¦, 300â—¦] relative to the center.
â€¢ Objective: Minimize the enclosing hexagonâ€™s side length
ð¿(which is equal to its circumradius).
OBJECTIVE FUNCTION
Maximize Fitness: âˆ’ð¿(Minimize side length ð¿).
Target for ð‘= 11: ð¿â‰¤3.92.
CONSTRAINTS
(1) Containment: All vertices of every unit hexagon must lie
inside or on the boundary of the enclosing hexagon.
(2) Non-overlap: The intersection area between any pair of
unit hexagons must be zero (touching is allowed).
(3) Count: Exactly hex_num unit hexagons must be placed.
IMPLEMENTATION REQUIREMENTS
Libraries:
Use numpy, scipy, sklearn, jax, optax, jaxopt or standard Python
libraries.
Class Interface:
You must implement the following class structure exactly:
import numpy as np
class Improver:
def __init__(self, hex_num=11, seed: int = 0):
self.hex_num = hex_num
self.seed = seed
def improve(self, input_config: tuple[np.ndarray, np.ndarray], seed=None) ->
tuple[np.ndarray, np.ndarray]:
"""
Refines the configuration to minimize L.
"""
pass
def perturb(self, input_config, intensity: float, seed=None) -> tuple[np.
ndarray, np.ndarray]:
"""
Perturbs the configuration (position/rotation).
"""
pass
def generate_config(self, seed=None) -> tuple[np.ndarray, np.ndarray]:
"""
Generates a valid starting configuration.


--- Page 11 ---
ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise
KDD â€™26, Under review, Jeju, Korea
â€¢ Geometry Errors: Assuming point-topped enclosing hexagon
instead of flat-topped.
â€¢ Invalid Output: Hexagons overlapping or protruding out-
side the boundary in the final result.
â€¢ Wrong Return Type: Returning a class or object instead of
the (centers, angles) tuple.
DOCUMENTATION
Supply your code with a brief explanation of the algorithm using
LaTeX in the introductory comment.
"""
pass
def entrypoint():
return Improver
CRITICAL FAILURE MODES
â€¢ Wrong Shapes: Returning arrays of shape (12, ...) when
hex_num=11.
â€¢ Geometry Errors: Assuming point-topped enclosing hexagon
instead of flat-topped.
â€¢ Invalid Output: Hexagons overlapping or protruding out-
side the boundary in the final result.
DOCUMENTATION
Supply your code with a brief explanation of the algorithm using
LaTeX in the introductory comment.


--- Page 12 ---
KDD â€™26, Under review, Jeju, Korea
Kravatskiy et al.
A.2
Evolved Solution Code
A.2.1
Baseline. The following program was evolved by GigaEvo
(Program ID: 80ed10a3-7d87-42f7-a610-068c6d69411e, Fitness: -3.9327,
Generation: 13).
import numpy as np
import jax
import jax.numpy as jnp
import optax
def entrypoint(hex_num=11, seed=0) -> tuple[np.ndarray, np.ndarray]:
"""""
Algorithm: Gradient-based packing optimization with SAT for non-overlap
and explicit projection constraints for a flat-topped enclosing hexagon.
L is the side length (and circumradius) of the container.
"""""
jax.config.update("jax_enable_x64", True)
# Flat-topped container normals at 30, 90, 150, 210, 270, 330 degrees
cont_angles = jnp.deg2rad(jnp.array([30, 90, 150, 210, 270, 330]))
container_normals = jnp.stack([jnp.cos(cont_angles), jnp.sin(cont_angles)],
axis=1)
â†©â†’
# Unit hexagon local geometry
unit_angles = jnp.arange(6) * (jnp.pi / 3.0)
unit_verts_local = jnp.stack([jnp.cos(unit_angles), jnp.sin(unit_angles)],
axis=1)
â†©â†’
sat_axes_local = jnp.array([0, jnp.pi/3, 2*jnp.pi/3]) + jnp.pi/6
# Midpoints
of edges
â†©â†’
def get_world_data(centers, angles):
c, s = jnp.cos(angles), jnp.sin(angles)
rot = jnp.stack([jnp.stack([c, -s], axis=-1), jnp.stack([s, c],
axis=-1)], axis=-2)
â†©â†’
verts = jnp.einsum('nij,kj->nki', rot, unit_verts_local) + centers[:,
None, :]
â†©â†’
axes_angles = angles[:, None] + sat_axes_local[None, :]
axes = jnp.stack([jnp.cos(axes_angles), jnp.sin(axes_angles)], axis=2)
return verts, axes
def containment_loss(verts, L):
# For flat-topped hexagon with side L, apothem is L * cos(30 deg)
h = L * jnp.cos(jnp.pi / 6.0)
# Projections of unit hexagon vertices onto container normals must be <= h
projections = jnp.dot(verts.reshape(-1, 2), container_normals.T)
return jnp.sum(jax.nn.relu(projections - h)**2)
def overlap_loss(verts, axes_all):
N = verts.shape[0]
idx_i, idx_j = jnp.triu_indices(N, 1)
def pair_penalty(i, j):
v_i, v_j = verts[i], verts[j]
axes = jnp.concatenate([axes_all[i], axes_all[j]], axis=0)
p_i = jnp.dot(v_i, axes.T)
p_j = jnp.dot(v_j, axes.T)
gaps = jnp.maximum(jnp.min(p_j, axis=0) - jnp.max(p_i, axis=0),
jnp.min(p_i, axis=0) - jnp.max(p_j, axis=0))
return jax.nn.relu(-jnp.max(gaps) + 1e-9)**2
return jnp.sum(jax.vmap(pair_penalty)(idx_i, idx_j))
def optimize_instance(sub_key):
total_steps = 22000
# LLM-EDIT: total_steps = 30000
k1, k2, k3 = jax.random.split(sub_key, 3)
# Insight: Expanded range based on expected L ~ 4.0
centers = jax.random.uniform(k1, (hex_num, 2), minval=-3.5, maxval=3.5)
# LLM_EDIT: centers = jax.random.uniform(k1, (hex_num, 2), minval=-3.0,
maxval=3.0)
â†©â†’
init_angles = jax.random.uniform(k2, (hex_num,), minval=0.0,
maxval=jnp.pi/3.0)
â†©â†’
params = {'centers': centers, 'angles': init_angles, 'log_L':
jnp.log(4.5)}
â†©â†’
lr = optax.cosine_decay_schedule(0.04, total_steps, alpha=1e-3)
optimizer = optax.chain(optax.clip_by_global_norm(1.0),
optax.adam(learning_rate=lr))
â†©â†’
opt_state = optimizer.init(params)
def step_fn(carry, i):
p, state, rng = carry
prog = i / total_steps
# Smoother, more gradual weight ramping to allow rearrangement
A.2.1
With Improver. The following program was evolved by Im-
provEvolve (Program ID: e98264be-75e4-4160-aaaa-530ec55f7848,
Fitness: -3.92467, Generation: 13). Lines marked with EDIT show
the human modifications applied in the ImprovEvolve+E variant:
the optimizer was changed from L-BFGS-B to SLSQP, initial penalty
weights were softened, variable bounds were relaxed, and the itera-
tion limit was increased.
import numpy as np
import jax
import jax.numpy as jnp
from scipy.optimize import minimize
jax.config.update("jax_enable_x64", True)
@jax.jit
def get_unit_hex_verts(center, theta):
# Regular hexagon vertices, circumradius 1.0
base_angles = jnp.array([0.0, jnp.pi/3, 2*jnp.pi/3, jnp.pi, 4*jnp.pi/3,
5*jnp.pi/3], dtype=jnp.float64)
â†©â†’
angles = base_angles + theta
return center + jnp.stack([jnp.cos(angles), jnp.sin(angles)], axis=1)
@jax.jit
def get_container_normals():
# Normals for flat-topped enclosing hexagon (face-centered directions)
angles = jnp.array([jnp.pi/6, jnp.pi/2, 5*jnp.pi/6, 7*jnp.pi/6, 3*jnp.pi/2,
11*jnp.pi/6], dtype=jnp.float64)
â†©â†’
return jnp.stack([jnp.cos(angles), jnp.sin(angles)], axis=1)
@jax.jit
def compute_separation(c1, theta1, c2, theta2):
v1 = get_unit_hex_verts(c1, theta1)
v2 = get_unit_hex_verts(c2, theta2)
axes_angles = jnp.array([jnp.pi/6, jnp.pi/2, 5*jnp.pi/6], dtype=jnp.float64)
n1 = jnp.stack([jnp.cos(axes_angles + theta1), jnp.sin(axes_angles +
theta1)], axis=1)
â†©â†’
n2 = jnp.stack([jnp.cos(axes_angles + theta2), jnp.sin(axes_angles +
theta2)], axis=1)
â†©â†’
axes = jnp.concatenate([n1, n2], axis=0)
p1 = jnp.dot(v1, axes.T)
p2 = jnp.dot(v2, axes.T)
gaps = jnp.maximum(jnp.min(p1, axis=0) - jnp.max(p2, axis=0), jnp.min(p2,
axis=0) - jnp.max(p1, axis=0))
â†©â†’
return jnp.max(gaps)
@jax.jit
def objective_fn(params, idx_i, idx_j, weight_cont, weight_ov, margin):
N = (len(params) - 1) // 3
centers = params[:2*N].reshape((N, 2))
thetas = params[2*N:3*N]
L = params[-1]
# Flat-topped container containment
H = L * (jnp.sqrt(3.0) / 2.0)
normals = get_container_normals()
def hex_cont(c, t):
v = get_unit_hex_verts(c, t)
return jnp.sum(jax.nn.relu(jnp.dot(v, normals.T) - H)**2)
total_cont = jnp.sum(jax.vmap(hex_cont)(centers, thetas))
def hex_ov(i, j):
sep = compute_separation(centers[i], thetas[i], centers[j], thetas[j])
return jax.nn.relu(margin - sep)**2
total_ov = jnp.sum(jax.vmap(hex_ov)(idx_i, idx_j))
return L + weight_cont * total_cont + weight_ov * total_ov
_grad_jit = jax.jit(jax.value_and_grad(objective_fn))
class Improver:
def __init__(self, hex_num=11, seed: int = 0):
self.hex_num = hex_num
self.seed = seed
self.idx_i, self.idx_j = map(jnp.array, np.triu_indices(hex_num, k=1))
def generate_config(self, seed=None) -> tuple[np.ndarray, np.ndarray]:
rng = np.random.default_rng(seed if seed is not None else self.seed)
centers = []


--- Page 13 ---
ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise
KDD â€™26, Under review, Jeju, Korea
weight = 50.0 + 5e6 * jnp.power(prog, 2.8)
def loss_fn(par):
L = jnp.exp(par['log_L'])
# Maintain symmetry constraint
ang = par['angles'] % (jnp.pi / 3.0)
v, a = get_world_data(par['centers'], ang)
c_err = containment_loss(v, L)
o_err = overlap_loss(v, a)
return L + weight * (c_err + 5.0 * o_err), (L, c_err + o_err)
(val, (L, err)), grads = jax.value_and_grad(loss_fn, has_aux=True)(p)
rng, n_rng = jax.random.split(rng)
# Langevin-style noise for escaping local minima
temp = 1e-3 * jnp.exp(-4.0 * prog)
# LLM-EDIT: temp = 2e-3 * jnp.exp(-3.5 * prog)
grads['centers'] += jax.random.normal(n_rng, grads['centers'].shape)
* temp
â†©â†’
updates, state = optimizer.update(grads, state)
p = optax.apply_updates(p, updates)
return (p, state, rng), (L, err)
(final_p, _, _), (h_L, h_e) = jax.lax.scan(step_fn, (params, opt_state,
k3), jnp.arange(total_steps))
â†©â†’
return final_p, h_L[-1], h_e[-1]
batch_size = 96
# LLM-EDIT: batch_size = 256
rng_key = jax.random.PRNGKey(seed)
keys = jax.random.split(rng_key, batch_size)
all_p, all_L, all_e = jax.jit(jax.vmap(optimize_instance))(keys)
# Precision check
valid = all_e < 1e-7
best_idx = jnp.where(valid, all_L, 1e10).argmin()
best_idx = jax.lax.cond(valid[best_idx], lambda: best_idx, lambda:
all_e.argmin())
â†©â†’
res = jax.tree_util.tree_map(lambda x: x[best_idx], all_p)
return np.array(res['centers']), np.array(res['angles']) % (2*np.pi)
for q in range(-5, 6):
for r in range(-5, 6):
if abs(q+r) <= 5:
# Hexagonal lattice base
x = (q + r/2.0) * np.sqrt(3)
y = r * 1.5
# LLM-EDIT: x = q * 1.5
# LLM-EDIT: y = (r + q/2.0) * np.sqrt(3)
centers.append([x, y])
centers = np.array(centers)
dists = np.linalg.norm(centers, axis=1)
# Start with slightly jittered central points
idx = np.argsort(dists + rng.uniform(0, 0.5,
size=len(dists)))[:self.hex_num]
â†©â†’
return centers[idx], rng.uniform(0, np.pi/3, self.hex_num)
# LLM-EDIT: return centers[idx], rng.normal(0, 0.01, self.hex_num)
def perturb(self, input_config, intensity, seed=None):
rng = np.random.default_rng(seed if seed is not None else self.seed)
c, a = map(np.copy, input_config)
if intensity > 2.0:
# Structural swap to escape local optima
i, j = rng.choice(self.hex_num, 2, replace=False)
c[i], c[j] = c[j].copy(), c[i].copy()
a[i], a[j] = a[j].copy(), a[i].copy()
c += rng.normal(0, 0.05 * intensity, c.shape)
a += rng.normal(0, 0.02 * intensity, a.shape)
return c, np.mod(a, np.pi/3)
def improve(self, input_config, seed=None):
centers, angles = input_config
L_est = np.max(np.linalg.norm(centers, axis=1)) + 1.0
x = np.concatenate([centers.flatten(), angles,
[L_est]]).astype(np.float64)
â†©â†’
# Graduated hardening schedule for N=11 precision
stages = [
# EDIT: {'w_cont': 1e2, 'w_ov': 10, 'margin': 1e-3}
{'w_cont': 1e3, 'w_ov': 1e2, 'margin': 1e-3},
{'w_cont': 1e4, 'w_ov': 1e4, 'margin': 1e-4},
{'w_cont': 1e6, 'w_ov': 1e6, 'margin': 1e-5},
{'w_cont': 1e9, 'w_ov': 1e8, 'margin': 1e-7}
]
# LLM-EDIT:
# stages = [
#
{'w_cont': 1e1, 'w_ov': 1e1, 'margin': 1e-1},
#
{'w_cont': 1e3, 'w_ov': 1e3, 'margin': 1e-3},
#
{'w_cont': 1e6, 'w_ov': 1e6, 'margin': 1e-5},
#
{'w_cont': 1e9, 'w_ov': 1e9, 'margin': 1e-7}
# ]
for st in stages:
res = minimize(
lambda p: tuple(map(np.array, _grad_jit(p, self.idx_i, self.idx_j,
st['w_cont'], st['w_ov'], st['margin']))),
â†©â†’
x, method='L-BFGS-B', jac=True,
# EDIT: x, method='SLSQP', jac=True,
bounds=[(-15, 15)]*(2*self.hex_num) + [(0.0,
np.pi/3)]*self.hex_num + [(1.0, 15.0)],
â†©â†’
# EDIT: bounds=[(None, None)]*(2*self.hex_num) + [(None,
None)]*self.hex_num + [(1.0, 15.0)],
â†©â†’
options={'maxiter': 800, 'ftol': 1e-10}
# EDIT: options={'maxiter': 10000, 'ftol': 1e-11}
# LLM-EDIT: options={'maxiter': 1000, 'ftol': 1e-10}
)
x = res.x
final_centers = x[:2*self.hex_num].reshape((self.hex_num, 2))
final_angles = np.mod(x[2*self.hex_num:3*self.hex_num], 2*np.pi)
return final_centers, final_angles
def entrypoint():
return Improver
B
Second Autocorrelation Inequality: Prompt and Evolved Solution


--- Page 14 ---
KDD â€™26, Under review, Jeju, Korea
Kravatskiy et al.
seed 1
seed 3
= 1
= 10
2
= 10
3
final
f(x)
(f*f)(x)
Stage A
Stage B
C(f) = 0.8811
C(f) = 0.9050
C(f) = 0.9078
C(f) = 0.9080
C(f) = 0.9508
C(f) = 0.9512
 best
 final
initialize
from best
Figure 9: Optimization path of the ImprovEvolve validation scheme on the ACI 2 problem. Each column shows the evolved
function ð‘“(ð‘¥) (top row) and its autoconvolution (ð‘“âˆ—ð‘“)(ð‘¥) (bottom row) at a key moment; ð¶(ð‘“) values are displayed between
the rows. Stage A (blue background): two random seeds are generated and improved; seed 3 yields the best initial result
(ð¶(ð‘“) = 0.9050, gold border). Stage B (red background): the perturbâ€“improve cycle is applied with geometrically decreasing
perturbation intensity ðœ€. Iterations at ðœ€= 1 and ðœ€= 10âˆ’2 produce only marginal gains (ð¶(ð‘“) â‰ˆ0.908). At ðœ€= 10âˆ’3 (red arrow),
ð¶(ð‘“) jumps to 0.9508, accompanied by a qualitative change in both ð‘“and ð‘“âˆ—ð‘“. Further refinement yields the final result of
ð¶(ð‘“) = 0.9512 (gold border).


--- Page 15 ---
ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise
KDD â€™26, Under review, Jeju, Korea
B.1
Prompt
B.1.1
Baseline. TASK DEFINITION â€“ SECOND AUTOCORRE-
LATION INEQUALITY
Challenge: Functional optimization in analysis. Implement a Python
function that generates a non-negative function ð‘“: R â†’[0, âˆž) to
maximize the constant ð¶in the second autocorrelation inequality.
Adaptive Resolution: The solver is allowed and encouraged to
choose the optimal resolution (array size ð‘) of the function.
â€¢ Coarse Grids (Lower ð‘): faster iteration and global structure
search.
â€¢ Fine Grids (Higher ð‘): higher precision and higher potential
fitness ð¶.
â€¢ Your solution should ideally be scalable for ð‘up to 100,000.
MATHEMATICAL SPECIFICATIONS
(1) The Function (ð‘“):
â€¢ A discrete 1D array representing a function ð‘“(ð‘¥) on a
finite support.
â€¢ Non-negativity: ð‘“(ð‘¥) â‰¥0 for all ð‘¥.
â€¢ Non-triviality: Ã ð‘“(ð‘¥) > 0.
(2) The Convolution (ð‘”):
â€¢ ð‘”= ð‘“â˜…ð‘“. In the discrete domain, this is the discrete
convolution of the array ð‘“with itself (linear convolution).
(3) The Objective:
â€¢ Maximize the ratio involving the ð¿1, ð¿2, and ð¿âˆžnorms of
the autocorrelation ð‘”.
OBJECTIVE FUNCTION
Maximize the constant ð¶:
ð¶(ð‘“) =
âˆ¥ð‘“â˜…ð‘“âˆ¥2
2
âˆ¥ð‘“â˜…ð‘“âˆ¥1âˆ¥ð‘“â˜…ð‘“âˆ¥âˆž
Target: ð¶â‰¥0.962.
CONSTRAINTS
(1) Validity: All elements of the output array must be non-
negative finite floats.
(2) Bounds: 0.961 â‰¤ð¶â‰¤1.
(3) Minimum Resolution: The final output array must have
length ð‘â‰¥1024 to ensure the discretization approximates
the continuous function reasonably well.
IMPLEMENTATION REQUIREMENTS
Libraries:
Use numpy, jax, optax, scipy, jaxopt, or standard Python libraries.
JAX is preferred for automatic differentiation and GPU accelera-
tion.
Interface:
You must implement the following function structure exactly:
import numpy as np
def entrypoint() -> np.ndarray:
"""
Generates and optimizes a function f to maximize the autocorrelation
constant C.
The function should perform the optimization internally (using JAX/SciPy/etc
.)
and return the final optimized 1D array.
B.1.1
For Improver. TASK DEFINITION â€“ SECOND AUTO-
CORRELATION INEQUALITY
Challenge: Functional optimization in analysis. Implement a Python
class that generates a non-negative function ð‘“: R â†’[0, âˆž) to
maximize the constant ð¶in the second autocorrelation inequality.
Adaptive Resolution: The solver is allowed and encouraged to
change the resolution (array size ð‘) of the function.
â€¢ Coarse Grids (Lower ð‘): faster iteration and global structure
search.
â€¢ Fine Grids (Higher ð‘): higher precision and higher potential
fitness ð¶.
â€¢ Your solution must be scalable for ð‘up to 100 000 (but, of
course, with larger time limits).
MATHEMATICAL SPECIFICATIONS
(1) The Function (ð‘“):
â€¢ A discrete 1D array representing a function ð‘“(ð‘¥) on a
finite support.
â€¢ Non-negativity: ð‘“(ð‘¥) â‰¥0 for all ð‘¥.
â€¢ Non-triviality: Ã ð‘“(ð‘¥) > 0.
(2) The Convolution (ð‘”):
â€¢ ð‘”= ð‘“â˜…ð‘“. In the discrete domain, this is the discrete
convolution of the array ð‘“with itself (linear convolution).
(3) The Objective:
â€¢ Maximize the ratio involving the ð¿1, ð¿2, and ð¿âˆžnorms of
the autocorrelation ð‘”.
OBJECTIVE FUNCTION
Maximize the constant ð¶:
ð¶(ð‘“) =
âˆ¥ð‘“â˜…ð‘“âˆ¥2
2
âˆ¥ð‘“â˜…ð‘“âˆ¥1âˆ¥ð‘“â˜…ð‘“âˆ¥âˆž
Target: ð¶â‰¥0.962.
CONSTRAINTS
(1) Validity: All elements of the output array must be non-
negative finite floats.
(2) Bounds: 0.961 â‰¤ð¶â‰¤1.
(3) Minimum Resolution: The final output array must have
length ð‘â‰¥1024 to ensure the discretization approximates
the continuous function reasonably well.
IMPLEMENTATION REQUIREMENTS
Libraries:
Use numpy, jax, optax, scipy, jaxopt, or standard Python libraries.
JAX is preferred for automatic differentiation and GPU accelera-
tion.
Class Interface:
You must implement the following class structure exactly:
import numpy as np
class Improver:
def __init__(self, seed: int = 0):
"""
Initialize with reproducible random state.
"""
self.seed = seed
# Initialize JAX keys or RNG here


--- Page 16 ---
KDD â€™26, Under review, Jeju, Korea
Kravatskiy et al.
Returns:
f: 1D NumPy array (float) representing the optimized function.
Shape should be at least (1024,).
"""
pass
CRITICAL FAILURE MODES
â€¢ Zero Function: Returning an array of all zeros.
â€¢ Negative Values: Returning ð‘“(ð‘¥) < 0.
â€¢ Dimensionality Errors: Returning a 2D array.
â€¢ Excessively Low Resolution: Returning ð‘< 1000 where
convolution properties degrade significantly.
â€¢ Delusions: Trying to â€œguessâ€ optimal function rather than
searching for it. Believe me, the example for ð¶= 0.961 is a
really strange function.
DOCUMENTATION
Supply your code with a brief explanation of the algorithm, using
LaTeX in the introductory comment.
def improve(self, input_f: np.ndarray) -> np.ndarray:
"""
Refines an existing function f using rigorous local optimization.
ADAPTIVE RESOLUTION:
The output array does NOT need to match the input size.
Args:
input_f: 1D NumPy array of shape (N_in,)
Returns:
improved_f: 1D NumPy array of shape (N_out,)
"""
pass
def perturb(self, input_f: np.ndarray, intensity: float) -> np.ndarray:
"""
Applies DISCRETE, structural, or RESOLUTION modifications.
Args:
input_f: 1D NumPy array.
intensity: Float (1e-3 to 1e3).
Returns:
perturbed_f: 1D NumPy array (size may differ from input).
"""
pass
def generate_config(self, initial_resolution: int = 1000) -> np.ndarray:
"""
Generates a valid starting function f with a maximum possible fitness.
Args:
initial_resolution: Suggested starting size N.
Returns:
f: 1D NumPy array of shape (initial_resolution,)
"""
pass
def entrypoint():
return Improver
CRITICAL FAILURE MODES
â€¢ Zero Function: Returning an array of all zeros.
â€¢ Negative Values: Returning ð‘“(ð‘¥) < 0.
â€¢ Dimensionality Errors: Returning a 2D array.
â€¢ Excessively Low Resolution: Returning ð‘< 1000 where
convolution properties degrade significantly.
â€¢ Excessively High Resolution: Returning ð‘> 20000 where
optimization is very slow. Your solution must work even for
this case, but we will not validate it now, so put in the com-
ments to your program how it should be scaled or program
a â€œself.scale_modeâ€ for your class.
â€¢ Inefficiency: Ignoring the benefits of Multigrid strategies
(not utilizing lower ð‘for fast initial convergence), using a
wrong optimizer, or resorting to extremely large ð‘.
â€¢ Delusions: Trying to â€œguessâ€ optimal function rather than
searching for it. Believe me, the example for ð¶= 0.961 is a
really strange function.
DOCUMENTATION
Supply your code with a brief explanation of the algorithm, using
LaTeX in the introductory comment.


--- Page 17 ---
ImprovEvolve: Ask AlphaEvolve to Improve the Input Solution and Then Improvise
KDD â€™26, Under review, Jeju, Korea
B.2
Evolved Solution Code
B.2.1
Baseline. The following program was evolved by GigaEvo
(Program ID: 175c1208-29b0-4c6a-9323-c73d52804f2f, Fitness: 0.9406,
Generation: 18).
import numpy as np
import jax
import jax.numpy as jnp
import optax
from jax.image import resize
from scipy.optimize import minimize
jax.config.update('jax_enable_x64', True)
def entrypoint() -> np.ndarray:
"""""
Maximizes C(f) = ||f*f||_2^2 / (||f*f||_1 * ||f*f||_inf)
Algorithm:
A hierarchical multi-scale approach targeting fractal-like function supports.
â†©â†’
The strategy uses a stochastic pulse-mixture initialization followed by
coarse-to-fine optimization (N=1024 up to N=65536) using Adam and L-BFGS-B.
The L-infinity norm is approximated by an adaptive p-norm proxy to stabilize
gradients across resolution jumps.
$$ C(f) = \frac{\sum |(f \star f)(x)|^2}{(\sum (f \star f)(x)) \cdot \max (f
\star f)(x)} $$
â†©â†’
"""""
def get_objective(p, alpha=100.0, exact=False):
f = jnp.square(p)
N = f.shape[0]
n_fft = 2**((2 * N - 1).bit_length())
f_fft = jnp.fft.rfft(f, n=n_fft)
g = jnp.fft.irfft(f_fft * f_fft, n=n_fft)[:2*N-1]
g = jnp.maximum(g, 0.0)
l1 = jnp.sum(f)**2
l2_sq = jnp.sum(jnp.square(g))
if exact:
linf = jnp.max(g)
else:
# Detached-max p-norm for stable L-infinity approximation
g_max_stop = jax.lax.stop_gradient(jnp.max(g))
g_normed = g / (g_max_stop + 1e-18)
linf = jnp.power(jnp.sum(jnp.power(g_normed, alpha)), 1.0/alpha) *
g_max_stop
â†©â†’
# Non-negativity and sum constraint are implicit
return -(l2_sq / (l1 * linf + 1e-15))
# 1. Stochastic Initialization (Diversity improvement)
N_base = 1024
key = jax.random.PRNGKey(np.random.randint(0, 10000))
k1, k2, k3, k4 = jax.random.split(key, 4)
# Mixture of spikes and low-frequency components
p = jnp.zeros(N_base)
spikes = jax.random.choice(k1, N_base, shape=(64,), replace=False)
p = p.at[spikes].set(jax.random.uniform(k2, (64,)))
noise = 0.1 * jax.random.normal(k3, (N_base,))
low_freq = jnp.abs(jnp.fft.irfft(jax.random.normal(k4, (N_base//4,)),
n=N_base))
â†©â†’
p = p + noise + low_freq
# 2. Multi-scale Adam Phase
# Resolutions and alpha schedules for progressive refinement
resolutions = [1024, 4096, 16384]
alphas = [64.0, 128.0, 256.0]
lrs = [0.01, 0.005, 0.002]
current_p = p
for res, alpha, base_lr in zip(resolutions, alphas, lrs):
if current_p.shape[0] != res:
current_p = resize(current_p, (res,), method='cubic')
optimizer = optax.adam(optax.cosine_decay_schedule(base_lr, 1000))
opt_state = optimizer.init(current_p)
@jax.jit
def train_step(params, state, a):
loss, grads = jax.value_and_grad(get_objective)(params, a, False)
updates, next_state = optimizer.update(grads, state, params)
return optax.apply_updates(params, updates), next_state
B.2.1
For Improver. The following program was evolved by Im-
provEvolve (Program ID: b8dadcb7-a2a7-452d-93ec-386e06ea1cb8,
Fitness: 0.9512, Generation: 11). Lines marked with EDIT START/END
show the human modifications applied in the ImprovEvolve+E vari-
ant: the multi-grid schedule was scaled up to accommodate AlphaE-
volveâ€™s 50 000-step solution and progressively refine it up to 1.6
million steps.
import numpy as np
import jax
import jax.numpy as jnp
import optax
import jaxopt
# LaTeX: C(f) = \frac{\|f \star f\|_2^2}{\|f \star f\|_1 \|f \star f\|_\infty}
# We use a multi-grid strategy with JAX and an adaptive LogSumExp approximation.
# Resolution scales up to 32768, and Beta scales to 50000 for high-precision
convergence.
â†©â†’
class Improver:
def __init__(self, seed: int = 0):
self.seed = seed
self.key = jax.random.PRNGKey(seed)
@staticmethod
@jax.jit
def calculate_c_loss(w, beta):
f = jnp.square(w)
n = f.shape[0]
n_fft = 2**((2*n - 1).bit_length())
f_fft = jnp.fft.rfft(f, n=n_fft)
g = jnp.fft.irfft(f_fft * f_fft, n=n_fft)[:2*n-1]
g = jnp.maximum(g, 0.0)
l2_sq = jnp.sum(jnp.square(g))
l1 = jnp.sum(g) + 1e-10
# Stabilized LogSumExp to approximate L_infinity
g_max = jnp.max(g)
linf_proxy = jax.nn.logsumexp(beta * (g / (g_max + 1e-10))) / beta * g_max
# Objective: Maximize C -> Minimize -C
return -(l2_sq / (l1 * linf_proxy + 1e-10))
def improve(self, input_f: np.ndarray) -> np.ndarray:
w = jnp.sqrt(jnp.maximum(jnp.array(input_f), 1e-10))
# Multi-grid schedule: increase resolution and beta (sharpness)
concurrently
â†©â†’
# Final stage at 32k resolution with very high beta for precision
stages = [
{"res": 4096, "beta": 800, "iters": 1000},
{"res": 16384, "beta": 5000, "iters": 2000},
{"res": 32768, "beta": 50000, "iters": 3000}
]
# Our own edit to effectively start from the AlphaEvolve's solution:
# EDIT START
# w = jnp.sqrt(jnp.maximum(jnp.array(input_f), 0)) # removed 1e-10
# stages = [
#
{"res": max(100000, len(input_f)),
"iters": 10000, "beta": 20000,},
#
{"res": max(200000, len(input_f)),
"iters": 10000, "beta": 20000,},
#
{"res": max(400000, len(input_f)),
"iters": 10000, "beta": 20000,},
#
{"res": max(800000, len(input_f)),
"iters": 10000, "beta": 20000,},
#
{"res": max(1600000, len(input_f)),
"iters": 10000, "beta": 20000,},
# ]
# EDIT END
for st in stages:
if len(w) != st["res"]:
# Use linear resizing to avoid Fourier/Gibbs artifacts
w = jax.image.resize(w, (st["res"],), method='linear')
def obj_fn(weights):
return self.calculate_c_loss(weights, st["beta"])
lbfgs = jaxopt.LBFGS(fun=obj_fn, maxiter=st["iters"], tol=1e-12)
w = lbfgs.run(w).params
final_f = np.square(np.array(w))
return final_f / (np.max(final_f) + 1e-15)
def perturb(self, input_f: np.ndarray, intensity: float) -> np.ndarray:
self.key, subkey = jax.random.split(self.key)


--- Page 18 ---
KDD â€™26, Under review, Jeju, Korea
Kravatskiy et al.
for _ in range(1000):
current_p, opt_state = train_step(current_p, opt_state, alpha)
# 3. High-Resolution Polish (L-BFGS-B)
N_final = 65536
current_p = resize(current_p, (N_final,), method='cubic')
@jax.jit
def val_and_grad_fn(p_in):
# Use higher alpha for more exactness but still differentiable
return jax.value_and_grad(get_objective)(p_in, alpha=512.0, exact=False)
def scipy_interface(p_np):
p_jax = jnp.array(p_np)
v, g = val_and_grad_fn(p_jax)
return np.array(v, dtype=np.float64), np.array(g, dtype=np.float64)
res_opt = minimize(
scipy_interface,
np.array(current_p, dtype=np.float64),
method='L-BFGS-B',
jac=True,
options={'maxiter': 2500, 'ftol': 1e-12}
)
f_final = np.square(res_opt.x)
f_final = np.maximum(f_final, 0.0)
v_max = np.max(f_final)
if v_max > 0:
f_final /= v_max
else:
f_final = np.ones(N_final)
return f_final.astype(np.float64)
n = len(input_f)
f = jnp.array(input_f)
# Randomly roll or apply mirror symmetry to find better global shapes
if jax.random.uniform(subkey) > 0.5:
f = jnp.flip(f)
noise = jax.random.uniform(subkey, (n,)) * intensity * 0.1
f = jnp.maximum(f + noise, 0.0)
return np.array(f)
def generate_config(self, initial_resolution: int = 2048) -> np.ndarray:
# Start with a denser initialization to provide more gradient paths
n = max(initial_resolution, 1024)
self.key, subkey1, subkey2 = jax.random.split(self.key, 3)
# Mix of uniform noise and specific pulses
f = jax.random.uniform(subkey1, (n,), minval=0.0, maxval=0.1)
spike_pos = jax.random.randint(subkey2, (32,), 0, n)
f = f.at[spike_pos].set(jax.random.uniform(subkey2, (32,), minval=0.5,
maxval=1.0))
â†©â†’
# Small smoothing to help initial L-BFGS
x = jnp.linspace(-2, 2, 5)
kernel = jnp.exp(-x**2)
f = jnp.convolve(f, kernel / jnp.sum(kernel), mode='same')
return np.array(f / (jnp.max(f) + 1e-12))
def entrypoint():
return Improver
C
LLM-Based Program Tuning: Prompt
The following prompt was used to evaluate whether Gemini 3 Pro could replicate the expert-guided edits of ImprovEvolve+E (see Table 4 for
results).
Your objective is to improve the program that solves the given mathematical challenge while making only minimal modifications to the existing
code. Allowed changes include adjusting numerical constants, modifying parameter values, or replacing function arguments.
Do not rewrite the program or restructure its logic; prioritize the smallest possible edits that lead to improved performance or correctness.
Program: [evolved program inserted here]
Challenge: [task description inserted here]
