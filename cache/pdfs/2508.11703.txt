--- Page 1 ---
Data-Driven Discovery of Interpretable Kalman Filter Variants
through Large Language Models and Genetic Programming
Vasileios Saketos1, 2, Sebastian Kaltenbach1, Sergey Litvinov1, Petros Koumoutsakos 1, *
1Computational Science and Engineering Laboratory, Harvard University, Cambridge, USA
2KTH Stockholm
* Corresponding author: petros@seas.harvard.edu
Abstract
Algorithmic discovery has traditionally relied on human in-
genuity and extensive experimentation. Here we investigate
whether a prominent scientific computing algorithm, the
Kalman Filter, can be discovered through an automated, data-
driven, evolutionary process that relies on Cartesian Genetic
Programming (CGP) and Large Language Models (LLM).
We evaluate the contributions of both modalities (CGP and
LLM) in discovering the Kalman filter under varying condi-
tions. Our results demonstrate that our framework of CGP and
LLM-assisted evolution converges to near-optimal solutions
when Kalman optimality assumptions hold. When these as-
sumptions are violated, our framework evolves interpretable
alternatives that outperform the Kalman filter. These results
demonstrate that combining evolutionary algorithms and gen-
erative models for interpretable, data-driven synthesis of sim-
ple computational modules is a potent approach for algorith-
mic discovery in scientific computing.
Introduction
In the past decades, algorithm design has been a manual
process that relies heavily on domain knowledge and ad-
vanced mathematics. Recent advances in machine learning,
particularly in program synthesis via Large Language Mod-
els (Romera-Paredes et al. 2024; Novikov et al. 2025; Surina
et al. 2025) as well as evolutionary computation (Cortacero
et al. 2023), now open the possibility of automating parts of
this process. A key area of interest is the development of
methods that generate algorithms that are interpretable and
can adapt to complex real-world environments.
This work explores algorithmic discovery in the context of
estimating unknown variables based on time-series data, us-
ing the Kalman filter (Kalman 1960), a prominent scientific
computing algorithm, as a canonical target. The Kalman
filter is a classical, recursive algorithm for estimating the
state of a linear dynamical system observed through noisy
measurements. Under certain assumptions (i.e. a linear
system and Gaussian noise), it yields the optimal minimum
mean squared error (MSE) estimator. Various variants such
as the Extended Kalman Filter (EKF) (Gelb et al. 1974) and
the Unscented Kalman Filter (UKF) (Julier and Uhlmann
1997) exist that allow the aferomentioned assumptions to be
relaxed. While these variants preserve the recursive nature
of the original algorithm, they are not optimal estimators
and can lead to a degrade in performance.
In parallel, deep learning models such as Recurrent Neural
Networks (RNNs) (Rumelhart, Hinton, and Williams 1986),
Long Short-Term Memory (LSTM) networks (Hochre-
iter and Schmidhuber 1997), and Gated Recurrent Units
(GRUs) (Cho et al. 2014) have been proposed to estimate
unknown quantities using a learned relation based on given
data. Despite their success in capturing nonlinear behaviors,
such models lack interpretability, require large training
sets, and often generalize poorly outside their training
distribution.
This paper proposes a data-driven framework for discov-
ering the state of a system based on noisy observations.
Our framework combines the adaptability of data-driven
methods with the interpretability and efficiency of classical
solutions. The approach relies on modern tools —specif-
ically Cartesian Genetic Programming (CGP) and Large
Language Models (LLMs) — to search over symbolic
representations of algorithms using only input–output
trajectories and a black-box fitness function. Our primary
goal is not to rediscover the Kalman filter structure but to
discover new data-driven variants that can compute accurate
estimators for scenarios where it was previously impossible.
The key contributions of this work are as follows:
• We introduce an algorithm discovery framework based
on Cartesian Genetic Programming and LLM-assisted
evolutionary search (ES).
• We evaluate both the LLM-assisted ES and CGP for al-
gorithmic discovery.
• We evaluate our framework under a range of challenging
scenarios, including non-linearity, non-Gaussian noise,
and irregular time sampling — and show that it produces
suitable algorithms for these settings.
• We release all code and discovered algorithms. The code
is available here 1.
Related Work
Genetic Programming (GP) is a framework within evo-
lutionary computation that evolves computer programs by
1URL will be added upon publication
arXiv:2508.11703v2  [cs.NE]  25 Aug 2025


--- Page 2 ---
simulating principles of natural evolution, including selec-
tion, mutation, and crossover (Koza 1992; Poli, Langdon,
and McPhee 2008). Cartesian Genetic Programming (CGP)
(Miller and Turner 2015) extends GP by introducing a
structured representation of the solution space in the form
of fixed-length directed acyclic graphs, thereby facilitating
more localized and stable mutations. In general, CGP al-
gorithms maintain a population of candidate solutions that
are iteratively refined based on random sampling and mu-
tations as well as the performance on a pre-defined fitness
function. A central challenge in CGP lies in the design of
mutation operators and the choice of building blocks (the
graph nodes), which critically affect the efficiency and ef-
fectiveness of the search process. The selection of the build-
ing blocks and mutation operators is inherently empirical,
and suboptimal choices can significantly degrade the per-
formance of the evolved programs. Since these elements
are typically problem-specific, their design requires knowl-
edge and intuition about the nature of the problem. Recently,
CGP has been successfully adopted to discover algorithms
for biomedical image analysis (Cortacero et al. 2023) using
primitive image modification operators as building blocks.
For the present work, we choose building blocks based on
fundamental mathematical operations to allow for general
algorithmic discovery.
LLMs have not only revolutionized the field of Natural Lan-
guage Processing, but have been successfully applied across
numerous scientific domains. Their success would have not
been possible without the advent of the Transformer ar-
chitecture (Vaswani et al. 2017) that allowed the develop-
ment of earlier models such as BERT (Devlin et al. 2019)
and GPT (Brown et al. 2020). Recently, reasoning capa-
bilities have become a central focus in LLM development,
with DeepSeek (Guo et al. 2025) emerging as first open-
source model to rival the performance of closed-source al-
ternatives (Comanici et al. 2025) by combining large-scale
pretraining with reinforcement learning techniques to en-
hance logical inference capabilities. As such LLMs in gen-
eral consist of billions of parameters, techniques such as
QLoRA (Dettmers et al. 2023) have been developed to en-
able memory-efficient inference and fine-tuning through 4-
bit quantization and parameter-efficient adaptation.
Automatic algorithmic discovery can be based on LLMs as
they can be employed to generate new program variants by
using their ability to produce a wide spectrum of syntacti-
cally and semantically meaningful mutations based on rep-
resentations learned during pretraining, thereby eliminating
the need for manually defined primitive sets or mutation
operators as in GP. Recently, Funsearch (Romera-Paredes
et al. 2024) was introduced as a hybrid framework that com-
bines Large Language Models with evolutionary search. It
enables the automated generation of high-quality program
variants guided by task-specific evaluation. Through the use
of Funsearch, the authors were able to automatically gener-
ate state-of-the-art heuristics for several challenging combi-
natorial problems, including bin packing (Ausiello, Lucer-
tini, and Serafini 1984), the cap set (Grochow 2018), and
the admissible sets problem (Tao and Vu 2006). AlphaE-
volve (Novikov 2025) is a recently introduced coding agent
that extends the capabilities of Funsearch by enabling the
evolution of entire source files rather than isolated functions.
This led to the discovery of state-of-the-art algorithms, in-
cluding a novel method for 4 × 4 complex matrix multipli-
cation that requires only 48 scalar multiplications (Strassen
1969; Novikov 2025). Our framework relies both on CGP
and LLMs and the LLM part is heavily inspired by Fun-
search (Romera-Paredes et al. 2024) and its successor Al-
phaEvolve (Novikov 2025) but as no open-source software
has been released for both of these framework, we imple-
mented our LLM-assisted evolutionary search framework
ourselves.
The Kalman Filter
The Kalman filter is an important algorithm in scientific
computing used for estimating the internal state of a dynami-
cal systems from (potentially noisy) observations. Originally
introduced by Rudolf K´alm´an (Kalman 1960) for systems
with discrete time steps and later extended for continuous
time systems (Kalman and Bucy 1961). Its effectiveness in
early aerospace applications, such as the Apollo navigation
system (Bierman 1977), highlighted its practical value and
efficiency. In contemporary cyber-physical systems, Kalman
filtering continues to serve as a fundamental tool in domains
such as robotics, autonomous navigation, and sensor fusion
(Grewal and Andrews 2015).
The discrete-time Kalman filter is designed for systems
modeled as linear dynamical processes disturbed by Gaus-
sian noise. It assumes that the system dynamics and observa-
tion models are linear, with both processes subject to Gaus-
sian noise. Let xt ∈Rn denote the hidden state of the system
at time t, and zt ∈Rm the observed measurement. The sys-
tem evolves according to the following discrete-time linear
state-space equations:
xt = Fxt−1 + But−1 + wt−1,
wt−1 ∼N(0, Q)
(1)
zt = Hxt + vt,
vt ∼N(0, R)
(2)
Where, F ∈Rn×n is the state transition matrix, B ∈
Rn×k is the control input matrix, H ∈Rm×n is the obser-
vation matrix. Q and R are the covariance matrices of the
process and observation noise respectively. The control in-
put ut−1 is assumed to be known.
The Kalman filter operates recursively in two main steps:
predict and update. In the predict step, it projects the cur-
rent state and its uncertainty forward in time, estimating the
system’s next state without incorporating new observations.
ˆxt|t−1 = F ˆxt−1|t−1 + But−1
(3)
Pt|t−1 = FPt−1|t−1F ⊤+ Q
(4)
Where, ˆxt|t−1 is the prior estimate of the state at time t,
and Pt|t−1 is the corresponding error covariance matrix.
Upon receiving the observation yt, the update step adjusts
the prediction using the measurement:
Kt = Pt|t−1H⊤ HPt|t−1H⊤+ R
−1
(5)
ˆxt|t = ˆxt|t−1 + Kt(yt −Hˆxt|t−1)
(6)
Pt|t = (I −KtH)Pt|t−1
(7)


--- Page 3 ---
The matrix Kt is the Kalman gain, determining the rela-
tive weighting between the predicted state and the new ob-
servation. The posterior estimate ˆxt|t combines the prior
with the measurement residual, while Pt|t reflects the re-
duced uncertainty after the update.
The Kalman filter is optimal under the assumptions of lin-
earity and Gaussian noise, providing the minimum mean
squared error (MMSE) estimate of the state. However, if
the noise deviates from Gaussianity, or the system dynam-
ics are nonlinear, the theoretical guaranties do not longer
hold and the filter’s performance can degrade. In such cases,
extensions like the Extended Kalman Filter (EKF) or Un-
scented Kalman Filter (UKF) are employed. Nevertheless,
these methods are not theoretically optimal and often require
additional information, such as the computation of Jacobians
in the case of EKF, or careful parameter tuning and prior
knowledge of system structure, which may limit their appli-
cability in complex or poorly understood systems.
Methodology
Within this work, we phrase algorithmic discovery as an op-
timization problem which is subsequently solved using an
iterative refinement procedure. We do not need to provide
any details regarding the actual algorithm that is going to be
discovered, but only an evaluation function that can compute
a score for each suggested algorithm. Our framework builds
both on LLM as well as Cartesian Genetic Programming. A
general overview can be found in Figure 1.
At the core of the framework is a database that contains the
current best performing algorithms discovered by both LLM
and CGP and their corresponding scores. Despite operating
in distinct solution spaces, both the CGP and LLM based
approach aim to solve the same optimization problem. As
CGP is operated on CPUs and the LLMS on GPU this pro-
cess can be easily parallelized and we can efficiently use all
available hardware resources. The framework operates us-
ing three phases: Sampling, Mutation, and Evaluation. In the
sampling stage, solutions are sampled from the database, fa-
voring those with higher fitness value. During the mutation
phase, both the CGP and the LLM based approach apply
transformations to the sampled candidates with the objective
of generating improved solutions. In Cartesian Genetic Pro-
gramming (CGP), mutations involve altering node connec-
tions or changing the type of computational nodes, which are
chosen from a predefined set of functions. The graph struc-
ture has a fixed size, and mutations operate within these con-
straints to explore different computational pathways. In con-
trast, for the LLM-assisted evolutionary search, mutations
are applied by modifying the structure of symbolic func-
tions, allowing for more flexible and expressive changes.
This approach can dynamically introduce new syntactic ele-
ments, effectively expanding the representation space as the
search progresses. As shown in Figure 1, the system takes
a problem specification along with two sampled candidate
solutions and creates the prompt. The prompt is forwarded
to the actual LLM, which in our case is a publicly avail-
able model from DeepSeek (Guo et al. 2025). The LLM pro-
cesses the prompt and produces mutations and combinations
of the two input functions.
After generation, each candidate solution is evaluated based
on a fitness/loss function. Although the CGP- and LLM-
assisted approaches employ different internal representa-
tions, they are both designed to operate over the same input
and output interfaces. This alignment enables the use of a
single, well-defined lfitness function to assess solution qual-
ity across both approaches in parallel. The functions and fit-
ness values are used to update the database that maintains
the top N highest-scoring candidates.
A more detailed description of both approaches can be found
below:
LLM assisted evolutionary search
Our LLM-assisted ES is strongly inspired by Funsearch
(Romera-Paredes et al. 2024). However, as no official
publicly available code is available, we implemented it
ourselves based on the available descriptions. This im-
plementation was done utilizing the transformers library
of Hugging Face (Wolf et al. 2019) and we employed
the DeepSeek-R1-Distill-Qwen-14B model (Guo et al.
2025). We note that we also tested other models within the
DeepSeek family but models with fewer than 14 billion
parameters tended to produce repetitive and low-quality
generations, whereas larger models introduced significant
latency and substantially increased computational costs. We
thus identified the 14B model as offering the best trade-off
between efficiency and output quality. To ensure that the
obtained framework is comparable to Funsearch, we applied
it to the backpacking task as defined in the Funsearch paper
(Romera-Paredes et al. 2024) and obtained comparable
results. A detailed description of this experiment and its
results can be found in Appendix A.
For all our experiments, we employed a solution database
that retains the 200 best solutions and their corresponding
fitness value. For each mutation step, 60 candidates are sam-
pled. The selection probability Pi for the i-th candidate is
given by:
Pi =
e−fi
T
P
j e−
fj
T
where fi denotes the fitness value of the i-th candidate,
and T is the temperature parameter controlling the trade-off
between exploitation and exploration. This mechanism fa-
vors higher-quality solutions while still allowing exploration
based on including lower-performing ones. Afterwards, we
instruct the LLM to generate combinations and mutations,
where each prompt has as an input two of the chosen candi-
date functions from the data base as well as a prototype that
the generated functions must adhere to. A key component of
our approach is to generate multiple variants (mutations) for
each prompt. This capability was largely impractical with
earlier generation language models such as PaLM (Chowd-
hery et al. 2023) and StarCoder (Li et al. 2023), which more
frequently produced repetitive or poorly aligned outputs that
did not adhere to the specified function definitions. We set
the number of output tokens of the LLM max len = 3,000
tokens as a trade-off between computational efficiency and
exploration.


--- Page 4 ---
k Sampled 
Functions
k Sampled 
Graphs
Sampler
2
   Database   
1
0.9
5
0.1
0.05
0.5
2.2
Sampling
Mutation
Evaluation
CGP
Problem 
Specification
Add
LLM
loss 
Prompt
Figure 1: General overview of our framework for algorithmic discovery: Algorithm candidates are stored in a database. To
generate new algorithm variants using either CGP or LLM-assisted ES, algorithms are samples from the database and mutated.
Subsequently, the new algorithm variants are evaluated using a fitness function and newly identified top performing algorithms
are incorporated into the database.
We note, that the ES is distributed across four independent
islands as suggested in (Romera-Paredes et al. 2024) and
each island is executed on a separate GPU and uses its own
database. After 10 iterations of sampling, mutation and up-
dating the database, the stored algorithms of the islands with
the weakest top-performing candidates are cleared and reini-
tialized with the best candidate from the island that achieved
the highest performance.
Cartesian Genetic Programming
Our implementation of CGP is inspired by the work of
Cortacero et al. (Cortacero et al. 2023). The solutions are
represented as directed acyclic graphs with a fixed maxi-
mum size. In each mutation step, we choose 30 graphs from
the database using the same sampling rule as in the LLM-
assisted ES. For each chosen graph, we generate 1000 vari-
ants. The mutations involve altering node connections or
changing the type of computational nodes, which are cho-
sen from a predefined set of functions. In our case this set of
functions include addition (+), assignment (=), matrix multi-
plication (@), and matrix inversion (inv). In our CGP setup,
we employ the island model exactly as used in the LLM-
assisted ES with the difference that each island uses a pre-
defined amount of CPU resources instead of a GPU.
The hyperparameters used for both approaches are summa-
rized in Appendix B.
Experiments
We apply the proposed framework for scientific discovery
to datasets from dynamical systems and try to find an algo-
rithm that predicts the state representation based on noisy
observations. While we know that for linear dynamical sys-
tems with Gaussian noise the resulting algorithm should be
the Kalman Filter due to its theoretical optimality, for other
dynamical systems of interest with different added noise the
optimal estimation algorithm is in general unknown.
To generate the trajectory data, we consider a linear time-
invariant, discrete-time dynamical system that is modeling
the position and velocity of an object. This system is gov-
erned by the following equation xk = Fxk−1 +Gak, where
the state xk = [pk, vk]T includes position and velocity, and
the random acceleration input ak ∼N(0, σ2
a) induces pro-
cess noise wk = Gak with covariance Q = GG⊤σ2
a. F de-
scribes the system’s dynamics. The system is fully observ-
able via a linear measurement model zk = Hxk + vk, with
H = I and measurement noise vk ∼N(0, σ2
zI). More de-
tails can be found in the Appendix C.
The described system serves as a canonical benchmark for
filtering and control tasks (Greenberg, Yannay, and Mannor
2023; Freirich, Michaeli, and Meir 2023) and in the present
form fulfills all constraints such that Kalman-Filer is the op-
timal estimator for the state based on noisy observations.
We note that each algorithm candidate takes as input the cur-
rent state estimate, system dynamics, covariance matrices,
and the latest observation. To assess performance and com-
pute the fitness value of each algorithm candidate, we com-
pute the mean squared error (MSE) between the estimated ˆx
and true states x on a trajectory of length T:
L = 1
T
T
X
k=1
∥ˆxk −xk∥2
(8)
As evaluating the performance of candidates for algorithms
is done multiple times, we only use a single trajectory
of 200 time steps for these evaluations during training to
ensure rapid evaluation and high-throughput during the
discovery process.
To ensure robustness and generalization, all candidates
are evaluated on a substantially larger validation set com-
prising 50 independently simulated trajectories, each of
length 500. The best-performing algorithm on this set is se-
lected for final evaluation on an unseen test set of equal
size and structure. This protocol ensures that final perfor-
mance reflects true generalization to new trajectories and


--- Page 5 ---
Method
CGP
LLM-assisted ES
Random Search
predict
0.995077 ± 9e−3
0.995493 ± 9e−3
1.009967 ± 9e−3
predict + update
0.995220 ± 9e−3
1.968045 ± 1e−2
1.209344 ± 1e−2
Table 1: MSE loss ± standard error of our methods compared to Kalman Filter performance (0.995077). Green highlights
optimal or near-optimal, yellow/orange indicates moderate deviation, and red marks the least favorable outcomes in each row.
noisy realizations, rather than overfitting to a specific train-
ing instance. For each of our experiments, we ran the LLM-
assisted ES twice on four H100 GPUs each whereas the CGP
was executed a total of fifteen times using sixty-four CPUs
each. Each run was executed over a period of a maximum of
72 hours.
To establish a baseline for our algorithm’s performance, we
use random search. Random search generates K graph nodes
and connects them arbitrarily to form valid computational
graphs. The connections ensure a valid path from inputs to
outputs, without any optimization or heuristics.
(Re)discovering the Kalman Filter
For the first experiment, we choose the dynamical system
as described in the previous section which fulfills all the
criteria for the optimality of the Kalman Filter. We note that
apart from the evaluation function that is used to score each
discovered algorithm, no further details about the Kalman
Filter are provided and we are uncovering the structure and
behavior of the Kalman filter purely data-driven through
finding the best fitness value — specifically, by minimizing
the mean squared error (MSE) between its state estimates
and the true latent states over time.
We evaluate performance on two principal benchmarks.
The first, and conceptually simplest, assesses the ability to
reconstruct the Kalman filter’s prediction step, assuming
that the update step is already known. This corresponds
to equation 3 and 4 in the original Kalman-Filter that we
attempt to rediscover. The second benchmark requires
reconstructing the full Kalman filter, including both the
prediction and update steps.
In case of the task to to rediscover the first half of the
Kalman filter only, i.e. the predict operator, both CGP
and LLM-assisted ES receive the state transition matrix
F, current state x, covariance P, and process noise Q as
an input, and must output the predicted state xpredict and
updated covariance P. In the full Kalman filter task, they
are also given the measurement z and measurement noise R,
and must produce xpredict, P, y (innovation), S (innovation
covariance), K (Kalman gain), and xupdate (updated state).
However, we note that we pass all inputs without any
description and even use a generic representation. Together
with not providing our framework any information regard-
ing the semantic nature of the task or the internal structure
of the target algorithm, this is done to rigorously prevent
data leakage. Especially in case of the LLM-assisted ES, it
can be assumed that the LLM has seen the Kalman-Filter
during training and including a task description or variable
names in the prompt would significantly accelerate the
discovery. Instead, we only explicitly define the target
function signature, specifying the exact number and order
of input and output variables using a generic names (i.e.
inputs i1, . . . , in; outputs o1, . . . , om). This guarantees that
the search process is limited to a fixed function design,
but prevents passing any indirect hints when generating
programs. We note that data leakage is not a concern for the
CGP approach.
Table 1 presents the MSE loss and the standard error for
different methods, benchmarked against the Kalman filter,
which serves as the lower bound. We note that CGP suc-
cessfully discovered the optimal predict program, match-
ing the Kalman filter’s performance, while LLM-assisted ES
closely approximated it. As CGP operates within a bounded
search space, i.e. a finite number of nodes and building
blocks, the complexity of the solution is constrained al-
though the actual number of possible combination of these
building blocks can still be very high. For LLM-assisted ES,
by contrast, very long and complicated candidate algorithms
can be generated that tend to overfit which negatively im-
pacts the evolutionary search close to the optimal solution.
For the full predict + update task, CGP maintains near-
optimal performance. In contrast, our LLM-assisted ES
tends to appear to stuck in local minima. This limitation is
likely due to computational constraints: Firstly, the utilized
LLM is using 14 billion parameters only and larger mod-
els could lead to better performance. Secondly, we limit the
number of generated tokens per prompt, which reduces the
number of new candidates that are generated in the muta-
tion steps. The difference in performance between CGP and
LLM-assisted ES further justifies our approach of employ-
ing both methods to establish a robust framework for sci-
entific discovery across diverse settings and tasks. We note
that in Appendix D, we present an ablation study where we
progressively increase the difficulty by increasing the per-
centage of the Kalman filter that is to be discovered. There,
we analyze in detail when the drop in performance of the
LLM-assisted ES occurs. Random Search discovered a com-
petitive program for the simple predict task but degraded
for the full Kalman Filter. This is expected, as more com-
plex problems yield a significantly larger solution space,
reducing the probability of discovering optimal solutions
through purely random exploration. Our framework signifi-
cantly outperforms this baseline for both tasks.
Beyond the Kalman filter
In this section, we investigate the applicability of our
methods in scenarios where the Kalman filter is no longer
the optimal solution. Our objective is to assess whether our


--- Page 6 ---
Legend: - - - Observations, ··· Kalman filter, - - - Random Search, – · – LLM-assisted ES, — CGP.
0
100
200
300
400
500
Time Step
0.0
0.5
1.0
1.5
2.0
Mean Squared Error
(a) Half Gaussian Noise
0
100
200
300
400
500
Time Step
0
10
20
30
Mean Squared Error
(b) Delayed observations
0
100
200
300
400
500
Time Step
0
1
2
3
4
Mean Squared Error
(c) Non-linear dynamics
Figure 2: Mean squared error (MSE) of discovered algorithms and baselines for different settings.
LLM-assisted ES
CGP
Random Search
Kalman filter
Observations
Half Gaussian Noise
0.5618 ± 6e−3
0.6032 ± 5e−3
0.6116 ± 5e−3
1.6221 ± 1e−2
1.9680 ± 1e−2
Delayed observation
4.9601 ± 5e−1
2.2788 ± 1e−1
6.9536 ± 4e−1
10.6176 ± 1e−1
16.7031 ± 2e+1
Nonlinear Dynamics
0.8064 ± 8e−3
0.8760 ± 6e−3
0.9589 ± 7e−3
1.0235 ± 2e−2
1.9680 ± 1e−2
Table 2: Mean squared error (MSE) of discovered algorithms and baselines under different conditions (mean ± standard error).
Color gradients indicate performance per row: green for best, orange/yellow for moderate, and red for worst.
algorithmic discovery frameworks can synthesize robust and
interpretable programs that surpass the Kalman filter’s per-
formance under violated assumptions. To this end, we con-
sider challenging settings characterized by non-Gaussian
noise, delayed observations, and nonlinear system dynam-
ics. As currently no optimal algorithm exists for these set-
ting, we do not have to worry about data leakage. Thus,
in contrast to the previous setting, the language model is
provided with complete information about the underlying
problem to leverage the full knowledge acquired during pre-
training for discovering robust and interpretable algorithms.
Moreover, the starting databases are initialized using the
original Kalman filter combined with random initializations.
We observed that this lead not only to faster convergence but
also to algorithms that can be more easily interpreted due to
being closer to the roginal Kalman-Filter. We note that in
general LLM-assisted ES was relativly robust regarding the
initialization as the LLM was also able to correctly recon-
struct the Kalman filter from the prompt alone in case none
of the initial algorithm corresponded to a Kalman-Filter. In
contrast, CGP showed improved performance, likely due to
a well-chosen starting point with the original Kalman-Filter
and enhanced exploration thanks to the random initializa-
tions.
As a first task, we modified the dynamical system from
the previous experiment by introducing asymmetric noise
via a Half-Gaussian distribution. We apply our frameworks
to assess whether discovered algorithms can outperform the
Kalman filter under this violation of classical assumptions.
Next, we simulate a setting with randomly delayed obser-
vations. Again we consider the dynamcial system from the
previous experiment but at each time step, the observation
corresponds to a slightly earlier time, with the delay sam-
pled uniformly from a fixed range. Since this delayed time
typically falls between two discrete simulation steps, we in-
terpolate between adjacent ground-truth states to generate
the corresponding observation. Our model, however, is not
informed about this delayed observation and processes this
delayed observation as if it were current. This setup mimics
real-world sensor latency and breaks the Kalman filter’s as-
sumption of synchronized dynamics and observations, pro-
viding a challenging scenario for assessing the robustness of
discovered programs.
Finally, we evaluate our frameworks in a setting with non-
linear but known dynamics. The state evolves according to
xt+1 = F·g(xt)+wt, where g(x) introduces structured non-
linearities such as cubic and sinusoidal terms. Although the
dynamics deviate from linearity, their structure is assumed to
be fully known. The observations remain linear. This exper-
iments tests the ability of our methods to discover effective
estimators in settings where classical linear filters, such as
the Kalman filter, are no longer applicable.
Figure 2 presents the MSE and the standard error trajec-
tories over 500 time steps for the three scenarios. The corre-
sponding time-averaged MSE values are reported in Table 2.
In the half-Gaussian noise scenario, the algorithm discov-
ered by LLM-assisted ES achieves a steady-state MSE of
0.56, corresponding to a nearly threefold improvement over
the Kalman filter, which plateaus at 1.62. As shown in the
leftmost panel, the performance gap between the discovered
algorithms and the Kalman filter remains consistently large
throughout the time horizon, highlighting the persistent ad-
vantage of program-discovered estimators under asymmet-
ric noise conditions.
In the delayed observation setting (Figure 2, center), all
methods exhibit increasing error over time due to the accu-


--- Page 7 ---
def function_approximate(x, F, P, Q, z, R):
xp =F @x
P_new =F @P @F.T +Q
y =z -xp
S =P_new +R +F.min(axis=1)[:, None] *1.2
inv_S =np.linalg.inv(S)
K =(P_new @inv_S) *0.85
x =xp +K @y
P =(P_new -K @S @K.T) *0.95
return xp, P, y, S, K, x
def graph_approximate(x, F, P, Q, z, R):
A =R.T +x
y =P -A
S =(y +F).T @P +A
K =np.linalg.inv(S)
x =R -(A +R.T) @K
P =np.linalg.inv(y)
return xp, P, y, S, K, x
Figure 3: Functions discovered for Half Gaussian Noise by LLM-assisted ES on the left and CGP discovered function on the
right.
mulation of misalignment between the latent state and de-
layed observations. This effect becomes more pronounced
as the object accelerates, making the object’s position in-
creasingly sensitive to temporal discrepancies. The Kalman
filter, which assumes perfectly synchronized observations,
performs poorly under this violation, yielding a high average
MSE of 10.62 (Table 2). In contrast, the algorithms discov-
ered by LLM-assisted and CGP demonstrate substantially
improved robustness, achieving average MSEs of 4.96 and
2.28, respectively. While both methods outperform the base-
lines, CGP achieves the best performance. This highlights
the benefit of relying on two approaches for creating new al-
gorithms to increase the chances of finding a very effective
algorithm.
Finally, in the nonlinear setting (Figure 2, right), both
LLM-assisted ES and CGP achieve lower errors of 0.81
and 0.88 comapred to the Kalman Filter. The learned pro-
grams consistently deliver superior accuracy, highlighting
their flexibility in adapting to known nonlinear dynamics.
We note that the random search was able to surpass the
performance of the Kalman filter but falls short of the algo-
rithms discovered using both LLM-assisted ES and CGP in
all three settings.
In Figure 3, we present the function discovered by LLM-
assisted ES (left) and CGP (right) for the half Gaussian noise
case. It is evident that the algorithm discovered by the LLM-
assisted ES assigns greater weight to the predicted state xp
compared to the observation. This bias is introduced in mul-
tiple ways. First, the innovation covariance matrix S is mod-
ified by adding the term F. min(axis = 1)[:, None] × 1.2,
which increases its diagonal elements and thus inflates the
perceived uncertainty of the observation. This, in turn, re-
duces the magnitude of the inverse S−1. Additionally, the
Kalman gain K is explicitly scaled by a factor of 0.85, fur-
ther diminishing the influence of the residual z −xp. To-
gether, these modifications cause the update step to rely
more heavily on the prediction xp than on the observation
z, resulting in a conservative correction.
In contrast, the algorithm discovered by CGP is more dif-
ficult to interpret as it does not closely resemble the structure
of the Kalman filter. This shows that despite consisting only
of known building blocks, a detailed analysis would be re-
quired to analyze the identified algorithm.
In Appendix E, we present the algorithms discovered for
the other two settings together with a short analysis.
Conclusions
We have presented a framework for algorithmic discovery
based on both CGP and LLM-assisted ES. By relying on
both CGP and LLM-assisted ES, we are able to discover
high-performing algorithms, as our experiments show that
either CGP or the LLM yields the best results depending on
the setting. Moreover, this approach allows us to simulta-
neously leverage both GPU and CPU resources. The frame-
work was successfully applied to discover novel Kalman Fil-
ter variants and showed promise for discovering fundamen-
tal scientific computing algorithms.
Current limitations include that there is no exchange of al-
gorithm candidates between the CGP and LLM-assisted ES
during the algorithmic discovery process. While a naive ex-
change of candidates is not possible as both approaches re-
quire a specific structure of the algorithms, even just the ex-
change of a few suitable algorithm candidate towards the
end of the algorithmic discovery process could increase ex-
ploration significantly in case one of the two approaches is
stuck in a local minima.
Another limitation is that during the mutation process the
LLM may produce very complex patterns that overfit the
data. As the complexity of the algorithm of interest in-
creases, it becomes increasingly difficult to trace and under-
stand the rationale behind the LLM’s outputs, which may
hinder transparency and trust in practical applications. One
solution could be to explicitly specify constraints or desired
properties in the prompt; however, this approach may not
fully prevent the model from generating overly complex or
non-intuitive functions, especially when operating in high-
dimensional or ambiguous problem spaces.
In future work, we plan to develop strategies to exchange
algorithm candidates between CGP and LLM-assisted ES.
Moreover, we plan to extend this framework to more
complex domains, including multi-object tracking in au-
tonomous driving scenarios, as explored in (Chiu et al. 2021,
2024), as well as nonlinear control and decision-making sys-
tems (Eftekhar Azam et al. 2015). Finally, a promising direc-
tion is applying our discovery framework to settings where
system and control dynamics are unknown, aiming to extract
interpretable models purely from observations.


--- Page 8 ---
Acknowledgements
The authors thank Cengiz Pehlevan and Yue Lu for valuable
discussions and helpful insights.
S.K. and P.K. acknowledge support by the Defense Ad-
vanced Research Projects Agency (DARPA) through Award
HR00112490489.
V.S. acknowledges support by the Karl Engvers foundation.
References
Ausiello, G.; Lucertini, M.; and Serafini, P., eds. 1984. Al-
gorithm design for computer system design. Berlin, Heidel-
berg: Springer-Verlag. ISBN 0387818162.
Beasley, J. E. 1990. OR-Library: Distributing test problems
by electronic mail. Journal of the Operational Research So-
ciety, 41(11): 1069–1072.
Bierman, G. J. 1977. Factorization Methods for Discrete
Sequential Estimation, volume 128.
Brown, T.; Mann, B.; Ryder, N.; Subbiah, M.; Kaplan, J. D.;
Dhariwal, P.; Neelakantan, A.; Shyam, P.; Sastry, G.; Askell,
A.; et al. 2020. Language models are few-shot learners. Ad-
vances in neural information processing systems, 33: 1877–
1901.
Chiu, H.-k.; Li, J.; Ambrus¸, R.; and Bohg, J. 2021. Prob-
abilistic 3D multi-modal, multi-object tracking for au-
tonomous driving. In 2021 IEEE international conference
on robotics and automation (ICRA), 14227–14233. IEEE.
Chiu, H.-K.; Wang, C.-Y.; Chen, M.-H.; and Smith, S. F.
2024. Probabilistic 3d multi-object cooperative tracking for
autonomous driving via differentiable multi-sensor kalman
filter. In 2024 IEEE International Conference on Robotics
and Automation (ICRA), 18458–18464. IEEE.
Cho, K.; van Merri¨enboer, B.; Gulcehre, C.; Bahdanau, D.;
Bougares, F.; Schwenk, H.; and Bengio, Y. 2014. Learning
phrase representations using RNN encoder-decoder for sta-
tistical machine translation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language Pro-
cessing (EMNLP), 1724–1734.
Chowdhery, A.; Narang, S.; Devlin, J.; Bosma, M.; Mishra,
G.; Roberts, A.; Barham, P.; Chung, H. W.; Sutton, C.;
Gehrmann, S.; et al. 2023. Palm: Scaling language model-
ing with pathways. Journal of Machine Learning Research,
24(240): 1–113.
Comanici, G.; Bieber, E.; Schaekermann, M.; Pasupat, I.;
Sachdeva, N.; Dhillon, I.; Blistein, M.; Ram, O.; Zhang,
D.; Rosen, E.; et al. 2025. Gemini 2.5: Pushing the fron-
tier with advanced reasoning, multimodality, long context,
and next generation agentic capabilities.
arXiv preprint
arXiv:2507.06261.
Cortacero, K.; McKenzie, B.; M¨uller, S.; Khazen, R.;
Lafouresse, F.; Corsaut, G.; Acker, N. V.; Frenois, F.-X.;
Lamant, L.; Meyer, N.; Vergier, B.; Wilson, D. G.; Luga, H.;
Staufer, O.; Dustin, M. L.; Valitutti, S.; and Cussat-Blanc,
S. 2023. Evolutionary design of explainable algorithms for
biomedical image segmentation. Nature Communications,
14(1): 7112.
Dettmers, T.; Pagnoni, A.; Holtzman, A.; and Zettlemoyer,
L. 2023.
Qlora: Efficient finetuning of quantized llms.
Advances in neural information processing systems, 36:
10088–10115.
Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.
Bert: Pre-training of deep bidirectional transformers for lan-
guage understanding. In Proceedings of the 2019 conference
of the North American chapter of the association for compu-
tational linguistics: human language technologies, volume 1
(long and short papers), 4171–4186.
Eftekhar Azam, S.; Chatzi, E.; Papadimitriou, C.; and
Smyth, A. 2015.
Experimental Validation of the Dual
Kalman Filter for Online and Real-Time State and Input Es-
timation. In Atamturktur, H. S.; Moaveni, B.; Papadimitriou,
C.; and Schoenherr, T., eds., Model Validation and Uncer-
tainty Quantification, Volume 3, 1–13. Cham: Springer In-
ternational Publishing. ISBN 978-3-319-15224-0.
Freirich, D.; Michaeli, T.; and Meir, R. 2023.
Percep-
tual kalman filters: Online state estimation under a perfect
perceptual-quality constraint. Advances in Neural Informa-
tion Processing Systems, 36: 63292–63326.
Gelb, A.; et al. 1974. Applied optimal estimation. MIT press.
Greenberg, I.; Yannay, N.; and Mannor, S. 2023.
Op-
timization or architecture: How to hack kalman filtering.
Advances in Neural Information Processing Systems, 36:
50482–50505.
Grewal, M. S.; and Andrews, A. P. 2015. Kalman Filtering:
Theory and Practice with MATLAB. Wiley, 4 edition.
Grochow, J. 2018.
New applications of the polynomial
method: The cap set conjecture and beyond. Bulletin of the
American Mathematical Society, 56: 1.
Guo, D.; Yang, D.; Zhang, H.; Song, J.; Zhang, R.; Xu, R.;
Zhu, Q.; Ma, S.; Wang, P.; Bi, X.; et al. 2025. Deepseek-r1:
Incentivizing reasoning capability in llms via reinforcement
learning. arXiv preprint arXiv:2501.12948.
Hochreiter, S.; and Schmidhuber, J. 1997. Long short-term
memory. Neural computation, 9(8): 1735–1780.
Julier, S. J.; and Uhlmann, J. K. 1997. New extension of
the Kalman filter to nonlinear systems. In Defense, Security,
and Sensing.
Kalman, R. E. 1960.
A New Approach to Linear Filter-
ing and Prediction Problems. Journal of Basic Engineering,
82(1): 35–45.
Kalman, R. E.; and Bucy, R. S. 1961. New results in linear
filtering and prediction theory. Journal of Basic Engineer-
ing, 83(1): 95–108.
Koza, J. R. 1992. Genetic Programming: On the Program-
ming of Computers by Means of Natural Selection.
MIT
Press.
Li, R.; Allal, L. B.; Zi, Y.; Muennighoff, N.; Kocetkov, D.;
Mou, C.; Marone, M.; Akiki, C.; Li, J.; Chim, J.; et al.
2023. Starcoder: may the source be with you! arXiv preprint
arXiv:2305.06161.
Miller, J.; and Turner, A. 2015. Cartesian Genetic Program-
ming. In Proceedings of the Companion Publication of the


--- Page 9 ---
2015 Annual Conference on Genetic and Evolutionary Com-
putation, GECCO Companion ’15, 179–198. New York,
NY, USA: Association for Computing Machinery.
ISBN
9781450334884.
Novikov, A.; V˜u, N.; Eisenberger, M.; Dupont, E.; Huang,
P.-S.; Wagner, A. Z.; Shirobokov, S.; Kozlovskii, B.; Ruiz,
F. J.; Mehrabian, A.; et al. 2025. AlphaEvolve: A coding
agent for scientific and algorithmic discovery. arXiv preprint
arXiv:2506.13131.
Novikov, A. e. a. 2025. AlphaEvolve: A Gemini-powered
coding agent for designing advanced algorithms.
Poli, R.; Langdon, W. B.; and McPhee, N. F. 2008. A Field
Guide to Genetic Programming. Lulu Enterprises, UK Ltd.
ISBN 1409200736.
Romera-Paredes, B.; Barekatain, M.; Novikov, A.; Balog,
M.; Kumar, M. P.; Dupont, E.; Ruiz, F. J. R.; Ellenberg,
J. S.; Wang, P.; Fawzi, O.; Kohli, P.; and Fawzi, A. 2024.
Mathematical discoveries from program search with large
language models. Nature, 625(7995): 468–475.
Rumelhart, D. E.; Hinton, G. E.; and Williams, R. J. 1986.
Learning representations by back-propagating errors. Na-
ture, 323(6088): 533–536.
Strassen, V. 1969. Gaussian Elimination is not Optimal. Nu-
merische Mathematik, 13(4): 354–356.
Surina, A.; Mansouri, A.; Quaedvlieg, L.; Seddas, A.; Via-
zovska, M.; Abbe, E.; and Gulcehre, C. 2025. Algorithm
discovery with llms: Evolutionary search meets reinforce-
ment learning. arXiv preprint arXiv:2504.05108.
Tao, T.; and Vu, V. H. 2006. Additive Combinatorics. Cam-
bridge Studies in Advanced Mathematics. Cambridge Uni-
versity Press.
Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones,
L.; Gomez, A. N.; Kaiser, Ł.; and Polosukhin, I. 2017. At-
tention is all you need. Advances in neural information pro-
cessing systems, 30.
Wolf, T.; Debut, L.; Sanh, V.; Chaumond, J.; Delangue, C.;
Moi, A.; Cistac, P.; Rault, T.; Louf, R.; Funtowicz, M.; et al.
2019. Huggingface’s transformers: State-of-the-art natural
language processing. arXiv preprint arXiv:1910.03771.
Appendix A: Binpacking
We verified our LLM-assisted ES implementation by apply-
ing it to the bin-packing task as defined in the DeepMind
FunSearch paper (Romera-Paredes et al. 2024). By doing
so, we are able to benchmark our implementation against
FunSearch. We note that apart from potential differences in
the implementation, we also rely on a LLM from DeepSeek
(Guo et al. 2025) in contrast to a Gemini variant for Fun-
Search.
The experiments are based on standard benchmark datasets
from the OR-Library (Beasley 1990), including binpack1,
binpack2, binpack3, and binpack4. Each dataset
contains 20 bin packing instances with 120, 250, 500, and
1000 items, respectively. The sizes of the items are sampled
uniformly from the interval [20, 100] and the bin capacity
is fixed at 150. Following the original setup, we generated
a training dataset of 20 instances with 120 items (mirror-
ing binpack1) and a validation dataset of 20 instances
with 250 items (similar to binpack2). Candidate heuris-
tics were evolved using our LLM-assisted ES and selected
based on validation performance. The best performing pro-
grams were then evaluated on the complete benchmark suite
(binpack1–binpack4) to assess generalization. This re-
production served to confirm that our implementation faith-
fully replicates the original methodology and yields consis-
tent performance behavior.
In Figure 4 and Table 3, we compare the performance of
three heuristics on the OR-Library bin packing benchmarks:
the standard Best Fit heuristic, the heuristic discovered by
the original DeepMind FunSearch framework, and the one
produced by our own implementation.
Across all datasets, both Deepmind FunSearch and our
implementation outperform the default Best Fit heuristic,
confirming that learned algorithms lead to more efficient
bin usage. In binpack1.txt, both Deepmind FunSearch
and our algorithm achieve a 5.30% excess over the L1
bound, improving on the Best Fit heuristic’s 5.81%. In
binpack2.txt, Deepmind FunSearch achieves the best
result (4.19%), with our method slightly behind at 4.92%,
both improving significantly over Best Fit heuristic’s 6.06%.
A similar trend holds for binpack3.txt, where Deep-
mind FunSearch yields the lowest excess (3.11%), followed
by our result at 4.20%, again outperforming the Best Fit
heuristic (5.37%). In binpack4.txt, the pattern contin-
ues: Deepmind FunSearch produces the best excess (2.47%),
our method is second (3.92%), and Best Fit trails behind
(4.94%). Regarding computational cost, our method was
run for six days on four H100 GPUs. The original Deep-
Mind FunSearch paper reports the heuristic used for bin
packing, but does not disclose the exact number of runs re-
quired to obtain it. Based on the scale of their capset ex-
periments (which involved 140 separate runs, each using 15
A100 GPUs for two days), it is possible that their original
search could have involved substantially more compute than
our replication. Despite this, our results remain highly com-
petitive.
These results demonstrate that our implementation is ca-
pable of discovering heuristics that outperform the current
Best Fit heuristic and are competitive with those produced


--- Page 10 ---
by DeepMind’s FunSearch framework.
binpack1.txt
binpack2.txt
binpack3.txt
binpack4.txt
0
2
4
6
Excess over L1 bound (%)
Best fit
Funsearch
Our Results
Figure 4: Comparisons of the accuracy of discovered algo-
rithms for the bin packing task.
Dataset
FunSearch
Our Results
Best Fit
binpack1
5.30%
5.30%
5.81%
binpack2
4.19%
4.92%
6.06%
binpack3
3.11%
4.20%
5.37%
binpack4
2.47%
3.92%
4.94%
Table 3: Excess over L1 bound (%) for each method on bin-
pack datasets. Lower is better. Colors indicate performance
per row: green = best, yellow = middle, red = worst.
Appendix B: Hyperparameters
In Table 4 we report the hyperparameters used for the LLM-
assisted ES and CGP frameworks.
Parameter
LLM-assisted ES
CGP
Database Size
200
200
Sampling Temperature
0.2
0.2
Prompts per Iteration
30
NA
Tokens per prompt
3000
NA
Mutations per Iteration
varies
1000
Parents per Mutation
2
1
Max Algorithm Size
NA
target size + 2
Table 4: Comparison of hyperparameters used in LLM-
assisted ES and CGP.
Appendix C: Dynamical System
We present the dynamical system which is used as an illus-
trative example within this paper in more detail:
We consider a linear time-invariant discrete-time dynamical
system modeling the position and velocity of an object. The
continuous-time second-order equation is discretized using
a fixed sampling interval ∆t, yielding the following stochas-
tic difference equation:
xk = Fxk−1 + Gak.
(9)
Here, ak is a random acceleration input modeled as a
zero-mean Gaussian variable, and the state vector xk =
[pk, vk]T includes position and velocity. The system matri-
ces are defined as:
F =

1
∆t
0
1

,
G =
 1
2∆t2
∆t

.
This corresponds to the forward-Euler discretization of
Newtonian motion under stochastic acceleration. The accel-
eration noise ak ∼N(0, σ2
a) induces process noise wk =
Gak, distributed as:
wk ∼N(0, Q),
with
Q = GG⊤σ2
a = σ2
a
 1
4∆t4
1
2∆t3
1
2∆t3
∆t2

.
For simplicity, we assume full observability of the system
state at each time step. Observations are obtained through a
linear measurement model:
zk = Hxk + vk,
H =

1
0
0
1

,
where both position and velocity are measured directly. The
measurement noise vk is modeled as zero-mean Gaussian
with covariance R = σ2
zI, i.e.,
vk ∼N(0, σ2
zI).
The resulting discrete-time state-space model satisfies the
standard conditions for applying the Kalman filter: linear
time-invariant dynamics, additive Gaussian noise in both the
process and measurements, and fully known system param-
eters and noise covariances. Under these assumptions, the


--- Page 11 ---
Kalman filter yields the optimal state estimate in the mini-
mum mean square error (MMSE) sense. Due to its analyti-
cal tractability, physical relevance, and ability to capture es-
sential features of uncertainty propagation in dynamic sys-
tems, the described model is widely considered a canonical
benchmark for evaluating state estimation methods in filter-
ing, tracking, and control applications (Greenberg, Yannay,
and Mannor 2023; Freirich, Michaeli, and Meir 2023).
Appendix D: Progressive Discovery
In this section, we continue the experiment of rediscover-
ing the Kalman-Filter by analyzing the differences between
LLM-assisted ES and CGP in more detail. To do so, we run
multiple experiments and task our framework with discover-
ing a progressively more complete Kalman Filter algorithm.
We begin with the simplest case: the prediction step of the
Kalman filter. The corresponding computational procedure
is shown in the first two lines of Figure 5. We progressively
increase the complexity of the discovery task by incremen-
tally introducing additional components of the Kalman filter,
adding more and more operations at a time to the target al-
gorithm until the complete filter is recovered.
Table 5 presents the MSE loss for the different approaches
and experiments. We observe that both the predict, predict +
12.5% update, and predict + 25% update were successfully
discovered by both CGP and LLM-assisted ES. In particu-
lar, CGP was also able to discover the more complex vari-
ants, while maintaining MSE values closely aligned with the
optimal solution. This consistent accuracy across increas-
ing program complexity highlights the robustness of CGP.
However, LLM-assisted ES seems to get stuck in a local
minima and only finds algorithms that produce a forecast
with high MSE. This behavior is likely attributable to its
reliance on a LLM comprising only 14 billion parameters.
Moreover, even a LLM of this size must be executed on
GPUs and incurs significant computational overhead. Con-
sequently, LLM-assisted ES is limited in the number of to-
kens it can evaluate within a fixed resource budget. We hy-
pothesize that a larger computational budget would increase
the abilities of LLM-assisted ES, which is in accordance
with new research (Novikov et al. 2025).
The results also justify our choice of running both ap-
proaches, i.e. CGP and LLM-assisted ES in parallel, to fa-
cilitate robust algorithmic discovery.
We also observe a consistent trend in the performance of
Random Search. While it can occasionally identify com-
petitive solutions for simple tasks, its effectiveness deteri-
orates as program complexity increases. This is expected, as
more complex problems yield a significantly larger solution
space, reducing the probability of discovering optimal solu-
tions through purely random exploration.
Appendix E: Discovered algorithms
In Figure 6, we present the algorithms discovered by Fun-
Search and CGP for the delayed observation scenario, while
Figure 7 shows the corresponding solutions for the case
of nonlinear state transitions. These examples highlight the
structural differences between the two approaches. LLM-
def kalman(x, F, P, Q, z, R):
# Predict step
x_predict =F @x
P =F @P @F.T +Q
# Update step
y =z -x_predict
S =P +R
K =P @inv(S)
x_update =x_predict +K @y
P =P -K @P
return x_predict, P, y, S, K, x_update
Figure 5: Kalman Filter algorithm
assisted ES tends to produce programs with greater algorith-
mic richness and mathematical depth, making use of a wide
range of operations, including matrix products, element-
wise nonlinearities, and adaptive scaling mechanisms. In
contrast, the CGP-generated functions are more constrained
in form and typically rely on a pre-defined, fixed-size set of
operations.
One of the key strengths of LLM-assisted ES is its abil-
ity to discover expressive and complex update rules that
go beyond the structure of classical filtering techniques.
For instance, the inclusion of operations such as np.log,
np.tanh, and sinusoidal terms in LLM-assistes ES out-
puts reflects an inherent flexibility to model richer dynamics
or nonlinear observation processes. Moreover, in our case,
these algorithms often maintain recognizable algorithmic
blocks — such as state predictions xp, covariance updates
P, and innovation terms y — which can be directly asso-
ciated with standard Kalman filter notation. This facilitates
theoretical analysis and easily shows in which part the newly
discovered algorithm differs from the established baseline.


--- Page 12 ---
Method
CGP
LLM-assisted ES
Random Search
predict
0.995077 ± 9e−3
0.995493 ± 9e−3
1.009967 ± 9e−3
predict + 12.5% update
0.995077 ± 9e−3
0.996792 ± 9e−3
1.069877 ± 1e−2
predict + 25 % update
0.995077 ± 9e−3
1.042292 ± 9e−3
1.045160 ± 8e−3
predict + 50 % update
0.994762 ± 9e−3
1.968045 ± 1e−2
1.141732 ± 1e−2
predict + 75 % update
1.003259 ± 9e−3
1.968045 ± 1e−2
1.209344 ± 1e−2
predict + update
0.995220 ± 9e−3
1.968045 ± 1e−2
1.209344 ± 1e−2
Table 5: MSE loss of our methods compared to Kalman Filter performance (0.995077). Green highlights optimal or near-
optimal results, yellow/orange indicates moderate deviation, and red marks the least favorable outcomes in each row.
def function_approximate(x, F, P, Q, z, R):
a =F @x
b =F @np.log(np.maximum(a *0.03, 1e-8))
c =F @np.tanh(b *0.2)
xp =a +c
P =F @P @F.T +0.7 *Q
y =z -xp
S =P +0.7 *R
inv_S =np.linalg.inv(S)
K =P @inv_S +0.15 *inv_S
x =xp +K @y
x +=0.6 *F @np.tanh(F @x *0.08)
P =(np.eye(F.shape[0]) -K) @P
return xp, P, y, S, K, x
def graph_approximate(x, F, P, Q, z, R):
A =F @R
B =P +Q
K =np.linalg.inv(B)
S =Q @K
y =A -x
T =K.T
P =S -S
F_ =S +F
x =y @T +x
S =F_ @S
K =T -P
return xp, P, y, S, K, x
Figure 6: Algorithms discovered for delayed observations by LLM-assisted ES on the left and CGP on the right.
def function_approximate(x, F, P, Q, z, R):
x =np.array(
[0.04 *x[0]**3 -1.8 *x[0] +0.34 *np.sin(x
[1]),
0.14 *np.tanh(0.05 *x[0] *(x[1] +
0.8))])
xp =F.dot(x)
scale_Q =(x[0] *x[1] +x[0]**2 +x[1]**2 +0.6)
*\
(1 +0.9 *(x[0] *x[1] +x[0]**2 +x[1]
**2))
P =F.dot(P.dot(F.T)) +Q *scale_Q
y =z -xp
scale_R =(x[0]**2 +x[1]**2 +0.5) *(1 +0.8 *(x
[0]**2 +x[1]**2))
S =P +R *scale_R
inv_S =np.linalg.inv(S +0.0002 *np.eye(S.
shape[0]))
K =P.dot(inv_S) *(0.85 *np.tanh(np.linalg.
norm(y)))
x =xp +K.dot(y)
P =(np.eye(F.shape[0]) -K) *P *(0.5 +0.05 *np
.mean(y**2))
return xp, P, y, S, K, x
def graph_approximate(x, F, P, Q, z, R):
x =np.array([0.05 *x[0]**3 -2*x[0], 0.1 *np.
sin(x[1])])
Ft =F.T
y =z -(F @x)
S =Ft.T +Ft +P +Q
K =Ft @np.linalg.inv(S)
P =K @y
x =x +P
return xp, P, y, S, K, x
Figure 7: Algorithms discovered for non linear transitions by LLM-assisted ES on the left and CGP on the right.
