--- Page 1 ---
Toward a Trustworthy Optimization Modeling Agent
via Verifiable Synthetic Data Generation
Vinicius Lima, Dzung T. Phan, Jayant Kalagnanam, Dhaval Patel, Nianjun Zhou
1IBM Research AI, Yorktown Heights, NY
viniciuslima@ibm.com, phandu@us.ibm.com, jayant@us.ibm.com, pateldha@us.ibm.com, jzhou@us.ibm.com
Abstract
We present a framework for training trustworthy large lan-
guage model (LLM) agents for optimization modeling via a
verifiable synthetic data generation pipeline. Focusing on lin-
ear and mixed-integer linear programming, our approach be-
gins with structured symbolic representations and systemat-
ically produces natural language descriptions, mathematical
formulations, and solver-executable code. By programmati-
cally constructing each instance with known optimal solu-
tions, the pipeline ensures full verifiability and enables au-
tomatic filtering of low-quality demonstrations generated by
teacher models. Each dataset instance includes a structured
representation of the optimization problem, a corresponding
natural language description, the verified optimal solution,
and step-by-step demonstrations — generated by a teacher
model — that show how to model and solve the problem
across multiple optimization modeling languages. This en-
ables supervised fine-tuning of open-source LLMs specifi-
cally tailored to optimization tasks. To operationalize this
pipeline, we introduce OptiTrust, a modular LLM agent
that performs multi-stage translation from natural language
to solver-ready code, leveraging stepwise demonstrations,
multi-language inference, and majority-vote cross-validation.
Our agent achieves state-of-the-art performance on standard
benchmarks. Out of 7 datasets, it achieves the highest accu-
racy on six and outperforms the next-best algorithm by at
least 8% on three of them. Our approach provides a scalable,
verifiable, and principled path toward building reliable LLM
agents for real-world optimization applications. The code is
available as supplementary material.
Introduction
Optimization serves as a foundational tool in science and
engineering, underpinning a wide range of decision-making
applications such as logistics, supply chain management, fi-
nance, healthcare, energy systems, and infrastructure plan-
ning. Despite its ubiquity and impact, the process of trans-
lating real-world requirements into robust, executable opti-
mization models is often labor-intensive and demands rare
expert knowledge. This modeling bottleneck limits the ac-
cessibility and scalability of optimization in practice.
Recent advances in large language models (LLMs) offer
an exciting opportunity to automate the end-to-end pipeline
from natural language descriptions to solver-ready code. An
effective natural language-to-optimization (NL2Opt) agent
has the potential to democratize optimization modeling, em-
powering non-experts to harness advanced mathematical
tools. However, current approaches in this area face major
obstacles. Many LLM-based methods produce code or mod-
els that are difficult to verify, lack transparency and repro-
ducibility, and do not generalize well to new problem struc-
tures or domains. The scarcity of high-quality, structured
datasets further impedes progress, as does the challenge of
multi-stage reasoning required for accurate translation.
Building reliable optimization modeling agents presents
several intertwined challenges. First, natural language prob-
lem statements are frequently ambiguous or under-specified,
which means that agents must often resolve vagueness or
infer missing information to produce well-posed mathe-
matical models. Second, the translation process itself is
inherently multi-stage and complex: it requires the agent
to accurately identify relevant entities, assemble symbolic
mathematical formulations, and ultimately generate solver-
executable code that preserves the intent of the original de-
scription. Third, verifiability and fidelity remain central con-
cerns—generated code must not only be syntactically cor-
rect but also mathematically valid and provably optimal for
the given problem. Finally, the lack of large-scale, high-
quality datasets for NL2Opt modeling limits the effective
supervised fine-tuning of language models, since existing re-
sources are often small, domain-specific, or lack the neces-
sary annotations to support robust learning and evaluation.
Together, these factors underscore the need for principled
frameworks that enable both verifiable modeling and scal-
able, trustworthy LLM training for optimization tasks.
To address these barriers, we propose a novel, verifi-
able synthetic data generation (SDG) pipeline for training a
trustworthy optimization modeling agent. Our approach be-
gins with structured symbolic representations of optimiza-
tion problems and programmatically generates aligned nat-
ural language descriptions, mathematical formulations, and
solver-executable code, each instance paired with a veri-
fied optimal solution. This not only ensures data quality and
full verifiability, but also enables automatic filtering of low-
quality demonstrations, thereby fostering reproducible and
reliable agent behavior.
Contributions. Our main contributions are as follows:
• We design and implement a modular LLM agent,
OptiTrust, that performs multi-stage translation from
arXiv:2508.03117v1  [cs.AI]  5 Aug 2025


--- Page 2 ---
natural language descriptions to solver-ready code.
OptiTrust generates step-by-step demonstrations for opti-
mization modeling, leveraging multi-language inference
and majority vote to improve robustness and accuracy.
• We introduce a scalable SDG pipeline for linear and
mixed-integer linear programming that creates verifiable
multi-modal datasets—bridging symbolic, linguistic, and
code representations—enabling fine-tuning of LLMs in
five modeling languages.
• We leverage OptiTrust to systematically identify addi-
tional inaccurate instances within 5 of the 7 existing opti-
mization modeling datasets, particularly those containing
incorrect ground-truth optimal values. By updating these
values with verified solutions, we improve the reliability
and quality of benchmark datasets for the community.
• We demonstrate that our model, trained using the syn-
thetic data pipeline, achieves state-of-the-art perfor-
mance across multiple public benchmarks, outperform-
ing all prompting and fine-tuning baselines on 6 out of 7
datasets and exceeding the next-best method by at least
8% on three of them.
In summary, our framework closes a critical gap in the
development of optimization modeling agents by combin-
ing scalable synthetic data generation with rigorous verifica-
tion. This work lays the groundwork for trustworthy, repro-
ducible, and accessible optimization modeling using LLMs.
Related Work
Recent work on (large) language models for optimization
modeling can be broadly classified into two main directions:
prompting based techniques that rely primarily on frontier
models such as GPT-4 (Li et al. 2023; Xiao et al. 2023;
Zhang et al. 2024; AhmadiTeshnizi, Gao, and Udell 2024;
Astorga et al. 2025), and fine-tuning of open-source models
using domain-specific optimization modeling datasets (Tang
et al. 2024; Jiang et al. 2025; Yang et al. 2025; Lu et al. 2025)
— for a more comprehensive overview of natural language
for optimization modeling, we refer the reader to the recent
survey paper (Xiao et al. 2025).
Within the first research direction, a framework to de-
sign LLM agents to enable what-if analysis for and provide
insights about existing supply-chain optimization models
given natural language inputs is proposed in (Li et al. 2023).
Chain-of-Experts (Xiao et al. 2023) and OptiMUS (Ahma-
diTeshnizi, Gao, and Udell 2024) both propose multi-agent
frameworks to solve optimization problems from scratch
using LLMs: in Chain-of-Experts (Xiao et al. 2023), each
agent is assigned a specific role in the optimization pipeline
(formulation, implementation and debugging, for example),
while an LLM-powered orchestrator oversees the workflow
used to solve the optimization problem; in OptiMUS (Ah-
madiTeshnizi, Gao, and Udell 2024), a similar framework
with dedicated agents and prompts is used, and the paper fur-
ther introduces a connection graph to allow independent for-
mulation and implementation of objectives and constraints.
More recently, an inference framework combining large lan-
guage models and Monte Carlo tree search is proposed in
(Astorga et al. 2025).
The reliance of prompt based techniques on proprietary
frontier models, combined with the limited availability of
datasets containing detailed problem descriptions, mathe-
matical formulations, and solver-ready code, motivates re-
search into synthetic data generation and training of open-
source models specialized in optimization modeling. This
line of work aims to both close the gap between open-source
and proprietary models, and to enable smaller, more compu-
tationally efficient LLMs specialized in optimization mod-
eling (Tang et al. 2024; Jiang et al. 2025; Yang et al. 2025;
Lu et al. 2025). The synthetic data generation pipelines pro-
posed in (Tang et al. 2024) and (Jiang et al. 2025) primar-
ily rely on augmenting or modifying an existing pool of
seed problems in natural language to generate new prob-
lem descriptions. This approach limits their ability to gen-
erate new classes of optimization problems that are not al-
ready represented among the seed problems. Furthermore,
it restricts the scalability of these pipelines when handling
longer descriptions or more complex problem instances. Re-
Socratic (Yang et al. 2025) goes one step further by using
a pool of formatted demonstrations as seeds for new op-
timization samples created by LLMs; however, there is no
guarantee that the generated formulation accurately reflects
the generated problem description. Concurrent to our work,
recent efforts have explored similar directions on generating
problem descriptions from mathematical formulations (Lu
et al. 2025), showing promising results on leveraging struc-
tured representations of optimization models to generate op-
timization modeling datasets. However, existing approaches
lack a mechanism for verifying the correctness of compo-
nents within the pipeline. Our work is dedicated to develop-
ing a method for generating verifiable training data.
Multi-Agent Architecture for OptiTrust
Our proposed OptiTrust agent employs a structured, mod-
ular architecture comprising three coordinated sub-agents,
each dedicated to a distinct stage in translating a natural
language descriptions into solver-ready code, as shown in
Figure 1. This modular decomposition mirrors the work-
flow of a human optimization expert, enabling a clear di-
vision of responsibilities, improved interpretability, and ef-
fective error diagnosis. We adopt a commonly used design
pattern for LLM-based agents that convert natural language
descriptions into executable code for optimization solvers
(Xiao et al. 2023; AhmadiTeshnizi, Gao, and Udell 2024;
Jiang et al. 2025), and equip each sub-agent with dedicated
prompts, self-reflection, and step-by-step in-context learn-
ing demonstrations. Those step-by-step demonstrations are
used not only to provide the model with explicit examples
of variable definitions, problem formulations, and code im-
plementation, but also to guide the generation of multi-task
reasoning traces for supervised fine-tuning, as discussed in
more details in the following section.
The decomposition agent initiates the workflow by pars-
ing the natural language description provided by the user.
Its core function is to identify and extract key optimization
components, such as decision variables (including the do-
main of those variables), objectives, and constraints (includ-
ing implicit ones such as non-negativity), and to summarize


--- Page 3 ---
Figure 1: Agentic workflow of OptiTrust from natural language to executable code.
them using natural language. That summarized list of com-
ponents, alongside the original description of the problem,
is then passed to the formulation agent, tasked with con-
structing a clear, formal mathematical formulation — typi-
cally presented in LaTeX — that precisely captures the op-
timization problem. The workflow culminates with the code
agent, which translates the mathematical formulation into
executable optimization code (e.g., Pyomo and DOcplex)
suitable for solvers such as CPLEX (Cplex 2024), Gurobi
(Gurobi Optimization, LLC 2024) or SCIP (Bolusani et al.
2024). An integral feature of the code agent is its built-in
validation mechanism, which executes the generated code
using external optimization solvers to verify correctness. If
execution errors or infeasible solutions occur, detailed error
messages are communicated back to the agent, triggering it-
erative code refinement until a viable solution is produced
or a maximum number of debugging calls is reached. More-
over, instead of relying solely on the formulation generated
in the previous step, as is usually done in the literature, the
coding agent also has access to the original problem descrip-
tion and the detailed list of components previously extracted.
That is primarily designed to allow the coding agent to re-
trieve information directly from the problem description in
case any of the previous steps fails.
As optimization modeling datasets are relatively scarce
and often imbalanced across problem classes, and optimiza-
tion modeling libraries differ in adoption as well as availabil-
ity and quality of documentation, language models might
be biased toward certain optimization modeling languages.
However, existing agents are limited to working with a sin-
gle modeling language. To mitigate this data imbalance and
performance mismatch issue, we adopt a consistency mech-
anism inspired by recent works on chain-of-thought reason-
ing (Wei et al. 2022; Wang et al. 2023; Chen et al. 2024). In
particular, we prompt the coding agent to model the problem
using five common optimization modeling languages (Py-
omo, Gurobipy, DOCplex, CVXPY, and PySCIPOpt) and
employ a majority voting mechanism based on the solutions
found by each solver to select the most consistent and re-
liable implementation. We find that incorporating this con-
sistency check into the optimization workflow significantly
improves model performance across both baseline and fine-
tuned models, as detailed in the numerical experiments.
The key novelty of our agent is that it incrementally
evolves the components of the modeling trajectory, so if a
mistake occurs at an intermediate stage, there remains an op-
portunity to recover the correct information from the original
problem description. We provide the problem description to
each sub-agent and require them to supply explicit reasoning
steps. These reasoning steps, combined with majority voting
based on solver code across 5 modeling languages, help pro-
mote generalization. The additional input and output compo-
nents for each sub-agent are incorporated into our synthetic
data, which is then used to effectively fine-tune LLMs.
Verifiable Synthetic Data Generation Pipeline
Although prompt-based techniques provide flexible work-
flows to elicit optimization models from natural language
descriptions using pre-trained LLMs, their performance ul-
timately depends upon the ability of pre-trained LLMs to
model optimization problems and implement solver-ready
code. To help bridge the performance gap between pro-
prietary and open-source LLMs on optimization model-
ing tasks, on the one hand, and to enable the develop-
ment of small, portable LLMs for optimization modeling,
on the other, we propose a verifiable synthetic data genera-
tion pipeline to create synthetic descriptions of optimization
problems. The synthetic description is then processed by the
optimization workflow discussed in the previous section, us-
ing a teacher LLM model to prepare step-by-step demonstra-
tions showing how to model optimization problems. Dur-
ing the data generation process, we capture reasoning traces
for each step in the optimization workflow, including the
implementation of optimization models in five modeling
languages — Pyomo, Gurobipy, DOcplex, CVXPY, and
PySCIPOpt — to promote robustness. The overall frame-
work is illustrated in Figure 2.
Representing Mixed-Integer Linear Programs
To enable automatic validation of training samples, our
pipeline starts with a symbolic representation of mixed-
integer linear programs (MILP). In a standard MILP formu-


--- Page 4 ---
Figure 2: Data generation pipeline.
lation, we model the decision-making process using a col-
lection of decision variables, an objective function, and a
set of linear constraints. The decision variables may include
both continuous and integer-valued variables, representing
choices such as the number of units to produce, for example,
or binary on/off decisions. The objective function quantifies
the underlying goal of the optimization problem – such as
minimizing cost or maximizing profit – while a set of lin-
ear constraints captures requirements or limitations such as
resource capacities, demand satisfaction, or logical relation-
ships between decision variables. Accordingly, one can ab-
stract a typical MILP as
P :
optimizex∈Rn
n
X
j=1
cjxj
subject to
n
X
j=1
aijxj ◦bi,
i = 1, . . . , m
lj ≤xj ≤uj,
j = 1, . . . , n
xj ∈Z,
j ∈I,
where optimize ∈{minimize, maximize}, ◦∈{≤
, =, ≥}, aij ∈R, bi ∈R, lj ∈R∪{−∞}, uj ∈R∪{+∞},
and I is the set of integer variables. Based on that typi-
cal representation, the SDG pipeline begins by sampling the
number of decision variables n, the number of linear con-
straints m, and the type of optimization (i.e., minimize
or maximize), such that P = (n, m, optimize). At this
stage, we also sample upper or lower bounds for decision
variables, if any, and the sparsity of the objective and con-
straint coefficients. Given the set of (symbolic) coefficients
and the list of decision variables, we rely on an automated
Python script to convert the symbolic representation to a
parametrized Pyomo or Gurobipy template. The template
defines the structure of the optimization model, but leaves
coefficients and domains of variables still uninstantiated.
Generating Natural Language Descriptions
While sampling the number of decision variables and con-
straints, as well as the sparsity of the model parameters, im-
proves structural diversity, it does not promote semantic or
linguistic diversity. To address this, we uniformly sample
the problem domain from a variety of application domains
(e.g., manufacturing, education, energy). We then prompt
the teacher model to generate structured, concise descrip-
tions of the decision variables, including their domain (either
Z or R) and implicit ranges, if any (e.g., non-negative).
Once the teacher model has successfully defined struc-
tured descriptions for all decision variables, we next prompt
the model to generate sentences describing those variables,
and to define value ranges for parameters associated with
that variable. At this stage, we expect the teacher model
to prepare a sentence describing the decision variables, but
without instantiating any parameter values; for example,
A research institution needs to allocate
resources to two key areas: purchasing
microscopes and reagents, with a minimum of
\\parameter{l_1} microscopes required.
The main motivation to do so is to condition parameter sam-
pling on the context of the optimization problem, thereby
avoiding potentially incoherent relationships – for example,
a negative budget. The SDG pipeline then iterates over the
objective and constraints of the optimization problem in a
similar manner. Once all components have been described,
we prompt the teacher model to synthesize them into a sin-
gle, uninstantiated problem statement, as shown by an exam-
ple in Fig. 3. Moreover, if the implementation generated by
the teacher model cannot be executed, but the teacher is able
to debug that implementation successfully, we store that de-
bugging step as a training sample. In the following, we em-
pirically show that our approach improves performance of
open-source models, providing a principled path for build-
ing reliable NL2Opt agents for real-world applications.
Next, we sample coefficients within the ranges defined by
the teacher model, instantiate the parametrized optimization
template, and select sets of coefficients that render the prob-
lem feasible. For feasible instances, we save the expected
optimal value computed by the optimization template, and
programmatically instantiate the symbolic natural language
description generated by the teacher model. Because our


--- Page 5 ---
Figure 3: An example illustrating the key steps from sym-
bolic representation to problem description.
work focuses on ensuring the correctness of mathematical
formulations and code generated from natural language de-
scriptions, we keep only instances where an optimal solu-
tion exists. In other words, we discard infeasible instances
(where the feasible set is empty) and unbounded instances
(where the feasible set is non-empty, but the objective value
can be made arbitrarily good). We then pass the natural
language description of each problem through the agen-
tic workflow described in the previous section to generate
trajectories that connect the problem description to solver-
ready code. If (any of) the solutions found by the teacher
model match the expected ground truth, we collect reason-
ing traces for each step of the workflow and save those for
fine-tuning. Each valid trajectory consists of three instruc-
tion–output pairs:
- pairDA= ({problem description,
decomposition prompt}; {reasoning step 1,
extracted components}),
- pairFA= ({problem description,
extracted components, formulation prompt};
{reasoning step 2, math formulation}),
- pairCA= ({problem description,
math formulation, coding prompt};
{reasoning step 3, code in {Pyomo,
Gurobipy, DOcplex, CVXPY, PySCIPOpt}}).
Tabular data
To improve diversity, we also generate prob-
lems with data stored in a table. We store the coefficients in
tabular format, and prompt the teacher model to generate
text descriptions for the row and column labels. We do not
prompt the teacher model to prepare the tabular data; rather,
we implement a Python script to define a string representing
that table based on a set of feasible parameters and the labels
generated by the teacher model. This allows us to randomly
shuffle the sequence of decision variables and constraints,
avoiding the generation of data in a fixed format.
Extension to MILPs with abstract semantics
To extend
the pipeline to classical MILPs such as traveling salesman
or bin-packing problems — in which the decision variables
used in the formal model (whether to travel from a specific
location to another, for example) do not exhibit a one-to-one
correspondence with semantic decisions (the most efficient
travel route) — we define semantic proxies as more inter-
pretable descriptions of the high-level decisions of the prob-
lem (e.g., locations to visit, or items that need to be packed),
and prompt the teacher model to define those instead. We
also provide the teacher model with a general description
of the optimization class and indicate typical application
domains. We employ this approach for traveling salesman,
bin packing, multidimensional knapsack, set cover, and shift
scheduling problems. We use a simplified generation proce-
dure for certain structured problems such as maximum flow,
minimum cost flow, and transportation network tasks. Sp-
eficically, we fix the number of decision variables, and rely
on templated descriptions and paraphrasing for problem de-
scriptions. While this restricts structural diversity, it enables
us to efficiently scale data generation for these more com-
plex problem classes.
Teacher models
To generate varied problem descriptions,
we rely on two models: Llama3.3-70B-Instruct (Grattafiori
et al. 2024), and Llama 4 Maverick (Meta AI 2025). Simi-
larly, to generate varied training demonstrations, we rely on
three teacher models: Phi-4 (Abdin et al. 2024), DeepSeek-
R1-Distill-Llama-70B (DeepSeek-AI et al. 2025), and Ope-
nAI o3-mini (OpenAI 2025). Phi-4 and DeepSeek-R1-
Distill-Llama-70B were primarily used to generate demon-
strations for easier problems (linear problems, knapsack
and multidimensional knapsack, set cover), and o3-mini for
more challenging instances (e.g., traveling salesman, shift
scheduling, bin packing, minimum cost flow).
Multi-task Supervised Fine-Tuning
To optimize perfor-
mance, we train a small open-source LLM (Granite 3.2
(Mishra et al. 2024)) using targeted multi-instruction data
synthesized by the pipeline described in the previous sec-
tion. The training set includes detailed reasoning traces and
diverse cross-format demonstrations designed to enhance
generalization across tasks and representations. During fine-
tuning, the model is provided with pairs pairDA, pairFA,
and pairCA of input instructions and corresponding refer-
ence outputs, typically in the form of (x(i), y(i)) for i =
1, . . . , N training examples. The loss function is the negative
log-likelihood, which measures how well the model predicts
each token in the reference output sequence. For a dataset of
N instances, the loss is computed as:
L(θ) = −1
N
N
X
i=1
T (i)
X
t=1
log pθ

y(i)
t
| x(i), y(i)
0:t−1

where T (i) is the length of the i-th target sequence, y(i)
t
de-
notes the t-th token, and pθ is the model probability.
Experimental Evaluation
To evaluate the effectiveness of our proposed OptiTrust
agent, we compare it against state-of-the-art baseline meth-
ods (four prompting-based methods, including GPT-4 with
standard prompting, Chain-of-Thought (CoT), Chain-of-
Experts, and CAFA, and one fine-tuning-based method,
ORLM-LLaMA-3 8B) on seven publicly available datasets
commonly used in the optimization modeling literature:
NL4Opt (Ramamonjison et al. 2023), EasyLP and Com-
plexLP (Huang et al. 2024), IndustryOR (Tang et al. 2024),
NLP4LP (AhmadiTeshnizi, Gao, and Udell 2024), Com-
plexOR (Xiao et al. 2023), and ReSocratic (Yang et al.


--- Page 6 ---
Methods
NL4Opt
EasyLP
NLP4LP
ReSocratic
ComplexOR
IndustryOR
ComplexLP
GPT-4
61.2%
70.3%
73.6%
48.4%
42.9%
38.1%
57.7%
CoT
62.2%
49.5%
74.7%
43.6%
39.2%
40.5%
42.3%
Chain-of-Experts
66.7%
94.4%
87.4%
71.2%
57.1%
31.2%
50.6%
CAFA
68.1%
71.2%
50.0%
40.1%
46.4%
41.1%
44.5%
ORLM-LLaMA-3 8B
73.8%
90.4%
76.4%
61.8%
50.0%
42.9%
59.5%
OptiTrust
91.6%
92.3%
94.4%
81.4%
61.1%
42.9%
63.1%
Table 1: Solution accuracy comparison across seven benchmark datasets.
2025). These datasets span different application domains
and cover multiple types of optimization problems; however,
as discussed in the recent survey paper (Xiao et al. 2025),
the original datasets are unreliable for rigorous evaluation
due to substantial inaccuracies arising from logical errors,
poorly defined parameters, and incorrect ground truth data.
Due to the inconsistency of ground-truth labels, as well as
limited code accessibility, we compare performance primar-
ily against the results reported in (Xiao et al. 2025). Our pri-
mary evaluation metric is Solution Accuracy, defined as the
proportion of solutions correctly identifying the optimal so-
lution to the optimization problems. This metric is widely
accepted and recommended in prior benchmarking studies
(Xiao et al. 2025; Yang et al. 2025; Huang et al. 2025). We
use the same evaluation methodology in terms of the selec-
tion of baseline methods, cleaned datasets (LLM4OR 2025),
and performance metric as proposed in (Xiao et al. 2025),
which aims to establish the latest leaderboard for optimiza-
tion modeling methods.
We fine-tuned the Granite 3.2 8B Instruct model (IBM
Granite Team 2025) to serve as the agent backbone, leverag-
ing 15000 synthetic training samples for a full fine-tuning -
details are documented in the supplementary material. Dur-
ing training and evaluation, we permitted up to six iterations
of debugging, as well as one self-reflection round for both
decomposition and formulation agents.
Overall Performance Analysis
Table 1 summarizes the solution accuracy of OptiTrust com-
pared to baseline methods across all benchmark datasets.
The training-free methods utilize the cutting-edge commer-
cial OpenAI model gpt-4o-2024-08-06, ensuring state-of-
the-art performance from prompting-based models.
As presented in Table 1, our OptiTrust agent consis-
tently achieves superior performance across the majority of
datasets, attaining the highest solution accuracy in 6 out of
the 7 evaluated benchmarks. Notably, OptiTrust significantly
outperforms the next-best algorithm on several datasets such
as NL4Opt and ReSocratic by at least 14%, demonstrating
its effectiveness in handling both standard and more nuanced
optimization modeling challenges. While Chain-of-Experts
shows strong performance on EasyLP, OptiTrust maintains
a competitive second position, underscoring its robustness.
Our analysis further reveals that optimization problems
characterized by complex and lengthy descriptions—such
as ComplexOR, IndustryOR, and ComplexLP—remain par-
ticularly challenging for all evaluated methods, with solu-
tion accuracies consistently below 65%. This indicates that
substantial scope exists for further research into enhancing
LLM agents’ capability to interpret and accurately model
highly complex optimization scenarios.
Overall, the empirical results strongly validate the effi-
cacy and robustness of our proposed OptiTrust framework.
By incorporating systematic, structured reasoning steps, ma-
jority voting, and leveraging verified synthetic training data,
OptiTrust demonstrates significant potential for improving
the reliability and interpretability of automated optimization
modeling agents, setting a strong foundation for future ad-
vances in this important domain.
Individual Modeling Language and Majority
Voting Analysis
We further investigate the performance for each modeling
language and the effectiveness of majority voting across
different optimization modeling languages within our Op-
tiTrust framework. Specifically, we compare the solution ac-
curacy of the OptiTrust agent employing majority voting
across five popular optimization modeling languages: Py-
omo, Gurobipy, PySCIPOpt, DOcplex, and CVXPY. Results
using our OptiTrust agent with the base Granite model, with-
out fine-tuning, are summarized in Table 2, while results af-
ter fine-tuning Granite are presented in Table 3.
As demonstrated by these results, majority voting consis-
tently enhances performance across all datasets. This aggre-
gation mechanism effectively captures correct solutions by
leveraging the diversity of solver implementations, thereby
mitigating the limitations of any individual solver. Notably,
substantial performance improvements are observed follow-
ing the fine-tuning of the Granite model. Each modeling lan-
guage demonstrates significant accuracy improvements after
fine-tuning, underscoring the effectiveness of our synthetic
data generation approach. For several datasets, including Ea-
syLP and NLP4LP, the modeling languages achieve simi-
larly strong performance levels, yielding comparably high
accuracies after training.
Moreover,
it
is
noteworthy
that
more
challenging
datasets—such as ComplexOR, IndustryOR, and Com-
plexLP—exhibit greater relative improvements after fine-
tuning. For instance, the accuracy for the ComplexOR
dataset improved markedly from 38.9% to 61.1%, while
ComplexLP increased from 41.4% to 63.1%, underscoring
the enhanced capability of the fine-tuned model to handle
complex optimization scenarios.
These findings illustrate the advantage of majority voting


--- Page 7 ---
Methods
NL4Opt
EasyLP
NLP4LP
ReSocratic
ComplexOR
IndustryOR
ComplexLP
Pyomo
20.6%
29.7%
15.7%
13.4%
22.2%
11.9%
22.5%
Gurobipy
84.6%
79.4%
88.2%
73.2%
38.9%
26.2%
37.8%
PySCIPOpt
83.6%
87.3%
84.3%
68.7%
22.2%
23.8%
35.1%
DOcplex
66.4%
64.8%
73.0%
52.9%
27.8%
19.0%
27.9%
CVXPY
43.9%
57.8%
36.5%
41.4%
0.0%
14.3%
29.7%
OptiTrust
84.6%
89.2%
88.2%
73.4%
38.9%
26.2%
41.4%
Table 2: Solution accuracy comparison across modeling languages with non-fine-tuned Granite model.
Methods
NL4Opt
EasyLP
NLP4LP
ReSocratic
ComplexOR
IndustryOR
ComplexLP
Pyomo
90.7%
90.5%
92.7%
73.4%
50.0%
40.5%
51.4%
Gurobipy
87.9%
91.6%
93.8%
79.9%
50.0%
35.7%
56.8%
PySCIPOpt
87.9%
91.4%
91.6%
76.9%
50.0%
38.1%
48.6%
DOcplex
89.3%
91.0%
92.7%
75.7%
44.4%
28.6%
57.7%
CVXPY
89.3%
89.0%
92.7%
73.9%
27.8%
28.6%
45.9%
OptiTrust
91.6%
92.3%
94.4%
81.4%
61.1%
42.9%
63.1%
Table 3: Solution accuracy comparison across modeling languages with fine-tuned Granite.
in enhancing robustness and solution accuracy, especially
when combined with fine-tuning, highlighting the impor-
tance of integrating multiple modeling languages and rigor-
ous training methodologies for complex optimization tasks.
Addressing Data Quality Issues
Existing optimization modeling datasets are significantly
constrained in terms of scale, quality, and structural consis-
tency. A key insight made by (Xiao et al. 2025) highlights
that the original 7 benchmark datasets are unreliable for
rigorous evaluation due to substantial inaccuracies, primar-
ily manifesting as incorrect optimal ground-truth values and
logical inconsistencies within problem descriptions. Apart
from the EasyLP dataset, the reported error rates in these
benchmarks exceed 16%, with the IndustryOR dataset ex-
hibiting errors as high as 54%. Such severe inaccuracies not
only undermine the credibility of comparative studies but
also emphasize the necessity for precise, verifiable, and ro-
bust datasets within the optimization modeling community.
To address this critical issue, (Xiao et al. 2025) provided
cleaned versions of these datasets by removing problematic
data instances, resulting in a notable reduction in dataset
size. Table 4 outlines the impact of this cleaning proce-
dure, comparing the original number of problem instances
(“Original Size”) with the number remaining after cleaning
(“Cleaned Size”). For datasets such as IndustryOR, Com-
plexLP, and ComplexOR, nearly half of the original data in-
stances were excluded due to inaccuracies.
Building upon this previous effort, in this work, we further
enhance the dataset quality beyond the initial cleaning pro-
cess. We utilize our OptiTrust agent to systematically iden-
tify additional instances with incorrect ground truth optimal
values. These inaccuracies were then corrected by using val-
ues from our agent, and the resulting revisions underwent
rigorous validation by domain experts. As indicated in the
Dataset
Original Size
Cleaned Size
Error Rate
NL4Opt
289
214
7.0%
IndustryOR
100
42
2.4%
ComplexLP
211
111
2.7%
ReSocratic
605
405
0.7%
ComplexOR
37
18
11.1%
Table 4: Detected and corrected error rates of optimization
modeling benchmarks.
Error Rate column of Table 4, even after the previous clean-
ing efforts, some datasets such as NL4Opt and ComplexOR
retained a non-trivial proportion of errors, highlighting the
importance and effectiveness of our further refinements.
Conclusion
We have introduced OptiTrust, a modular LLM agent de-
signed to translate natural language descriptions into solver-
ready code by leveraging a principled synthetic data genera-
tion pipeline. By starting from a structured symbolic repre-
sentation and systematically producing aligned natural lan-
guage description, mathematical formulation, and code with
a verified optimal solution, our framework addresses the
challenges of data scarcity, lack of verifiability, and limited
generalization in optimization modeling with LLMs. Our
approach enables fully programmatic construction of diverse
and scalable NL2Opt datasets, supporting robust supervised
fine-tuning across multiple modeling languages. The incor-
poration of stepwise demonstrations, multi-language infer-
ence, and majority-vote cross-validation leads to enhanced
performance, as demonstrated by OptiTrust’s state-of-the-
art results on a range of public benchmarks. Furthermore,
our agent has proven valuable in identifying and correcting
errors in existing datasets, thereby improving the reliability
of evaluation standards within the community.


--- Page 8 ---
References
Abdin, M.; Aneja, J.; Behl, H.; Bubeck, S.; Eldan, R.; Gu-
nasekar, S.; Harrison, M.; Hewett, R. J.; Javaheripi, M.;
Kauffmann, P.; Lee, J. R.; Lee, Y. T.; Li, Y.; Liu, W.;
Mendes, C. C. T.; Nguyen, A.; Price, E.; de Rosa, G.;
Saarikivi, O.; Salim, A.; Shah, S.; Wang, X.; Ward, R.; Wu,
Y.; Yu, D.; Zhang, C.; and Zhang, Y. 2024. Phi-4 Technical
Report. arXiv:2412.08905.
AhmadiTeshnizi, A.; Gao, W.; and Udell, M. 2024. Opti-
MUS: Scalable Optimization Modeling Using MIP Solvers
and Large Language Models. In International Conference
on Machine Learning (ICML).
Astorga, N.; Liu, T.; Xiao, Y.; and van der Schaar, M. 2025.
Autoformulation of Mathematical Optimization Models Us-
ing LLMs.
In Forty-second International Conference on
Machine Learning.
Bai, J.; Bai, S.; Chu, Y.; Cui, Z.; Dang, K.; Deng, X.; Fan,
Y.; Ge, W.; Han, Y.; Huang, F.; Hui, B.; Ji, L.; Li, M.; Lin,
J.; Lin, R.; Liu, D.; Liu, G.; Lu, C.; Lu, K.; Ma, J.; Men,
R.; Ren, X.; Ren, X.; Tan, C.; Tan, S.; Tu, J.; Wang, P.;
Wang, S.; Wang, W.; Wu, S.; Xu, B.; Xu, J.; Yang, A.; Yang,
H.; Yang, J.; Yang, S.; Yao, Y.; Yu, B.; Yuan, H.; Yuan, Z.;
Zhang, J.; Zhang, X.; Zhang, Y.; Zhang, Z.; Zhou, C.; Zhou,
J.; Zhou, X.; and Zhu, T. 2024. Qwen Technical Report.
arXiv preprint arXiv:2309.16609.
Bolusani, S.; Besanc¸on, M.; Bestuzheva, K.; Chmiela, A.;
Dion´ısio, J.; Donkiewicz, T.; van Doornmalen, J.; Eifler,
L.; Ghannam, M.; Gleixner, A.; Graczyk, C.; Halbig, K.;
Hedtke, I.; Hoen, A.; Hojny, C.; van der Hulst, R.; Kamp, D.;
Koch, T.; Kofler, K.; Lentz, J.; Manns, J.; Mexi, G.; M¨uhmer,
E.; Pfetsch, M. E.; Schl¨osser, F.; Serrano, F.; Shinano, Y.;
Turner, M.; Vigerske, S.; Weninger, D.; and Xu, L. 2024.
The SCIP Optimization Suite 9.0. arXiv:2402.17702.
Chen, X.; Aksitov, R.; Alon, U.; Ren, J.; Xiao, K.; Yin,
P.; Prakash, S.; Sutton, C.; Wang, X.; and Zhou, D. 2024.
Universal Self-Consistency for Large Language Models. In
ICML 2024 Workshop on In-Context Learning.
Cobbe, K.; Kosaraju, V.; Bavarian, M.; Chen, M.; Jun, H.;
Kaiser, L.; Plappert, M.; Tworek, J.; Hilton, J.; Nakano, R.;
Hesse, C.; and Schulman, J. 2021.
Training Verifiers to
Solve Math Word Problems. arXiv:2110.14168.
Cplex, I. I. 2024. V22.1.2: User’s Manual for CPLEX.
DeepSeek-AI; Guo, D.; Yang, D.; Zhang, H.; Song, J.;
Zhang, R.; Xu, R.; Zhu, Q.; Ma, S.; Wang, P.; Bi, X.; Zhang,
X.; Yu, X.; Wu, Y.; Wu, Z. F.; Gou, Z.; Shao, Z.; Li, Z.; Gao,
Z.; Liu, A.; Xue, B.; Wang, B.; Wu, B.; Feng, B.; Lu, C.;
Zhao, C.; Deng, C.; Zhang, C.; Ruan, C.; Dai, D.; Chen, D.;
Ji, D.; Li, E.; Lin, F.; Dai, F.; Luo, F.; Hao, G.; Chen, G.; Li,
G.; Zhang, H.; Bao, H.; Xu, H.; Wang, H.; Ding, H.; Xin,
H.; Gao, H.; Qu, H.; Li, H.; Guo, J.; Li, J.; Wang, J.; Chen,
J.; Yuan, J.; Qiu, J.; Li, J.; Cai, J. L.; Ni, J.; Liang, J.; Chen,
J.; Dong, K.; Hu, K.; Gao, K.; Guan, K.; Huang, K.; Yu, K.;
Wang, L.; Zhang, L.; Zhao, L.; Wang, L.; Zhang, L.; Xu,
L.; Xia, L.; Zhang, M.; Zhang, M.; Tang, M.; Li, M.; Wang,
M.; Li, M.; Tian, N.; Huang, P.; Zhang, P.; Wang, Q.; Chen,
Q.; Du, Q.; Ge, R.; Zhang, R.; Pan, R.; Wang, R.; Chen,
R. J.; Jin, R. L.; Chen, R.; Lu, S.; Zhou, S.; Chen, S.; Ye,
S.; Wang, S.; Yu, S.; Zhou, S.; Pan, S.; Li, S. S.; Zhou, S.;
Wu, S.; Ye, S.; Yun, T.; Pei, T.; Sun, T.; Wang, T.; Zeng, W.;
Zhao, W.; Liu, W.; Liang, W.; Gao, W.; Yu, W.; Zhang, W.;
Xiao, W. L.; An, W.; Liu, X.; Wang, X.; Chen, X.; Nie, X.;
Cheng, X.; Liu, X.; Xie, X.; Liu, X.; Yang, X.; Li, X.; Su,
X.; Lin, X.; Li, X. Q.; Jin, X.; Shen, X.; Chen, X.; Sun, X.;
Wang, X.; Song, X.; Zhou, X.; Wang, X.; Shan, X.; Li, Y. K.;
Wang, Y. Q.; Wei, Y. X.; Zhang, Y.; Xu, Y.; Li, Y.; Zhao, Y.;
Sun, Y.; Wang, Y.; Yu, Y.; Zhang, Y.; Shi, Y.; Xiong, Y.; He,
Y.; Piao, Y.; Wang, Y.; Tan, Y.; Ma, Y.; Liu, Y.; Guo, Y.; Ou,
Y.; Wang, Y.; Gong, Y.; Zou, Y.; He, Y.; Xiong, Y.; Luo, Y.;
You, Y.; Liu, Y.; Zhou, Y.; Zhu, Y. X.; Xu, Y.; Huang, Y.;
Li, Y.; Zheng, Y.; Zhu, Y.; Ma, Y.; Tang, Y.; Zha, Y.; Yan,
Y.; Ren, Z. Z.; Ren, Z.; Sha, Z.; Fu, Z.; Xu, Z.; Xie, Z.;
Zhang, Z.; Hao, Z.; Ma, Z.; Yan, Z.; Wu, Z.; Gu, Z.; Zhu, Z.;
Liu, Z.; Li, Z.; Xie, Z.; Song, Z.; Pan, Z.; Huang, Z.; Xu, Z.;
Zhang, Z.; and Zhang, Z. 2025. DeepSeek-R1: Incentivizing
Reasoning Capability in LLMs via Reinforcement Learning.
arXiv:2501.12948.
FMS HF Tuning Team. 2025. Foundation Model Stack Hug-
ging Face Tuning.
Grattafiori, A.; Dubey, A.; Jauhri, A.; Pandey, A.; Kadian,
A.; Al-Dahle, A.; Letman, A.; Mathur, A.; Schelten, A.;
Vaughan, A.; Yang, A.; Fan, A.; Goyal, A.; Hartshorn,
A.; Yang, A.; Mitra, A.; Sravankumar, A.; Korenev, A.;
Hinsvark, A.; Rao, A.; Zhang, A.; Rodriguez, A.; Gregerson,
A.; Spataru, A.; Roziere, B.; Biron, B.; Tang, B.; Chern, B.;
Caucheteux, C.; Nayak, C.; Bi, C.; Marra, C.; McConnell,
C.; Keller, C.; Touret, C.; Wu, C.; Wong, C.; Ferrer, C. C.;
Nikolaidis, C.; Allonsius, D.; Song, D.; Pintz, D.; Livshits,
D.; Wyatt, D.; Esiobu, D.; Choudhary, D.; Mahajan, D.;
Garcia-Olano, D.; Perino, D.; Hupkes, D.; Lakomkin, E.;
AlBadawy, E.; Lobanova, E.; Dinan, E.; Smith, E. M.; Rade-
novic, F.; Guzm´an, F.; Zhang, F.; Synnaeve, G.; Lee, G.;
Anderson, G. L.; Thattai, G.; Nail, G.; Mialon, G.; Pang,
G.; Cucurell, G.; Nguyen, H.; Korevaar, H.; Xu, H.; Tou-
vron, H.; Zarov, I.; Ibarra, I. A.; Kloumann, I.; Misra, I.;
Evtimov, I.; Zhang, J.; Copet, J.; Lee, J.; Geffert, J.; Vranes,
J.; Park, J.; Mahadeokar, J.; Shah, J.; van der Linde, J.; Bil-
lock, J.; Hong, J.; Lee, J.; Fu, J.; Chi, J.; Huang, J.; Liu,
J.; Wang, J.; Yu, J.; Bitton, J.; Spisak, J.; Park, J.; Rocca,
J.; Johnstun, J.; Saxe, J.; Jia, J.; Alwala, K. V.; Prasad, K.;
Upasani, K.; Plawiak, K.; Li, K.; Heafield, K.; Stone, K.; El-
Arini, K.; Iyer, K.; Malik, K.; Chiu, K.; Bhalla, K.; Lakho-
tia, K.; Rantala-Yeary, L.; van der Maaten, L.; Chen, L.; Tan,
L.; Jenkins, L.; Martin, L.; Madaan, L.; Malo, L.; Blecher,
L.; Landzaat, L.; de Oliveira, L.; Muzzi, M.; Pasupuleti,
M.; Singh, M.; Paluri, M.; Kardas, M.; Tsimpoukelli, M.;
Oldham, M.; Rita, M.; Pavlova, M.; Kambadur, M.; Lewis,
M.; Si, M.; Singh, M. K.; Hassan, M.; Goyal, N.; Torabi,
N.; Bashlykov, N.; Bogoychev, N.; Chatterji, N.; Zhang,
N.; Duchenne, O.; C¸ elebi, O.; Alrassy, P.; Zhang, P.; Li, P.;
Vasic, P.; Weng, P.; Bhargava, P.; Dubal, P.; Krishnan, P.;
Koura, P. S.; Xu, P.; He, Q.; Dong, Q.; Srinivasan, R.; Gana-
pathy, R.; Calderer, R.; Cabral, R. S.; Stojnic, R.; Raileanu,
R.; Maheswari, R.; Girdhar, R.; Patel, R.; Sauvestre, R.;
Polidoro, R.; Sumbaly, R.; Taylor, R.; Silva, R.; Hou, R.;
Wang, R.; Hosseini, S.; Chennabasappa, S.; Singh, S.; Bell,


--- Page 9 ---
S.; Kim, S. S.; Edunov, S.; Nie, S.; Narang, S.; Raparthy,
S.; Shen, S.; Wan, S.; Bhosale, S.; Zhang, S.; Vandenhende,
S.; Batra, S.; Whitman, S.; Sootla, S.; Collot, S.; Gururan-
gan, S.; Borodinsky, S.; Herman, T.; Fowler, T.; Sheasha, T.;
Georgiou, T.; Scialom, T.; Speckbacher, T.; Mihaylov, T.;
Xiao, T.; Karn, U.; Goswami, V.; Gupta, V.; Ramanathan,
V.; Kerkez, V.; Gonguet, V.; Do, V.; Vogeti, V.; Albiero, V.;
Petrovic, V.; Chu, W.; Xiong, W.; Fu, W.; Meers, W.; Mar-
tinet, X.; Wang, X.; Wang, X.; Tan, X. E.; Xia, X.; Xie,
X.; Jia, X.; Wang, X.; Goldschlag, Y.; Gaur, Y.; Babaei,
Y.; Wen, Y.; Song, Y.; Zhang, Y.; Li, Y.; Mao, Y.; Coudert,
Z. D.; Yan, Z.; Chen, Z.; Papakipos, Z.; Singh, A.; Srivas-
tava, A.; Jain, A.; Kelsey, A.; Shajnfeld, A.; Gangidi, A.;
Victoria, A.; Goldstand, A.; Menon, A.; Sharma, A.; Boe-
senberg, A.; Baevski, A.; Feinstein, A.; Kallet, A.; Sangani,
A.; Teo, A.; Yunus, A.; Lupu, A.; Alvarado, A.; Caples, A.;
Gu, A.; Ho, A.; Poulton, A.; Ryan, A.; Ramchandani, A.;
Dong, A.; Franco, A.; Goyal, A.; Saraf, A.; Chowdhury,
A.; Gabriel, A.; Bharambe, A.; Eisenman, A.; Yazdan, A.;
James, B.; Maurer, B.; Leonhardi, B.; Huang, B.; Loyd, B.;
Paola, B. D.; Paranjape, B.; Liu, B.; Wu, B.; Ni, B.; Han-
cock, B.; Wasti, B.; Spence, B.; Stojkovic, B.; Gamido, B.;
Montalvo, B.; Parker, C.; Burton, C.; Mejia, C.; Liu, C.;
Wang, C.; Kim, C.; Zhou, C.; Hu, C.; Chu, C.-H.; Cai, C.;
Tindal, C.; Feichtenhofer, C.; Gao, C.; Civin, D.; Beaty, D.;
Kreymer, D.; Li, D.; Adkins, D.; Xu, D.; Testuggine, D.;
David, D.; Parikh, D.; Liskovich, D.; Foss, D.; Wang, D.;
Le, D.; Holland, D.; Dowling, E.; Jamil, E.; Montgomery,
E.; Presani, E.; Hahn, E.; Wood, E.; Le, E.-T.; Brinkman, E.;
Arcaute, E.; Dunbar, E.; Smothers, E.; Sun, F.; Kreuk, F.;
Tian, F.; Kokkinos, F.; Ozgenel, F.; Caggioni, F.; Kanayet,
F.; Seide, F.; Florez, G. M.; Schwarz, G.; Badeer, G.; Swee,
G.; Halpern, G.; Herman, G.; Sizov, G.; Guangyi; Zhang;
Lakshminarayanan, G.; Inan, H.; Shojanazeri, H.; Zou, H.;
Wang, H.; Zha, H.; Habeeb, H.; Rudolph, H.; Suk, H.; As-
pegren, H.; Goldman, H.; Zhan, H.; Damlaj, I.; Molybog,
I.; Tufanov, I.; Leontiadis, I.; Veliche, I.-E.; Gat, I.; Weiss-
man, J.; Geboski, J.; Kohli, J.; Lam, J.; Asher, J.; Gaya, J.-
B.; Marcus, J.; Tang, J.; Chan, J.; Zhen, J.; Reizenstein, J.;
Teboul, J.; Zhong, J.; Jin, J.; Yang, J.; Cummings, J.; Carvill,
J.; Shepard, J.; McPhie, J.; Torres, J.; Ginsburg, J.; Wang, J.;
Wu, K.; U, K. H.; Saxena, K.; Khandelwal, K.; Zand, K.;
Matosich, K.; Veeraraghavan, K.; Michelena, K.; Li, K.; Ja-
gadeesh, K.; Huang, K.; Chawla, K.; Huang, K.; Chen, L.;
Garg, L.; A, L.; Silva, L.; Bell, L.; Zhang, L.; Guo, L.; Yu,
L.; Moshkovich, L.; Wehrstedt, L.; Khabsa, M.; Avalani, M.;
Bhatt, M.; Mankus, M.; Hasson, M.; Lennie, M.; Reso, M.;
Groshev, M.; Naumov, M.; Lathi, M.; Keneally, M.; Liu, M.;
Seltzer, M. L.; Valko, M.; Restrepo, M.; Patel, M.; Vyatskov,
M.; Samvelyan, M.; Clark, M.; Macey, M.; Wang, M.; Her-
moso, M. J.; Metanat, M.; Rastegari, M.; Bansal, M.; San-
thanam, N.; Parks, N.; White, N.; Bawa, N.; Singhal, N.;
Egebo, N.; Usunier, N.; Mehta, N.; Laptev, N. P.; Dong, N.;
Cheng, N.; Chernoguz, O.; Hart, O.; Salpekar, O.; Kalinli,
O.; Kent, P.; Parekh, P.; Saab, P.; Balaji, P.; Rittner, P.; Bon-
trager, P.; Roux, P.; Dollar, P.; Zvyagina, P.; Ratanchandani,
P.; Yuvraj, P.; Liang, Q.; Alao, R.; Rodriguez, R.; Ayub,
R.; Murthy, R.; Nayani, R.; Mitra, R.; Parthasarathy, R.; Li,
R.; Hogan, R.; Battey, R.; Wang, R.; Howes, R.; Rinott, R.;
Mehta, S.; Siby, S.; Bondu, S. J.; Datta, S.; Chugh, S.; Hunt,
S.; Dhillon, S.; Sidorov, S.; Pan, S.; Mahajan, S.; Verma,
S.; Yamamoto, S.; Ramaswamy, S.; Lindsay, S.; Lindsay, S.;
Feng, S.; Lin, S.; Zha, S. C.; Patil, S.; Shankar, S.; Zhang,
S.; Zhang, S.; Wang, S.; Agarwal, S.; Sajuyigbe, S.; Chin-
tala, S.; Max, S.; Chen, S.; Kehoe, S.; Satterfield, S.; Govin-
daprasad, S.; Gupta, S.; Deng, S.; Cho, S.; Virk, S.; Subra-
manian, S.; Choudhury, S.; Goldman, S.; Remez, T.; Glaser,
T.; Best, T.; Koehler, T.; Robinson, T.; Li, T.; Zhang, T.;
Matthews, T.; Chou, T.; Shaked, T.; Vontimitta, V.; Ajayi,
V.; Montanez, V.; Mohan, V.; Kumar, V. S.; Mangla, V.;
Ionescu, V.; Poenaru, V.; Mihailescu, V. T.; Ivanov, V.; Li,
W.; Wang, W.; Jiang, W.; Bouaziz, W.; Constable, W.; Tang,
X.; Wu, X.; Wang, X.; Wu, X.; Gao, X.; Kleinman, Y.; Chen,
Y.; Hu, Y.; Jia, Y.; Qi, Y.; Li, Y.; Zhang, Y.; Zhang, Y.; Adi,
Y.; Nam, Y.; Yu; Wang; Zhao, Y.; Hao, Y.; Qian, Y.; Li, Y.;
He, Y.; Rait, Z.; DeVito, Z.; Rosnbrick, Z.; Wen, Z.; Yang,
Z.; Zhao, Z.; and Ma, Z. 2024. The Llama 3 Herd of Models.
arXiv:2407.21783.
Gurobi Optimization, LLC. 2024. Gurobi Optimizer Refer-
ence Manual.
Huang, C.; Tang, Z.; Hu, S.; Jiang, R.; Zheng, X.; Ge,
D.; Wang, B.; and Wang, Z. 2025.
ORLM: A Cus-
tomizable Framework in Training Large Models for Au-
tomated Optimization Modeling.
Operations Research.
ArXiv:2405.17743 [cs].
Huang, X.; Shen, Q.; Hu, Y.; Gao, A.; and Wang, B. 2024.
Mamo: a Mathematical Modeling Benchmark with Solvers.
ArXiv:2405.13144 [cs].
IBM Granite Team. 2025. Granite 3.2 Language Models.
Jiang, C.; Shu, X.; Qian, H.; Lu, X.; ZHOU, J.; Zhou, A.;
and Yu, Y. 2025. LLMOPT: Learning to Define and Solve
General Optimization Problems from Scratch. In The Thir-
teenth International Conference on Learning Representa-
tions.
Kwon, W.; Li, Z.; Zhuang, S.; Sheng, Y.; Zheng, L.; Yu,
C. H.; Gonzalez, J. E.; Zhang, H.; and Stoica, I. 2023. Ef-
ficient Memory Management for Large Language Model
Serving with PagedAttention. In Proceedings of the ACM
SIGOPS 29th Symposium on Operating Systems Principles.
Lambert, N.; Morrison, J.; Pyatkin, V.; Huang, S.; Ivison,
H.; Brahman, F.; Miranda, L. J. V.; Liu, A.; Dziri, N.; Lyu,
S.; Gu, Y.; Malik, S.; Graf, V.; Hwang, J. D.; Yang, J.;
Bras, R. L.; Tafjord, O.; Wilhelm, C.; Soldaini, L.; Smith,
N. A.; Wang, Y.; Dasigi, P.; and Hajishirzi, H. 2025. Tulu 3:
Pushing Frontiers in Open Language Model Post-Training.
arXiv:2411.15124.
Li, B.; Mellou, K.; Zhang, B.; Pathuri, J.; and Menache, I.
2023. Large Language Models for Supply Chain Optimiza-
tion. ArXiv:2307.03875 [cs].
Li, J.; Beeching, E.; Tunstall, L.; Lipkin, B.; Solet-
skyi, R.; Huang, S. C.; Rasul, K.; Yu, L.; Jiang, A.;
Shen,
Z.;
Qin,
Z.;
Dong,
B.;
Zhou,
L.;
Fleureau,
Y.;
Lample,
G.;
and
Polu,
S.
2024.
Numina-
Math.
[https://huggingface.co/AI-MO/NuminaMath-
CoT](https://github.com/project-numina/aimo-progress-
prize/blob/main/report/numina dataset.pdf).


--- Page 10 ---
LLM4OR.
2025.
LLM4OR.
Available
at:
https://anonymous.4open.science/r/LLM4OR-
2781/README.md.
Lu, H.; Xie, Z.; Wu, Y.; Ren, C.; Chen, Y.; and Wen, Z. 2025.
OptMATH: A Scalable Bidirectional Data Synthesis Frame-
work for Optimization Modeling. In Forty-second Interna-
tional Conference on Machine Learning.
Meta AI. 2025. The Llama 4 herd: The beginning of a new
era of natively multimodal AI innovation.
Mishra, M.; Stallone, M.; Zhang, G.; Shen, Y.; Prasad, A.;
Soria, A. M.; Merler, M.; Selvam, P.; Surendran, S.; Singh,
S.; Sethi, M.; Dang, X.-H.; Li, P.; Wu, K.-L.; Zawad, S.;
Coleman, A.; White, M.; Lewis, M.; Pavuluri, R.; Koyfman,
Y.; Lublinsky, B.; de Bayser, M.; Abdelaziz, I.; Basu, K.;
Agarwal, M.; Zhou, Y.; Johnson, C.; Goyal, A.; Patel, H.;
Shah, Y.; Zerfos, P.; Ludwig, H.; Munawar, A.; Crouse, M.;
Kapanipathi, P.; Salaria, S.; Calio, B.; Wen, S.; Seelam, S.;
Belgodere, B.; Fonseca, C.; Singhee, A.; Desai, N.; Cox,
D. D.; Puri, R.; and Panda, R. 2024. Granite Code Models:
A Family of Open Foundation Models for Code Intelligence.
arXiv:2405.04324.
OpenAI. 2025. OpenAI o3 and o4-mini System Card.
Ramamonjison, R.; Yu, T. T.; Li, R.; Li, H.; Carenini,
G.; Ghaddar, B.; He, S.; Mostajabdaveh, M.; Banitalebi-
Dehkordi, A.; Zhou, Z.; and Zhang, Y. 2023.
NL4Opt
Competition: Formulating Optimization Problems Based on
Their Natural Language Descriptions.
ArXiv:2303.08233
[cs].
Tang, Z.; Huang, C.; Zheng, X.; Hu, S.; Wang, Z.; Ge, D.;
and Wang, B. 2024. ORLM: Training Large Language Mod-
els for Optimization Modeling. ArXiv:2405.17743 [cs].
von Werra, L.; Belkada, Y.; Tunstall, L.; Beeching, E.;
Thrush, T.; Lambert, N.; Huang, S.; Rasul, K.; and Gal-
lou´edec, Q. 2020. TRL: Transformer Reinforcement Learn-
ing. https://github.com/huggingface/trl.
Wang, X.; Wei, J.; Schuurmans, D.; Le, Q. V.; Chi, E. H.;
Narang, S.; Chowdhery, A.; and Zhou, D. 2023.
Self-
Consistency Improves Chain of Thought Reasoning in Lan-
guage Models. In The Eleventh International Conference on
Learning Representations.
Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; brian ichter;
Xia, F.; Chi, E. H.; Le, Q. V.; and Zhou, D. 2022. Chain
of Thought Prompting Elicits Reasoning in Large Language
Models. In Oh, A. H.; Agarwal, A.; Belgrave, D.; and Cho,
K., eds., Advances in Neural Information Processing Sys-
tems.
Xiao, Z.; Xie, J.; Xu, L.; Guan, S.; Zhu, J.; Han, X.; Fu,
X.; Yu, W.; Wu, H.; Shi, W.; Kang, Q.; Duan, J.; Zhong,
T.; Yuan, M.; Zeng, J.; Wang, Y.; Chen, G.; and Zhang, D.
2025. A Survey of Optimization Modeling Meets LLMs:
Progress and Future Directions. In The International Joint
Conference on Artificial Intelligence (IJCAI).
Xiao, Z.; Zhang, D.; Wu, Y.; Xu, L.; Wang, Y. J.; Han, X.;
Fu, X.; Zhong, T.; Zeng, J.; Song, M.; and Chen, G. 2023.
Chain-of-Experts: When LLMs Meet Complex Operations
Research Problems.
Yang, Z.; Wang, Y.; Huang, Y.; Guo, Z.; Shi, W.; Han, X.;
Feng, L.; Song, L.; Liang, X.; and Tang, J. 2025. OptiBench
Meets ReSocratic: Measure and Improve LLMs for Opti-
mization Modeling. In The Thirteenth International Con-
ference on Learning Representations.
Zhang, J.; Wang, W.; Guo, S.; Wang, L.; Lin, F.; Yang,
C.; and Yin, W. 2024. Solving General Natural-Language-
Description Optimization Problems with Large Language
Models. In Yang, Y.; Davani, A.; Sil, A.; and Kumar, A.,
eds., Proceedings of the 2024 Conference of the North Amer-
ican Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (Volume 6: Indus-
try Track), 483–490. Mexico City, Mexico: Association for
Computational Linguistics.
Zhao, Y.; Gu, A.; Varma, R.; Luo, L.; Huang, C.-C.; Xu, M.;
Wright, L.; Shojanazeri, H.; Ott, M.; Shleifer, S.; Desmai-
son, A.; Balioglu, C.; Damania, P.; Nguyen, B.; Chauhan,
G.; Hao, Y.; Mathews, A.; and Li, S. 2023.
PyTorch
FSDP: Experiences on Scaling Fully Sharded Data Parallel.
arXiv:2304.11277.


--- Page 11 ---
Appendix
A.
Data Generation
We used the list of 18 problem domains suggested in (Ahma-
diTeshnizi, Gao, and Udell 2024) as seed domains. The do-
mains include: manufacturing and production, supply chain
management, food and beverage, transportation and logis-
tics, healthcare and medical, retail and e-commerce, envi-
ronmental and sustainability, agriculture and forestry, sci-
ence and research, energy and power systems, finance and
banking, sports and entertainment, government and pub-
lic sector, education, human resources, telecommunications,
marketing and media, and aerospace and defense.
B.
Cleaned Evaluation Datasets
Our experimental evaluation utilizes a diverse set of bench-
mark datasets, each curated to assess the modeling, reason-
ing, and solver capabilities of large language models for
mathematical optimization. The datasets include both aca-
demic and industrial benchmarks, spanning various opti-
mization problem types, real-world scenarios, and difficulty
levels. (Jiang et al. 2025) is one of the first papers to high-
light the erroneousness of benchmark datasets, but it did not
quantify the severity of the issue. Later, (Xiao et al. 2025)
systematically analyzes and reports that the majority of these
datasets have error rates exceeding 20%, and provides a
cleaned version. We further used our agent to improve the
cleaned version. Below is a brief description of each origi-
nal dataset and the final cleaned datasets.:
• NL4Opt: NL4Opt originates from the NL4Opt Competi-
tion (Ramamonjison et al. 2023), designed to evaluate au-
tomated methods for translating optimization problems
stated in natural language into code that can be processed
by mathematical solvers. The original dataset primarily
contains linear programs (LP) and mixed-integer linear
programs (MILP) and features 289 instances. After fil-
tering out low-quality examples by (Xiao et al. 2025),
it contains 214 instances. We further detected 15 incor-
rect ground truth values and fixed them for the processed
dataset.
• MAMO: The MAMO dataset consists of two categories:
EasyLP and ComplexLP (Huang et al. 2024) with some
nonlinear problems.
– EasyLP: Originally contains 652 instances covering a
wide range of LP and MILP problems. After manually
checking for correctness, the cleaned version remains
545 instances, our agent does not detect any inconsis-
tencies.
– ComplexLP: Provides 211 instances of higher diffi-
culty, focusing on more complex problem statements.
It consists of 2 nonlinear programs, and 65 combina-
torial optimization problems. The cleaned dataset in-
cludes 111 instances, where our agent corrected 3 in-
stances.
• NLP4LP: NLP4LP is sourced from the OptiMUS bench-
mark (AhmadiTeshnizi, Gao, and Udell 2024), originally
comprising 344 linear and integer programming prob-
lems characterized by some lengthy descriptions and
multi-dimensional parameters. After data cleaning, 178
consistent instances remain, with our agent detecting no
inconsistencies.
• ReSocratic: It is the OptiBench comprehensive bench-
mark (Yang et al. 2025) that encompasses both linear and
nonlinear programming problems, including those with
integer and mixed-integer variables. It consists of 605
original problems, covering a wide range of optimiza-
tion contexts and tabular data. After cleaning, the dataset
contains 405 instances, with our agent correcting three of
them.
• ComplexOR: ComplexOR, introduced in the Chain-of-
Experts paper (Xiao et al. 2023), initially comprises 37
challenging optimization problems. The dataset features
complex operations research scenarios—including three
combinatorial optimization tasks—designed to assess the
reasoning and problem-solving abilities of LLMs. Af-
ter two corrections by our agent, the final number of in-
stances is 18.
• IndustryOR: IndustryOR is an industrial benchmark
(Tang et al. 2024) tailored for optimization modeling,
introduced to evaluate the real-world applicability of
LLMs. The dataset covers data from 13 different indus-
tries, 5 question types, and 3 levels of difficulty, reflect-
ing a wide range of practical use cases. We corrected 1
instance, and the final number of cleaned instances is 42.
The final cleaned datasets are included in the zipped code
files.
C.
Implementation Details
To fine-tune the models, we use NVIDIA H100 GPUs, with
an effective batch size of 8 (four GPUs, each with a per
device train batch size of 1 and 2 gradient accumulation
steps). We set the learning rate to 1 × 10−5, and use super-
vised fine-tuning recipes from the FMS HF Tuning reposi-
tory (FMS HF Tuning Team 2025), which relies on Hugging
Face SFTTrainer (von Werra et al. 2020) and PyTorch FSDP
(Zhao et al. 2023). Moreover, we employ a two-stage super-
vised fine-tuning approach. In the first stage, we fine-tune
the model for two epochs on a set consisting of 10000 linear
problems (4000 with tabular data), 2000 knapsack problems
(1000 with tabular data) and 2000 multidimensional knap-
sack problems (1000 with tabular data). To mitigate overfit-
ting to synthetic data and promote generalization, we further
incorporate 2000 training examples from GSM8K (Cobbe
et al. 2021); 5000 instruction following (allenai/tulu-3-sft-
personas-instruction-following) and 5000 code (allenai/tulu-
3-sft-personas-code) samples from the T¨ulu 3 SFT dataset
(Lambert et al. 2025); as well as 9000 chain-of-thought sam-
ples from the Numina-CoT and Numina-TIR datasets (Li
et al. 2024). In the second stage, we fine-tune the model for
one additional targeted epoch using 1200 complex optimiza-
tion problems, including traveling salesman, set cover, bin
packing, shift scheduling, transportation, maximum flow,
and minimum cost flow tasks.
We fine-tuned the Granite 3.2 8B Instruct model (IBM
Granite Team 2025) to serve as the agent backbone of our


--- Page 12 ---
OptiTrust agent, leveraging 15000 synthetic training sam-
ples for a full fine-tuning. During training and evaluation,
we permitted up to six iterations of debugging, as well as one
self-reflection round for both the decomposition and formu-
lation agents. During inference, we set the random seed to
zero and the temperature to 0.7. We employed one NVIDIA
H100 GPU via vLLM (Kwon et al. 2023) for LLM infer-
ence and serving. We used the CPLEX solver for the mod-
eling languages Pyomo, DOcplex, and CVXPY; the Gurobi
solver for Gurobipy; and the SCIP solver for PySCIPOpt.
The accuracy is calculated based on our corrected
datasets, presented in the Experimental Evaluation section,
which are included in the zipped file. The condition to verify
the correctness of the optimal value is |fOptiTrust −flabel| ≤ϵ,
where ϵ = 10−4. Here, fOptiTrust is the value produced by
our agent, and flabel is the ground truth. We observed that
for some instances, the ground truth values are rounded to
one decimal place; in such cases, we used ϵ = 10−1 instead.
D.
Additional Numerical Results
In this section, experiments for base and fine-tuned Qwen
1.5 14B models (Bai et al. 2024) for OptiTrust are summa-
rized in Tables 5 and 6, respectively. In general, the base
Qwen model achieves worse accuracy rates than the non-
finetuned Granite model. We conjecture that the difference
in performance is due to Granite 3.2 8B being a more recent
model, on the one hand, and being exposed to supervised
instruction data that enables it to better utilize the provided
in-context learning demonstrations, on the other. It is also
worth noting that the discrepancy in accuracy across model-
ing languages is smaller for the base Qwen 1.5 14B model
than for the non-fine-tuned Granite model.
We also report both the accuracy rate and the execution
rate for the non-fine-tuned and fine-tuned Qwen 1.5 14B and
Granite 3.2 8B Instruct models on OptiTrust. The execu-
tion rate is defined as the proportion of problem instances
whose code runs without errors and generates output re-
sults. As shown in Table 7, our multi-language fine-tuning
data for OptiTrust results in higher accuracy rates, especially
for complex problems in the ComplexOR, IndustryOR, and
ComplexLP datasets. This highlights the effectiveness of the
synthetic data generation method. Overall, we also observe
improvements in execution rate after fine-tuning, except for
the Qwen model on three datasets: EasyLP, ReSocratic, and
IndustryOR.


--- Page 13 ---
Methods
NL4Opt
EasyLP
NLP4LP
ReSocratic
ComplexOR
IndustryOR
ComplexLP
Pyomo
37.4%
55.2%
66.3%
30.5%
0.0%
28.6%
12.6%
Gurobipy
31.3%
63.9%
67.4%
30.3%
0.0%
21.4%
14.4%
PySCIPOpt
34.6%
62.4%
60.7%
30.3%
0.0%
23.8%
5.4%
DOcplex
33.2%
57.2%
56.2%
25.8%
5.6%
26.2%
13.5%
CVXPY
35.5%
54.7%
64.6%
29.8%
0.0%
23.8%
9.9%
OptiTrust
49.1%
67.9%
75.8%
45.4%
5.6%
31.0%
15.3%
Table 5: Solution accuracy comparison across modeling languages for Qwen 1.5 14B without fine-tuning. For each dataset, the
highest score among Pyomo, Gurobipy, PySCIPOpt, DOcplex, and CVXPY is shown in bold.
Methods
NL4Opt
EasyLP
NLP4LP
ReSocratic
ComplexOR
IndustryOR
ComplexLP
Pyomo
85.0%
85.0%
87.6%
71.2%
27.8%
35.7%
60.4%
Gurobipy
75.2%
76.0%
79.2%
67.0%
44.4%
31.0%
63.1%
PySCIPOpt
78.0%
79.8%
82.6%
66.5%
44.4%
35.7%
63.1%
DOcplex
80.4%
81.7%
84.3%
69.5%
44.4%
31.0%
61.3%
CVXPY
84.1%
79.6%
86.0%
67.0%
27.8%
28.6%
45.9%
OptiTrust
88.3%
91.2%
91.0%
77.9%
50.0%
40.5%
77.5%
Table 6: Solution accuracy comparison across modeling languages for Qwen 1.5 14B with fine-tuning. For each dataset, the
highest score among Pyomo, Gurobipy, PySCIPOpt, DOcplex, and CVXPY is shown in bold.
Methods
NL4Opt
EasyLP
NLP4LP
ReSocratic
ComplexOR
IndustryOR
ComplexLP
Execution Rate
Qwen non-fine-tuned
98.1%
99.6%
100.0%
98.8%
72.2%
100%
97.3%
Qwen fine-tuned
99.5%
98.0%
100.0%
97.5%
77.8%
95.2%
98.2%
Granite non-fine-tuned
100.0%
99.1%
99.4%
96.8%
50.0%
81.0%
85.6%
Granite fine-tuned
100.0%
99.6%
100.0%
99.8%
88.9%
90.5%
99.1%
Accuracy Rate
Qwen non-fine-tuned
49.1%
67.9%
75.8%
45.4%
5.6%
31.0%
15.3%
Qwen fine-tuned
88.3%
91.2%
91.0%
77.9%
50.0%
40.5%
77.5%
Granite non-fine-tuned
84.6%
89.2%
88.2%
73.4%
38.9%
26.2%
41.4%
Granite fine-tuned
91.6%
92.3%
94.4%
81.4%
61.1%
42.9%
63.1%
Table 7: Execution rate and accuracy rate comparison for non-fine-tuned and fine-tuned Qwen and Granite models.


--- Page 14 ---
E.
Prompt Templates
In this section, we present the key prompt templates. Owing to space limitations, we provide only the structures of the prompts,
omitting some details. Additional prompts are available in the zipped code.
E.1.
OptiTrust Agent Prompt
This subsection describes an end-to-end prompting workflow to decompose, formulate, and implement optimization problem.
DECOMPOSITION AGENT PROMPT
1
You are an expert in mathematical optimization. Your task is to identify and prepare
natural language descriptions of components of an optimization problem.
2
3
Upon receiving a problem description, you should:
4
5
1. Carefully analyze and comprehend the problem.
6
2. Summarize the decision variables related to the problem. Indicate whether each of
the decision variables is required to be integer, real or binary based on the
context of the problem.
7
3. Summarize and define the objective of the problem. Indicate any parameters or
numerical values needed to define the objective.
8
4. Identify and list all constraints, including any implicit ones like non-
negativity. List and summarize the constraints using natural language. Indicate
any parameters or numerical values needed to define each of the constraints
9
5. Verify if any numerical values or parameters defined in the problem description
are missing from the objective or constraints you identified, and update the
list of components you prepared, if necessary.
10
11
Note that
12
- If adding any mathematical expressions, try to mathematically represent
constraints and objectives as close to their natural language description as
possible; you do not need to simplify any constraints or objectives.
13
- The final list of components should be enclosed between the "‘‘‘" lines.
14
15
Here is a description of the problem we need you to find the components for:
16
-----
17
{description}
18
-----
19
20
Now, follow the steps outlined above. Explain your reasoning and remember to enclose
the final list of components between the "‘‘‘" lines.
DECOMPOSITION VERIFIER PROMPT
1
You are an expert in mathematical optimization. Your task is to review previously
identified components of an optimization problem.
2
3
Upon receiving the description of an optimization problem and a list of previously
identified components of the optimization problem, you should:
4
5
1. Carefully analyze and comprehend the problem.
6
2. Verify if the decision variables, objectives and constraints listed in the
previously prepared list of components have been identified correctly.
7
3. Verify if any decision variables, objectives or constraints in the description of
the optimization problem are missing from the previously prepared list of
components and update the list, if necessary.
8
4. Verify if any numerical values or parameters defined in the problem description
are missing from the components you identified, and update the list of
components you prepared to include those, if necessary.
9
5. Prepare a final, revised list with the components of the optimization problem (
including objectives, constraints and decision variables) in natural language.
Make sure to avoid repeating components.
10


--- Page 15 ---
11
Note that
12
- You should include any implicit constraints such as non-negativity
13
- If adding any mathematical expressions, try to mathematically represent
constraints and objectives as close to their natural language description as
possible; you do not need to simplify any constraints or objectives.
14
- You should indicate whether each of the decision variables is required to be
integer, real or binary based on the context of the problem.
15
- The final list of components should be enclosed between the "‘‘‘" lines.
16
17
Here is a description of the problem we need you to find the components for:
18
-----
19
{description}
20
-----
21
22
And here is the list of previously identified components:
23
-----
24
{previous_components}
25
-----
26
27
Now, follow the steps outlined above. Explain your reasoning and remember to enclose
the final list of components between the "‘‘‘" lines.
FORMULATION AGENT PROMPT
1
You are an expert in mathematical optimization, and your task is to model an
optimization problem.
2
3
Upon receiving the description of an optimization problem, you should:
4
5
1. Carefully analyze and comprehend the problem.
6
2. Carefully review the decision variables previously identified. Define symbols
representing the decision variables and indicate whether each of the decision
variables is required to be integer, real or binary based on the context of the
problem.
7
3. Indicate whether any decision variables are required to be non-negative based on
the context of the problem.
8
4. Carefully review the previously identified objectives, and prepare a mathematical
formulation representing the objective. If the optimization problem has
multiple objectives, convert a multi-objective optimization problem into a
single-objective optimization problem using linear scalarization with the
weights of the objectives.
9
5. Carefully review the previously identified constraints, and prepare a
mathematical formulation representing each of the constraints.
10
6. Prepare a mathematical formulation of the problem using LaTeX.
11
7. Verify if any numerical values or parameters defined in the problem description
are missing from the formulation, and update the mathematical formulation to
include them, if necessary.
12
13
Note that
14
- Try to mathematically represent constraints and objectives as close to their
natural language description as possible.
15
- You do not need to simplify any constraints or objectives.
16
- Your formulation should be in LaTeX mathematical format.
17
- The final mathematical formulation should be enclosed between the "‘‘‘" lines.
18
19
Here is a description of the problem we need you to model:
20
-----
21
{description}
22
-----
23
24
The following components have been previously identified:
25
-----


--- Page 16 ---
26
{components}
27
-----
28
29
Now, solve the problem step by step. Explain your reasoning and remember to enclose
the final list of components between the "‘‘‘" lines.
FORMULATION VERIFIER PROMPT
1
You’re an expert in mathematical optimization. You need to revise the mathematical
formulation of an optimization problem prepared by a student.
2
3
Here is a description of the problem we need you to model:
4
-----
5
{description}
6
-----
7
8
The following components have been previously identified:
9
-----
10
{components}
11
-----
12
13
And here is the mathematical formulation we need you to verify:
14
-----
15
{previous_formulation}
16
-----
17
18
Solve the problem step by step. Explain your reasoning and remember to enclose the
final list of components between the "‘‘‘" lines.
PROGRAMMER PROMPT
1
You are an expert in mathematical optimization, and your objective is to create a
Python script to solve an optimization problem using {solver}. When solving an
optimization problem, you should follow a structured approach:
2
1. Carefully analyze and comprehend the problem description.
3
2. Carefully analyze and comprehend the provided decomposition of the problem into a
detailed list of decision variables, objective(s) and constraints.
4
3. Carefully analyze and comprehend the previously prepared mathematical formulation
of the optimization problem.
5
4. Prepare a well-documented Python script to solve the optimization problem using {
solver}. Anchor your implementation on the context, the detailed decomposition,
and the formulation of the optimization problem. Pay special attention to the
domain of each decision variable, implicit constraints such as non-negativity,
and that all relevant parameters are included in the script you generate.
6
Note that
7
- You should clearly explain your reasoning and the steps you take to solve the
problem.
8
- You should enclose the final code between "‘‘‘" lines, as in the provided examples
.
9
- You should print the optimal value of the optimization problem using ’Optimal
value: ’, as in the provided examples.
10
Let’s think step by step and clearly describe our reasoning.
11
12
13
Here is the problem description:
14
-----
15
{description}
16
-----
17
18
The following components have been extracted from the problem description:
19
-----


--- Page 17 ---
20
{components}
21
-----
22
23
And the following mathematical formulation to represent the optimization problem has
been prepared:
24
-----
25
{formulation}
26
-----
27
28
Now, follow the steps outlined above. Explain your reasoning and remember to enclose
the generated code between "‘‘‘" lines.
CODE DEBUGGING PROMPT
1
Your task is to debug Python {solver} code used to solve the following optimization
problem:
2
-----
3
{description}
4
-----
5
This is the code snippet for which an error occured
6
-----
7
{code_w_error}
8
-----
9
and here is the error message:
10
-----
11
{error_message}
12
-----
13
14
First reason about the source of the error, and decide whether it is a modeling
issue, or a code bug. Then, generate a Python {solver} script accordingly to fix
any errors, and enclose it between "‘‘‘" lines.
INFEASIBILITY DEBUGGING PROMPT
1
Your task is to investigate {solver} code used to solve the following optimization
problem:
2
-----
3
{description}
4
-----
5
This is the code snippet initially used to solve the problem:
6
-----
7
{code_w_error}
8
-----
9
That optimization model, however, is infeasible. Your task now is to investigate the
source of that issue, and decide whether infeasibility is due to a code bug or
a modeling issue. Then, generate a Python {solver} script accordingly to fix any
errors or modeling issues, and enclose it between "‘‘‘" lines.
10
Now, here is a demonstration showing how to solve this task:
11
-----
12
{code_examples}
13
-----
14
Now, reason about the source of the error, generate a Python {solver} script
accordingly to fix any issues, and enclose it between "‘‘‘" lines.
E.2.
Synthetic Data Generation Prompt
It generates a description of an optimization problem based on symbolic representation of an optimization problem. The SDG
workflow consists of (i) sampling an application domain, (ii) prompting teacher model to create a new seed (with the underlying
objective of improving natural language diversity), (iii) prompting teacher model to define decision variables, (iv) prepare a new
problem description, and (v) define ranges for each parameter in the optimization problem.


--- Page 18 ---
A NATURAL LANGUAGE DESCRIPTION SEED PROMPT
1
You are an expert in mathematical optimization, and your task is to create a new
optimization problem. Upon receiving some sample problem descriptions, you
should create a new optimization problem within the {industry} domain and with {
no_variables} variables that follows a structure similar to the provided samples
.
2
3
Note that
4
- The new optimization problem should be enclosed between the "‘‘‘" lines.
5
- The problem you generate should be new, that is, do not repeat any of the provided
examples.
6
- Avoid using symbols in the problem description you generated, try to use natural
language instead. For example, instead of saying "A manufacturing company
produces two products, A and B", try to say something like "A manufacturing
company produces two products, soap bars and shampoo bottles".
7
- Make sure to use the {industry} domain in your new optimization problem.
8
9
Here’s a demonstration showing how to complete your task
10
{q_n_a_sample}
11
and here are some sample problem descriptions to base the new problem description on
12
{sample_problems}
VARIABLE DEFINITION PROMPT
1
You are an expert in mathematical optimization, and your task is to define a list of
decision variables for an optimization problem. Upon receiving a pre-defined
list of decision variables and a pre-initialized description of an optimization
problem, you should
2
3
1. Carefully analyze and comprehend the provided formulation.
4
2. Clearly define the decision variables present in the pre-initialized description.
Be specific.
5
3. Define the domain of those variables, that is, indicate whether those variables
are continous, binary or integer based on the context of the problem. Indicate
whether any decision variable should be non-negative or not.
6
7
Note that your final response should be between the ‘‘‘ lines, as shown in the
provided demonstration.
8
9
Here’s a demonstration showing how to complete your task
10
-----
11
{qna_examples}
12
-----
13
14
Now, here are the decision variables we need you to prepare a detailed list for:
15
-----
16
{formulation}
17
-----
18
and here is the pre-initialized description:
19
-----
20
{description}
21
-----
22
Now, follow the steps above, generate a list indicating the decision variables in
the optimization problem.
VARIABLE DEFINITION DEBUGGING PROMPT
1
You are a mathematical optimization expert. Your task is to review a list of
decision variables prepared for a new optimization problem. Upon receiving a
detailed mathematical formulation of an optimization problem and the variables


--- Page 19 ---
missing from the definition, you should:
2
3
1. Carefully analyze and comprehend the provided formulation.
4
2. Carefully review the previously prepared description of decision variables for
the provided formulation.
5
3. Carefully revise the previously prepared list describing the decision variables,
and refine it to include the missing variables.
6
7
Note that
8
- The list of variables should be enclosed between the "‘‘‘" lines.
9
10
Here’s a demonstration showing how to complete your task
11
-----
12
{qna_examples}
13
-----
14
15
Now, here is the formulation of the optimization problem we need you to prepare a
list of decision variables for:
16
-----
17
{formulation}
18
-----
19
here is the problem description:
20
-----
21
{description}
22
-----
23
and here is the list of missing variables:
24
-----
25
{missing_components}
26
-----
OBJECTIVE DEFINITION PROMPT
1
You are an expert in the {industry} domain working closely with a mathematical
optimization professor to prepare realistic descriptions of optimization
problems for a new textbook. Your task is to first think of a unique aspect of a
business case within the {industry} domain, then indicate a real metric with
which that goal can be measured (such as dollars, seconds, minutes, hours, miles
, pounds, cubic meters, ml, etc), and then create a realistic natural-language
description that reflects the objective of the new optimization problem
generated by the optimization expert.
2
3
Here’s a demonstration showing the expected format
4
-----
5
{q_n_a_sample}
6
-----
7
and here is the detailed formulation of the problem you should base the description
you generate on
8
-----
9
{formulation}
10
-----
11
12
Note that
13
- The objective description should be enclosed between the "‘‘‘" lines, and focus on
a clear, measurable aspect of a business case within the {industry} domain.
14
- All parameters present in the formulation should be written in the form \\
parameter in the corresponding natural language description, as in the provided
examples.
15
- Do not include symbols from the provided formulation into the description you
generate. That is, do not include symbols such as "x_1" in the description you
generate.
16
- Do not initialize the parameter values indicated in the problem description.


--- Page 20 ---
17
- Don’t be explicit about non-negative quantities or the type of decision variable,
that is, do not include statements such as "The number of libraries must be a
non-negative integer" in the description you generate.
18
- Carefully review the description you generated, and make sure it includes all the
decision variables and parameters present in the optimization objective.
19
- Do not add any new variables or parameters not listed in the provided formulation.
20
- Don’t simply write a literal description of the objective, try to create a
realistic description of a business case within your {industry} expertise.
21
- For any negative parameters, try to indicate the non-negativity by using terms
such as "penalty", "loss", "decreases", "reduces".
OBJECTIVE DEFINITION DEBUGGING PROMPT
1
You are an expert in the {industry} domain working closely with a mathematical
optimization professor to prepare realistic descriptions of optimization
problems for a new textbook. Your task is to revise the description of the
objective of a new optimization problem to include a list of missing parameters.
2
3
Here’s a demonstration showing the expected format
4
-----
5
{q_n_a_sample}
6
-----
7
here is the detailed formulation of the problem you should base the description you
generate on
8
-----
9
{formulation}
10
-----
11
here is the description we need you to revise:
12
-----
13
{previous_description}
14
-----
15
and, finally, here is the list of missing parameters
16
-----
17
{missing_params}
18
-----
19
20
Note that
21
- The revised description should be enclosed between the "‘‘‘" lines, and focus on a
clear, measurable aspect of a business case within the {industry} domain.
22
- All parameters present in the formulation should be written in the form \\
parameter in the corresponding natural language description, as in the provided
examples.
23
- Do not include symbols from the provided formulation into the description you
generate. That is, do not include symbols such as "x_1" in the description you
generate.
CONSTRAINT DEFINITION PROMPT
1
You are an expert in the {industry} domain working closely with a mathematical
optimization professor to prepare realistic descriptions of optimization
problems for a new textbook. Your task is to first think of a unique aspect of a
business case within the {industry} domain, then indicate a real, well-defined
metric with which that goal can be measured (such as dollars, seconds, minutes,
hours, miles, pounds, cubic meters, ml, etc), and then create a realistic
natural-language description that reflects one of the constraints of the new
optimization problem generated by the optimization expert.
2
3
Here’s a demonstration showing the expected format
4
-----
5
{q_n_a_sample}
6
-----


--- Page 21 ---
7
and here is the detailed formulation of the problem you should base the description
you generate on
8
-----
9
{formulation}
10
-----
11
The following topics have already been used, so try to focus on a new aspect:
12
-----
13
{previous_topics}
14
-----
15
16
Note that
17
- The constraint description should be enclosed between the "‘‘‘" lines, and focus
on a clear, measurable aspect of a business case within the {industry} domain.
18
- All parameters present in the formulation should be written in the form \\
parameter in the corresponding natural language description, as in the provided
examples.
19
- Do not include symbols from the provided formulation into the description you
generate. That is, do not include symbols such as "x_1" in the description you
generate.
20
- Do not initialize the parameter values indicated in the problem description.
21
- Don’t be explicit about non-negative quantities or the type of decision variable,
that is, do not include statements such as "The number of libraries must be a
non-negative integer" in the description you generate.
22
- Carefully review the description you generated, and make sure it includes all the
decision variables and parameters present in the constraint.
23
- Do not add any new variables or parameters not listed in the provided formulation.
24
- Don’t simply write a literal description of the constraint, try to create a
realistic description of a business case within your {industry} expertise.
25
- For any negative parameters, try to indicate the non-negativity by using terms
such as "penalty", "loss", "decreases", "reduces".
CONSTRAINT DEFINITION DEBUGGING PROMPT
1
You are an expert in the {industry} domain working closely with a mathematical
optimization professor to prepare realistic descriptions of optimization
problems for a new textbook. Your task is to revise the description of a
constraint of a new optimization problem to include a list of missing parameters
.
2
3
Here’s a demonstration showing the expected format
4
-----
5
{q_n_a_sample}
6
-----
7
here is the detailed formulation of the problem you should base the description you
generate on
8
-----
9
{formulation}
10
-----
11
here is the description we need you to revise:
12
-----
13
{previous_description}
14
-----
15
and, finally, here is the list of missing parameters
16
-----
17
{missing_params}
18
-----
19
20
Note that
21
- The revised description should be enclosed between the "‘‘‘" lines, and focus on a
clear, measurable aspect of a business case within the {industry} domain.
22
- All parameters present in the formulation should be written in the form \\
parameter in the corresponding natural language description, as in the provided


--- Page 22 ---
examples.
23
- Do not include symbols from the provided formulation into the description you
generate. That is, do not include symbols such as "x_1" in the description you
generate.
PARAMETER RANGE DEFINITION PROMPT
1
You are a mathematical optimization expert. Your task is to define a list of
plausible value ranges for parameters in an optimization problem. Upon receiving
a detailed mathematical formulation of an optimization problem, and its natural
language description, you should:
2
3
1. Carefully analyze and comprehend the provided formulation.
4
2. Carefully analyze and comprehend the problem description within the {industry}
domain.
5
3. Define suitable minimum and maximum values for all listed parameters within the {
industry} domain.
6
7
Note that
8
- The range of values should be enclosed between the "‘‘‘" lines.
9
- Make sure to use suitable values within the {industry} domain.
10
- Make sure to enclose the range of values between the "‘‘‘" lines.
11
12
Here is the formulation of the optimization problem
13
-----
14
{formulation}
15
-----
16
and here is the natural language description of the problem:
17
-----
18
{description}
19
-----
20
21
Now, follow the steps outlined above. The range of values should be enclosed between
the "‘‘‘" lines. Here are some examples:
22
-----
23
{qna_examples}
24
-----
25
26
Solve the problem step by step.
PARAMETER RANGE DEBUGGING PROMPT
1
You are a mathematical optimization expert. Your task is to review a list of
plausible value ranges for parameters in an optimization problem. Upon receiving
a detailed mathematical formulation of an optimization problem, its natural
language description, and a list of parameters for which minimum and maximum
values were not defined, you should:
2
3
1. Carefully analyze and comprehend the provided formulation.
4
2. Carefully analyze and comprehend the problem description within the {industry}
domain.
5
3. Carefully review the previously prepared range of plausible values for parameters
included in the provided formulation.
6
4. Carefully revise the previously prepared range of plausible values for all
parameters, and refine it to include the missing parameters.
7
5. Define suitable minimum and maximum values for all listed parameters within the {
industry} domain.
8
9
Note that
10
- The range of values should be enclosed between the "‘‘‘" lines.
11
- Make sure to use suitable values within the {industry} domain.


--- Page 23 ---
12
- Make sure to enclose the range of values between the "‘‘‘" lines.
13
14
Here is the formulation of the optimization problem
15
-----
16
{formulation}
17
-----
18
here is the natural language description of the problem
19
-----
20
{description}
21
-----
22
here is the definition of parameter ranges we need you to revise:
23
-----
24
{previous_description}
25
-----
26
and here is the list of missing parameters:
27
-----
28
{missing_components}
29
-----
30
31
Now, follow the steps outlined above. The range of values should be enclosed between
the "‘‘‘" lines. Here are some examples:
32
-----
33
{qna_examples}
34
-----
35
36
Solve the problem step by step.
NATURAL LANGUAGE DESCRIPTION PROMPT
1
You are an editor working closely with a mathematical optimization professor on a
new textbook, and your task is to create a natural-language description for a
new problem for the textbook. Upon receiving a detailed list of decision
variables, objectives, and constraints prepared by the optimization professor,
you should create a well-written description that harmoniously integrates all
the aspects of the problem previously prepared by the optimization expert.
2
3
Here’s a demonstration showing the expected format
4
-----
5
{q_n_a_sample}
6
-----
7
and here is the detailed list of decision variables, objective, and constraints you
should include in the new description
8
-----
9
{formulation}
10
-----
11
12
Note that
13
- The final description of the optimization problem should be enclosed between the
"‘‘‘" lines.
14
- All parameters present in the formulation should be written in the form \\
parameter in the corresponding natural language description, as in the provided
examples. But do not add parenthesis to the parameters, that is, do not use \(
\) in the description you generate.
15
- Do not initialize the parameter values indicated in the problem description.
16
- Don’t be explicit about non-negative quantities or the type of decision variable,
that is, do not include statements such as "The number of libraries must be a
non-negative integer" in the description you generate.
17
- Carefully review the description you generated, and make sure it includes all the
decision variables, constraints and objectives of the provided formulation.
18
- The description should not include any decision variables or parameters not listed
in the provided formulation.


--- Page 24 ---
SYMBOLIC DEBUGGING PROMPT
1
You are a mathematical optimization expert. Your task is to review a description
prepared for a new optimization problem. Upon receiving a detailed mathematical
formulation of an optimization problem and a list of parameters missing from the
description, you should:
2
3
1. Carefully analyze and comprehend the provided formulation.
4
2. Carefully review the previously prepared description for the provided formulation
.
5
3. Carefully revise the previously prepared description, and refine it to include
the missing parameters.
6
4. Make sure that all parameters are written in the form \\parameter, as in the
provided examples.
7
8
Note that
9
- The description of the optimization problem should be enclosed between the "‘‘‘"
lines.
10
- The description you generate should be new, that is, do not repeat any of the
provided examples.
11
- Avoid using symbols representing the decision variables in the problem description
you generate, use natural language instead. For example, instead of saying "A
manufacturing company produces two products, A and B", try to say something like
"A manufacturing company produces two products, soap bars and shampoo"
12
- Make sure to use the {industry} domain in the description of the optimization
problem.
13
- Make sure to use meaningful measures for parameters included in the description of
the optimization problem. That is, instead of using something like "at least
b_1_1 units", try saying "at least b_1_1 gallons".
14
- Do not include symbols from the provided formulation into the description you
generate. That is, do not include symbols such as "x_1" in the description you
generate.
15
- Do not include mathematical expressions in your description. Use natural language
instead. For example, do not include something like $x_3 - x_4 \ge 10$ in the
description you generate.
16
- Do not initialize the parameter values indicated in the problem description.
17
- Don’t be explicit about non-negative quantities, that is, do not include
statements such as "The number of libraries must be a non-negative integer" in
the description you generate.
18
- Don’t be explicit about the type of decision variables, that is, do not include
statements such as "The number of libraries must be an integer" in the
description you generate.
19
- Only generate the description of the optimization problem, and nothing else.
20
- Make sure to enclose the problem description between the "‘‘‘" lines.
21
22
Here is the formulation of the optimization problem
23
-----
24
{formulation}
25
-----
26
here is the description we need you to revise:
27
-----
28
{previous_description}
29
-----
30
and here is the list of missing components:
31
-----
32
{missing_components}
33
-----
34
35
Now, follow the steps outlined above. The problem description should be enclosed
between the "‘‘‘" lines. Here are some examples:
36
-----
37
{qna_examples}
38
-----


--- Page 25 ---
39
40
Solve the problem step by step. Be concise.
