--- Page 1 ---
ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization
Modeling
Zhuohan Wang‚àó1
Ziwei Zhu‚àó1
Ziniu Li1
Congliang Chen23
Yizhou Han1
Yufeng Lin1
Zhihang Lin1
Angyang Gu1
Xinglin Hu1
Ruoyu Sun14
Tian Ding‚Ä†24
1The Chinese University of Hong Kong, Shenzhen
2Shenzhen Research Institute of Big Data
3Shenzhen Loop Area Institute
4Shenzhen International Center for Industrial and Applied Mathematics
*: Equal contribution; ‚Ä†: Correspondence author.
November 3, 2025
Abstract
Formulating optimization problems for industrial applications demands significant manual effort and domain
expertise. While Large Language Models (LLMs) show promise in automating this process, evaluating their
performance remains difficult due to the absence of robust metrics. Existing solver-based approaches often face
inconsistency, infeasibility issues, and high computational costs. To address these issues, we propose ORGEval, a
graph-theoretic evaluation framework for assessing LLMs‚Äô capabilities in formulating linear and mixed-integer
linear programs. ORGEval represents optimization models as graphs, reducing equivalence detection to graph
isomorphism testing. We identify and prove a sufficient condition, when the tested graphs are symmetric
decomposable (SD), under which the Weisfeiler‚ÄìLehman (WL) test is guaranteed to correctly detect isomorphism.
Building on this, ORGEval integrates a tailored variant of the WL-test with an SD detection algorithm to evaluate
model equivalence. By focusing on structural equivalence rather than instance-level configurations, ORGEval
is robust to numerical variations. Experimental results show that our method can successfully detect model
equivalence and produce 100% consistent results across random parameter configurations, while significantly
outperforming solver-based methods in runtime, especially on difficult problems. Leveraging ORGEval, we
construct the Bench4Opt dataset and benchmark state-of-the-art LLMs on optimization modeling. Our results
reveal that although optimization modeling remains challenging for all LLMs, DeepSeek-V3 and Claude-Opus-4
achieve the highest accuracies under direct prompting, outperforming even leading reasoning models.
1
Introduction
Operations Research (OR) leverages mathematical modeling and optimization techniques to support decision
making in complex systems (Hillier & Lieberman, 2015). It plays a vital role across industries such as logistics,
manufacturing, finance, and healthcare (Winston, 2004), where real-world scenarios are formalized into mathemati-
cal optimization models. However, this formulation process is highly challenging, demanding interdisciplinary
expertise. Recently, there has been growing interest in using Large Language Models (LLMs) to automate the
formulation of optimization models from user inputs, write proper programs, and solve complex problems with
minimal human intervention (Jiang et al., 2024; Huang et al., 2025; Lu et al., 2025).
Evaluating modeling correctness is challenging because fundamentally equivalent optimization models can be
represented by different variable names and structures. To handle this non-uniqueness, prior work has primarily
adopted solver-based evaluation, which solves the generated model to obtain its objective value and then compares
it against the ground-truth optimal objective (Tang et al., 2024). The assumption is that correct models should
produce matching objective values. However, we noticed that solver-based evaluation suffers from a few major
limitations: 1) models may coincidentally have the same optimal value under one parameter configuration but
produce distinct values under another, 2) the solver fails to evaluate model equivalence when input parameters
result in an infeasible problem, and 3) solvers may encounter high computation costs for a single round evaluation.
Moreover, current evaluation settings focus on problems that embed both the description and the numerical data
within a single prompt (Ramamonjison et al., 2022a; Xiao et al., 2023), which often constrains the problem size
1
arXiv:2510.27610v1  [cs.LG]  31 Oct 2025


--- Page 2 ---
ÔÉº
Problem Description
Parameter
Maximize
    x[0] + 2 x[1]
Subject To
    3 x[0] + 4 x[1] <= 5
Bounds
Binaries
    x[0] x[1]
End
Ground Truth Instance
Bench4Opt
LLM
Step 1. Input problem 
description into LLM 
to get test model 
represented in Gurobi 
Code.
Passing
Step 2. Passing 
parameter into code 
to generate Test 
instance.
Test 
Model
Maximize
    x[0] + 2 x[1]
Subject To
    3 x[0] + 4 x[1] <= 5
Bounds
Binaries
    x[0] x[1]
End
Test Instance
Step 3. Represent instances 
as bipartite graphs.
(5, ‚â§)
(‚àí1, ¬†integer)
(‚àí2, integer)
œÖ
œ≥[1]
œ≥[0]
(5, ‚â§)
(‚àí1, ¬†integer)
(‚àí2, integer)
œÖ
œ≥[1]
œ≥[0]
Step 4. Check if the 
instance satisfies 
sufficient condition (SD) 
with a theoretical 
guarantee for WL-test to 
determine isomorphism.
SD check
ÔÅè
Compile
WL-Test
ÔÅè
ÔÅè
compile 
error
Not SD
Color 
distribution 
not match
In Bench4Opt, all ground truth 
instances are symmetric 
decomposable (SD). 
constraint nodes
decision variable nodes
Step 5. Conduct 
isomorphism testing based 
on WL-test coloring.
3
4
3
4
Figure 1: Evaluation Pipeline: Each example in our dataset includes a problem description, a parameter file, and a
model instance with parameters applied. To assess an AI system‚Äôs modeling capability, we evaluate the equivalence
between the AI-generated instance and the ground truth instance in our dataset, using a common set of parameters.
These instance pairs can be represented by two bipartite graphs, on which we applied an isomorphism testing
algorithm, and meanwhile, checked the sufficiency of the algorithm.
to relatively small instances. This approach can not reflect many real-world scenarios, where data is typically
large-scale and is separated from the modeling process (ApIO et al., 2017).
In this paper, we address these limitations by introducing ORGEval, a novel evaluation method for assessing
modeling equivalence and correctness for linear and mixed-integer linear programs‚Äîthe dominant classes in
practical OR applications. Specifically, we formulate optimization models as graphs, then reduce the equivalence
detection task to a graph isomorphism problem. We identify sufficient conditions, symmetric decomposable graphs,
under which the Weisfeiler-Lehman (WL) test is guaranteed to detect isomorphism. Additionally, we develop a
selection algorithm that identifies problems satisfying these conditions and combined this selection algorithm to
develop an enhanced WL test that checks isomorphism.
Our main contributions can be summarized as follows:
1. We formalize model equivalence under the model‚Äìdata separation setting (Section 2).
2. We reduce model equivalence detection into graph isomorphism testing (Section 3.1).
3. We identify and prove a sufficient condition that enhances existing graph isomorphism testing algorithms
(Section 3.2 and Section 3.3).
4. We propose ORGEval, a graph-theoretic evaluation method for assessing optimization models (Section 3.4).
5. We introduce Bench4Opt, the first model‚Äìdata separated dataset for optimization modeling. Using Bench4Opt,
we empirically demonstrate the efficiency and consistency of ORGEval, and further benchmark the perfor-
mance of leading LLMs (Section 4).
2
Problem Formulation
In this section, we establish the background for the OR modeling task and define the capabilities we aim to measure
and evaluate. First, we note that real-world OR modeling typically unfolds through three distinct stages:
‚Ä¢ Pre-modeling stage: Stakeholders articulate problems in natural language (e.g., "I want to maximize revenue
through car production") and collect all relevant numerical parameters.
‚Ä¢ Modeling stage: Analysts transform these natural language descriptions into mathematical models by defining
decision variables, formulating objective functions, and establishing constraints. This results in mathematical
formulations or solver-ready code with separately stored parameters.
‚Ä¢ Post-modeling stage: The model is instantiated with problem-specific data to generate a fully specified problem
ready for computational solving.
2


--- Page 3 ---
LLM
LLM
Check model reducible 
equivalence.
Step 1: Draw random test 
parameters from the 
parameter support of the 
ground-truth model.
Solve two instances and 
check equivalence between 
their optimal values.
Step 3: Check instance 
isomorphism.
Ground truth model 
Ideal Evaluation 
Test model 
Previous Evaluation 
Ground truth instance 
Test  instance 
Our Evaluation 
Test model 
Ground truth model 
Step 2: 
Parameterize the 
model to form a 
test instance.
Ground truth instance 
Test  instance 
LLM
Figure 2: Evaluation Framework: The ultimate goal of modeling equivalence is to directly assess whether one
model can be equivalently transformed to a standard model (top left). Existing work tests the equivalence between
numerical instances by comparing their optimal objective (top right). Our evaluation method approximates the
ultimate goal of directly evaluating modeling equivalence by randomly sampling instances and testing instance
isomorphism (bottom).
We explicitly distinguish between the modeling stage and the post-modeling stage. In many real-world applications,
models are designed for reusability: the structural components (decision variables, objectives, and constraints) are
specified once, while the problem-specific parameters are supplied separately for each instance. This separation is
standard practice in modern modeling languages such as AMPL (Fourer et al., 2003) or Pyomo (Hart et al., 2011),
where the model (.mod) and the data (.dat) are maintained as distinct artifacts. We thus view ‚Äúinstantiation with
problem-specific data‚Äù as a necessary step that bridges abstract modeling and computational solving.
Our primary goal is to leverage LLMs to automate the first two stages, enabling users to input problem
descriptions and receive both mathematical formalizations and solver-ready code as outputs. We formally reframed
the evaluation of modeling equivalence in the following subsections and illustrated ideal evaluation, previous
evaluation, and our new evaluation framework in Figure 2.
2.1
Definition of Modeling "Accuracy"
Our work proposes a formal evaluation framework for model-level "accuracy", which requires the definition of
model equivalence. To support the definition of this kind of equivalence, we introduce the notions of modeling
problem instance and modeling parameter support.
2.1.1
Definitions for Modeling Problems
Definition 1 (Modeling Problem Instance). A MILP/LP problem instance, denoted by P, has the following standard
formulation (Luenberger et al., 1984):
min
x‚ààRp√óZn‚àíp
c‚ä∫x,
(1)
such that
Ax ‚ó¶b,
where A ‚ààRm√ón, c ‚ààRn, b ‚ààRm, and ‚ó¶‚àà{=, <, >, ‚â§, ‚â•}m for i = 1, ¬∑ ¬∑ ¬∑ , n. Note that in this formulation,
there are p real optimization variables and n ‚àíp integer optimization variables, and m constraints.
To facilitate later usage, we use a vector œÑ to represent the decision variable type, where œÑi = 1 indicates xi is
an integer and œÑi = 0 indicates a continuous variable.
Definition 2 (MILP/LP Model). A MILP/LP model is a mapping M : Œò ‚ÜíP, where Œò denotes a space of
model parameters. Each Œ∏ ‚ààŒò is a tuple Œ∏ = (A, c, œÑ, b, ‚ó¶), where A, c, b, ‚ó¶are the same as in Definition 1, and
œÑ ‚àà{0, 1}n is a binary vector indicating whether each variable is continuous (0) or integer (1).
3


--- Page 4 ---
We refer to Œò as the modeling parameter support of M. Given any Œ∏ ‚ààŒò, the mapping M(Œ∏) returns a
concrete MILP or LP instance P of the form Eq. (1). An example of a blending optimization model Mblend and its
parameter support Œò(Mblend) can be found in Example 4 in the appendix. Figure Section D.2 illustrates how to
generate model instances for Mblend.
2.1.2
Definitions for Modeling Equivalence
In practical optimization workflows, "modeling equivalence" should reflect whether one predicted model can be
systematically transformed to a target model.
Definition 3 (Model-lossless-reduction). For two models M1 and M2, they are said to be model-lossless-reducible
if the following conditions hold:
1. Shared parameter support: M1 and M2 share the same parameter support Œò;
2. Existence of solution-preserving transformation: There exists a mapping F over decision variables such that,
for any parameter Œ∏ ‚ààŒò:
‚Ä¢ If M1(Œ∏) is feasible and bounded, then M2(Œ∏) is also feasible and bounded, and for any optimal
solution x‚àóof M1(Œ∏), F(x‚àó) is an optimal solution of M2(Œ∏);
‚Ä¢ If M1(Œ∏) is infeasible or unbounded, then M2(Œ∏) is also infeasible or unbounded.
This model-lossless-reduction captures the essence of equivalence between models: if one model can fully
simulate the feasible behaviors and optimal outcomes of another, we treat them as equivalent for all practical
purposes.
However, such a form of equivalence is difficult to check and has not been reliably captured by existing
works. First, it is hard to verify the equivalence between parameter support. Second, verifying solution mappings
F between models can be computationally expensive and sometimes impractical, as it may require comparing
optimality across a large space of instances rather than a single solution.
As verifying model-lossless-reducibility is often intractable in practice, current approaches typically rely on
a much weaker proxy, comparing solver outputs on specific model instances. In the following section, we will
formally introduce solver-based modeling accuracy evaluation and discuss its limitations.
2.2
Solver-based Modeling "Accuracy"
Previous work (Tang et al., 2024) explored evaluating modeling "accuracy" through execution accuracy, which we
formalize below:
Definition 4 (Execution Accuracy). For a data configuration Œ∏, a mathematical model M with a program code C is
said to be correct if, upon execution of C, we obtain z(C, Œ∏) = z‚ãÜ, where z‚ãÜis the optimal value of the mathematical
model if it exists.
We point out several limitations of this definition.
‚Ä¢ (Limitation 1) No rigorous correctness guarantee when the solver returns values: Cases exist where final
answers appear correct despite fundamentally flawed underlying optimization models; see example 1 and example
2 in Appendix D.
‚Ä¢ (Limitation 2) Uninformative in cases of infeasible problems Mathematical models could be infeasible under
certain data configurations, in which cases the solver would return no feasible solution. Solver-based evaluation
becomes uninformative in this scenario; see 3 in Appendix D.
‚Ä¢ (Limitation 3) Prohibitively high computational costs: Solvers may require hundreds and thousands of CPUs
and run for several hours and days, especially for large-scale problems such as Mixed Integer Linear Programming
(MILP) tasks. This makes the evaluation time-consuming and computationally expensive. This would further
make it impractical to apply advanced post-training techniques like those proposed by (OpenAI, 2024; Guo et al.,
2025) that could otherwise enhance LLM performance.
Fundamentally, the limitations illustrated above reveal a critical limitation in the execution accuracy definition:
it is restricted to a single data configuration and relies solely on optimal value comparison. This approach is
clearly inadequate for reliable model evaluation. A mathematical model should be correct across all possible data
configurations, not just one specific test case. Only when a model demonstrates consistent performance across
diverse scenarios can we trust the decision information it provides for practical applications. Therefore, an ideal
evaluation metric for model equivalence is expected to be reliable, informative, and consistent over various data
configurations.
4


--- Page 5 ---
2.3
Model Isomorphism
As an alternative, we further define model isomorphism to capture structural equivalence between models, rather
than relying on numerical optimal values.
Definition 5 (Model Isomorphism). We say two optimization models M1 and M2 are model isomorphic if the
following conditions hold:
‚Ä¢ Shared parameter support: M1 and M2 share the same parameter support Œò;
‚Ä¢ Existence of permutation-invariant transformation: There exists a permutation mapping F1 over decision
variables and F2 over constraints such that, for any Œ∏ ‚ààŒò, the transformed instance F1 ‚ó¶F2(M1(Œ∏)) is
exactly M2(Œ∏).
In this work, we refer to this as isomorphism equivalence, or simply equivalence. Note that model isomorphism
is sufficient for mutual reducibility: if M1 and M2 are isomorphic, then M1 and M2 are mutually model-lossless-
reducible.
Optimization Model Equivalence
Previous work typically assesses instance-level equivalence by comparing the
optimal values of P1 = M1(Œ∏) and P2 = M2(Œ∏) for specific Œ∏, where both the model and data are coupled in the
input prompt. Different from previous work, we aim to detect model-level equivalence and consider a model-data
separated framework for evaluating autonomous modeling systems. To make model-level equivalence evaluation
tractable, we reduce model "equivalence" to model isomorphism, a stricter form of equivalence that focuses on the
inherent structure of models rather than their optimal solutions. Importantly, we observe that if two instances are
isomorphic, their isomorphism remains unchanged under different data configurations. This property allows us to
efficiently evaluate equivalence at the model level without repeatedly solving individual model instances.
Specifically, we evaluate equivalence between M1 and M2 by randomly sampling parameters Œ∏ from Œò(M)
and testing the isomporphism of modeling instances M1(Œ∏) and M2(Œ∏). This serves as an empirical approximation
of model-level correctness.
3
Methodology
In this section, we introduce our evaluation method ORGEval, and the theoretical guarantee of ORGEval. ORGEval
is developed to evaluate modeling equivalence by detecting whether the inherent structure of two random instances
from two models is equivalent, thus making the evaluation stable when altering instance parameters.
3.1
Evaluation Principle
We first introduce our notion of equivalence between two model instances. Specifically, our notion allows model
instances to change the notations of variables and rearrange their variables/constraints in different orders without
losing essential information. The formal definition is as follows:
Definition 6 (Instance-Level Isomorphism). We say model instances P2 and P1 are isomorphic, if ‚àÉpermutation
matrices P1, P2 which shuffle the index of a vector or column index of a matrix such that P2 can be written in the
following form:
min
x‚ààRn‚àíp√óZpÀÜcT x,
s.t. ÀÜAx ÀÜ‚ó¶ÀÜb,
where ÀÜb = P2b, ÀÜc = P1c, ÀÜA = P2AP1, ÀÜ‚ó¶= P2‚ó¶.
We denote that two instances P1 and P2 are equivalent or instance-level-isomorphic by P1 ‚àºP2. Note that we
require the model formulation to strictly adhere to the textual description of the problem and account for differences
in formulation strength. For example, adding slack variables to the standard instance may not change the optimal
solution, but it alters the direct physical meaning specified in the textual description. Therefore, we consider it a
different formulation. Consequently, our definition of model equivalence only allows altering the variable notations
and permutating variables/constraints, which is in general stricter than that conventionally adopted in OR.
Our concept of model equivalence aligns with the isomorphism of graphs, allowing nodes to be re-indexed or
rearranged without changing the graph structure. This motivates us to incorporate tools in graph theory to evaluate
model equivalence. Following existing work in learning to optimize (Gasse et al., 2019; Chen et al., 2022b), we
represent an LP/MILP model instance by a bipartite graph (see Figure 3 for an illustrative example). We proved
that detecting the model equivalence can be reduced to testing graph isomorphism; See Appendix C.3 for a formal
demonstration.
5


--- Page 6 ---
ùëéùëö1ùë•1 + ‚ãØ+ ùëéùëöùëõùë•ùëõ‚â§ùëèùëö
ùëé11ùë•1 + ‚ãØ+ ùëé1ùëõùë•ùëõ‚â§ùëè1
min
ùë• ùëê1ùë•1 + ‚ãØ+ ùëêùëõùë•ùëõ
‚ãÆ
ùë•1
ùë•ùëõ
‚ãØ
ùõø1
ùõøùëö
‚ãØ
ùëê1
ùëêùëõ
ùëè1
ùëèùëö
ùëé11
ùëéùëö1
ùëéùëöùëõ
ùëé1ùëõ
Variable
nodes
Constraint
nodes
Figure 3: Transform model instance to a bipartite graph.
3.2
Model equivalence based on graph isomorphism
We evaluate the modeling result in two steps:
Create test and standard graphs
We can use (weighted) bipartite graphs to equivalently represent the modeling
problem instance. We follow the formal notation from Chen et al. (2022b) to represent (MI)LP instances to bipartite
graphs as follows:
Definition 7 (Weighted Bipartite Graph Instance Representation). A MILP/LP instance can be represented as
a weighted bipartite graph G = (V ‚à™W, E), where V = {v1, . . . , vm} corresponds to constraints and
W = {w1, . . . , wn} corresponds to variables. Each edge (vi, wj) ‚ààE is weighted by the coefficient Aij, and
each vertex is associated with features (e.g., right-hand side bi, operator type ‚ó¶i for constraints; objective coefficient
cj, integrality type œÑj for variables).
Since its dependence on Œ∏ = (A, c, œÑ, b, ‚ó¶), we may write G(Œ∏); see figure Figure 3 for an example to transform
a modeling problem instance to a bipartite graph instance.
As introduced in Definition 7 and Figure 3, we represent MILP/LP instances as bipartite graphs. In such
graphs, nodes can be divided into two groups: variable nodes and constraint nodes. All nodes are equipped
with the necessary features. Each constraint node connects with all associated variable nodes. Given such graph
representations, we can use graph isomorphism testing tools to detect equivalence between models.
Isomorphism testing
Graph isomorphism testing is a challenging problem, with no known polynomial-time
algorithm to date (Garey & Johnson, 1979; Babai, 2016). The Weisfeiler-Lehman test (Leman & Weisfeiler, 1968)
is an effective and computationally efficient approximation for graph isomorphism testing. Typically, one may
determine that two graphs are non-isomorphic if the WL-test algorithm produces different outputs (in the form of
so-called ‚Äúcoloring distributions‚Äù). However, if the WL-test yields the same outputs for the two graphs, they are not
guaranteed to be isomorphic (Cai et al., 1992); See Appendix D for counterexamples.
In contrast to the widely used WL-test, which offers no theoretical guarantee of producing correct results within
polynomial time, our enhanced algorithm first verifies the satisfaction of a sufficient condition. This additional step
establishes a formal guarantee of correctness for the subsequent equivalence evaluation.
3.3
Sufficient condition for graph isomorphism testing
We propose a sufficient condition, say symmetric decomposable, that modeling instances should satisfy to be
testable by a polynomial-time isomorphism testing algorithm.
Definition 3.1 (Symmetric Decomposable Instance). We say a modeling instance P is symmetric decomposable
if, after WL-test, the coloring on its representation graph G satisfies the following conditions: Excluding nodes that
are uniquely colored, the remaining nodes can be divided into k disjoint groups (with some k ‚â•0) of the same size,
denoted by S1, S2, ¬∑ ¬∑ ¬∑ , Sk, where
1. All nodes in the same group have distinct colors,
2. All groups share the same coloring sets, and
3. Every two groups are disconnected, i.e. ‚àÄnodes a ‚ààSi, b ‚ààSj, i Ã∏= j, a is disconnected with b.
In previous work, Chen et al. (2022b) characterized one class of graph conditions, termed unfoldable graphs,
whose isomorphism can be accurately distinguished by WL-Test. Yet the underlying graphs of many MILP
problems do not fall into this category. For example, graphs for bin-packing instances are typically not unfoldable;
see example D.3. The symmetric decomposable condition broadens the scope of problems for which WL-based
isomorphism detection is guaranteed.
6


--- Page 7 ---
While the unfoldable property requires all nodes to have distinct colors, the symmetric decomposable property
is more relaxed. It allows the graph to be partitioned into several subgraphs such that within each subgraph, every
node has a distinct color. Note that when k = 1, a symmetric decomposable problem is reduced to being unfoldable.
One example of a decomposable instance can be found in Figure 10.
In the following theorem, we show that if the standard instance is symmetric decomposable, then Algorithm 1
is reliable for detecting whether a test instance is model-equivalent to the standard instance. Rigorous proof can be
found in Appendix C.6.
Theorem 3.1. Suppose P1,P2 are symmetric decomposable, then G1 and G2 shares the same coloring distribution
after WL-test coloring ‚áê‚áíP1 ‚àºP2.
To leverage theorem 3.1 in practice, we designed an algorithm to identify symmetric decomposable instances
(Algorithm 3). Moreover, we prove that under mild assumptions, a random sample yields a symmetric decomposable
instance with high probability (Theorem C.5, C.6). Leveraging this property, we construct a benchmark dataset in
which all ground-truth instances are guaranteed to be symmetric decomposable.
3.4
ORGEval: Model-Equivalence Evaluation based on Graph
Combined with the symmetric decomposable detection algorithm (Algorithm 3), we develop ORGEval, a variant
form of WL-test to test model equivalence. ORGEval can accurately detect whether a test instance is equivalent
to a symmetric decomposable ground truth. It involves 1) running a WL-test for the LP/MILP test and standard
instances1; 2) checking whether the test instance is symmetric decomposable based on its coloring distributions
(done by Algorithm 3). If not, since all ground truth instances are selected to be symmetric decomposable, the test
instance must be different from a ground truth one, so the algorithm returns "not equivalent". If yes, go to step 3. 3)
checking whether the two coloring distributions are identical. If yes, then return "equivalent"; if not, then return
"not equivalent".
Efficiency of ORGEval
The time complexity to distinguish tested problem instances from the standard instances
with m variables and n nodes is at most O(k(m + n)2), where k is the number of clusters in a symmetric
decomposable graph. This is far better than the complexity for exhaustive isomorphism testing; detailed complexity
analysis can be found in Appendix C.8.
Algorithm 1 Modeling Equivalence Detection
Require: Two graph instances (Gk, Hk) ‚ààGk
m,n √ó HV
m √ó HW
n and adjacency matrix Ak, k = 1, 2; iterate limit L > 0.
1: Color nodes in two graphs using WL-test Algorithm for MILP/LP.
2: Get two coloring multi-sets Ck =
n
{{Ck,V
i
}}m
i=0, {{Ck,W
j
}}n
j=0}
o
, k = 1, 2 for coloring G1 and G2.
3: Derive set of unique elements in Ck, denote as set Ak, ‚àÄk = 1, 2.
4: if C1 Ã∏= C2 then
5:
return Not equivalent
6: else if G2 are symmetric decomposable then
7:
return Equivalent
8: else
9:
return Not Equivalent
4
Experiment and Analysis
We present comprehensive experiments on ORGEval using Bench4Opt, the first dataset for optimization modeling
that separates models from data. Bench4Opt comprises 209 LP and MILP instances curated from both hand-crafted
problems and the MIPLIB dataset (Gleixner et al., 2021). We empirically demonstrate the efficiency and consistency
of ORGEval in Section 4.2, and further employ it to benchmark the performance of LLMs in optimization modeling
in Section 4.3.
4.1
Benchmark dataset
To robustly assess ORGEval, we introduce Bench4Opt, a diverse benchmark dataset consisting of 394 optimization
modeling word problems in a model-data separated format, each with two levels of abstract, structured, and
unstructured description. Specifically, each Bench4Opt problem instance comprises three components: 1) problem
description, 2) parameter file, and 3) reference model in .lp format.
1We use the same implementation as Chen et al. (2022b), presented as Algorithm 2.
7


--- Page 8 ---
An illustrative example from Bench4Opt can be found in Figure 5. Besides careful verification and quality
control, we applied our sufficient condition detection algorithm Algorithm 3 to evaluate the problem instances in
our benchmark dataset. While we did not intentionally select problem instances based on specific criteria, we found
that all problems in Bench4Opt satisfy our sufficient conditions.
4.2
Advantages of ORGEval
Evaluation Efficiency
Empirically, we demonstrate that ORGEval offers significantly higher evaluation efficiency
compared with solver-based methods, especially for problem instances that are challenging for solvers. To test this,
we sampled 75 problem instances from the MIPLIB (Gleixner et al., 2021) dataset across three difficulty levels:
easy, hard, and open for existing solvers, with 25 instances per level. According to MIPLIB‚Äôs definition, easy
instances can be solved within an hour using a standard solver on a typical desktop machine with up to 16 threads;
hard instances require a longer time, non-standard hardware, or advanced algorithms; and open instances have
not yet been solved. Solver often requires hours or more to evaluate selected instances from MIPLIB. In contrast,
ORGEval consistently produced evaluation results within a reasonable timeframe‚Äî ORGEval runs 30 seconds on
average to output an evaluation result, even for the most challenging open problems for solvers. See Table 1 for the
average evaluation time of ORGEval across the three difficulty levels.
Table 1: Evaluation time of ORGEval for three levels of difficulties: easy, hard, open. Instances are sampled from
MIPLIB, with 25 instances per level.
Level of Difficulty
Average Problem Size
(#variables + # constraints)
Average Evaluation Time
(Solver)
Average Evaluation Time
(ORGEval)
Easy
1848
about 1 hour
0.21s
Hard
10463
> 1 hour
3.83s
Open
17050
not yet being solved
32.07s
Evaluation Consistency
We use the evaluation result of five random instances to indicate equivalence between
two models. For such an evaluation to be valid, we address the consistency of our evaluation result across various
data configurations: Our experimental results show that ORGEval achieves 100% consistency across five random
data configurations for all models in Bench4Opt. In contrast, solvers fail to evaluate models with random data
configurations for more than 60% of the models due to infeasibility, and even among the remaining models, 5.89%
of model pairs yield inconsistent results under solver-based equivalence evaluation.
Table 2: Comparison of model consistency across 5 random instances under different evaluation schemes.
Model
Feasibility consistency
ORGEval consistency
Solver consistency
gpt-4o
36.30%
100.00%
95.58%
claude-opus-4
36.05%
100.00%
92.12%
deepseek-v3
34.69%
100.00%
93.95%
o1
35.43%
100.00%
94.77%
Average
35.62%
100.00%
94.11%
4.3
Benchmark the modeling ability using ORGEval and Bench4Opt
To assess the capabilities of LLMs in optimization modeling, we conducted a comprehensive evaluation using
the Bench4Opt benchmark. Our evaluation focused on top-performing LLMs via direct prompting. The main
evaluation result is listed in Table 3.
8


--- Page 9 ---
Table 3: Evaluation Results on Bench4Opt. SOTA in each category is marked in red.
Overall
Modeling Accuracy
LLMs
Accuracy
Compile Error
Structured
Unstructured
deepseek-v3
54.82
2.28
63.45
46.19
claude-opus-4
54.82
2.28
60.41
49.24
gpt-4.1
52.28
1.78
57.36
47.21
gpt-4o
51.02
7.36
58.38
43.65
claude-opus-4.1
50.76
0.76
59.39
42.13
o3
47.97
0.76
55.84
40.10
deepseek-r1
47.72
2.28
55.84
39.59
o1
47.21
1.78
52.79
41.62
Our benchmark revealed varying performances among the tested models. In particular, claude-opus-4 (An-
thropic, 2025) and deepseek-v3 (Liu et al., 2024a) achieved the strongest results, each reaching an overall accuracy
of 54.82%, outperforming other contenders across structured and unstructured optimization tasks. In contrast,
reasoning models such as deepseek-r1 (Liu et al., 2024a), o1 (OpenAI, 2024), and o3 (OpenAI, 2025) consistently
exhibited lower accuracy compared to the base model. While reasoning models produce outputs with relatively
fewer compile errors, their multi-step reasoning capabilities appear susceptible to hallucination propagation. The
cascading effect of these reasoning artifacts likely contributes to progressive accuracy degradation throughout
complex problem-solving sequences. This phenomenon may explain the observed performance gap despite their
enhanced error-handling capabilities.
5
Conclusion
In this work, we formalize the task of detecting equivalence between (MI)LP models and introduced a new
modeling equivalence evaluation method, ORGEval, to evaluate the equivalence between optimization models. By
representing optimization models as graphs and leveraging the Weisfeiler-Lehman (WL) test under well-defined
sufficient conditions, our method offers a principled and efficient alternative to solver-based evaluations. Our
experiments demonstrate that ORGEval achieves consistent evaluation results across all data configurations and
offers significant speed advantages over solver-based methods, particularly on hard-to-solve problems. To access
ORGEval , we also introduce Bench4Opt, a diverse benchmark dataset of 394 model-data-separated optimization
problems containing problem from MIPLIB dataset and hand crafted problem generated with the help of LLM.
References
Ali AhmadiTeshnizi, Wenzhi Gao, and Madeleine Udell. Optimus: Scalable optimization modeling with (mi) lp
solvers and large language models. arXiv preprint arXiv:2402.10172, 2024.
Marie Anastacio and Holger H Hoos. Combining sequential model-based algorithm consingh2012overviewuration
with default-guided probabilistic sampling. In Proceedings of the 2020 Genetic and Evolutionary Computation
Conference Companion, pp. 301‚Äì302, 2020.
Carlos Ans√≥tegui, Meinolf Sellmann, and Kevin Tierney. A gender-based genetic algorithm for the automatic cons-
ingh2012overviewuration of algorithms. In International Conference on Principles and Practice of Constraint
Programming, pp. 142‚Äì157. Springer, 2009.
Anthropic. claude-4. https://www.anthropic.com/news/claude-4, 2025.
Team ApIO, Santiago Ram√≠rez Palacio, Mariana Escall√≥n Barrios, and Daniel L√≥pez Cornejo. 9th aimms-mopta
optimization modeling competition (2017) production and delivery of radio-pharmaceuticals to medical imaging
centers. https://coral.ise.lehigh.edu/~mopta2017/competition, 2017.
L√°szl√≥ Babai. Graph isomorphism in quasipolynomial time. In Proceedings of the forty-eighth annual ACM
symposium on Theory of Computing, pp. 684‚Äì697, 2016.
David Bergman, Teng Huang, Philip Brooks, Andrea Lodi, and Arvind U Raghunathan. Janos: an integrated
predictive and prescriptive modeling framework. INFORMS Journal on Computing, 34(2):807‚Äì816, 2022.
9


--- Page 10 ---
Daniel G Bobrow. A question-answering system for high school algebra word problems. In Proceedings of the
October 27-29, 1964, fall joint computer conference, part I, pp. 591‚Äì614, 1964.
Jin-Yi Cai, Martin F√ºrer, and Neil Immerman. An optimal lower bound on the number of variables for graph
identification. Combinatorica, 12(4):389‚Äì410, 1992.
Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. Program of thoughts prompting: Disentangling
computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588, 2022a.
Ziang Chen, Jialin Liu, Xinshang Wang, Jianfeng Lu, and Wotao Yin. On representing linear programs by graph
neural networks. arXiv preprint arXiv:2209.12288, 2022b.
Cheng Chi, Amine Aboussalah, Elias Khalil, Juyoung Wang, and Zoha Sherkat-Masoumi. A deep reinforcement
learning framework for column generation. Advances in Neural Information Processing Systems, 35:9633‚Äì9644,
2022.
Denise Dellarosa. A computer simulation of children‚Äôs arithmetic word-problem solving. Behavior Research
Methods, Instruments, & Computers, 18(2):147‚Äì154, 1986.
Adam N Elmachtoub and Paul Grigas. Smart ‚Äúpredict, then optimize‚Äù. Management Science, 68(1):9‚Äì26, 2022.
Robert Fourer, David M. Gay, and Brian W. Kernighan. Specifying data. In AMPL: A Modeling Language
for Mathematical Programming. Thomson/Brooks/Cole, 2nd edition, 2003. URL https://ampl.com/
wp-content/uploads/Chapter-9-Specifying-Data-AMPL-Book.pdf. Chapter 9.
Michael R Garey and David S Johnson. Computers and intractability, volume 174. freeman San Francisco, 1979.
Maxime Gasse, Didier Ch√©telat, Nicola Ferroni, Laurent Charlin, and Andrea Lodi. Exact combinatorial opti-
mization with graph convolutional neural networks. Advances in neural information processing systems, 32,
2019.
Ambros Gleixner, Gregor Hendel, Gerald Gamrath, Tobias Achterberg, Michael Bastubbe, Timo Berthold,
Philipp M. Christophel, Kati Jarck, Thorsten Koch, Jeff Linderoth, Marco L√ºbbecke, Hans D. Mittelmann,
Derya Ozyurt, Ted K. Ralphs, Domenico Salvagnin, and Yuji Shinano. MIPLIB 2017: Data-Driven Com-
pilation of the 6th Mixed-Integer Programming Library. Mathematical Programming Computation, 2021.
doi:10.1007/s12532-020-00194-3. URL https://doi.org/10.1007/s12532-020-00194-3.
Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi
Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv
preprint arXiv:2501.12948, 2025.
William E Hart, Jean-Paul Watson, and David L Woodruff. Pyomo: modeling and solving mathematical programs
in python. Mathematical Programming Computation, 3(3):219‚Äì260, 2011.
Frederick S Hillier and Gerald J Lieberman. Introduction to operations research. McGraw-Hill, 2015.
Chenyu Huang, Zhengyang Tang, Shixi Hu, Ruoqing Jiang, Xin Zheng, Dongdong Ge, Benyou Wang, and
Zizhuo Wang. Orlm: A customizable framework in training large models for automated optimization modeling.
Operations Research, 2025.
Xuhan Huang, Qingning Shen, Yan Hu, Anningzhe Gao, and Benyou Wang. Mamo: a mathematical modeling
benchmark with solvers. arXiv preprint arXiv:2405.13144, 2024.
Caigao Jiang, Xiang Shu, Hong Qian, Xingyu Lu, Jun Zhou, Aimin Zhou, and Yang Yu. Llmopt: Learning to
define and solve general optimization problems from scratch. arXiv preprint arXiv:2410.13213, 2024.
Andrei Leman and Boris Weisfeiler. A reduction of a graph to a canonical form and an algebra arising during this
reduction. Nauchno-Technicheskaya Informatsiya, 2(9):12‚Äì16, 1968.
Marius Lindauer, Katharina Eggensperger, Matthias Feurer, Andr√© Biedenkapp, Difan Deng, Carolin Benjamins,
Tim Ruhkopf, Ren√© Sass, and Frank Hutter. Smac3: A versatile bayesian optimization package for hyperparameter
optimization. Journal of Machine Learning Research, 23(54):1‚Äì9, 2022.
Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng,
Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437, 2024a.
10


--- Page 11 ---
Fan Liu, Zherui Yang, Cancheng Liu, Tianrui Song, Xiaofeng Gao, and Hao Liu. Mm-agent: Llm as agents for
real-world mathematical modeling problem. arXiv preprint arXiv:2505.14148, 2025.
Hongwei Liu, Zilong Zheng, Yuxuan Qiao, Haodong Duan, Zhiwei Fei, Fengzhe Zhou, Wenwei Zhang, Songyang
Zhang, Dahua Lin, and Kai Chen. Mathbench: Evaluating the theory and application proficiency of llms with a
hierarchical mathematics benchmark. arXiv preprint arXiv:2405.12209, 2024b.
Hongliang Lu, Zhonglin Xie, Yaoyu Wu, Can Ren, Yuxuan Chen, and Zaiwen Wen. Optmath: A scalable
bidirectional data synthesis framework for optimization modeling. arXiv preprint arXiv:2502.11102, 2025.
David G Luenberger, Yinyu Ye, et al. Linear and nonlinear programming, volume 2. Springer, 1984.
Donato Maragno, Holly Wiberg, Dimitris Bertsimas, ¬∏S ÀôIlker Birbil, Dick den Hertog, and Adejuyigbe O Fajemisin.
Mixed-integer optimization with constraint learning. Operations Research, 2023.
OpenAI. Openai o1 system card. https://openai.com/index/openai-o1-system-card/, 2024.
OpenAI. Openai o3 system card. https://openai.com/index/o3-o4-mini-system-card/, 2025.
Jayant Rajgopal. Principles and applications of operations research. Maynard‚Äôs Industrial Engineering Handbook.‚Äì
2004.‚ÄìP, pp. 11‚Äì27, 2004.
Rindranirina Ramamonjison, Haley Li, Timothy T Yu, Shiqi He, Vishnu Rengan, Amin Banitalebi-Dehkordi, Zirui
Zhou, and Yong Zhang. Augmenting operations research with auto-formulation of optimization models from
problem descriptions. arXiv preprint arXiv:2209.15565, 2022a.
Rindranirina Ramamonjison, Timothy Yu, Raymond Li, Haley Li, Giuseppe Carenini, Bissan Ghaddar, Shiqi
He, Mahdi Mostajabdaveh, Amin Banitalebi-Dehkordi, Zirui Zhou, and Yong Zhang. Nl4opt competition:
Formulating optimization problems based on their natural language descriptions. In Marco Ciccone, Gustavo
Stolovitzky, and Jacob Albrecht (eds.), Proceedings of the NeurIPS 2022 Competitions Track, volume 220
of Proceedings of Machine Learning Research, pp. 189‚Äì203. PMLR, 28 Nov‚Äì09 Dec 2022b. URL https:
//proceedings.mlr.press/v220/ramamonjison23a.html.
Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M Pawan Kumar,
Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, et al. Mathematical
discoveries from program search with large language models. Nature, 625(7995):468‚Äì475, 2024.
Tomohiro Sawada, Daniel Paleka, Alexander Havrilla, Pranav Tadepalli, Paula Vidas, Alexander Kranias, John J
Nay, Kshitij Gupta, and Aran Komatsuzaki. Arb: Advanced reasoning benchmark for large language models.
arXiv preprint arXiv:2307.13692, 2023.
Sowmya S Sundaram and Deepak Khemani. Natural language processing for solving simple word problems. In
Proceedings of the 12th international conference on natural language processing, pp. 394‚Äì402, 2015.
EG Talbi. Metaheuristics: From design to implementation. John Wiley & Sons google schola, 2:268‚Äì308, 2009.
Zhengyang Tang, Chenyu Huang, Xin Zheng, Shixi Hu, Zizhuo Wang, Dongdong Ge, and Benyou Wang. Orlm:
Training large language models for optimization modeling. arXiv preprint arXiv:2405.17743, 2024.
Po-Wei Wang, Priya Donti, Bryan Wilder, and Zico Kolter. Satnet: Bridging deep learning and logical reasoning
using a differentiable satisfiability solver. In International Conference on Machine Learning, pp. 6545‚Äì6554.
PMLR, 2019.
Wayne L Winston. Operations research: applications and algorithm. Thomson Learning, Inc., 2004.
Ziyang Xiao, Dongxiang Zhang, Yangjun Wu, Lilin Xu, Yuan Jessica Wang, Xiongwei Han, Xiaojin Fu, Tao Zhong,
Jia Zeng, Mingli Song, et al. Chain-of-experts: When llms meet complex operations research problems. In The
Twelfth International Conference on Learning Representations, 2023.
Zhicheng Yang, Yinya Huang, Wei Shi, Liang Feng, Linqi Song, Yiwei Wang, Xiaodan Liang, and Jing Tang.
Benchmarking llms for optimization modeling and enhancing reasoning via reverse socratic synthesis. arXiv
preprint arXiv:2407.09887, 2024a.
Zhicheng Yang, Yiwei Wang, Yinya Huang, Zhijiang Guo, Wei Shi, Xiongwei Han, Liang Feng, Linqi Song,
Xiaodan Liang, and Jing Tang. Optibench meets resocratic: Measure and improve llms for optimization modeling.
arXiv preprint arXiv:2407.09887, 2024b.
11


--- Page 12 ---
Sihan Zeng, Alyssa Kody, Youngdae Kim, Kibaek Kim, and Daniel K Molzahn. A reinforcement learning approach
to parameter selection for distributed optimal power flow. Electric Power Systems Research, 212:108546, 2022.
Haotian Zhai, Connor Lawless, Ellen Vitercik, and Liu Leqi. Equivamap: Leveraging llms for automatic equivalence
checking of optimization formulations. arXiv preprint arXiv:2502.14760, 2025.
Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li,
and Maosong Sun. Graph neural networks: A review of methods and applications. AI open, 1:57‚Äì81, 2020.
Zihao Zhou, Shudong Liu, Maizhen Ning, Wei Liu, Jindong Wang, Derek F Wong, Xiaowei Huang, Qiufeng
Wang, and Kaizhu Huang. Is your model really a good math reasoner? evaluating mathematical reasoning with
checklist. arXiv preprint arXiv:2407.08733, 2024.
12


--- Page 13 ---
A
Data Construction
A.1
Dataset
Table 4: Optimization problem types and classes including in our Bench4Opt.
Problem Types
Problem Classes
LPs
Diet Problem
Transportation Problem
Blending Problem
Production Planning Problem
Network Flow Problem
Portfolio Optimization Problem
Cutting Stock Problem
Staff Scheduling Problem‚Äô
MILPs
Knapsack Problem
Traveling Salesman Problem (TSP)
Vehicle Routing Problem (VRP)
Bin Packing Problem
Set Covering Problem
Capacitated Facility Location Problem
Capital Budgeting Problem
Assignment Problem
Figure 4: Example for concise version word problem on cargo loading.
13


--- Page 14 ---
Figure 5: Example for word problem on cargo loading.
14


--- Page 15 ---
Figure 6: Code skeleton for optimization model simulation.
15


--- Page 16 ---
Figure 7: Standard structure for word problem crafted from INFORMS AIMMS-MOPTA Optimization Modeling
Competition.
16


--- Page 17 ---
B
Related work
NLP for OR Modeling
While substantial progress has been made in automatic modeling of general mathematical
problems (Bobrow, 1964; Dellarosa, 1986; Sundaram & Khemani, 2015; Liu et al., 2025), there has been limited
focus on applying these techniques specifically to operations research. Prior to the rise of LLMs, the NL4Opt
competition (Ramamonjison et al., 2022b) explored the feasibility of learning-based natural language interfaces
for optimization solvers. More recently, works leveraging LLMs, such as the Chain-of-Experts (CoE) (Xiao et al.,
2023) and OptiMUS (AhmadiTeshnizi et al., 2024), introduced multi-agent cooperative systems to model and
code complex OR problems automatically. Furthermore, Tang et al. (2024) fine-tuned open-source LLMs with
approximately 7B parameters, achieving significant performance improvements over baseline models. These
advancements underscore the immense potential of LLMs in optimization modeling. With the emergence of LLMs,
there is an increasing need for benchmarks to understand their capability boundaries (Liu et al., 2024b; Zhou et al.,
2024; Sawada et al., 2023). Several optimization modeling benchmarks have been proposed to evaluate LLMs.
The Linear Programming Word Problem (LPWP) dataset (Ramamonjison et al., 2022a) includes multiple domains
and comprises up to 1,001 LP problems. However, it primarily consists of elementary-level LP problems. The
ComplexOR dataset (Xiao et al., 2023) was designed to feature more complicated OR problems, but its limited size
and inclusion of numerical data within the textual description still constrain the level of complexity it can represent.
IndustryOR (Tang et al., 2024), MAMO (Huang et al., 2024), and E-OPT (Yang et al., 2024a) strive to cover a
broader range of OR problems through data synthesis and augmentation. The NLP4LP dataset (AhmadiTeshnizi
et al., 2024) attempts to separate data from textual descriptions, yet the problem sizes remain small, and the
descriptions are well structured with variables/constraints/objectives explicitly presented. In comparison to existing
benchmarks, our work aims to provide a more comprehensive dataset and a more rigorous evaluation method,
enabling a more precise assessment of LLM capabilities in optimization modeling.
Modeling Equivalence Evaluation
The earliest work to evaluate NLP for OR modeling performance is to
calculate the canonical accuracy (Ramamonjison et al., 2022a). This accuracy counts for the declaration-level(e.g.,
objective or constraints) matching score between predicted and reference formulations. This method has severe
limitations as it‚Äôs highly sensitive to superficial differences in formulation, such as variable naming or ordering.
More recent benchmark works‚Äîincluding MAMO (Huang et al., 2024), IndustryOR (Tang et al., 2024), NLP4LP
(AhmadiTeshnizi et al., 2024), and OptiBench (Yang et al., 2024b), and equivamap (Zhai et al., 2025)‚Äîrelies
on solvers to assess modeling quality. They execute the predicted numerical models and compare the resulting
optimal values with reference optimal values to evaluate correctness. While solver-based approaches better align
with the functional goals of optimization, they introduce new limitations. The evaluation becomes dependent on
solver behavior, which is often unstable, especially when the focus is on model structure equivalence rather than
model instance outcome equivalence. For instance, small changes in parameters can render a model infeasible or
non-convex, causing solvers to fail or return suboptimal solutions. As a result, optimal value mismatches may stem
not from modeling errors but from solver or numerical issues, thereby confounding the reliability of equivalence
assessment.
Broader Research on AI for OR
Beyond model formulation, significant progress has been made in the field of
AI for Operations Research (AI for OR), particularly in parameter generation and solving optimization problems
(Rajgopal, 2004). In parameter generation, AI techniques have been employed for better simulation of key
parameters of optimization problems (Elmachtoub & Grigas, 2022; Maragno et al., 2023; Bergman et al., 2022).
Similarly, our work leverages LLMs to generate necessary problem data through a program of thoughts (Chen
et al., 2022a). On the optimization side, numerous studies have focused on leveraging AI models in automatic
algorithm configuration (Ans√≥tegui et al., 2009; Lindauer et al., 2022; Anastacio & Hoos, 2020), optimization
algorithm selection (Wang et al., 2019; Chi et al., 2022), and heuristic algorithm design (Zeng et al., 2022; Talbi,
2009; Romera-Paredes et al., 2024). Specifically, a line of research has modeled MILP/LP problems as bipartite
graphs and applied Graph Neural Networks (GNNs) to make decisions at various stages of their solution processes
(Gasse et al., 2019; Zhou et al., 2020). These GNN-based methods have demonstrated efficacy in tasks such as
variable selection and node branching, leading to significant improvements in solver performance. Inspired by this,
we model optimization problems as bipartite graphs and formalize the evaluation paradigm based on the classical
WL-test algorithm Leman & Weisfeiler (1968).
17


--- Page 18 ---
C
Equivalence Evaluation
C.1
Model Equivalence Class
Definition C.1 (Model Equivalence). We say C(P) is a model equivalence class of the MILP/LP problem instance
P if ‚àÄÀÜP ‚ààC(P), ‚àÉpermutation matrices P1, P2 which shuffles the index of a vector or column index of a matrix
s.t. ÀÜP can be written in the following form:
min
x ÀÜcT x,
s.t. ÀÜAxÀÜ‚ó¶ÀÜb, ÀÜl ‚â§x ‚â§ÀÜu
where ÀÜb = P2b, ÀÜC = P1C, ÀÜA = P2AP1, ÀÜ‚ó¶= P2‚ó¶, ÀÜl = P1l, u = P1u.
‚àÄP2 ‚ààC(P1), we say P2 is model-equivalent to P1, denote as P1 ‚àºP2.
C.2
Weighted Bipartite Graph for Representing MILP/LP
A weighted bipartite graph for a MILP/LP instance is denoted by G = (V ‚à™W, E), with vertex set V ‚à™W
divided into 2 groups V = {v1, ¬∑ ¬∑ ¬∑ , vm} for constraints, and W = {w1, ¬∑ ¬∑ ¬∑ , wn} for variables, E consisting
of Eij = E(vi, wj), ‚àÄi = 1, ¬∑ ¬∑ ¬∑ , m, j = 1, ¬∑ ¬∑ ¬∑ , n. To fully represent all information in a MILP/LP instance, we
associate each vertex with features:
‚Ä¢ The constraint vertex vi ‚ààV is equipped with a feature vector HV with elements hV
i = (bi, oi) ‚ààHV =
R √ó {‚â§, ‚â•, =, <, >}
‚Ä¢ The variable vertex wj ‚ààW is equipped with a feature vector HW with elements hW
j
= (cj, œÑj) ‚ààHW =
R √ó {R ‚à™‚àí‚àû} √ó {R ‚à™‚àû} √ó {0, 1}. œÑj = 1 if j ‚ààZ and œÑj = 0 otherwise.
The edge Eij ‚ààR connects vi ‚ààV and wj ‚ààW, Eij = Aij. There is no edge connecting vertices in the same
vertex group.
C.3
Connection between Model Equivalence and Graph Isomorphism
To test whether 2 modeling instances were permutation equivalent, we can equivalently conduct isomorphism
testing between their corresponding weighted bipartite graphs. Lemma C.1 establishes an equivalence between
assessing modeling appropriateness and graph isomorphism testing.
Definition C.2 (Graph Isomorphism). Consider 2 graphs G1 = (G1, HV
1 √ó HW
1 ) and G2 = (G2, HV
2 √ó HW
2 )
with Gi = (Vi ‚à™Wi, Ei)|1‚â§i‚â§2. We say G1 and G1 are isomorphic if there exists permutation matrix P1, P2such
that: P1E1P T
2 = E2, P1HW
1 = HW
2 , P2HV
1 = HV
2 . If 2 graphs G1 and G1 are isomorphic, denote G1
g‚àºG2.
Lemma C.1. ‚àÄMILP/LP instances P1, P2 with corresponding bipartite graph G1, G1, we have
P1 ‚àºP2 ‚áê‚áíG1
g‚àºG2.
C.4
Proof of lemma C.1:
We prove this lemma by proving 2 claims:
Claim 1:
G1 ‚àºG2 =‚áíP1 ‚àºP2.
Suppose G1 ‚àºG2. For bipartite graphs G1 and G2, nodes vi would only connect with some node wj if
the j-th constraint involves decision variable xi. Therefore the adjacency matrix of Gk would be in the form
A(k)
adj =

0
AT
k
Ak
0

, ‚àÄk = 1, 2. Now, by the assumption that G1 ‚àºG2, ‚àÉpermutation matrix P such that
P =
PV
0
0
PW

,
PA(1)
adjP = A(2)
adj,
PT
V HV
1 = PT HV
2 ,
PT
W HW
1 = PT
W HW
2 .
18


--- Page 19 ---
Therefore, we have
A(2)
adj =

0
PV AT
1
PW A1
0

and H2 =

PV HV
1
PW HW
1

.
We may reformulate the MILP/LP instance P2 as follows:
P2 :
min
x‚ààRp√ó{0,1}n‚àíp cT PV x,
s.t. PW APV x ‚ó¶PW b, l ‚â§PV x ‚â§u,
By the definition of permutation equivalent, we say P2 ‚àºP1.
Claim 2:
P1 ‚àºP2 =‚áíG1 ‚àºG2.
Suppose P1 ‚àºP2. By the definition of permutation equivalent class, ‚àÉpermutation matrix P1 and P2 such that
A2 = P2A1P1
b2 = P2b1,
C2 = PT
1 C1,
P2‚ó¶1 = ‚ó¶2,
Therefore, the corresponding adjacent matrix in the bipartite graph of P2 is
A(2)
adj =

0
AT
2
A2
0

=

0
PT
1 AT
1 PT
2
P2A1P2
0

=

PT
1
0
0
P2
 
0
AT
1
A1
0
 P1
0
0
PT
2

= ÀÜPT A(1)
adj ÀÜP
In addition, we have b2 = P2b1, c2 = PT
1 c1. Therefore,
H2 =
HV
2
HW
2

=

PT
1
0
0
P2
 HV
1
HW
1

= ÀÜPT H1.
According to the definition of graph isomorphism, G1 is isomorphic to G2.
19


--- Page 20 ---
C.5
Algorithms
Algorithm 2 WL test for MILP/LP Graphs
Require: A graph instance (G, H) ‚ààGm,n √ó HV
m √ó HW
n and iterate limit L > 0.
1: Initialize with C0,V
i
= HASH0,V (hV
i ), C0,W
j
= HASH0,W (hW
j )
2: for l = 1, 2, ¬∑ ¬∑ ¬∑ , L do
3:
Cl,V
i
= HASH(Cl‚àí1,V
i
, Pn
j=1 Ei,jHASH‚Ä≤
l,W (Cj)l‚àí1,W )
4:
Cl,W
i
= HASH(Cl‚àí1,W
i
, Pn
j=1 Ei,jHASH‚Ä≤
l,V (Cj)l‚àí1,V )
5: return The multisets containing all colors {{CL,V
i
}}m
i=0, {{CL,W
i
}}n
j=0.
Algorithm 3 Determine if the graph is symmetric decomposable
Require: Graph G‚Äôs adjacent matrix A and type 2 stable partition sets of it‚Äôs variable nodes I = {I1, I2, ¬∑ ¬∑ ¬∑ , Is‚Ä≤}
and constraint nodes J = {J1, J2, ¬∑ ¬∑ ¬∑ , Jt‚Ä≤}.
Ensure: Returns True if the graph is decomposable symmetric; otherwise, False.
1: k ‚Üê|I1|.
2: if |Is| Ã∏= k or |Jt| Ã∏= k for some s = 1, ¬∑ ¬∑ ¬∑ , s‚Ä≤, t = 1, ¬∑ ¬∑ ¬∑ , t‚Ä≤. then
3:
return False
4: else
5:
Initialize an empty Cluster dictionary Cluster
6:
for i ‚Üê0 to k ‚àí1 do
7:
C ‚Üêthe set of all numbers for type 2 stable partition sets
8:
Initialize an empty cluster set Cluster[i], initialize an empty queue Q.
9:
while Set C is not empty do
10:
if Q is empty then
11:
Randomly select a color c ‚ààC, delete c from C.
12:
Pc ‚Üêthe list of nodes labeled with c ‚ààC.
13:
Cluster[i] ‚Üê[Pc[i]], delete node Pc[i] from S, push Pc[i] in Q.
14:
else
15:
while Q not empty do
16:
u ‚ÜêQ.dequeue()
17:
for neighborhood node w of u do
18:
if w is not in any of Pc or w is in Cluster[i] then
19:
continue
20:
else if color(w) appears in Cluster[i] then
21:
return False
22:
else
23:
Add w in Cluster[i], delete color(w) from C, push w in Q.
24:
if colors in Cluster[i] Ã∏= 1 are not distinct for some i = 0, ¬∑ ¬∑ ¬∑ k ‚àí1 then
‚ñ∑check distinct color
25:
return False
26:
else if checkDisjointness([S1, ¬∑ ¬∑ ¬∑ , Sk‚àí1]) then
‚ñ∑check disjointness
27:
return False
28:
else if checkConnectivity([S1, ¬∑ ¬∑ ¬∑ , Sk‚àí1]) then
‚ñ∑check disconnectivity
29:
return False
30: return True
Notation: We denote the collection of all nodes v‚Ä≤
is indexed by i ‚ààIp as Ip.
Function checkDisjointness([Cluster[1], . . . , Cluster[k ‚àí1]]) outputs True if any two sets Cluster[i] and
Cluster[j], where i Ã∏= j, share a common element.
Function checkConnectivity([Cluster[1], ¬∑ ¬∑ ¬∑ , Cluster[k ‚àí1]]) output True if there exists some nodes s ‚àà
Cluster[i], s‚Ä≤ ‚ààCluster[j], i Ã∏= j such that s connected with s‚Ä≤.
20


--- Page 21 ---
C.6
Proof Preparation for Theorem 3.1
Before establishing the proof, we first introduce the coloring refinement process of WL test for MILP/LP problem
since it is the first step 1 in algorithm A. For iteration l of the algorithm we will be assigning to each node a tuple
HL
i containing the node‚Äôs old compressed label and a multiset of the node‚Äôs neighbors‚Äô compressed labels. A
multiset is a set (a collection of elements where order is not important) where elements may appear multiple times.
At each iteration l, we will additionally be assigning to each node a new ‚Äúcompressed‚Äù label CL
i with the same
HL
i will get the same compressed label.
Repeat the above process for up to (m+n) (the number of nodes) iterations or until the partition of nodes by
compressed label does not change from one iteration to the next, we will get a converged multiset.
In addition, we introduce preliminary tools for an algorithm-independent definition.
In fact, unfoldable and symmetric decomposable can be defined without relying on WL-test algorithm. We
introduced equivalent definitions based on stable partition index sets.
Definition C.3 (Stable Partition Index Sets). For a modeling instance P in the form of (1) with n decision variables
and n constraints, define index set for optimization variables by I = {I1, I2, ¬∑ ¬∑ ¬∑ , Is} and index set for constraints
by J = {J1, J2, ¬∑ ¬∑ ¬∑ , Jt}, where
‚Ä¢ Ss
l=1 Il = {1, 2, ¬∑ ¬∑ ¬∑ , m}, St
k=1 Jk = {1, 2, ¬∑ ¬∑ ¬∑ , n};
‚Ä¢ Ili ‚à©Ilj = ‚àÖ, Jkp ‚à©Jkq = ‚àÖ, ‚àÄi, j ‚àà[1, ¬∑ ¬∑ ¬∑ , |Il|], i Ã∏= j, and p, q ‚àà[1, ¬∑ ¬∑ ¬∑ , |Jk|], p Ã∏= q.
We say (I, J ) is a pair of stable partition index sets if the following condition holds:
1. (ci, œÑi) = (ci‚Ä≤, œÑi‚Ä≤), ‚àÄi, i‚Ä≤ ‚ààIp for some p ‚àà1, 2, ¬∑ ¬∑ ¬∑ , s;
2. (bj, ‚ó¶j) = (bj‚Ä≤, ‚ó¶j‚Ä≤), ‚àÄj, j‚Ä≤ ‚ààJq for some q ‚àà1, 2, ¬∑ ¬∑ ¬∑ , t;
3. ‚àÄp ‚àà1, 2, ¬∑ ¬∑ ¬∑ , s, q ‚àà1, 2, ¬∑ ¬∑ ¬∑ , t, and i, i‚Ä≤ ‚ààIp, we have P
j‚ààJq aij = P
j‚ààJq ai‚Ä≤j;
4. ‚àÄp ‚àà1, 2, ¬∑ ¬∑ ¬∑ , s, q ‚àà1, 2, ¬∑ ¬∑ ¬∑ , t, and j, j‚Ä≤ ‚ààJq, we have P
i‚ààIp aij = P
i‚ààIp aij‚Ä≤;
Lemma C.2. If there are no collision of hash functions and their weighted averages, then WL test algorithm 2 will
finally terminated at some stable partition in O(m + n) iterations.
Lemma C.2 is proved in Chen et al. (2022b).
Definition C.4 (Unfoldable, by trivial partition). P is unfoldable if ‚àÉstable partition index sets I and J such that
I or J are trivial partitions, i.e. s = m and t = n.
Definition C.5 (Decomposable Symmetric, by grouped partition). P is decomposable symmetric if the following
condition holds:
‚àÉstable partition index set I and J such that:
1. There are only two types of index set in I and J . Type 1 set only contains a single index. Type 2 contains
several indexes, denote type 2 sets by I1, ¬∑ ¬∑ ¬∑ , Is‚Ä≤; J1, ¬∑ ¬∑ ¬∑ , Jt‚Ä≤. (By WL-test coloring, nodes with index in Ii
or Jj share the same color.)
2. Type 2 sets I1, ¬∑ ¬∑ ¬∑ , Is‚Ä≤ and J1, ¬∑ ¬∑ ¬∑ , Jt‚Ä≤ are equal-sized with |Ip| = |Jq| = k > 1, ‚àÄp ‚àà{1, 2, ¬∑ ¬∑ ¬∑ , s‚Ä≤} and
q ‚àà{1, 2, ¬∑ ¬∑ ¬∑ , t‚Ä≤}.
3. There exist k disjoint groups S1, ¬∑ ¬∑ ¬∑ , Sk such that |Si ‚à©Ip| = |Si ‚à©Ip| = 1; and ‚àÄa ‚ààSi, b ‚ààSj with
i Ã∏= j, a disconnected with b.
By Lemma C.2, we can show two sets of definitions are equivalent.
C.7
Proof of Theorem 3.1
We construct the proof by two lemmas to illustrate sufficient conditions that the result of WL test coloring can
reliably infer graph isomorphism.
Lemma C.3. Suppose Pstandard is unfoldable, then Gstandard and Gtest shares the same coloring ‚áê‚áíGstandard ‚àº
Gtest.
21


--- Page 22 ---
Suppose Pstandard is unfoldable, want to show A(Gtest, Gstandard) == Equivalent ‚áê‚áíPtest ‚àºPstandard.
If Ptest ‚àºPstandard, it is trivial that A(Gtest, Gstandard) == Equivalent.
Now, consider when A(Gtest, Gstandard) == Equivalent and Pstandard unfoldable, we have len(A1) =
len(C1) & len(A2) = len(C2).
By the detection algorithm, every color in the multisets output by WL test must be distinct, and multisets for
Pstandard are the same as multisets for Pstandard.
One stable partition of Gstandard and is {I1, ¬∑ ¬∑ ¬∑ , In}, {J1, ¬∑ ¬∑ ¬∑ , Jm}, where Ik, Jl are single-element sets.
WLOG, assume Ik = ik, Jl = jl.
Similarly, denote the stable partition of Gtest by {I‚Ä≤
1, ¬∑ ¬∑ ¬∑ , I‚Ä≤
n}, {J‚Ä≤
1, ¬∑ ¬∑ ¬∑ , J‚Ä≤
m}, with I‚Ä≤
k = [i‚Ä≤
k], J‚Ä≤
l = [j‚Ä≤
l].
Now, define a bijection mapping that shuffles [i1, ¬∑ ¬∑ ¬∑ , im] and [j1, ¬∑ ¬∑ ¬∑ , jn] to get [i‚Ä≤
1, ¬∑ ¬∑ ¬∑ , i‚Ä≤
m] and [j‚Ä≤
1, ¬∑ ¬∑ ¬∑ , j‚Ä≤
n],
denote such mapping by P. (Since each element in [i1, ¬∑ ¬∑ ¬∑ , im], [j1, ¬∑ ¬∑ ¬∑ , jn], [i‚Ä≤
1, ¬∑ ¬∑ ¬∑ , i‚Ä≤
m], or [j‚Ä≤
1, ¬∑ ¬∑ ¬∑ , j‚Ä≤
n] is
distinct, we can uniquely find such bijection).
Notice that such bijection may only map the index of vstandard
i
to the index of vtest
j
and map the index of
wstandard
l
to the index of wtest
p
, we can separately define a bijection for decision variable index as P1 and a
bijection for constraint index as P2.
Therefore, exists bijection P1 and P2 such that Ptest can be written in the following form:
min
x ÀÜcT x,
s.t. ÀÜAxÀÜ‚ó¶ÀÜb
where ÀÜb = P2bstandard, ÀÜC = P1Cstandard, ÀÜA = P2AstandardP1, ÀÜ‚ó¶= P2‚ó¶standard. This implies Ptest ‚àº
Pstandard.
Lemma C.4. Suppose Pstandard,Ptest are decomposible symmetric, then Gstandard and Gtest shares the same
coloring ‚áê‚áíGstandard ‚àºGtest.
When Pstandard is decomposible symmetric, and algorithm A output "Equivalent", the partition sets of
Gstandard and Gtest can be denoted as
Istandard = [I1, ¬∑ ¬∑ ¬∑ , Ik, Ik+1, ¬∑ ¬∑ ¬∑ , Is];
Jstandard = [J1, ¬∑ ¬∑ ¬∑ , Jl, Jl+1, ¬∑ ¬∑ ¬∑ , Jt];
Itest = [ÀÜI1, ¬∑ ¬∑ ¬∑ , ÀÜIk, ÀÜIk+1, ¬∑ ¬∑ ¬∑ , ÀÜIs];
Jtest = [ ÀÜJ1, ¬∑ ¬∑ ¬∑ , ÀÜJl, ÀÜJl+1, ¬∑ ¬∑ ¬∑ , ÀÜJt],
where set [I1, ¬∑ ¬∑ ¬∑ , Ik], [ÀÜI1, ¬∑ ¬∑ ¬∑ , ÀÜIk], [J1, ¬∑ ¬∑ ¬∑ , Jl], [ ÀÜJ1, ¬∑ ¬∑ ¬∑ , ÀÜJl], only contains one index, and set
[Ik+1, ¬∑ ¬∑ ¬∑ , Is], [ÀÜIk+1, ¬∑ ¬∑ ¬∑ , ÀÜIs], [Jk+1, ¬∑ ¬∑ ¬∑ , Jt], [ ÀÜJk+1, ¬∑ ¬∑ ¬∑ , ÀÜJt] consist at least 2 indexes; Ii, ÀÜIi shares the same
color ‚àÄi; and Jj, ÀÜJj shares the same color ‚àÄj.
Now, define a bijection mapping that maps
[I1, ¬∑ ¬∑ ¬∑ , Ik, Ik+1, ¬∑ ¬∑ ¬∑ , Is, J1, ¬∑ ¬∑ ¬∑ , Jl, Jl+1, ¬∑ ¬∑ ¬∑ , Jt]
to
[ÀÜI1, ¬∑ ¬∑ ¬∑ , ÀÜIk, ÀÜIk+1, ¬∑ ¬∑ ¬∑ , ÀÜIs, ÀÜJ1, ¬∑ ¬∑ ¬∑ , ÀÜJl, ÀÜJl+1, ¬∑ ¬∑ ¬∑ , ÀÜJt],
by the following rules:
1. For the unique index i ‚ààIp, where p ‚àà{1, ¬∑ ¬∑ ¬∑ , k}, map i to the unique index i‚Ä≤ ‚ààÀÜIp.
2. For the unique index j ‚ààJq, where q ‚àà{1, ¬∑ ¬∑ ¬∑ , l}, map j to to the unique index j‚Ä≤ ‚ààÀÜJq.
3. For the remaining nodes, we consider a cluster-wise mapping, i.e, finding some equivalent clusters, mapping
a cluster to another, and providing a unique mapping rule within chosen cluster.
Let V ‚Ä≤ and ÀÜV ‚Ä≤ be sets of all variable nodes except those with unique color in Gstandard and Gtest; W ‚Ä≤ and
ÀÜW ‚Ä≤ be sets of all constraint nodes except those with unique color in Gstandard and Gtest.
Find clusters S1, ¬∑ ¬∑ ¬∑ , Sr such that each Si is disconnected, disjoint, consists of nodes with the same
combination of unique colors as other Si, and Sr
i=1 Si = V ‚Ä≤ ‚à™W ‚Ä≤. Similarly, for symmetric decomposable
Gtest with the same coloring distribution, we can find clusters ÀÜS1, ¬∑ ¬∑ ¬∑ , ÀÜSr such that ÀÜSi has the same coloring
22


--- Page 23 ---
distribution with Si, and each Si is disconnected, disjoint, consists of nodes with the same combination of
unique colors as other Si, and Sr
i=1 ÀÜSi = ÀÜV ‚Ä≤ ‚à™ÀÜW ‚Ä≤.
The existence of S1, ¬∑ ¬∑ ¬∑ , Sr and ÀÜS1, ¬∑ ¬∑ ¬∑ , ÀÜSr are guaranteed by the symmetric decomposable property of
Gstandard and Gtest.
Now, we can define a bijection that maps Si to a corresponding cluster ÀÜSi. Note that nodes in one cluster
have distinct colors. The bijection mapping maps nodes from cluster Si to ÀÜSi according to color-matching,
i.e. a node maps to another one when they are in the same color.
Now, consider the adjacency matrix of the representing bipartite graph
Aadj =

0
AT
A
0

.
Since node groups S1, ¬∑ ¬∑ ¬∑ , Sk are disconnected, we can rearrange matrix A by some column permutation Pb
1 and
row permutation Pb
2 such that
Pb
1APb
2 =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
A1
0
¬∑ ¬∑ ¬∑
0
a1
0
A2
¬∑ ¬∑ ¬∑
0
a2
...
...
...
...
...
0
0
¬∑ ¬∑ ¬∑
Ar
ar
b1
T
b2
T
¬∑ ¬∑ ¬∑
br
T
Ar+1
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
where A1, ¬∑ ¬∑ ¬∑ , Ar are coefficient matrix for r clusters S1, ¬∑ ¬∑ ¬∑ , Sr with associated decision variables and constraints,
and Ar+1 is a k √ó l matrix.
The above composition of bijection mapping operations is equivalent to applying permutation operations on
Astandard, bstandard, cstandard, ‚ó¶standard by the following steps:
1. point-wise mapping for variables: permute c and A by permutation matrix P0
1 to map unique index i ‚ààIp to
i‚Ä≤ ‚ààÀÜIp, which produce ÀÜc = P0
1cstandard and ÀÜA = AstandardP0
1
2. point-wise mapping for constraints: permute bstandard, ‚ó¶standard and ÀÜA by permutation matrix P0
2 to map
unique index j ‚ààIq to j‚Ä≤ ‚ààÀÜJq, which produce ÀÜb = P0
2bstandard, ÀÜ‚ó¶= P0
2‚ó¶standard and ÀÜA = P0
2 ÀÜA =
P0
2AstandardP0
1
3. clustering mapping: permute ÀÜc and ÀÜA by permutation matrix Pc
1 and permute ÀÜb, ÀÜ‚ó¶and ÀÜA by permutation
matrix Pc
2 to produce
ÀÜA = Pc
1 ÀÜAPc
2 =
Ô£Æ
Ô£ØÔ£ØÔ£ØÔ£ØÔ£ØÔ£∞
A1
0
¬∑ ¬∑ ¬∑
0
a1
0
A2
¬∑ ¬∑ ¬∑
0
a2
...
...
...
...
...
0
0
¬∑ ¬∑ ¬∑
Ar
ar
b1
T
b2
T
¬∑ ¬∑ ¬∑
br
T
Ar+1
Ô£π
Ô£∫Ô£∫Ô£∫Ô£∫Ô£∫Ô£ª
= Pc
1P0
1AstandardP0
2Pc
2,
ÀÜb = Pc
2P0
2bstandard, ÀÜ‚ó¶= Pc
2P0
2‚ó¶standard, and ÀÜc = Pc
1P0
1cstandard
4. in-cluster mapping: iteratively permute ÀÜc and ÀÜA by permutation matrices P1
1, ¬∑ ¬∑ ¬∑ , Pr
1 and permute ÀÜb, ÀÜ‚ó¶
and ÀÜA by permutation matrices P1
2, ¬∑ ¬∑ ¬∑ , Pr
2 to produce ÀÜA = Pr
1 ¬∑ ¬∑ ¬∑ P1
1Pc
1P0
1AstandardP0
2Pc
2P1
2 ¬∑ ¬∑ ¬∑ Pr
2,
ÀÜb = Pk
2 ¬∑ ¬∑ ¬∑ P1
2Pb
2P0
2bstandard, ÀÜ‚ó¶= Pr
2 ¬∑ ¬∑ ¬∑ P1
2Pb
2P0
2‚ó¶standard, and ÀÜc = Pr
1 ¬∑ ¬∑ ¬∑ P1
1Pc
1P0
1cstandard
Now, define P1 = Pk
1 ¬∑ ¬∑ ¬∑ P1
1Pc
1P0
1 and P2 = Pk
2 ¬∑ ¬∑ ¬∑ P1
2Pc
2P0
2, we can write Ptest in the following form:
min
x ÀÜcT x,
s.t. ÀÜAxÀÜ‚ó¶ÀÜb
where ÀÜb = P2bstandard, ÀÜC = P1Cstandard, ÀÜA = P2AstandardP1, ÀÜ‚ó¶= P2‚ó¶standard. This implies Ptest ‚àº
Pstandard.
23


--- Page 24 ---
C.8
Complexity Analysis
For the two main types of problem realizations in our benchmark, Algorithm 2 converges in O(m + n) iteration.
In addition, for problems with m variables and n constraints, the time complexity to distinguish tested problem
realizations from the standard realization is at most O(k(m + n)2), which is is significantly lower than classical
algorithms employed by popular solvers, such as simplex method for LP and branch and bound algorithm for MILP.
Specifically,
1. For unfoldable problem instances, algorithm 2 converges in at most O(m + n) iterations according to
lemma C.2.
2. For decomposable symmetric problem instances, algorithm 2 converges in at most O(m+n) iterations, and
we shall further conduct symmetric decomposable detection using algorithm 3, which takes time complexity
O(kmn) in the worst case, where k is the number of clusters in the symmetric decomposable graph. The
total time complexity could be O(kmn).
C.9
Randomly sampling suffices to obtain symmetric decomposable
To make WL test work, it is desirable to sample a symmetric decomposable instance. In Theorem C.5 and C.6,
we proved that for a large range of modeling problems with reasonable assumptions, we can sample a symmetric
decomposable instance from its parameter support with probability 1.
Definition C.6 (Modeling Parameter Support). For a class of model formulation M with n decision variables and
m constraints, the parameter set Œò(M) is a collection of all possible values for problem data (A, c, b, ‚ó¶). The
parameter set associated with decision variable xi is Œò(M, i) =

[AT
:,i, ci]
	
.
An example of a formulation parameter support is attached in Appendix Section D.
Theorem C.5 (Efficient Sampling - continuous case). Suppose a model M satisfies the following conditions:
For each ‚ÉóŒ∏i ‚ààRd, i = 1, ¬∑ ¬∑ ¬∑ , n, there exists a coordinate ki such that ‚Éóe‚ä§
ki‚ÉóŒ∏i follows a continuous distribution
¬µi independently across i.
then a random draw ‚ÉóŒ∏ ‚àºŒò yields a symmetric decomposable instance M(‚ÉóŒ∏) almost surely.
Theorem C.6 (Efficient Sampling - discrete case). Suppose a model M satisfies the following conditions:
‚àÄi = 1, ¬∑ ¬∑ ¬∑ , n, ‚àÄ‚ÉóŒ∏i ‚ààRd, ‚àÉki ‚àà{1, ¬∑ ¬∑ ¬∑ , d} such that ‚Éóe‚ä§
ki‚ÉóŒ∏i ‚àº¬µi(¬∑) and independent of the distribution of
‚ÉóŒ∏j, ‚àÄj Ã∏= i, where ‚Éóeki is the ki-th standard basis vector in Rd, ¬µi(¬∑) is some discrete uniform distribution with
ui(‚Éóe‚ä§
ki‚ÉóŒ∏i)‚àºUniform {x1 ¬∑ ¬∑ ¬∑ xl}, i.e. at lease one coordinate of ‚ÉóŒ∏i can be randomly sampled with probability 1
l ,
where ki is the index of coordinate in ‚ÉóŒ∏i that being sampled.
Then, as l ‚Üí‚àû, randomly sample ‚ÉóŒ∏ from parameter support Œò, we can get a symmetric decomposable instance
for model M with probability 1.
We present the proof for Theorem C.5 and C.6 in Appendix C.10.
C.10
Proof of Theorem C.5 and Theorem C.6
Proof:
Lemma C.7. Suppose model M satisfies the following assuption:
‚àÄi = 1, ¬∑ ¬∑ ¬∑ , n.‚àÄ‚ÉóŒ∏i ‚ààRd, ‚àÉki ‚àà{1, ¬∑ ¬∑ ¬∑ , d} such that ‚Éóe‚ä§
ki‚ÉóŒ∏i ‚àº¬µi

‚ÉóŒ∏i

and independent of the distribution of
‚ÉóŒ∏j, where ‚Éóeki is the ki-th standard basis vertor in Rd, ¬µi(‚ÉóŒ∏i) is some continuous distribution; i.e., at least one
coordinate of ‚ÉóŒ∏i can be randomly sampled according to some continuous distribution.
Then, we have P(‚ÉóŒ∏i = ‚ÉóŒ∏j) = 0, ‚àÄi Ã∏= j.
Proof of lemma C.7:
Consider i Ã∏= j, 0 ‚â§P

‚ÉóŒ∏i = ‚ÉóŒ∏j

‚â§P

‚Éóekj‚ÉóŒ∏j = ‚Éóekj‚ÉóŒ∏i

= 0 since ¬µi is continuous distribution.
By lemma C.7, we have P

‚ÉóŒ∏i Ã∏= ‚ÉóŒ∏j

= 1.
Lemma C.8. Suppose model M satisfies the following condition:
‚àÄi = 1, ¬∑ ¬∑ ¬∑ , n, ‚àÄ‚ÉóŒ∏i ‚ààRd, ‚àÉki ‚àà{1, ¬∑ ¬∑ ¬∑ , d} such that ‚Éóe‚ä§
ki‚ÉóŒ∏i ‚àº¬µi(¬∑) and independent of the distribution of
‚ÉóŒ∏j, ‚àÄj Ã∏= i, where ‚Éóeki is the ki-th standard basis vector in Rd, ¬µi(¬∑) is some discrete uniform distribution with
24


--- Page 25 ---
ui(‚Éóe‚ä§
ki‚ÉóŒ∏i)‚àºUniform {x1 ¬∑ ¬∑ ¬∑ xl}, i.e. at lease one coordinate of ‚ÉóŒ∏i can be randomly sampled with probability 1
l ,
where ki is the index of coordinate in ‚ÉóŒ∏i that being sampled.
Then P(‚ÉóŒ∏i = ‚ÉóŒ∏i) ‚Üí0 as l ‚Üí‚àû.
Proof of lemma C.8:
P

‚ÉóŒ∏i = ‚ÉóŒ∏j

= P

‚Éóeki‚ÉóŒ∏i = ‚Éóeki‚ÉóŒ∏j

=
X
x
P

‚Éóeki‚ÉóŒ∏j = x | ‚Éóeki‚ÉóŒ∏i = x

P

‚Éóeki‚ÉóŒ∏i = x

=
X
x
P

‚Éóeki‚ÉóŒ∏j = x

=
X
x
1
l2
= 1
l .
as l ‚Üí‚àû,
P

‚ÉóŒ∏i = ‚ÉóŒ∏j

‚Üí0.
Lemma C.9. Suppose a modeling instance P has P(‚ÉóŒ∏j = ‚ÉóŒ∏j‚Ä≤) = 0, ‚àÄj Ã∏= j‚Ä≤, then
P(P is symmetric decomposable) = 1
.
Proof of lemma C.9:
Suppose ‚àÉindex set k ‚äÇ{1, 2, ¬∑ ¬∑ ¬∑ , d} such that ‚àÄk ‚ààk,‚Éóek‚ÉóŒ∏j Ã∏= ‚Éóek‚ÉóŒ∏j, want to show the joint probability of
the following event is 1 :
1. Event A: cj Ã∏= cj‚Ä≤. [Objective coefficients are not the same.]
2. Event B: P
i‚ààI aij Ã∏= P
i‚ààI aij‚Ä≤ [accumulated edge weights for variable nodes of j, j‚Ä≤ are not the same].
3. Event C: P
q‚ààJ ai‚Ä≤q Ã∏= P
q‚ààJ aiq for some J containing index j or j‚Ä≤ and some i Ã∏= i‚Ä≤ ‚ààI. [accumulated
edge weights for two constraint nodes are not the same];
where I and J are sets in stable partitions I, J . It is equivalent to show P(A ‚à™B ‚à™C) = 1. Now, consider two
cases when j, j‚Ä≤ ‚àà{1, ¬∑ ¬∑ ¬∑ , n}:
1. Case 1: ‚àÉk ‚ààK s.t. ‚Éóe‚ä§
k ‚ÉóŒ∏j = cj, ‚Éóe‚ä§
k ‚ÉóŒ∏j‚Ä≤ = cj‚Ä≤, then cj Ã∏= cj‚Ä≤.
2. Case 2: ‚àÉk ‚ààK s.t. ‚Éóe‚ä§
k ‚ÉóŒ∏j = aij,‚Éóe‚ä§
k ‚ÉóŒ∏j‚Ä≤ = aij‚Ä≤ for some i, then aij Ã∏= aij‚Ä≤ for some i.
Notice that P(‚Ñ¶) = P(Case 1 ‚à™Case 2) = 1).
It suffices to show P(A ‚à™B ‚à™C | case 1 ‚à™case 2) = 1. Now, P(A ‚à™B ‚à™C | case 1) = 1 since P(A | case
1) = 1. It suffices to show P(A ‚à™B ‚à™C | case 2) = 1; Is suffices to show P(B ‚à™C | case 2) = 1.
Now, suppose ‚àÉk ‚ààK s.t. ‚Éóek‚ÉóŒ∏j = aij Ã∏= ‚Éóek‚ÉóŒ∏j‚Ä≤ = aij‚Ä≤.
Consider I containing i. WLOG, suppose ÀÜI ‚äÇI is an index set that containing all i‚Ä≤s such that aij Ã∏= aij‚Ä≤, and
P
i‚ààI/ÀÜI (aij ‚àíaij‚Ä≤) = c for come constant c, then
P
 X
i‚ààI
aij Ã∏=
X
i‚ààI
aij‚Ä≤
!
= P
 
Ii‚ààÀÜIaij Ã∏=
X
i‚ààI
aij‚Ä≤ + c
!
= 1 ‚àíP
 
Ii‚ààÀÜIaij =
X
i‚ààI
aij‚Ä≤ + c
!
= 1 ‚àí0
= 1
The third equality holds since P
i‚ààÀÜI aij and P
i‚ààÀÜI aij‚Ä≤ are independent and can be sampled from some
continuous distribution. Therefore. P(B | case 2) = 0, we have P(A ‚à™B ‚à™C) = P(A ‚à™B ‚à™C | ‚Ñ¶) =
P(A ‚à™B ‚à™C | (case 1 ‚à™case2)) = 1.
25


--- Page 26 ---
P(A ‚à™B ‚à™C) = P(A ‚à™B ‚à™C | ‚Ñ¶) = P(A ‚à™B ‚à™C | case 1 ‚à™case 2) = 1.
Now, by lemma C.7 and lemma C.9, we can prove Theorem C.5; by lemma C.8 and lemma C.9, we can prove
Theorem C.6.
D
Examples
D.1
Examples for limitations of solver-based evaluation
Example 1 (The solver returns values, and the execution accuracy is 1 but the mathematical model is actually
wrong). Consider a car production and revenue maximization problem. A manufacturer produces two types of
cars: sedans and SUVs. Let the decision variables of x be the number of sedans to produce and y be the number of
SUVs to produce. The correct formulation is:
Maximize 30x + 50y
such that: x + 2y ‚â§100
(Production capacity in labor-hours)
x ‚â•0, y ‚â•0
(Non-negativity)
Now suppose an LLM generates an incorrect model with an additional erroneous constraint:
Maximize 30x + 50y
such that: x + 2y ‚â§100
(Production capacity in labor-hours)
x + y ‚â§40
(ERRONEOUS constraint)
x ‚â•0, y ‚â•0
(Non-negativity)
If we test with a data configuration Œ∏ where production capacity = 80 and the market demand limit is 40, both
models will yield the same optimal solution and optimal value: produce 40 SUVs for a revenue of $2,000. However,
if the data configuration changes to Œ∏‚Ä≤ with production capacity = 200, the correct model would recommend
producing 100 SUVs for a revenue of $5,000, while the incorrect model would still limit production to 40 units total
due to the erroneous constraint.
Example 2 (The solver returns constant value, and its useless for modeling equivalence detection). Consider a
facility location problem where the goal is to determine whether it is possible to open a subset of facilities to serve
all customer demand within a fixed budget. The objective is a constant (e.g., 0), since only feasibility is of interest:
Minimize 0
such that:
X
j‚ààF
xj ¬∑ cj ‚â§B
(Budget constraint)
X
j‚ààF
aijxj ‚â•1
‚àÄi ‚ààD
(Coverage: each demand point must be served)
xj ‚àà{0, 1}
‚àÄj ‚ààF
Now, suppose the LLM generates an incorrect model with slightly relaxed constraints:
Minimize 0
such that:
X
j‚ààF
xj ¬∑ cj ‚â§B
(Same budget constraint)
X
j‚ààF
aijxj ‚â•0.5
‚àÄi ‚ààD
(ERRONEOUS weaker coverage)
xj ‚àà{0, 1}
‚àÄj ‚ààF
If both models happen to be feasible under a specific data configuration Œ∏ (e.g., a small number of facilities
with low costs and high coverage), then the solver will return ‚Äúfeasible‚Äù for both. However, the second model
allows partial coverage (due to the threshold of 0.5), which violates the intended semantics. Since the objective
function is constant, execution accuracy based on solver output cannot detect this structural mistake.
26


--- Page 27 ---
Example 3 (The mathematical model is incorrect but the execution accuracy is invalid for infeasible problems).
Consider the same car production problem, but with modified constraints:
Maximize 30x + 50y
such that: x + 2y ‚â§10
(Limited production capacity in labor-hours)
x ‚â•20, y ‚â•0
(Minimum sedan production requirement)
This correct model is genuinely infeasible because the minimum sedan production requirement (x ‚â•20) cannot be
satisfied with the limited production capacity (x + 2y ‚â§10). Now suppose an LLM generates an incorrect model
with an erroneous constraint:
Maximize 30x + 50y
such that: x + 2y ‚â§10
(Limited production capacity in labor-hours)
x ‚â•5, y ‚â•7
(ERRONEOUS minimum requirements)
x, y ‚â•0
(Non-negativity)
For the data configuration Œ∏ shown above, both models will be evaluated as infeasible by the solver. The execution
accuracy metric cannot distinguish between the correct model that is genuinely infeasible under this configuration
and the incorrect model that is infeasible due to contradictory constraints (x ‚â•5 and y ‚â•7 would require at least
19 labor-hours, exceeding the 10 available).
D.2
Examples for model, model parameter set, and model instance
Example 4 (Model Parameter Set for Blending Problem). For example, a blending problem can be formulated as:
min
x
n
X
i=1
cixi
s.t.
n
X
i=1
ajixi ‚â•pj, ‚àÄj = 1, ¬∑ ¬∑ ¬∑ , m.
xi ‚â§ui, ‚àÄi = 1, ¬∑ ¬∑ ¬∑ , n.
The corresponding parameter set Œò(Mblend) can be defined as
Œò(Mblend) =
n
(A, c, b, ‚ó¶)
A = [ ÀÜAT , In]T , where ÀÜA ‚ààRm√ón and In is an n √ó n
identity matrix; c = [c1, ¬∑ ¬∑ ¬∑ , cn]T ‚ààRn; b = [‚àíp1, ¬∑ ¬∑ ¬∑ , ‚àípJ, ‚àíu1, ¬∑ ¬∑ ¬∑ , ‚àíun]n ‚ààRm+n;
‚ó¶= [‚â•, ¬∑ ¬∑ ¬∑ , ‚â•, ‚â§, ¬∑ ¬∑ ¬∑ , ¬∑ ¬∑ ¬∑ , ‚â§]T
1√ó(m+n)
o
.
The parameter set associated with xi is Œò(Mblend, i) =

[AT
:,i, ci]
	
= Rm+1.
D.3
Examples for Symmetry
Example 5 (Undesirable Symmetry). Discriminating problem instances involving symmetry in their decision
variables or constraints can be tricky. Because some non-isomorphic bipartite graphs cannot be distinguished by
WL-test due to their automorphic structure in the graph. For example, Chen et al. (2022b) illustrates one case in
which two MILP graphs are non-isomorphic while WL-test outputs the same multiset.
27


--- Page 28 ---
Model Parameter
(MI)LP Model 
Model Instance 
Model Parameter
Model Instance 
Model Instance 
Model Parameter
Model Parameter
Model Instance 
Figure 8: Model Instances Generation
Figure 9: Two non-isomorphic MILP graphs that cannot be distinguished by WL test
Example 6 (Symmetric Decomposable Problem). For decomposable symmetric problems, their corresponding
bipartite graph can be divided into several symmetric sub-graphs, with each isomorphic and disconnected from
others. For example, an instance on bin-packing with heterogeneous vehicles is formulated as
min
x‚àà{0,1}q,y‚àà{0,1}p
p
X
j=1
yj
s.t.
X
i
sixij ‚â§byj, ‚àÄj = 1, ¬∑ ¬∑ ¬∑ , p.
p
X
j=1
xij = 1, ‚àÄi = 1, ¬∑ ¬∑ ¬∑ , q
For the bin-packing problem with p = 3 and q = 2, a corresponding bipartite is illustrated in figure 10, where the
red node represents decision variables and the blue nodes represent constraints.
28


--- Page 29 ---
Figure 10: Bipartite for a bin-packing problem. Different colors indicate that the nodes are colored using the
WL test. This figure illustrates the representation of a symmetric decomposable graph. There are four groups of
nodes with the same colors in each group, and two nodes with distinct colors. In addition, a node in any group, for
example, the lightest red group, only connects with one node in other groups.
Such graphs are quite special since by excluding uniquely colored nodes and their connecting edges, the
remaining symmetric nodes (nodes labeled in the same color via the WL test) can be combined to form several
isomorphic, disconnected, and unfoldable graphs, as the dashed line highlights in Figure 11.
Figure 11: Decompose a symmetric decomposable graph
29


--- Page 30 ---
Example 7 (Solver can be Inconsistant).
Structurally different
Parameter 
Configuration 1
Parameter 
Configuration 2
optimal value = 2
solver solution: (1,1) 
optimal value = 2
solver solution: (1,1) 
Instance B1
Same optimal value
Not functionally 
equivalent
Instance A2
optimal value = 3
solver solution: (1,1) 
optimal value = 2
solver solution: (2,0) 
Instance B2
Different optimal value
Remark: Instance B1 has an infinite number of different optimal 
solutions, but a solver typically output just one of the optimal solution.
Can pass solver 
evaluation
Cannot pass solver 
evaluation
Model B
Model A
Instance A1
Figure 12: Solver‚Äôs evaluation on modeling equivalence can be inconsistent across different parameter configurations
30
