--- Page 1 ---
Large Language Models as Surrogate Models in Evolutionary Algorithms: A Preliminary
Study
Hao Haoa, Xiaoqun Zhanga, Aimin Zhoub,c,∗
aInstitute of Natural Sciences, Shanghai Jiao Tong University, Shanghai, 200240, China
bSchool of Computer Science and Technology, East China Normal University, Shanghai, 200062, China
cShanghai Institute of AI for Education, East China Normal University, Shanghai, 200062, China
Abstract
Large Language Models (LLMs) have achieved significant progress across various fields and have exhibited strong potential in
evolutionary computation, such as generating new solutions and automating algorithm design. Surrogate-assisted selection is a core
step in evolutionary algorithms to solve expensive optimization problems by reducing the number of real evaluations. Traditionally,
this has relied on conventional machine learning methods, leveraging historical evaluated evaluations to predict the performance
of new solutions. In this work, we propose a novel surrogate model based purely on LLM inference capabilities, eliminating
the need for training. Specifically, we formulate model-assisted selection as a classification and regression problem, utilizing
LLMs to directly evaluate the quality of new solutions based on historical data. This involves predicting whether a solution is
good or bad, or approximating its value. This approach is then integrated into evolutionary algorithms, termed LLM-assisted EA
(LAEA). Detailed experiments compared the visualization results of 2D data from 9 mainstream LLMs, as well as their performance
on optimization problems. The experimental results demonstrate that LLMs have significant potential as surrogate models in
evolutionary computation, achieving performance comparable to traditional surrogate models only using inference. This work offers
new insights into the application of LLMs in evolutionary computation. Code is available at: https://github.com/hhyqhh/LAEA.git
Keywords: Large language models, black-box optimization, surrogate models, evolutionary algorithms
1. Introduction
Surrogate-assisted evolutionary algorithms (SAEAs) serves
as a crucial bridge for the practical application of theoretical
evolutionary algorithms (EAs). Surrogate models can effec-
tively reduce the dependency of evolutionary algorithms on the
objective evaluation function during the search process, thereby
lowering the optimization cost. This is particularly important
in expensive optimization problems (EOPs). The essence of
model-assisted evolutionary optimization algorithms lies in ap-
proximating the high-cost optimization objective function of a
black-box through historical evaluation data, guiding the search
process of the evolutionary algorithm.
Surrogate modeling fundamentally serves the purpose of
replicating the functionality of complex, resource-intensive
evaluations using more cost-effective models [1]. Within this
realm, techniques are predominantly split into two categories,
namely regression and classification [2].
Normally, regres-
sion is leveraged to predict continuous outputs or fitness val-
ues correlated with specific inputs. Conversely, classification
models are tasked with predicting discrete labels or categories
for solutions, an area which is receiving progressively more
∗Corresponding author: Aimin Zhou
Email addresses: haohao@sjtu.edu.cn (Hao Hao),
xqzhang@sjtu.edu.cn (Xiaoqun Zhang), amzhou@cs.ecnu.edu.cn
(Aimin Zhou)
academic and practical interest. The proliferation of machine
learning (ML) technologies [3] has fueled the adoption of var-
ious algorithms in the creation of surrogate models. Notable
among these are Gaussian processes (GP) [4], neural networks
(NN) [5], radial basis functions (RBF) [6], and support vec-
tor machines (SVM) [7], which have been effectively employed
across both single- and multi-objective optimization tasks [8].
Applications of these techniques span a broad spectrum, from
optimizing the design of buildings [9] to improving processes in
industrial settings such as iron production in blast furnaces [10],
and the design of neural networks [11].
The capabilities of large language models (LLMs) across
diverse sectors have recently reached impressively advanced
stages, as evidenced by various key studies [12, 13, 14, 15, 16].
These models operate by assimilating information from ex-
tensive text datasets, effectively capturing human knowledge,
which enables them to exhibit powerful cognitive functions
such as reasoning and decision-making [17, 18, 19, 20]. Given
their proficiency in understanding and applying learned knowl-
edge, it is conceivable that LLMs possess insights akin to hu-
man experience and pragmatic intuition in the realm of design-
ing optimization algorithms. This prompts a compelling inquiry
regarding the utility of LLMs in aiding EAs to confront and
solve intricate optimization challenges [21].
Mainstream SAEAs follow a paradigm wherein historical
evaluated solutions are used as training data. Machine learn-
ing models are then employed to learn the data distribution and
Preprint submitted to Elsevier
June 18, 2024
arXiv:2406.10675v1  [cs.NE]  15 Jun 2024


--- Page 2 ---
predict the quality of new solutions, thereby guiding the search
process of the evolutionary algorithm. This paradigm faces two
potential challenges:
• The time and computational costs associated with model
training: as the evolutionary algorithm iterates, the model
requires frequent updates, leading to repeated training and
additional computational overhead.
• Limitations related to data types and scales: surrogate
models based primarily on Gaussian processes have lim-
ited capacity to handle discrete and large-scale data, re-
stricting the application scope of some advanced SAEA
methods.
Against this backdrop, the emergence of LLMs offers new pos-
sibilities for SAEAs. LLMs, a class of deep learning models
trained on vast amounts of textual data, possess powerful nat-
ural language processing capabilities. They can directly lever-
age prompts to utilize their inference capabilities to predict the
quality of new solutions without the need for separate training.
This method can bypass the time and computational costs of
model training during the iterative process of the evolutionary
algorithm and enhance the model’s generalization to data.
Motivated by this, our work attempts to use LLMs as sur-
rogate models in SAEAs to directly predict the quality of new
solutions. Specifically, the task for LLMs needs to be defined.
Based on the literature [2], model-assisted selection can be
viewed as a classification or regression problem. In the clas-
sification problem, LLMs need to predict the category of new
solutions, such as “good” or “bad”. In the regression prob-
lem, LLMs need to predict the value of new solutions. Subse-
quently, appropriate prompts must be designed to guide LLMs’
inference based on the defined task. Finally, LLMs are inte-
grated into SAEAs for the selection of new solutions. We pro-
pose LLM-based surrogate models for regression and classifi-
cation tasks and integrate them into SAEAs, forming the LLM-
assisted SAEA (LAEA) algorithm. To validate this approach,
we conducted a series of experiments comparing the perfor-
mance of 9 mainstream LLMs in 2D data visualization and 2
LLMs in optimization problems. The performance was bench-
marked against the mainstream SAEA method, Bayesian Opti-
mization (BO), and evaluated in terms of model selection accu-
racy. Results indicate that LLMs have significant potential in
SAEAs, achieving performance comparable to traditional sur-
rogate models solely through prompt engineering. The main
contributions of this work are as follows:
• An innovative LLM-based surrogate model is proposed
for predicting the quality of new solutions in SAEAs, uti-
lizing LLMs’ inference capabilities to perform regression
and classification tasks without the need for training.
• The LLM-assisted SAEA (LAEA) algorithm is intro-
duced, integrating LLM-based surrogate models into
SAEAs to facilitate the selection of new solutions.
• Detailed experimental analysis is conducted, compar-
ing the performance of LLMs in 2D data visualization
and multiple optimization problems, and benchmarking
against traditional SAEA algorithms and model selection
accuracy.
• Extensible open-source code is provided to support further
research and development in this area.
The remainder of this paper is organized as follows: Sec-
tion 2 presents the preliminaries, including LLM applications in
SAEAs, black-box optimization problems, and surrogate model
paradigms. Section 3 details the implementation of LLMs as
surrogate models, including prompt generation for regression
and classification tasks and integration into SAEAs. Section 4
describes the experimental design and analysis of results. Sec-
tion 5 concludes the paper and discusses future research direc-
tions.
2. Preliminaries
LLMs have already found several applications within EAs.
This section will provide an overview of these applications, for-
mally define black-box optimization problems, and discuss typ-
ical surrogate model paradigms in SAEAs.
2.1. LLMs Enhanced EAs
Liu et al. [21] highlight the collaborative benefits of integrat-
ing LLMs with EAs. This partnership enhances optimization
processes in EAs [22, 23, 24] through the predictive capacity
of LLMs and improves LLM performance by leveraging EA’s
optimization techniques [25, 22, 26]. This synergy effectively
boosts applications ranging from Neural Architecture Search to
text generation [21], illustrating a potent intersection of large
language models and evolutionary algorithms. Next, we will
list the applications of LLMs in various stages of EAs.
• Solution generation: Yang et al. [27] pioneered the use
of LLMs for evolutionary optimization with their opti-
mization by PROmpting (OPRO) technique, which utilizes
LLMs to generate solutions based on natural language
descriptions. This approach was extended by Meyerson
et al. [28] through Language Model Crossover (LMX),
where LLMs create offspring from text-based parent so-
lutions.
Further developments by Liu et al. [29, 30]
and Bradley et al. [31] demonstrated LLMs’ effectiveness
in generating diverse and high-quality solutions in both
single and multi-objective optimization tasks, showcas-
ing their potential to enhance evolutionary algorithms by
leveraging their generative and pattern recognition capa-
bilities.
• Algorithm generation: Wu et al. [32] developed AS-
LLM to recommend optimal EAs by analyzing problem
and algorithm features using LLMs. In algorithm gener-
ation, Pluhacek et al. [33] used LLMs to design hybrid
swarm intelligence algorithms, while OptiMUS [34] au-
tomated all stages of mixed-integer linear programming
problems. Liu et al. [23, 35] integrated LLMs into the evo-
lutionary process to create new algorithms, demonstrating
2


--- Page 3 ---
superior performance in tasks like the traveling salesman
problem. Bradley et al. [36] introduced OpenELM, a li-
brary that facilitates the design of EAs using LLMs for
generating variations and evaluating solutions. These de-
velopments highlight LLMs’ pivotal role in enhancing and
innovating EA methodologies.
While LLMs have demonstrated remarkable performance in the
field of evolutionary algorithms, their application in model-
assisted optimization, specifically in the construction of surro-
gate models, remains largely unexplored. The successes of ex-
isting works and the gaps in the model-assisted selection stage
have motivated us to investigate the use of LLMs as surrogate
models in evolutionary algorithms.
2.2. Black-box Optimization
Consider a black-box function f : Rn →R, where each
evaluation of f is assumed to be expensive in terms of com-
putational resources or time. The objective of the black-box
optimization problem is to find [37]:
x∗= arg min
x∈X f(x)
(1)
where:
• x ∈Rn represents a vector of decision variables.
• X ⊆Rn denotes the feasible region within the decision
variable space.
• f(x) is the value of the objective function for a given vector
x, which is costly to evaluate.
• x∗is the optimal solution, satisfying f(x∗) ≤f(x) for all
x ∈X.
The function f is considered a black box as its explicit form is
unknown, rendering gradient-based optimization methods inap-
plicable. Evaluating f(x) typically demands substantial compu-
tational effort. The challenge lies in identifying the optimal x∗
with the fewest possible evaluations of f, owing to the signifi-
cant cost associated with each evaluation.
2.3. Surrogate Model Paradigm
Surrogate models serve as approximations for the optimiza-
tion of black-box functions that are costly to evaluate. A diverse
range of supervised machine learning algorithms are typically
employed in the construction of surrogate models, including
Gaussian processes [4], neural networks [5, 38], radial basis
networks [39], support vector machines [2], and others. The
basic paradigms of surrogate models have evolved over time,
moving from simple replacements of the original black-box
function to more sophisticated forms such as approximating ob-
jective values, class prediction, and even direct relationship pre-
diction. The specific operational paradigms of surrogate models
in EAs can be categorized into three major types:
• Regression-based: the model Mreg predicts a continuous
output y based on the input vector x. The general form can
be depicted as:
y = Mreg(x)
(2)
where Mreg represents the regression model, x denotes de-
cision variables in the evolutionary algorithm, and y de-
notes the predicted output, often serving as a surrogate to
expensive black-box functions. In this paradigm, Jones
et al. [40] proposed a Gaussian process-based surrogate
model, coupled with expected improvement as the acqui-
sition function, aimed at global optimization within the
GA framework. Liu et al. [41] employed Gaussian process
surrogates in differential evolution algorithms to enhance
convergence speed. Similarly, Li et al. [39] incorporated
radial basis functions in particle swarm optimization to
improve performance in high-dimensional problems. The
use of regression models in multi-objective optimization
has resulted in significant performance improvements as
demonstrated by Chugh et al. [42] and Song et al. [43].
• Classification-based: the model Mcla aims to map an input
vector x to a discrete class label l. The general form of the
model can be represented as:
l = Mcla(x)
(3)
where Mclass denotes the classification model, x represents
decision variables in the evolutionary algorithm, and l is
the predicted class label, used to indicate the quality of a
solution. Zhou et al. [44] utilized a fuzzy KNN classifier to
filter the quality of solutions, enhancing the performance
of the differential evolution (EA) algorithm.
Similarly,
Wei et al. [45] employed a gradient boosting classifier
to predict the quality of solutions in a level-based learn-
ing swarm optimizer. Classification models also find am-
ple application in multi-objective optimization contexts;
Zhang [46] and Pan [5] respectively applied KNN and neu-
ral network classifiers within multi-object evolutionary al-
gorithms to accelerate convergence.
• Relation-based: the model Mrel focuses on learning the
relative advantages directly among solutions. The relation
model can be expressed as:
r = Mrel(x1, x2)
(4)
where Mrel denotes the relation model, x1 and x2 repre-
sent two solution vectors, and r indicates the predicted re-
lation between the two solutions. As a novel class of sur-
rogate models, fast development has been witnessed this
year: Hao et al. [2, 47] utilized direct relation learning
and prediction to boost the performance of differential evo-
lution and estimation of distribution algorithms in single-
objective problems. In the field of multi-objective opti-
mization, the dominance relationships between solutions
are directly employed in constructing surrogate models,
thus enhancing the performance of algorithms, as reported
by Yuan et al. [48], Hao et al. [49], and Tian et al. [49].
3


--- Page 4 ---
Among the three typical paradigms mentioned above, regres-
sion and classification are two fundamental methods that will be
employed to construct the inference tasks for LLM-based surro-
gate models. In this paper, we investigate how to utilize LLMs
as surrogate models to directly predict the quality of new solu-
tions.
3. LLMs-assisted Evolutionary Algorithms
This section first introduces the basic framework of employ-
ing LLMs as surrogates to assist evolutionary algorithms. Sub-
sequently, then details how to use LLMs through prompts for
classification and regression tasks, including specific imple-
mentation details. Finally, the surrogate will be integrated into
an efficient evolutionary algorithm [50].
3.1. Framework
Figure 1 presents an overview of the LLM-assisted EA
framework. On the left, a typical surrogate-assisted evolution-
ary algorithm structure is shown. The process begins with the
initialization of a population, where a parent population gen-
erates offspring through reproduction operators. Subsequently,
under model-assisted selection, the next generation of the pop-
ulation is formed. This procedure iterates until termination cri-
teria are met, ultimately outputting the optimal solution. The
surrogate-assisted selection task may involve classification or
regression tasks, as demonstrated in section 2.3. On the right,
the process of using LLMs as surrogate models is depicted in
four steps. Initially, input data undergo preprocessing, which
includes rounding and normalization, among other adjustments.
Next, prompts describing the task are generated. Then, using
the LLM combined with these prompts, inference is conducted
to produce the final output. Finally, post-processing is applied
where predictive results are extracted from the LLM’s infer-
ence and converted into the appropriate format, such as labels
for classification tasks or numerical values for regression tasks.
The integration of these two processes forms the LLM-assisted
EA framework, which is detailed in Algorithm 2.
3.2. LLMs as Surrogate Models
The basic process of incorporating LLMs as surrogate mod-
els into Evolutionary Algorithms is illustrated in Figure 1.
This process comprises four steps: preprocessing, generating
prompts, inference, and post-processing, as depicted in Algo-
rithm1. Next, the details will be introduced in conjunction with
specific tasks, including regression and classification.
3.2.1. Regression Task
For regression tasks, Algorithm 1 receives the evaluated so-
lutions X and their value Y, as well as the solutions U to be
predicted, along with the large language model (LLM) used for
inference. Initially, the input data are preprocessed by scaling
the feature vectors X and U to a range of [0, 1], retaining β dec-
imal places (by default, β is set to 3), as shown in Equation (5).
˜z =
z −min(Z)
max(Z) −min(Z)
(5)
Algorithm 1: LLM as Surrogate Model
Input : X (evaluated solutions),
Y (the values or labels of solutions X),
U (to be predicted solutions),
LLM (large language model),
Opt (“Reg” or “Cla”).
Output: ˜Y (Predictions for U: values or labels).
1 ˜Y ←∅;
2 X, U ←Preprocessing(X, U);
3 for u ∈U do
4
prompt ←GeneratePrompt(X, Y, u, Opt);
5
response ←Inference(LLM, prompt);
6
y ←PostProcessing(response, Opt);
7
˜Y ←˜Y ∪y;
8 end
where z represents the original feature vector, Z denotes the
set of feature vectors, and ˜z is the scaled feature vector. Con-
currently, the Y values are also scaled to a range of [0, 1], re-
taining 5 decimal places. This scaling is performed to ensure
that the feature vectors are within a consistent range, facilitat-
ing the LLM’s inference process. Subsequently, prompts de-
scribing the task are generated, as illustrated in Figure 2. These
prompts comprise five parts: task description, process descrip-
tion, historical data , newly evaluated feature vectors (u), and an
emphasis on the output format to ensure the model returns data
in JSON format. This facilitates the extraction of prediction re-
sults during the post-processing stage. Then, the LLM performs
inference based on the prompts, and finally, the predicted re-
sults are extracted from the LLM’s inference and reverse-scaled
to obtain the predicted values. In Algorithm 1, the aforemen-
tioned process is iteratively executed (lines 3 to 8) until all the
unevaluated solutions U have been evaluated by the LLM.
3.2.2. Classification Task
For classification tasks, Algorithm 1 receives evaluated so-
lutions X and their corresponding labels Y, as well as uneval-
uated solutions U, utilizing a LLM for inference. The label
set Y includes categories 1 and 0, provided by upstream tasks.
Similar to the regression tasks, preprocessing involves scaling
feature vectors X and U to the range [0, 1], retaining β deci-
mal places (by default, β is set to 3). The scaling process is
shown in Equation (5). Subsequently, prompts describing the
task are generated, as illustrated in Figure 3. These prompts
comprise five parts: task description, process description, his-
torical data, newly evaluated feature vectors (u), and the output
format specification. Then, the LLM performs inference based
on the prompts. Finally, the predicted results are extracted from
the LLM’s inference and parsed to obtain the predicted labels.
This process is repeated until all the unevaluated solutions U
have been assessed by the LLM.
The above section introduces the method of employing Zero-
Shot Learning to use a Large Language Model as a surrogate
model for evaluating solutions within evolutionary algorithms.
As models for classification and regression tasks, historical
4


--- Page 5 ---
Figure 1: The framework of LLM-assisted evolutionary algorithm (LAEA). The left side illustrates the basic structure of a surrogate-assisted evolutionary algorithm,
where selection can be either a classification or regression task. The right side depicts the four steps of utilizing LLMs as surrogate models: preprocessing, generating
prompts, inference, and post-processing.
Regression task prompt
Your task is to predict the numerical value of each object based
on its attributes. These attributes and their corresponding values
are outcomes of a black box function’s operation within its de-
cision space. The target value for each object is determined by
a specific mapping from these attributes through the black box
function. Your objective is to infer the underlying relationships
and patterns within the black box function using the provided
historical data. This task goes beyond simple statistical analy-
ses, such as calculating means or variances, and requires under-
standing the complex interactions between the attributes. Please
do not attempt to fit the function using code similar to Python;
instead, directly learn and infer the numerical values.
Procedure:
1. Analyze the historical data to uncover how attributes relate to
the numerical values.
2. Use these insights to predict the numerical value for new ob-
jects based on their attributes.
3. Respond using JSON format, e.g. {‘Value’: ‘approximation
result’}
Historical Examples:
Features: ⟨0.338, 0.531, . . . , 0.363⟩Value: 0.41148
Features: ⟨0.207, 0.598, . . . , 0.285⟩Value: 0.35745
...
Features: ⟨0.629, 0.029 . . . , 0.279⟩Value: 0.67179
New Evaluation:
Features: ⟨0.189, 0.917, . . . , 0.443⟩
Note:
Respond in Json with the format {‘Value’:‘approximation result’}
only.
Figure 2: Regression task prompt
Classification task prompt
You are tasked with evaluating each object based on its numerical
attributes to determine its category as ‘better’ or ‘worse’. These
attributes derive from a black box function’s decision space, with
the assessment of the label based on the post-mapping function
values. Your role involves discerning the internal variable rela-
tionships of the black box function from provided historical data,
moving beyond mere statistical analyses like calculating means
and variances.
Procedure:
1. Identify patterns in how attributes are categorized.
2.
Apply these patterns to assess new objects, determining
whether its category is better or worse.
3. Respond using JSON format, e.g. {‘Class’: ‘result’}
Historical Examples:
Features: ⟨0.555, 0.881, . . . , 0.491⟩, Class: better
Features: ⟨0.593, 0.515, . . . , 0.456⟩, Class: worse
...
Features: ⟨0.253, 0.747, . . . , 0.475⟩, Class: better
New Evaluation:
⟨0.189, 0.917, . . . , 0.443⟩better or worse?
Note:
Respond in Json with the format {‘Class’: ‘result’} only.
Figure 3: Classification task prompt
5


--- Page 6 ---
evaluation data are utilized as context, allowing the LLM to pre-
dict each unevaluated individual. Next, we will delve into how
to integrate the LLM as a surrogate model within evolutionary
algorithms to enhance search efficiency.
3.3. LLM-assisted Evolutionary Algorithms
When the LLM can be adapted for both regression and
classification tasks, integrating the LLM as a surrogate model
with EAs becomes straightforward. We adopt the foundation
framework from the distribution estimation algorithm proposed
in [50], which enhances search efficiency using unevaluated
solutions. This algorithm can easily integrate both regression
and classification models. Subsequently, the LLMs is embed-
ded as surrogate models within this framework.
This algo-
rithm employs a variable-width histogram(VWH) [51] as a new
solution generation operator to enhance global convergence
speed. Additionally, it uses promising solutions predicted by
the model, without real evaluation (referred to as unevaluated
solutions, Pu), in generating new solutions for the next genera-
tion. This approach can effectively improve the population dis-
tribution [47]. The detailed algorithm procedure is illustrated in
Algorithm 2. There are several key steps in this algorithm:
Algorithm 2: LLM-assisted Evolutionary Algorithm
Input : N (population size),
τ (historical data size),
fesmax(maximum function evaluations)
LLM (large language model).
Output: x∗(optimal solution).
1 P ←Initialize(N);
2 A ←P ;
3 Pu ←∅;
4 fes ←0;
5 while fes < fesmax do
6
Q ←Reproduction(P ∪Pu, N);
7
˜V ←Prediction(LLM, A1:τ, Q, ‘Reg’) ;
8
˜L ←Prediction(LLM, A1:τ, Q, ‘Cla’) ;
9
q ←AssistedSelect(Q, ˜V) ;
10
Pu ←AssistedSelect(Q, ˜L) ;
11
P ←Select(P ∪Evaluate(q), N);
12
A ←A ∪q;
13
fes ←fes + 1;
14 end
15 x∗←argmin(A);
• Initialization (lines 1-3): The initialization of the popula-
tion P involves sampling N solutions using the Latin Hy-
percube Sampling (LHS) method [52]. This initial popula-
tion is evaluated using a black-box function. Additionally,
an archive A, identical to the population, is set up, and
an unevaluated population Pu is initiated as an empty set.
The function evaluation counter fes is set to 0.
• Stop condition (line 5): Checks whether the maximum
number of evaluations fesmax has been reached. If not, the
algorithm continues.
• Reproduction (line 6): Offspring Q are generated by ap-
plying reproduction operators to the combined population
P ∪Pu. This process uses a VWH model proposed within
EDA/LS [51] to model evaluated population P and uneval-
uated population Pu. This strategy has been proven effec-
tive in prior works [50, 47].
• Prediction (lines 7-8): LLMs predicts the values ˜V and
class ˜L for offspring solutions Q based on historical data
A1:τ. For classification tasks, labels of historical data are
assigned based on the objective values of the A1:τ: solu-
tions are first sorted by their function values in ascending
order, and labels are then assigned as “+1” to the top 30%
of solutions and “0” to the remaining solutions up to τ. For
regression tasks, the actual function values from the histor-
ical data are used directly as target values for prediction.
Predictions are performed using Algorithm 1.
• Assisted Selection (lines 9-10): Based on ˜V, the best so-
lution q is selected. Then, based on ˜L, selections are made
for solutions with a label of +1. If more than N/2 solutions
are chosen, a random selection of N/2 solutions is made to
form the unevaluated population Pu.
• Selection: The solution q is evaluated using a black-box
function, combined with the current population P, and the
best N solutions are selected based on the real objective
function to form the next generation population P.
• Update: Solution q is added to the archive A. The evalu-
ation counter fes is incremented.
• Termination: The optimal solution x∗is determined as the
solution with the minimum objective value in the archive
A.
We introduce the algorithm referred to as the LLM-assisted
evolutionary algorithm (LAEA), which embeds a LLM as a sur-
rogate model for both regression and classification tasks within
an EA. The LAEA leverages optimal solutions q and a subset
of unevaluated solutions Pu for enhancing the efficiency and
demonstrating the effectiveness of LLM as a surrogate model.
Additionally, a simplified version of this algorithm, solely uti-
lizing LLM for regression without employing it for classifica-
tion, is termed as LAEA-Reg. Specifically, during the predic-
tion phase in LAEA-Reg, the LLM is only applied to predict
the values ˜V of the solutions. In line 10 of Algorithm 2, the
predicted values ˜V are used to select the top N/2 solutions,
ordered by ˜V from lowest to highest, to form the unevaluated
population Pu.The LAEA-Reg variant potentially reduces the
computational overhead of LLM inference by half. However,
it does not facilitate the evaluation of LLM’s effectiveness as a
classification model. Extensive performance assessments will
be presented in Section 4.
4. Empirical Studies
As a gap-filling study, we will conduct comprehensive exper-
iments to verify the effectiveness of multiple LLMs as surrogate
6


--- Page 7 ---
models for EAs. Initially, we will show the performance and
visualization results of nine LLMs on a two-dimensional func-
tion using visual methods. Subsequently, we will evaluate the
performance of LLMs in selecting promising solutions on 5-
and 10-dimensional datasets. Following this, we will compare
the proposed LAEA algorithm with mainstream black-box opti-
mization algorithms to demonstrate its performance advantages
and disadvantages. Finally, a more detailed set of experiments
will analyze the model’s effectiveness and time complexity in
various scenarios. The experimental results will be presented in
the following sections.
4.1. Experimental Setup
In this section, we provide an overview of the test instances
and the LLMs used in our study, outlining the characteristics
of the test instances and describing the LLMs employed for the
experiments.
4.1.1. Test Instances
We used four well-known benchmark test functions for eval-
uating the performance of the models: Ellipsoid, Rosenbrock,
Ackley, and Griewank [41]. The details of these functions are
as follows:
• Ellipsoid function:
f(x) =
n
X
i=1
ix2
i
(6)
Interval: −5.12 ≤xi ≤5.12
Characteristics:
The Ellipsoid function is a convex
quadratic function. It is unimodal with its global minimum
at the origin.
• Rosenbrock function:
f(x) =
n−1
X
i=1
[100(xi+1 −x2
i )2 + (1 −xi)2]
(7)
Interval: −2.048 ≤xi ≤2.048
Characteristics: it is a non-convex function used to test
the performance of optimization algorithms. The global
minimum is inside a long, narrow, parabolic shaped flat
valley.
• Ackley function:
f(x) = −20 exp
−0.2
v
t
1
n
n
X
i=1
x2
i

−exp

1
n
n
X
i=1
cos(2πxi)
+ 20 + e
(8)
Interval: −32.768 ≤xi ≤32.768
Characteristics: it features a nearly flat outer region and
a large hole at the center. The global minimum is at the
origin.
• Griewank function:
f(x) = 1 +
1
4000
n
X
i=1
x2
i −
n
Y
i=1
cos
 xi√
i
!
(9)
Interval: −600 ≤xi ≤600
Characteristics: it has many widespread local minima,
making it difficult for optimization algorithms to converge
to the global minimum quickly. The global minimum is at
the origin.
4.1.2. LLMs used in the exceptional study
This work employs a variety of large language models, as
detailed in table 1. The models from Meta AI are based on the
Llama3-8B architecture [53], which has 8 billion parameters.
Two versions of this model are utilized: one is the original,
unquantized model with a size of 16 GB, and the other is a
4-bit quantized version that is significantly smaller, occupying
only 4.7 GB. From Mistral AI, we utilize two models: Mixtral-
8x7B [54] and Mistral-7B [55]. The former is a sparse mixture
of experts (MOE) model with 56 billion parameters and a size
of 26 GB, while the latter has 7 billion parameters and is 4.1
GB in size. Both models employ 4-bit quantization. For models
from Microsoft, we chose the Phi-2 [56] and Phi-3 [57] models.
Phi-2 has 2.7 billion parameters and a size of 1.6 GB, while Phi-
3 has 3.8 billion parameters and occupies 2.3 GB. Both mod-
els use 4-bit quantization. Additionally, Google’s Gemma-7B
model [58] is employed, which has 7 billion parameters and a
size of 5.0 GB, utilizing 4-bit quantization. Finally, two mod-
els from OpenAI, GPT-3.5 [59] and GPT-4 [60], are included
in this study. The specifics regarding their parameters, size, and
quantization are not publicly available. These models collec-
tively represent a broad spectrum of the current state of large
language models, providing comprehensive evidence for evalu-
ating LLMs as surrogate models.
All 4-bit quantized models were deployed using Ollama [61],
while GPT-3.5 and GPT-4 were accessed through OpenAI’s
API service. The unquantized version of Llama3-8B was de-
ployed using VLLM [62] to achieve improved inference speeds.
4.2. 2D Case Study
In EAs, the role of the surrogate model largely involves se-
lecting a subset of promising solutions from a given set. This
section will examine the ability of multiple models to correctly
select such subsets.
For generality, we define the task as a
label-balanced binary classification task. To align with com-
mon machine learning terminology, we refer to historical data
as training data (Dtrain) and the data used for evaluation as test-
ing data (Dtest). In reality, the training data only provides con-
text for inference of the LLMs and is not used for model train-
ing.
We choose four test problems provided in Section 4.1.1, with
each problem’s decision space set to 2-dimensional. Using latin
hypercube sampling, 50 points are sampled to form the training
data set (Dtrain). The testing data set consists of 400 sampled
points (Dtest), created by forming a grid with 20 evenly spaced
7


--- Page 8 ---
Table 1: Large Language Models Used in the Study
Model
Label
Parameters
Size
Quantization
Organization
Open Source
Llama3-8B [53]
8b-instruct-q4 0
8B
4.7 GB
4-bit
Meta AI
Yes
Llama3-8B* [53]
Meta-Llama-3-8B-Instruct
8B
16 GB
-
Meta AI
Yes
Mixtral-8x7B [54]
8x7b-instruct-v0.1-q4 0
8×7B
26 GB
4-bit
Mistral AI
Yes
Mistral-7B [55]
7b-instruct-v0.2-q4 0
7B
4.1 GB
4-bit
Mistral AI
Yes
Phi-2 [56]
2.7b-chat-v2-q4 0
2.7B
1.6 GB
4-bit
Microsoft
Yes
Phi-3 [57]
3.8b-mini-instruct-4k-q4 K M
3.8B
2.3 GB
4-bit
Microsoft
Yes
Gemma-7B [58]
7b-instruct-v1.1-q4 0
7B
5.0 GB
4-bit
Google
Yes
GPT-3.5 [59]
gpt-3.5-turbo-0125
-
-
-
OpenAI
No
GPT-4 [60]
gpt-4-turbo-2024-04-09
-
-
-
OpenAI
No
points in each dimension. Classification thresholds are deter-
mined by the median value of the function values at Dtrain, cat-
egorizing Dtrain and Dtest below the threshold as class “1” and
above the threshold as class “0”. These points are used to eval-
uate the regression and classification capabilities of the LLMs.
When testing the LLM for regression, the predicted values are
sorted in ascending order, with the top 50% considered as “1”
samples and the bottom 50% as “0” samples. For testing LLM
for classification , the predicted labels from the model are di-
rectly used as the final labels.
Nine LLMs listed in Table 1 will use prompts tailored for
classification and regression tasks to infer the values and cat-
egories for the 400 test points. Classification accuracy (acc),
defined by the equation (10), is used to measure each LLM’s
performance across different functions:
acc =
P|Dtest|
i=1
δ(lpre,i, lreal,i)
|Dtest|
(10)
where lpre,i and lreal,i are the predicted and real labels, respec-
tively, and δ(·) is an indicator function that returns “1” if two
labels are the same and “0” otherwise.
The experimental results are illustrated in Figure 4.
For
LLMs used as classification models (Figure 4a), most models
can predict labels through contextual inference alone (acc > 0.5
). Notably, the GPT-4, GPT-3.5, Mixtral-8x7B, and Llama3-
8B* models capture the distribution of the test data’s origi-
nal categories and achieve high classification accuracy.
For
LLMs used as regression models (Figure 4b), The Mixtral-
8x7B model performs best in the regression tasks, followed by
the GPT-4, GPT-3.5 and Llama3-8B* model. These results in-
dicate that some LLMs can serve as surrogate models through
inference alone; however, model performance varies across dif-
ferent tasks. Comparing the Llama3-8B and Llama3-8B* mod-
els shows that the quantized model exhibits a slight decline in
regression prediction capability. Figure 4 provides statistical
accuracy for various LLMs across the four test problems. The
box plot structure and visualization results are generally con-
sistent. Among the open-source models, the Llama3-8B* and
Mixtral-8x7B models exhibit the best overall performance, and
they perform better on regression tasks compared to classifi-
cation tasks. By contrast, GPT-4 also demonstrates high ac-
curacy but comes with substantial service costs. Considering
these factors, the two open-source models, Llama3-8B* and
Mixtral-8x7B, will be the primary models used in subsequent
experiments.
4.3. Selection Acuracy
Next, we analyze the ability of LLMs to select promising so-
lutions during the iterations of an evolutionary algorithm. The
experimental design is as follows: we choose problems with 5
and 10 dimensions and collect population data of parents and
offspring generated by the genetic algorithm (GA) [63] during
the solving process. Specifically, we collect data from the 2nd,
22nd, and 42nd generations to represent the population distri-
bution at the early, middle, and late stages of the algorithm’s
run. and the process is independently repeated 30 times. This
data serves as the training and testing data to overcome the ran-
domness of the evolutionary algorithm population. We test the
accuracy of selecting half of the offspring when compared to
the accuracy of the true function’s selection. The details of us-
ing LLMs as regression and classification models for predic-
tions are the same as in the 2D case. We use the precision (P),
recall (R), and F1 score (F1) as evaluation metrics, defined as
follows:
• Precision (P): The ratio of correctly predicted positive ob-
servations to the total predicted positives. It is calculated
as:
P =
TP
TP + FP
(11)
where TP is the number of true positive observations and
FP is the number of false positive observations.
• Recall (R): The ratio of correctly predicted positive obser-
vations to the all observations in actual class. It is calcu-
lated as:
R =
TP
TP + FN
(12)
where FN is the number of false negative observations.
• F1 Score (F1): The harmonic mean of precision and re-
call, providing a balance between the two. It is calculated
as:
F1 = 2 × P × R
P + R
(13)
8


--- Page 9 ---
Real Data
0.46
Llama3-8B
0.55
Llama3-8B*
0.68
Mixtral-8x7B
0.55
Mistral-7B
0.54
Phi-2
0.65
Phi-3
0.60
Gemma-7B
0.57
GPT-3.5
0.73
GPT-4
0.57
0.60
0.52
0.56
0.47
0.53
0.66
0.69
0.88
0.49
0.52
0.67
0.49
0.53
0.54
0.51
0.62
0.67
0.52
0.58
0.73
0.58
0.44
0.63
0.66
0.76
0.88
(a) Visualization of predicted labels by LLMs as classification models
Real Data
0.54
Llama3-8B
0.64
Llama3-8B*
0.80
Mixtral-8x7B
0.64
Mistral-7B
0.57
Phi-2
0.66
Phi-3
0.74
Gemma-7B
0.70
GPT-3.5
0.80
GPT-4
0.45
0.74
0.83
0.45
0.47
0.55
0.72
0.73
0.72
0.61
0.65
0.65
0.59
0.52
0.56
0.68
0.71
0.63
0.70
0.78
0.86
0.68
0.51
0.62
0.85
0.80
0.81
(b) Visualization of predicted labels by LLMs as regression models
Figure 4: Visualization results of label predictions by LLMs for 2-dimensional test problem. The first column represents the real data distribution, where blue •
and red × indicate class “1” and class “0”, respectively. Yellow and purple shading represent the distribution of true labels for the test data. Columns 2 through 10
present the prediction results of nine LLMs, with classification accuracy (acc) annotated in the bottom right corner of each test plot.
9


--- Page 10 ---
Llama3-8B
Llama3-8B*
Mixtral-8x7B
Mistral-7B
Phi-2
Phi-3
Gemma-7B
GPT-3.5
GPT-4
0.5
0.6
0.7
0.8
Accuracy
Model Accuracies
Cla
Reg
Figure 5: Box plots of acc for nine LLMs on four 2D test problems. The blue
boxes represent the acc of LLMs used as classification models, while the orange
boxes represent the acc of LLMs used as regression models.
where:
• TP (True Positives): the number of correctly predicted
positive samples, promising solutions that need to be se-
lected.
• FP (False Positives): the number of incorrectly predicted
positive samples, non-promising solutions that were incor-
rectly selected.
• FN (False Negatives): the number of positive samples
that were incorrectly predicted as negative, promising so-
lutions that were incorrectly not selected.
Table 2: Performance metrics of various LLMs across different dimensions.
Values are presented as mean (standard deviation).
n
LLMs
Task Precision
Recall
F1-Score
5
Llama3-8B*
Cla 0.50 (0.07) 0.48 (0.07) 0.49 (0.07)
Llama3-8B* Reg 0.61 (0.13) 0.62 (0.13) 0.62 (0.13)
Mixtral-8x7B Cla 0.34 (0.32) 0.07 (0.09) 0.11 (0.12)
Mixtral-8x7B Reg 0.53 (0.10) 0.55 (0.12) 0.54 (0.11)
10
Llama3-8B*
Cla 0.51 (0.08) 0.49 (0.07) 0.50 (0.08)
Llama3-8B* Reg 0.67 (0.12) 0.67 (0.12) 0.67 (0.12)
Mixtral-8x7B Cla 0.14 (0.30) 0.01 (0.03) 0.02 (0.05)
Mixtral-8x7B Reg 0.55 (0.07) 0.69 (0.21) 0.60 (0.09)
Llama3-8B* and Mixtral-8x7B models were used for classi-
fication (Cla) and regression (Reg) tasks, respectively, to pre-
dict on 5-dimensional and 10-dimensional datasets. Table 2
presents the mean and standard deviation of performance met-
rics for the two models across four test problems, three stages,
and 30 independent runs.
The results show that both mod-
els perform better on regression tasks compared to classifica-
tion tasks. An increase in dimension does not significantly af-
fect model performance. The Llama3-8B* model demonstrates
stable performance in both regression and classification tasks,
whereas the Mixtral-8x7B model performs poorly in classifica-
tion tasks. Specifically, the recall rate is very low, indicating
poor selection capability for solutions.
To further illustrate the variation in model performance
across different test problems and stages, Figure 6 shows the
line plots of the F1-Score for LLMs during data selection tasks
at different stages of the four test problems. The overall conclu-
sions are consistent with the results presented in Table 2. The
Llama3-8B* model demonstrates stable performance across all
test problems, while the Mixtral-8x7B model shows poor per-
formance in classification tasks. Additionally, as the iterations
of the GA algorithm progress, there is a downward trend in
model performance. This decline could be attributed to the con-
vergence properties of the GA, leading to uneven population
distribution.
4.4. Comparative Study
In this section, the Llama3* and Mixtral-8x7B are utilized as
surrogate models, embedded within the LAEA algorithm pro-
posed in Algorithm 2. The performance of the proposed al-
gorithm is compared against other mainstream black-box op-
timization algorithms. The implemented versions of the algo-
rithm in this section include the following four variants:
• LAEA-8B: Utilizes Llama3-8B* as both regression and
classification model in the LLM-assisted evolutionary al-
gorithm.
• LAEA-Reg-8B: Utilizes Llama3-8B* solely as a regres-
sion model in the LLM-assisted evolutionary algorithm.
• LAEA-8x7B: Utilizes Mixtral-8x7B as both regression
and classification model in the LLM-assisted evolutionary
algorithm.
• LAEA-Reg-8x7B: Utilizes Mixtral-8x7B solely as a re-
gression model in the LLM-assisted evolutionary algo-
rithm.
The comparison algorithms chosen are Bayesian Optimiza-
tion (BO) and surrogate-assisted evolutionary algorithms, as
specified below:
• Bayesian Optimization (BO): Incorporates sequential do-
main reduction [64] within the standard BO framework,
significantly accelerating the search progress and hasten-
ing convergence. It uses a Gaussian process as the sur-
rogate model. For specific implementation details, refer
to [65].
• Surrogate-assisted
Evolutionary
Algorithm
(SAEA):
Utilizes various single-objective SAEA provided by
the PlatEMO platform [66],
including SADE [67],
SAMSO [39], SACOSO [68], and SACC-EAM-II [69],
representing state-of-the-art surrogate-assisted evolution-
ary algorithms. All algorithms are executed with default
parameter settings.
10


--- Page 11 ---
2
22
42
0.0
0.5
1.0
n=5
Ellipsoid
2
22
42
0.0
0.5
1.0
Rosenbrock
2
22
42
0.0
0.5
1.0
Ackley
2
22
42
0.0
0.5
1.0
Griewank
2
22
42
Generations
0.0
0.5
1.0
n=10
2
22
42
Generations
0.0
0.5
1.0
2
22
42
Generations
0.0
0.5
1.0
2
22
42
Generations
0.0
0.5
1.0
Llama3* Cla
Llama3* Reg
Mixtral-8x7B Cla
Mixtral-8x7B Reg
Figure 6: Line plots of F1-Score for LLMs during data selection tasks at different stages of the four test problems.
The test functions selected are the four functions from sec-
tion 4.1.1, with each test function being evaluated at dimensions
of 5 and 10. Each algorithm runs 30 times on each test function,
with a maximum of 300 evaluations per run, simulating limited
evaluation counts due to high computational cost. The mean
optimal values and standard deviations achieved by each algo-
rithm are presented in Table 3. Additionally, the The Wilcoxon
rank-sum test [70] is used to perform statistical analysis on the
optimal values obtained by each algorithm, and the mean rank
values achieved by each algorithm are provided.
The results indicate that among the four implementations of
LAEA, both LAEA-Reg-8B and LAEA-8B exhibit outstand-
ing performance on most test problems, with no significant dif-
ferences between them. In contrast, LAEA-8x7B and LAEA-
Reg-8x7B perform relatively poorly. Considering that Llama3-
8B* demonstrates better performance on regression tasks than
on classification tasks, LAEA-Reg-8B, which uses Llama3-8B*
solely as a regression model, has a superior average rank com-
pared to LAEA-8B, which employs Llama3-8B* for both clas-
sification and regression tasks. Using LAEA-8B as a bench-
mark, in terms of average rank, LAEA-Reg-8B surpasses BO,
SADE, SACC-EAM-II, and SAMSO algorithms, but performs
worse than the SACOSO algorithm. According to the results
of the Wilcoxon rank-sum test, LAEA-8B and BO exhibit re-
spective advantages across the eight test problems, outperform-
ing SADE and SACC-EAM-II, but falling short compared to
SACOSO and SAMSO.
In summary, under a limited evaluation budget, LAEA
achieves performance levels comparable to mainstream opti-
mization algorithms when Llama3-8B* model is used solely for
context-based inference.
4.5. Model Performance in Pre-selection
In section 4.4, we utilized Llama3* and Mixtral-8x7B as
surrogate models within the LAEA algorithm for comparisons
with mainstream algorithms. To further evaluate the perfor-
mance gains provided by LLMs and to eliminate the influ-
ence of additional model management strategies (e.g., solu-
tions without evaluations as referenced in Algorithm 2), this
section employs the CoDE algorithm [71] as the basic frame-
work. Figure 8 illustrates the pre-selection process. CoDE is a
multi-operator differential evolution algorithm where each par-
ent generates multiple trial solutions. By using LLM to pre-
select promising trial solutions, we can clearly evaluate the per-
formance gains of using LLM as a surrogate model. Specifi-
Figure 7: Illustration of the pre-selection process in the CoDE algorithm.
cally, each parent generates three trial solutions, and the LLM
infers the quality of the solutions based on the parent popula-
tion information. When using LLM as a regression model, the
trials with the smallest predicted value is selected. When us-
ing LLM as a classification model, the offspring with the label
“1” is selected (if multiple solutions exist, one is chosen ran-
domly). Random selection is also used as a baseline algorithm
to evaluate the performance of LLM.
Table 4 presents the performance of Llama3* and Mixtral-
8x7B in pre-selection tasks. The results show that, compared
to random selection, both Llama3* and Mixtral-8x7B perform
as well as or better than the baseline in pre-selection tasks.
Specifically, when used as regression models, the two LLMs
achieved better pre-selection performance, with average ranks
of 1.25 and 1.75, respectively.
When used as classification
11


--- Page 12 ---
Table 3: Statistics of mean and standard deviation results obtained by nine comparison algorithms on four test functions with n = 5, 10, adhere to a maximum
evaluation budget of 300.
problem
LAEA-Reg-8B
LAEA-8B
LAEA-8x7B
LAEA-Reg-8x7B
BO
SADE
SACC-EAM-II
SACOSO
SAMSO
n = 5
Ellipsoid
1.01e+00[3]
2.30e+00[6](≈) 1.47e+00[5](≈) 2.52e+00[7](−)
6.15e-03[1](+) 5.72e+00[9](−) 3.44e+00[8](−) 1.20e+00[4](≈) 1.01e-01[2](+)
(9.29e-01)
(1.90e+00)
(1.26e+00)
(1.70e+00)
(2.65e-03)
(2.33e+00)
(1.86e+00)
(1.20e+00)
(1.32e-01)
Rosenbrock
8.35e+00[2]
1.50e+01[5](≈) 1.38e+01[4](−) 1.53e+01[6](≈) 1.08e+01[3](≈) 2.95e+01[9](−) 1.65e+01[7](−) 1.97e+01[8](−) 7.05e+00[1](≈)
(6.76e+00)
(1.53e+01)
(6.27e+00)
(9.22e+00)
(6.82e+00)
(1.53e+01)
(7.93e+00)
(5.19e+00)
(4.19e+00)
Ackley
6.83e+00[3]
6.28e+00[2](≈) 7.76e+00[4](≈) 9.72e+00[6](−) 1.76e+01[9](−) 9.54e+00[5](−) 1.21e+01[7](−) 5.18e+00[1](≈) 1.31e+01[8](−)
(2.50e+00)
(2.35e+00)
(3.35e+00)
(2.89e+00)
(4.26e+00)
(1.69e+00)
(1.14e+00)
(1.14e+00)
(2.76e+00)
Griewank
5.10e+00[6]
4.47e+00[5](≈) 2.74e+00[4](≈) 5.43e+00[7](≈) 2.28e+00[3](≈) 6.35e+00[9](≈) 6.08e+00[8](≈) 1.64e+00[2](+) 1.53e+00[1](+)
(5.16e+00)
(5.05e+00)
(1.65e+00)
(3.28e+00)
(9.96e-01)
(3.77e+00)
(1.59e+00)
(1.63e+00)
(1.27e+00)
n = 10
Ellipsoid
2.44e+01[4]
2.51e+01[5](≈) 2.54e+01[6](≈) 3.90e+01[8](≈)
9.29e-01[1](+) 7.22e+01[9](−) 2.57e+01[7](≈) 1.60e+01[3](+) 4.67e+00[2](+)
(7.98e+00)
(6.96e+00)
(1.76e+01)
(2.05e+01)
(2.61e+00)
(1.48e+01)
(1.54e+00)
(8.39e+00)
(4.65e+00)
Rosenbrock
9.41e+01[3]
9.82e+01[4](≈) 1.70e+02[6](≈) 1.76e+02[7](−) 1.23e+02[5](≈) 2.73e+02[9](−) 1.88e+02[8](−) 7.55e+01[2](≈) 3.76e+01[1](+)
(3.16e+01)
(2.77e+01)
(1.20e+02)
(9.54e+01)
(4.51e+01)
(9.73e+01)
(4.49e+01)
(5.49e+01)
(2.02e+01)
Ackley
1.18e+01[3]
1.14e+01[2](≈) 1.37e+01[5](≈) 1.54e+01[6](−) 1.73e+01[8](−) 1.34e+01[4](≈) 1.66e+01[7](−) 5.87e+00[1](+) 1.76e+01[9](−)
(1.71e+00)
(1.45e+00)
(2.48e+00)
(2.54e+00)
(4.25e+00)
(1.25e+00)
(7.48e-01)
(1.50e+00)
(1.66e+00)
Griewank
1.44e+01[3]
1.50e+01[4](≈) 2.48e+01[6](≈) 3.53e+01[7](−) 1.42e+00[1](+) 4.52e+01[9](−) 3.94e+01[8](−) 4.48e+00[2](+) 2.06e+01[5](≈)
(8.35e+00)
(5.91e+00)
(1.49e+01)
(1.61e+01)
(1.45e-01)
(1.38e+01)
(1.15e+01)
(3.01e+00)
(1.76e+01)
mean rank
3.375
4.125
5
6.75
3.875
7.875
7.5
2.875
3.625
+ / −/ ≈
0/0/8
0/1/7
0/5/3
3/2/3
0/6/2
0/6/2
4/1/3
4/2/2
models, Llama3* and Mixtral-8x7B had average ranks of 3.375
and 3.625, respectively. These results indicate that LLMs can
effectively select promising solutions through context-based in-
ference, with better performance noted when LLMs are used as
regression models. This finding is consistent with the results
from previous experiments.
Table 4: Llama3* and Mixtral-8x7B performance in pre-selection tasks.
problem
random
Llama3*-reg
Llama3*-cla
Mixtral-8x7B-reg
Mixtral-8x7B-cla
n = 5
Ellipsoid
2.05e-01[5]
1.87e-02[2](+)
8.29e-02[3](+)
1.61e-02[1](+)
8.86e-02[4](+)
(1.13e-01)
(9.08e-03)
(4.20e-02)
(1.04e-02)
(8.61e-02)
Rosenbrock
5.12e+00[5]
2.22e+00[1](+)
4.42e+00[4](≈)
2.67e+00[2](+)
3.99e+00[3](+)
(1.46e+00)
(8.59e-01)
(7.86e-01)
(9.38e-01)
(8.48e-01)
Ackley
4.34e+00[5]
2.53e+00[1](+)
3.68e+00[3](+)
2.55e+00[2](+)
3.89e+00[4](≈)
(4.59e-01)
(5.36e-01)
(5.14e-01)
(5.18e-01)
(6.23e-01)
Griewank
1.14e+00[5]
6.88e-01[2](+)
9.58e-01[4](≈)
6.32e-01[1](+)
8.85e-01[3](+)
(1.62e-01)
(1.60e-01)
(2.18e-01)
(1.28e-01)
(1.67e-01)
n = 10
Ellipsoid
1.80e+01[5]
6.41e+00[1](+)
1.57e+01[4](≈)
1.14e+01[2](+)
1.25e+01[3](≈)
(6.38e+00)
(2.41e+00)
(4.68e+00)
(3.97e+00)
(2.98e+00)
Rosenbrock
9.56e+01[5]
4.27e+01[1](+)
7.26e+01[3](≈)
6.01e+01[2](+)
7.49e+01[4](≈)
(2.56e+01)
(9.17e+00)
(2.52e+01)
(2.82e+01)
(1.48e+01)
Ackley
1.29e+01[5]
9.36e+00[1](+)
1.24e+01[3](≈)
1.07e+01[2](+)
1.27e+01[4](≈)
(6.73e-01)
(1.16e+00)
(9.02e-01)
(1.26e+00)
(9.34e-01)
Griewank
1.46e+01[5]
5.85e+00[1](+)
1.10e+01[3](+)
8.29e+00[2](+)
1.20e+01[4](≈)
(3.23e+00)
(1.67e+00)
(2.74e+00)
(2.19e+00)
(3.40e+00)
mean rank
5.00
1.25
3.375
1.75
3.625
+ / −/ ≈
8/0/0
3/0/5
8/0/0
3/0/5
4.6. Time Analysis
This section analyzes the inference time overhead of LLMs
under different scales of data.
We selected the unquantized
Llama3-8B* model and conducted inference time statistics on
5-dimensional and 10-dimensional data. The training dataset
size is 50, and the testing dataset size is also 50. We recorded to-
ken counts and inference times for regression and classification
prompts under different data precisions (β). The vllm platform
was used as the backend for inference, with hardware compris-
ing two NVIDIA 4090 GPUs. Both serial and parallel inference
times were tested, with concurrency set to match the test dataset
size. The specific data are shown in Figure 8.
5d β3 reg
5d β3 cla
5d β5 reg
5d β5 cla
10d β3 reg
10d β3 cla
10d β5 reg
10d β5 cla
0
10
20
30
40
50
Time (s)
27.05
24.48
29.01
26.30
39.95
35.91
42.90
40.65
23.71
22.32
26.57
24.08
35.72
33.11
40.65
37.54
Single
Parallel
1000
2000
3000
4000
5000
6000
T
oken Size
T
oken Size
Figure 8: Inference time statistics of Llama3-8B* on different scales of data.
From the data, it can be observed that for 5-dimensional data,
prompt lengths range between 3000-4000 tokens, with an in-
ference time of approximately 20-30 seconds for 50 test sam-
ples. For 10-dimensional data, prompt lengths range between
4000-5000 tokens, with an inference time of approximately 30-
40 seconds. Parallel inference times are reduced compared to
serial ones but not linearly proportional to concurrency levels.
Classification task prompts have fewer tokens than regression
tasks; hence their corresponding inference times are relatively
shorter. When β = 5, token lengths are longer compared to
when β = 3, resulting in slightly increased inference times;
however, this difference is marginal.
12


--- Page 13 ---
5. Conclusion
This work proposes a surrogate model that relies solely on
inference from large language models (LLMs), aiming to as-
sist selection within evolutionary algorithms and reduce depen-
dence on the black-box function during the optimization pro-
cess. Based on the paradigms of surrogate models in SAEAs,
we define specific tasks for LLMs. By leveraging prompt en-
gineering, we transform model-assisted selection into an infer-
ence task where LLMs assess the quality of candidate solutions
based on historical evaluation data. Specifically, we implement
classification and regression tasks to predict the category or ap-
proximate value of candidate solutions, thereby evaluating their
quality. LLMs are then integrated as surrogate models within
the evolutionary algorithm framework, resulting in the LLM-
assisted Evolutionary Algorithm (LAEA). Initially, we evalu-
ate the data selection capabilities of nine mainstream LLMs
using low-dimensional visualization and fixed datasets. Subse-
quently, we conduct experiments on 5- and 10- dimensional test
functions to test the performance of LAEA. The results indi-
cate that LAEA is comparable to mainstream optimization algo-
rithms under limited evaluation budgets. Additionally, we eval-
uate the performance of LLMs in pre-selection tasks, demon-
strating that LLMs can effectively identify promising solutions
through contextual inference. Finally, we analyze the inference
time overhead of LLMs, showing that the overhead is accept-
able across different data scales. Overall, this work demon-
strates the feasibility of using LLMs as surrogate models in
evolutionary algorithms, offering a novel approach to surrogate
model construction. The code is available as an open-source
repository for researchers.
However, some limitations are worth noting. For continuous
optimization, traditional machine learning models remain the
mainstream surrogate models due to several reasons. Firstly,
the tokenizer used during LLM training may not handle numer-
ical data well. Additionally, literature points to the limitations
of self-attention and positional embedding in transformers, po-
tentially resulting in insensitivity to numerical data [72], which
limits LLMs’ efficacy in purely numerical problems. Secondly,
the inference cost of LLMs cannot be overlooked. While using
LLMs as surrogate models can avoid the training process of tra-
ditional surrogate models, the inference cost is significant, es-
pecially compared to efficient surrogate models like K-Nearest
Neighbors (KNN) and random forests etc, where LLMs do not
have an advantage in terms of time.
Despite these limitations, we remain optimistic about the
broad application prospects of using LLMs as surrogate models
in EAs. Future work can explore the following directions:
• Inference for Discrete or Non-numerical Data: In some in-
dustrial optimizations or human-computer interaction op-
timizations, the input and output of black-box models
are not simple continuous values, posing significant chal-
lenges for traditional surrogate models. LLMs can handle
these scenarios uniformly through embeddings.
• Adapting LLMs for Numerical Contexts:
Fine-tuning
LLMs to be more adept in numerical scenarios can be
achieved by modifying tokenizers or incorporating numer-
ical data during LLM training, thereby enhancing their
sensitivity to numerical data.
• Optimizing Inference Time: Advanced inference frame-
works have significantly improved the efficiency of LLMs.
Furthermore, parallel inference for individual predictions
can enhance prediction speed. Utilizing advanced compu-
tation and inference services like Groq1 can also improve
prediction speed.
In conclusion, the application of LLMs as surrogate models
in evolutionary algorithms holds promising prospects, although
there are areas that need further refinement and optimization.
References
[1] Y. Jin, A comprehensive survey of fitness approximation in evolutionary
computation, Soft Computing 9 (1) (2005-01) 3–12.
[2] H. Hao, J. Zhang, X. Lu, A. Zhou, Binary Relation Learning and Classi-
fying for Preselection in Evolutionary Algorithms, IEEE Transactions on
Evolutionary Computation 24 (6) (2020-12) 1125–1139.
[3] M. I. Jordan, T. M. Mitchell, Machine learning: Trends, perspectives, and
prospects, Science 349 (6245) (2015) 255–260.
[4] B. Liu, Q. Zhang, G. G. Gielen, A gaussian process surrogate model as-
sisted evolutionary algorithm for medium scale expensive optimization
problems, IEEE Transactions on Evolutionary Computation 18 (2) (2013)
180–192.
[5] L. Pan, C. He, Y. Tian, H. Wang, X. Zhang, Y. Jin, A classification-based
surrogate-assisted evolutionary algorithm for expensive many-objective
optimization, IEEE Transactions on Evolutionary Computation 23 (1)
(2018) 74–88.
[6] H. Yu, Y. Tan, J. Zeng, C. Sun, Y. Jin, Surrogate-assisted hierarchical par-
ticle swarm optimization, Information Sciences 454-455 (2018-07) 59–
72.
[7] H. Hao, A. Zhou, H. Zhang, An approximated domination relationship
based on binary classifiers for evolutionary multiobjective optimization,
in: IEEE Congress on Evolutionary Computation, CEC 2021, Krak´ow,
Poland, June 28 - July 1, 2021, IEEE, 2021, pp. 2427–2434. doi:10.
1109/CEC45853.2021.9504781.
URL https://doi.org/10.1109/CEC45853.2021.9504781
[8] A. Zhou, B.-Y. Qu, H. Li, S.-Z. Zhao, P. N. Suganthan, Q. Zhang, Multi-
objective evolutionary algorithms: A survey of the state of the art, Swarm
and evolutionary computation 1 (1) (2011) 32–49.
[9] Q. Liu, F. Lanfermann, T. Rodemann, M. Olhofer, Y. Jin, Surrogate-
assisted many-objective optimization of building energy management,
IEEE Computational Intelligence Magazine 18 (4) (2023) 14–28.
[10] T. Chugh, N. Chakraborti, K. Sindhya, Y. Jin, A data-driven surrogate-
assisted evolutionary algorithm applied to a many-objective blast furnace
optimization problem, Materials and Manufacturing Processes 32 (10)
(2017-07-27) 1172–1178.
[11] Y. Liu, Y. Sun, B. Xue, M. Zhang, G. G. Yen, K. C. Tan, A sur-
vey on evolutionary neural architecture search, IEEE Transactions on
Neural Networks and Learning Systems 34 (2) (2023) 550–570. doi:
10.1109/TNNLS.2021.3100554.
[12] B. Min, H. Ross, E. Sulem, A. P. B. Veyseh, T. H. Nguyen, O. Sainz,
E. Agirre, I. Heintz, D. Roth, Recent advances in natural language pro-
cessing via large pre-trained language models: A survey, ACM Comput-
ing Surveys 56 (2) (2023) 1–40.
[13] P. Lee, S. Bubeck, J. Petro, Benefits, limits, and risks of gpt-4 as an ai
chatbot for medicine, New England Journal of Medicine 388 (13) (2023)
1233–1239.
[14] A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F.
Tan, D. S. W. Ting, Large language models in medicine, Nature medicine
29 (8) (2023) 1930–1940.
1https://wow.groq.com/why-groq/
13


--- Page 14 ---
[15] E. Kasneci, K. Seßler, S. K¨uchemann, M. Bannert, D. Dementieva, F. Fis-
cher, U. Gasser, G. Groh, S. G¨unnemann, E. H¨ullermeier, et al., Chatgpt
for good? on opportunities and challenges of large language models for
education, Learning and individual differences 103 (2023) 102274.
[16] Y. Liu, T. Han, S. Ma, J. Zhang, Y. Yang, J. Tian, H. He, A. Li,
M. He, Z. Liu, et al., Summary of chatgpt-related research and perspec-
tive towards the future of large language models, Meta-Radiology (2023)
100017.
[17] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia, E. H.
Chi, Q. V. Le, D. Zhou, Chain-of-thought prompting elicits reasoning in
large language models, in: Proceedings of Advances in Neural Informa-
tion Processing Systems, NeurIPS’2022, 2022, pp. 24824–24837.
[18] X. Wang, J. Wei, D. Schuurmans, Q. V. Le, E. H. Chi, S. Narang,
A. Chowdhery, D. Zhou, Self-consistency improves chain of thought rea-
soning in language models, in: Proceedings of the 11th International Con-
ference on Learning Representations, ICLR’2023, 2023.
[19] D. Zhou, N. Sch¨arli, L. Hou, J. Wei, N. Scales, X. Wang, D. Schuurmans,
C. Cui, O. Bousquet, Q. V. Le, E. H. Chi, Least-to-most prompting en-
ables complex reasoning in large language models, in: Proceedings of the
11th International Conference on Learning Representations, ICLR’2023,
2023.
[20] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. R. Narasimhan, Y. Cao, Re-
act: Synergizing reasoning and acting in language models, in: Proceed-
ings of the 11th International Conference on Learning Representations,
ICLR’2023, 2023.
[21] X. Wu, S. hao Wu, J. Wu, L. Feng, K. C. Tan, Evolutionary computation
in the era of large language model: Survey and roadmap (2024). arXiv:
2401.10034.
[22] C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le, D. Zhou, X. Chen, Large
language models as optimizers (2024). arXiv:2309.03409.
[23] F. Liu, X. Tong, M. Yuan, Q. Zhang, Algorithm evolution using large
language model (2023). arXiv:2311.15249.
[24] F. Liu, X. Tong, M. Yuan, X. Lin, F. Luo, Z. Wang, Z. Lu, Q. Zhang, Evo-
lution of heuristics: Towards efficient automatic algorithm design using
large language mode (2024). arXiv:2401.02051.
[25] T. Sun, Y. Shao, H. Qian, X. Huang, X. Qiu, Black-box tuning for
language-model-as-a-service, in: International Conference on Machine
Learning, PMLR, 2022, pp. 20841–20855.
[26] R. Lapid, R. Langberg, M. Sipper, Open sesame! universal black box
jailbreaking of large language models (2023). arXiv:2309.01446.
[27] C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le, D. Zhou, X. Chen, Large
language models as optimizers, arXiv preprint arXiv:2309.03409 (2023).
[28] E. Meyerson, M. J. Nelson, H. Bradley, A. Moradi, A. K. Hoover,
J. Lehman, Language model crossover:
Variation through few-shot
prompting, arXiv preprint arXiv:2302.12170 (2023).
[29] S. Liu, C. Chen, X. Qu, K. Tang, Y.-S. Ong, Large language models as
evolutionary optimizers, arXiv preprint arXiv:2310.19046 (2023).
[30] F. Liu, X. Lin, Z. Wang, S. Yao, X. Tong, M. Yuan, Q. Zhang, Large lan-
guage model for multi-objective evolutionary optimization, arXiv preprint
arXiv:2310.12541 (2023).
[31] H. Bradley, A. Dai, H. B. Teufel, J. Zhang, K. Oostermeijer, M. Bel-
lagente, J. Clune, K. Stanley, G. Schott, J. Lehman, Quality-diversity
through ai feedback, in: Proceedings of the 2nd Agent Learning in Open-
Endedness Workshop, in 37th Annual Conference on Neural Information
Processing Systems, 2023.
[32] X. Wu, Y. Zhong, J. Wu, K. C. Tan, As-llm: When algorithm selection
meets large language model, arXiv preprint arXiv:2311.13184 (2023).
[33] M. Pluhacek, A. Kazikova, T. Kadavy, A. Viktorin, R. Senkerik, Lever-
aging large language models for the generation of novel metaheuristic
optimization algorithms, in: Proceedings of the Companion Conference
on Genetic and Evolutionary Computation, 2023, pp. 1812–1820.
[34] A. AhmadiTeshnizi, W. Gao, M. Udell, Optimus: Optimization mod-
eling using mip solvers and large language models, arXiv preprint
arXiv:2310.06116 (2023).
[35] F. Liu, X. Tong, M. Yuan, X. Lin, F. Luo, Z. Wang, Z. Lu, Q. Zhang,
An example of evolutionary computation+ large language model beat-
ing human:
Design of efficient guided local search, arXiv preprint
arXiv:2401.02051 (2024).
[36] H. Bradley, H. Fan, T. Galanos, R. Zhou, D. Scott, J. Lehman, The
openelm library: Leveraging progress in language models for novel evo-
lutionary algorithms, in: Genetic Programming Theory and Practice XX,
Springer, 2024, pp. 177–201.
[37] D. Golovin, B. Solnik, S. Moitra, G. Kochanski, J. Karro, D. Sculley,
Google vizier: A service for black-box optimization, in: Proceedings of
the 23rd ACM SIGKDD International Conference on Knowledge Discov-
ery and Data Mining, Halifax, NS, Canada, August 13 - 17, 2017, ACM,
2017, pp. 1487–1495.
[38] H. Hao, A. Zhou, H. Zhang, An approximated domination relationship
based on binary classifiers for evolutionary multiobjective optimization,
in: 2021 IEEE Congress on Evolutionary Computation (CEC), IEEE,
2021, pp. 2427–2434.
[39] F. Li, X. Cai, L. Gao, W. Shen, A surrogate-assisted multiswarm op-
timization algorithm for high-dimensional computationally expensive
problems, IEEE transactions on cybernetics 51 (3) (2020) 1390–1402.
[40] D. R. Jones, M. Schonlau, W. J. Welch, Efficient Global Optimization of
Expensive Black-Box Functions, Journal of Global Optimization 13 (4)
(1998-12-01) 455–492.
[41] B. Liu, Q. Zhang, G. G. E. Gielen, A Gaussian Process Surrogate Model
Assisted Evolutionary Algorithm for Medium Scale Expensive Optimiza-
tion Problems, IEEE Transactions on Evolutionary Computation 18 (2)
(2014-04) 180–192.
[42] T. Chugh, Y. Jin, K. Miettinen, J. Hakanen, K. Sindhya, A surrogate-
assisted reference vector guided evolutionary algorithm for computation-
ally expensive many-objective optimization, IEEE Transactions on Evo-
lutionary Computation 22 (1) (2016) 129–142.
[43] Z. Song, H. Wang, C. He, Y. Jin, A kriging-assisted two-archive evo-
lutionary algorithm for expensive many-objective optimization, IEEE
Transactions on Evolutionary Computation 25 (6) (2021) 1013–1027.
[44] A. Zhou, J. Zhang, J. Sun, G. Zhang, Fuzzy-classification assisted so-
lution preselection in evolutionary optimization, in: Proceedings of the
AAAI conference on artificial intelligence, Vol. 33, 2019, pp. 2403–2410.
[45] F.-F. Wei, W.-N. Chen, Q. Yang, J. Deng, X.-N. Luo, H. Jin, J. Zhang,
A classifier-assisted level-based learning swarm optimizer for expensive
optimization, IEEE Transactions on Evolutionary Computation 25 (2)
(2020) 219–233.
[46] J. Zhang, A. Zhou, K. Tang, G. Zhang, Preselection via classification:
A case study on evolutionary multiobjective optimization, Information
Sciences 465 (2018-10) 388–403.
[47] H. Hao, X. Zhang, A. Zhou, Enhancing saeas with unevaluated solutions:
a case study of relation model for expensive optimization, Science China
Information Sciences 67 (2) (2024) 1–18.
[48] Y. Yuan, W. Banzhaf, Expensive multiobjective evolutionary optimiza-
tion assisted by dominance prediction, IEEE Transactions on Evolution-
ary Computation 26 (1) (2021) 159–173.
[49] H. Hao, A. Zhou, H. Qian, H. Zhang, Expensive multiobjective optimiza-
tion by relation learning and prediction, IEEE Transactions on Evolution-
ary Computation 26 (5) (2022) 1157–1170.
[50] H. Hao, X. Zhang, A. Zhou, Model uncertainty in evolutionary op-
timization and bayesian optimization: A comparative analysis (2024).
arXiv:2403.14413.
[51] A. Zhou, J. Sun, Q. Zhang, An estimation of distribution algorithm with
cheap and expensive local search methods, IEEE Transactions on Evolu-
tionary Computation 19 (6) 807–822.
[52] M. D. Mckay, R. J. Beckman, W. J. Conover, A Comparison of Three
Methods for Selecting Values of Input Variables in the Analysis of Output
From a Computer Code, Technometrics 42 (1) (2000-02) 55–61.
[53] M. AI, Meta llama 3, https://ai.meta.com/blog/meta-llama-3/
(2024).
[54] A. Q. Jiang, A. Sablayrolles, A. Roux, A. Mensch, B. Savary, C. Bamford,
D. S. Chaplot, D. d. l. Casas, E. B. Hanna, F. Bressand, et al., Mixtral of
experts, arXiv preprint arXiv:2401.04088 (2024).
[55] A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot,
D. d. l. Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, et al.,
Mistral 7b, arXiv preprint arXiv:2310.06825 (2023).
[56] M. Javaheripi, S. Bubeck, M. Abdin, J. Aneja, S. Bubeck, C. C. T.
Mendes, W. Chen, A. Del Giorno, R. Eldan, S. Gopi, et al., Phi-2: The
surprising power of small language models, Microsoft Research Blog
(2023).
[57] M. Abdin, S. A. Jacobs, A. A. Awan, et al., Phi-3 technical report: A
highly capable language model locally on your phone (2024). arXiv:
2404.14219.
[58] T. M. Gemma Team, C. Hardin, R. Dadashi, S. Bhupatiraju, L. Sifre,
14


--- Page 15 ---
M. Rivi`ere, M. S. Kale, J. Love, P. Tafti, L. Hussenot, et al., Gemma
(2024). doi:10.34740/KAGGLE/M/3301.
URL https://www.kaggle.com/m/3301
[59] OpenAI, Introducing gpt-3.5 series: text-davinci-002 and code-davinci-
002 models, https://platform.openai.com/, archived from the
original on March 20, 2023. Retrieved April 27, 2023. (2022).
[60] OpenAI, J. Achiam, S. Adler, et al., Gpt-4 technical report (2024).
arXiv:2303.08774.
[61] Ollama, Ollama’s github repository, accessed: 2024-04-28 (2024).
URL https://github.com/ollama/ollama
[62] W. Kwon, Z. Li, S. Zhuang, Y. Sheng, L. Zheng, C. H. Yu, J. Gonzalez,
H. Zhang, I. Stoica, Efficient memory management for large language
model serving with pagedattention, in: Proceedings of the 29th Sympo-
sium on Operating Systems Principles, 2023, pp. 611–626.
[63] S. Sivanandam, S. Deepa, S. Sivanandam, S. Deepa, Genetic algorithms,
Springer, 2008.
[64] N. Stander, K. Craig, On the robustness of a simple domain reduction
scheme for simulation-based optimization, Engineering Computations
19 (4) (2002) 431–450.
[65] F. Nogueira, Bayesian Optimization: Open source constrained global op-
timization tool for Python (2014–).
URL https://github.com/fmfn/BayesianOptimization
[66] Y. Tian, R. Cheng, X. Zhang, Y. Jin, PlatEMO: A MATLAB Platform for
Evolutionary Multi-Objective Optimization [Educational Forum], IEEE
Computational Intelligence Magazine 12 (4) (2017-11) 73–87.
[67] G. Chen, K. Zhang, X. Xue, L. Zhang, J. Yao, H. Sun, L. Fan, Y. Yang,
Surrogate-assisted evolutionary algorithm with dimensionality reduction
method for water flooding production optimization, Journal of Petroleum
Science and Engineering 185 (2020) 106633.
[68] C. Sun, Y. Jin, R. Cheng, J. Ding, J. Zeng, Surrogate-assisted coopera-
tive swarm optimization of high-dimensional expensive problems, IEEE
Transactions on Evolutionary Computation 21 (4) (2017) 644–660.
[69] J. Blanchard, C. Beauthier, T. Carletti, A surrogate-assisted cooperative
co-evolutionary algorithm using recursive differential grouping as decom-
position strategy, in: 2019 IEEE congress on evolutionary computation
(CEC), IEEE, 2019, pp. 689–696.
[70] M. Hollander, D. A. Wolfe, E. Chicken, Nonparametric Statistical Meth-
ods, John Wiley & Sons, 2013-11-25. arXiv:Y5s3AgAAQBAJ.
[71] Y. Wang, Z. Cai, Q. Zhang, Differential evolution with composite trial
vector generation strategies and control parameters, IEEE transactions on
evolutionary computation 15 (1) (2011) 55–66.
[72] S. McLeish, A. Bansal, A. Stein, N. Jain, J. Kirchenbauer, B. R. Bar-
toldson, B. Kailkhura, A. Bhatele, J. Geiping, A. Schwarzschild, et al.,
Transformers can do arithmetic with the right embeddings, arXiv preprint
arXiv:2405.17399 (2024).
15
