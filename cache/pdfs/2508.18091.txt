--- Page 1 ---
1
Teaching LLMs to Think Mathematically: A
Critical Study of Decision-Making via Optimization
Mohammad J. Abdel-Rahman, Senior Member, IEEE, Yasmeen Alslman, Dania Refai, Amro Saleh,
Malik A. Abu Loha, and Mohammad Yahya Hamed
Abstract—This paper investigates the capabilities of large
language models (LLMs) in formulating and solving decision-
making problems using mathematical programming. We first
conduct a systematic review and meta-analysis of recent literature
to assess how well LLMs understand, structure, and solve
optimization problems across domains. The analysis is guided
by critical review questions focusing on learning approaches,
dataset designs, evaluation metrics, and prompting strategies.
Our systematic evidence is complemented by targeted experi-
ments designed to evaluate the performance of state-of-the-art
LLMs in automatically generating optimization models for prob-
lems in computer networks. Using a newly constructed dataset,
we apply three prompting strategies: Act-as-expert, chain-of-
thought, and self-consistency, and evaluate the obtained outputs
based on optimality gap, token-level F1 score, and compilation
accuracy. Results show promising progress in LLMs’ ability to
parse natural language and represent symbolic formulations, but
also reveal key limitations in accuracy, scalability, and inter-
pretability. These empirical gaps motivate several future research
directions, including structured datasets, domain-specific fine-
tuning, hybrid neuro-symbolic approaches, modular multi-agent
architectures, and dynamic retrieval via chain-of-RAGs. This
paper contributes a structured roadmap for advancing LLM
capabilities in mathematical programming.
Index Terms—Linear programming, combinatorial optimiza-
tion, large language models, fine-tuning, in-context learning,
retrieval-augmented generation.
ACRONYMS
LLM
large language model
NLP
natural language processing
GPT
generative pre-trained transformer
OR
operations research
CoT
chain-of-thought
GNN
graph neural network
TSP
traveling salesman problem
RL
reinforcement learning
VRP
vehicle routing problem
RAG
retrieval-augmented generation
LP
linear programming
MILP
mixed-integer LP
M. J. Abdel-Rahman is with the Data Science Department, Princess Sumaya
University for Technology, Amman 11941, Jordan. He is also with the
Electrical and Computer Engineering Department, Virginia Tech, Blacksburg,
VA 24061 USA.
Y. Alslman and A. Saleh are with the Computer Science Department,
Princess Sumaya University for Technology, Amman 11941, Jordan.
D. Refai is with the Computer Science Department, King Fahd University
of Petroleum and Minerals, Dhahran 31261, Saudi Arabia.
M. A. Abu Loha and M. Yahya Hamed are with the Data Science
Department, Princess Sumaya University for Technology, Amman 11941,
Jordan. They have equal contributions.
UAV
unmanned aerial vehicle
LPWP
LP word problems
LoRA
low-rank adaptation
ToT
tree of thoughts
SMT
satisfiability modulo theories
GoT
graph of thoughts
JSS
job shop scheduling
CoE
chain-of-experts
MoE
mixture of experts
CP
constraint programming
QP
quadratic programming
I. INTRODUCTION
I
N recent years, large language models (LLMs), such as
generative pre-trained transformer (GPT) and DeepSeek,
have shown remarkable advancements in the field of natural
language processing (NLP). These sophisticated models are
designed to understand and generate human language, enabling
them to perform a wide range of tasks. As a result, LLMs
have been applied to various applications that enhance our
interactions with technology, such as text generation, question
answering, summarization, and other tasks [1].
The remarkable capability of LLMs propels researchers
to harness their potential in revolutionizing various domains,
including healthcare [2] and mathematical reasoning [3]. By
training LLMs on domain-specific tasks, their potential to
tolerate various challenges continues to expand, driving in-
novation across different industries. By using sophisticated
tuning, LLMs leveraged the effectiveness of many domains,
such as clinical settings, educational, and research work in
healthcare systems. Additionally, LLMs demonstrate a surge
in code generation [4] and mathematical reasoning for solv-
ing math word problems and geometry, and even providing
mathematical proofs.
Operations research (OR) problems arise in various do-
mains, including supply chain, finance, networking, and many
others. Mathematical modeling plays a crucial role across
various industries by enabling companies to analyze complex
systems, predict outcomes, and optimize decision-making pro-
cesses. Mathematical models help improve efficiency, reduce
costs, and increase competitiveness. For example, in supply
chain management, models are used to optimize inventory
levels and transportation routes; in finance, they support risk
assessment and investment strategies.
Recognizing its value, many companies invest heavily in
developing and implementing optimization solutions, often
arXiv:2508.18091v1  [cs.AI]  25 Aug 2025


--- Page 2 ---
2
allocating millions of dollars annually for research, soft-
ware tools, and expert consultation. Finding optimal solutions
through mathematical modeling is a complex process that
requires deep expertise in the specific problem domain, a
strong understanding of the underlying data, solid mathemati-
cal foundations, and effective deployment skills to ensure the
model can be successfully integrated and utilized within the
company. Consequently, global spending on OR and analytics
is estimated to exceed several billion dollars per year, high-
lighting the importance of mathematical modeling in driving
innovation and operational industries.
Unlike the common tasks that LLMs are used in, OR
problems involve more than text generation and information
retrieval. The objective of LLMs when approaching OR prob-
lems is to correctly formulate and find the optimal solution
for a given problem. This includes dealing with both textual
and numerical data. Additionally, optimality, feasibility, and
computational efficiency are key factors to be measured in any
generated solution, which pose different challenges compared
to original measures, such as relevance, accuracy, and fluency.
LLMs demonstrate potential proficiency in solving OR
problems, enabling OR practitioners to streamline problem
formulation, enhance decision-making, and make optimiza-
tion techniques more intuitive and accessible. As a result,
the research into the synergy between LLMs and OR has
accelerated. This paper aims to provide an in-depth review
of utilizing LLMs for mathematical modeling in terms of
the type of mathematical problems, their domain, the main
approach followed to leverage the LLMs’ capability in solving
these mathematical problems, and the type of LLMs utilized.
Furthermore, in this paper, we conduct a meta-analysis on the
key factors that affect the process of using LLMs for gener-
ating mathematical models. Finally, this paper complements
the provided systematic evidence with targeted experiments
designed to evaluate the capabilities of state-of-the-art LLMs
in formulating optimization models for problems in computer
networks, showing promising progress in LLMs’ ability to
parse natural language and represent symbolic formulations,
but also revealing key limitations in accuracy, scalability, and
interpretability. These empirical gaps motivate several future
research directions.
Main Contributions:
Our main contributions can be summarized as follows:
• Conduct a review on utilizing LLMs for mathematical
modeling. Exclusion criteria are applied to papers col-
lected from five digital libraries: IEEE, Springer, ACM,
ScienceDirect, and arXiv. The resulting 51 papers are
reviewed comprehensively. Furthermore, we present an
overview covering all stages of utilizing LLMs for gener-
ating mathematical models, from identifying the domain
of the targeted problem to assessing the LLM-generated
solution.
• Perform a meta-analysis based on a set of critical review
questions to gain a deep and structured understanding of
current trends in using LLMs for mathematical modeling.
The review questions are centered around the learn-
ing approaches adopted, the types of datasets used, the
evaluation metrics applied, and the prompt engineering
strategies employed. The generated visualizations are
used to identify dominant gaps in the literature and
potential synergies between techniques, thereby laying
a data-driven foundation for selecting the most effective
methods in our experimental framework.
• Design and conduct experiments to examine the capa-
bilities of LLMs in formulating optimization models for
problems in computer networks. Driven by our meta-
analysis, we adopt the most prevalent approaches for
employing LLMs (specifically, DeepSeek and GPT-4o) in
automatic mathematical modeling: (i) Constructing a new
domain-specific dataset, (ii) applying three widely used
prompt engineering strategies: Act-as-expert, chain-of-
thought (CoT), and self-consistency, and (iii) evaluating
the results using the most commonly accepted perfor-
mance metrics.
• Shed light on the future directions and challenges facing
LLM-based mathematical modeling. We identify two
main areas for future research and provide actionable
directions. Specifically, we propose directions for (i)
enhancing LLM learning and mathematical reasoning
capabilities, as well as directions for (ii) developing
methodologies for better understanding and diagnosing
LLM limitations.
This paper not only helps researchers contribute toward
leveraging the process of automating formulation of OR
problems but also provides actionable insights on how to
deploy LLMs in diverse business domain-specific areas, supply
chains, finance, energy, communications, and others.
Research Questions:
The primary objective of this survey is to identify and
analyze articles that employ LLMs for generating mathemat-
ical models. In light of this objective, the following research
questions are formulated:
• What are the most commonly used LLMs for generating
mathematical models?
• To what extent are LLMs capable of generating mathe-
matical models?
• What is the best approach to be used when utilizing an
LLM for formulating mathematical models?
• What are the current challenges and limitations of utiliz-
ing LLMs in mathematical modeling?
• What are the main future directions to enhance the LLMs’
capabilities in mathematical modeling?
Paper Organization:
The rest of this paper is organized as follows: In Section II,
we provide an overview of existing surveys on related areas.
Section III outlines the general steps for utilizing LLMs
in generating mathematical models and presents our paper
review protocol. Sections IV and V offer a review of the
existing literature on LLM-based mathematical modeling. In
Section VI, we conduct a meta-analysis based on critical
review questions. Key limitations and opportunities for LLMs


--- Page 3 ---
3
in mathematical modeling are discussed in Section VII. We
examine the capabilities of LLMs in addressing domain-
specific problems in Section VIII. Our future directions are
elaborated in Sections IX and X. Finally, in Section XI,
we present our concluding remarks for this paper. A visual
representation of the structure of the paper is provided in Fig. 1
for more clarity.
II. RELATED SURVEYS
The synergy of LLMs in different domains has led to
remarkable development. As a result, researchers have made
notable efforts in providing several surveys that explore LLM
applications in various fields. To the best of our knowledge, no
prior work has directly explored the use of LLMs for solving
mathematical optimization problems. However, related efforts
can be found under broader categories such as mathematical
reasoning and general problem-solving with LLMs. Recently,
the research on utilizing LLMs in modeling mathematical
optimization problems has been accelerated significantly, and
there has been no dedicated study that offers a comprehensive
overview of LLMs utilization in formulating mathematical op-
timization problems. In this section, we aim to summarize sur-
veys on mathematical reasoning and related subjects, including
graph learning and optimization algorithms, to contextualize
our study.
A. LLMs in Mathematical Reasoning
Although mathematical reasoning and mathematical mod-
eling are strongly interconnected, there are key differences
between them. Mathematical reasoning is an abstract concept
that focuses on logically analyzing and proving mathematical
truths using proof techniques and algebraic manipulations. In
contrast, mathematical modeling applies these mathematical
concepts to represent real-world problems using equations.
Our review is particularly concerned with mathematically
modeling real-world, often constrained, decision-making prob-
lems, aiming to achieve one or multiple objectives, a.k.a.
mathematical programming.
Several surveys have focused on the role of LLMs in math-
ematical reasoning, showing their capabilities to solve arith-
metic problems and prove theorems. Ahn et al. [5] categorized
mathematical problems faced by LLMs into arithmetic, math
word, geometry problems, and automated theorem proving.
Additionally, the authors discussed the challenges of formal
proof generation, logical reasoning, and handling complex
symbolic representations. Liu et al. [6] provided a broader
taxonomy of mathematical LLMs, including instruction-based
learning, tool-assisted problem solving, and CoT reasoning ap-
proaches. Their survey highlighted over 60 benchmark datasets
used for evaluating LLMs in mathematical tasks.
B. LLMs in Graph Learning and Optimization
Beyond symbolic mathematics, researchers have explored
how LLMs interact with graph-based problems, including
graph learning and graph optimization. Graph learning is a
field that aims to gain useful information and patterns using
machine learning (ML) and other techniques from data that is
represented as a graph. Node classification, edge prediction,
and graph clustering are considered the main common tasks
in graph learning. In graph optimization, the main objective is
to find the best solution to problems modeled as graphs.
Chen et al. [7] focused on the synergy between LLMs
and graph neural networks (GNNs); they explored the use
of an LLM as an encoder and as a predictor for the node
classification tasks. When utilizing LLMs as an encoder, they
are used to pre-process the text attributes, and then GNNs are
trained on the enhanced attributes as predictors. However, they
overlooked the importance of using LLMs to solve pure graph
problems, which refer to classical graph-theoretic tasks such as
the traveling salesman problem (TSP), shortest path problem,
and minimum cut problem, where the objective is to directly
reason over graph structures without relying on external textual
attributes or paired information. These problems are typically
formulated as combinatorial optimization problems and often
require rigorous mathematical modeling to identify optimal
or near-optimal solutions. Ignoring this dimension limits the
exploration of how LLMs could contribute not only to graph
representation and reasoning but also to bridging optimization
techniques with mathematical formulations of complex graph
problems.
Ren et al. [8] provided a comprehensive review of LLMs in
graph learning tasks, discussing four main aspects: GNNs as a
prefix, LLMs as a perfix, fusion models, and applying LLMs
directly on graph tasks. Using GNNs as a prefix refers to
applying GNN as a preliminary step for processing a specific
graph, after which the structural tokens are input into LLMs.
Similar to [7], the authors discussed LLMs as a prefix for
providing initial embeddings or labels for GNNs, which is the
same as using LLMs as encoders. They also covered fusion
models where LLMs are combined with GNNs, as well as
the direct use of LLMs in tasks like node classification and
spatio-temporal graph representation. Once again, the authors
did not adequately cover the LLM’s capability in solving pure
graph problems, which require mathematical modeling and
optimization rather than representation learning alone.
Jin et al. [9] categorized graph scenarios where LLMs are
applicable into pure, text-attributed, and text-paired graphs.
In a text-attributed graph, each node or edge is associated
with textual attributes or labels, while the primary structure
remains the graph itself. When graphs are combined with
external textual data, such as documents, sentences, or para-
graphs, this is referred to as text-paired graphs. Moreover, they
classified the proposed three techniques for applying LLMs:
LLM as a predictor, LLM as an encoder, and LLM as an
aligner. Although they offered a comprehensive taxonomy
of pure graphs, which can be addressed as an optimization
problem through mathematical modeling. They inadequately
explore graph representations, such as edge verbalization and
adjacency lists.
C. LLMs in Optimization Algorithms
Ma et al. [10] provided a comprehensive review of meta-
black-box optimization (MetaBBO), categorizing the role of


--- Page 4 ---
4
Introduction
Related Surveys
LLMs in Mathematical Reasoning
LLMs in Graph Learning and
Optimization
LLMs in Optimization Algorithms
Mathematical Modeling Frame-
work and Review Protocol
Mathematical Modeling Frame-
work
Review Protocol
Mathematical Modeling via Fine-
tuning
RAG-based Approaches
Dataset-driven Approaches
Mathematical Modeling via In-
context Learning
RAG-based Approaches
Dataset-driven Approaches
Meta-analysis
Dataset Construction
LLM Learning
Model Evaluation
Limitations and Opportunities for
LLMs in Mathematical Modeling
Empirical Insights from Meta-
analysis
Limitations and Opportunities
from Literature
Answering Research Questions
Experimental Design and Results
Experimental Design
Experimental Results
Enhancing LLM Learning
and Mathematical Reasoning
Capabilities
Training Specialized LLMs with
Structured Datasets
Modular Use of Multiple LLMs
Chain of RAGs
Improving Prompting Strategies
Neuro-symbolic Formulation in
Mathematical Optimization
Understanding and Diagnosing
LLM Limitations
Designing Better Evaluation
Metrics
Feature Mapping for Failure
Analysis
Conclusion
Fig. 1: Paper organization.
LLMs in algorithm selection, configuration, and automated
problem formulation. They reviewed reinforcement learn-
ing (RL), supervised learning, and in-context learning tech-
niques to optimize computational efficiency and solve complex
OR problems. These contributions indicate the growing role
of LLMs in automating and optimizing mathematical and
decision-making problems, a core aspect of OR.
Tao et al. [11] presented how deep learning (DL) and artifi-
cial intelligence (AI) in general have been deployed for com-
binatorial optimization. It traces the evolution from traditional
methods, such as branch-and-bound and simulated annealing,
which struggle with large-scale problems, to modern DL-
based approaches that now rival or even outperform profes-
sional solvers in specific scenarios. The paper categorizes DL
methods based on problem types, e.g., TSP, vehicle routing
problem (VRP), model architecture, e.g., GNNs, transformers,
and training strategies, e.g., supervised, reinforcement, and
unsupervised learning, highlighting recent innovations, such as
chaotic backpropagation and prompt-based optimization using
LLMs.
Table I presents a comparison of related surveys on LLM
capabilities in mathematical modeling, focusing on their
methodological approach, scope of applications, and the roles
assigned to LLMs. The last two columns highlight the key
distinctions between their findings and the contributions of
our work.
III. MATHEMATICAL MODELING FRAMEWORK AND
REVIEW PROTOCOL
In this section, we first discuss the LLM-driven mathemat-
ical modeling framework, outlining the key steps involved
in leveraging the capabilities of LLMs for automating math-
ematical modeling. Then, we present our adopted protocol
for collecting and reviewing papers related to mathematical
modeling using LLMs.
A. Mathematical Modeling Framework
The first step in using LLMs for solving mathematical
problems is to establish the scope of the knowledge and the
type of data that will be collected by determining the specific
domain of interest (e.g., networking, healthcare, telecom-
munication, economics, etc.). The second step involves es-
tablishing a theoretical framework to address the domain-
specific problem, enabling the capture of relationships between
entities, concepts, or events. At this stage, the problem may be
formulated using graph theory, game theory, or mathematical
programming. Considerable research has explored the use of
LLMs for solving graph-based problems, as discussed in [7],
[9]. Game-based problems have received comparatively less
attention, with only a few studies such as [12]–[14]. In this
paper, we focus on the mathematical programming framework.


--- Page 5 ---
5
TABLE I: Overview of surveys that explore LLM applications in various fields. To the best of our knowledge, our paper is
the first to survey the synergy between LLMs and mathemtical optimization.
Survey
Focus area
Methodology
used
Scope of
application
Use of LLMs
Relation to
optimization
Ahn et
al. [5]
Mathematical
reasoning
Performance
analysis
Theorem
proving,
problem-
solving
Reasoning
Not discussed
Liu et
al. [6]
Mathematical
reasoning
Categorization
Datasets,
problem-
solving
Mathematical
calculation and
mathematical
reasoning
Not discussed
Ren et
al. [8]
Graph learning
tasks
Literature review
and novel
taxonomy
How LLMs are
applied in
graph-based
learning
Integration
with GNNs
Not discussed
Jin et
al. [9]
Graph-based LLM
applications (LLM
as predictor, LLM
as encoder, and
LLM as aligner)
Taxonomy
creation and
systematic review
of scenarios and
techniques of
utilizing LLMs
with graphs
Graph-
structured data
Classification
Not discussed
Chen et
al. [7]
LLMs in graph
learning
Empirical study
Graph-based
prediction
Attribute
enhancement
Not discussed
Ma et
al. [10]
Automated
algorithm design
Meta-learning
review
Evolutionary
algorithms
Meta-learning
for
optimization
Mentioned but
not primary
Peng et
al. [11]
Combinatorial
optimization
Literature review
Combinatorial
algorithms
Reasoning
Mentioned
The third step is dataset construction, and it is a crucial step
for building a knowledge base that can be used in LLM train-
ing. There are two main approaches for using the data: Either
by constructing a typical dataset that requires preprocessing
techniques or by using the retrieval-augmented generation
(RAG) approach. To ensure that the collected data is ready to
be used when considering a typical dataset, data preprocessing
is considered to clean the data. On the other hand, when
using RAG, the data is broken into chunks, making it ready
for use by downstream tasks (calculating the embeddings).
Data augmentation is an optional step that can be used to
increase the size of the knowledge base when considering the
use of a typical dataset. Data augmentation can be considered
depending on the performance of LLMs. The data is then
fed to the LLM for fine-tuning or in-context learning. After
training the LLM, the end user can interact with the LLM via
prompts, and prompt optimization techniques are employed to
optimize responses. The LLM-driven mathematical modeling
framework is depicted in Fig. 2.
B. Review Protocol
In this subsection, we present (i) the search queries and
strings used to collect papers related to mathematical mod-
eling using LLMs, (ii) the paper exclusion criteria applied
to exclude irrelevant papers, and (iii) the review questions
utilized to comprehensively review the selected papers. We
defined review questions related to each step of the LLM-
driven mathematical modeling framework.
TABLE II: Search strings.
S1
((large language model) OR (natural language processing))
AND ((mathematical modeling) OR (operations research)
OR (mathematical programming) OR (optimization
modeling))
S2
((LLM) OR (large language model) OR (natural language
processing)) AND ((mathematical optimization) OR
(mathematical modeling) OR (operations research) OR
(mathematical programming) OR (linear programming) OR
(optimization modeling))
S3
((LLM) OR (large language model) OR (generative AI) OR
(natural language processing)) AND ((mathematical
optimization) OR (mathematical modeling) OR (operations
research) OR (mathematical programming) OR (linear
programming) OR (optimization modeling))
1) Search Queries and Strings: The keywords used for
the initial search can be divided into two main groups: The
first is related to the LLMs (large language model, generative
AI, natural language processing), whereas the second one is
related to mathematical modeling (mathematical modeling,
operations research, mathematical programming, linear pro-
gramming, optimization modeling, mathematical optimization,
auto formulation).
The search queries shown in Table II were used to retrieve
all 61 papers from five digital libraries, IEEE, Springer, ACM,
ScienceDirect, and arXiv.
2) Paper Exclusion Criteria: The following exclusion cri-
teria were then applied to exclude irrelevant papers:


--- Page 6 ---
6
 
Prompt
Dataset
Preprocessing
Embeddings 
Dataset construction
(knowledge base)
LLM learning
Fine-tuning 
Embedding
Find similarity
Data
augmentation
Few-shots
Zero-shot
Best-shot
Chain-of-
expert
Chain-of-
thoughts
In-context
Formulation generation
Code generation
Domain
End users
RAG
Fig. 2: General framework steps. The process begins by determining the main domain, followed by establishing a theoretical
framework for problem representation. A dataset or knowledge base is then created to support LLM learning through in-context
learning or fine-tuning. Finally, the LLM generates a mathematical formulation, possibly including solver code, using either a
standard or optimized prompt.
• Papers that did not use LLMs specifically for modeling
mathematical optimization problems: Our main objective
is to provide an in-depth review of papers that utilize
LLMs to tackle mathematical optimization problems.
• Survey or review papers: Our objective is to analyze
primary research contributions rather than resummarizing
existing reviews.
• Short papers, letters, or comment papers: These formats
often lack detailed methodological descriptions and thor-
ough experimental evaluations, making them unsuitable
for in-depth review.
The following subsections outline sets of review questions
aligned with the steps described in the previous subsection and
depicted in Fig. 2.
3) Domain Determination and Problem Representation Re-
view Questions: As the first step is to determine the domain
and the representation of the problem, the following review
questions were used when reviewing the final set of papers.
RQ1: What is the primary domain of the problem?
A1: This question is essential to study the primary domain
studied across the literature. The answer to this question
allows for classifying the problem into one of the fol-
lowing domains: (i) Linear programming (LP) problems,
(ii) combinatorial problems, which include integer LP
(ILP) and mixed-integer LP (MILP) problems, and (iii) a
combination of both linear and combinatorial problems.
Identifying the domain provides clarity on the mathe-
matical structures, methodologies, and algorithms most
suitable for addressing the problem at hand.
RQ2: What type of optimization problems is being addressed?
A2: Identifying the type of optimization problem that is
being addressed can help in determining the complexity
of the problem. Additionally, the problems differ in their
structure, constraints, and objectives, which influence the
choice of solution techniques. The possible optimiza-
tion problems include general optimization problems,
wireless optimization problems, scheduling problems,
resource allocation problems, unmanned aerial vehicle
(UAV) optimization problems, data center networking,
and business optimization problems.
4) Dataset Construction Review Questions: This subsection
presents the review questions related to the process of prepar-
ing the data for use by the LLMs.
RQ3: What is the name of the used dataset?
A3: The used datasets can directly affect the capability
of the LLMs to solve complex optimization prob-
lems. Many datasets can be used by LLMs, in-
cluding NL4Opt [15], LP word problems (LPWP),
Mamo [16], IndustryOR [17], NLP4LP [18], Com-
plexOR [19], OptiBench [20], StarJob [21], ReSo-
cratic [20], GSM8K [22], Big-Bench Hard (BBH) [23],
StructuredOR [24], Cycle Share [25], DiDi oper-
ational [26], Pyomo Cookbook [27], AQUA [28],
Ner4Opt [29], Scientific variable extraction bench-


--- Page 7 ---
7
mark [30], and MultiArith [31]. In some studies, the
authors developed their own datasets.
RQ4: What is the size of the used dataset?
A4: The size of the dataset also has a direct impact on the
LLMs learning process. The answer to this question
outlines the size used.
5) LLM and Solver Determination Review Questions: This
subsection presents the review questions related to LLMs
learning.
RQ5: What is the name of the used LLM?
A5: In recent years, there have been many LLMs that can
be used for different tasks, each with its benefits. The
type of LLMs can be determined by one of the follow-
ing: GPT-2, GPT-3, GPT-3.5, GPT-4, Mistral, Llama,
DeepSeek, Qwen, PaLM, Zephyr, Phi, CodeRL, Mixtral,
Falcon, and Claude.
RQ6: What types of solvers and modeling languages are used
in the study?
A6: In the literature, LLMs are utilized not only for gener-
ating the mathematical formulations of specific prob-
lems but also for generating the corresponding code.
This code is tailored for specific solvers, meaning the
types of solvers adopted by the LLMs, which include
CPLEX [32], Gurobi [33], Google’s OR-Tools [34],
satisfiability modulo theories (SMT) [35], OptVerse [36],
COPT [37], and SCIP [38]. In certain situations, the
solver may not be specified. These solvers were adopted
using different modeling languages, including MiniZinc,
MAPL code, Pyomo, CPMpy, PuLP, Zimpl, and AMPL.
RQ7: Which approach does the study use to adapt LLMs?
A7: Adapting an LLM to a specific task or domain is a
critical step in leveraging its capabilities effectively. The
study may employ one of the following approaches:
Using a dataset for in-context or fine-tuning, or using
the RAG approach. Each approach has its trade-offs in
terms of cost, complexity, and adaptability.
6) LLM Learning Review Questions: This subsection out-
lines the review questions concerning the chosen learning
paradigm for the LLMs.
RQ8: What are the approaches used to adapt LLMs for new
tasks?
A8: Generally, there are two main approaches: Fine-tuning
and in-context learning.
7) Model Evaluation Review Questions: This subsection
presents the review questions related to the evaluation process
of the models generated by LLMs.
RQ9: What evaluation metrics are used to assess the quality
of LLM-generated optimization formulations?
A9: The evaluation of LLM-generated formulations can
be
structured
into
several
categories.
Firstly,
the
category of solution quality evaluates how far the
obtained solution is from the best-known or optimal
value. This is measured through solution accuracy,
optimality gap, and relative regret, which all quantify
the deviation between the obtained solution and the
optimum, as well as the average improvement ratio
(AIR), among each benchmark it compares how far
the LLM-generated formulation is from the best-known
optimum relative to a human-designed heuristic; values
below 1 mean the generated formulation is closer
to the optimum on average, around 1 means similar
performance, and above 1 means worse. The second
category, surface-form accuracy, examines how well
the generated text matches the reference formulation.
This is assessed at the token level using precision (the
fraction of generated tokens that are correct), recall (the
fraction of required tokens that appear in the output),
and their harmonic mean, the F1-score.
The third category, buildability and runtime robustness,
examines whether the generated code can run reliably in
practice. Buildability is assessed through compilation
accuracy, which checks whether the code parses
correctly and is accepted by the solver without syntax
or schema errors. Runtime robustness is then measured
by the execution rate, defined as the proportion of
compilable runs that complete successfully without
runtime errors or crashes. A related category, feasibility
or model soundness, goes one step further by verifying
whether compiled runs produce solver-feasible outputs,
quantified by the feasibility pass rate.
Efficiency
and
search
effectiveness
form
another
category, which captures different aspects of solver
performance. Efficiency reflects how quickly the solver
delivers high-quality results. It is measured by the
average solving time or running time, where shorter
times indicate better performance, and by convergence
performance, which evaluates how rapidly solution
quality improves, for example, the time required to
reach a predefined quality level such as achieving an
objective value within 1% of the best-known solution.
Search effectiveness, in contrast, measures the system’s
ability to identify valid solutions. A common metric is
Valid@k within time t, which checks whether at least
one of the top-k generated solutions is valid within a
specified time limit.
Additional
metrics
capture
broader
aspects
of
quality. Domain utility outcomes measure real-world
effectiveness using utility improvement metric in the
problem’s native units (e.g., Mbps, dollars, or minutes),
compared against a baseline or the best-known result.
For
multi-objective
problems,
hypervolume
(HV)
quantifies the extent of objective space covered by the
produced Pareto set, whereas inverted generational
distance (IGD) measures the closeness of the produced
set to the reference front.
Another category is mathematical fidelity, which checks
whether the LLM-generated formulation expresses the
same mathematics as the original formulation. We
use two measures. Integrity gap (structure): which
shows how different the building blocks and their
connections are compared with the original counts and


--- Page 8 ---
8
types of variables and constraints, and which variables
appear in which constraints. Report it so that 0 means
identical structure and larger values mean a worse
match. Semantic
similarity Evaluates whether the
two formulations express the same meaning even if
written differently; in practice, this can be computed
via (i) embedding-based similarity between normalized
formulations or (ii) an LLM-judge that decides whether
predicted elements semantically match the original and
then summarizes with precision, recall, and F1.
Finally, human-centered evaluation complements these
quantitative metrics with expert qualitative assess-
ments, focusing on aspects such as clarity, maintain-
ability, and practical usefulness.
In the following two sections, we comprehensively review
the fine-tuning and in-context learning based studies, respec-
tively.
IV. MATHEMATICAL MODELING VIA FINE-TUNING
Mathematical programming is essential in solving complex
optimization problems across various domains. As mentioned
earlier, LLMs demonstrate exceptional capabilities across var-
ious domains due to their reasoning abilities. While their
general-purpose capabilities are powerful, adapting LLMs to
the complexities of mathematical programming often requires
refinement. In this context, fine-tuning can be used to refine
pre-trained models such as LLMs to specialize in mathematical
programming tasks by learning from domain-specific data.
Fine-tuning takes the model’s previous knowledge as a starting
point and refines its performance in specific tasks such as solv-
ing LP, integer programming (IP), or even MILP problems.
Fine-tuning can be very expensive in terms of computational
resources, making it a less preferable approach. However,
researchers have developed strategies to reduce the computa-
tional cost of fine-tuning by using lightweight adapters such as
low-rank adaptations (LoRAs) and similar techniques. These
methods allow models to adapt efficiently without retraining
all parameters, thereby significantly lowering resource require-
ments.
This section explores the role of fine-tuning in trans-
forming LLMs into tools for mathematical programming. It
highlights how fine-tuning enhances the ability of LLMs to
solve optimization problems effectively. Across the literature,
researchers have identified the need for a comprehensive
knowledge base to fine-tune pre-trained models effectively.
This knowledge base, tailored to the specific domain in which
the model is intended to specialize, can be constructed through
two primary approaches: RAG techniques or utilizing a super-
vised dataset. As a result, we categorized the literature based
on how they build their knowledge base. LP, IP, and MILP
differ significantly in terms of the computational complexity
and the effort required for any model to solve them, primarily
due to the nature of their constraints and variables. Thus, we
further classify the literature based on the type of optimization
problem that has been addressed, as shown in Fig. 3.
A. RAG-based Approaches
RAG serves as a powerful mechanism to enhance LLM’s
ability to tackle M/ILP problems by retrieving relevant
domain-specific knowledge, such as constraints, problem for-
mulations, and solution techniques, from an external knowl-
edge base. RAG can be used with fine-tuning. The LLM is
first fine-tuned for a specific domain. Then, RAG provides the
context that fills gaps in the fine-tuned model’s understanding,
especially for uncommon or highly specific tasks.
To the best of our knowledge, one study has considered
using RAG to leverage the capabilities of LLMs in mathe-
matical modeling [39]. Liu et al. [39] used RAG for data
center networking in solving and formulating optimization
problems. Their study demonstrates the fundamentals of using
LLMs for automatic formulations and presents the data center
networking problems as a case study. Table III summarizes
the main findings of the related literature.
B. Dataset-driven Approaches
Recently, researchers have proposed several benchmarks
and datasets designed to facilitate the ability of LLMs to solve
mathematical problems. Each of these datasets is characterized
by distinct properties, as detailed in Table IV. The most com-
mon dataset is NL4Opt, which is used for a competition aimed
at automating the process of mathematical modeling. This
dataset comprises 1, 101 annotated LPWPs sourced from six
distinct domains: Sales, advertising, investment, production,
transportation, and sciences. Each problem from the NL4Opt
dataset has approximately two constraints and two decision
variables.
In [18], the authors constructed a similar dataset, NLP4LP,
a comprehensive open-source dataset containing 355 opti-
mization problems, designed to provide broad coverage of
various problem types. It integrates problems from existing
datasets alongside newly introduced ones, ensuring diversity in
complexity and description length. The dataset includes real-
world optimization problems that are significantly longer than
those found in other MILP modeling datasets.
Tang et al. [17] proposed a more challenging dataset for
LLMs. This dataset consists of 100 real-world problems re-
flecting the complexity and diversity encountered in industrial
settings. Similarly, Xiao et al. [64] constructed a dataset
consisting of 37 problems from diversified sources, including
academic papers, textbooks, and real-world industry scenarios.
These problems cover a wide range of subjects, spanning
from supply chain optimization and scheduling problems to
warehousing logistics. The Mamo dataset proposed by Huang
et al. [16] consists of two main types of problems: 196
ordinary differential equations (ODEs) and 863 optimization
problems. What makes this dataset stand out is its integration
with mathematical solvers.
Unlike previous datasets, OptiBench developed in [20] pro-
vides both linear and nonlinear optimization instances. Other
datasets, such as StructuredOR [47], DiDi operational [45],
and Cycle share [25], are not as popular as the other datasets.
It is worth noting that many researchers constructed and used


--- Page 9 ---
9
LLM-based optimization
modeling approaches
Optimization modeling via
fine-tuning
RAG-based
Combinatorial
[39]
Data-driven
Combinatorial
[20], [40], [41]
[21], [42], [43]
[24], [44], [45]
Combinatorial
and linear
[17], [46], [47]
[48]
Linear
[29], [49]
Optimization modeling via
in-context learning
RAG-based
Combinatorial
[18], [50], [51]
Data-driven
Combinatorial
[18], [30]
[52]–[62]
[20], [63], [64]
[25], [65]–[67]
Combinatorial
and linear
[17], [18], [68]
[46], [69]–[71]
Linear
[29], [72]–[75]
Fig. 3: Taxonomy of LLM-based optimization modeling approaches.
TABLE III: Combinatorial optimization modeling via fine-tuning using RAGs.
Study
RQ2
RQ3
RQ4
RQ5
RQ9
Main findings
[39]
Data center
networking
Raw data
–
GPT-4
Optimality
gap
Presented a case study composed of two
modules: Automatic optimization formulation
and diffusion-empowered optimization solving.
TABLE IV: Datasets.
Dataset
Size
Year
List of Papers
NLP4LP
355
2024
[18], [44], [47]
NL4Opt
1011
2021
[17], [18], [46], [47],
[67], [76]
ComplexOR
37
2024
[18], [44], [47], [64],
[65]
IndustryOR
100
2024
[17], [67]
OptiBench
605
–
[20]
Mamo
863
2024
[17], [47]
StructuredOR
124
–
[47]
DiDi
operational
12, 500
2016
[45]
StarJob
120, 000
2024
[21]
Cycle share
283, 143
2024
[25]
ReSocratic
29, 000
2024
[20]
Pyomo
Cookbook
40
2018
[52]
GSM8K
8500
2021
[77]
MultiArith
600
2016
[55]
AQuA
100000
2017
[52]
BBH
23
2022
[52]
Ner4Opt
1101
2023
[29]
Their own
–
–
[40], [43], [46], [49],
[50], [68]
their own datasets. These datasets are usually designed to solve
problems related to a specific and specialized field.
1) Combinatorial Optimization: Recent studies have ex-
plored the capabilities of LLMs in addressing combinatorial
optimization. A common approach across these works involves
fine-tuning LLMs on domain-specific datasets, such as StrJob,
ReSocratic [20], OptiBench, and StructuredOR, which were
specifically designed to convert structured optimization prob-
lems into natural language formats suitable for LLMs learning.
These models, including GPT, Llama, Phi3, and Qwen, have
been evaluated using various techniques such as zero-/few-shot
prompting, CoT reasoning, and RL.
Findings consistently indicate that LLMs can be used to
solve simple tasks, such as job shop scheduling, binary
packing, and automated model generation. Fine-tuning strate-
gies, such as LoRA, parameter-efficient tuning (PEFT), and
progressive fine-tuning, were shown to significantly enhance
performance, especially when combined with methods such as
temperature scaling and tree of thoughts (ToT) reasoning.
Notably, LLMs tend to perform better on simple linear
problems, while challenges remain in solving highly non-linear
complex tasks. Almost all studies leveraged LLMs to generate
executable algorithm code, highlighting their potential not
just as solvers but as meta-reasoners capable of producing
optimization strategies. Overall, these works underscore the
growing promise of LLMs in combinatorial optimization and
the importance of tailored datasets and adaptive fine-tuning
techniques. Table V presents a comprehensive summary of all
studies undertaken to utilize a dataset for the fine-tuning of
LLMs, enabling them to address mathematical modeling in
the context of the specified review questions.
2) Combinatorial and Linear Optimization: Motivated by
the urge to reduce the reliance on closed-source LLMs
like GPTs, Tang et al. [17] proposed OR language models
(ORLMs) trained on the IndustryOR dataset, which is a dataset
constructed by the authors using a new data synthesis method,
OR-Instruct. Their framework not only provides mathematical
modeling for a wide variety of OR problems but also con-
structs a solver code for finding the objective value.
Alibaba Group also worked on automating the process of
mathematical modeling using a supervised dataset to fine-tune
Qwen, as stated in [46]. The authors proposed OptLLM, which
supports multi-round dialog to learn the mathematical model
correctly. It has been experimentally proven that fine-tuning
the LLM in OptLLM achieves better accuracy compared to
the prompt-based models. Similar to [17], OptLLM uses an


--- Page 10 ---
10
TABLE V: Combinatorial optimization modeling via fine-tuning using datasets.
Study
RQ2
RQ3
RQ4
RQ5
RQ6
RQ9
Main findings
[40]
job
shop
schedul-
ing
(JSS)
Their own
120k
Phi-3-
Mini
OR-Tools
Optimality
gap
• Developed a supervised dataset specif-
ically designed to train LLMs for Job
Shop Scheduling Problems (JSSPs).
• Utilized
the
LoRA
for
fine-tuning,
demonstrating high-quality schedules for
small-scale JSS problems.
[20]
General
OptiBench
816
GPT-3.5,
GPT-4,
Llama,
DeepSeek
SCIP
Solution
accuracy
• Presented a new dataset, OptBinch, re-
flecting the complexity of real-world op-
timization challenges.
• Introduced a reverse method for generat-
ing synthetic data called ReSocratic.
[21]
JSS
StarJob
120k
Llama
OR-Tools
Optimality
gap
• Provided a dataset of 120k on JSS. Ap-
plied LLM to the dataset.
• Fine-tuned the Llama model on the pro-
posed dataset using LoRA.
[42]
General
MIPLIB
1065
GPT-3.5,
GPT-4,
Claude
SCIP
AIR, op-
timality
gap
• Proposed using LLMs to produce high-
quality algorithms for combinatorial op-
timization solvers.
• Utilized a derivative-free evolutionary
framework that allows for efficient explo-
ration and optimization of the generated
algorithms.
[45]
General
DiDi
operational
12500
Llama,
Instruct
Gurobi,
CPLEX,
COPT
Optimality
gap
• Proposed a framework for solving com-
plex
and
mixed-integer
programming
(MIP) challenges.
• Introduced a method that adjusts the
“temperature” parameter during the solu-
tion generation process.
[24]
General
StructuredOR
30
GPT-4o
Gurobi
Solution
accuracy,
recall,
precision,
F1-score
• Introduced a new dataset called Structure-
dOR.
• Proposed new searching techniques that
integrate RL into a ToT, incorporating
beam search, PRM, and pairwise prefer-
ence algorithm for enhancing the decision
making.
[43]
General
Extended
NL4Opt
–
GPT-3.5,
GPT-3
–
Solution
accuracy
• Extended
the
NL4Opt
dataset
with
more problem descriptions and constraint
types.
• Proposed a three-phase framework for
determining the decision variables, con-
straints, and objective function.
• Presented a structured approach to clas-
sifying constraints.
[41]
General
NL4Opt
67
Llama
–
Solution
accuracy
• Introduced LM4OPT, a progressive fine-
tuning framework designed to enhance
the performance of smaller LLMs, such
as Llama.
external solver to ensure that the model is solved correctly
and to help decision-makers make decisions.
Jiang et al. [47] proposed LLMOpt, a model that automates
mathematical modeling using the five-step approach (sets,
parameters, variables, objective function, and constraints).
Chen et al. [48] integrated RL with LLMs in a solver,
outperforming the LLMs baseline solver. Table VI summarizes
the main findings of studies that utilize datasets in solving both
linear and combinatorial problems using fine-tuning in relation
to the established review questions..
3) Linear Optimization: Solving linear optimization prob-
lems is considered the most straightforward entry point for
enabling LLMs to address mathematical modeling tasks, since
these problems have well-defined structures, established solu-
tion methods, and lower computational complexity compared
to nonlinear or combinatorial optimization problems. Amaras-
inghe et al. [49] proposed AI-Copilot, an approach for LLM
fine-tuning to automate business optimization problems. They
introduced modularization and prompt engineering techniques
to reduce the token length limitation. Although the proposed


--- Page 11 ---
11
TABLE VI: Combinatorial and linear optimization modeling via fine-tuning using datasets.
Study
RQ2
RQ3
RQ4
RQ5
RQ6
RQ9
Main findings
[17]
General
IndustryOR
100
Mistral,
Llama,
DeepSeek
Math
COPT
Solution
accuracy
• Developed OR-Instruct, a semi-automated
process for generating synthetic data tailored
to optimization modeling.
• Generated an industrial benchmark designed
to evaluate LLMs on real-world OR prob-
lems.
[46]
General
–
–
Qwen,
GPT-3.5,
GPT-4
–,
MAPL
Code
–
• Proposed OptLLM framework that supports
iterative dialogues for solving optimization
problems.
• Provided tutorials on three typical optimiza-
tion applications and conducted experiments
using both prompt-based GPT models and a
fine-tuned Qwen model.
[47]
General
NL4Opt,
Mamo, In-
dustryOR,
NLP4LP,
Com-
plexOR
NL4Opt:
1101,
Mamo:
863,
Indus-
tryOR:
100,
NLP4LP:
65,
Com-
plexOR:
19
Qwen1.5
–,
Pyomo
Execution
rate,
solution
accuracy,
average
solving
time
• Proposed LLMOPT that boosts optimization
generalization through multi-instruction fine-
tuning and model alignment for improving
accuracy in problem solving and expanding
the range of problem types that the model
can handle.
[48]
General
NL4Opt,
Mamo, In-
dustryOR
–
Qwen2.5-
7B,
Qwen2.5-
14B,
DeepSeek,
GPT-4
Gurobi
Solution
accuracy,
execu-
tion rate
• Solver-informed RL significantly outper-
forms baseline LLMs (e.g., CodeLlama,
GPT-4) in mathematical reasoning tasks by
integrating external verification signals.
AI-Copilot was tested on the JSS problem formulation, this
framework can be used for other types of business optimization
problems. Similarly, Kadıo˘glu et al. [29] proposed Ner4Opt,
combining classical NLP with modern LLMs and fine-tuned
transformers, and achieved 50% improvement. Table VII pro-
vides an overview of AI-Copilot and Ner4Opt in the context
of the predefined review questions.
V. MATHEMATICAL MODELING VIA IN-CONTEXT
LEARNING
Although fine-tuning is a powerful learning approach for
adapting LLMs to specific domains, it requires more compu-
tational power as it involves updating the model’s weights.
In-context learning offers a more lightweight and flexible
alternative, allowing LLMs to adapt to mathematical program-
ming tasks without modifying their underlying parameters. In-
context learning enables models to generalize from examples
provided directly within the input prompt, making it an effi-
cient and dynamic approach.
Depending on how many examples are used by the LLM,
there are different types of in-context learning: Zero shots,
one-shot, few shots, CoT, ToT, and graph of thoughts (GoT).
In zero-shot learning, only the task description is provided to
the LLM. One or a few examples, along with the task descrip-
tion, are provided when using one-shot and few-shot learning.
In CoT, the task and reasoning guidance are provided. ToT
is an extension of the CoT; rather than following a single
linear reasoning path, ToT explores multiple reasoning paths
branching out from a given state, evaluating them to find the
most optimal solution. Similarly, GoT represents the reasoning
paths as a graph rather than a tree.
Similar to fine-tuning, we classified the studies that adopted
in-context learning in the literature based on how the knowl-
edge base is constructed and the type of optimization model
considered, as shown in Fig. 3.
A. RAG-based Approaches
RAG can be combined with in-context learning, creating a
powerful method for overcoming the prompt length limitation,
which is the case in mathematical modeling. With RAG, the
retrieved information and task-specific examples are included
as part of the input prompt.
In [18], the authors utilized RAG to enhance the capabilities
of their framework, OptiMUS-3, which is an LLM-based
agent framework designed for solving general-purpose MILP
problems. The primary reason for implementing RAG was
to improve the generation of accurate model objectives and
constraints in their previous framework, OptiMUS [76]. By
retrieving examples of similar constraints and their formula-
tions, these examples were incorporated into the LLM prompt
to refine the model’s output.
OptiMUS-3 consists of four main steps: The first is to divide
the optimization problem into smaller, manageable sub-tasks.
The second step is to extract each constraint and objective


--- Page 12 ---
12
TABLE VII: Linear optimization modeling via fine-tuning using datasets.
Study
RQ2
RQ3
RQ4
RQ5
RQ6
RQ9
Main findings
[49]
JSS
–
182
CodeRL
–,
CPMpy
Solution
accuracy
• Proposed a new fine-tuning approach based
on AI-Copilot for business optimization
problem formulation.
• Developed new modularization and prompt-
ing techniques for complex problems.
• Proposed a new evaluation metric.
• Constructed a new dataset.
[29]
General
Ner4Opt
1101
GPT-4
–,
MiniZ-
inc
Precision,
recall,
F1-score,
compila-
tion
accuracy
• Presented Ner4Opt, addressing optimization-
specific entity extraction from natural lan-
guage.
• Utilized a hybrid approach combining classi-
cal NLPs with modern LLMs and fine-tuned
transformers.
• Improved optimization model compilation
by nearly 50% when guided by Ner4Opt
annotations.
independently while employing a graph to represent relation-
ships between the components of the optimization problem. In
the third step, the LLM will generate a code for solving the
MILP problems and iteratively execute and debug to achieve
the desired results. Finally, the accuracy of a given solution
is calculated. The study further demonstrated that adapting
RAG with GPT-4 and Llama improved the accuracy of the
generated solution. Using RAGs drastically enhanced the LLM
capabilities in solving VRPs, as experimentally shown in [50].
Zhang et al. [51] employed RAG to retrieve domain-specific
satellite knowledge, thereby enhancing the capability of LLMs
to formulate and solve satellite optimization problems. Ta-
ble VIII summarizes the literature that tackles combinatorial
optimization modeling via in-context learning using RAGs in
light of the predefined review questions.
B. Dataset-driven Approaches
When utilizing datasets for in-context learning, LLMs learn
patterns and relationships by relying on examples given in the
input prompt rather than making explicit parameter updates. In
the context of mathematical modeling, this approach leverages
LLM capabilities in learning how to approach OR problems
without requiring extensive retraining. By carefully crafting
datasets and optimizing the selection of in-context examples,
researchers can improve model adaptability, reduce computa-
tional costs, and enhance decision-making.
1) Combinatorial Optimization: Combinatorial problems
and in-context learning via datasets are the most common
directions among researchers in the field of mathematical
modeling due to the existence of combinatorial problems in
real-world scenarios and the simplicity of implementing in-
context learning. Consequently, OptiMUS-3 [18] used RAG
to incorporate relevant past examples of mathematical formu-
lations into its prompts, enabling better generalization without
retraining. On the other hand, Wang et al. [78] presented a
new dataset to enhance the ability of LLMs in mathematical
modeling. The chain-of-experts (CoE) framework employs a
multi-agent setup, where each agent specializes in an OR
task under a central conductor, improving complex problem-
solving through CoT reasoning [59], [64]. OptiChat [52]
offers natural language-based explanations and diagnostics
for infeasible optimization models by combining GPT-4 with
solver tools and enhanced prompting techniques, such as CoT
and sentiment analysis. Similarly, GPT-4 in [62] was used for
negotiation tasks for a game-theoretic framework.
Several other frameworks explored different problem-
solving strategies by integrating LLMs with optimization
tools. MEoH [53], proposed by Microsoft, used evolutionary
algorithms and zero-shot in-context learning to solve multi-
objective problems, such as TSP and the bin packing prob-
lem. MILP-Evolve [66] generates diverse MILP instances
using CoT-guided prompting. OPRO [55], proposed by Deep-
Mind, tackled combinatorial problems by iteratively refining
prompts based on previous solution quality. Additionally,
MLPrompt [65], [67] coupled LLMs with Monte Carlo tree
search (MCTS) to explore and refine optimization hypotheses,
leveraging few-shot prompting for model generation. Liu et
al. [30] integrated rule-based extraction with LLMs. In [58],
Wang et al. used LLMs to create a cognitive-inspired frame-
work.
Other efforts focus on domain-specific applications and gen-
eralization strategies. LLMFP [56] provided a zero-shot plan-
ning framework that models and solves optimization problems
through self-assessment and code refinement. City-LEO [25]
used LLMs in agent-based city management, applying in-
context learning for prediction and optimization. A similar
problem that is common in cities is TSP, which was tackled
by Luzzi et al. [60] using LLMs.
Lastly, frameworks, such as the one proposed by Sun et
al. [63], applied LLMs as black-box search operators, de-
composing UAV-related multi-objective problems into smaller
sub-problems. Collectively, these approaches showcase the
growing ability of LLMs to autonomously understand, solve,
and optimize complex real-world problems across domains.
Table IX summarizes the aforementioned studies in light of
the predefined review questions. From Table IX, it can be
observed that the studies [18], [60], [63] did not consider
employing solvers to determine the objective value of the


--- Page 13 ---
13
TABLE VIII: Combinatorial optimization modeling via in-context learning using RAGs.
Study
RQ2
RQ3
RQ4
RQ5
RQ6
RQ9
Main findings
[50]
VRPs
–
48
Llama,
GPT-4,
GPT-3.5
Turbo
OR-
Tools,
Gurobi
Solution
accuracy
and opti-
mality
gap
• Proposed a new framework to enhance
LLMs in exploiting solvers to solve VRPs
using RAG to extract the knowledge.
[18]
General
NL4Opt,
Com-
plexOR,
NLP4LP
NL4Opt:
1101,
Com-
plexOR:
37,
NLP4LP:
354
GPT-4o,
Llama
Not
speci-
fied
Solution
accuracy
• Employed an LLM-based agent, a modular
architecture that processes each constraint
and objective independently.
• Utilized a graph to represent relationships
between different components of the opti-
mization problem.
[51]
Wireless
re-
source
alloca-
tion
Their own
8
GPT-3.5
–
Utility
improve-
ment,
relative
regret,
conver-
gence
perfor-
mance,
running
time
• Proposed an approach to design transmis-
sion strategies in satellite communication
networks using generative AI and a mixture
of experts (MoE) with the proximal policy
optimization (PPO) method.
• Utilized RAG to retrieve satellite ex-
pert knowledge that supports mathematical
modeling.
• MoE-PPO outperforms traditional meth-
ods, greedy, and random baselines in per-
formance (e.g., sum-rate and energy effi-
ciency).
generated mathematical models.
2) Combinatorial and Linear Optimization: Tang et al. [17]
aimed to create a dataset that represents real-world scenarios,
featuring a variety of combinatorial and linear optimization
problems for in-context learning. To achieve this, they devel-
oped OR-Instruct for generating synthetic data. When address-
ing both combinatorial and linear optimization problems, ex-
ploratory questions and iterative discussions become essential.
Therefore, Zhang et al. [46] and Li et al. [68] tackled these
issues by offering answers to what-if questions and providing
iterative dialogues.
Multi-agent LLMs help in decomposing the problem into
smaller subproblems and solving each problem independently.
For example, in OptiMUS [18], the process is initiated by
transforming a structured problem into three essential compo-
nents: Parameters, clauses (which encompass objectives and
constraints), and background information. These components
are subsequently analyzed by four agents that collaborate
to create a connection graph for the constraints. Similarly,
Mostajabdaveh et al. [69] used a multi-agent LLM in their
framework.
Other frameworks, such as NL2OR [70], consist of four
key stages: Identifying query type, converting natural language
to a domain-specific language, building and instantiating an
abstract model, and finally storing and reporting solutions. To-
gether, these studies highlight the growing sophistication and
adaptability of LLMs in optimization modeling via structured
in-context learning and agent collaboration. Table X provides
a summary of the studies in light of the predefined review
questions.
3) Linear Optimization: In the context of solving only lin-
ear mathematical modeling using in-context learning, Zhang et
al. [73] demonstrated that their framework can achieve 85.54
solution accuracy through CoTs prompts. On the other hand,
Deng et al. [72] introduced CAFA, a method that simplifies LP
problem-solving by employing a single, compact prompt. This
approach eliminates the complexity of multi-step pipelines
by directly guiding LLMs to generate executable optimiza-
tion code, improving efficiency and usability in LP problem
formulation and execution. Li et al. [74] developed an end-
to-end framework that allows non-expert users to create and
edit abstract OR models using queries expressed in natural
language. Similarly, Zhang et al. [75] introduced the use
of LLMs as an explainable tool for mathematical models.
Kadıo˘glu et al. [29] presented a method that combined feature
engineering and data augmentation to exploit the language of
optimization problems and solve annotated linear optimization
problems. Table XI presents a summary of the literature in
light of the review questions.
VI. META-ANALYSIS
In order to answer the main research question of this
study, in this section, we conduct a meta-analysis based on
the aforementioned review questions. These review questions
reveal a profound grasp of the latest trends in leveraging LLMs
for mathematical modeling, highlighting their significance and
potential impact.
Fifty-four papers were used to conduct the following meta-
analysis. The first step in utilizing LLMs for automating
mathematical modeling is to determine the specific domain
of interest. This helps define the types of problems that can
be addressed using LLMs. As shown in Fig. 4, the results
of RQ1 indicate that combinatorial problems are the most
prevalent in mathematical modeling. The main reason for this
trend is that the current capabilities of LLMs in reasoning
make LP problems not particularly challenging. Additionally,
combinatorial problems reflect the complexity of real-world
problems.


--- Page 14 ---
14
TABLE IX: Combinatorial optimization modeling via in-context learning using datasets.
Study
RQ2
RQ3
RQ4
RQ5
RQ6
RQ9
Main findings
[18]
General
NL4Opt,
Com-
plexOR,
NLP4LP
NL4Opt:
1101,
Com-
plexOR:
37,
NLP4LP:
354
GPT-4o,
Llama
–
Solution
accuracy
• Employed an LLM-based agent, a modular
architecture that processes each constraint
and objective independently.
• Utilized a graph to represent relationships
between different components of the opti-
mization problem.
[64]
General
ComplexOR,
LPWP
1286
GPT-3.5
Gurobi
Solution
accuracy,
compila-
tion
accuracy,
running
time
• Presented a new dataset, ComplexOR, which
consists of complex OR problems.
• Proposed a new methodology for utilizing
LLMs to solve OR problems called CoE,
involving a multi-agent solution where each
agent is assigned a specific role and domain
knowledge.
[52]
General
Pyomo
Cookbook
63
GPT-4
Gurobi
Solution
accuracy
• Proposed OptiChat that helps users under-
stand and troubleshoot infeasible optimiza-
tion models using natural language.
• Utilized GPT-4 to interface with solvers and
identify the minimal subset of constraints
causing infeasibility.
[53]
General
–
5064
GPT-
3.5-
turbo
Not
speci-
fied
HV, IGD
• Developed MEoH, which automatically gen-
erates a diverse set of heuristics in a single
run that offers more trade-off options than
existing methods.
[66]
General
MIPLIB,
Their own
1
Million
GPT-4o
Not
speci-
fied
Integrity
gap
• Proposed a new framework MILP-Evolve
based on GNN for generating MILP in-
stances for LLM learning.
[78]
General
OptiBench
816
GPT-
3.5,
GPT-4,
Llama,
DeepSeek
SCIP
Solution
accuracy
• Presented a new dataset, OptBinch, reflect-
ing the complexity of real-world optimiza-
tion challenges.
• Employed a model-data separation format to
enhance LLM’s understanding during evalu-
ation.
[55]
General
GSM8K,
MultiArith,
AQuA,
BBH
GSM8K:
7473,
BBH:
250/task
PaLM
2-L,
GPT-
3.5-
turbo,
GPT-4
Gurobi
Solution
accuracy
• Introduced OPRO, a novel method leverag-
ing LLMs to solve math and TSP problems
and tune parameters in linear regression.
[63]
UAV
Raw data
–
–
–
Optimality
gap
• Proposed a novel generative AI-based frame-
work for UAV networking.
• Presented a case study on optimizing trans-
mission rate and spectrum map estimation.
[65]
General
ComplexOR
60
GPT-
3.5,
GPT-4,
GPT-4o,
GPT-
4o-mini
Gurobi,
Opt-
Verse,
CPLEX
Solution
accuracy
• Introduced MLPrompt, a novel prompting
strategy that translates error-prone rules into
less dominant language representations, en-
hancing LLM reasoning in complex con-
texts.
[67]
General
NL4Opt,
IndustryOR
344
GPT-
4o-mini
Gurobi,
CPLEX
Solution
accuracy
• Introduced a novel method that leverages
LLMs within a Monte Carlo tree search
framework by exploiting the hierarchical na-
ture of optimization modeling.


--- Page 15 ---
15
Study
RQ2
RQ3
RQ4
RQ5
RQ6
RQ9
Main findings
[56]
Planning
–
9
GPT-4,
CLAUDE-
3.5
SMT
solver
Optimality
gap
• Demonstrated the capability of LLMs
to handle planning tasks without fine-
tuning.
• Introduced
a
framework
integrat-
ing LLMs into formal programming
pipelines with interpretable and veri-
fiable outputs.
[25]
Cycle
Share
–
283, 143
trip
–
Gurobi
Solution
accuracy
• Presented City-LEO, an LLM-based
agent for efficient and transparent city
management.
• Integrated prediction and optimization
to handle environmental uncertainty
and complex queries.
[58]
General
NL4Opt,
ComplexOR
NL4Opt:
1101,
Com-
plexOR:
36
GPT-
3.5-
turbo,
GPT-4,
GPT-4o-
mini
–, PuLP
Solution
accuracy,
execution
rate
• Proposed
ORMind,
a
cognitive-
inspired
framework
achieving
68.8%
on
NL4Opt
and
40.5%
on ComplexOR.
• Outperformed CoT, reflection, and
ToT; deployed successfully at Lenovo
AI assistant.
[57]
General
–
863
GPT-4
series,
Claude,
Gemini,
DeepSeek,
Llama-
3.1,
Qwen-
2.5,
Mixtral
COPT,
Gurobi
Solution
accuracy
• Introduced Mamo dataset covering
ODEs, LP, MILP.
• Proposed a process-oriented frame-
work
for
automatic
mathematical
modeling using LLMs.
[59]
Resource
alloca-
tion
problem
–
290
GPT-4
and
GPT-
3.5-turbo
Gurobi
Solution
accuracy,
running
time,
expert
qualita-
tive
assess-
ment
• Presented Chat-SGP framework for
translating NL queries into Gurobi-
based optimization formulations.
• Used a multi-agent setup (coder, op-
timizer, interpreter) for better control,
debugging, and interpretability.
• Provided clear human-readable expla-
nations for the results.
[60]
Shortest
path
problem
–
120
GPT-4
–
Average
solving
time
• Utilized ChatGPT to address several
variants of shortest path problems.
[30]
Optimize
variable
extrac-
tion
Scientific
variable
extraction
benchmark
22
GPT-
3.5-
turbo,
GPT-4o,
Llama-3-
8B-
Instruct,
Mistral-
7B-
Instruct
–
Semantic
similarity
• Demonstrated the best performance in
extracting mathematical model vari-
ables from scientific literature using
transfer learning and instruction tun-
ing.
• Integrated rule-based extraction out-
puts with LLMs to boost performance.
[62]
General
–
3200
PaLM 2
–
Utility
improve-
ment
• Presented a new framework that inte-
grates game-theoretic solvers with nat-
ural language dialogue using LLMs.
• Produced less exploitable and more re-
warding dialogue in negotiation tasks
when LLMs were guided by game-
theoretic solvers.


--- Page 16 ---
16
TABLE X: Combinatorial and linear optimization modeling via in-context learning using datasets.
Study
RQ2
RQ3
RQ4
RQ5
RQ6
RQ9
Main findings
[68]
General
Their own
57
GPT-4,
text-
davinci-
003
Gurobi
Solution
accuracy
• Proposed OptiGuide that uses LLMs
to translate human queries to opti-
mization code.
• OptiGuide handles what-if queries by
modifying inputs and rerunning the
solver.
[18]
General
NL4Opt
67
GPT-4
Gurobi
Solution
accuracy
• Proposed a new dataset NL4Opt.
• Developed a framework using GPT-4
with agents to solve MILP problems.
[17]
General
IndustryOR
100
Mistral,
Llama,
DeepSeek,
Math
COPT
Solution
accuracy
• Developed
OR-Instruct,
a
semi-
automated
pipeline
for
generating
synthetic data for optimization.
• Created an industrial benchmark for
evaluating LLMs on real-world prob-
lems.
[46]
General
–
–
Qwen,
GPT-3.5,
GPT-4
–, MAPL
Code
–
• Proposed
the
OptLLM
framework
supporting iterative dialogue for solv-
ing optimization problems.
• Provided tutorials and experimental
comparisons
between
prompt-based
GPT and fine-tuned Qwen models.
[69]
General
NL4Opt,
NLP4LP,
custom
dataset
–
Llama,
Zephyr
–, Pyomo
Solution
accuracy
• Introduced a multi-agent, multi-stage
approach where distinct LLMs are
used across stages to handle complex
optimization modeling.
[70]
General
–
30
GPT-3.5,
GPT-4
Gurobi,
CPLEX,
OR-Tools,
AMPL
Valid@k
within
time t
• Proposed
NL2OR,
an
end-to-end
pipeline to automate formulation and
solve OR problems.
Fig. 4: Classes of optimization problems studied in the litera-
ture using LLMs, with combinatorial problems being the most
frequent.
Using LLMs in mathematical modeling is a relatively new
topic that has only recently begun to develop; thus, it is worth
noting that most studies were not specialized in a specific
domain, meaning that they tend to test the LLM’s capability
in solving general problems. In other words, the answers to
RQ2 showed that 34 papers focused on general domains.
A. Dataset Construction
Constructing a knowledge base for training LLMs is a
crucial step, as shown in Fig. 2. There are two approaches:
We can either use a predefined dataset to train the LLM or
employ RAG. Out of the 54 papers, only four employ RAG;
this is because most papers tend to address general problems
rather than domain-specific problems. RAG is a powerful tool
to address many issues, and one of them is to make LLMs
capable of solving domain-specific tasks, as discussed in [79].
When addressing mathematical modeling, researchers tend
to construct and use different benchmarks to automate the
process of mathematical modeling. Studying the effect of RQ3
demonstrates that the most common dataset is NL4Opt, as
depicted in Fig. 5. NL4Opt is a dataset proposed in a compe-
tition at NeurIPS 2022 to bridge OR with NLP. Nevertheless,
this dataset has its limitations regarding the complexity of the
considered problems. Consequently, other datasets have been
proposed, such as ComplexOR, which is the second most
used dataset. Other researchers construct their own datasets
for teaching LLMs to formulate OR problems. The “other”
column includes the following datasets, where each one con-
tributes one unit in the “other” column: DiDi operational,
StarJob, Cycle share, StructuredOR, OptBinch, ReSocratic, the
Pyomo Cookbook, GSM8K, MultiArith, AQuA, BBH, Mamo.


--- Page 17 ---
17
TABLE XI: Linear optimization modeling via in-context learning using datasets.
Study
RQ2
RQ3
RQ4
RQ5
RQ6
RQ9
Main findings
[72]
General
NL4Opt
–
GPT-4,
GPT-
3.5-
turbo,
DeepSeek,
Llama
CPLEX,
Gurobi
Solution
accuracy
• Proposed an LLM-based model to
translate LP problems into executable
code.
• Introduced CAFA, which uses a com-
pact prompt to instruct LLMs to gen-
erate solver-ready code, simplifying
pipelines.
[73]
General
–
83
GPT-
3.5-o-
mini,
GPT-4o,
DeepSeek,
Gemini
Flash,
Claude
Gurobi
Execution
rate,
solution
accuracy
• OR-LLM-Agent achieved 100% exe-
cution success and 85.54% solution
accuracy.
• Outperformed SOTA LLMs on real-
world OR tasks.
• Demonstrated robust CoT-based rea-
soning and self-verification via sand-
boxed Gurobi execution.
[74]
General
LPWP
287
GPT-3.5,
GPT-4,
GPT-4o
Gurobi,
CPLEX,
OR-Tools,
AMPL
Solution
accuracy
• Presented
NL2OR:
an
end-to-end
framework with a multi-turn chat sys-
tem for automating mathematical pro-
gramming.
[29]
General
Ner4Opt
1101
GPT-4
–,
MiniZinc
Precision,
recall,
F1-score,
compila-
tion
accuracy
• Presented
Ner4Opt,
addressing
optimization-specific entity extraction
from natural language.
• Improved model compilation perfor-
mance by nearly 50% via NER-guided
annotations.
[75]
General
–
–
GPT-4,
GPT-4-
turbo
Gurobi
Solution
accuracy
• Proposed explainable operations re-
search (EOR), enabling LLMs to gen-
erate human-readable explanations of
OR model behavior.
• Quantified “decision information” via
bipartite graphs and supported what-if
analysis.
• Released a new industrial benchmark
for explainable OR.
0
2
4
6
8
10
12
14
16
18
20
Fig. 5: Frequency of the datasets used in the literature, with
NL4Opt being the most frequently used.
B. LLM Learning
Recently, there has been significant progress in the devel-
opment of LLMs that can automate mathematical modeling
processes. Table XII provides a brief comparison of the most
commonly available LLMs. After analyzing the effects of
2%
20%
31%
15%
5%
3%
4%
5%
2%
2% 2%
9%
Not mentioned
GPT-3.5
GPT-4
LLaMa
Qwen
Claude
Deep seek
Mistral
PaLM
Gemini
Instruct
Others
Fig. 6: Distribution of the LLMs used in the literature, with
GPT-4 being the most frequent LLM.
RQ5, as illustrated in Fig. 6, GPT-4 stands out as the most
widely used LLM in mathematical modeling, largely due to
its impressive reasoning capabilities.
As previously discussed, there are two effective methods


--- Page 18 ---
18
TABLE XII: Comparison of various LLMs.
Model
Creator
Available sizes (Parameters)
Architecture
Main domain
GPT-4/o
OpenAI
Not publicly disclosed
Transformer-based
General-purpose
GPT-3
OpenAI
175B
Transformer-based
General-purpose
GPT-3.5
OpenAI
Not publicly disclosed
Transformer-based
General-purpose
DeepSeek-R1
DeepSeek
671B total (37B active per
forward pass)
MoE
Reasoning-focused
Llama 3.1
Meta
405B
Transformer-based
General-purpose
Mistral Large 2
Mistral AI
123B
Transformer-based
General-purpose
Claude 3.5 Sonnet
Anthropic
Not publicly disclosed
Transformer-based
General-purpose
PaLM
Google
540B
Transformer-based
General-purpose
Phi-3.5-MoE
Microsoft
60.8B total (6.6B active per
forward pass)
MoE
General-purpose
CodeRL
Salesforce
770M
Transformer-based
Code generation
Fig. 7: Frequency of in-context learning and fine-tuning across
different classes of optimization problems.
for enabling LLMs to adapt to new fields: In-context learning
and fine-tuning. This leads us to an important investigation of
the effects of RQ8 in the realm of mathematical modeling. As
illustrated in Fig. 7, in-context learning is more common than
fine-tuning across all problem types: Combinatorial, combina-
torial and linear, and linear, with a total of 36 research papers
for in-context learning and 19 for fine-tuning. This preference
reflects the efficiency and scalability of in-context learning,
particularly given the substantial computational demands of
fine-tuning. Nevertheless, nearly 35% of use cases still rely
on fine-tuning, which remains a valid approach in light of the
intricate reasoning often required in mathematical modeling.
In such cases, updating model parameters through fine-tuning
may be necessary to tackle complex, structured problems
effectively.
Once a mathematical model is created with LLMs, the
next step is to find the objective function value considering
any dataset. To facilitate this, some researchers train LLMs
to generate code that utilizes different solvers to solve the
model. Upon studying the effect of RQ6, it can be noticed
Gurobi (17)
CPLEX (7)
Google's
OR-Tools (5) 
COPT (4)
SCIP (4)
OptV-
erse (1)
SMT (1)
Fig. 8: Frequency of the solvers used in the literature, with
Gurobi being the most frequently used.
that not all of the proposed frameworks consider the process
of solving the mathematical model and finding the objective
value, despite its importance for decision-makers. As depicted
in Fig. 8, Gurobi, CPLEX, and Google’s OR-Tools were the
most commonly adopted solvers in the literature. Gurobi’s
cutting-edge parallel optimization algorithms and advanced
heuristics make it highly responsive to dynamic and real-
time changes in complex optimization problems. CPLEX, on
the other hand, uses advanced algorithms like branch-and-cut
and dual simplex to efficiently solve large-scale optimization
problems. Similar to CPLEX, SCIP combines cutting-edge
algorithms, such as branch-and-bound, cutting planes, and
branch-and-cut. In the context of large-scale optimization
problems, Google’s OR-Tools can integrate seamlessly with
Google Cloud. COPT and OptVerse integrate ML and AI-
based techniques into their optimization processes, allowing
for faster convergence and handling dynamic constraints.
Table XIII provides a comparison between the solvers used
in the literature. These solvers can solve different types of
problems, such as LP, MILP, quadratic programming (QP),
and constraint programming (CP) problems.
The complexity of various types of mathematical modeling
can differ significantly. Therefore, we aimed to examine the


--- Page 19 ---
19
TABLE XIII: Comparison of solvers used in mathematical
modeling.
Solver
License
Best for
LP
MILP
QP
CP
Gurobi
[33]
Commercial
MILP
(fast
solver)
✓
✓
✓
✗
CPLEX
[32]
Commercial
Business
applica-
tions
✓
✓
✓
✗
OR-
Tools
[34]
Open-
source
General
opti-
mization
✓
✓
✗
✓
COPT
[37]
Commercial
Large-
scale
opti-
mization
✓
✓
✓
✗
OptVerse
[36]
Commercial
Dynamic
opti-
mization
✓
✓
✓
✗
SCIP
[38]
Open-
source
MILP
and CP
✓
✓
✗
✓
SMT
[35]
Open-
source
Formulas
satisfia-
bility
check
-
-
-
✓
most common LLM for each type of mathematical models by
analyzing the impact of RQ1 and RQ5, as shown in Fig. 9. It
can be noticed that the capability of GPT-4 in solving different
types of mathematical modeling was extensively studied in
the literature, and this is due to its multimodal capability
allows users to interact with the model in more diverse
and flexible ways, enhancing its applicability across different
domains. Other LLMs are rapidly evolving and require further
investigation regarding their capabilities for various levels of
complexity in mathematical modeling.
The difference in the complexities of mathematical models
also requires different ways of dealing with these complexities
by the LLMs, and this can be handled by either fine-tuning
or in-context learning. Thus, we have examined the frequency
of in-context learning and fine-tuning across the LLMs used
in mathematical modeling. This investigation indicates the
capabilities of LLMs, determining whether they require simple
in-context learning or if their reasoning abilities necessitate
fine-tuning instead. From Fig. 10 it can be seen that GPT-4
is the most frequently used model for in-context learning (18
occurrences), followed by GPT-3.5 (16) and Llama (11), indi-
cating a strong preference for these models in scenarios where
adaptation is needed without modifying model parameters.
Regarding fine-tuning, Llama and GPT-4 are the most com-
monly LLMs (8 occurrences). While both are widely employed
in both approaches, fine-tuning appears to be applied more
selectively, likely due to computational demands. Overall, the
figure highlights that GPT-4 and Llama dominate automatic
mathematical modeling, with in-context learning being the
more widely adopted approach across different models.
The dataset always has a direct impact on the capability of
any model when approaching any given problem, regardless of
the learning technique. Thus, the effect of the RQ3 and RQ5
was inspected. Fig. 11 illustrates the frequency of datasets used
Combinatorial
Linear
Combinatorial
and Linear 
GPT-3.5 (12)
GPT-4 (11)
LLaMA (9)
GPT-4o (9)
Claude (2)
PaLM (2)
Mixtral (3)
Phi (1)
GPT-3 (1)
Sonnet
 (
1)
Gemini (1)
GPT-4 (5)
GPT-3.5 (3)
LLaMA (2)
GPT-4o (2)
Gemini (1)
Claude (1)
InternLM (1)
CodeRL (1)
GPT-4 (5)
Qwen (5)
GPT-3.5 (2)
LLaMA (2)
Zephyr (1)
DeepSeek (2)
Qwen (1)
DeepSeek (1)
Mistral (1)
Yi-9B (1)
Mistral (1)
DeepSeek (1)
Fig. 9: Frequency of the optimization classes studied and
adopted LLMs.
In-context
Fine-tuning
GPT-4 (18)
GPT-3.5 (16)
LLaMa (11)
GPT-4o (11)
Mistral (4)
DeepSeek (4)
Qwen (3)
Claude (3)
Gemini (3)
PaLM (2)
Zephyr (1)
Sonnet (1)
GPT-4 (8)
LLaMa (7)
GPT-3.5 (5)
Qwen (3)
Mistral (2)
DeepSeek (2)
CodeRL (1)
Phi (1)
GPT-4o (1)
Claude (1)
BART (1)
Fig. 10: Frequency of in-context learning and fine-tuning
across the LLMs used for mathematical modeling.


--- Page 20 ---
20
Their own
ComplexOR
LPWP
NLP4opt
MEMO
IndustryOR
TSPLIB
NLP4LP
OptiBench
Starjob
MIPLIB
GSM8K
MultiArith
AQuA
DiDi operational
StructuredOR
OptMath
ORQA
NER4OPT
GPT-3
GPT-4
Test-davinci
GPT-3.5
CodeRL
Mistral
LLaMa
Qwen
Phi-3
PaLM
Instruct
Zephyr
Gimini
GPT-4
GPT-3.5
Mistral
LLaMa
Qwen
GPT-3.5
BART
Falcon
GPT-3
GPT-4
GPT-3.5
Mistral
LLaMa
pS
Qwen
Zephyr
GPT-4
Mistral
LLaMa
DeepSeek
Qwen
GPT-4
Mistral
LLaMa
DeepSeek
Qwen
GPT-4
GPT-3.5
GPT-4
Mistral
LLaMa
Qwen
Instruct
Zephyr
GPT-4
CodeRL
LLaMa
LLaMa
GPT-4
GPT-3.5
Claude
GPT-4
PaLM
GPT-4
PaLM
GPT-4
PaLM
GPT-4
PaLM
LLaMa
Instruct
GPT-4
Qwen
Mistral
LLaMa
DeepSeek
GPT-4
Big-Bench Hard
Dee    eek
Fig. 11: Frequency of the datasets used and adopted LLMs.
for training various LLMs. GPT-4, Llama, and GPT-3.5 are
the most frequently used LLMs for mathematical modeling,
as they appear extensively across the literature and are trained
on a diverse range of datasets. Among these datasets, NL4Opt
stands out as the most commonly utilized across various
LLMs, suggesting its significance in optimizing learning for
mathematical modeling tasks. Notably, almost all LLMs have
been trained, at least in part, on proprietary datasets that are not
publicly available (“their own”). Additionally, certain datasets,
such as IndustryOR, DiDi Operational, AQUA, and Multi-
Arith, were tested on only one or two LLMs, indicating limited
adoption. This suggests the need for further investigation into
their applicability, effectiveness, and potential for broader use
in training mathematical models. Understanding how these
datasets influence model performance could provide valuable
insights into their suitability for different learning tasks.
Given the variety of well-known solvers available for ad-
dressing different OR problems, we investigate the distribution
of solvers utilized in LLM-generated code and analyze the
categories of problems for which they are applied. As a result,
the effect of RQ1 and RQ6 is illustrated in Fig. 12. It can be
noticed that Gurobi was the most used solver regardless of
the mathematical problem type. This is due to its reliability
and efficiency in solving optimization problems. Other solvers,
such as SCIP, COPT, OptVerse, and SMT solvers, were used
but less frequently. Studies that addressed both combinatorial
problems adopt a wider variety of solvers, including Gurobi,
CPLEX, COPT, and Google’s OR-Tools, SCIP, OptVerse, and
SMT. Research on both combinatorial and linear appears to be
the least explored in the context of generating solver codes.
It can be seen that such studies used Gurobi, COPT, and OR-
Tools, but with fewer occurrences per solver.
Combinatorial
Linear
Combinatorial
and linear
Gurobi (12)
CPLEX (6)
OR-Tools (3)
SCIP (3)
COPT (2) 
OptVerse (1) 
SMT (1) 
Gurobi (5)
CPLEX (2)
OR-Tools (1)
Gurobi (4)
 COPT (2)
OR-Tools (1)
Fig. 12: Frequency of the optimization classes studied and
adopted solvers.
C. Model Evaluation
This section summarizes the evaluation metrics used to
assess LLM-generated optimization formulations introduced in
RQ9. It provides precise definitions with explicit equations for
the principal measures and brief explanations for less common
ones, and it reports their prevalence in the literature based on
our meta-analysis. The metrics are grouped into the following
categories: Solution quality, surface-form accuracy, buildabil-
ity, runtime robustness, feasibility/model soundness, efficiency,
search effectiveness, domain utility outcomes, multi-objective
quality, mathematical fidelity, and human-centered evaluation.
1) Solution Quality Metrics: Solution quality metrics eval-
uate how good a feasible, successfully executed solution is
relative to the original.
• Optimality gap: This metric measures the relative differ-
ence between the objective value produced by the LLM
formulation and the known optimal solution. Let ‘optimal
value’ represent the best-known objective value for the
problem, and ‘model’s objective value’ be the value
obtained by solving the generated model. The optimality
gap is defined as:
Optimality gap = |optimal value−model’s objective value|
|optimal value|
.
(1)
• Average
improvement
ratio
(AIR)
(vs.
human-
designed heuristic): We evaluate on M benchmark prob-
lems (test instances). For each problem m ∈{1, . . . , M},
measure how far a method s is from the best-known
optimum using its relative gap gm(s) = |Solm(s)−Optm|
|Optm|+ε
,
where Solm(s) is the objective achieved by s, Optm is
the best-known optimum, and ε > 0 is a tiny constant to
avoid dividing by zero. Let h be the best human-designed


--- Page 21 ---
21
heuristic with gap gm(h). AIR is the average, across all
problems, of your method’s gap relative to the heuristic’s
gap, which can be expressed as:
AIR(s) =
1
M
M
X
m=1
gm(s)
gm(h).
(2)
AIR(s) < 1 means your method is better than the
heuristic on average; = 1 means about the same; > 1
means worse.
2) Surface-form Accuracy Metrics: Surface-form accuracy
measures literal overlap with the original at the token/compo-
nent level.
• Precision: Fraction of produced items that are correct.
Let TP be the true positives and FP be the false positives.
Then,
Precision =
TP
TP + FP.
(3)
• Recall: Fraction of required items that were produced.
Let FN be the false negatives. Then,
Recall =
TP
TP + FN.
(4)
• F1-score: Harmonic mean of precision and recall.
F1-score = 2 × Precision × Recall
Precision + Recall
.
(5)
3) Buildability Metrics: Buildability checks whether the
generated formulation can be parsed and accepted before any
execution.
• Compilation accuracy: The proportion of generated
formulations that pass (parsing, typing, and schema)
checks. Let #Compiled be the number that compile and
#Generated the total. Then,
Compilation accuracy = #Compiled
#Generated.
(6)
4) Runtime Robustness Metrics: Runtime robustness evalu-
ates whether compiled programs finish execution cleanly.
• Execution rate: Among compilable runs, the share that
finish without runtime errors or timeouts. Let #Ran be
runs that finished and #Compiled those that compiled.
Then,
Execution rate =
#Ran
#Compiled.
(7)
5) Feasibility / Model Soundness Metrics: Feasibility
records whether a compiled run yields a solver-feasible so-
lution.
• Feasibility pass rate: The share of compiled runs that
return a feasible (or optimal) status. Let #Feasible be
feasible outcomes. Then,
Feasibility pass rate = #Feasible
#Compiled.
(8)
6) Efficiency Metrics: Efficiency metrics measure (i) how
long it takes to build and solve the LLM-generated formula-
tion on each instance, and (ii) how fast the solution quality
improves during training/search.
• Average solving time: Wall-clock time per instance to
build and solve the generated formulation (shorter is
better). Let Tj be the elapsed time to finish instance j
(including model build and solve), tmax a time limit (if
used), and N the number of instances. Then, the average
solving time, T, is given by:
T =
1
N
N
X
j=1
min
 Tj, tmax

.
(9)
• Convergence performance curve (episodes vs. perfor-
mance): Average performance of the solution obtained
by solving the generated formulation after each train-
ing/search episode (higher or lower is better depending
on the metric). Let Sj(e) denote the chosen performance
measure for instance j after episode e (e.g., −optimality
gap, achievable sum-rate). The aggregated curve is:
S(e) =
1
N
N
X
j=1
Sj(e).
(10)
7) Search Effectiveness Metrics: Search effectiveness eval-
uates whether sampling multiple generations yields at least
one usable formulation within k attempts.
• Valid@k: For each instance j = 1, . . . , N, generate
k attempts. Define Sj,i = 1 if attempt i for instance
j compiles and executes to completion (i.e., yields a
runnable solver run), and Sj,i = 0 otherwise. Valid@k,
denoted by Vk, is the fraction of instances for which at
least one attempt succeeds:
Vk =
1
N
N
X
j=1
max
i≤k Sj,i.
(11)
8) Domain Utility Outcomes: Domain utility reports perfor-
mance in the problem’s own units (e.g., Mbps, $, minutes).
• Utility improvement (vs. baseline): How much better the
solution obtained from the LLM-generated formulation
performs compared with a baseline method on the same
instance. Let Uj be the payoff computed from the solution
returned by the LLM-generated formulation for instance
j (in native units), U base
j
be the payoff from the baseline
method on that instance, and ε > 0 be a tiny constant to
avoid division by zero. Then,
Utility improvement = Uj −U base
j
|U base
j
| + ε .
(12)
For “higher-is-better” payoffs (e.g., throughput, revenue),
positive values mean the LLM-generated formulation
improved over the baseline; for “lower-is-better” payoffs
(e.g., delay, cost), report the percent decrease or define
the payoff so that larger is better.


--- Page 22 ---
22
9) Multi-objective Quality Metrics: When the generated
formulation must balance several goals (e.g., cost and delay),
solving it produces a set of trade-off solutions (a Pareto set).
We use two metrics to judge this set: One for coverage and
one for closeness to a reference front.
• Hypervolume (HV): How much of the objective space is
covered by the Pareto set produced by the LLM-generated
formulation. A larger HV means your set spans a bigger,
better region of trade-offs. Let P be the set of solutions
you obtained, ND(P) its nondominated subset, and r a
fixed reference point that is worse than all solutions (per
objective). Then,
HV(P, r) = λ

[
p∈ND(P )
[p, r]

.
(13)
• Inverted generational distance (IGD): Shows how close
your produced set is to a reference Pareto front. A smaller
IGD means your set better approximates the desired front.
Let Z∗be the reference set (true front if known, or the
nondominated union across methods), and P be the set
from the LLM-generated formulation. Then,
IGD(P, Z∗) =
1
|Z∗|
X
z∈Z∗
min
p∈P ∥z −p∥2.
(14)
10) Mathematical Fidelity Metrics: Mathematical fidelity
checks whether the LLM-generated formulation encodes the
same mathematics as the original formulation.
• Integrity gap (structure): Measures how different the
variable–constraint incidence pattern is from the original.
Let Egen and Eorg be the sets of incidence edges (a vari-
able appears in a constraint) after simple normalization
(consistent naming, ordering, and sign conventions). The
integrity gap is the complement of the Jaccard overlap,
and is given by:
IntegrityGap = 1 −|Egen ∩Eorg|
|Egen ∪Eorg|.
(15)
0 means identical structure; larger values indicate a worse
structural match.
• Semantic similarity (meaning): Check whether the two
formulations express the same relationships overall, even
if written differently. After normalizing both formulations
(e.g., consistent variable naming, ordering, and scaling),
map each to an embedding with ϕ(·) and compute cosine
similarity:
SemanticSimilarity =
⟨ϕ(formgen), ϕ(formorg)⟩
∥ϕ(formgen)∥2 ∥ϕ(formorg)∥2 .
(16)
As an alternative, an “LLM-judge” can label whether
predicted elements semantically match the reference and
the results can be summarized with precision, recall, and
F1 [30].
Fig. 13 presents a meta-analysis of metric usage frequency,
offering insights into which metrics are most frequently em-
ployed across existing studies. In addition, Fig. 14 shows how
different types of mathematical modeling tasks are associated
with specific evaluation metrics.
Fig. 13: Frequency of the metrics used to measure the LLMs’
ability in formulating and solving mathematical optimization
problems. Accuracy is the most used metric.
Fig. 14: Distribution of the optimization classes studied and
adopted evaluation metrics.
VII. LIMITATIONS AND OPPORTUNITIES FOR LLMS IN
MATHEMATICAL MODELING
Building on the results of meta-analysis, this section high-
lights the key limitations and potential opportunities of using
LLMs for mathematical modeling. While the analysis confirms
that LLMs can effectively handle simple and structured tasks,
it also uncovers several critical challenges, such as limited
numerical reasoning, sensitivity to input complexity, and over-
reliance on narrow datasets, that constrain their performance in
realistic scenarios. We summarize these limitations based on


--- Page 23 ---
23
both empirical evidence and findings from prior studies, and
we outline emerging research directions aimed at enhancing
the reasoning ability, generalizability, and robustness of LLMs
for complex, domain-specific optimization tasks.
A. Empirical Insights from Meta-Analysis
Our meta-analysis reveals several critical limitations, along
with promising opportunities, in the current use of LLMs for
mathematical modeling.
A prominent limitation across the literature is the heavy
reliance on a narrow set of simple datasets, typically compris-
ing small-scale linear or combinatorial optimization problems
with only a few decision variables and constraints. While these
datasets offer a convenient and controlled environment for
benchmarking, they fail to reflect the complexity, variability,
and scale of real-world applications. This over-reliance leads to
inflated performance assessments and significantly limits the
generalizability of results to more realistic, domain-specific
scenarios. However, this limitation presents a clear opportu-
nity: The development and adoption of richer, more repre-
sentative datasets, including non-linear, high-dimensional, and
stochastic problems, would enable a more rigorous and mean-
ingful evaluation of LLMs capabilities in practical contexts.
Another key challenge is the predominant use of closed-
source models, particularly those developed by commercial
providers. Although these models often deliver strong per-
formance, their widespread adoption raises concerns regard-
ing transparency, reproducibility, and long-term sustainabil-
ity within the research community. In contrast, open-source
LLMs remain considerably underexplored, despite offering
significant advantages such as flexibility, cost-efficiency, and
greater control over data privacy and deployment. This un-
derutilization signals an important opportunity: Advancing
and systematically evaluating open-source models tailored to
the needs of mathematical modeling could promote more
transparent, accessible, and sustainable research practices.
While in-context learning has emerged as the most com-
monly adopted learning strategy, primarily due to its flexi-
bility, scalability, and low resource demands, it is not always
sufficient, particularly in domain-specific applications. In such
cases, fine-tuning remains crucial, as it enables models to
internalize structured patterns and knowledge derived from
datasets tailored to specific fields or tasks. This distinction
highlights a key insight from the meta-analysis: Although in-
context learning is often favored for its ease of use and broad
applicability, fine-tuning plays a vital role in achieving the
depth and precision required for specialized modeling tasks.
This reveals a broader opportunity to more effectively align
training strategies with the complexity and contextual demands
of the problem, ensuring that LLMs are robustly optimized
for both general-purpose and domain-specific mathematical
modeling.
Finally, a major shortcoming in the current literature is
the absence of a unified evaluation framework for assess-
ing LLM-generated formulations. Most studies emphasize
accuracy while neglecting equally important factors such as
solution feasibility, optimality, execution time, and robustness.
This fragmented evaluation approach reduces the reliability,
comparability, and interpretability of reported results. There
is a clear need for a comprehensive framework that captures
multiple performance dimensions simultaneously, enabling a
more accurate and holistic assessment of model outputs in
mathematical modeling tasks.
In summary, the meta-analysis reveals several key limita-
tions in the current literature: A lack of diversity in problem
types, the frequent use of overly simplistic datasets, a strong
reliance on closed-source models, and the absence of stan-
dardized, multi-dimensional evaluation practices. At the same
time, it points to clear directions for future progress. These
include the development of more realistic and representative
datasets, greater adoption of open-source LLMs, targeted fine-
tuning on domain-specific datasets to improve specialization,
and the design of comprehensive evaluation frameworks that
assess model performance across multiple critical dimensions.
Together, these opportunities provide a foundation for advanc-
ing the reliability and applicability of LLMs in real-world
mathematical modeling.
B. Limitations and Opportunities from Literature
Recent literature highlights several key limitations that
constrain the effectiveness of LLMs in mathematical modeling,
alongside emerging research directions aimed at overcoming
these challenges.
One major limitation is the difficulty LLMs face in numeri-
cal reasoning. Although these models excel at language gener-
ation, they often struggle with arithmetic operations and fail to
accurately interpret numerical relationships [80]. This short-
coming stems from their statistical architecture and the ab-
sence of symbolic understanding. To address this, researchers
have explored integrating symbolic reasoning components into
language models, as well as experimenting with alternative
number encoding techniques to improve numerical compre-
hension. In the long term, a promising direction involves
designing architectures that generate structured, executable
formulations, allowing external solvers to ensure correctness
rather than relying solely on the model’s internal reasoning.
Another persistent challenge is the sensitivity of LLMs
to input length. When handling long or complex prompts,
these models often lose critical context, an issue that is
especially problematic in mathematical modeling tasks, which
frequently require detailed and extended inputs [81], [82]. To
mitigate this, prompt compression techniques and sub-word
regularization strategies such as byte pair encoding (BPE)
dropout have been proposed. However, these solutions are not
always sufficient. A promising opportunity lies in developing
models or workflows capable of decomposing large problems
into smaller, manageable subproblems that preserve coherence
and semantic integrity across the full task.
A more fundamental limitation is the tendency of LLMs to
rely on surface-level pattern matching rather than true reason-
ing. Rather than deducing solutions through logical inference,
models often generate responses based on statistical patterns
learned during training [80]. This limits their reliability in
tasks that require structured reasoning or complex decision-
making. To address this, several prompting strategies, such


--- Page 24 ---
24
as CoT, ToT, and GoT, have been proposed to guide models
through step-by-step reasoning. Additionally, frameworks such
as RAG and RL are being explored to enhance logical depth
and factual consistency. Ongoing research is needed to strike
the right balance between generative fluency and explicit
reasoning, particularly for high-stakes applications.
Another important limitation is the difficulty LLMs faces in
filtering out irrelevant information. When exposed to prompts
containing unnecessary or distracting content, models often
fail to distinguish between relevant and extraneous details,
resulting in incoherent or erroneous outputs [83]. While
structured prompting and preprocessing can partially mitigate
this issue, more robust solutions are needed. Future work
could focus on developing instruction-aware architectures and
relevance-guided processing mechanisms that help models
prioritize essential information during inference.
In summary, the literature identifies a range of limitations
affecting the use of LLMs in mathematical modeling, from
weaknesses in numerical reasoning and input length sensitivity
to shallow logic and poor relevance filtering. However, it also
points to a growing body of work focused on integrating sym-
bolic reasoning, improving prompting strategies, incorporating
retrieval mechanisms, and coordinating specialized models.
These directions offer a valuable path forward for enhancing
the robustness, adaptability, and domain-specific effectiveness
of LLMs in mathematical and decision-oriented applications.
C. Answering Research Questions
Based on the preceding meta-analysis and literature review,
we now address the four research questions that guided this
study.
What are the most commonly used LLMs for generating
mathematical models? Our findings indicate that GPT-based
models, particularly those developed by OpenAI, are the
most widely adopted in the current literature. These models
dominate both in frequency of use and reported effectiveness
across various mathematical modeling tasks. Their popularity
is largely attributed to their strong general performance, ac-
cessibility via APIs, and integration into existing optimization
workflows. In contrast, open-source models such as Llama and
DeepSeek are significantly underutilized, despite offering ad-
vantages in customization, transparency, and data governance.
To what extent are LLMs capable of generating math-
ematical models? LLMs demonstrate promising capabili-
ties in generating mathematical models, especially for well-
structured, small-scale, and general-purpose problems. They
are often successful in producing syntactically correct formula-
tions for linear and combinatorial optimization tasks. However,
their performance is notably limited when applied to domain-
specific or complex problems that involve non-linearity, uncer-
tainty, or large-scale constraints. These limitations highlight
the need for improvements in reasoning capabilities, domain
adaptation, and structured problem representation to ensure
accurate and context-aware model generation.
What is the best approach to utilize LLMs for generating
and formulating mathematical models? Current evidence
suggests that the most effective approach involves combin-
ing well-structured, representative datasets with in-context
learning techniques. These strategies help guide the model
toward producing coherent and relevant outputs. Multi-agent
architectures, where different models collaborate or specialize
in distinct subtasks, also show potential in enhancing the
formulation process. However, techniques such as fine-tuning
and RAG, though conceptually promising, have not been suf-
ficiently explored in this context. Further empirical evaluation
is needed to determine their comparative effectiveness.
What are the key challenges and future directions
for improving LLM-based mathematical modeling? The
key challenges identified include limited numerical reasoning,
sensitivity to input complexity, reliance on pattern matching
rather than logical inference, and the inability to filter irrel-
evant information. In addition, the lack of diverse datasets,
open-source model utilization, and comprehensive evaluation
frameworks limits progress in the field.
VIII. EXPERIMENTAL DESIGN AND RESULTS
This section presents the experimental design and empirical
findings of our study, which investigates the ability of LLMs
to generate mathematical optimization formulations from nat-
ural language descriptions. We implemented an experiment
designed to evaluate the performance of language models
under both zero-shot and few-shot prompting conditions. We
analyze performance trends, identify observed limitations,
and highlight potential opportunities. These findings lay the
foundation for the subsequent sections, which highlight key
challenges and propose directions for future research.
A. Experimental Design
This section outlines the core components of the experiment,
including the design of optimization problems, prompting
strategies, the selected LLMs and their configurations, and the
evaluation metrics.
1) Problems Design: Despite the recent surge in applying
LLMs to a wide range of reasoning and problem-solving tasks
in OR, the availability of datasets specifically designed to test
the ability of LLMs in mathematical modeling in the computer
networks domain remains a critical gap.
Existing datasets primarily address general mathematical
modeling problems or simple scheduling tasks, thus neglecting
the essential domain-specific datasets. As each domain has
its own characteristics, terms, and constraints that might not
necessarily exist in other domains, there is a need for a
domain-specific dataset.
To address this gap, we present ten optimization prob-
lems specifically designed to evaluate LLM’s capabilities in
mathematical modeling in the computer network domain,
following the structure of the most recent challenging dataset,
ComplexOR [19]. Appendix XI provides a description of each
problem.
2) Prompting Strategies: To guide the LLMs in translat-
ing natural language problem descriptions into formal math-
ematical formulations, we developed three distinct prompt
templates. Each prompt reflects a unique reasoning strategy
and was carefully designed to elicit structured and consistent
outputs from the models. Prompts were presented alongside


--- Page 25 ---
25
TABLE XIV: Summary of model details and configurations.
Model
Model Version
Temp
Max
Tokens
Source
DeepSeek
Math
DeepSeek-Math-
7b-Instruct
0.1
900
Open
GPT-4o
GPT-4o
0.1
900
Closed
the problem description and sample data as part of the input.
The designed prompts are shown below.
Prompt 1: Act-As-Expert
You are an expert in mathematical optimization. Solve
the problem by clearly defining:
1) Decision variables.
2) Objective function.
3) Constraints.
Finally: Output the complete mathematical formula-
tion. Do not include any explanations.
Prompt 2: CoT
Solve the problem using a logical step-by-step ap-
proach:
1) Define the decision variables.
2) Formulate the objective function.
3) Specify the constraints.
Finally: Provide the complete mathematical formula-
tion. Do not include any explanations.
Prompt 3: Self-Consistency
Generate three independent mathematical formulations
of the same optimization problem:
• Each should include decision variables, an objec-
tive function, and constraints.
• Internally
evaluate
and
compare
them,
then
choose the best formulation.
Finally: Output only the final selected formulation. Do
not include any explanations.
3) LLMs and Configurations: We evaluated two state-of-
the-art LLMs: DeepSeek Math (open-source) and GPT-4o
(closed-source). These models were selected based on their
demonstrated strengths in mathematical reasoning and opti-
mization tasks. To ensure a fair comparison, both models were
configured with the same temperature and maximum token
limit. Table XIV summarizes the key settings.
4) Evaluation Metrics: In the experiment, we evaluated
the quality of the LLM-generated optimization formulations
using three key metrics: Optimality gap, token-level F1 score,
and compilation accuracy. These metrics, previously defined
in Section VI, are selected to capture different aspects of
correctness. The optimality gap quantifies the deviation be-
tween the objective value obtained from the generated for-
mulation and the known optimal value, providing a measure
of numerical accuracy. The token-level F1 score assesses
symbolic similarity by comparing tokenized expressions in
the generated and reference formulations, capturing structural
correctness. The compilation accuracy metric verifies whether
the generated code can be parsed and executed without errors,
serving as a prerequisite for downstream evaluations. Together,
these metrics provide a multidimensional assessment of model
performance across functional, structural, and syntactic levels.
B. Experimental Results
This experiment investigates the ability of LLMs to trans-
late natural language descriptions into formal mathematical
optimization formulations under both zero-shot and in-context
learning settings. The goal is to evaluate how prompting
strategies and contextual demonstrations influence formulation
quality across a diverse set of optimization problems.
As outlined in the experimental setup, we use ten network-
ing optimization problems of varying complexity, covering
tasks such as routing, resource allocation, and scheduling.
Each problem is paired with three prompting strategies:
Act-as-expert, CoT, and self-consistency, designed to guide
model reasoning in different ways. Two state-of-the-art LLMs,
DeepSeek Math and GPT-4o, are evaluated using identical
configurations to ensure a fair comparison. We consider three
prompting configurations: Zero-shot (problem and prompt
only), one-shot (a single solved example), and two-shot (two
solved examples), with examples drawn from the ComplexOR
dataset [19]. This unified setup allows us to assess the models’
performance across multiple levels of contextual support using
a consistent experimental protocol.
To evaluate the generated formulations, we use three com-
plementary metrics: Optimality gap, token-level F1 score,
and compilation accuracy, each capturing a distinct aspect of
performance; numerical accuracy, symbolic structure, and syn-
tactic soundness, respectively. Tables XV and XVI report the
optimality gaps for DeepSeek Math and GPT-4o, respectively,
across all prompting strategies and in-context configurations.
Tables XVII and XVIII present the token-level F1 scores
for both models, Fig. 15 visualizes the distribution of token-
level F1 scores, and Table XIX summarizes the compilation
accuracy comparisons.
1) Results Analysis: The results reveal mixed and often
inconsistent patterns regarding the effect of in-context learning
on model performance. However, a consistent trend emerges
in the numerical evaluation: GPT-4o demonstrates superior
performance in terms of optimality gap, achieving signifi-
cantly lower values than DeepSeek Math across nearly all
problem instances and prompting configurations, as shown in
Tables XV and XVI. GPT-4o attains near-zero gaps for simpler
problems such as P1, P2, P6, P8, and P10, and maintains
stable accuracy even on more complex tasks. In contrast,
DeepSeek Math exhibits greater variability and more frequent
degradation in performance as problem complexity increases.
Although some improvements are observed under one-shot
prompting, particularly with the act-as-expert strategy, these
gains are inconsistent. These findings suggest that GPT-4o


--- Page 26 ---
26
TABLE XV: Optimality gaps for the DeepSeek model across different in-context learning settings and prompting strategies.
Problem
Act-As-Expert
CoT
Self-Consistency
Zero-shot
One-shot
Two-shot
Zero-shot
One-shot
Two-shot
Zero-shot
One-shot
Two-shot
P1
0
0
0
0
0.57
0
0.57
0
0
P2
0
0
0
0
0
0
0
0
0
P3
1
0.25
0.5
0.25
0.25
0.75
0.97
1
1
P4
1
0.14
1
1
1
0
1
1
1
P5
0.13
0
0.13
0.1
0.98
0.13
0.23
0.98
0.13
P6
0
0
0
0
0
0
0
0
0
P7
1.82
0.64
1.82
4.64
1.66
6.36
1.82
1
0.12
P8
0.45
0
0
0
0.1
0
0.63
0.1
0
P9
1
1
1
1
1
0.06
1
1
1
P10
0
0
0
0
0
0
0
0
0
TABLE XVI: Optimality gaps for the GPT-4o model across different in-context learning settings and prompting strategies.
Problem
Act-As-Expert
CoT
Self-Consistency
Zero-shot
One-shot
Two-shot
Zero-shot
One-shot
Two-shot
Zero-shot
One-shot
Two-shot
P1
0
0.04
0.04
0
0.04
0.04
0
0.04
0.04
P2
0
0
0
0
0
0
0
0
0
P3
0.25
0.25
0.25
0.75
0.25
0.25
0.25
0.25
0.25
P4
0
0
0
0
0
0
0
0
0
P5
0.13
0
0
0.13
0
0
0.13
0
0
P6
0
0
0
0
0
0
0
0
0
P7
0.18
2.5
2.5
0.18
2.5
2.5
0.18
2.5
2.5
P8
0
0
0
0
0
0
0
0
0
P9
1
1
1
1
1
1
1
1
1
P10
0
0
0
0
0
0
0
0
0
TABLE XVII: Token-level F1 scores for DeepSeek-Math-7B-Instruct across prompting strategies and in-context settings.
Problem
Act-as-Expert
CoT
Self-Consistency
Zero-shot
One-shot
Two-shot
Zero-shot
One-shot
Two-shot
Zero-shot
One-shot
Two-shot
P1
0.41
0.49
0.53
0.36
0.43
0.42
0.29
0.13
0.33
P2
0.42
0.52
0.44
0.40
0.42
0.40
0.38
0.37
0.41
P3
0.22
0.27
0.22
0.18
0.23
0.20
0.17
0.14
0.20
P4
0.20
0.28
0.20
0.15
0.25
0.17
0.19
0.00
0.16
P5
0.37
0.41
0.46
0.39
0.41
0.42
0.39
0.41
0.45
P6
0.49
0.51
0.53
0.48
0.51
0.52
0.47
0.50
0.51
P7
0.53
0.59
0.58
0.53
0.58
0.60
0.51
0.54
0.59
P8
0.38
0.42
0.41
0.40
0.41
0.40
0.41
0.39
0.40
P9
0.76
0.81
0.83
0.73
0.86
0.81
0.68
0.78
0.82
P10
0.59
0.62
0.60
0.60
0.62
0.61
0.59
0.82
0.62
TABLE XVIII: Token-level F1 scores for GPT-4o across prompting strategies and in-context settings.
Problem
Act-As-Expert
CoT
Self-Consistency
Zero-shot
One-shot
Two-shot
Zero-shot
One-shot
Two-shot
Zero-shot
One-shot
Two-shot
P1
0.50
0.59
0.56
0.53
0.64
0.60
0.51
0.55
0.58
P2
0.53
0.58
0.57
0.55
0.63
0.60
0.54
0.62
0.61
P3
0.25
0.32
0.30
0.23
0.29
0.27
0.21
0.25
0.28
P4
0.28
0.35
0.30
0.25
0.35
0.29
0.26
0.32
0.31
P5
0.44
0.48
0.46
0.45
0.49
0.47
0.43
0.47
0.47
P6
0.54
0.56
0.55
0.52
0.55
0.54
0.52
0.54
0.53
P7
0.62
0.65
0.63
0.60
0.64
0.62
0.60
0.62
0.61
P8
0.44
0.49
0.46
0.45
0.49
0.47
0.44
0.48
0.47
P9
0.73
0.76
0.75
0.71
0.76
0.75
0.69
0.75
0.74
P10
0.59
0.61
0.60
0.58
0.61
0.60
0.57
0.60
0.59


--- Page 27 ---
27
TABLE XIX: Compilation accuracy comparison between GPT-4o and DeepSeek across prompting strategies.
Prompt Style
GPT-4o (Mean)
DeepSeek (Mean)
Difference (%)
Act-As-Expert
1.00
0.95
+5.0%
CoT
0.95
0.75
+26.7%
Self-Consistency
0.85
0.70
+21.4%
Overall Average
0.93
0.80
+16.7%
Fig. 15: Token-level F1 score distribution across different
prompt shot settings for GPT-4o and DeepSeek-Math-7B-
Instruct. GPT-4o exhibits consistently higher median scores
and lower variance.
benefits from stronger internal reasoning capabilities and is
less dependent on contextual examples.
In terms of symbolic fidelity, token-level F1 scores, as
shown in Tables XVII and XVIII, highlight GPT-4o’s clear
advantage in generating formulations that are structurally and
semantically aligned with the reference solutions. GPT-4o
outperforms DeepSeek Math across all prompting strategies
and context settings, with particularly notable gains under CoT
and self-consistency prompts. This suggests that GPT-4o is
more effective at capturing the symbolic structure of opti-
mization problems, even when the surface form or phrasing
varies. Fig. 15 further illustrates this advantage, showing GPT-
4o’s consistently higher median F1 scores and lower variance,
indicating more stable and reliable symbolic output across
varied scenarios.
Finally, compilation accuracy results, as shown in Ta-
ble XIX, demonstrate that GPT-4o is also more reliable
in generating executable Python code. It achieves a 16.7%
higher average compilation accuracy compared to DeepSeek
Math and performs especially well under reasoning-intensive
prompts. GPT-4o reaches perfect execution under the act-
as-expert prompt and maintains strong results across other
configurations. In contrast, DeepSeek Math struggles under
CoT and self-consistency settings, frequently producing code
that fails to compile or execute. These findings reinforce GPT-
4o’s robustness not only in numerical and symbolic correctness
but also in producing syntactically sound and functionally
usable optimization models.
2) Limitations: Despite the strengths observed in GPT-
4o and the structured experimental setup, several limitations
emerge from this study. First, prompting strategies are not
universally effective. While the act-as-expert prompt often
performs well, especially for GPT-4o, no strategy consistently
delivers superior results across all problems and models.
DeepSeek Math, in particular, is highly sensitive to prompt
phrasing and structure, resulting in unstable outputs and in-
consistent gains from in-context learning.
Second, model behavior remains unpredictable in complex
problem scenarios. Both models struggle with tasks that re-
quire implicit constraint modeling or multiple interdependent
variables, most notably P3, P4, P7, and P9. Even when ex-
amples are provided through one-shot or two-shot prompting,
performance on these complex problems often fails to improve
and, in some cases, degrades. This indicates that current
models still lack the deep abstraction and generalization ca-
pabilities needed for complex optimization formulations.
Third, the evaluation framework itself poses limitations.
Although the optimality gap, token-level F1 score, and com-
pilation accuracy offer complementary perspectives, they do
not explain the precise source of errors. For instance, a poor
optimality gap could result from incorrect decision variable
definitions, misaligned constraints, or an erroneous objective
function, but these components are not individually assessed.
This lack of granularity limits our ability to diagnose model
failures or guide fine-grained improvements in prompt design
and model architecture.
3) Opportunities: Despite the challenges identified, the ex-
perimental findings point to several opportunities for advanc-
ing LLM performance in mathematical optimization formu-
lation. First, the relative success of structured prompts such
as act-as-expert suggests that better prompting strategies can
improve model reasoning. However, the inconsistency across
problems indicates that a one-size-fits-all approach is insuf-
ficient. This opens the door for adaptive prompting methods
that can adjust prompt structure based on the characteristics
of the problem, such as complexity, domain, or variable types.
Second, the performance gap observed between GPT-4o and
DeepSeek Math may stem less from differences in model scale
and more from disparities in training objectives, instruction
tuning, or domain alignment. Rather than assuming that larger
models inherently perform better, recent work has shown that
small language models (SLMs) can be highly effective in
structured, agent-based systems due to their modularity, con-
trollability, and efficiency [84]. This highlights the importance
of training strategies that prioritize task decomposition, clarity
of representation, and domain-specific supervision. Develop-


--- Page 28 ---
28
ing datasets that explicitly annotate decision variables, con-
straints, and objective functions, with varied representations
and complexity levels, may significantly improve both large
and small models’ ability to learn the structure of optimization
problems and generalize across domains.
Third, improving the structure of problem inputs presents
another promising direction. Presenting tasks in a modular or
semi-formal format, explicitly separating components such as
objectives, variables, and constraints, could reduce ambiguity
and help models process complex formulations more effec-
tively. Such representations also make it easier to apply multi-
agent or modular model strategies, where different LLMs
specialize in generating different parts of the formulation.
Finally, our results underscore the need for more granular
evaluation methods. While current metrics provide useful high-
level signals, they do not explain where models fail or how to
improve them. Moving toward component-level evaluation that
separately scores variable definitions, constraint correctness,
and objective alignment could provide more actionable feed-
back for both prompt design and model development. These
future directions, taken together, represent a promising path
toward more accurate, interpretable, and robust use of LLMs
in mathematical optimization modeling.
Building on the combined insights from our meta-analysis
of the existing literature and the empirical findings from both
zero-shot and in-context learning experiments, the following
two sections outline future research directions centered on two
key areas: (i) Advancing LLM learning and mathematical rea-
soning capabilities, and (ii) improving the understanding and
diagnosis of LLM limitations in the context of mathematical
optimization modeling.
IX. ENHANCING LLM LEARNING AND MATHEMATICAL
REASONING CAPABILITIES
In light of the limitations uncovered through our meta-
analysis and experiments, it is clear that current LLMs face
significant challenges in reliably formulating mathematical
optimization problems. These challenges include sensitivity to
prompt phrasing, limited generalization to structurally com-
plex tasks, and inconsistent performance when confronted
with unfamiliar or varied problem types. To address these
limitations, this section explores several promising directions
for improving how LLMs learn and reason in mathematical
contexts. Specifically, we focus on the development of struc-
tured training datasets, the adoption of modular or collabo-
rative model architectures, the integration of RAG pipelines,
and the refinement of prompting strategies. Collectively, these
approaches aim to enhance the robustness, adaptability, and
reasoning depth of LLMs in formulating optimization prob-
lems.
A. Training Specialized LLMs with Structured Datasets
A promising direction for improving the reasoning capabili-
ties of LLMs in mathematical optimization is the development
of structured, domain-specific training datasets. Instead of
relying solely on general-purpose corpora, models can benefit
substantially from datasets curated for specific application do-
mains, such as scheduling, logistics, or network design, where
the problem structure, terminology, and modeling conventions
are well defined. Domain specialization of this kind enhances
the model’s ability to generalize within its context and generate
accurate, interpretable formulations.
The following subsections outline key design principles
for constructing such datasets, focusing on structured repre-
sentation, complexity variation, and data augmentation, each
critical for training LLMs to reason effectively in mathematical
optimization contexts.
1) Structuring Datasets to Capture Reasoning: Many ex-
isting datasets present optimization problems using free-form
text, code snippets, or solution outputs without explicitly
identifying the core components of the formulation, including
the decision variables, objective function, and constraints. This
limitation is evident in resources such as [85], which lack the
modular structure necessary for teaching models how to reason
through the formulation process itself. To support learning that
goes beyond simple input-output mapping, datasets should be
designed to expose the logical structure of the modeling task
transparently and consistently.
Among current resources, the most effective structured
datasets typically provide three key components for each
record. First, a problem statement offers a natural language
description of the optimization task. Second, a file containing
the mathematical elements defines the sets, indices, param-
eters, and decision variables used in the formulation. Third,
the mathematical formulation presents the complete formal
model, including the objective function and constraints [19].
While this three-part structure establishes a solid foundation,
it can be enhanced to better support step-by-step reasoning
and interpretability.
We propose extending this structure by introducing a fourth
component: A detailed breakdown of the problem statement
into its semantic and logical elements. This leads to a stan-
dardized four-part structure for each dataset entry:
1) Problem statement: A clear, natural language descrip-
tion of the optimization scenario.
2) Problem breakdown (new addition): A structured
decomposition of the problem written in English. This
includes:
• Identification of the objective to be optimized.
• Description of the decision variables (distinguishing
between true and auxiliary variables).
• Categorization of constraints based on their role: (i)
those directly stated in the problem statement, (ii)
those added during reformulation (e.g., for lineariza-
tion), and (iii) auxiliary constraints used to link
different model components or support structural
decomposition.
3) Mathematical elements: Definitions of sets, indices,
parameters, and associated data. This file should include
semantic annotations that map textual concepts to sym-
bolic representations.
4) Mathematical formulation: The complete optimization
model, presented in a modular format (objective func-


--- Page 29 ---
29
tion, decision variables, and constraints), with metadata
specifying the origin and role of each element.
This extended structure enables models to internalize not
only the mapping from text to equations but also the interme-
diate reasoning steps required to construct a correct and mean-
ingful formulation. It improves transparency, supports error
analysis, and facilitates reverse engineering of the modeling
process.
A notable step toward structured modeling has been intro-
duced in the OptiMUS system [18], which demonstrates the
power of modular, multi-agent LLM pipelines that translate
natural language descriptions into executable optimization
code. While OptiMUS leverages a connection graph and
structured prompts to guide agent-based reasoning at inference
time, our proposal complements this by focusing on building
datasets that embed semantic structure and reasoning path-
ways directly into the training data. This distinction makes
our approach highly synergistic; the proposed dataset format
could help train future agent-based systems to reason more
effectively, even with limited context or smaller models.
2) Incorporating Problem Complexity: A second key di-
rection is to ensure that datasets span a wide range of
problem complexities. Our experiments show that LLMs such
as GPT-4o and DeepSeek Math struggle with more complex
tasks, especially those involving multiple constraints, auxil-
iary variables, or interdependent decision components. These
limitations underscore the need to include both simple and
advanced formulations in training data.
By exposing models to problems with varying structural
difficulty, we can encourage more robust reasoning behavior
and better equip models to generalize to real-world scenarios
with nuanced requirements. A diverse complexity range allows
LLMs to learn how to deconstruct and solve optimization tasks
of differing scales and sophistication.
3) Applying Data Augmentation Techniques: A third impor-
tant strategy is the use of data augmentation to improve dataset
diversity and robustness. Augmentation exposes models to
multiple representations of the same problem, strengthening
both linguistic and structural generalization, especially in zero-
shot and few-shot settings. Effective augmentation techniques
include:
• Paraphrasing: Rewriting the problem statement using
varied natural language.
• Mathematical rewriting: Reordering constraints or re-
naming variables while preserving semantic equivalence
to encourage structural flexibility.
• Constraint variation: Adding, modifying, or removing
constraints to simulate real-world variability.
These strategies help models recognize that different surface
forms can represent the same underlying logic, which is
essential for reasoning-aware generalization.
In summary, improving LLM reasoning in mathematical
optimization requires more than domain coverage. It demands:
(i) well-structured datasets that capture intermediate reasoning
steps, (ii) inclusion of problems with varying levels of com-
plexity, and (iii) systematic augmentation to increase linguistic
and structural diversity. Together, these directions provide
Fig. 16: Visual representation of the proposed structured
dataset construction framework for optimization modeling.
Each record consists of four components: (i) A problem
statement describing the task in natural language, (ii) a plain-
English breakdown of objectives, variables, and constraints,
(iii) a list of sets, indices, parameter symbols, and corre-
sponding input data values, and (iv) the complete mathemat-
ical formulation. Dataset-level enhancements, such as data
augmentation and problem complexity variation, are applied
to increase diversity and robustness. The resulting structured
dataset is then used for both fine-tuning and in-context learning
of LLMs.
a strong foundation for building robust, generalizable, and
interpretable optimization modeling systems.
Fig. 16 illustrates the proposed four-part dataset structure,
along with enhancements for complexity and augmentation.
B. Modular Use of Multiple LLMs
A promising direction for enhancing the performance of
LLMs in mathematical optimization formulation is the tran-
sition from single-model pipelines to a modular, multi-agent
architecture. Instead of relying on a single LLM to generate the
entire formulation end-to-end, the task can be decomposed into
smaller, manageable subtasks, each delegated to a specialized
model. This divide-and-conquer strategy enables each LLM to
focus on a specific aspect of the modeling process, potentially
improving the overall accuracy, interpretability, and reliability
of the formulation pipeline.
The motivation for such modularity is strongly supported by
recent advances in multi-agent and cross-team LLM coordina-
tion. Du et al. [86] presented a comprehensive survey detailing
how LLMs can manage multimodal and multi-component


--- Page 30 ---
30
tasks effectively. They outline two major strategies: (i) Tool-
augmented design, where a central LLM delegates subtasks to
multiple external models tailored for specific operations, and
(ii) monolithic LLMs trained to handle multiple modalities
within a single model.
Building on this foundation, Zhou et al. [87] proposed a
central orchestration framework in which an LLM coordi-
nates domain-specific generative models (DGMs) to synthesize
multi-modal sensor data. Likewise, He et al. [88] introduced
a dynamic ‘cross-team orchestration’ approach that resolves
the inefficiencies and coordination bottlenecks often encoun-
tered in traditional static multi-agent systems, particularly as
the complexity of the task scales. These works collectively
demonstrate that task decomposition and model specialization
lead to substantial improvements in reasoning quality, task
success rate, and system flexibility.
Inspired by these results, we propose decomposing the
mathematical modeling task across multiple LLMs, each spe-
cializing in a particular modeling component or formulation
paradigm. We outline four key strategies for task decompo-
sition: (i) Component-wise specialization, (ii) cross-domain
specialization, (iii) formulation-type specialization, and (iv)
hierarchical decomposition. The following subsections explore
each in detail.
1) Component-wise Specialization: One promising strategy
for improving LLM performance in mathematical optimization
is to divide the formulation task into distinct components and
assign each to a dedicated model. In this component-wise
setup, different LLMs are responsible for specific subtasks,
such as identifying decision variables, constructing constraints,
or extracting sets and parameters. Each model is trained or
fine-tuned to specialize in its role, allowing for more focused
reasoning and reducing the overall complexity of the task.
For example, one LLM may focus on understanding what
the problem is asking, interpreting the objective, and identify-
ing the appropriate decision variables. Another may handle the
formal definition of constraints, while a third is responsible
for extracting relevant sets, indices, and input data from
the problem description. This modular structure mirrors how
human experts build optimization models: by breaking down
the problem into logical parts that can be reasoned about
and refined independently. By narrowing the focus of each
LLM, this approach improves accuracy, interpretability, and
robustness in the overall formulation process.
To further illustrate this approach, Fig. 17 presents a more
granular component-wise architecture. In this setup, three
specialized LLMs are responsible for: (i) Extracting sets and
data, (ii) identifying decision variables and their types, and (iii)
representing mathematical constraints. A central LLM then
aggregates their outputs into a unified, executable optimization
model.
2) Cross-domain Specialization: Another effective modular
strategy involves assigning LLMs based on domain expertise.
In this setup, each LLM is specialized in a specific knowledge
domain, such as healthcare, logistics, or scheduling, and is
responsible for interpreting problems within that context. For
instance, a healthcare-specific LLM may understand medical
terminology, policy constraints, or clinical workflows, while
a logistics LLM focuses on supply chain structures, trans-
portation rules, or delivery windows. These domain-specific
LLMs extract relevant information from natural language
descriptions, including entities, objectives, and constraints.
Once this domain-level understanding is established, the
extracted information is passed to a separate LLM trained
specifically in mathematical modeling. This model is respon-
sible for transforming the contextual knowledge into a formal
optimization formulation. The final step is handled by a
central LLM that integrates the mathematical components and
domain-specific insights into a complete and coherent model.
Fig. 18 illustrates this cross-domain specialization strategy.
Each domain-specific LLM contributes contextual understand-
ing tailored to its area of expertise, while the mathematical
reasoning LLM formalizes this input into symbolic structures.
The outputs are then aggregated by the main LLM to generate
the final optimization formulation.
3) Formulation-type Specialization: Another modular strat-
egy involves dividing the formulation process based on the
type of optimization problem being addressed. In this ap-
proach, each LLM is specialized in a particular mathematical
formulation type, such as linear, integer, non-linear, stochastic,
or combinatorial optimization. This setup reduces the need for
a single model to handle multiple mathematical paradigms, en-
abling each specialized LLM to focus on the unique structure
and reasoning patterns of its assigned formulation type.
As illustrated in Fig. 19, the initial prompt is parsed and
routed to the appropriate LLMs based on the characteristics
of the problem. For instance, one LLM may handle formu-
lations involving continuous variables and linear constraints,
while another is responsible for integer programming ele-
ments. Additional models may address non-linear structures or
uncertainty-based (stochastic) components. Each specialized
LLM generates a portion of the overall model, tailored to
its formulation type, and these outputs are then aggregated
by a central LLM into a complete, coherent optimization
formulation.
4) Hierarchical Decomposition: Another promising direc-
tion is the use of a hierarchical architecture, in which a
high-level controller LLM is responsible for decomposing a
complex problem into smaller sub-problems based on struc-
tural, domain-specific, or formulation-related complexity. Each
sub-problem can then be assigned to a specialized LLM for
independent processing. Once the subtasks are completed, the
controller reassembles the outputs into a coherent and com-
plete optimization formulation. This hierarchical setup enables
dynamic problem structuring, supports domain-specific fine-
tuning at the sub-problem level, and offers scalability for
handling multi-objective or highly complex formulations.
C. Chain of RAGs
RAGs have emerged as a powerful technique for enhancing
the reasoning capabilities of LLMs by incorporating exter-
nal knowledge into the generation process. Traditional RAG
frameworks typically perform a single retrieval step before
generation, using the retrieved content as static context. While
effective in many knowledge-intensive tasks, this approach


--- Page 31 ---
31
Fig. 17: Component-wise specialization of the formulation task across dedicated LLMs. One model extracts sets and data,
another identifies decision variables and their types, and a third represents mathematical constraints. A main LLM then integrates
these outputs into a unified optimization model.
Fig. 18: Cross-domain specialization for mathematical modeling. Each LLM is trained on a specific application domain (e.g.,
healthcare, logistics) and extracts relevant contextual information from the prompt. A separate LLM, specialized in mathematical
reasoning, transforms this information into a formal optimization model. The main LLM integrates these outputs into a unified
formulation.


--- Page 32 ---
32
Fig. 19: A modular architecture based on formulation-type specialization. Each LLM is responsible for handling a specific
class of optimization problems, such as linear, combinatorial, non-linear, or stochastic programming. These specialized models
extract and construct sub-models aligned with their formulation type, which a central LLM then aggregates into a unified
optimization model.
is fundamentally limited by the quality and relevance of the
retrieved information. In complex scenarios, a single retrieval
step often fails to capture all necessary aspects of the problem,
leading to incomplete, irrelevant, or even hallucinated outputs.
To overcome this limitation, the chain-of-RAGs paradigm was
proposed by Wang et al. [89]. In this framework, retrieval
is performed iteratively: Each step refines the context based
on the evolving state of reasoning. Rather than retrieving all
relevant documents at once, the model incrementally forms
sub-queries, gathers targeted evidence at each stage, and pro-
gressively builds a more informed and accurate representation.
This iterative retrieval mechanism improves contextual align-
ment, reduces noise, and supports deeper, multi-hop reasoning,
especially in domains where stepwise information acquisition
is essential.
In the context of mathematical optimization, chain-of-RAGs
presents a promising opportunity to enhance LLM reasoning
by mirroring the natural workflow of human modelers. Rather
than attempting to formulate the entire problem in a single
step, the LLM can engage in a structured, staged process,
retrieving and reasoning over key components sequentially.
For example, the model might begin by identifying and
retrieving domain-specific patterns for decision variables (e.g.,
assignment variables in routing or scheduling tasks), followed
by a focused retrieval stage for constraints (such as capacity
limits, time windows, or precedence relations), and finally, for-
mulate the objective function based on the previously gathered
structure. Each retrieval stage would be guided by the partial
formulation constructed thus far, allowing the LLM to refine its
understanding dynamically. Moreover, integrating structured
external knowledge, such as optimization templates, technical
documentation, or domain-specific knowledge graphs, into the
retrieval pipeline can further guide the model toward more
accurate and complete formulations. This approach has the
potential to reduce hallucinations, increase interpretability, and
improve performance on complex, multi-component problems
where current end-to-end prompting strategies often fall short.
As such, chain-of-RAGs offers a compelling pathway for
enhancing the reasoning depth and formulation accuracy of
LLMs in mathematical optimization tasks.
D. Improving Prompting Strategies
Prompting plays a critical role in guiding LLMs to generate
mathematical optimization formulations. However, as observed
in our experiment and the literature, there is no universally
optimal prompt. A prompt that performs well for one type
of problem may fail on another. For example, while some
strategies may be effective for simple assignment problems,
they often fall short in capturing the complexity of scheduling
or multi-stage tasks. This inconsistency highlights the need for
more flexible and intelligent prompting strategies.
One promising direction is the development of dynamic
prompting frameworks that can adapt prompts based on the
characteristics of the problem. For instance, if a task involves
numerous binary variables or nested constraints, the system
could automatically select a prompt format better suited to
that structure. A classifier or meta-model could be trained to
predict the most appropriate prompt style for different problem
types.
Another valuable direction involves designing new, general-
purpose prompts specifically tailored for optimization tasks.
These could combine structured expert-style guidance with


--- Page 33 ---
33
step-by-step reasoning, for example, prompting the model to
define decision variables first, followed by constraints, and
finally the objective function. Such prompts could embed a
standardized formulation scaffold, leading the model through
a logical and interpretable workflow rather than relying on
open-ended instructions. This structured approach may help
reduce ambiguity, improve consistency across problem types,
and minimize common formulation errors such as missing
components or misaligned constraints.
In summary, improving prompting strategies, whether
through adaptive mechanisms or robust, domain-specific
prompt templates, remains a key avenue for enhancing the
accuracy, reliability, and generalizability of LLMs in mathe-
matical optimization formulation.
E. Neuro-Symbolic Formulation in Mathematical Optimiza-
tion
Despite recent advances in applying LLMs to optimization
modeling, recent investigations have identified persistent lim-
itations in LLMs’ ability to generate correct and verifiable
mathematical formulations [29], [30], [60]. These limitations
are particularly critical in mathematical optimization tasks,
where structural feasibility, constraint satisfaction, and solution
optimality must be strictly preserved. Addressing these chal-
lenges calls for hybrid neuro-symbolic systems that combine
neural language understanding with symbolic solvers, verifi-
cation procedures, and programmatic constraint reasoning.
One promising direction is the integration of program-
aided reasoning frameworks, such as program-aided language
(PAL) models and tool-integrated reasoning agents (ToRA),
where LLMs are fine-tuned or prompted to generate exe-
cutable optimization code using libraries, such as Gurobi,
OR-Tools, or PuLP [90], [91]. These frameworks translate
natural language descriptions into formal mathematical models
and offload the solving process to dedicated optimization
solvers. Additionally, reasoning agents based on architectures
like ReAct and OR-LLM-Agent enhance this interaction by
allowing the LLM to decide when to call an external solver,
how to handle infeasibility, and how to iteratively refine model
components [92], [93].
Symbolic feedback mechanisms, such as reporting con-
straint violations, infeasibility, or numerical instability, can
guide LLMs to revise and regenerate improved formulations.
These feedback loops, forming a core part of hybrid neuro-
symbolic systems, support the iterative validation of solution
structures and enhance robustness in deployment [29], [73].
Furthermore, synthetic data generation using optimization
solvers provides a scalable path to fine-tune LLMs with struc-
turally sound, domain-specific training instances [30], [61].
This process supports learning optimization patterns across
application domains like logistics, energy, and scheduling,
and serves as a valuable complement to manually curated
datasets. It also enables domain adaptation while ensuring
solver-grounded correctness and feasibility.
A key enabler of correctness in such systems is formal
constraint verification, often supported by SMT solvers or fea-
sibility checkers [62]. SMT solvers verify whether a symbolic
Fig. 20: Neuro-symbolic architecture combines language mod-
els with symbolic solvers for accurate optimization.
model meets logical and numerical constraints across domains
such as scheduling, planning, or energy balancing. Similarly,
abstract planning modules serve as high-level reasoning layers
that generate constraint sketches and structural model outlines
before detailed formulation [74]. In summary, neuro-symbolic
architectures offer a compelling pathway to enable verifiable
and scalable optimization modeling. These systems blend the
generative strengths of LLMs with the rigor of symbolic
solvers and structured reasoning.
Fig. 20 presents a conceptual neuro-symbolic architecture
for optimization modeling, integrating semantic interpretation,
symbolic validation, and solver feedback. The process begins
with a natural language description of a decision problem,
which is parsed by a language model (e.g., DeepSeek) to gen-
erate an initial formulation. The LLM output is then handled in
two parallel paths. One path sends it to a symbolic solver (e.g.,
DeepSeek, OR-Tools) for computation, while the other runs a
validation workflow. This includes an abstract planning step,
an intermediate stage that extracts structural elements such as
objectives, variables, and constraints from the user’s intent.
Validation continues via constraint checkers, including SMT-
based feasibility checks to ensure logical and mathematical
consistency. If errors are detected, the system may regenerate
or revise the formulation. A synthetic data generator can also
create structurally similar validated problems to fine-tune the
LLM and reinforce solver-aligned learning. The architecture
distills emerging design patterns across recent neuro-symbolic
reasoning work [90]–[93], supporting iterative verification,
trust, and correctness in LLM-driven optimization.


--- Page 34 ---
34
X. UNDERSTANDING AND DIAGNOSING LLM
LIMITATIONS
Despite ongoing efforts to improve the learning and reason-
ing capabilities of LLMs, a fundamental challenge remains:
We still lack a clear understanding of why LLMs succeed in
some formulation tasks and fail in others. As demonstrated in
our experiment, a model may generate accurate constraints but
incorrect decision variables, solve one problem but struggle
with a structurally similar one, or respond inconsistently to
different prompts. These unpredictable behaviors underscore
the need for a deeper understanding of how LLMs reason and
where their limitations lie.
To move beyond surface-level performance, it is essential to
develop tools and methodologies that allow for more precise
interpretation and analysis of model behavior. In this section,
we propose two future directions: (i) designing improved eval-
uation metrics that enable fine-grained assessment of model
outputs, and (ii) applying feature-based mapping techniques to
identify patterns between problem characteristics and model
performance. Together, these approaches aim to provide a
clearer picture of what LLMs can and can not do and to
support the development of more robust, interpretable, and
dependable models for mathematical optimization formulation.
A. Designing Better Evaluation Metrics
A fundamental challenge in evaluating LLMs for mathemat-
ical optimization tasks is the lack of interpretability behind
their successes and failures. In our experiment, we observed
cases where an LLM produced a correct formulation for one
problem but failed on another with a similar structure. In some
instances, the model accurately captured the constraints but
failed to define the decision variables or the objective function.
These inconsistencies highlight a critical gap: While current
evaluation metrics can assess overall formulation correctness,
they often do so without sufficient precision to identify which
components are correct or flawed.
To address this issue, it is important to examine the lim-
itations of the evaluation metrics used in our experiments.
Specifically, we employed three dimensions: Optimality gap,
token-level F1 score, and compilation accuracy, to obtain a
broad overview of model performance. While these metrics
can assess formulation correctness to some extent, each car-
ries inherent weaknesses that limit their ability to precisely
diagnose where and why a formulation fails.
In our experiments, we evaluated LLM outputs using three
primary dimensions: Optimality gap, token-level F1 score, and
compilation accuracy, to obtain a broad overview of model
performance and to reflect the metrics applied in our study.
However, each metric carries inherent weaknesses that limit
its ability to precisely diagnose where and why a formulation
fails.
The token-level F1 score, designed to assess symbolic
similarity between the generated and reference formulations, is
highly sensitive to surface-level variations that do not impact
semantic meaning. Differences in index notation (e.g., i and
j vs. d and l), variable naming, or formatting can result in
low F1 scores even when the model’s output is functionally
equivalent to the reference. Moreover, LLM-generated outputs
often omit formal elements, such as quantifiers or domain con-
straints, further complicating automated parsing and symbolic
comparison.
The optimality gap, although widely used as a solver-
level metric, also presents challenges when applied to LLM-
generated formulations. A low gap may suggest that the
model produced a correct or near-optimal solution, yet it
could mask significant issues in variable definitions, constraint
structures, or objective logic. Conversely, a high gap might
stem from minor syntax errors or alternative encodings that
are semantically valid but solver-incompatible. Critically, the
optimality gap provides no information about which part of
the formulation is flawed, limiting its usefulness for model
diagnosis or improvement.
Compilation accuracy, which checks whether the generated
code compiles and runs, serves as a basic quality filter. While
valuable for detecting incomplete or malformed outputs, this
metric offers only a shallow indication of correctness. Code
that executes successfully may still represent an incorrect or
incomplete optimization model. Additionally, syntactic success
is often influenced by prompt phrasing, making it difficult
to disentangle prompt engineering effects from actual model
capability.
Together, these limitations reveal the need for more com-
prehensive and diagnostic evaluation strategies. As LLMs are
increasingly used in critical reasoning tasks, particularly in
optimization and mathematical modeling, understanding why
a model works or fails is essential.
Future directions in evaluation should include component-
level metrics that assess the correctness of individual elements
within a formulation, specifically, decision variables, con-
straints, and objective functions. Relying solely on aggregate
scores can obscure which part of the formulation caused
the failure. Additionally, graph-based equivalence testing can
provide a more robust assessment of structural similarity
by focusing on the underlying logic rather than superficial
differences in syntax. Incorporating human-in-the-loop evalu-
ation, especially for domain-specific or ambiguous problems,
can further help calibrate and validate automated scoring
mechanisms.
To enable both broad and detailed insights, we propose the
development of a comprehensive evaluation framework that
integrates multiple complementary metrics. Such a framework
could combine solver-level, symbolic, and syntactic evalua-
tions to provide a well-rounded assessment of model perfor-
mance. Moreover, it could include a modular architecture com-
prising multiple LLMs, each trained to evaluate or generate
a specific component of the formulation. This would allow
each element, such as constraints or decision variables, to be
assessed in isolation, offering a clearer diagnosis of errors.
By combining these metrics and component-wise evaluations,
the framework would support both high-level benchmarking
and fine-grained analysis, offering a more interpretable and
actionable understanding of LLM behavior in mathematical
optimization tasks.
In summary, advancing evaluation methods beyond single-
score metrics is not merely a technical refinement; it is


--- Page 35 ---
35
a necessary step toward building transparent, reliable, and
interpretable LLM systems for complex reasoning tasks.
B. Feature Mapping for Failure Analysis
Traditional evaluation metrics, such as optimality gap,
token-level F1 score, and compilation accuracy, offer a quan-
titative assessment of model performance but provide limited
insight into why an LLM succeeds on certain optimization
problems and fails on others. In our experiment, we observed
inconsistent behavior across problem instances. For example,
a model may fully solve P1, generate a partially correct
formulation for P2, and fail on Problem P3 even when the
problems appear structurally similar. These unpredictable out-
comes highlight the limitations of surface-level metrics and
underscore the need for more diagnostic tools. To address
this, we propose feature mapping as a promising approach
for better understanding and interpreting LLM performance in
optimization problem formulation.
Feature mapping involves characterizing each problem us-
ing a set of descriptive attributes that capture its structural
and semantic properties. These attributes may include the
type and number of decision variables (e.g., binary, integer,
or continuous), the number and nature of constraints (e.g.,
equality, inequality, or logical conditions), the complexity of
the objective function (e.g., linear or nonlinear), the overall
problem size (i.e., number of variables and constraints), and
the application domain (e.g., routing, scheduling, or resource
allocation). By aligning these characteristics with observed
model outcomes, success, partial success, or failure, we can
begin to identify patterns and uncover structural factors that
influence LLM behavior.
For instance, an LLM may consistently succeed on problems
involving only continuous variables and a small number of
linear constraints but frequently fail on problems with binary
variables and nested logical dependencies. When such pat-
terns are systematically observed, they can serve as “failure
signatures” or heuristic rules. These rules might indicate, for
example, that the model is more reliable when the formulation
includes fewer than five constraints and a linear objective, but
less so when binary decision variables and conditional logic
are present.
Feature mapping can be applied at multiple levels of gran-
ularity. At the problem level, it enables analysis of the overall
formulation and corresponding outcomes. At a finer level,
constraint-level mapping can help identify specific structures,
such as disjunctive constraints or conditional dependencies,
that consistently trigger formulation errors. This multilevel
analysis supports a more precise understanding of model
limitations.
Ultimately, feature mapping can inform a range of fu-
ture developments. It enables rule-based prediction of model
performance, supports adaptive prompt selection based on
problem features, and provides actionable insights for targeted
model refinement or fine-tuning. Most importantly, it offers a
pathway toward more interpretable, predictable, and reliable
use of LLMs in complex reasoning tasks such as mathematical
optimization.
XI. CONCLUSION
This study explored the capabilities and limitations of LLMs
in mathematical optimization modeling through a systematic
literature review and empirical evaluation. Our meta-analysis
revealed persistent empirical gaps in symbolic reasoning,
formulation accuracy, and interpretability, underscoring key
limitations in current LLM-based approaches. To investigate
these challenges, we developed a domain-specific dataset and
evaluated the performance of state-of-the-art LLMs across
multiple prompting strategies. While the models demonstrated
progress in interpreting problem statements and generating
partial formulations, the results revealed ongoing difficulties in
producing complete, accurate, and interpretable mathematical
formulations, particularly for complex, domain-specific prob-
lems.
In response, we propose a set of targeted research directions
to address these limitations. These include designing struc-
tured, domain-adapted datasets; adopting modular, multi-agent
architectures; advancing prompting strategies; and integrating
neuro-symbolic reasoning with retrieval-augmented generation
techniques. We highlight two key research priorities emerging
from the identified empirical gaps: (i) advancing LLM learning
and mathematical reasoning capabilities and (ii) improving
the understanding and diagnosis of LLM limitations in the
context of optimization modeling. These recommendations
have the potential not only to enhance the effectiveness of
LLMs in solving complex real-world optimization problems
but also to support better decision-making, ultimately leading
to substantial cost savings for organizations.
REFERENCES
[1] M. A. K. Raiaan, M. S. H. Mukta, K. Fatema, N. M. Fahad, S. Sakib,
M. M. J. Mim, J. Ahmad, M. E. Ali, and S. Azam, “A review on large
language models: Architectures, applications, taxonomies, open issues
and challenges,” IEEE Access, vol. 12, pp. 26 839–26 874, Mar. 2024.
[2] A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F.
Tan, and D. S. W. Ting, “Large language models in medicine,” Nat.
Med., vol. 29, no. 8, pp. 1930–1940, Aug. 2023.
[3] J. Ahn, R. Verma, R. Lou, D. Liu, R. Zhang, and W. Yin, “Large lan-
guage models for mathematical reasoning: Progresses and challenges,”
in Proc. Conf. Eur. Chapter Assoc. Comput. Linguistics: Student Res.
Workshop (EACL SRW), Mar. 2024, pp. 225–237.
[4] X. Jiang, Y. Dong, L. Wang, Z. Fang, Q. Shang, G. Li, Z. Jin, and
W. Jiao, “Self-planning code generation with large language models,”
ACM Trans. Softw. Eng. Methodol., vol. 33, no. 7, pp. 1–30, Sep. 2024.
[5] J. Ahn, R. Verma, R. Lou, D. Liu, R. Zhang, and W. Yin, “Large lan-
guage models for mathematical reasoning: Progresses and challenges,”
arXiv preprint arXiv:2402.00157, Feb. 2024.
[6] W. Liu, H. Hu, J. Zhou, Y. Ding, J. Li, J. Zeng, M. He, Q. Chen, B. Jiang,
A. Zhou, and L. He, “Mathematical language models: A survey,” arXiv
preprint arXiv:2312.07622, Dec. 2025.
[7] Z. Chen, H. Mao, H. Li, W. Jin, H. Wen, X. Wei, S. Wang, D. Yin,
W. Fan, H. Liu, and J. Tang, “Exploring the potential of large language
models (LLMs) in learning on graphs,” ACM SIGKDD Explor. Newsl.,
vol. 25, no. 2, pp. 42–61, Jun. 2024.
[8] X. Ren, J. Tang, D. Yin, N. Chawla, and C. Huang, “A survey of large
language models for graphs,” in Proc. ACM Conf. Knowl. Discov. Data
Min. (SIGKDD), Aug. 2024, pp. 6616–6626.
[9] B. Jin, G. Liu, C. Han, M. Jiang, H. Ji, and J. Han, “Large language
models on graphs: A comprehensive survey,” IEEE Trans. Knowl. Data
Eng., vol. 36, no. 12, pp. 8622–8642, Dec. 2024.
[10] Z. Ma, H. Guo, Y.-J. Gong, J. Zhang, and K. C. Tan, “Toward automated
algorithm design: A survey and practical guide to meta-black-box-
optimization,” IEEE Trans. Evol. Comput., pp. 1–1, Jan. 2025.


--- Page 36 ---
36
[11] P. Tao and L. Chen, “Combinatorial optimization: From deep learning
to large language models,” Sci. China Math., vol. 68, no. 7, pp. 1–19,
Apr. 2025.
[12] L. He, G. Sun, D. Niyato, H. Du, F. Mei, J. Kang, M. Debbah, and
Z. Han, “Generative AI for game theory-based mobile networking,”
IEEE Wirel. Commun., vol. 32, no. 1, pp. 122–130, Feb. 2025.
[13] S. Mao, Y. Cai, Y. Xia, W. Wu, X. Wang, F. Wang, T. Ge, and F. Wei,
“Alympics: Language agents meet game theory,” in Proc. Int. Conf.
Comput. Linguist. (COLING), May 2025, pp. 2845–2866.
[14] J. Duan, R. Zhang, J. Diffenderfer, B. Kailkhura, L. Sun, E. Stengel-
Eskin, M. Bansal, T. Chen, and K. Xu, “Gtbench: Uncovering the
strategic reasoning limitations of LLMs via game-theoretic evaluations,”
arXiv preprint arXiv:2402.12348, Feb. 2024.
[15] R. Ramamonjison, T. Yu, R. Li, H. Li, G. Carenini, B. Ghaddar, S. He,
M. Mostajabdaveh, A. Banitalebi-Dehkordi, Z. Zhou et al., “Nl4OPT
competition: Formulating optimization problems based on their natural
language descriptions,” in Proc. NeurIPS Compet. Track, vol. 220, Dec.
2022, pp. 189–203.
[16] X. Huang, Q. Shen, Y. Hu, A. Gao, and B. Wang, “Mamo:
A mathematical modeling benchmark with solvers,” arXiv preprint
arXiv:2405.13144, May 2024.
[17] Z. Tang, C. Huang, X. Zheng, S. Hu, Z. Wang, D. Ge, and B. Wang,
“ORLM: Training large language models for optimization modeling,”
arXiv preprint arXiv:2405.17743, May 2024.
[18] A. AhmadiTeshnizi, W. Gao, H. Brunborg, S. Talaei, and M. Udell,
“OptiMUS-0.3: Using large language models to model and solve opti-
mization problems at scale,” arXiv preprint arXiv:2407.19633, Jul. 2024.
[19] Z. Xiao, D. Zhang, Y. Wu, L. Xu, Y. J. Wang, X. Han, X. Fu,
T. Zhong, J. Zeng, M. Song, and G. Chen, “Chain-of-experts: When
LLMs meet complex operations research problems,” in Proc. Int. Conf.
Learn. Represent. (ICLR), May 2024.
[20] Z. Huang, Y. Yang, Y. Wang, Z. Guo, W. Shi, X. Han, F. Liang,
L. Song, X. Liang, and J. Tang, “OptiBench meets ReSocratic: Mea-
sure and improve LLMs for optimization modeling,” arXiv preprint
arXiv:2407.09887, Jul. 2024.
[21] H. Abgaryan, T. Cazenave, and A. Harutyunyan, “Starjob: Dataset for
LLM-driven job shop scheduling,” arXiv preprint arXiv:2503.01877,
Mar. 2025.
[22] K. Cobbe, V. Kosaraju, M. Bavarian, J. Hilton, R. Nakano, C. Hesse, and
J. Schulman, “Training verifiers to solve math word problems,” arXiv
preprint arXiv:2110.14168, Oct. 2021.
[23] A. Srivastava, A. Rastogi, A. Rao, A. A. Shoeb, A. Abid, A. Fisch,
A. R. Brown, A. Santoro, A. Gupta, A. Garriga-Alonso et al., “Beyond
the imitation game: Quantifying and extrapolating the capabilities of
language models,” Trans. Mach. Learn. Res., Jan. 2023.
[24] T. Wang, W.-Y. Yu, Z. He, Z. Liu, X. Han, H. Gong, H. Wu, W. Shi,
R. She, F. Zhu et al., “BPP-Search: Enhancing tree of thought rea-
soning for mathematical modeling problem solving,” arXiv preprint
arXiv:2411.17404, Nov. 2024.
[25] Z. Jiao, M. Sha, H. Zhang, X. Jiang, and W. Qi, “City-LEO: Toward
transparent city management using LLM with End-to-End optimization,”
arXiv preprint arXiv:2406.10958, Jun. 2024.
[26] H. Yao, F. Wu, J. Ke, X. Tang, Y. Jia, S. Lu, P. Gong, J. Ye, and Z. Li,
“Deep multi-view spatial-temporal network for taxi demand prediction,”
in Proc. AAAI Conf. Artif. Intell., vol. 32, no. 1, Apr. 2018.
[27] J. C. Kantor, “Nd pyomo cookbook,” 2018, accessed: 2025-08-22.
[Online]. Available: https://jckantor.github.io/ND-Pyomo-Cookbook
[28] W. Ling, D. Yogatama, C. Dyer, and P. Blunsom, “Program induction
by rationale generation: Learning to solve and explain algebraic word
problems,” arXiv preprint arXiv:1705.04146, May 2017.
[29] S. Kadıo˘glu, P. Pravin Dakle, K. Uppuluri, R. Politi, P. Raghavan, S. Ral-
labandi, and R. Srinivasamurthy, “Ner4Opt: Named entity recognition
for optimization modelling from natural language,” Constraints, vol. 29,
no. 3, pp. 261–299, Jul. 2024.
[30] C. Liu, E. Noriega-Atala, A. Pyarelal, C. T. Morrison, and M. Cafarella,
“Variable extraction for model recovery in scientific literature,” arXiv
preprint arXiv:2411.14569, Nov. 2024.
[31] R.
Koncel-Kedziorski,
S.
Roy,
A.
Amini,
N.
Kushman,
and
H. Hajishirzi, “MAWPS: A math word problem repository,” in Proc.
Conf. North Am. Chapter Assoc. Comput. Linguistics: Hum. Lang.
Technol. (NAACL-HLT), Jun. 2016, pp. 1152–1157. [Online]. Available:
https://aclanthology.org/N16-1136/
[32] IBM ILOG CPLEX Optimization Studio, “CPLEX User’s Manual
(Version 12.6),” Dec. 2013. [Online]. Available: https://public.dhe.ibm.
com/software/products/Decision Optimization/docs/pdf/usrcplex.pdf
[33] Gurobi Optimization, LLC, “Gurobi Optimizer Reference Manual
(Version 12.0),” May 2025. [Online]. Available: https://docs.gurobi.
com/ /downloads/optimizer/en/12.0/pdf/
[34] v.
O.
Nikolaj
L.
Perron,
and
V.
Furnon,
“or-tools
User’s
Manual,”
Google,
Tech.
Rep.,
Sep.
2014.
[Online].
Available:
https://acrogenesis.com/or-tools/documentation/user manual/
[35] L. de Moura and N. Bjørner, “Z3 User Guide,” Apr. 2024. [Online].
Available: https://microsoft.github.io/z3guide/
[36] Huawei
Cloud
Computing
Technologies
Co.,
Ltd.,
“OptVerse
Solver
Service
User
Guide
(Version
2.0),”
Nov.
2024.
[On-
line]. Available: https://support.huaweicloud.com/usermanual-optverse/
optverse-usermanual.pdf
[37] D.
Ge,
Q.
Huangfu,
Z.
Wang,
J.
Wu,
and
Y.
Ye,
“Cardinal
Optimizer (COPT) User Guide,” Aug. 2023. [Online]. Available:
Available:https://guide.coap.online/copt/en-doc
[38] Zuse Institute Berlin (ZIB), “SCIP User Manual (SCIP Optimization
Suite Version 9.1.0),” Jun. 2024. [Online]. Available: https://scipopt.
org/doc/html/
[39] Y. Liu, H. Du, D. Niyato, J. Kang, Z. Xiong, Y. Wen, and D. I. Kim,
“Generative AI in data center networking: Fundamentals, perspectives,
and case study,” IEEE Network, pp. 1–1, Apr. 2025.
[40] H. Abgaryan, A. Harutyunyan, and T. Cazenave, “LLMs can schedule,”
arXiv preprint arXiv:2408.06993, Aug. 2024.
[41] T. Ahmed and S. Choudhury, “LM4OPT: Unveiling the potential of large
language models in formulating mathematical optimization problems,”
Inf. Syst. Oper. Res., vol. 62, no. 4, pp. 559–572, Nov. 2024.
[42] Y. Zhou, J. Wang, Y. Kuang, X. Li, W. Luo, J. HAO, and F. Wu,
“LLM4Solver: Large language model for efficient algorithm design of
combinatorial optimization solver,” 2024.
[43] Q. Li, L. Zhang, and V. Mak-Hau, “Synthesizing mixed-integer linear
programming models from natural language descriptions,” arXiv preprint
arXiv:2311.15271, Nov. 2023.
[44] H. Yu and J. Liu, “Deep insights into automated optimization with
large language models and evolutionary algorithms,” arXiv preprint
arXiv:2410.20848, Oct. 2024.
[45] T. Wang, W.-Y. Yu, R. She, W. Yang, T. Chen, and J. Zhang, “Leveraging
large language models for solving rare MIP challenges,” arXiv preprint
arXiv:2409.04464, Sep. 2024.
[46] J. Zhang, W. Wang, S. Guo, L. Wang, F. Lin, C. Yang, and W. Yin,
“Solving general natural-language-description optimization problems
with large language models,” in Proc. Conf. North Am. Chapter Assoc.
Comput. Linguistics: Hum. Lang. Technol. (NAACL-HLT), Jun. 2024,
pp. 483–490.
[47] C. Jiang, X. Shu, H. Qian, X. Lu, J. Zhou, A. Zhou, and Y. Yu,
“LLMOPT: Learning to define and solve general optimization problems
from scratch,” arXiv preprint arXiv:2410.13213, Oct. 2024.
[48] Y. Chen, J. Xia, S. Shao, D. Ge, and Y. Ye, “Solver-informed RL:
Grounding large language models for authentic optimization modeling,”
arXiv preprint arXiv:2505.11792, May 2025.
[49] P. T. Amarasinghe, S. Nguyen, Y. Sun, and D. Alahakoon, “AI-copilot
for business optimisation: A framework and a case study in production
scheduling,” arXiv preprint arXiv:2309.13218, Sep. 2023.
[50] Anonymous, “DRoC: Elevating large language models for complex
vehicle routing via decomposed retrieval of constraints,” in Proc. Int.
Conf. Learn. Represent. (ICLR), May 2025.
[51] R. Zhang, H. Du, Y. Liu, D. Niyato, J. Kang, Z. Xiong, A. Jamalipour,
and D. In Kim, “Generative AI agents with large language model for
satellite networks via a mixture of experts transmission,” IEEE J. Sel.
Areas Commun., vol. 42, no. 12, pp. 3581–3596, Jun. 2024.
[52] H. Chen, G. E. Constante-Flores, and C. Li, “Diagnosing infeasible
optimization problems using large language models,” Inf. Syst. Oper.
Res., vol. 0, pp. 1–15, Jul. 2024.
[53] S. Yao, F. Liu, X. Lin, Z. Lu, Z. Wang, and Q. Zhang, “Multi-objective
evolution of heuristic using large language model,” in Proc. AAAI Conf.
Artif. Intell., vol. 39, no. 25, Feb. 2025, pp. 27 144–27 152.
[54] S. Wasserkrug, L. Boussioux, D. d. Hertog, F. Mirzazadeh, I. Birbil,
J. Kurtz, and D. Maragno, “From large language models and opti-
mization to decision optimization copilot: A research manifesto,” arXiv
preprint arXiv:2402.16269, Feb. 2024.
[55] C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le, D. Zhou, and X. Chen,
“Large language models as optimizers,” in Proc. Int. Conf. Learn.
Represent. (ICLR), Sep. 2024.
[56] Y. Hao, Y. Zhang, and C. Fan, “Planning anything with rigor: General-
Purpose zero-shot planning with LLM-based formalized programming,”
arXiv preprint arXiv:2410.12112, Oct. 2024.


--- Page 37 ---
37
[57] X. Huang, Q. Shen, Y. Hu, A. Gao, and B. Wang, “LLMs for
mathematical modeling: Towards bridging the gap between natural and
mathematical languages,” in Proc. Findings Assoc. Comput. Linguistics:
NAACL, Jun. 2025, pp. 2678–2710.
[58] Z. Wang, B. Chen, Y. Huang, Q. Cao, M. He, J. Fan, and X. Liang,
“ORMind: A cognitive-inspired end-to-end reasoning framework for
operations research,” arXiv preprint arXiv:2506.01326, Jun. 2025.
[59] A. Nammouchi, C. Chaabani, A. Theocharis, and A. Kassler, “Towards
explainable renewable energy communities operations using generative
AI,” in Proc. IEEE Innov. Smart Grid Technol. Eur. (ISGT EUROPE),
Oct. 2024, pp. 1–5.
[60] M. Luzzi, F. Guerriero, M. Maratea, G. Greco, and M. Garofalo,
“ChatGPT and operations research: Evaluation on the shortest path
problem,” Soft Comput., vol. 29, pp. 1–12, Jan. 2025.
[61] H. Dui, Q. Zeng, and M. Xie, “Generative AI-based spatiotemporal
resilience, green and low-carbon transformation strategy of smart re-
newable energy systems,” Front. Eng. Manag., pp. 1–16, Jan. 2025.
[62] I. Gemp, R. Patel, Y. Bachrach, M. Lanctot, V. Dasagi, L. Marris,
G. Piliouras, S. Liu, and K. Tuyls, “Steering language models with
game-theoretic solvers,” in Proc. Agentic Markets Workshop at Int. Conf.
Mach. Learn. (ICML), Jul. 2024.
[63] G. Sun, W. Xie, D. Niyato, H. Du, J. Kang, J. Wu, S. Sun, and P. Zhang,
“Generative AI for advanced UAV networking,” pp. 244–253, Nov. 2025.
[64] Z. Xiao, D. Zhang, Y. Wu, L. Xu, Y. J. Wang, X. Han, X. Fu, T. Zhong,
J. Zeng, M. Song et al., “Chain-of-Experts: When LLMs meet complex
operations research problems,” in Proc. Int. Conf. Learn. Represent.
(ICLR), May 2023.
[65] T. Wang, Z. He, W.-Y. Yu, X. Fu, and X. Han, “Large language
models are good multi-lingual learners: When LLMs meet cross-lingual
prompts,” in Proc. Int. Conf. Comput. Linguist. (COLING), Jan. 2025,
pp. 4442–4456.
[66] S. Li, J. Kulkarni, I. Menache, C. Wu, and B. Li, “Towards foun-
dation models for mixed integer linear programming,” arXiv preprint
arXiv:2410.08288, Oct. 2024.
[67] N. Astorga, T. Liu, Y. Xiao, and M. van der Schaar, “Autoformulation
of mathematical optimization models using LLMs,” arXiv preprint
arXiv:2411.01679, Nov. 2024.
[68] B. Li, K. Mellou, B. Zhang, J. Pathuri, and I. Menache, “Large language
models for supply chain optimization,” arXiv preprint arXiv:2307.03875,
Jul. 2023.
[69] M. Mostajabdaveh, T. T. Yu, R. Ramamonjison, G. Carenini, Z. Zhou,
and Y. Zhang, “Optimization modeling and verification from problem
specifications using a multi-agent multi-stage LLM framework,” Inf.
Syst. Oper. Res., vol. 62, no. 4, pp. 599–617, Nov. 2024.
[70] J. Li, R. Wickman, S. Bhatnagar, R. K. Maity, and A. Mukherjee,
“NL2OR: Solve complex operations research problems using natural
language inputs,” arXiv preprint arXiv:2408.07272, Aug. 2024.
[71] J. Sidhu, S. Mishra, A. Gulati, D. Ladsaria, and B. Miranda, “An
evaluation benchmark for autoformalization in lean4,” in Proc. Tiny
Papers Track at ICLR, May 2024.
[72] H. Deng, B. Zheng, Y. Jiang, and T. H. Tran, “CAFA: Coding as
auto-formulation can boost large language models in solving linear
programming problem,” in Workshop on Mathematical Reasoning and
AI at NeurIPS’24, Dec. 2024.
[73] B. Zhang and P. Luo, “OR-LLM-agent: Automating modeling and
solving of operations research optimization problem with reasoning large
language model,” arXiv preprint arXiv:2503.10009, Mar. 2025.
[74] J. Li, R. Wickman, S. Bhatnagar, R. K. Maity, and A. Mukherjee,
“Abstract operations research modeling using natural language inputs,”
Inf., vol. 16, no. 2, p. 128, Feb. 2025.
[75] Y. Zhang, Q. Kang, W. Y. Yu, H. Gong, X. Fu, X. Han, T. Zhong, and
C. Ma, “Decision information meets large language models: The future
of explainable operations research,” arXiv preprint arXiv:2502.09994,
Feb. 2025.
[76] A. AhmadiTeshnizi, W. Gao, and M. Udell, “OptiMUS: Scalable opti-
mization modeling with (mi)lp solvers and large language models,” in
Proc. Int. Conf. Mach. Learn. (ICML).
PMLR, Jul. 2024, pp. 577–596.
[77] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, J. S.
Miller, J. Hilton, R. Nakano, C. Hesse et al., “Training verifiers to solve
math word problems,” arXiv preprint arXiv:2110.14168, Oct. 2021.
[78] Z. Wang, Z. Zhu, Y. Han, Y. Lin, Z. Lin, R. Sun, and T. Ding,
“OptiBench: Benchmarking large language models in optimization
modeling with equivalence-detection evaluation,” in Int. Conf. Learn.
Represent. (ICLR), May 2024.
[79] T. Zhang, S. G. Patil, N. Jain, S. Shen, M. Zaharia, I. Stoica, and J. E.
Gonzalez, “RAFT: Adapting language model to domain specific RAG,”
in Proc. Lang. Model., Feb. 2024.
[80] I. Mirzadeh, K. Alizadeh, H. Shahrokhi, O. Tuzel, S. Bengio, and
M. Farajtabar, “Gsm-symbolic: Understanding the limitations of mathe-
matical reasoning in large language models,” in Proc. Int. Conf. Learn.
Represent. (ICLR), May 2024.
[81] Y. Chai, Y. Fang, Q. Peng, and X. Li, “Tokenization falling short: On
subword robustness in large language models,” in Proc. Findings Assoc.
Comput. Linguistics: EMNLP, Nov. 2024, pp. 1582–1599.
[82] M. Levy, A. Jacoby, and Y. Goldberg, “Same task, more tokens: The
impact of input length on the reasoning performance of large language
models,” in Proc. Annu. Meet. Assoc. Comput. Linguistics (ACL), Jan.
2024, pp. 15 339–15 353.
[83] F. Shi, X. Chen, K. Misra, N. Scales, D. Dohan, E. H. Chi, N. Sch¨arli,
and D. Zhou, “Large language models can be easily distracted by
irrelevant context,” in Proc. Int. Conf. Mach. Learn. (ICML), Jul. 2023,
pp. 31 210–31 227.
[84] P. Belcak, G. Heinrich, S. Diao, Y. Fu, X. Dong, S. Muralidharan, Y. C.
Lin, and P. Molchanov, “Small language models are the future of agentic
AI,” arXiv preprint arXiv:2506.02153, Jun. 2025.
[85] C. Huang, Z. Tang, S. Hu, R. Jiang, X. Zheng, D. Ge, B. Wang, and
Z. Wang, “ORLM: A customizable framework in training large models
for automated optimization modeling,” Oper. Res., May 2025.
[86] Z. Du, C. Qian, W. Liu, Z. Xie, Y. Wang, Y. Dang, W. Chen,
and C. Yang, “Multi-agent software development through cross-team
collaboration,” arXiv preprint arXiv:2406.08979, Jun. 2024.
[87] X. Zhou, Y. Hu, Q. Jia, and R. Xie, “LLM-Enabled multi-modal data
synthesis via cross-domain collaboration,” IEEE Commun. Mag., Jan.
2025.
[88] Y. He, Z. Liu, J. Chen, Z. Tian, H. Liu, X. Chi, R. Liu, R. Yuan, Y. Xing,
W. Wang et al., “LLMs meet multimodal generation and editing: A
survey,” arXiv preprint arXiv:2405.19334, May 2024.
[89] L. Wang, H. Chen, N. Yang, X. Huang, Z. Dou, and F. Wei, “Chain-of-
retrieval augmented generation,” arXiv preprint arXiv:2501.14342, Jan.
2025.
[90] L. Gao, A. Madaan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan, and
G. Neubig, “Pal: Program-aided language models,” in Proc. Int. Conf.
Mach. Learn. (ICML), Jul. 2023.
[91] Z. Gou, Z. Shao, Y. Gong, Y. Shen, Y. Yang, M. Huang, N. Duan, and
W. Chen, “ToRA: A tool-integrated reasoning agent for mathematical
problem solving,” in Proc. Int. Conf. Learn. Represent. (ICLR), May
2024.
[92] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao,
“ReAct: Synergizing reasoning and acting in language models,” in Proc.
Int. Conf. Learn. Represent. (ICLR), May 2023.
[93] B. Zhang and P. Luo, “OR-LLM-Agent: Automating modeling and
solving of operations research optimization problem with reasoning large
language model,” arXiv preprint arXiv:2503.10009, Mar. 2025.
APPENDIX A:
In our dataset, we have ten problems, each contains three
main files: The problem description, the input data, and the
ground truth model. In the following, we provide a detailed
description of each problem:


--- Page 38 ---
38
Problem 1
Problem description:
The network resource allocation problem aims to assign network devices (e.g., routers, switches, or servers) to
communication links or data routes in order to minimize the total transmission cost while satisfying traffic demand
constraints using limited available devices. The problem involves a set of network devices and a set of communication
routes. Given the cost of assigning a particular device to a specific route, the objective is to minimize the total assignment
cost. Each device type is available in limited quantity, and the allocation of devices can not exceed their availability.
Each communication route has a traffic demand, and each device has a capacity representing the maximum traffic it can
handle on that route. The demand constraint ensures that the total allocated capacity on each route meets or exceeds its
required traffic load. The goal is to determine the most cost-efficient assignment of devices to routes while respecting
both resource limitations and service requirements.
Input data:
“Availability”: [2, 3, 1], “Demand”: [100, 150], “Capability”: [ [50, 70], [60, 80], [70, 90] ], “Cost”: [ [100, 200], [150,
250], [200, 300] ]
Output: 700
Ground truth model:
Sets:
• Devices: Set of devices.
• Links: Set of links.
Parameters:
• Availabilityd: Availability of device d, ∀d ∈Devices.
• Demandl: Traffic demand for link l, ∀l ∈Links.
• Capabilityd,l: Capability of device d for link l, ∀d ∈Devices, l ∈Links.
• Costd,l: Cost of assigning device d to route l, ∀d ∈Devices, l ∈Links.
Decision Variables:
• Allocationd,l: Allocation of device d to route l, ∀d ∈Devices, l ∈Links.
Objective: Minimize the total cost of the assignment:
minimize
X
d∈Devices
X
l∈Links
Costd,l · Allocationd,l
Constraints:
1) Device availability constraint:
X
l∈Links
Allocationd,l ≤Availabilityd,
∀d ∈Devices
2) Demand satisfaction constraint:
X
d∈Devices
Allocationd,l · Capabilityd,l = Demandl,
∀l ∈Links


--- Page 39 ---
39
Problem 2
Problem description:
The network node assignment problem aims to assign client devices to network nodes (e.g., access points, servers,
or routers) in a way that maximizes the total number of successful connections. The problem involves a set of client
devices and a set of network nodes, where each client device is capable of connecting to a subset of nodes based on
compatibility, location, or signal strength. The objective is to determine the optimal assignment of clients to nodes that
satisfies certain network constraints, such as capacity limits or connection rules.
Input data:
“Clients”: [“C1”, “C2”, “C3”], “Nodes”: [“N1”, “N2”, “N3”], “PossibleAssignments”: [ [1, 0, 1], [0, 1, 0], [1, 1, 1] ]
Output:
3
Ground truth model:
Sets:
• Clients: Set of all clients.
• Nodes: Set of all network nodes.
Parameter:
• PossibleAssignmentsc,n: Indicates if client c is interested in node n, ∀c ∈Clients, n ∈Nodes.
Decision Variables:
• Assignmentc,n: 1 if client c is assigned to node n, 0 otherwise, ∀c ∈Clients, n ∈Nodes.
Objective: Maximize the total number of assignments:
maximize
X
c∈Clients
X
n∈Nodes
Assignmentc,n
Constraints:
1) Available assignments:
Assignmentc,n ≤PossibleAssignmentsc,n,
∀c ∈Clients, ∀n ∈Nodes
2) Each client is assigned to at most one node:
X
n∈Nodes
Assignmentc,n ≤1,
∀c ∈Clients
3) Each node is assigned to at most one client:
X
c∈Clients
Assignmentc,n ≤1,
∀n ∈Nodes


--- Page 40 ---
40
Problem 3
Problem description:
A telecom company needs to build a set of cell towers to provide signal coverage for the inhabitants of a given city. A
number of potential locations where the towers could be built have been identified. The towers have a fixed range, and
due to budget constraints, only a limited number of them can be built. Given these restrictions, the company wishes to
provide coverage to the largest percentage of the population possible. To simplify the problem, the company has split
the area it wishes to cover into a set of regions, each of which has a known population. The goal is then to choose
which of the potential locations the company should build cell towers on in order to provide coverage to as many
people as possible.
Input data:
“∆”: [[1, 0, 1], [0, 1, 0] ], “Cost”: [3, 4], “Population”: [100, 200, 150], “Budget”: 4
Output:
200
Ground truth model:
Sets:
• Towers: Set of potential sites to build a tower.
• Regions: Set of regions.
Parameters:
• ∆i,j: Binary parameter, equals 1 if site i covers region j, 0 otherwise; ∀i ∈Towers, j ∈Regions.
• Costi: Cost of setting up a tower at site i, ∀i ∈Towers.
• Populationj: Population of region j, ∀j ∈Regions.
• Budget: Total budget allocated to build the towers.
Decision Variables:
• Coveredj ∈{0, 1}: 1 if region j is covered, 0 otherwise; ∀j ∈Regions.
• Buildi ∈{0, 1}: 1 if tower at site i is built, 0 otherwise; ∀i ∈Towers.
Objective: Maximize the total population covered:
maximize
X
j∈Regions
Populationj · Coveredj
Constraints:
1) Region coverage constraint:
X
i∈Tower
∆i,j · Buildi ≥Coveredj,
∀j ∈Regions
2) Budget constraint:
X
i∈Tower
Costi · Buildi ≤Budget


--- Page 41 ---
41
Problem 4
Problem description:
A set of data flows, Flows, needs to be transmitted through a series of network functions or nodes, Nodes (e.g., firewalls,
NATs, intrusion detection systems), in a fixed sequential order, from Node 1 to Node M. Each node is capable of
processing multiple flows in parallel. The transmission workflow is as follows: The first flow in the sequence is
forwarded to the first node for processing, while the remaining flows wait. Once the first node completes processing
the first flow, that flow moves on to the second node, and the second flow begins processing at the first node. This
continues in a pipelined fashion. The time required to process flow f at node n is ProcessTimef,n. The objective is to
determine the optimal scheduling of flows through the nodes that minimizes the total makespan (i.e., the time at which
all flows have been fully processed through the entire sequence of network nodes).
Input data:
“Flows”: [1, 2, 3], “Schedules”: [1, 2, 3], “Nodes”: [1, 2], “ProcessTime”: [ [1, 3], [2, 2], [3, 1] ]
Output:
7
Ground truth model:
Sets:
• Flows: Set of all flows.
• Schedules: Set of all schedule positions.
• Nodes: Set of all processing nodes.
Parameters:
• ProcessTimef,n: Time required to process flow f on node n, ∀f ∈Flows, n ∈Nodes.
Decision Variables:
• Flowschedulef,s ∈{0, 1}: 1 if flow f is assigned to schedule position s, 0 otherwise, ∀f ∈Flows, s ∈Schedules.
• StartTimes,n ≥0: Start time of schedule position s on node n, ∀s ∈Schedules, n ∈Nodes.
Objective: Minimize total processing time:
minimize

StartTimesmax,nmax +
X
f∈Flows
ProcesTimef,nmax · Flowschedulef,smax


Constraints:
1) Only one flow is assigned to each schedule position:
X
f∈Flows
Flowschedulef,s = 1,
∀s ∈Schedules
2) Each flow is assigned exactly one schedule position:
X
s∈Schedules
Flowschedulef,s = 1,
∀f ∈Flows
3) Schedule position s on node n + 1 must start no earlier than the finish time of the same schedule position on
node n:
StartTimes,n+1 ≥StartTimes,n+
X
f∈Flows
ProcesTimef,n·Flowschedulef,s,
∀s ∈Schedules, n ∈Nodes\{nmax}
4) Schedule position s + 1 on node n must start after the previous schedule finishes on the same node:
StartTimes+1,n ≥StartTimes,n +
X
f∈Flows
ProcesTimef,n ·Flowschedulef,s,
∀s ∈Schedules\{smax}, n ∈Nodes


--- Page 42 ---
42
Problem 5
Problem description:
We have a set of network links (point-to-point data transmission paths), each with limited bandwidth capacity. Based on
service design and market analysis, we define a set of end-to-end communication services (e.g., VPNs, video streaming
paths, or application-level sessions) to offer as packages, each associated with a specific price. Each package consists
of a predefined path through one or more network links. For each package, we have an estimated user demand. The
question is: How many units of each service package should be provisioned or sold in order to maximize total revenue?
Bandwidth is reserved on the underlying network links according to the number of service packages we commit to
deliver.
Input data:
“AvailableBandwidth”: [50, 60, 70], “Demand”: [30, 40], “Revenue”: [100, 150], “∆”: [[1, 1, 0], [0, 1, 1]]
Output:
8000
Ground truth model:
Sets:
• NetworkLinks: Set of network links (point-to-point transmission paths).
• Packages: Set of packages.
Parameters:
• AvailableBandwidthr: Bandwidth capacity for link r, ∀r ∈NetworkLinks.
• Demandp: Estimated demand for package p, ∀p ∈Packages.
• Revenuep: Revenue per unit of package p, ∀p ∈Packages.
• ∆p,r: Binary parameter; equals 1 if package p uses resource r, 0 otherwise, ∀p ∈Packages, r ∈NetworkLinks.
Decision Variables:
• Sellp ≥0: Number of units of package p to sell, ∀p ∈Packages.
Objective: Maximize total revenue:
maximize
X
p∈Packages
Revenuep · Sellp
Constraints:
1) Do not sell more than the estimated demand:
Sellp ≤Demandp,
∀p ∈Packages
2) Do not exceed available bandwidth on any network link:
X
p∈Packages
∆p,r · Sellp ≤AvailableBandwidthr,
∀r ∈NetworkLinks


--- Page 43 ---
43
Problem 6
Problem description:
Consider a data routing problem involving multiple types of network traffic. Given a set of nodes, Nodes, and a set of
communication links, Links, connecting them, each node i has a certain amount of outgoing traffic of type t, denoted
by OutgoingTraffici,t, and a certain amount of incoming traffic requirement for type t, denoted by IncomingTraffici,t.
The cost of transmitting one data unit of traffic type t from node i to node j is TransmissionCosti,j,t. Each link (i, j)
has a bandwidth capacity for each traffic type t, represented as BandwidthCapacityi,j,t, and a total combined bandwidth
capacity for all traffic types, denoted as TotalLinkCapacityi,j. The objective is to determine how much traffic of each
type t should be routed from each node i to each node j such that the total cost of routing the data is minimized, and
the total amount of traffic routed from i to j does not exceed TotalLinkCapacityi,j. For each traffic type t, the total
traffic entering a node should meet its incoming traffic requirement, and the total outgoing traffic should not exceed
its outgoing traffic availability. No link can be overloaded for any individual traffic type or in total. This network flow
optimization problem determines the optimal routing strategy for multiple traffic types while respecting link capacity
constraints and minimizing overall transmission cost.
Input data:
“Nodes”: [“A”, “B”], “Links”: [ [A, B] ], “TrafficTypes”: [“Product1”], “OutgoingTraffic”: [ [10], [0] ], “Incoming-
Traffic”: [ [0],[10] ], “TransmissionCost”: [ [ [1] ] ], “BandwidthCapacity”: [ [ [10] ] ], “TotalLinkCapacity”: [ [10] ]
Output:
10
Ground truth model:
Sets:
• Nodes: Set of all nodes (cities).
• Links ⊆Nodes × Nodes: Set of directed links between cities.
• TrafficTypes: Set of traffic types.
Parameters:
• OutgoingTraffici,t: Amount of traffic type t available at node i, ∀i ∈Nodes, t ∈TrafficTypes.
• IncomingTraffici,t: Amount of traffic type t required at node i, ∀i ∈Nodes, t ∈TrafficTypes.
• TransmissionCosti,j,t: Cost of transmitting one unit of traffic type t from node i to node j, ∀(i, j) ∈Links, t ∈
TrafficTypes.
• BandwidthCapacityi,j,t: Maximum number of units of traffic type t that can be transmitted over link (i, j), ∀(i, j) ∈
Links, t ∈TrafficTypes.
• TotalLinkCapacityi,j: Total capacity (across all traffic types) on link (i, j), ∀(i, j) ∈Links.
Decision Variables:
• Routei,j,t ≥0: Number of data units of traffic type t routed from node i to node j, ∀(i, j) ∈Links, t ∈
TrafficTypes.
Objective: Minimize total transmission cost:
minimize
X
(i,j)∈Links
X
t∈TrafficTypes
TransmissionCosti,j,t · Routei,j,t
Constraints:
1) Flow conservation for each node and traffic type:
X
i:(i,k)∈Links
Routei,k,t + OutgoingTraffick,t = IncomingTraffick,t +
X
j:(k,j)∈Links
Routek,j,t, ∀k ∈Nodes, t ∈TrafficTypes
2) Total link capacity constraint:
X
t∈TrafficTypes
Routei,j,t ≤TotalLinkCapacityi,j,
∀(i, j) ∈Links
3) Bandwidth capacity per traffic type:
Routei,j,t ≤BandwidthCapacityi,j,t,
∀(i, j) ∈Links, t ∈TrafficTypes


--- Page 44 ---
44
Problem 7
Problem description:
Consider a wireless resource allocation problem. Given a set of data services, Services (e.g., video streaming, VoIP,
file transfer), and a set of transmission bands, Bands (e.g., frequency channels or time slots). Each service s has a
certain transmission efficiency Efficiencys,b in each band b (representing data throughput per unit resource) and a profit
per unit of data Profits (e.g., revenue per MB delivered). Each band b has a limited amount of available transmission
time or bandwidth Availableb per scheduling window (e.g., per minute or scheduling period). Additionally, there are
lower and upper bounds on the amount of data that can be served per service, represented by MinimumDemands and
MaximumCapacitys, respectively. The goal is to maximize total network profit while ensuring that the total transmission
time used in each band does not exceed its available resources. The decision involves determining how many units
of data to transmit for each service s (e.g., how much bandwidth or time to allocate to each service). How to decide
the data volume to be allocated to each service s to maximize total profit, while respecting per-band capacity and
service-level constraints.
Input data:
“Services”: [“P1”, “P2”], “Bands”: [“S1”, “S2”], “Efficiency”: [ [2, 3], [3, 2] ], “Profit”: [10, 20], “MinimumDemand”:
[1, 2], “MaximumCapacity”: [5, 4], “Available”: [10, 8]
Output:
110
Ground truth model:
Sets:
• Services: A set of data services.
• Bands: A set of wireless transmission bands (e.g., frequency channels or time slots).
Parameters:
• Efficiencys,b: Data units (e.g., MB) per time unit in band b for service s, ∀s ∈Services, b ∈Bands.
• Availableb: Time units available per scheduling period in band b, ∀b ∈Bands.
• Profits: Profit per ton for product s, ∀s ∈Services.
• MinimumDemands: Minimum required data transmission for service s during a scheduling period, ∀s ∈Services.
• MaximumCapacitys: Maximum allowable data transmission for service s during a scheduling period, ∀s ∈
Services.
Decision Variables:
• Allocations: Amount of data (e.g., MB) to be transmitted for service s, ∀s ∈Services.
Objective:
maximize
X
s∈Services
Profits · Allocations
Constraints:
1) In each band b, the total transmission time used by all services may not exceed the available time:
X
s∈Products
 
1
Efficiencys,b
!
· Profits ≤Availableb,
∀b ∈Bands
2) Minimum guaranteed data delivery per service s must be met:
MinimumDemands ≤Allocations,
∀s ∈Services
3) Maximum production may not be larger than the upper limit on tons of products s sold in a week:
Allocations ≤MaximumCapacitys,
∀s ∈Services


--- Page 45 ---
45
Problem 8
Problem description:
In wireless computer networks, we want to decide which devices or applications to schedule for transmission within
a limited resource window, such as energy. Each device or application has an associated utility value (e.g., QoS
satisfaction score) and consumes a specific amount of a limited resource (e.g., transmission energy). The goal is to
select the most valuable subset of devices or applications to serve in a scheduling cycle such that the total utility is
maximized without exceeding the available network resource capacity (e.g., total energy budget or number of slots per
frame). This formulation captures common scheduling and access control problems in wireless energy-constrained IoT
environments and delay-sensitive applications.
Input data:
“DeviceUtility”: [60, 100, 120], “DeviceCost”: [10, 20, 30], “NetworkCapacity”: 50
Output:
220
Ground truth model:
Set:
• Devices: Set of items.
Parameters:
• DeviceUtilityd: Value of item d, ∀d ∈Devices.
• DeviceCostd: The energy consumption of item d, ∀d ∈Devices.
• NetworkCapacity: Maximum capacity of the network.
Decision Variables:
• ScheduleDeviced: Item d is placed in network, ∀d ∈Devices.
Objective:
maximize
X
d∈Devices
ScheduleDeviced · DeviceUtilityd
Constraint:
1) Constraint on total network resource energy usage:
X
d∈Devices
ScheduleDeviced · DeviceCostd ≤NetworkCapacity


--- Page 46 ---
46
Problem 9
Problem description:
This is a multi-commodity secure data routing problem in computer network security. Given a set of source servers or
data centers, Sources, a set of target nodes or client devices, Targets, and a set of data types or services, DataTypes.
Each source i has a certain availability of each data type p, denoted as Availabilityi,p, and each target node j has a
certain requirement for each data type p, denoted as Requirementj,p. The cost of securely transmitting one unit of data
type p from source i to target j (e.g., due to encryption overhead, latency, or risk exposure) is TransmissionCosti,j,p.
The problem aims to minimize the total secure transmission cost of routing all data types from sources to targets across
the network. It is constrained such that the total amount of each data type p transmitted from each source i must equal
its availability. The total amount of each data type p received at each target j must equal its requirement. The total
amount of all data types transmitted from source i to target j must not exceed a network bandwidth or security policy
constraint, denoted as Capacityi,j. How to determine the number of units of each data type p to be securely transmitted
from each source i to each target j?
Input data:
“Availability”: [ [20, 30], [40, 10] ], “Requirement”: [ [30, 30], [30, 10] ], “Capacity”: [ [35, 25], [20, 30] ],
“TransmissionCost”: [ [ [2, 3], [4, 1] ], [ [3, 2], [2, 4] ] ]
Output:
235
Ground truth model:
Sets:
• Sources: A set of source servers or data centers.
• Targets: A set of target nodes or client devices.
• DataTypes: A set of data types or services.
Parameters:
• Availabilityi,p: Amount of each data type p available at source i, ∀i ∈Sources, p ∈DataTypes.
• Requirementj,p: Amount of each data type p required at target j, ∀j ∈Targets, p ∈DataTypes.
• Capacityi,j: Maximum total amount of all data types that can be securely transmitted from source i to target j,
∀i ∈Sources, j ∈Targets.
• TransmissionCosti,j,p: Secure transmission cost per unit of data type p from source i to target j, ∀i ∈Sources, j ∈
Targets, p ∈DataTypes.
Decision Variables:
• Flowi,j,p: Units of each data type p to be securely transmitted from source i to target j, ∀i ∈Sources, j ∈
Targets, p ∈DataTypes.
Objective: Minimize the total cost of securely transmitting all data types:
min
X
i∈Sources
X
j∈Targets
X
p∈DataTypes
TransmissionCosti,j,p · Flowi,j,p
Constraints:
1) The total amount of each data type p transmitted from source i equals its availability:
X
j∈Targets
Flowi,j,p = Availabilityi,p,
∀i ∈Sources, p ∈DataTypes
2) The total amount of each data type p received at target j equals its requirement:
X
i∈Sources
Flowi,j,p = Requirementj,p,
∀j ∈Targets, p ∈DataTypes
3) The total amount of all data types transmitted from source i to target j does not exceed the secure channel
capacity:
X
p∈DataTypes
Flowi,j,p ≤Capacityi,j,
∀i ∈Sources, j ∈Targets


--- Page 47 ---
47
Problem 10
Problem description:
Consider a resource allocation problem in a wireless communication network. Given a set of base stations, BaseStations,
and a set of user devices or communication tasks, Tasks. Each base station i has a certain number of available
transmission resource units (e.g., time slots, frequency blocks), denoted as Capacityi, and each task j requires a certain
number of resource units, denoted as Requirementj. The cost per unit of resource for serving task j from base station
i (e.g., due to signal degradation, energy consumption, or interference) is Costi,j. Each base station i can allocate up
to a maximum limit, Limiti,j, of its resources to task j (e.g., due to quality-of-service or interference constraints). The
problem aims to minimize the total transmission cost of serving all tasks from the base stations. It is constrained that
the total number of resource units allocated from each base station i must equal its capacity, and the total number of
resource units allocated to each task j must equal its requirement. How to decide the number of resource units to be
allocated from each base station i to each task j?
Input data:
“Capacity”: [8, 7], “Requirement”: [5, 10], “Cost”: [[10, 20], [15, 25]], “Limit”: [[5, 6], [4, 7]]
Output:
285
Ground truth model:
Sets:
• BaseStations: A set of base stations.
• Tasks: A set of tasks.
Parameters:
• Capacityi: Resource units available at base station i, ∀i ∈BaseStations.
• Requirementj: Resource units required by task j, ∀j ∈Tasks.
• Costi,j: Cost per resource unit of assigning base station i to task j, ∀i ∈BaseStations, j ∈Tasks.
• Limiti,j: Maximum resource units assignable from base station i to task j, ∀i ∈BaseStations, j ∈Tasks.
Decision Variables:
• Assigni,j: Resource units assigned from base station i to task j, ∀i ∈BaseStations, j ∈Tasks.
Objective: Minimize total assignment cost:
minimize
X
i∈BaseStations
X
j∈Tasks
Costi,j · Assigni,j
Constraints:
1) Total assigned resource units from each base station equals its capacity:
X
j∈Tasks
Assigni,j = Capacityi,
∀i ∈BaseStations
2) Total assigned resource units to each task equals its requirement:
X
i∈BaseStations
Assigni,j = Requirementj,
∀j ∈Tasks
3) Assignment can not exceed the limit for each base station-task pair:
Assigni,j ≤Limiti,j,
∀i ∈BaseStations, j ∈Tasks
