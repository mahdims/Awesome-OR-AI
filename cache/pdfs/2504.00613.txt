--- Page 1 ---
LLM-Guided Search for Deletion-Correcting Codes
Franziska Weindel and Reinhard Heckel
School of Computation, Information and Technology, Technical University of Munich
Munich Center for Machine Learning
April 2, 2025
Abstract
Finding deletion-correcting codes of maximum size has been an open problem for over 70
years, even for a single deletion. In this paper, we propose a novel approach for constructing
deletion-correcting codes. A code is a set of sequences satisfying certain constraints, and we
construct it by greedily adding the highest-priority sequence according to a priority function.
To find good priority functions, we leverage FunSearch, a large language model (LLM)-guided
evolutionary search proposed by Romera et al., 2024. FunSearch iteratively generates, evaluates,
and refines priority functions to construct large deletion-correcting codes. For a single deletion,
our evolutionary search finds functions that construct codes which match known maximum
sizes, reach the size of the largest (conjectured optimal) Varshamov-Tenengolts codes where the
maximum is unknown, and independently rediscover them in equivalent form. For two deletions,
we find functions that construct codes with new best-known sizes for code lengths n = 12, 13,
and 16, establishing improved lower bounds. These results demonstrate the potential of LLM-
guided search for information theory and code design and represent the first application of such
methods for constructing error-correcting codes.
1
Introduction
Error-correcting codes enable reliable communication and data recovery from storage media (such
as HDDs and SSDs), even in the presence of errors and defects. In a typical coding scheme, an
encoder maps information to a codeword, which is corrupted by errors during transmission, and
a decoder attempts to recover the original message.
While substitution and erasure errors are
well understood with optimal encoding and decoding algorithms approaching known theoretical
limits, deletion errors are significantly more challenging. Deletion errors shift subsequent symbols,
disrupting the memoryless property typically assumed in coding theory.
Correcting deletion errors is of theoretical and practical interest. In theoretical computer science,
problems related to deletions include determining whether the edit distance between two strings
can be computed in strongly sub-quadratic time [BI15]. Deletion errors are practically relevant
in cryptography [BK23], multiple sequence alignment in computational biology [CL88], document
exchange [Che+18], traditional storage technologies such as racetrack memories [PHT08; Bla+20]
and bit-patterned magnetic recording [Alb+15], as well as emerging technologies such as DNA data
storage [LG+24].
For a fixed number of correctable errors, better codes have larger code sizes. Despite significant
effort, determining the maximum code size for a fixed number of adversarial deletions has proven
difficult using traditional hand-crafted, human-driven approaches to information theory. A class of
codes known as Varshamov-Tenengolts (VT) codes [VT65] achieves the maximum possible size for
correcting a single deletion as the code length tends to infinity [Lev66]. However, for finite code
lengths, the gap to the best-known upper bound is large even at moderate code lengths [KK13].
1
arXiv:2504.00613v1  [cs.AI]  1 Apr 2025


--- Page 2 ---
Improve f2
over
i t s
previous
v e r s i o n s
f1(v, G) and f0(v, G) .
Step 2: Prompt Construction and LLM Inference
Step 1: Sampling from the Program 
Database
Step 4: Deduplication 
and Storing the New 
Priority Function
 
 
score( f2 ) = s1
Step 3: Evaluating the New 
Priority Function on Graphs
f2(
) =
f2
Island 1
Island 2
Island 3
Island 4
Island 5
Cluster s1
Cluster s2
… 
{ f1,1
m }
{ f 2,1
m }
LLM
Figure 1: FunSearch for finding deletion-correcting codes iteratively refines a priority function
through evolutionary search guided by a pretrained LLM. In each iteration, a few-shot prompt is
constructed by sampling from the program database. The LLM generates a new priority function,
which is evaluated by greedily constructing deletion-correcting codes for different code lengths with
a fixed or variable number of deletions. If executable and not a duplicate, the function is added to
the database.
Although VT codes are conjectured to be largest for all code lengths and a single deletion, their
optimality has only been proven for lengths up to 11 [Slo02; But+02; Nak+23].
In this paper, we propose a novel approach to constructing error-correcting codes using large
language models (LLMs) and evolutionary search. While our framework is general, we focus on
codes that correct a fixed number of adversarial deletions in a sequence of bits, as many fundamental
questions remain open in this setting, even for a single deletion [Slo02]. [Slo02]. We find explicit
algorithms that construct deletion-correcting codes by assigning priorities to sequences.
These
algorithms build the code greedily by iteratively adding the highest-priority sequence while ensuring
that deletion-correcting constraints are satisfied.
LLMs are successful for challenging tasks such as mathematical reasoning and coding [Lew+22;
Cob+21; Che+21; Li+22], but are often limited to their training data and existing knowledge
[Ben+21; Mah+24]. Recently, Romera-Paredes et al. [RP+24] showed that combining LLMs with
evolutionary search and an external evaluator can overcome this limitation for problems that are
difficult to solve but easy to evaluate. Their method, FunSearch (Function Space Search), represents
combinatorial problems as code and searches for algorithmic solutions, improving upon the best-
known results for problems such as the cap set problem and the online bin-packing problem.
We adapt FunSearch [RP+24] to find large deletion-correcting codes. To improve sample effi-
ciency, we introduce a deduplication step that removes priority functions that differ only in syntax.
Previously generated priority functions are used as candidates in few-shot prompts for the LLM to
generate new, improved functions. Removing duplicate functions makes the prompt more effective
at discovering new logic rather than repeating minor syntactic variations.
Our main contributions are:
• We propose an LLM-guided evolutionary search to find deletion-correcting codes based on
FunSearch.
2


--- Page 3 ---
• Our search discovers functions that construct previously unknown maximum-size codes for a
single deletion and small code lengths (n ≤11), and match the size of the conjectured-optimal
VT codes for larger code lengths (up to n = 25), including one that independently rediscovers
them. For two deletions, we find improved lower bounds for code lengths n = 12, 13 and 16.
• We provide an efficient, parallel implementation of the LLM-guided evolutionary search and
release our code alongside the paper to facilitate future research.
Our results demonstrate the potential of LLM-guided search for information and coding theory.
However, our current approach does not scale well to long codes, a limitation we discuss in more
detail later.
2
Related work
We review related work on LLM-guided search and deletion-correcting codes.
2.1
Related work on LLM-guided search
As mentioned, our work builds on FunSearch [RP+24]. Other approaches also integrate LLMs
in evolutionary search. Lehman et al. [Leh+24] first demonstrate a synergy between LLMs and
evolutionary search, using the LLM as an intelligent mutator for automatic data generation (see
also [Xu+23]). Other applications of LLM-guided search are in machine learning [Yan+23; Fer+24;
Ma+23; Haz+24; CDS23; Zhe+23; Nas+24; Lu+25; Lee+25; Sho+24], black-box optimization
[Bra+25; LTT24; Agl+24], and automatic heuristic design.
The most relevant application to deletion-correcting codes is automatic heuristic design for
combinatorial problems. Liu et al. [Liu+24] propose EoH, which improves performance and sample
efficiency over FunSearch by evolving both natural language and algorithmic components. Ye et al.
[Ye+24] introduce ReEvo, which incorporates reflection into the search by prompting the LLM to
analyze and revise previously generated solutions. ReEvo improves sample efficiency over FunSearch
at the cost of increased inference per iteration. Dat et al. [DDB24] propose two diversity metrics
and find that FunSearch and ReEvo stagnate in local optima due to low diversity, while EoH trades
off diversity for performance. To address the tradeoff, they tune function parameters via harmony
search [SHS13], though this approach is impractical for problems with more costly evaluations like
ours.
None of the methods building on FunSearch [Liu+24; Ye+24; DDB24; Che+24; Zhe+25] out-
perform the results discovered by FunSearch on large-scale instances of the cap set problem. This
suggests that scaling LLM-based evolutionary search in a distributed system is important to solve
certain combinatorial problems. We provide a suitable, scalable implementation.
2.2
Related work on deletion-correcting codes
Levenshtein [Lev66] proves that VT codes [VT65] are asymptotically optimal for correcting a single
deletion and proposes a linear-time decoding algorithm. VT codes are also conjectured to be largest
for finite code lengths n, but this has only been proven for n ≤11 (for n ≤8 [Slo02]; for n ≤10 in
[But+02]; for n ≤11 in [Nak+23]).
3


--- Page 4 ---
"""
Finds
large
independent
set in graph G where
vertices
are binary
strings of length
n.
Vertices in G are
connected if they
share a subsequence of length at least n −s.
Improve f1 over its
previous
versions
below.
Keep the code
short and
comment
for easy
understanding .
"""
import
numpy as np
import
networkx as nx
def f0(v, G):
""" Returns
the
priority
with
which we want to add vertex v."""
return 0.0
def f1(v, G):
""" Improved
version of f0"""
Figure 2: Baseline prompt.
Levenshtein [Lev02] derives non-asymptotic upper and lower bounds for single-deletion-correcting
codes. Later work [KK13; FVY15; CK16] refines his upper bound by formulating the problem as a
linear program and considering its dual relaxation. The optimal solution to the relaxation equals
the relaxation of the original problem and provides an upper bound on the maximum code size.
However, exhaustive search by Kulkarni and Kiyavash [KK13] for short code lengths shows a gap
between the best relaxed solution and the largest VT codes.
Regarding known constructions for multiple deletions, Helberg and Ferreira [HF02] extend VT
codes and propose the first explicit construction, but the resulting code sizes remain limited for
longer lengths. Swart and Ferreira [SF03] find larger code sizes for two deletions and code lengths
n ≤12 by using a run-length representation of sequences in a greedy search over 5 × 104 random
permutations. Similarly, Landjev and Haralambiev [LH07] use heuristics and search to construct
deletion-correcting codes for code lengths n ≤30 and deletions s = 2, 3, 4, 5.
Cullina et al. [CKK12] obtain a lower bound on the maximum code size by partitioning sequences
by Hamming weight, dividing the problem into smaller subproblems.
Khajouei et al. [KZK11]
propose concatenating shorter deletion-correcting codes, which they construct using a minimum-
degree heuristic on the same graph formulation we consider. We also find a priority function that
implements this heuristic, but it does not yield the largest code sizes for the lengths we consider.
3
Problem statement
We consider the problem of constructing deletion-correcting codes with a large number of codewords
for finite code lengths n, correcting a fixed number s of adversarial bit deletions.
A deletion-correcting code is a set of sequences such that, even if an adversary deletes s bits
from a codeword, the original codeword can still be uniquely recovered. Unique recovery is not
possible if two codewords share a common subsequence of length n −s. A subsequence is any
sequence of length n −s obtained by deleting s bits from a codeword while preserving the order
of the remaining bits. Thus, an n-bit, s-deletion-correcting code is a set C ⊆{0, 1}n such that the
sets of length-(n −s) subsequences obtained from any two distinct codewords c, c′ ∈C are disjoint.
4


--- Page 5 ---
The problem of constructing large n-bit, s-deletion-correcting codes can be reduced to finding
an independent set I in a graph G defined as follows. Let G be an undirected graph where each
vertex is one of the 2n binary sequences of length n, and we have an edge between two vertices
if and only if the binary sequences they represent share a common subsequence of length at least
n −s. An independent set in the graph G is a subset of vertices I such that no two vertices are
connected by an edge. An n-bit, s-deletion-correcting code is an independent set in the graph G.
To construct deletion-correcting codes, we greedily build independent sets I in the graph G by
iteratively adding vertices v with the highest priority to an initially empty set and removing their
neighbors. Let f(v, G) be a priority function that assigns a real-valued priority to each vertex v
in the graph G. At each step, we select the vertex with the highest priority f(v, G), add it to
the independent set I, and remove the vertex and its neighbors from G. If two or more vertices
have the same priority, we break the tie by selecting the lexicographically smallest vertex (with 0
considered smaller than 1). The size of the resulting independent set I depends on the choice of
the priority function f, which determines which vertices are added.
In this formulation, constructing large n-bit, s-deletion-correcting codes reduces to designing a
priority function f that maximizes the independent set size I in the graph G.
4
Method
We adapt FunSearch, originally proposed by Romera-Paredes et al. [RP+24], and augment it with
a deduplication step to optimize the priority function f to construct large deletion-correcting codes.
FunSearch consists of five steps, explained below.
Step 1: Sampling from the program database. The program database is divided into
islands that evolve independently to promote diversity. Each island groups priority functions into
clusters based on the independent set sizes they achieve on evaluation inputs.
Each cluster is
assigned a score, which is explained in Step 3.
We sample a priority function from the program database as follows. First, we randomly sample
an island j. Then, from island j, we sample a cluster i with probability pi, given by a softmax
distribution over the scores of all clusters on island j
pi =
escorei /Tj
P
i′ escorei′ /Tj ,
where Tj = T

1 −nj mod P
P

.
Here, scorei is the score of cluster i, and Tj is the temperature for island j.
The temperature Tj depends on an initial temperature T, the number of priority functions
nj stored on island j, and a sampling period P. As the number of stored priority functions nj
increases, the temperature for island j decreases to shift the focus from exploration (sampling closer
to uniform) to exploitation (favoring clusters with higher evaluation scores). The temperature resets
after every P stored priority functions to reintroduce exploration and avoid suboptimal convergence.
We sample a priority function f from cluster i on island j, favoring shorter functions based
on their lengths relative to the minimum and maximum function lengths in that cluster.
The
preference is based on the assumption, under Kolmogorov complexity [LV19; Kol65], that shorter
functions often have lower computational complexity and are more efficient to evaluate, though this
is not always the case in practice.
Step 2: Prompt construction and LLM inference. We construct a few-shot prompt by
repeating the sampling process from Step 1 twice to obtain two priority functions. Sampling is done
5


--- Page 6 ---
without replacement, and the same cluster cannot be sampled twice for diverse few-shot examples.
The initial prompt is shown in Figure 2.
The sampled priority functions are sorted by their cluster score, with the lower-scoring function
first and the higher-scoring function as an example for improvement. The prompt is framed as a
code completion task and ends with the header of a new priority function for the LLM to improve
the higher-scoring example.
The prompt is passed through a pretrained LLM to generate a new priority function. We use
StarCoder2-15B [Loz+24], an open-access model with 15 billion parameters trained on The Stack
v2 dataset (775B tokens from 600+ programming languages) and additional tokens from sources
like pull requests, issues, Jupyter notebooks, and StackOverflow, totaling 913B tokens.
Step 3: Evaluating the new priority function on graphs. We evaluate the new priority
function as follows. For each evaluation input consisting of a code length n and a deletion correction
parameter s, we construct an independent set I in the graph G using the new priority function, as
described in Section 3. If the function is not executable (e.g., due to syntax errors), it is discarded.
The evaluator assigns a score to the priority function using the scoring function score(f). We use
the independent set size obtained for the longest code length n in the evaluation input as the score,
as we found this to outperform aggregate metrics such as averaging independent set sizes across
all evaluation inputs (see Appendix E). A priority function is said to be optimal if it constructs
maximum independent sets for all evaluation inputs n ∈[6, 11] and a single deletion s = 1, where
the maximum is known.
Step 4: Deduplication and storing the new priority function. The evaluated priority
function is stored on the same island j from which the few-shot examples in Step 1 are sampled.
Each island serves as an independent program database to promote diversity. The independent set
sizes achieved by the priority function over the evaluation inputs are compared to existing clusters
on island j. If no cluster exists with priority functions that achieve the same independent set sizes,
the function forms a new cluster and is assigned score(f).
If a matching cluster exists, we apply our deduplication step to improve exploration and en-
courage the LLM to generate priority functions with distinct logic rather than minor syntactic
variations. Two functions are considered duplicates if they produce the same hash value, computed
from the priority scores they assign to each sequence. If the function is not a duplicate, it is assigned
to the matching cluster, where all functions share the same score(f), denoted as scorei in Step 1.
If it is a duplicate, it is discarded.
Our deduplication step allows finding good priority functions with fewer functions processed
(generated, evaluated, and stored) by avoiding prompts that include functionally identical examples
differing only in syntax (see Appendix D).
Each island in the program database is initialized with the same trivial priority function shown
in Figure 2, which assigns equal priority to all sequences.
To allow information exchange between islands, we periodically reset them. During a reset, the
stored priority functions in the worst-performing half of the islands are discarded. Each island
is then re-initialized with the priority function that initialized the highest-scoring cluster from a
randomly sampled surviving island.
Romera-Paredes et al. [RP+24] reset islands after a fixed
time interval. In our implementation, we reset islands after a fixed number R of stored priority
functions to decouple the reset logic from the rate at which functions are processed (which depends
on available resources).
6


--- Page 7 ---
def f(v, G, n, s):
position = [(j + 1) · (n −j)/(6 · s) for j, value in enumerate v if int(value) == 1]
total_position = np.sum(position)
degree = G.degree(v)/ float(n)
return 4 · total position + 5 · degree
Figure 3: Graph-based priority function that constructs codes with zero sequence overlap with the
largest VT0(n) codes for lengths n = 7, 9, 11, 13 while achieving the same code size.
def f(v, G, n, s):
def
_find_matches(vertex , n, s):
counter = 0
counter = sum ([int(c) · (2i −1) for i, c in enumerate(reversed(list(vertex)))])
return (bin(counter)).count("1")
def
_count_ones(vertex):
counter =0
counter=sum([int(_)for _ in list(vertex)])
return
counter
weights =[( _find_matches(vertex_ ,n, s)/(s+0.5)*np.exp(-( _count_ones(vertex_))),
vertex_) for
vertex_ in G[v]]
return
sorted(weights)[-1]
Figure 4: Number-theoretic priority function that constructs the same codes as the largest VT0(n)
codes for lengths n ∈[6, 11], but follows a different logic.
5
Experiments
We run 20 evolutionary search experiments, varying the initial temperature T, sampling period P,
and the number of functions R stored before an island reset. Each experiment runs with or without
dynamically decreasing the LLM sampling temperature to balance exploration and exploitation.
Our main finding is that FunSearch discovers priority functions that construct maximum-size
single-deletion-correcting codes for lengths 6 ≤n ≤11, including previously unknown constructions.
For longer code lengths (n > 11), where VT codes are conjectured to be optimal, FunSearch
rediscovers them within our greedy framework and also finds alternative constructions of the same
size (up to lengths n = 25). For two deletions, we discover larger codes than previously known for
code lengths n = 12, 13 and 16.
5.1
Experimental setup
Each evolutionary search processes (generates, evaluates, and stores) 400K priority functions, which
takes about 3.5K GPU hours. If an optimal function is found before reaching 400K, the run is
stopped early. We then process an additional 20K functions to allow the search to discover other
optimal solutions that may generalize better to longer code lengths.
We use the LLM hyperparameters listed in Table 9c in Appendix B, which we find to perform
best in smaller-scale experiments.
We score the generated priority functions on code sizes achieved for a single deletion (s = 1) and
lengths n ∈[6, 11], where the maximum is known. The evaluation range balances computational
feasibility and problem difficulty. Smaller code lengths n make the problem trivial, while larger n
result in prohibitive computational and memory costs.
7


--- Page 8 ---
6
7
8
9
10
11
12
13
14
15
16
Code length n
Count
0
85
170
100%
90−99%
80−89%
70−79%
60−69%
50−59%
40−49%
30−39%
20−29%
10−19%
1−9%
0%
Sequence overlap (%):
Figure 5: Sequence overlap between discovered optimal priority functions and the largest VT0(n)
codes for n ∈[6, 16]. Color denotes overlap bin; bar height the number of functions.
In all experiments, we use the independent set size for code length n = 11 as the scoring function
for the generated priority functions, as it finds optimal ones with fewer processed than aggregate
scoring functions (see Appendix E).
Performance is measured as a binary outcome: success or failure. A configuration is successful
if it discovers an optimal priority function, that is, one that constructs a maximum independent
set for all evaluation inputs.
Table 3 in Appendix C summarizes the configurations of successful runs. Appendix C details
the code lengths where failed runs do not construct a maximum independent set, and shows their
search trajectories, that plot the highest score assigned to priority functions across all clusters and
islands as new functions are processed.
5.2
Underlying logic of optimal priority functions
We first identify common logical structures in the discovered optimal priority functions, and then
discuss their relation to the best known VT codes. We categorize the discovered priority functions
into graph-based and number-theoretic functions.
Graph-based priority functions assign priority based on local graph connectivity and sequence
characteristics, considering both the degree of a vertex and the bit patterns of its neighbors. An
example is in Figure 3.
Number-theoretic priority functions assign priority based on the integer representations of neigh-
boring sequences and their bit patterns. An example is in Figure 4.
The best-known single-deletion-correcting codes are the VT codes [VT65]. For a given parameter
a ∈Z, the VT code of length n, denoted VTa(n), is defined as the set of binary sequences v =
(v1, v2, . . . , vn) ∈{0, 1}n satisfying
n
X
i=1
i · vi ≡a
mod (n + 1).
(1)
The VT0(n) code has maximum code size as n →∞and is conjectured to have maximum
code size for all code lengths n. In our framework, VT0(n) codes can be represented by a priority
function that assigns a high priority (e.g., +∞) to sequences satisfying Equation (1) with a = 0,
and a low priority (e.g., 0) to those that do not.
8


--- Page 9 ---
Table 1: Code sizes for single-deletion correction across code lengths n ∈[6, 16]. Each row shows
the code size achieved by a priority function discovered under a specific run configuration: trivial
initialization (fT ), first optimal function after 120K processed (f120K), best function selected from
standard runs with varying hyperparameters (f), from runs using weighted scoring (fW ), and from
prompt 3 or 4 using StarCoder2 (f3,4) or GPT-4o mini (f3,4/GPT). Bold values mark known optimal
sizes or the VT code size, conjectured to be optimal.
Priority function
n = 6
n = 7
n = 8
n = 9
n = 10
n = 11
n = 12
n = 13
n = 14
n = 15
n = 16
f T
8
14
25
42
71
125
224
406
737
1345
2468
f ∗
10
16
30
52
94
172
316
586
1054
2000
3389
f 120K
10
16
30
52
94
172
316
449
794
1386
2515
f W ∗
10
16
30
52
94
172
316
564
1096
1364
2493
f 3,4&3/GPT
10
16
30
52
94
172
316
586
1096
2048
3856
f 4/GPT
10
16
30
52
94
172
316
586
1083
2025
3696
∗Reported code sizes are not constructed by a single priority function. For each code length n, we report the maximum size achieved across all
optimal functions discovered with the run configuration.
Figure 5 shows the sequence overlap between the codes constructed by our discovered priority
functions and the largest VT0(n) codes for tested lengths n ∈[6, 16].
Many of our discovered
priority functions recover the largest VT0(n) codes with 100% sequence overlap and follow similar
logic, as both graph-based and number-theoretic functions assign weights to bits based on their
position in the sequence. However, priority functions that use graph structure alongside sequence
information discover previously unknown codes. For example, the graph-based priority function in
Figure 3 constructs codes that share no sequences with the largest VT0(n) codes for n = 7, 9, 11,
and 13, while achieving the same size. Interestingly, we only find new codes matching VT code
sizes for odd code lengths.
5.3
Generalization to longer code lengths and multiple deletions
A key strength of our approach is that we search for priority functions that construct deletion-
correcting codes, rather than searching for the codes directly. This allows us to construct longer
and multiple deletion-correcting codes with the priority functions found for short code lengths and
a single deletion.
Table 1 shows that priority functions optimized for code lengths n ∈[6, 11] also achieve the
conjectured largest VT0(n) code sizes for n = 12, 13 and remain close for n ∈[14, 16]. For two
deletions, the priority functions construct codes whose sizes are close to the best known over the
tested lengths n ∈[7, 16], and improve on them for n = 13, where our search discovers a two-
deletion-correcting code of size 50, larger than the previous best known size of 49, setting a new
lower bound. The corresponding priority function is shown in Figure 11, and detailed results are
given in Table 4, both in Appendix I.
Compared to previous search-based methods that search the full space of 2n binary sequences
[SF03; LH07], our search finds functions that construct larger two-deletion-correcting codes for
lengths n ∈[12, 16]. Searching the sequence space becomes exponentially harder with the code
length, making it increasingly difficult to discover large codes. In contrast, our approach searches
in the space of priority functions, which is independent of the code length.
These results show that priority functions optimized for single-deletion correction can, to some
9


--- Page 10 ---
def f(v, G, n, s):
# The
condition
ord(a) > 125 has no effect , as the ASCII
values of
’0’ and
’1’
are always
below
125.
v = ’’.join ([’-’ * (ord(a) > 125) + a for a in list(v)])
onepositions = [c for c, d in reversed(list(enumerate(v, start=-len(v)))) if d
== ’1’]
negonesum = sum([-c for c in onepositions ])
# Maximum of negonesum is (n-1)/2 for n odd and n/2 for n even , which is
always < n, so taking mod n does not change the
priority
finalans = (⌊negonesum/((n + s) · 1)⌋% n)
return
finalans
Figure 6: Priority function as generated by StarCoder2 using prompt 4, with comments added for
clarity. For s = 1, this function is equivalent to the largest VT0 code when sequences are iteratively
added to an initially empty code based on highest priority and lexicographic order.
extent, generalize beyond their evaluation range. However, we did not find any priority function
that constructs optimal single-deletion-correcting codes (where known) and matches or exceeds the
best-known sizes for two deletions over all tested lengths.
5.4
Prompt engineering and general-purpose LLMs
The way LLMs are prompted can influence response quality. To assess whether prompt engineering
improves generalization to longer code lengths or sample efficiency (i.e., the number of functions
processed before finding an optimal one), we modify the baseline prompt in Figure 2.
We also evaluate whether a general-purpose instruction-tuned model (we consider GPT-4o mini)
can achieve similar improvements. Since GPT-4o mini has been trained on a broad range of tasks
beyond code generation, it may better interpret the task compared to a model trained exclusively
on code.
We find that prompt engineering improves generalization for both StarCoder2 and GPT-4o mini
and improves sample efficiency for GPT-4o mini. Explicitly instructing StarCoder2 to consider
binary string properties leads to rediscovering the largest VT0(n) codes for all code lengths n in
an alternative form.
5.4.1
Prompt engineering
We test five prompts. Prompt 1 explicitly states that we are considering the single deletion case
(s = 1) and that the priority function determines the importance of each vertex for inclusion in the
independent set. Prompt 2 includes the evaluation script to provide context on how the priority
function determines independent set size through greedy selection. Prompt 3 removes the graph G
as an input to the priority function and excludes the networkx package to bias the LLM toward
computing priority based on sequence structure only. Prompt 4 explicitly instructs the LLM to
consider sequence structure. Prompt 5 combines modifications from prompts 1 and 4. The prompts
are shown in Appendix G.1.
Table 1 shows that the priority functions discovered using StarCoder2 with prompts 3 and 4
generalize better to longer code lengths. Figures 19 and 21 in Appendix G.1 show examples of
priority functions found with prompts 3 and 4, respectively, that achieve V T0(n) code sizes for all
10


--- Page 11 ---
0
1
2
3
4
Total Functions Processed
×105
140
160
180
200
Overall Best Score
Baseline
Prompt 1
Prompt 2
Prompt 3
Prompt 4
Prompt 5
Optimal
(a) Search trajectory with GPT-4o mini.
0
1
2
3
4
Total Functions Processed
×105
140
160
180
200
Overall Best Score
Baseline
Prompt 1
Prompt 2
Prompt 3
Prompt 4
Prompt 5
Optimal
(b) Search trajectory with StarCoder2.
Figure 7: GPT-4o mini finds optimal priority functions with fewer processed and generates more
executable functions than StarCoder2, but requires prompt engineering.
tested code lengths n ∈[6, 25], but follow a different logic. The function in Figure 21 constructs
new codes for odd lengths that have zero sequence overlap with the largest VT0(n) codes in this
range. Figure 6 shows the priority function found with prompt 4, which is equivalent to the largest
VT0(n) codes for all code lengths, as explained in Appendix H.
The other prompts fail to find optimal priority functions within 400K processed. With prompt
engineering (prompt 3), the first optimal priority function is discovered after approximately 300K
functions, compared to 120K in the best run without prompt engineering. This indicates that for
StarCoder2, the prompts considered here do not improve sample efficiency.
5.4.2
GPT-4o mini for generating priority functions
Figure 7 shows that GPT-4o mini finds an optimal priority function with fewer candidates than
StarCoder2 (69K vs.
120K) and generates a larger fraction of executable functions (43.7% vs.
16.2%).
However, without prompt engineering, GPT-4o mini fails to find an optimal function
within 400K processed. Optimal solutions are only found with prompts 3 and 4.
Figures 23 and 24 in Appendix G.2 show examples of priority functions discovered with GPT-4o
mini using prompt 3 and prompt 4, respectively. Functions generated with prompt 3 achieve 100%
sequence overlap with the largest VT0(n) codes for lengths n ∈[6, 25], while functions generated
with prompt 4 achieve VT0(n) code sizes for n ∈[6, 13] and are close to VT0(n) code sizes for
larger lengths n ∈[14, 16].
5.5
Search for multiple deletion-correcting codes
We now conduct evolutionary searches to find two-deletion-correcting codes. In our prior searches,
we focused on single-deletion-correcting codes.
We consider two additional evaluation sets for the search. The first scores functions based on
two-deletion-correcting code sizes for code lengths n ∈[7, 12]. The second jointly scores functions
based on single- and two-deletion-correcting code sizes, using n ∈[9, 11] for s = 1 and n ∈[10, 12]
11


--- Page 12 ---
for s = 2. For each set, we run searches using the default configuration from Section 5.1, as well as
with weighted scoring and prompt 4, resulting in a total of six additional runs.
Searches targeting two-deletion-correcting codes discover a new lower bound at n = 12; the
previously best-known code size was 32, while we find functions (e.g., the one shown in Figure 28)
that construct codes of size 34. Joint searches for single- and two-deletion-correcting codes estab-
lish a new lower bound at n = 16, where the best-known size was 201 and our method finds a
function that constructs a code of size 204. These joint searches also find functions that construct
known-optimal or VT0(n)-sized codes for a single deletion with n ∈[6, 13], and closely match the
best-known sizes for two and three deletions over tested lengths n ∈[7, 16] (e.g., the function in
Figure 33). More details are in Appendix I; Table 4 summarizes the achieved code sizes for cor-
recting one, two, and three deletions, and Figure 26 shows their difference from the best-known
sizes.
6
Limitations
In this work, we found new error-correcting codes and re-discovered existing ones using LLMs and
evolutionary search. These results demonstrate the potential of LLM-guided search for information
theory and error-correcting code design.
Unlike previous approaches that mostly rely on hand-crafted heuristics specific to the error
type, our method applies to any error type or combination thereof, as long as the distinguishability
constraint is well-defined (e.g., for deletions, ensuring no common subsequences).
A key limitation of our approach is the poor scalability of the evaluator, which makes evolu-
tionary search infeasible for moderate to large code lengths. The evaluator computes the priority
of each sequence, and the number of sequences grows exponentially with the code length. If the
function additionally relies on the graph to compute priority, the evaluator must also construct or
load the graph, which quickly becomes memory-prohibitive as it stores all sequences along with
their pairwise edges.
Nonetheless, searching in the function space at a strategic level generalizes better than previous
approaches [SF03; LH07] that search directly in the space of all binary sequences. Priority functions
found for shorter codes can be used to construct codes of larger lengths and, as we have seen,
generalize to some extent.
Moreover, the discovered priority functions can be mathematically
analyzed, potentially allowing code sizes to be determined without explicitly constructing the codes,
as demonstrated by the priority function that rediscovered VT codes.
12


--- Page 13 ---
Acknowledgements
This work was funded by the European Union (DiDAX, 101115134). Views and opinions expressed
are, however, those of the authors only and do not necessarily reflect those of the European Union
or the European Research Council Executive Agency. Neither the European Union nor the granting
authority can be held responsible for them.
The authors thank Maria Abu Sini for proofreading and helpful comments, as well as Roni Con
and Eitan Yaakobi for insightful discussions on deletion-correcting codes.
Code availability
The code used in this work will be made publicly available at https://github.com/MLI-lab/FunDCC.
13


--- Page 14 ---
References
[Agl+24]
V. Aglietti, I. Ktena, J. Schrouff, E. Sgouritsa, F. J. R. Ruiz, A. Malek, A. Bellot,
and S. Chiappa. FunBO: Discovering Acquisition Functions for Bayesian Optimization
with FunSearch. Preprint: arXiv:2406.04824, 2024.
[Alb+15]
T. R. Albrecht et al. “Bit-Patterned Magnetic Recording: Theory, Media Fabrication,
and Recording Performance”. IEEE Transactions on Magnetics, pp. 1–42, 2015.
[BI15]
A. Backurs and P. Indyk. “Edit Distance Cannot Be Computed in Strongly Sub-
quadratic Time (unless SETH is false)”. In: Proceedings of the forty-seventh annual
ACM symposium on Theory of Computing, pp. 51–58, 2015.
[BK23]
J. Bartusek and D. Khurana. “Cryptography with Certified Deletion”. In: Advances in
Cryptology - CRYPTO 2023, pp. 192–223, 2023.
[Ben+21]
E. M. Bender, T. Gebru, A. McMillan-Major, and S. Shmitchell. “On the Dangers of
Stochastic Parrots: Can Language Models Be Too Big?” In: Proceedings of the 2021
ACM Conference on Fairness, Accountability, and Transparency, pp. 610–623, 2021.
[Bla+20]
R. Blasing, A. A. Khan, P. C. Filippou, C. Garg, F. Hameed, J. Castrillon, and
S. S. P. Parkin. “Magnetic Racetrack Memory: From Physics to the Cusp of Appli-
cations Within a Decade”. Proceedings of the IEEE, pp. 1303–1321, 2020.
[Bra+25]
S. Brahmachary, S. M. Joshi, A. Panda, K. Koneripalli, A. K. Sagotra, H. Patel, A.
Sharma, A. D. Jagtap, and K. Kalyanaraman. “Large language model-based evolution-
ary optimizer: Reasoning with elitism”. Neurocomputing, p. 129272, 2025.
[But+02]
S. Butenko, P. Pardalos, I. Sergienko, V. Shylo, and P. Stetsyuk. “Finding maximum
independent sets in graphs arising from coding theory”. In: Proceedings of the 2002
ACM symposium on Applied computing, pp. 542–546, 2002.
[CL88]
H. Carrillo and D. Lipman. “The Multiple Sequence Alignment Problem in Biology”.
SIAM Journal on Applied Mathematics, pp. 1073–1082, 1988.
[CDS23]
A. Chen, D. Dohan, and D. So. “EvoPrompting: Language Models for Code-Level
Neural Architecture Search”. In: Advances in Neural Information Processing Systems.
Vol. 36, pp. 7787–7817, 2023.
[Che+21]
M. Chen et al. Evaluating Large Language Models Trained on Code. Preprint: arXiv:
2107.03374, 2021.
[Che+24]
Z. Chen, Z. Zhou, Y. Lu, R. Xu, L. Pan, and Z. Lan. UBER: Uncertainty-Based Evo-
lution with Large Language Models for Automatic Heuristic Design. Preprint: arXiv:
2412.20694, 2024.
[Che+18]
K. Cheng, Z. Jin, X. Li, and K. Wu. “Deterministic Document Exchange Protocols,
and Almost Optimal Binary Codes for Edit Errors”. In: IEEE 59th Annual Symposium
on Foundations of Computer Science (FOCS), pp. 200–211, 2018.
[Cob+21]
K. Cobbe et al. Training Verifiers to Solve Math Word Problems. Preprint: arXiv:
2110.14168, 2021.
14


--- Page 15 ---
[CK16]
D. Cullina and N. Kiyavash. “Generalized Sphere-Packing Bounds on the Size of Codes
for Combinatorial Channels”. IEEE Transactions on Information Theory, pp. 4454–
4465, 2016.
[CKK12]
D. Cullina, A. A. Kulkarni, and N. Kiyavash. “A coloring approach to constructing
deletion correcting codes from constant weight subgraphs”. In: IEEE International
Symposium on Information Theory Proceedings, pp. 513–517, 2012.
[DDB24]
P. V. T. Dat, L. Doan, and H. T. T. Binh. HSEvo: Elevating Automatic Heuristic
Design with Diversity-Driven Harmony Search and Genetic Algorithm Using LLMs.
Preprint: arXiv:2412.14995, 2024.
[FVY15]
A. Fazeli, A. Vardy, and E. Yaakobi. “Generalized Sphere Packing Bound”. IEEE
Transactions on Information Theory, pp. 2313–2334, 2015.
[Fer+24]
C. Fernando, D. S. Banarse, H. Michalewski, S. Osindero, and T. Rocktaschel. “Prompt-
breeder: Self-Referential Self-Improvement via Prompt Evolution”. In: Proceedings of
the 41st International Conference on Machine Learning, pp. 13481–13544, 2024.
[Haz+24]
R. Hazra, A. Sygkounas, A. Persson, A. Loutfi, and P. Z. D. Martires. REvolve: Re-
ward Evolution with Large Language Models using Human Feedback. Preprint: arXiv:
2406.01309, 2024.
[HF02]
A. Helberg and H. Ferreira. “On multiple insertion/deletion correcting codes”. IEEE
Transactions on Information Theory, pp. 305–308, 2002.
[KZK11]
F. Khajouei, M. Zolghadr, and N. Kiyavash. “An algorithmic approach for finding
deletion correcting codes”. In: 2011 IEEE Information Theory Workshop, pp. 25–29,
2011.
[Kol65]
A. N. Kolmogorov. “Three approaches to the definition of the concept quantity of
information”. Problemy peredachi informatsii, pp. 3–11, 1965.
[KK13]
A. A. Kulkarni and N. Kiyavash. “Nonasymptotic Upper Bounds for Deletion Correct-
ing Codes”. IEEE Transactions on Information Theory, pp. 5115–5130, 2013.
[LG+24]
A. L. Gimpel, W. J. Stark, R. Heckel, and R. N. Grass. “Challenges for error-correction
coding in DNA data storage: photolithographic synthesis and DNA decay”. Digital
Discovery, pp. 2497–2508, 2024.
[LH07]
I. Landjev and K. Haralambiev. “On Multiple Deletion Codes”. Serdica Journal of
Computing, pp. 13–26, 2007.
[LTT24]
R. Lange, Y. Tian, and Y. Tang. “Large Language Models As Evolution Strategies”.
In: Proceedings of the Genetic and Evolutionary Computation Conference Companion,
pp. 579–582, 2024.
[Lee+25]
K.-H. Lee, I. Fischer, Y.-H. Wu, D. Marwood, S. Baluja, D. Schuurmans, and X. Chen.
Evolving Deeper LLM Thinking. Preprint: arXiv:2501.09891, 2025.
[Leh+24]
J. Lehman, J. Gordon, S. Jain, K. Ndousse, C. Yeh, and K. O. Stanley. “Evolution
Through Large Models”. In: Handbook of Evolutionary Machine Learning. Springer
Nature, pp. 331–366, 2024.
[Lev66]
V. I. Levenshtein. “Binary Codes Capable of Correcting Deletions, Insertions and Re-
versals”. Soviet Physics Doklady, p. 707, 1966.
15


--- Page 16 ---
[Lev02]
V. Levenshtein. “Bounds for deletion/insertion correcting codes”. In: Proceedings IEEE
International Symposium on Information Theory, p. 370, 2002.
[Lew+22]
A. Lewkowycz et al. “Solving Quantitative Reasoning Problems with Language Mod-
els”. In: Advances in Neural Information Processing Systems. Vol. 35, pp. 3843–3857,
2022.
[LV19]
M. Li and P. Vitanyi. An Introduction to Kolmogorov Complexity and Its Applications.
Springer, 2019.
[Li+22]
Y. Li et al. “Competition-level code generation with AlphaCode”. Science, pp. 1092–
1097, 2022.
[Liu+24]
F. Liu, T. Xialiang, M. Yuan, X. Lin, F. Luo, Z. Wang, Z. Lu, and Q. Zhang. “Evolution
of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language
Model”. In: Proceedings of the 41st International Conference on Machine Learning,
pp. 32201–32223, 2024.
[LP09]
L. Lovasz and M. D. Plummer. Matching Theory. Vol. 367. American Mathematical
Soc., 2009.
[Loz+24]
A. Lozhkov et al. StarCoder 2 and The Stack v2: The Next Generation. Preprint:
arXiv:2402.19173, 2024.
[Lu+25]
C. Lu, S. Holt, C. Fanconi, A. Chan, J. Foerster, M. van der Schaar, and R. Lange.
“Discovering Preference Optimization Algorithms with and for Large Language Mod-
els”. In: Advances in Neural Information Processing Systems. Vol. 37, pp. 86528–86573,
2025.
[Ma+23]
Y. J. Ma, W. Liang, G. Wang, D.-A. Huang, O. Bastani, D. Jayaraman, Y. Zhu, L. Fan,
and A. Anandkumar. “Eureka: Human-Level Reward Design via Coding Large Lan-
guage Models”. In: The Twelfth International Conference on Learning Representations,
2023.
[Mah+24]
K. Mahowald, A. A. Ivanova, I. A. Blank, N. Kanwisher, J. B. Tenenbaum, and E.
Fedorenko. “Dissociating language and thought in large language models”. Trends in
Cognitive Sciences. Publisher: Elsevier, pp. 517–540, 2024.
[Nak+23]
K. Nakasho, M. Hagiwara, A. Anderson, and J. B. Nation. The Tight Upper Bound for
the Size of Single Deletion Error Correcting Codes in Dimension 11. Preprint: arXiv:
2309.14736, 2023.
[Nas+24]
M. U. Nasir, S. Earle, J. Togelius, S. James, and C. Cleghorn. “LLMatic: Neural Archi-
tecture Search Via Large Language Models And Quality Diversity Optimization”. In:
Proceedings of the Genetic and Evolutionary Computation Conference, pp. 1110–1118,
2024.
[PHT08]
S. S. P. Parkin, M. Hayashi, and L. Thomas. “Magnetic Domain-Wall Racetrack Mem-
ory”. Science. Publisher: American Association for the Advancement of Science, pp. 190–
194, 2008.
[PS24]
I. Pivotal Software. RabbitMQ, 2024 Available at: https://www.rabbitmq.com/.
[RP+24]
B. Romera-Paredes et al. “Mathematical discoveries from program search with large
language models”. Nature, pp. 468–475, 2024.
16


--- Page 17 ---
[SHS13]
W. W. Shi, W. Han, and W. C. Si. “A Hybrid Genetic Algorithm Based on Harmony
Search and its Improving”. In: Informatics and Management Science I, pp. 101–109,
2013.
[Sho+24]
P. Shojaee, K. Meidani, S. Gupta, A. B. Farimani, and C. K. Reddy. “LLM-SR: Sci-
entific Equation Discovery via Programming with Large Language Models”. In: The
Thirteenth International Conference on Learning Representations, 2024.
[Slo02]
N. J. A. Sloane. “On single-deletion-correcting codes”. In: Codes and Designs. Walter
de Gruyter, pp. 273–292, 2002.
[SF03]
T. Swart and H. Ferreira. “A note on double insertion/deletion correcting codes”. IEEE
Transactions on Information Theory, pp. 269–273, 2003.
[VT65]
R. R. Varshamov and G. M. Tenengolts. “Codes which correct single asymmetric er-
rors.” Avtomatika i Telemekhanika, 1965.
[Xu+23]
C. Xu, Q. Sun, K. Zheng, X. Geng, P. Zhao, J. Feng, C. Tao, and D. Jiang. WizardLM:
Empowering Large Language Models to Follow Complex Instructions. Preprint: arXiv:
2304.12244, 2023.
[Yan+23]
C. Yang, X. Wang, Y. Lu, H. Liu, Q. V. Le, D. Zhou, and X. Chen. “Large Lan-
guage Models as Optimizers”. In: The Twelfth International Conference on Learning
Representations, 2023.
[Ye+24]
H. Ye, J. Wang, Z. Cao, F. Berto, C. Hua, H. Kim, J. Park, and G. Song. “ReEvo: Large
Language Models as Hyper-Heuristics with Reflective Evolution”. In: The Thirty-eighth
Annual Conference on Neural Information Processing Systems, 2024.
[Zhe+23]
M. Zheng, X. Su, S. You, F. Wang, C. Qian, C. Xu, and S. Albanie. Can GPT-4
Perform Neural Architecture Search? Preprint: arXiv:2304.10970, 2023.
[Zhe+25]
Z. Zheng, Z. Xie, Z. Wang, and B. Hooi. Monte Carlo Tree Search for Comprehensive
Exploration in LLM-Based Automatic Heuristic Design. Preprint: arXiv:2501.08603,
2025.
17


--- Page 18 ---
A
Implementation details
1
2
3
4
5
6
7
8
9
10
Number of LLMs
0
2
4
6
Functions/Hour
×103
Ratio 1:20
Ratio 1:15
Ratio 1:10
Ratio 1:5
Figure 8: Rate at which functions are processed for different LLM-to-Evaluator ratios in our dis-
tributed implementation of FunSearch.
We implement FunSearch using RabbitMQ [PS24] for parallelization via asynchronous message
passing. The system consists of multiple LLMs and evaluators, and a single program database,
each running as an independent worker. Workers communicate through RabbitMQ queues using
the Advanced Message Queuing Protocol (AMQP) 0-9-1, which runs over the Transmission Control
Protocol (TCP). Each worker consumes and publishes messages to their designated queues.
The program database constructs prompts and sends them to the LLM queue.
The LLMs
process these prompts to generate new priority functions, which are published to the evaluator
queue. The evaluators compute evaluation scores and return the results to the program database
queue.
The number of functions that can be processed within a fixed time interval is determined by the
number of LLMs and evaluators. We run our implementation of FunSearch with different LLM-
to-Evaluator ratios to understand how resource allocation affects throughput. Each LLM runs on
a single GPU (NVIDIA A100 (80GB) or H100 (94GB)), while each evaluator processes inputs in
parallel using two CPU cores. Evaluators execute functions with a 5-minute timeout; if execution
exceeds this limit, the function is considered non-executable.
Figure 8 shows the throughput in functions per hour (higher is better) for different LLM-to-
evaluator ratios. We achieve the highest throughput at the largest tested ratio of 20 evaluators
per LLM. We expect that increasing the number of evaluators further would increase throughput,
but we could not test this due to infrastructure constraints.
The reported results correspond
to a suboptimal setup where evaluators construct the graph from scratch rather than loading a
precomputed file, which increases evaluation time. Using precomputed graphs increases throughput
further, but does not change the conclusion that evaluators are the limiting factor, and increasing
their number relative to LLMs increases throughput up to a point.
If processing rates between LLMs and evaluators are imbalanced during execution, our imple-
mentation also supports dynamically scaling their number (within available resources) to optimize
throughput.
18


--- Page 19 ---
100
200
300
Maximum New Tokens
1.00
1.25
1.50
1.75
2.00
Rep. Penalty
0.0
0.5
1.0
1.5
Performance
(a) Performance across maximum
new tokens and repetition penalty.
0.5
1.0
1.5
Sampling Temperature
0.6
0.7
0.8
0.9
1.0
Top-p Value
0.0
0.1
0.2
0.3
Performance
(b) Performance across temperature
and top-p.
Parameter
Best
Range
Rep. Penalty
1.2
[1,2]
Top-p
0.78
[0.6,1]
Max. Tokens
246
[50,300]
Temp.
0.94
[0.5,1.5]
(c) Best-performing hyper-
parameters.
Figure 9: Results of LLM hyperparameter optimization from smaller-scale experiments.
B
LLM hyperparameter optimization
We conduct two independent grid searches for the LLM hyperparameters, varying maximum new
tokens and repetition penalty while keeping temperature and top-p fixed, and vice versa.
We measure performance as the average improvement in the independent set sizes constructed by
the best priority functions across all islands for all code lengths n ∈[6, 11] with deletion parameter
s = 1, relative to the trivial initialization. Each grid search run is evaluated after one hour using
one GPU and 40 CPUs to balance search depth with computational feasibility.
For the grid search over maximum new tokens, we consider values in the range [60, 300], and for
repetition penalty, values in [1.0, 2.0], both divided into 10 equally spaced grid points. Temperature
and top-p are fixed at 0.2 and 0.95, respectively, as in Section 7.1.3 of Lozhkov et al. [Loz+24].
The results are shown in Figure 9a. Low repetition penalties combined with high maximum new
tokens often result in the LLM repeating the code completion task, generating multiple function
headers with minor variations or trivial return statements instead of a single, improved function.
Repetition penalties above 1.22 fail to generate executable functions. While competitive results are
achieved with maximum new tokens between 60 and 140 and repetition penalties between 1.05 and
1.11, the highest performance is observed with 246 maximum new tokens and a repetition penalty
of 1.22. Since generating even a single optimal priority function suffices, we proceed with these
hyperparameters.
For the grid search over temperature and top-p, we consider values in [0.5, 1.5] and [0.6, 1.0],
respectively, with 10 equally spaced grid points, while keeping maximum new tokens fixed at 246
and the repetition penalty at 1.22. The results are shown in Figure 9b. Higher variability in token
sampling (larger temperature and top-p values) increases fluctuations in the performance metric
but also improves performance. More deterministic sampling results in more syntactically correct
functions but does not lead to better performance.
These findings align with the hypothesis of Romera-Paredes et al. [RP+24] that the LLM con-
tributes by exploring diverse function solutions, occasionally generating good executable functions
but often producing unusable outputs. The best performance is achieved at a temperature of 0.9444
and a top-p of 0.7778.
19


--- Page 20 ---
Table 2: Results for different evolutionary search hyperparameter configurations.
(a) Results for initial temperature T, with P = 30K
and R = 1.2K fixed.
T
n = 6
n = 7
n = 8
n = 9
n = 10
n = 11
0.05
×
√
×
×
×
×
0.1
√
√
√
√
√
√
0.3
√
√
×
×
√
×
0.5
×
×
√
×
×
×
1
√
√
×
×
×
×
(b) Results for period P, with T = 0.1 and R =
1.2K fixed.
P
n = 6
n = 7
n = 8
n = 9
n = 10
n = 11
5,000
√
√
√
√
√
√
10,000
√
√
√
×
×
×
30,000
√
√
√
√
√
√
50,000
√
√
√
√
√
√
100,000
√
√
√
×
×
×
(c) Results for the number of functions R stored be-
fore an island reset, with T = 0.1 and P = 30K
fixed.
R
n = 6
n = 7
n = 8
n = 9
n = 10
n = 11
300
√
√
√
√
√
√
600
√
√
√
√
√
√
1200
√
√
√
√
√
√
2400
×
√
×
×
×
×
5000
√
√
×
√
×
×
(d) Results for dynamically decreasing the LLM
temperature to greedy decoding after storing D
functions.
D
n = 6
n = 7
n = 8
n = 9
n = 10
n = 11
5,000
√
√
√
√
√
√
10,000
×
√
×
√
×
×
20,000
√
√
√
√
√
×
50,000
√
√
×
×
√
√
C
Evolutionary search hyperparameter optimization
We perform independent grid searches over the evolutionary search hyperparameters initial tem-
perature T, sampling period P and the number of functions R stored before an island reset, using
the best-performing LLM hyperparameters from Table 9c. Performance is measured as a binary
outcome: success or failure in finding an optimal priority function that constructs a maximum
independent set for all evaluation inputs n ∈[6, 11] with s = 1, where the maximum is known.
Each evolutionary search run is evaluated after generating 400K priority functions or stops early if
an optimal function is found and 20K additional ones are generated.
Table 2a summarizes the results for initial temperatures T ∈{0.05, 0.1, 0.3, 0.5, 1} with a fixed
sampling period of P = 30K and R = 1.2K functions stored before a reset. An optimal priority
function is found only when the temperature is set to T = 0.1. Figure 10a shows the evolutionary
search trajectories, plotting the highest score assigned to priority functions across all clusters and
islands as new functions are processed. With T = 0.1, an optimal function (shown in Figure 11) is
found after approximately 115,850 processed functions, with 20.7% of generated functions stored
at the end of the search. When the temperature is set to T = 0.05, 0.3, 0.5, or 1, the percentages of
stored functions are 18.6%, 19.3%, 12.0%, and 10.0%, respectively. Across all configurations, only
a small fraction of generated functions is stored, with many failed executions.
Table 2b summarizes the results for sampling periods P ∈{5K, 10K, 30K, 50K, 100K}, with a
fixed temperature of T = 0.1 and R = 1.2K functions stored before a reset. Adjusting the sampling
period does not improve performance beyond the configuration with P = 30K in the grid search
over temperature. Figure 10b shows the evolutionary trajectories for different sampling periods.
With P = 5K, an optimal priority function is found after 193,815 processed functions, with 18.1%
stored at termination.
With P = 50K, an optimal function is found after 132,499 processed
functions, with 23.0% stored. When the sampling period is set to P = 10K or P = 100K, no
20


--- Page 21 ---
0
1
2
3
4
Total Functions Processed
×105
140
160
180
200
Overall Best Score
T = 0.05
T = 0.1
T = 0.3
T = 0.5
T = 1
Optimal
(a) Varying initial temperature T ∈{0.05, 0.1, 0.3,
0.5, 1} with fixed P = 30K and R = 1.2K.
0
1
2
3
4
Total Functions Processed
×105
140
160
180
200
Overall Best Score
P = 5 000
P = 10 000
P = 30 000
P = 50 000
P = 100 000
Optimal
(b) Varying sampling period P ∈{5K, 10K, 30K,
50K, 100K} with fixed T = 0.1 and R = 1.2K.
0
1
2
3
4
Total Functions Processed
×105
140
160
180
200
Overall Best Score
R = 300
R = 600
R = 1 200
R = 2 400
R = 5 000
Optimal
(c) Varying number of functions R ∈{300, 600,
1.2K, 2.4K, 5K} stored before an island reset, with
fixed T = 0.1 and P = 30K.
0
1
2
3
4
Total Functions Processed
×105
140
160
180
200
Overall Best Score
D = 5 000
D = 10 000
D = 20 000
D = 50 000
Optimal
(d) Dynamically decreasing LLM temperature,
reaching greedy decoding at D ∈{5K, 10K, 20K,
50K} functions.
Figure 10: Trajectories for varying evolutionary search hyperparameters.
optimal function is found after 400K processed functions, and the fractions of stored functions are
13.0% and 19.8%, respectively.
Table 2c summarizes the results for numbers of functions R ∈{300, 600, 1.2K, 2.4K, 5K} stored
before an island reset, with a fixed temperature of T = 0.1 and a sampling period of P = 30K.
Varying R does not improve performance beyond the configuration with R = 1.2K in the grid
search over temperature.
Figure 10c shows the evolutionary trajectories for different values of
R. With R = 300, an optimal priority function is found after 251,359 processed functions, with
18.2% stored at termination. With R = 600, an optimal function is found after 196,756 processed
functions, with 19.9% stored. When R = 2, 400 or R = 5K, no optimal function is found within
400K processed, and the fractions of stored functions are 19.2% and 19.6% , respectively.
We also experiment with dynamically decreasing the LLM sampling temperature to balance ex-
ploration and exploitation. The temperature is initialized at 0.94 and decreases as more functions
are stored on the island from which the prompt is sampled, reaching zero at D ∈{5K, 10K, 20K, 50K}
stored functions. Similar to reducing the temperature for sampling clusters as more functions are
21


--- Page 22 ---
Initial T
Period P
Reset R
Dynamic D
0.1
30,000
1,200
w/o
0.1
30,000
1,200
5,000
0.1
30,000
300
w/o
0.1
30,000
600
w/o
0.1
5,000
1,200
w/o
0.1
50,000
1,200
w/o
Table 3: Evolutionary search configurations that find optimal priority functions with 400K pro-
cessed.
def f(v, G, n, s):
neighbours = []
for
neighbor
in G[v]:
p = np.log(int(neighbor [:-s], 2) + 1) * \
(2 ** ((( len(neighbor) - s) - neighbor [:(-s)]. count(’0’)) +
(( neighbor[-s:] != ’0’) * len([i for i in range (0, len(neighbor), 8)])))) / \
np.exp(sum ([(i == "1") * len([j for j in ["1"] * 3]) for i in
neighbor ]))
neighbours.append ((p, neighbor))
if not
neighbours:
return 0
return
sorted(neighbours , key=lambda x: x[0],
reverse=True)[0][0]
Figure 11: Optimal priority function f120K found after about 120K processed with T = 0.1,
P = 30K and R = 1.2K.
stored, decreasing the LLM sampling temperature makes token sampling more deterministic over
time, promoting the exploitation of higher-scoring function examples in prompts.
Table 2d summarizes the results for dynamically decreasing the LLM sampling temperature for
different values of D. While this approach slightly increases the number of executable functions,
it does not improve search efficiency in finding an optimal priority function with fewer functions
processed compared to a fixed temperature. Figure 10d shows the evolutionary trajectories. With
D = 5K, an optimal priority function is found after 246,639 processed functions, with 22.6% stored
at termination. When D = 10K, 20K, or 50K, no optimal function is found within 400K processed,
with 21.1%, 17.2%, and 21.4% stored, respectively.
22


--- Page 23 ---
0
2
4
6
Stored Functions (per Island)
×103
0.0
0.2
0.4
Duplicate Ratio
Mean duplicate ratio
±1 std dev
(a) Mean duplicate ratio.
0.0
0.5
1.0
140
160
Best Score
0.0
0.5
1.0
×105
Total Processed Functions
Island 1
Island 2
Island 3
Island 4
Island 5
Island 6
Island 7
Island 8
Island 9
Island 10
(b) Best score trajectory without (left) and with (right) deduplication.
Figure 12: Results of the evolutionary search experiments with and without function deduplication.
D
Effectiveness of deduplication
We assess the effectiveness of our function deduplication step by running an evolutionary search
without it. For this search, we use an initial temperature T = 0.1, a sampling period P = 30K,
store R = 1.2K functions before an island reset, and use the best-performing LLM hyperparameters
listed in Table 9c.
Figure 12a shows the mean duplicate ratio, defined as the number of duplicate functions divided
by the total number of stored functions.
It is computed every 200 stored functions per island
and averaged across all islands. Without deduplication, approximately 20% of stored functions
are duplicates, either exact copies of previously seen priority functions or syntactically modified
versions with unchanged logic.
Figure 13 shows a prompt with duplicate few-shot examples and the corresponding function
output generated by the LLM. Duplicate examples often result in the LLM generating functions
with identical logic or minor syntactic changes, which fail to construct larger independent sets.
Figure 12b compares the run without deduplication to the run with deduplication that uses the
same run configurations. The search with deduplication processes fewer functions before finding
an optimal one, suggesting that deduplication improves sample efficiency by filtering out prompts
with duplicate examples.
23


--- Page 24 ---
import
numpy as np
import
networkx
as nx
def f0(v, G, n, s):
""" Returns
the
priority
with
which we want to add
vertex v."""
vertex = str(v)
count = 0
for j in range (3, n + 1):
for k in range(n - (j - 1)):
ones = []
zeros = []
if vertex[k] == ’1’ or vertex[k] == ’0’:
for l in range(k, k + j):
if vertex[l] == ’1’:
ones.append("1")
elif
vertex[l] == ’0’:
zeros.append("0")
if len(ones) > len(zeros):
count += len(ones)
ones = []
elif
len(zeros) > len(ones):
count
-= len(zeros)
zeros = []
else:
pass
return
count
def f1(v, G, n, s):
"""
Improved
version
of f0."""
vertex = str(v)
count = 0
for i in range (3, n + 2):
# print ("i is ")
# print(i)
if i <= n + 1:
for j in range(n - (i - 1)):
ones = []
zeros = []
for k in range(j, j + i):
if vertex[k] == ’1’:
ones.append("1")
elif
vertex[k] == ’0’:
zeros.append(’0’)
if len(ones) > len(zeros):
count += len(ones)
elif
len(ones) < len(zeros):
count
-= len(zeros)
return
count
def f2(v, G, n, s):
""" Improved
version
of f1."""
vertex = str(v);
count = 0;
ones = list ();
zeros = list ();
for i in range ((n)):
if vertex[i] == ’0’:
zeros.append("0");
if vertex[i] == ’1’:
ones.append ("1")
if (len(ones)-len(zeros)) >= 1 :
count += len(ones);
while
len(ones)!=0:
ones.pop (-1)
zeros =[]
elif (-len(ones)+len(zeros)) >= 1:
count -= len(zeros);
while
len(zeros)!=0:
zeros.pop(-1)
# ones =[];
return
int(count /4 )
Figure 13: Prompt with duplicate few-shot examples f0 and f1 and the function f2 generated by
the LLM.
24


--- Page 25 ---
12
13
14
15
16
Code Length n
500
1500
2500
Independent Set Size
Largest
Weighted
(a) Average independent set size for code lengths
beyond the evaluation range, computed over all op-
timal priority functions, with error bars showing the
minimum–maximum range.
0
1
2
3
4
Total Functions Processed
×105
50
60
70
80
Overall Best Score
140
160
180
Largest
Weighted
Average
(b) Search trajectories.
The dotted lines indicate
the maximum scores at 172 (right axis), 72.78 (left
axis), and 62.33 (left axis) for largest, weighted, and
average scoring, respectively.
Figure 14: Results of evolutionary searches with different scoring functions.
E
Effect of the scoring function on performance and generalization
The experiments in Section 5.2 of the main paper show that the priority functions discovered using
the baseline prompt generalize to code lengths n = 12, 13, beyond the evaluation range n ∈[6, 11],
but remain only close to the largest VT0(n) code sizes for larger code lengths n.
To improve generalization to longer code lengths, we explore aggregate scoring functions that
evaluate priority functions based on their performance across all code lengths in the evaluation
range, rather than only on the largest length. We compare two aggregate scoring strategies against
the baseline, which uses the independent set size at length n = 11. The first is a simple average
of independent set sizes over all evaluated lengths (n ∈[6, 11]). The second is a weighted average
over the same range, with weights proportional to n. All runs use an initial temperature T = 0.1,
sampling period P = 30K, number of functions R = 1.2K stored before an island reset, and the
best-performing LLM hyperparameters listed in Table 9c.
Perhaps surprisingly, Figure 14a shows that the baseline scoring function achieves better gen-
eralization than the two aggregate alternatives. While the weighted scoring function discovers a
priority function that achieves the largest VT0(n) code size at n = 14, the baseline consistently
finds functions that construct larger code sizes for all other tested lengths (n ∈[12, 16] \ {14}).
Figure 14b further shows that evaluating only on the largest code length finds an optimal priority
function with fewer processed than the weighted scoring function. In contrast, the average scor-
ing function fails to find an optimal function within 400K processed. These results suggest that
focusing on the largest evaluated length is both more efficient and more effective for discovering
functions that generalize to longer code lengths when searching for large single-deletion-correcting
codes.
Given these findings, we also run an evolutionary search using only the largest code size n = 11
(and s = 1) to reduce computational overhead. However, evaluating priority functions on a single
code length biases the search toward functions that are hardcoded for n = 11 and fail to execute
for other lengths. Additionally, this setup affects clustering. Functions are now clustered based on
25


--- Page 26 ---
def f(v, G, n, s):
return -np.average ([ float ((( int(y[:n-(s+1) ]. count(’1’))*( int((y[ -1:(
-(n-s)):( -1)]).count (’1’) )))**2/ len(list(G.
neighbors(y))))) for y in [ v ]+( list(G.neighbors(v)))])
Figure 15: Optimal priority function fW found using weighted scoring.
their score (their performance on the largest code length n = 11) rather than their independent set
sizes across all evaluated code lengths (n ∈[6, 11]). This results in fewer, larger clusters (and thus
fewer distinct function length ranges). As a result, shorter functions are sampled more frequently,
and the few-shot prompts become less diverse compared to clustering based on multiple evaluation
inputs.
26


--- Page 27 ---
0
1
2
3
4
Total Functions Processed
×105
140
160
180
200
Overall Best Score
Run 1
Run 2
Run 3
Optimal
Figure 16: Trajectories for multiple runs with the same configuration using an initial temperature
T = 0.1, sampling period P = 30K, and number of functions R = 1.2K stored before an island
reset. Two out of the three runs find an optimal priority function within the limit of 400K processed.
F
Variation across evolutionary runs
The performance of FunSearch depends on two main factors: the quality of the LLM output and
the functions sampled as examples for the few-shot prompt.
These factors introduce inherent
randomness into the method. To evaluate how FunSearch’s performance varies across runs, we
conduct two additional evolutionary search experiments with initial temperature T = 0.1, sampling
period P = 30K, and R = 1.2K functions stored before an island reset as well as the best performing
LLM hyperparameters listed in Table 9c. This configuration previously found an optimal function
with the fewest processed.
Figure 16 shows the evolutionary search trajectories, plotting the maximum score (independent
set size for the largest code length n = 11) as new functions are processed. Out of the three runs
with the same configuration, two find a maximum independent set for all code lengths n ∈[6, 11]
within the limit of 400K processed.
27


--- Page 28 ---
G
Details on prompt engineering and general-purpose LLMs
In this section, we provide additional details on prompt engineering and replacing StarCoder2 with
GPT-4o Mini. For all runs, we use the configuration with an initial temperature T = 0.1, sampling
period P = 30K, and number of functions R = 1.2K stored before an island reset, as well as the
best performing LLM hyperparameters as listed in Table 9c.
G.1
Prompt engineering
Here we describe our modifications to the baseline prompt in Figure 2. For prompts 3 and 4, which
discover priority functions that achieve optimal code sizes where known, we further analyze their
logic, with prompt 4 rediscovering the largest VT0(n) codes for all code lengths n.
Prompt 1 in Figure 17 specifies that we consider the single-deletion case and that priority reflects a
vertex’s importance for inclusion in the independent set. The rest remains identical to the baseline
prompt.
We introduce prompt 1 after observing that many generated functions include redundant con-
ditions when s = 1, such as s > n, which is always false. While explicitly stating s = 1 reduces
such redundancies, it does not improve performance in constructing maximum independent sets.
"""
Finds
large
independent
set in graph G where
vertices
are
binary
strings
of length n.
Vertices
in G are
connected
if they
share a subsequence
of length at least n −s, where s = 1.
The
functions f
assign a priority
to each
vertex
indicating
its
importance
for
inclusion
in the
independent
set.
Improve f1
over
its
previous
versions
below.
Keep
the
code
short
and
comment
for
easy
understanding .
"""
import
numpy as np
import
networkx
as nx
def f0(v, G):
""" Returns
the
priority
with
which we want to add
vertex v."""
return
0.0
def f1(v, G):
""" Improved
version
of f0 """
Figure 17: Prompt 1.
Prompt 2 in Figure 25 includes the entire evaluation script to give context on how the priority
function is used to construct the independent set. The rest remains identical to the baseline prompt.
Within the 400K processed functions, prompt 2 does not find an optimal one. This may be because
the additional context distracts from the main task of improving the priority function to construct
larger independent sets.
Prompt 3 in Figure 18 removes the graph G as input to the priority function and the network
package from the import statements to bias the LLM to generate functions that rely only on
sequence-specific information. The rest remains identical to the baseline prompt.
The optimal priority functions discovered using evolutionary search with prompt 3 follow a
common structure. Most functions assign priority based on statistics of the number of 1-bits in an
increasing sliding window over the sequence, with either a fixed minimum length (e.g., 2) or one
determined by the deletion correction parameter s. The functions differ in which statistics of the
1-bit count they use (e.g., mean, variance, maximum) and how they transform the statistic(s) (e.g.,
scaling factors or number of unique sliding windows). These variations affect how well the priority
28


--- Page 29 ---
"""
Finds
large
independent
set in graph G where
vertices
are
binary
strings
of length n.
Vertices
in G are
connected
if they
share a subsequence
of length at least n −s.
Improve f1
over
its
previous
versions
below.
Keep
the
code
short
and
comment
for
easy
understanding .
"""
import
numpy as np
def f0(v, G):
""" Returns
the
priority
with
which we want to add
vertex v."""
return
0.0
def f1(v, G):
""" Improved
version
of f0 """
Figure 18: Prompt 3.
function generalizes to longer code lengths. The function achieving the largest VT0(n) code sizes
for lengths n ≤25 is given in Figure 19, with 100% sequence overlap.
def f(v, n, s):
lst =[]
for p in range ((n -2)) :
for q in range
(((p+2)) ,(n))
:
string=""
for r in range (p,q+1) :
string +=v[r]
lst.append(string)
clist =[* map(lambda w:(w).count(’1’),lst)]
averageofobservations =(np.mean(clist));
deviationfromaverage =(np.var(clist)**.65);
priortiyvalue = -( averageofobservations /3+.3) *( deviationfromaverage **.65*(.7))+ (.8) +(1/( len(v)*2.5 ));
return
round(priortiyvalue ,10)
Figure 19: Priority function found using prompt 3 that achieves largest VT0(n) code sizes for all
evaluated lengths n ∈[6, 25] with 100% sequence overlap.
Prompt 4 in Figure 20 explicitly instructs the LLM to focus on bit patterns in the sequence when
assigning priority. The rest remains identical to the baseline prompt. As a result, StarCoder2 redis-
covers the largest VT0(n) codes for all n. Beyond the VT formulation (discussed in Appendix H),
the other discovered optimal priority functions can be grouped into two main categories.
The first consists of functions that compute statistical properties of the sequence: the count
of 1-bits, the product of their positions, and the sum of cumulative sums of 0-bit positions. The
priority score is determined by applying bitwise operations (XOR, AND, OR, shifts) and logical
conditions on these statistics, as illustrated in Figure 21. Interestingly, both categories have 100%
overlap with the largest VT0(n) codes when n is even and 0% overlap when n is odd.
The second consists of a single function that assigns priority based on:
−
n
X
i=1
xi · (n −i + 1)
mod (n + 1) −b
mod n,
where b = 1.5. We find that this function appears multiple times with different values of b but
achieves optimal code sizes only when b = 1.5. This suggests that the LLM explores both globally
and locally within the function space, even without being explicitly instructed to do so.
Prompt 5 in Figure 22 combines the modifications of prompts 1 and 4. However, it does not find
an optimal priority function within 400K processed, even though prompt 4 successfully rediscovers
VT codes. The rest remains identical to the baseline prompt.
29


--- Page 30 ---
"""
Finds
large
independent
set in graph G where
vertices
are
binary
strings
of length n.
Vertices
in G are
connected
if they
share a subsequence
of length at least n −s.
Improve f1
over
its
previous
versions
below.
Keep
the
code
short
and
comment
for
easy
understanding .
Consider
properties
of the
binary
string v, such as
specific
patterns , the
number of ones/zeros.
"""
import
numpy as np
import
networkx
as nx
def f0(v, G):
""" Returns
the
priority
with
which we want to add
vertex v."""
return
0.0
def f1(v, G):
""" Improved
version
of f0 """
Figure 20: Prompt 4.
def f(v, G, n, s):
count_ones = np.array ([ int(char) for
char in v]).sum()
product_positions = abs((np.arange(n) * np.array ([int(char) for
char in v])).prod ())
sum_cumsum_zeros = ((~np.array ([int(char) for
char in v]).astype(bool)).cumsum ().sum()) % (n + 1)
c = [count_ones , product_positions , sum_cumsum_zeros ]
priority_score = min ([
((c[-1] ** 4) & c[ -2]) + (((c[-1] * 9) < c[ -2])),
~(((( -c[ -1]) << c[ -2]) ^ ~c[ -1]) & ~c[ -2]),
((~(~c[-2] | ~(c[ -1])))) ^ (~c[ -1]) ^ (( -(~(c[-1] | c[ -2]))) ^ (c[-1] > 1)),
~(~c[-1] & ~c[ -2]),
(c[-1] + 1) == c[-2]
])
return
priority_score
Figure 21: Example of a priority function found using prompt 4 that achieves the largest VT0(n)
code sizes for all evaluated code lengths n ∈[6, 20], based on statistical properties of the sequence.
It has 100% sequence overlap for even n and zero overlap for odd n.
G.2
Priority functions discovered with GPT-4o mini
Here, we discuss the logic used by the optimal priority functions discovered with GPT-4o Mini.
Using Prompt 3. The optimal priority functions discovered with prompt 3 and GPT-4o mini
follow a similar logic. They compute priority based on the counts of 1- and 0-bits, the number of
0-bits appearing after the last 1-bit, and the sum of 1-bits within certain sliding windows. Each
function combines or weights these counts differently. An example is shown in Figure 23. These
functions achieve the largest VT0(n) code sizes for all evaluated code lengths n ≤25, with 100%
sequence overlap.
Using Prompt 4. The optimal priority functions discovered with prompt 4 and GPT-4o mini
compute priority based on the number of 1- and 0-bits in a sequence, the count of 1-bits within
sliding windows, and the number of neighbors each sequence has in the graph G.
They differ
primarily in how the counts are weighted or combined. An example is shown in Figure 24. All
optimal functions achieve the largest VT0(n) code sizes for lengths n ∈[6, 13], with 100% sequence
overlap for even n and 0% overlap for odd n.
30


--- Page 31 ---
"""
Finds
large
independent
set in graph G where
vertices
are
binary
strings
of length n.
Vertices
in G are
connected
if they
share a subsequence
of length at least n −s.
The
functions f
assign a priority
to each
node
indicating
its
importance
for
inclusion
in the
independent
set.
Desired
properties
of the
function f :
- ** Efficiency **: The
function
should be
computationally
efficient.
- ** Avoid
Redundant
Computations **: Do not
perform
unnecessary
calculations
or repeat
work.
- ** Clarity **: The
code
should be easy to understand , with
appropriate
comments.
- ** Innovation **:
Explore
different
strategies
for
calculating
the
priority. Consider
specific
characteristics
of the
binary
strings , such as:
- Patterns
in the
binary
string.
- The
number of ones or zeros (Hamming
weight).
- Distribution
of bits (e.g., runs of ones or zeros).
Improve f1
over
its
previous
versions
below.
Keep
the
code
short
and
comment
for
easy
understanding .
"""
import
numpy as np
import
networkx
as nx
def f0(v, G):
""" Returns
the
priority
with
which we want to add
vertex v."""
return
0.0
def f1(v, G):
""" Improved
version
of f0 """
Figure 22: Prompt 5.
def f(v, n, s):
ones_count = v.count(’1’)
zero_count = v[:n - s]. count(’0’)
efficient_zero_contributions = sum(1 for i in range(n) if v[i] == ’0’ and ’1’ in v[:i])
overlap_ones = sum(v[i:i + n - s]. count(’1’) for i in range(n - s + 1))
overlap_count = ( overlap_ones + zero_count) // (n - s + 1)
return
ones_count + zero_count * (n - s + 2) + efficient_zero_contributions
- overlap_count + ones_count *
efficient_zero_contributions
// (n - s + 1)
Figure 23: Example of a priority function found using prompt 3 and GPT-4o mini that achieves
the largest VT0(n) code sizes for all lengths n ∈[6, 25], with 100% sequence overlap.
def f(v, G, n, s):
num_ones = v.count(’1’)
num_zeros = n - num_ones
total_neighbors = len(list(G.neighbors(v)))
balance = abs(num_ones
- num_zeros) / n
pattern_score = sum ((v[i:i+b]. count(’1’)) for b in range (1, n - s + 1) for i in range(n - b + 1))
uniqueness_score = len(set(v)) / n
redundancy_score = total_neighbors / (n + 1e -6)
density = num_ones / n
return (num_ones * redundancy_score + pattern_score + uniqueness_score
- density
- balance)
Figure 24: Example of a priority function found using prompt 4 and GPT-4o mini that achieves
the largest VT0(n) code sizes for all lengths n ∈[6, 13], with 100% sequence overlap for even n and
0% overlap for odd n.
31


--- Page 32 ---
"""
Finds
large
independent
set in graph G where
vertices
are
binary
strings
of length n.
Vertices
in G are
connected
if they
share a subsequence
of length at least n −s.
Improve f1
over
its
previous
versions
below.
Keep
the
code
short
and
comment
for
easy
understanding .
"""
import
numpy as np
import
networkx
as nx
import
itertools
def
generate_graph (n, s):
G = nx.Graph ()
sequences = [’’.join(seq) for seq in
itertools.product(’01’, repeat=n)]
for seq in
sequences:
G.add_node(seq)
for i in range(len(sequences)):
for j in range(i + 1, len(sequences)):
if
has_common_subsequence (sequences[i], sequences[j], n, s):
G.add_edge(sequences[i], sequences[j])
return G
def
has_common_subsequence (seq1 , seq2 , n, s):
threshold = n - s
if
threshold
<= 0:
return
True
prev = [0] * (n + 1)
current = [0] * (n + 1)
for i in range (1, n + 1):
for j in range (1, n + 1):
if seq1[i - 1] == seq2[j - 1]:
current[j] = prev[j - 1] + 1
else:
current[j] = max(prev[j], current[j - 1])
if
current[j] >= threshold:
return
True
prev , current = current , prev
return
False
def
evaluate(params):
n, s = params
independent_set = solve(n, s)
return
len( independent_set )
def
solve(n, s):
G_original = generate_graph (n, s)
G_for_priority = G_original.copy ()
priorities = {v: f1(v,G_for_priority , n, s) for v in
G_original.nodes}
vertices_sorted = sorted(G_original.nodes , key=lambda v: (-priorities[v], v))
independent_set = set()
for v in
vertices_sorted :
if v not in
G_original:
continue
independent_set .add(v)
neighbors = list(G_original.neighbors(v))
G_original.remove_node(v)
G_original. remove_nodes_from (neighbors)
return
independent_set
def f0(v, G):
""" Returns
the
priority
with
which we want to add
vertex v."""
return
0.0
def f1(v, G):
""" Improved
version
of f0 """
Figure 25: Prompt 2.
32


--- Page 33 ---
H
Equivalence between the discovered priority function and the
largest VT code
In this section, we show that our priority function f in Figure 6, found with prompt 4, rediscovers
the largest VT0(n) codes in an alternative form. That is, the priority function selects codewords
that match the largest VT0(n) codes for all code lengths n within our greedy construction algorithm.
For a single deletion (s = 1), the priority function f assigns priority to a binary sequence v of
length n as follows
f(v, n, s = 1) =
W(v)
n + 1

where
W(v) =
n
X
i=1
(n −i + 1) · vi.
(2)
Let q(v) and r(v) be defined as
q(v) =
W(v)
n + 1

and
r(v) = W(v) mod (n + 1),
such that the weighted sum can be decomposed as W(v) = q(v)(n + 1) + r(v). Expanding the
remainder, we obtain
r(v) ≡
n
X
i=1
(n + 1) · vi −
n
X
i=1
i · vi ≡−
n
X
i=1
i · vi ≡n + 1 −
n
X
i=1
i · vi
(mod n + 1).
Thus, a sequence v with remainder r satisfies VT Equation 1 with parameter a = n + 1 −r(v).
In our greedy construction, sequences are considered in descending order of their priority (i.e.,
their quotient q). Among sequences with the same priority q, we sort them in ascending lexico-
graphic order, with 0 smaller than 1. A binary sequence v precedes (i.e., is considered before)
binary sequence w if, at the first position j where they differ, vj = 0 and wj = 1.
The most significant bits (i.e., leftmost bits) contribute the most to the weighted sum W, so
sequences with fewer leading 1-bits (and thus smaller W) appear earlier in lexicographic order.
Thus, for each priority q, sequences with the smallest remainder r = 0, which correspond to the
codewords in the largest VT0(n) code, are considered first for inclusion in the independent set.
To establish equivalence, it remains to show that, once all sequences v with r(v) = 0 have been
included, no additional sequence with equal priority can be added to the independent set without
violating the independence property.
Claim 1. For any binary sequence w of length n with priority q(w), there exists a sequence v in
the largest VT0(n) code that shares a common subsequence with w and has priority q(v) ≥q(w)
(for all n).
The remainder of this section establishes this claim.
VT codes partition the space of all binary sequences of length n into n + 1 deletion-correcting
codes V Ta(n) (see Equation 1). Each V Ta(n) code forms a maximal independent set, meaning that
no additional sequence can be added without violating independence. This follows, for example,
from the result by Cullina et al. [CKK12], which proves that VT codes optimally solve the coloring
problem. Since each independent set is maximal, for any binary sequence w ∈{0, 1}n \ V Ta(n),
33


--- Page 34 ---
there must exist at least one binary sequence v ∈V Ta(n) that shares a common subsequence of
length n −1 with w. Otherwise, w could be added to V Ta(n), contradicting maximality.
To show that the sequence v that shares a common subsequence with w has priority q(v) ≥q(w),
we use the following property of VT codes.
Property 1 (Used in the decoding algorithm by Levenshtein [Lev66]; see also [Slo02]). If two
binary sequences v ∈V Ta(n) and w ∈V Ta′(n) with a ̸= a′ share a common subsequence of length
n −1, their VT-weighted sum difference satisfies
1 ≤

n
X
i=1
i · vi −
n
X
i=1
i · wi
 ≤n.
Below, we show that our weighted sum W in Equation 2 also satisfies Property 1. Thus, the
sequences have equal priority, q(v) = q(w) and we have established Claim 1.
We consider all three cases in which the sequences v and w can be obtained from their common
subsequence z of length n −1.
Case 1: Inserting a 0-bit. The sequences v and w are obtained from their common subse-
quence z by inserting a 0-bit at different positions, denoted by Ij
0(z), where j is the position of the
insertion. All three sequences have m 1-bits. The weighted sum W(Ij
0(z)) can change by at most
W(I0
0(z)) =
n
X
i=1
((n −1) + 1 −(i + 1) + 1) · zi = W(z)
≤W(Ij
0(z)) ≤W(In
0 (z)) =
n
X
i=1
((n −1) + 1 −i + 1) · zi = W(z) + m.
The lower bound follows from inserting the 0-bit before the first 1-bit, e.g., at position j = 0,
shifting all subsequent bits by one, and the upper bound from inserting it after the last 1-bit, e.g.,
at j = n.
Then it holds that
1 ≤|W(v) −W(w)| ≤m.
Case 2: Inserting a 1-bit. The sequences v and w are obtained from their common subsequence
z by inserting a 1-bit at different positions, denoted by Ij
1(z), where j is the position of the insertion.
Sequences v and w have m 1-bits and z has m −1 1-bits. The weighted sum W(Ij
1(z)) can change
by at most
W(z) + m ≤W(Ij
1(z)) ≤W(z) + n.
The lower bound follows from inserting the 1-bit at the end, contributing 1 to the new weighted
sum. The upper bound follows from inserting it at the beginning, contributing n to the weighted
sum and all subsequent positions shifted by one. Then it holds that
1 ≤|W(v) −W(w)| ≤n −m.
Case 3: Inserting Different Bits. Sequence v is obtained from common subsequence z by
inserting a 1-bit, while sequence w is obtained by inserting a 0-bit. The sequence v has m 1-bits,
whereas w and z have m −1 1-bits.
34


--- Page 35 ---
If we delete a 1-bit from v, denoted by Dj
1(v), its weighted sum can change by at most
W(v) −n ≤W(Dj
1(v)) = W(z) ≤W(v) −m,
where the upper bound follows from deleting a 1-bit at the end (when the sequence has a 0-bit in
the (n −1)th position) and the lower bound from deleting a 1-bit at the beginning.
Similarly, if we delete a 0-bit from sequence w, denoted by Dj
0(w), its weighted sum can change
by at most
W(w) −m + 1 ≤W(Dj
0(w)) = W(z) ≤W(w),
where the upper bound follows from deleting a 0-bit at the beginning and the lower bound from
deleting a 0-bit at the end.
By interchanging the upper bounds, we obtain a lower bound on the weighted sum difference:
W(w) −(m −1) ≤W(v) −m
⇒
1 ≤W(v) −W(w).
For the upper bound, we get:
W(v) −n ≤W(w)
⇒
W(v) −W(w) ≤n.
This shows that Property 1 also holds if the weighted sum for a sequence is defined as in our priority
function in Equation 2 and concludes our proof of equivalence.
35


--- Page 36 ---
10
15
Code length n
−103
−102
−101
−100
0
Gap to best-known (log)
s = 1
10
15
Code length n
−101
−100
0
100
s = 2
10
15
Code length n
−101
−100
0
s = 3
Scored on:
s=1
s=2 s=1, 2
Run conﬁguration:
default
weighted prompt 4
Figure 26: Gap to best-known code sizes (log scale) across all runs, varying evaluation inputs
(single, two, joint deletions) and configurations (default, weighted and prompt 4).
I
Details on search for multiple deletion correcting codes
In this section, we detail results from our searches for two-deletion-correcting codes, as well as joint
searches for single- and two-deletion-correcting codes. We analyze both performance on evaluation
inputs (i.e., the deletion parameters and code lengths used to evaluate the new functions during
the search) and generalization to unseen deletion parameters and code lengths.
We consider three sets of evaluation inputs, defined by the number of deletions s and the code
length n: (i) s = 1, n ∈[6, 11]; (ii) s = 2, n ∈[7, 12]; and (iii) s = 1, 2, with n ∈[9, 11] for s = 1,
and n ∈[10, 12] for s = 2. For each set, we report results using the default configuration, weighted
scoring, and prompt 4.
Table 4 summarizes the code sizes achieved for single, two, and three deletions across lengths
n ∈[6, 16]. For two deletions, the search finds priority functions that match or nearly match the
best-known code sizes across all tested lengths. For n = 12, it discovers a function (Figure 28)
that constructs a code of size 34, improving upon the previous best of 32. For n = 16, the search
for single- and two-deletion-correcting codes yields a new lower bound of 204 (e.g., achieved by the
function in Figure 32), exceeding the previous best of 201.
Figure 26 shows the difference from the best-known code sizes for the functions with the smallest
total difference to best-known across all deletion parameters (single, two, and three) and lengths
n ∈[6, 16]. Among all functions scored on two-deletion-correcting code sizes, the best one achieves
a total difference of 2957 (normalized: 4.03). In contrast, scoring on both single- and two-deletion-
correcting code sizes results in a much lower total difference of 30 (normalized: 1.75). The normal-
ized score divides each difference by the corresponding best-known code size, ensuring that large
absolute differences for single-deletion cases (where code sizes are larger) do not dominate the total.
The lower scores in the joint case (both normalized and unnormalized) suggest better generalization
across deletion counts and code lengths.
36


--- Page 37 ---
Table 4: Code sizes achieved for single, two, and three deletions by priority functions from runs
evaluated on s = 1, s = 2, and s = 1, 2. Each entry is the maximum across all best-performing
functions∗. Best-performing functions are selected based on exact matches (when s = 1), or the
smallest total difference from best-known sizes over the run’s evaluation inputs (when s > 1).
The final columns report the sizes achieved by the trivial lexicographic baseline, prior search re-
sults [LH07], and best-known VT0(n) code sizes [VT65] or minimum-degree heuristics code sizes
[KZK11] for comparison. Bold values indicate known maxima. Superscripts link to figures showing
the function that achieves the reported code size.
(n, s)
Scored on s = 1∗∗
Scored on s = 2
Scored on s = 1, 2
Trivial
Search-based
Best known
(7,1)
16
15
1633
14
-
16
(8,1)
30
27
3033
25
-
30
(9,1)
52
44
5233
42
-
52
(10,1)
94
80
9433
71
-
94
(11,1)
172
131
17233
125
-
172
(12,1)
3166,19,23
227
31633
224
-
316
(13,1)
5866,19,23
409
58633
406
-
586
(14,1)
10966,19,23
743
109633
737
-
1096
(15,1)
20486,19,23
1342
204833
1345
-
2048
(16,1)
38566,19,23
2467
385633
2468
-
3856
(7,2)
511,19
527
529
5
5
5
(8,2)
711,15
727
733
6
7
7
(9,2)
9
10
10
9
11
11
(10,2)
13
1628
15
13
16
16
(11,2)
21
22
21
20
21
24
(12,2)
3215
3428
33
29
31
32
(13,2)
5011
48
5031
46
49
49
(14,2)
7819
77
7833
72
75
78
(15,2)
125
123
124
114
109
126
(16,2)
20111
200
20432
189
176
201
(7,3)
26,19,21,23
227,28
229
2
2
2
(8,3)
46,19
427,28
429
4
4
4
(9,3)
56
527,28
4
5
5
5
(10,3)
5
627,28
630
5
6
6
(11,3)
7
827,28
7
6
7
8
(12,3)
11
11
10
10
10
12
(13,3)
13
14
14
13
12
15
(14,3)
19
2027
18
18
15
20
(15,3)
26
26
26
24
24
28
(16,3)
37
37
38
34
31
40
∗If the maximum is taken over all priority functions in the database at the end of the search, the constructed code sizes match (or exceed, for
n = 13) the best known sizes on all evaluation inputs.
∗∗For computational reasons, we did not construct code sizes for all of the 170 optimal priority functions discovered during the searches for
single-deletion-correcting codes. Instead, the maximum is taken over the subset of functions shown in Figures 3, 11, 15, 19, 6, 21, 23 and 24.
37


--- Page 38 ---
def
priority(node , G, n, s):
""" Returns
the
priority
with
which we want to add ‘node ‘ to the
independent
set."""
nodeInt= int(node ,base =2); #convert
to
decimal
bitwiseXORArray = [int(i,2)^nodeInt
for i in list(set(G[node ]))];#create
array
that
shows
what
value is
different
between
this
and
each
neighbour
numOfOnes= [( lambda x : sum(map(int , bin(x).replace(’0b’,’’)[:: -1])))(bitValue)#how
many
ones in the
difference
for
bitValue
in
bitwiseXORArray
];
distBetweenBitAndNode = [( lambda x: n - abs(n // 2 - x))(onesCount) for
onesCount
in
numOfOnes ];
avgOfDifferenceInBitsFromMedian = sum( distBetweenBitAndNode )/(max (1,( len(numOfOnes) -1)));
score= (.9**( avgOfDifferenceInBitsFromMedian )) * (( float)(bin(nodeInt).count(’1’)))**(7/(1+( abs(6-n))));
return
round(score ,3)
Figure 27: Example of a priority function found using default configuration, scored on two-deletion-
correcting code sizes.
def
priority(node , G, n, s):
""" Returns
the
priority
with
which we want to add ‘node ‘ to the
independent
set."""
hamming_dist = [ ]
for v in list(G.adj[node ]):
difference = [(i!= j)for (i,j) in zip(node ,v )]
dist= sum ([(i == True )for i in
difference
])
hamming_dist += [ int(dist)]
avg = np.array( hamming_dist ).mean ()
one_count = sum([ char == "1" for
char in node ])
percen_one
=( one_count / len(node))
priority
=.8*( avg)+
-.7* abs ((( percen_one) -.5 ))
return -round(priority ,4)
Figure 28: Example of a priority function found using prompt 4, scored on two-deletion-correcting
code sizes.
def
priority(node , n, s):
""" Returns
the
priority
with
which we want to add ‘node ‘ to the
independent
set."""
maxseqLenght = min ((n*.7) ,(7.+s));
kmrsLengh= max(( round(np.mean ([2, maxseqLenght ])) ), 3.);
numberKmers= n-( kmrsLengh)+(1);
kmscrLst =[]
for
stidx in range( numberKmers ):
numOfonesinNd = sum ([(c=="1") *1for c in node[stidx : (stidx +( kmrsLengh))]]);
OneWtgh= ( numOfonesinNd /kmrsLengh)**.5;
Kmrcr= (1./( OneWtgh
+.000001 ))**(( kmrsLengh )/2) * ( numberKmers /.1) *( kmrsLengh)**
-.45;
kmscrLst.append(Kmrcr );
Ttlscr= (np. log (((1.* numberKmers )*np. mean(kmscrLst)))).__abs__ ();
return -Ttlscr
Figure 29: Example of a priority function found using prompt 3, scored on single- and two-deletion-
correcting code sizes.
def
priority(node , G, n, s):
""" Returns
the
priority
with
which we want to add ‘node ‘ to the
independent
set."""
total =0
d=[ (int(bit)) for bit in list(node)]
degree=len(list(filter( lambda x :( int(x)==1 ) ,[ (int(bit)) for bit in list(node)])))
adj = len(list(nx.neighbors(G, node)))
if(degree <=1 and adj
<7):
return
(.9/(1.+ float(degree))) *( pow (((( deg +7) /2.*
float(total))+0.01) ,(.9/.9+(1/ deg)))) * pow (1./adj , -(.15))
else:
for k in range(n//2 + n %2):
total += sum ([( int)(d[i])for i in range(k,(n)-k)])
deg =(max(degree ,.1))/1.
return
((1./( float(deg)+1))* ( (deg
+1.) ** deg )*total +0.01) *( pow( ( 1. -(1. -1./ float(adj)) ) ,(-.3)))
Figure 30: Example of a priority function found using default configuration, scored on single- and
two-deletion-correcting code sizes.
38


--- Page 39 ---
def
priority(node , n, s):
""" Returns
the
priority
with
which we want to add ‘node ‘ to the
independent
set."""
def
findNumberOfOnesForEveryPossibleSubstring ():
def
numberOfOnesInNode (i,k):
substr = node[i:(i + k)]
return
sum([int (val == ’1’)for val in substr ]);
possibleLengths =[x for x in range (1,(n-s))]
onelist =[]
for index ,elemt in
enumerate( possibleLengths ):
startindex= 0
while
True:
numofOne= numberOfOnesInNode (startindex , elemt);
onelist.append ({’onenum ’:numofOne ,’startingIndex ’:startindex });
startindex
+= 1
if (( startindex+ elemt)>n):
break
return
onelist
onelist= findNumberOfOnesForEveryPossibleSubstring ()
score=lambda x:-(x[’onenum ’] * x[’onenum ’]) *(max(1,abs (((x[’startingIndex ’]/ float(n))) -(s/( float(n))))))
finalScore=map(score ,onelist)
return
sum(finalScore)
Figure 31: Example of a priority function found using prompt 3, scored on single- and two-deletion-
correcting code sizes. It achieves a new lower bound for s = 2 and n = 16, with size 202, compared
to the previously best known size of 201.
def
priority(node , n, s):
""" Returns
the
priority
with
which we want to add ‘node ‘ to the
independent
set."""
weight= []
for k in range ((n)+1):
cnt =0
for p in range (((n)- (k))+1):
substring=""
for r in range(p,(p)+(k)):
characTer=str( int(node[r]))
substring += characTer
numZeROES=substring.count("0")
NUMONES=substring.count("1")
if numZeROES >= NUMONES:
Weight =-( numZeROES *2*(k+1))
else :
Weight =( NUMONES *.8*(k+1))
weight.append(Weight)
averagE=np.mean(weight )
return
averagE
Figure 32: Example of a priority function found using prompt 4, scored on one and two-deletion
correcting code sizes. It achieves a new lower bound for s = 2 and n = 16, with size 204, compared
to the previously best known size of 201.
def
priority(node , G, n, s):
""" Returns
the
priority
with
which we want to add ‘node ‘ to the
independent
set."""
wt=[]
for q in range ((n)+1):
counter =0
for w in range (((n)-q )+1) :
substring=""
for e in range(w, (w +(q))):
character= str( int(node[e]))
substring +=
character
NumberofZeroes =substring.count("0")
NumbersOfOnes =substring.count("1")
if NumbersOfOnes >= NumberofZeroes :
weight= -( NumbersOfOnes )*(q*6+.89)
else :
weight= ( NumberofZeroes )*.5 * (q *3 )
wt.append(weight)
if len(wt)!=0 :
Average=sum(wt)/len(wt)**.7*3
return
Average
Figure 33: Example of a priority function found using prompt 4, evaluated on one and two-deletion-
correcting code sizes.
39


--- Page 40 ---
1016
30
52
94
172
Independent Set Size
0.0
0.1
0.2
0.3
0.4
Density
n = 6
n = 7
n = 8
n = 9
n = 10
n = 11
Figure 34: Distribution of independent set sizes when sequences are iteratively added in order over
105 permutations of all 2n sequences.
J
Computational difficulty of finding a maximum independent set
in our graphs
Finding a maximum independent set in a general graph is NP-complete [LP09]. Even if the optimal
size is known, evaluating all subsets of that size requires
 2n
optimal size

evaluations. For example, for
n = 6, s = 1 and maximum size 10, this already exceeds 151 billion evaluations. Without knowing
the exact optimal size, all possible subsets of varying sizes must be considered, leading to a worst-
case complexity of 22n.
However, if many maximum independent sets exist in the graph, a simple greedy search can
quickly find one, significantly reducing the problem’s difficulty. To get an idea of whether our
graphs contain many maximum independent sets, we iteratively add sequences in order over 105
random permutations of all 2n sequences to determine how often a random construction finds a
maximum independent set for code lengths n ∈[6, 11] and a single deletion s = 1.
Figure 34 shows the distribution of independent set sizes for each code length n ∈[6, 11]. For
the smallest code length (n = 6), the random search finds a maximum independent set in 118, and
for n = 7 in 8 out of 105 attempts. For larger code lengths, the random search does not find a
maximum independent set in any of the 105 attempts. Moreover, as the code length increases, the
distribution of independent set sizes shifts further from the maximum set size, indicating that the
problem becomes more difficult.
40
