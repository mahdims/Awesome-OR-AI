--- Page 1 ---
arXiv:2502.14760v2  [cs.AI]  10 Jun 2025
EQUIVAMAP: LEVERAGING LLMS FOR AUTOMATIC
EQUIVALENCE CHECKING OF OPTIMIZATION FORMULATIONS
Haotian Zhai1, Connor Lawless2, Ellen Vitercik3, Liu Leqi4
1,4The University of Texas at Austin
2,3Stanford University∗
ABSTRACT
A fundamental problem in combinatorial optimization is identifying equivalent formulations. Despite
the growing need for automated equivalence checks—driven, for example, by optimization copilots,
which generate problem formulations from natural language descriptions—current approaches rely
on simple heuristics that fail to reliably check formulation equivalence. Inspired by Karp reductions,
in this work we introduce Quasi-Karp equivalence, a formal criterion for determining when two
optimization formulations are equivalent based on the existence of a mapping between their decision
variables. We propose EquivaMap, a framework that leverages large language models to automatically
discover such mappings for scalable, reliable equivalence checking, with a verification stage that
ensures mapped solutions preserve feasibility and optimality without additional solver calls. To
evaluate our approach, we construct EquivaFormulation, the first open-source dataset of equivalent
optimization formulations, generated by applying transformations such as adding slack variables or
valid inequalities to existing formulations. Empirically, EquivaMap significantly outperforms existing
methods, achieving substantial improvements in correctly identifying formulation equivalence.2
Keywords Combinatorial Optimization · Large Language Models · Mixed Integer Linear Programming
1
Introduction
Combinatorial optimization lies at the heart of many of today’s most pressing challenges in operations research,
theoretical computer science, and machine learning. Its applications range from classic problems such as shortest path
[22] and maximum flow [31] to modern challenges in neural architecture search [12] and hyperparameter optimization
[20].
A fundamental problem in combinatorial optimization is identifying equivalent formulations. Historically, establishing
equivalence has played a pivotal role in unifying problem-solving techniques and advancing theoretical characterizations
of a problem’s computational complexity. In theoretical computer science, equivalence between problems underpins the
concept of NP-completeness [9, 19], which unifies many seemingly distinct problems—such as SAT, Vertex Cover, and
Subset Sum—into the same equivalence class. This unification enables researchers to prioritize the development of
algorithms for canonical problems while ensuring their applicability across equivalent problems. Similarly, in applied
fields such as network design [18] and semiconductor scheduling [13], recognizing equivalence between optimization
problems has historically facilitated the transfer of algorithms, reducing duplication of effort.
The advent of large language models (LLMs) has exposed a new frontier in combinatorial optimization, introducing
opportunities to automate problem formulation, while also presenting new challenges—chief among them, the need for
reliable equivalence checking. Recent research has focused on developing optimization copilots, systems that automate
the translation of natural language descriptions into formal optimization formulations, particularly for mixed-integer
∗Corresponding authors: haotian.zhai@utexas.edu
2The code and datasets are available at https://github.com/HumainLab/EquivaMap and https://huggingface.co/
datasets/humainlab/EquivaFormulation.


--- Page 2 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
linear programming (MILP) problems [30, 36, 2, 4]. These advancements hold significant potential for democratizing
access to optimization techniques, broadening the reach of powerful tools for better decision-making [35]. However, the
widespread adoption of optimization copilots hinges on reliable evaluation mechanisms capable of verifying whether the
generated formulations are equivalent to their ground-truth counterparts. Moreover, automatic formulation equivalence
checking is critical to improving optimization copilots by serving as an intermediate step, facilitating more efficient
formulation search and refinement [4].
Despite the importance of equivalence checking in combinatorial optimization, existing automatic approaches rely
heavily on heuristics (e.g., comparing optimal objective values) and lack a precise, universally accepted definition of
what constitutes formulation equivalence. Formal methods such as Karp reductions [19] offer valuable theoretical
insights into problem equivalence but were not designed for modern automated settings, often requiring considerable
human time and expertise to construct.
Towards precise and reliable equivalence checking, we propose a formal definition of formulation equivalence—Quasi-
Karp Equivalence—grounded in the principles of Karp reductions. Quasi-Karp Equivalence determines whether
two formulations are equivalent by checking for the existence of a mapping between their decision variables. We
propose EquivaMap, an approach that automates equivalence checking by using LLMs to identify mappings between
formulations, followed by a lightweight verification step to ensure these mappings preserve optimality and feasibility
without additional MILP solver calls. Grounded in a precise definition of formulation equivalence, EquivaMap allows
for automatic equivalence verification for optimization formulations.
Our contributions can be summarized as follows:
• We identify pitfalls of existing equivalence checking methods (Section 3.1).
• We propose Quasi-Karp equivalence as a formalism for defining when two optimization formulations are equivalent
through the existence of a mapping between their decision variables (Section 3.2) and present EquivaMap, a scalable
method that uses LLMs to discover candidate mappings, paired with a separate verification step to ensure correctness
(Section 3.3).
• To evaluate the performance of equivalence-checking methods, we introduce, to the best of our knowledge, the
first dataset—EquivaFormulation—that documents both equivalent formulations and the transformation between
them (Section 4.1). Empirically, we show that EquivaMap outperforms existing methods across various equivalent
transformations (Section 4.2).
2
Background and Related Work
Our work connects important lines of research on combinatorial optimization (especially MILPs), LLMs for MILP
modeling, and automatic equivalence-checking methods for optimization formulations.
2.1
Combinatorial Optimization and MILPs
Combinatorial optimization (CO) broadly deals with finding an optimal object from a finite (or countably infinite) set
of feasible candidates. Such problems arise in diverse fields, including operations research, computer science, and
engineering, where discrete variables model decisions in practical scenarios such as routing, scheduling, or allocation
of limited resources [28].
A foundational tool for combinatorial optimization is mixed-integer linear programming (MILP), formulated as:
min
x∈Rp×Zn−p c⊤x
subject to
Ax ◦b,
ℓ≤x ≤u,
(1)
where x is the vector of decision variables, c is the cost vector, A is the constraint coefficient matrix, and b is the vector
of constraint bounds. The notation Ax ◦b represents a system of linear constraints, where ◦denotes relational operators
from the set {≤, ≥, =}. The variables x are partitioned into p continuous variables and n −p integer variables. Let
x∗denote an optimal solution to (1), and let z∗= c⊤x∗be the corresponding optimal objective value. If all decision
variables are continuous (p = n), the problem is a linear program (LP). MILPs capture many prominent combinatorial
problems such as the traveling salesman problem (TSP) [10], knapsack problem [29], and network design problems
[18].
Many fundamental CO problems—including TSP and Knapsack—are known to be NP-hard. A key contribution to the
theory of NP-completeness was provided by Karp [19], who demonstrated that a number of widely studied problems
are mutually reducible in polynomial time (often referred to as “Karp reductions”). These reductions establish deep
2


--- Page 3 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
structural connections among CO problems, showing that if a polynomial-time algorithm exists for one, it can be
systematically adapted to solve many others.
2.2
Language Models for MILP Modeling
The use of language models for MILP modeling has sparked considerable interest in the AI-for-OR community. The
NL4Opt competition [30] focused on using natural language processing (NLP) methods to formulate optimization
problems based on their text descriptions. More recently, with the advent of LLMs, a number of LLM-based optimization
copilots aim to automate MILP modeling [27, 3, 26, 39, 15, 17, 38]. Both the Chain-of-Experts [36] and OptiMUS [2]
frameworks designed LLM-based multi-agent systems to automate the modeling of complex optimization problems
by leveraging the reasoning capabilities of the LLMs. Tang et al. [33] further demonstrated the potential of LLMs by
fine-tuning open-source models with synthetic data tailored for modeling optimization problems, achieving significant
performance improvements over baseline methods. Building on these capabilities, LLM-powered chatbots have been
used to allow users to interact with optimization models in a number of contexts including supply chain management
[25], meeting scheduling [24], debugging infeasible models [5], and improving solver configurations [23]. These
advancements highlight why LLMs are particularly suitable for MILP modeling: their ability to process and generate
structured information from natural language aligns well with the requirements of optimization problem formulation.
The rapid development of optimization copilots underscores the need for reliable, scalable evaluation techniques.
2.3
Existing Automatic Equivalence Checking Methods
The central task of evaluating optimization copilots is automatically checking whether the generated formulation is
equivalent to a ground-truth correct one. The earliest method used in the NL4OPT benchmark [30] for evaluating
formulation equivalence is canonical accuracy, which looks at direct equivalence between declarations (e.g., objec-
tive, constraints) between a reference correct formulation and a generated formulation. This method is sensitive to
permutations of the order of the declarations in a formulation and fails when multiple valid formulations exist for the
same problem. The method used in benchmarks such as NLP4LP [2], MAMO [16], and IndustryOR [33] is execution
accuracy, which evaluates whether two MILP formulations are equivalent by solving them (using a MILP solver such
as Gurobi) and checking if they have the same optimal objective value. Execution accuracy is sensitive to variable
re-scaling, which can create inconsistencies even when the formulations are functionally equivalent. To address these
issues, recent approaches utilize Graph Edit Distance [37] and a modified Weisfeiler-Lehman (WL) test [34] to measure
structural similarity between the generated and reference formulations. These methods offer insights into equivalence
beyond the optimal objective value but have limitations. They are particularly sensitive to structural modifications, such
as adding cutting planes, which keep the formulation equivalent but change its structural information. Beyond these
methods, Steever et al. [32] proposed an image-based approach to detect structural similarity among large-scale MILPs.
3
Methodology
This section introduces Quasi-Karp Equivalance and EquivaMap, our method for leveraging LLMs to automatically
check such equivalence. In the general setup, we have two formulations α and α′ corresponding to the same (feasible)
optimization problem P, with optimal objective values z∗and z′∗respectively. For example, Figure 1 presents two
formulations α and α′ of an optimization problem P — the stable set problem. Our method aims to evaluate the
equivalence of α and α′ for a given instantiation of the problem. In Figure 1, an instantiation of P would be defined by
a specific input graph.
3.1
Pitfalls of Existing Equivalence Checking Methods
We discuss existing methods for evaluating formulation equivalence, including canonical accuracy, execution accuracy,
and the WL-test, and exhibit settings where these methods fail.
Canonical accuracy is based on matching declarations between predicted and reference programs, where a declaration
represents either an optimization objective or a constraint [30].
Definition 3.1 (Canonical Accuracy). Given a reference declaration d (objective or constraint) and a generated
declaration ˆd, they are said to be matched if d = bd. Let D and bD denote the sets of reference and generated declarations,
respectively. A False Positive (FP) is a generated declaration ˆd that is unmatched, while a False Negative (FN) is a
reference declaration d that is unmatched. The canonical accuracy is defined as:
1 −min(|FP| + |FN|, |D|)
|D|
3


--- Page 4 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
Figure 1: A classic stable set problem, where the two formulations correspond to the same problem description.
Formulation α uses the standard formulation, while formulation α′ rescales the objective function and adds cutting
planes based on cliques (where K denotes the set of cliques in G). LLMs are used to find the mapping function f that
maps the variables of α′ into the variable space of α. An example mapping would be the identity function f(yi) = yi.
where any score under 100% indicates that the formulations are not equivalent.
Canonical accuracy imposes a strong assumption that generated MILPs must adhere to the same variable order as the
ground-truth MILP. As illustrated in Figure 1, if the constraints in α are permuted differently from those in α′, they are
erroneously treated as nonequivalent, despite being functionally identical. More broadly, canonical accuracy fails in
cases where the two formulations differ based on variable or constraint permutations.
Execution accuracy captures whether two optimization problems have the same optimal objective value [2].
Definition 3.2 (Execution Accuracy). α and α′ are considered equivalent if z∗= z′∗.
Execution accuracy has a clear limitation: it is not robust to rescaling, a common transformation in MILPs that may
simply reflect a change in units. For example, in Figure 1, the objective function in α′ is rescaled, which would lead
execution accuracy to incorrectly classify α and α′ as non-equivalent.
Previous studies have shown that MILPs can be represented as bipartite graphs [6, 7, 21, 14], providing a foundation for
defining equivalence using graph-isomorphism based approaches such as the WL-test. To construct this bipartite graph,
a node is added for each variable and each constraint of the graph. An edge connects a variable node to a constraint
node if that variable has a non-zero coefficient in the corresponding constraint. The nodes and edges are endowed with
various real-valued attributes describing the MILP (for example, a variable node’s attributes will include its coefficient
in the objective function). The WL-test tests whether two graphs are isomorphic.
Definition 3.3 (WL-test [11]). Let G = (V, E) and H = (V ′, E′) be two graphs. The Weisfeiler-Lehman test is an
iterative label refinement procedure used to determine whether G and H are distinguishable. Initially, each vertex
v ∈V is assigned a label ℓ0(v). At each iteration t, the label of each vertex v is updated as follows:
ℓt+1(v) = hash (ℓt(v), {ℓt(u) | u ∈N(v)})
where N(v) denotes the set of neighbors of v, and the function hash(·) provides a unique encoding neighboring nodes’
labels. The process continues iteratively until convergence. To compare graphs, the WL-test computes the multisets
of final labels for G and H. If these multisets differ at any iteration, the graphs are determined to be non-isomorphic,
which indicates that they are not equivalent.
Modifications of the WL-test were proposed by Wang et al. [34] to evaluate formulation equivalence. Xing et al.
[37] also introduced a related method based on graph-edit distance, which is a softer version of the WL-test. Since
graph-based methods evaluate equivalence after transforming formulations α and α′ into bipartite graphs, they will treat
the two formulations as non-equivalent if structural modifications change the number of variables or constraints. Such
modifications are extremely common (and desired) in MILPs, as techniques like adding cutting planes, reformulating
constraints, or introducing auxiliary variables are frequently used to improve solver efficiency and tighten linear
4


--- Page 5 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
relaxations. For example, the second formulation in Figure 1 includes clique cutting planes:
X
i∈k
yi ≤1
∀k ∈K
for cliques k ∈K in the graph. These cutting planes are well-known to strengthen the linear relaxation of the stable set
MILP formulation [8].
3.2
MILP Equivalence Based on Karp Reduction
Towards a more formal notion of MILP formulation equivalence, we introduce a new definition inspired by a classical
tool from complexity theory called a Karp Reduction:
Definition 3.4 (Karp Reduction). Two decision problems P, Q are said to be equivalent if there exists a function f that
maps arbitrary instances of P to Q such that:
• If p is a yes-instance of P, then f(p) is a yes-instance of Q,
• If p is a no-instance of P, then f(p) is a no-instance of Q, and
• f can be computed in polynomial time.
A Karp reduction can be used to show that two decision problems are equivalent (i.e., a solution to one can be used
to find a solution to the other). These reductions hold for arbitrary instances of the two decision problems, but we
leverage a similar approach to establish the equivalence between two specific formulations of an MILP problem instance.
Consider two optimization problem formulations α, α′ that correspond to the same optimization problem P. Our goal
is to formally check that an optimal solution to one formulation can be used to generate an optimal solution to the other
formulation for a specific instantiation of the problem. Unlike traditional Karp reductions, which define mappings for
arbitrary instances, we focus on instance-specific mappings. Moreover, our approach maps between solutions of the
optimization problem rather than the instance itself.
We also relax the condition that a no-instance (which corresponds to an infeasible or suboptimal solution) under
one formulation needs to be mapped to a no-instance of the other. This distinction is important in settings where
a MILP formulation may exclude some, but not all, optimal solutions to improve efficiency. For example, adding
symmetry-breaking constraints to an optimization model is a common modeling practice that removes functionally
equivalent solutions. With these distinctions in mind, we formalize a new notion of equivalence for MILP formulations
which we call Quasi-Karp Equivalence:
Definition 3.5 (Quasi-Karp Equivalence). Suppose α and α′ are two optimization problems over Rd and Rd′, re-
spectively. We say α′ is Quasi-Karp equivalent to α if there exists an algorithm A(α, α′) that produces a mapping
f : Rd′ →Rd such that:
• If x∗is an optimal solution to α′, then f(x∗) is an optimal solution to α,
• f can be computed in polynomial time, and
• A(α, α′) runs in polynomial time for all α, α′.
Note that the defintion of Quasi-Karp equivalence is directional, meaning that α′ being Quasi-Karp equivalent to α
does not necessarily imply that α is Quasi-Karp equivalent to α′. Also note there is a distinction between the second
and third point in definition 3.5: it is possible for A to run in polynomial time (e.g., a program implementing f), but for
f itself to require super-polynomial time to evaluate. For example, A could construct a branch-and-bound solver as
f-in which case A runs in polynomial time, but f may not.
In Figure 1, an example of one such mapping f would be xi = yi, ∀i ∈V, which is a linear function. Intuitively, the
notion of Quasi-Karp Equivalence is meaningful only when the optimization problem is NP-hard and both optimization
formulations admit feasible solutions with finite optimal values. If both formulations are infeasible, then neither has a
valid solution, making any comparison between them trivial and uninformative. Declaring two infeasible problems
equivalent does not provide any insight into their structural or computational properties. Likewise, if one formulation
is infeasible while the other is feasible, then no valid mapping f can transform an optimal solution of one into the
other. Finally, if a formulation is unbounded, then it lacks a finite optimal solution, so no single “optimal” point can be
mapped from one formulation to another. Thus, we use Quasi-Karp Equivalence to check equivalence between feasible,
bounded formulations.
5


--- Page 6 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
Figure 2: Workflow of EquivaMap. The method evaluates equivalence between two formulations (α and α′) of the
same optimization problem instance P. An LLM generates a mapping function (f) to map between the variable spaces
of α and α′. The mappings are applied to transform the optimal solution of α′ into a candidate solution in α. A verifier
assesses whether the candidate solution is feasible and optimal for α. If the verification succeeds, α and α′ are deemed
equivalent; otherwise, they are classified as not equivalent.
Algorithm 1 EquivaMap
1: Input: Two optimization formulations α, α′ with objective min c⊤x, min c′⊤x′ respectively. A solver S that finds
an optimal solution x∗for α and x′∗for α′.
2: Output: A Boolean value indicating whether α and α′ are Quasi-Karp equivalent.
3: # {Call an LLM with instance-dependent prompt to find a mapping}
4: f ←A(α, α′)
5: # {Obtain an optimal solution of α′ using solver S}
6: x′∗←S(α′)
7: # {Map the solution x′∗to a candidate solution in α}
8: ˆx ←f(x′∗)
9: # {Check if ˆx is optimal and feasible for α}
10: if c⊤ˆx = c⊤x∗and ˆx feasible for α then
11:
return True
12: else
13:
return False
14: end if
3.3
EquivaMap: LLM-Based Mapping Discovery with Lightweight Verification
To determine the mapping between α and α′, we propose EquivaMap, a framework that leverages LLMs as the
map-finding algorithm A from Definition 3.5. Specifically, given two formulations α and α′ corresponding to a given
instance of the problem P, the algorithm A returns a mapping function f that aligns their solutions: f = A(α, α′).
In EquivaMap (Algorithm 1), we first use the LLM A to find the mapping f for the pair of formulations (α, α′) using
an instance-specific prompt (Appendix A). Using a solver S, we compute an optimal solution x′∗to α′. With f, we
obtain a candidate solution ˆx = f(x∗) for α. We verify whether ˆx is an optimal solution of α by substituting ˆx into α
and verifying that ˆx is feasible and optimal (i.e., c⊤ˆx = c⊤x∗).
A key component of EquivaMap is the instance-specific prompt, which guides the LLM in finding the mapping function
f. The prompt includes a structured description of each variable in the formulation (α), including its textual description,
the constraints in which it appears, and whether it appears in the objective function. Note that if a variable is defined
over a set (e.g., xi ∀i ∈V in Figure 1), the definition of the variable is only included once in the prompt. This allows
the prompt to scale with the number of sets of variables, which can be far less than the number of individual variables
for large-scale problems (see Appendix C for an example). We provide an analogous description of the formulation
(α′). The prompt then instructs the LLM to generate a linear mapping for each variable in α, expressed as a list of
coefficients and corresponding variable names in α′. For more details, we defer to Appendix A.
Below we illustrate this procedure using the example in Figure 1. Suppose the optimal solution of α′ is y∗
i for all i ∈V.
Applying the identity mapping function f, we compute ˆxi = f(y∗
i ) = y∗
i for all i ∈V. We confirm ˆx is feasible, and
substitute ˆxi into the objective function
X
i∈V
xi,
6


--- Page 7 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
Table 1: Overview of the equivalent and nonequivalent transformations between formulations considered in Equiv-
aFormulation. Transformation Name describes the type of transformation; How It Is Transformed explains the
modification applied to the problem; Example (Before/After) provides a short snippet demonstrating the difference;
Equivalent? indicates whether the transformation preserves the original problem’s optimal solutions; and Size shows
the number of affected instances, reported as the count of LP and MILP problems.
Transformation Name
How It Is Transformed
Example (Before/After)
Equivalent?
Size
Substitute Objective Functions
Replace
objective
function
min c⊤x with an auxiliary vari-
able z, adding new constraint
z = c⊤x
Before: min c⊤x
After: min z, s.t. z = c⊤x
Yes
92LP + 140MILP
Add Slack Variables
Transform constraint g(x) ≤b
into g(x) + s = b, s ≥0
Before: x + 2y ≤5
After: x + 2y + s = 5, s ≥0
Yes
59LP + 134MILP
Replace by Base-10 Representation
Express an integer variable N in
its decimal expansion
Before: x ≤106
After: x = P6
i=0 di · 10i, 0 ≤di ≤9, di ∈Z
Yes
44LP + 123MILP
Add Valid Inequalities
Include cutting planes or valid
linear combinations that do not
exclude any integer feasible so-
lution
Before: { x + 2y ≤3, x ≤1.5 }
After: { x + 2y ≤3, x ≤1.5, 2x + 2y ≤4.5 }
Yes
92LP + 142MILP
Rescaling
Change units/scales for variables
or objectives (e.g., hours to min-
utes)
Before: x (hours)
After: 60x′ (minutes)
Yes
60LP + 133MILP
Replace by Linear Combinations
Decompose a variable x into
x = x+ −x−with x+, x−≥0
Before: x
After: x+ −x−
Yes
77LP + 115MILP
Random Order
Substitute the original instance
with a completely unrelated, ran-
domly chosen instance
Before: min z, s.t. z = c⊤x
After: max y, s.t. y = 3
No
87LP + 142MILP
Loose Constraints
Delete certain constraints that
are tight at the optimum, alter-
ing the feasible set
Before: x + 2y ≤3 (binding)
After: remove x + 2y ≤3
No
53LP + 120MILP
Feasibility
Turn both the original and a ran-
domly chosen instance into fea-
sibility problems (replace objec-
tives with 0)
Before: min 0, s.t. z = c⊤x
After: max 0, s.t. y = 3
No
87LP + 142MILP
to verify whether
X
i∈V
ˆxi =
X
i∈V
x∗
i .
Note that the mapping f discovered by EquivaMap is not instance-specific but operates at the formulation level. We feed
the LLM symbolic formulations where parameters and sets, such as the graph G = (V, E), remain abstract instead of
being replaced by real values. The LLM then infers a symbolic mapping between the two formulations that is applicable
across all instances. A more explicit prompt example can be found in Appendix B. However, the verification step
(L9-14) in our algorithm is instance-specific: we instantiate the symbolic formulation with concrete parameter values
and sets and verify that the mapped solution is valid. Thus, while the mapping is over formulations, the verification
check is over instances.
Comparing EquivaMap to Definition 3.5 of Quasi-Karp Equivalence, we note that, under the reasonable assumption
that the LLM’s inference time is polynomial in the length of its input prompt, EquivaMap runs in polynomial time.
Moreover, by restricting the mapping function f to be linear, we ensure that it can be computed in polynomial time.
Stochasticity in LLMs and Aggregation.
Since LLMs have stochastic outputs, we run Algorithm 1 K times and
then aggregate the outputs by declaring (α, α′) equivalent if at least one of the K attempts produces a valid mapping.
4
Experiments
We conduct a comprehensive evaluation of EquivaMap by introducing EquivaFormulation — to the best of our
knowledge, the first dataset that contains equivalent formulations of MILP instances. Moreover, the dataset includes
details about the transformations used to create these equivalent formulations (Section 4.1).
Next, we evaluate EquivaMap on this dataset and compare its performance against established baselines including
canonical accuracy, execution accuracy, and the WL-test (Section 4.2).
7


--- Page 8 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
Table 2: Accuracy of equivalence-checking methods on formulations obtained from equivalent and non-equivalent transformations.
Canonical Acc.
Execution Acc.
WL-test
naive-LLM
EquivaMap
Equivalent Transformations
Worst Case
0%
0%
0%
3.3%
100%
Substitute Objective Functions
0%
100%
0%
91.2%
100%
Add Slack Variables
0%
100%
0%
36.1%
100%
Replace by Base-10 Representation
0%
100%
0%
53.1%
100%
Add Valid Inequalities
0%
100%
0%
3.3%
100%
Rescaling
0%
0%
0%
69.9%
100%
Replace by Linear Combinations
0%
100%
0%
24.4%
100%
Non-Equivalent Transformations
Worst Case
100%
0%
100%
93.6%
100%
Random Order
100%
100%
100%
98.7%
100%
Loose Constraints
100%
100%
100%
93.6%
100%
Feasibility
100%
0%
100%
100%
100%
4.1
EquivaFormulation: a dataset of equivalent MILP formulations
We construct EquivaFormulation based on the NLP4LP dataset [2]. NLP4LP comprises a diverse set of optimization
problems with distinct problem sizes, objective functions, and constraints. Each instance in NLP4LP is composed
of three components: (1) A description file with a high-level description of the problem in natural language. (2) An
information file which contains the corresponding mathematical formulation of the optimization instance, written in
LaTeX. (3) A file that contains the GurobiPy code corresponding to the mathematical formulation.
As discussed in Section 3.2, we carefully select optimization problems in the NLP4LP dataset by removing the infeasible
and unbounded instances. In EquivaFormulation, we introduce seven (Quasi-Karp) equivalent transformations and three
non-equivalent transformations to transform the formulations in NLP4LP to corresponding (Quasi-Karp) equivalent
and nonequivalent counterparts, respectively (Table 1). Our proposed equivalent transformations capture widely used
and important modeling techniques in MILPs. Standard practices such as substituting the objective function, adding
slack variables, and decomposing variables into positive and negative components help simplify constraints and enforce
non-negativity. Additionally, robustness to rescaling is crucial, as quantities can be represented in different units (e.g., 1
kg rather than 1000 g). Similarly, certain structural transformations — such as adding valid inequalities, reformulating
constraints, or introducing auxiliary variables — are commonly employed to enhance solver efficiency and tighten
relaxations while preserving the formulation’s optimal solution. Finally, we incorporate non-equivalent transformations
to evaluate the susceptibility of equivalence-checking methods to false positives. These selected transformations in
EquivaMap are designed to test the robustness of different equivalence-checking methods in handling diverse MILP
formulations.
Since the selected transformations in EquivaFormulation are deterministic, to prevent the mapping finder or other
equivalence-matching methods from exploiting shortcuts—such as mapping decision variables based on their order
(e.g., if variable names are assigned alphabetically)—we apply several transformations to the formulation before
processing. Specifically, we randomly permute the order of problem parameters, decision variables, and constraints
in the information file. Additionally, we assign distinct names to all decision variables and use GPT-4o to generate
varied natural language descriptions for them. These transformations are implemented to reduce the similarity between
formulation α and α′, ensuring that LLMs cannot exploit recognizable transformation patterns to deduce the mapping
directly.
4.2
Performance
We use GPT-4 [1] as the mapping finder in EquivaMap, and evaluate our method against existing baselines, plus a
naive LLM baseline (naive-LLM). The naive-LLM baseline uses a prompt that includes two formulations α and α′
and directly checks if they are equivalent. The prompt can be found in Appendix A. We set K = 3, and report the
accuracy as the percentage of paired formulations α and α′ that are correctly identified as equivalent or nonequivalent,
and summarize the results in Table 2.
8


--- Page 9 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
The results demonstrate that our method consistently outperforms all baseline approaches, achieving perfect or near-
perfect accuracy in almost every scenario. Notably, EquivaMap performs perfectly even in cases where all baseline
approaches completely fail.
For the equivalent transformations (Table 3), our method performs exceptionally well under challenging transformations,
such as Add Valid Inequalities, Rescaling, and Replace by Linear Combinations. Execution accuracy and the WL-test
fail universally in these settings, achieving 0% accuracy across all variations. In contrast, EquivaMap achieves 100%
accuracy. These transformations are critical test cases because they highlight the fundamental weaknesses of existing
approaches: they struggle with capturing key modeling techniques such as cutting planes and variable rescaling. For
example, execution accuracy fails at Rescaling, since a naive solver run does not recognize scaled problem instances as
equivalent, while WL-test fails at Add Valid Inequalities or Replace by Linear Combinations since these transformations
break isomorphisms in the graph representation. Our method reliably handles them, achieving near-perfect accuracy.
The results for non-equivalent variations further highlight the reliability of our method. For the Feasibility transformation,
execution accuracy fails with 0% accuracy, yet our method achieves perfect accuracy for all instances. Under other
non-equivalent settings, our method also works well, achieving 100% accuracy.
We additionally perform a runtime analysis comparing EquivaMap with baseline methods such as Execution Accuracy
and the WL-test. The results, which show that EquivaMap operates within seconds, are presented in Appendix D.
Key observations.
EquivaMap outperforms all existing equivalence-checking methods, including the naive-LLM
baseline. This highlights the necessity of our algorithm — without the explicit map finding and optimality verification
steps, naively using LLMs with strong reasoning capabilities will not ensure reliability in checking formulation
equivalence. Moreover, these results demonstrate that our method is reliable across diverse transformations. It
consistently outperforms all baselines, especially in scenarios where execution accuracy and other methods fail.
5
Discussion
How can we define the equivalence of two formulations of the same optimization problem instance? In this paper, we
address this conceptual gap by proposing Quasi-Karp equivalence and a framework, EquivaMap, to systematically check
such equivalence. Through extensive experiments on MILP problems, we demonstrate that EquivaMap outperforms
existing approaches by large. Additionally, by introducing the first well-documented pool of equivalent optimization
formulations, encompassing diverse transformations such as the addition of cutting planes, we provide a valuable
dataset for advancing research in this domain.
Beyond examining whether two formulations represent the same problem instance, a promising direction for future
research is to leverage EquivaMap to check equivalences across diverse optimization problems, such as the equivalence
between max-flow and min-cut problems. It is also worth noting that our current work focuses on relatively straight-
forward transformations, thereby omitting more intricate reformulations such as those emerging from decomposition
algorithms. As more complex optimization copilots are developed, we may need equivalence-checking tools that can
tackle these more complex transformations.
References
[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo
Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. GPT-4 technical report. arXiv preprint
arXiv:2303.08774, 2023.
[2] Ali AhmadiTeshnizi, Wenzhi Gao, and Madeleine Udell. Optimus: Scalable optimization modeling with (mi) lp
solvers and large language models. In Forty-first International Conference on Machine Learning, 2024.
[3] Tasnim Ahmed and Salimur Choudhury. Lm4opt: Unveiling the potential of large language models in formulating
mathematical optimization problems. INFOR: Information Systems and Operational Research, 62(4):559–572,
2024.
[4] Nicol´as Astorga, Tennison Liu, Yuanzhang Xiao, and Mihaela van der Schaar. Autoformulation of mathematical
optimization models using llms. arXiv preprint arXiv:2411.01679, 2024.
[5] Hao Chen, Gonzalo E Constante-Flores, and Can Li. Diagnosing infeasible optimization problems using large
language models. arXiv preprint arXiv:2308.12923, 2023.
[6] Ziang Chen, Jialin Liu, Xinshang Wang, and Wotao Yin. On representing linear programs by graph neural
networks. In The Eleventh International Conference on Learning Representations, 2023a.
9


--- Page 10 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
[7] Ziang Chen, Jialin Liu, Xinshang Wang, and Wotao Yin. On representing mixed-integer linear programs by graph
neural networks. In The Eleventh International Conference on Learning Representations, 2023b.
[8] Michele Conforti, Gerard Cornuejols, and Giacomo Zambelli. Integer programming. Springer, 2014.
[9] Stephen A Cook. The complexity of theorem-proving procedures. In Proceedings of the third annual ACM
symposium on Theory of computing, pages 151–158, 1971.
[10] William J Cook, David L Applegate, Robert E Bixby, and Vasek Chvatal. The traveling salesman problem: a
computational study. Princeton university press, 2011.
[11] Brendan L Douglas.
The weisfeiler-lehman method and graph isomorphism testing.
arXiv preprint
arXiv:1101.5211, 2011.
[12] Thomas Elsken, Jan Hendrik Metzen, and Frank Hutter. Neural architecture search: A survey. Journal of Machine
Learning Research, 20(55):1–21, 2019.
[13] Jianxin Fang, Brenda Cheang, and Andrew Lim. Problems and solution methods of machine scheduling in
semiconductor manufacturing operations: A survey. Sustainability, 15(17):13012, 2023.
[14] Maxime Gasse, Didier Ch´etelat, Nicola Ferroni, Laurent Charlin, and Andrea Lodi.
Exact combinatorial
optimization with graph convolutional neural networks. Advances in neural information processing systems, 32,
2019.
[15] Sen Huang, Kaixiang Yang, Sheng Qi, and Rui Wang. When large language model meets optimization. arXiv
preprint arXiv:2405.10098, 2024.
[16] Xuhan Huang, Qingning Shen, Yan Hu, Anningzhe Gao, and Benyou Wang. Mamo: a mathematical modeling
benchmark with solvers. arXiv preprint arXiv:2405.13144, 2024.
[17] Serdar Kadıo˘glu, Parag Pravin Dakle, Karthik Uppuluri, Regina Politi, Preethi Raghavan, SaiKrishna Rallabandi,
and Ravisutha Srinivasamurthy. Ner4opt: named entity recognition for optimization modelling from natural
language. Constraints, 29(3):261–299, 2024.
[18] AHG Rinnooy Kan. The complexity of the network design problem. Networks, 8(4):279–285, 1978.
[19] Richard M. Karp. Reducibility among combinatorial problems. In Complexity of Computer Computations, pages
85–103. Plenum Press, 1972.
[20] Krishna Khadka, Jaganmohan Chandrasekaran, Yu Lei, Raghu N Kacker, and D Richard Kuhn. A combinatorial
approach to hyperparameter optimization. In Proceedings of the IEEE/ACM 3rd International Conference on AI
Engineering-Software Engineering for AI, pages 140–149, 2024.
[21] Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning combinatorial optimization
algorithms over graphs. Advances in neural information processing systems, 30, 2017.
[22] Bernhard Korte and Jens Vygen. Shortest paths. Combinatorial Optimization: Theory and Algorithms, pages
157–171, 2012.
[23] Connor Lawless, Yingxi Li, Anders Wikum, Madeleine Udell, and Ellen Vitercik. Llms for cold-start cutting
plane separator configuration. arXiv preprint arXiv:2412.12038, 2024.
[24] Connor Lawless, Jakob Schoeffer, Lindy Le, Kael Rowan, Shilad Sen, Cristina St. Hill, Jina Suh, and Bahareh
Sarrafzadeh. “i want it that way”: Enabling interactive decision support using large language models and constraint
programming. ACM Transactions on Interactive Intelligent Systems, 14(3):1–33, 2024.
[25] Beibin Li, Konstantina Mellou, Bo Zhang, Jeevan Pathuri, and Ishai Menache. Large language models for supply
chain optimization. arXiv preprint arXiv:2307.03875, 2023.
[26] Qingyang Li, Lele Zhang, and Vicky Mak-Hau. Synthesizing mixed-integer linear programming models from
natural language descriptions. arXiv preprint arXiv:2311.15271, 2023.
[27] Mahdi Mostajabdaveh, Timothy T Yu, Rindranirina Ramamonjison, Giuseppe Carenini, Zirui Zhou, and Yong
Zhang. Optimization modeling and verification from problem specifications using a multi-agent multi-stage llm
framework. INFOR: Information Systems and Operational Research, 62(4):599–617, 2024.
[28] Christos H Papadimitriou and Kenneth Steiglitz. Combinatorial optimization: algorithms and complexity. Courier
Corporation, 1998.
[29] David Pisinger and Paolo Toth. Knapsack problems. Springer, 1998.
[30] Rindranirina Ramamonjison, Timothy Yu, Raymond Li, Haley Li, Giuseppe Carenini, Bissan Ghaddar, Shiqi
He, Mahdi Mostajabdaveh, Amin Banitalebi-Dehkordi, Zirui Zhou, et al. Nl4opt competition: Formulating
optimization problems based on their natural language descriptions. In NeurIPS 2022 Competition Track, pages
189–203. PMLR, 2023.
10


--- Page 11 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
[31] A. Schrijver. Min-Max Results in Combinatorial Optimization, pages 439–500. Springer Berlin Heidelberg,
Berlin, Heidelberg, 1983.
[32] Zachary Steever, Chase Murray, Junsong Yuan, Mark Karwan, and Marco L¨ubbecke. An image-based approach
to detecting structural similarity among mixed integer programs. INFORMS Journal on Computing, 34(4):
1849–1870, 2022.
[33] Zhengyang Tang, Chenyu Huang, Xin Zheng, Shixi Hu, Zizhuo Wang, Dongdong Ge, and Benyou Wang. Orlm:
Training large language models for optimization modeling. arXiv preprint arXiv:2405.17743, 2024.
[34] Zhuohan Wang, Ziwei Zhu, Yizhou Han, Yufeng Lin, Zhihang Lin, Ruoyu Sun, and Tian Ding. Optibench:
Benchmarking large language models in optimization modeling with equivalence-detection evaluation. 2024.
[35] Segev Wasserkrug, Leonard Boussioux, Dick den Hertog, Farzaneh Mirzazadeh, Ilker Birbil, Jannis Kurtz, and
Donato Maragno. From large language models and optimization to decision optimization copilot: A research
manifesto. arXiv preprint arXiv:2402.16269, 2024.
[36] Ziyang Xiao, Dongxiang Zhang, Yangjun Wu, Lilin Xu, Yuan Jessica Wang, Xiongwei Han, Xiaojin Fu, Tao
Zhong, Jia Zeng, Mingli Song, et al. Chain-of-experts: When llms meet complex operations research problems.
In The Twelfth International Conference on Learning Representations, 2023.
[37] Linzi Xing, Xinglu Wang, Yuxi Feng, Zhenan Fan, Jing Xiong, Zhijiang Guo, Xiaojin Fu, Rindra Ramamonjison,
Mahdi Mostajabdaveh, Xiongwei Han, et al. Towards human-aligned evaluation for linear programming word
problems. In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language
Resources and Evaluation (LREC-COLING 2024), pages 16550–16556, 2024.
[38] Zhicheng Yang, Yiwei Wang, Yinya Huang, Zhijiang Guo, Wei Shi, Xiongwei Han, Liang Feng, Linqi Song,
Xiaodan Liang, and Jing Tang. Optibench meets resocratic: Measure and improve llms for optimization modeling.
arXiv preprint arXiv:2407.09887, 2024.
[39] He Yu and Jing Liu. Deep insights into automated optimization with large language models and evolutionary
algorithms. arXiv preprint arXiv:2410.20848, 2024.
11


--- Page 12 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
A
Additional Experimental Details and Results
In this section, we segment our main results by problem class (i.e., LP vs. MILP), and equivalence (i.e., equivalent vs.
nonequivalent). We also include the fraction of each instance solved correctly for each problem type. Our results are
consistent across both LP and MILP instances, highlighting that EquivaMap outperforms all baseline methods in all
settings.
Table 3: Accuracy of equivalence-checking methods on formulations obtained from equivalent transformations. Rows are
partitioned by whether the problems are linear programming problems (LP) or mixed-integer linear programming problems (MILP).
Numbers in parentheses correspond to the raw fraction of instances solved correctly.
Transformation
Canonical Acc.
Execution Acc.
WL-test
naive-LLM
EquivaMap
LP
Substitute Objective Functions
0%(0/92)
100%(92/92)
0%(0/92)
94.6%(87/92)
100%(92/92)
Add Slack Variables
0%(0/59)
100%(59/59)
0%(0/59)
49.1%(29/59)
100%(59/59)
Replace by Base-10 Representation
0%(0/44)
100%(44/44)
0%(0/44)
50%(22/44)
100%(44/44)
Add Valid Inequalities
0%(0/92)
100%(92/92)
0%(0/92)
6.5%(6/92)
100%(92/92)
Rescaling
0%(0/60)
0%(0/60)
0%(0/60)
76.7%(46/60)
100%(60/60)
Replace by Linear Combinations
0%(0/77)
100%(77/77)
0%(0/77)
13.0%(10/77)
100%(77/77)
MILP
Substitute Objective Functions
0%(0/140)
100%(140/140)
0%(0/140)
87.9%(123/140)
100%(140/140)
Add Slack Variables
0%(0/134)
100%(134/134)
0%(0/134)
23.1%(31/134)
100%(134/134)
Replace by Base-10 Representation
0%(0/123)
100%(123/123)
0%(0/123)
56.1%(69/123)
100%(123/123)
Add Valid Inequalities
0%(0/142)
100%(142/142)
0%(0/142)
0%(0/142)
100%(142/142)
Rescaling
0%(0/133)
0%(0/133)
0%(0/133)
63.2%(84/133)
100%(133/133)
Replace by Linear Combinations
0%(0/115)
100%(115/115)
0%(0/115)
35.7%(41/115)
100%(115/115)
Table 4: Accuracy of equivalence-checking methods on formulations obtained from nonequivalent transformations. Rows are
partitioned by whether the problems are linear programming problems (LP) or mixed-integer linear programming problems (MILP).
Numbers in parentheses correspond to the raw fraction of instances solved correctly.
Transformation
Canonical Acc.
Execution Acc.
WL-test
naive-LLM
EquivaMap
LP
Random Order
100%(87/87)
100%(87/87)
100%(87/87)
98.9%(86/87)
100%(87/87)
Loose Constraints
100%(53/53)
100%(53/53)
100%(53/53)
88.7%(47/53)
100%(53/53)
Feasibility
100%(87/87)
0%(0/87)
100%(87/87)
100%(87/87)
100%(87/87)
MILP
Random Order
100%(142/142)
100%(142/142)
100%(142/142)
98.6%(140/142)
100%(142/142)
Loose Constraints
100%(120/120)
100%(120/120)
100%(120/120)
96.7%(116/120)
100%(120/120)
Feasibility
100%(142/142)
0%(0/142)
100%(142/142)
100%(142/142)
100%(142/142)
B
Prompts
B.1
naive-LLM Prompt
Listing 1: naive-LLM Prompt
You are given two
optimization
problem
formulations (both
declared as MIP).
Decide if they are
equivalent
formulations.
First
problem
formulation (Problem A):
{
" parametrized_description ": "A laundromat
can buy two types of washing
machines ,
a top -loading
model and a front -loading
model. The top -loading
model can
wash
WashRateTopLoading
items per day while the front -loading
model can wash
WashRateFrontLoading
items per day. The top -loading
model
consumes
12


--- Page 13 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
EnergyConsumptionTopLoading
kWh per day while the front -loading
model
consumes
EnergyConsumptionFrontLoading
kWh per day. The
laundromat
must be
able to wash at least
MinItemsPerDay
items per day and has
available
MaxEnergyPerDay
kWh per day. Since the top -loading
machines
are harder to use
, at most
MaxFractionTopLoading
of the
machines
can be top -loading. Further ,
at least
MinNumFrontLoading
machines
should be front -loading. How many of
each
machine
should the
laundromat
buy to minimize
the total
number of
washing
machines?",
"keywords": [
"N.A."
],
"parameters": {
" WashRateTopLoading ": {
"description": "Number of items
washed per day by a top -loading
machine",
"shape": []
},
" WashRateFrontLoading ": {
"description": "Number of items
washed per day by a front -loading
machine",
"shape": []
},
" EnergyConsumptionTopLoading ": {
"description": "Energy
consumed
per day by a top -loading
machine (kWh)",
"shape": []
},
" EnergyConsumptionFrontLoading ": {
"description": "Energy
consumed
per day by a front -loading
machine (kWh)",
"shape": []
},
" MinItemsPerDay ": {
"description": "Minimum
number of items to wash per day",
"shape": []
},
" MaxEnergyPerDay ": {
"description": "Maximum
available
energy per day (kWh)",
"shape": []
},
" MaxFractionTopLoading ": {
"description": "Maximum
fraction of machines
that can be top -loading",
"shape": []
},
" MinNumFrontLoading ": {
"description": "Minimum
number of front -loading
machines",
"shape": []
}
},
"variables": {
" NumTopLoading": {
"description": "The number of top -loading
machines",
"type": "continuous",
"shape": []
},
" NumFrontLoading ": {
"description": "The number of front -loading
machines",
"type": "continuous",
"shape": []
}
},
"constraints": [
{
"description": "A top -loading
machine
washes
WashRateTopLoading
items per
day and a front -loading
machine
washes
WashRateFrontLoading
items per day
. The total
number of items
washed per day must be at least
MinItemsPerDay.",
"formulation": " WashRateTopLoading \\ cdot
NumTopLoading +
WashRateFrontLoading
\\ cdot
NumFrontLoading \\geq
MinItemsPerDay ",
13


--- Page 14 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
"code": {
"gurobipy": "model.addConstr( WashRateTopLoading * NumTopLoading +
WashRateFrontLoading * NumFrontLoading
>= MinItemsPerDay )"
}
},
{
"description": "A top -loading
machine
consumes
EnergyConsumptionTopLoading
kWh per day and a front -loading
machine
consumes
EnergyConsumptionFrontLoading
kWh per day. The total
energy
consumption
per day cannot
exceed
MaxEnergyPerDay
kWh.",
"formulation": "NumTopLoading \\ times
EnergyConsumptionTopLoading +
NumFrontLoading \\ times
EnergyConsumptionFrontLoading
\\leq
MaxEnergyPerDay ",
"code": {
"gurobipy": "model.addConstr( EnergyConsumptionTopLoading * NumTopLoading +
EnergyConsumptionFrontLoading * NumFrontLoading
<= MaxEnergyPerDay )"
}
},
{
"description": "At most
MaxFractionTopLoading
fraction of the total
machines
can be top -loading.",
"formulation": "NumTopLoading \\leq
MaxFractionTopLoading
\\ times (
NumTopLoading + NumFrontLoading )",
"code": {
"gurobipy": "model.addConstr( NumTopLoading
<= MaxFractionTopLoading * (
NumTopLoading + NumFrontLoading ))"
}
},
{
"description": "At least
MinNumFrontLoading
machines
must be front -loading."
,
"formulation": " NumFrontLoading \\geq
MinNumFrontLoading ",
"code": {
"gurobipy": "model.addConstr( NumFrontLoading
>= MinNumFrontLoading )"
}
}
],
"objective": {
"description": "Minimize
the total
number of washing
machines
purchased.",
"formulation": "Min \\ NumTopLoading + NumFrontLoading ",
"code": {
"gurobipy": "model.setObjective ( NumTopLoading + NumFrontLoading , GRB.
MINIMIZE)"
}
}
}
Second
problem
formulation (Problem B):
{
" parametrized_description ": "A laundromat
can buy two types of washing
machines ,
a top -loading
model and a front -loading
model. The top -loading
model can
wash V items per day while the front -loading
model can wash T items per day.
The top -loading
model
consumes F kWh per day while the front -loading
model
consumes A kWh per day. The
laundromat
must be able to wash at least J items
per day and has
available R kWh per day. Since the top -loading
machines
are
harder to use , at most S of the
machines
can be top -loading. Further , at
least W machines
should be front -loading. How many of each
machine
should the
laundromat
buy to minimize
the total
number of washing
machines?",
"keywords": [
"N.A."
],
"parameters": {
"W": {
"description": "The
smallest
quantity of front -loading
machines.",
"shape": []
14


--- Page 15 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
},
"A": {
"description": "Daily
electricity
usage of a front -loading
washer (kWh)",
"shape": []
},
"R": {
"description": "The
highest
amount of energy
that can be obtained in a
single day (kWh).",
"shape": []
},
"S": {
"description": "The
highest
percentage of machines
that can have a top -
loading
feature.",
"shape": []
},
"F": {
"description": "Daily
energy
usage of a top -loading
washing
machine in
kilowatt -hours",
"shape": []
},
"J": {
"description": "The
smallest
quantity of items
that need to be cleaned on a
daily
basis",
"shape": []
},
"V": {
"description": "Quantity of objects
cleaned
daily
using a top -loading
washer
",
"shape": []
},
"T": {
"description": "The
quantity of objects
cleaned
daily
with a front -loading
washing
machine.",
"shape": []
}
},
"variables": {
"a": {
"description": "The
quantity of top -loading
appliances",
"type": "continuous",
"shape": []
},
"g": {
"description": "The
quantity of front -loading
machines",
"type": "continuous",
"shape": []
}
},
"constraints": [
{
"description": "A top -loading
washer
cleans V items daily , while a front -
loading
washer
cleans T items
daily. The
combined
total of items
cleaned
each day should not fall
below J.",
"formulation": "J \\leq V \\ cdot a + T \\ cdot g",
"code": {
"gurobipy": "model.addConstr(V * a + T * g >= J)"
}
}
],
"objective": {
"description": "Reduce the
overall
quantity of washing
machines
bought.",
"formulation": "Min \\ g + a",
"code": {
"gurobipy": "model.setObjective (a + g, GRB.MINIMIZE)"
}
15


--- Page 16 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
}
}
Based on the data , please
respond
with
exactly
one of the
following:
- "Equivalent" if these two are the same
formulation. Be rigorous in your
reasoning.
- "Not
Equivalent" if they are
different. When you are not sure , say "Not
Equivalent".
Briefly
explain
the
reasoning in 1-2 sentences , then end with the word "Equivalent
" or "Not
Equivalent" on its own line.
B.1.1
EquivaMap Prompt
Listing 2: EquivaMap Prompt
You are an AI language
model
assisting in mapping
variables
between
two
optimization
problems by analyzing
their
roles in constraints
and the
objective
function.
** Variable
from
Problem
1:**
- ** Name :**
OdorRemovingChemicalUnits
- ** Description :** The number of units of odor -removing
chemical
used per house
- ** Constraints
involving
OdorRemovingChemicalUnits :**
- Description: The total
number of chemical
units
used per house
cannot
exceed
MaxTotalUnits.
Formulation: CleansingChemicalUnits + OdorRemovingChemicalUnits \leq
MaxTotalUnits
- Description: The number of cleansing
chemical
units
used
cannot
exceed
MaxCleansingToOdorRatio
times the number of odor -removing
chemical
units
used
.
Formulation: CleansingChemicalUnits \leq
MaxCleansingToOdorRatio \cdot
OdorRemovingChemicalUnits
- **In Objective
Function :** Yes
** Variables
from
Problem
2:**
- ** Name :** v_0
** Description :** Digit 0 of the The
quantity of cleaning
solution
units
utilized
per
household
** Constraints
involving
v_0 :**
- Description: The
quantity of cleansing
chemical
units
applied
must not
surpass H times the
quantity of odor -removing
chemical
units
used.
Formulation: H \cdot (f_0 *10^0 + f_1 *10^1) \geq (v_0 *10^0 + v_1 *10^1 + v_2
*10^2)
- Description: The
cumulative
quantity of chemical
components
utilized
for
each
residence
must not
surpass T.
Formulation: T \geq (f_0 *10^0 + f_1 *10^1) + (v_0 *10^0 + v_1 *10^1 + v_2 *10^2)
- Description: The
company is required to utilize a minimum of G units of the
cleaning
solution
per
household.
Formulation: G \leq (v_0 *10^0 + v_1 *10^1 + v_2 *10^2)
**In Objective
Function :** Yes
- ** Name :** v_1
** Description :** Digit 1 of the The
quantity of cleaning
solution
units
utilized
per
household
** Constraints
involving
v_1 :**
- Description: The
quantity of cleansing
chemical
units
applied
must not
surpass H times the
quantity of odor -removing
chemical
units
used.
Formulation: H \cdot (f_0 *10^0 + f_1 *10^1) \geq (v_0 *10^0 + v_1 *10^1 + v_2
*10^2)
- Description: The
cumulative
quantity of chemical
components
utilized
for
each
residence
must not
surpass T.
Formulation: T \geq (f_0 *10^0 + f_1 *10^1) + (v_0 *10^0 + v_1 *10^1 + v_2 *10^2)
16


--- Page 17 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
- Description: The
company is required to utilize a minimum of G units of the
cleaning
solution
per
household.
Formulation: G \leq (v_0 *10^0 + v_1 *10^1 + v_2 *10^2)
**In Objective
Function :** Yes
- ** Name :** v_2
** Description :** Digit 2 of the The
quantity of cleaning
solution
units
utilized
per
household
** Constraints
involving
v_2 :**
- Description: The
quantity of cleansing
chemical
units
applied
must not
surpass H times the
quantity of odor -removing
chemical
units
used.
Formulation: H \cdot (f_0 *10^0 + f_1 *10^1) \geq (v_0 *10^0 + v_1 *10^1 + v_2
*10^2)
- Description: The
cumulative
quantity of chemical
components
utilized
for
each
residence
must not
surpass T.
Formulation: T \geq (f_0 *10^0 + f_1 *10^1) + (v_0 *10^0 + v_1 *10^1 + v_2 *10^2)
- Description: The
company is required to utilize a minimum of G units of the
cleaning
solution
per
household.
Formulation: G \leq (v_0 *10^0 + v_1 *10^1 + v_2 *10^2)
**In Objective
Function :** Yes
- ** Name :** f_0
** Description :** Digit 0 of the The
quantity of odor - neutralizing
chemical
applied in each
household
** Constraints
involving
f_0 :**
- Description: The
quantity of cleansing
chemical
units
applied
must not
surpass H times the
quantity of odor -removing
chemical
units
used.
Formulation: H \cdot (f_0 *10^0 + f_1 *10^1) \geq (v_0 *10^0 + v_1 *10^1 + v_2
*10^2)
- Description: The
cumulative
quantity of chemical
components
utilized
for
each
residence
must not
surpass T.
Formulation: T \geq (f_0 *10^0 + f_1 *10^1) + (v_0 *10^0 + v_1 *10^1 + v_2 *10^2)
**In Objective
Function :** Yes
- ** Name :** f_1
** Description :** Digit 1 of the The
quantity of odor - neutralizing
chemical
applied in each
household
** Constraints
involving
f_1 :**
- Description: The
quantity of cleansing
chemical
units
applied
must not
surpass H times the
quantity of odor -removing
chemical
units
used.
Formulation: H \cdot (f_0 *10^0 + f_1 *10^1) \geq (v_0 *10^0 + v_1 *10^1 + v_2
*10^2)
- Description: The
cumulative
quantity of chemical
components
utilized
for
each
residence
must not
surpass T.
Formulation: T \geq (f_0 *10^0 + f_1 *10^1) + (v_0 *10^0 + v_1 *10^1 + v_2 *10^2)
**In Objective
Function :** Yes
Based on the above
information , find the best
mapping
from
variables in Problem 2
for the
variable ’OdorRemovingChemicalUnits ’ from
Problem 1. The
mapping
can be
a linear
combination of variables
from
Problem 2, possibly
with
constant
multipliers. Your goal is to express ’OdorRemovingChemicalUnits ’ in terms of
variables
from
Problem 2, as accurately as possible , based on their
roles in
the
constraints
and
objective
functions.
** Important
Instructions :**
- ** Provide
only the
mapping
for ’OdorRemovingChemicalUnits ’ as a JSON
object .**
- **Do not
include
any
additional text , explanations , or formatting .**
- **The JSON
object
must
follow
this
exact
structure :**
{
" OdorRemovingChemicalUnits ": [
{
"constant": constant_value_1 ,
17


--- Page 18 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
"variable": " variable_name_1 "
},
{
"constant": constant_value_2 ,
"variable": " variable_name_2 "
},
...
]
}
- **If there is only one term in the mapping , the list
should
contain a single
object .**
- **Use
numerical
values for
constants (decimals), and
enclose
variable
names in
double
quotes ("").**
** Examples :**
1. If the best
mapping is ’0.1*a’, your
response
should be:
{
" OdorRemovingChemicalUnits ": [
{
"constant": 0.1,
"variable": "a"
}
]
}
2. If the best
mapping is ’0.1*a + 0.01*b’, your
response
should be:
{
" OdorRemovingChemicalUnits ": [
{
"constant": 0.1,
"variable": "a"
},
{
"constant": 0.01,
"variable": "b"
}
]
}
3. If the best
mapping is a single
variable ’a’ with a coefficient of 1, your
response
should be:
{
" OdorRemovingChemicalUnits ": [
{
"constant": 1,
"variable": "a"
}
]
}
4. If there is no direct
mapping , your
response
should be:
{
" OdorRemovingChemicalUnits ": [
{
"constant": "none",
"variable": "none"
}
]
}
18


--- Page 19 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
Please
ensure
your
response is a valid
JSON
object
that can be parsed by standard
JSON
parsers.
19


--- Page 20 ---
EquivaMap: Leveraging LLMs for Automatic Equivalence Checking of Optimization Formulations
C
Maximum Independent Set example
Figure 3: Comparison between set-based and individual-variable representations in JSON input formatting. EquivaMap
operates on sets of variables, allowing the metadata and constraints to be described concisely (left) instead of expanding
each variable individually, resulting in longer and more redundant prompts (right).
Consider the maximum independent set example in Figure 3. EquivaMap takes in set-based representations of input
formulations (left). When the prompt iterates between variables of formulations α and α′, it processes the entire ’Node’
set as input, rather than individual variables like Node 1, Node 2, etc. If variables in formulation alpha′ are labeled as
Node’, the mapping discovered by the LLM will be Node[i] = Node′[i], ∀i, instead of separate mappings for each
indexed variable. This distinction is crucial for scalability, as it means our prompt size remains constant regardless of
the number of nodes in the graph.
D
Runtime Analysis
To evaluate the computational overhead of EquivaMap and the baseline methods, we measured the average runtime
across all instances in our dataset. The breakdown of time spent on different components is presented in Table 5.
Table 5: Mean (± std. dev.) runtime (seconds) per instance for different components of EquivaMap and baselines. Runtime is
averaged across all instances in the EquivaFormulation dataset.
Method
Solving Time
LLM Call Time
WL-Test Time
Total
Execution Accuracy
0.12 ± 0.02
-
-
0.12 ± 0.02
WL-Test
-
-
0.38 ± 0.07
0.38 ± 0.07
EquivaMap
0.12 ± 0.02
11.88 ± 4.48
-
12.00 ± 4.50
While EquivaMap exhibits a higher total runtime compared to the baselines, this cost should be considered in light of
its significantly improved accuracy and its ability to identify complex mappings that other methods miss (as shown
in Section 4.2). The LLM interaction, though currently the bottleneck, enables a level of symbolic reasoning and
mapping discovery previously unattainable. It is also worth noting that this runtime is for a single equivalence check. In
practice, formulation equivalence checking is often an offline analysis task where a higher runtime can be tolerated
in exchange for reliable results. Furthermore, the LLM call time can potentially be reduced with more optimized
prompting strategies, the use of smaller fine-tuned models, or by leveraging future advancements in LLM efficiency.
Additionally, as discussed in Section 3.3, EquivaMap’s prompt length scales with the number of sets of variables rather
than individual variables, which helps manage the LLM interaction cost for larger, structured problems.
20
