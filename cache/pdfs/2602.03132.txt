--- Page 1 ---
Contrastive Concept-Tree Search for LLM-Assisted Algorithm Discovery
Timothee Leleu * 1 2 Sudeera Gunathilaka 3 Federico Ghimenti 2 Surya Ganguli 2
Abstract
Large language Model (LLM)-assisted algorithm
discovery is an iterative, black-box optimization
process over programs to approximatively solve
a target task, where an LLM proposes candidate
programs and an external evaluator provides task
feedback. Despite intense recent research on the
topic and promising results, how can the LLM
internal representation of the space of possible
programs be maximally exploited to improve per-
formance is an open question. Here, we intro-
duce Contrastive Concept-Tree Search (CCTS),
which extracts a hierarchical concept representa-
tion from the generated programs and learns a
contrastive concept model that guides parent se-
lection. By reweighting parents using a likelihood-
ratio score between high- and low-performing so-
lutions, CCTS biases search toward useful con-
cept combinations and away from misleading
ones, providing guidance through an explicit con-
cept hierarchy rather than the algorithm lineage
constructed by the LLM. We show that CCTS im-
proves search efficiency over fitness-based base-
lines and produces interpretable, task-specific con-
cept trees across a benchmark of open Erd˝os-type
combinatorics problems. Our analysis indicates
that the gains are driven largely by learning which
concepts to avoid. We further validate these find-
ings in a controlled synthetic algorithm-discovery
environment, which reproduces qualitatively the
search dynamics observed with the LLMs.
1. Introduction
Recent advances in large language models (LLMs) have en-
abled a new class of algorithm-discovery systems in which
program synthesis is embedded in an iterative black-box
optimization loop: candidate programs are proposed by an
1NTT Research, Sunnyvale, CA, USA
2Stanford Uni-
versity,
Palo Alto,
USA
3AIST, Tsukuba,
Japan.
Cor-
respondence
to:
Timothee
Leleu
<timothee.leleu@ntt-
research.com,tleleu@stanford.edu>.
Preprint. February 4, 2026.
LLM, evaluated by an external objective function, and re-
fined over successive rounds. Such an iterative refinement
is often framed as an evolutionary process over the space
of possible programs, with the LLM acting as a mutation
operator and the programs’ performance playing the role of
a fitness function (Lehman et al., 2024). Recent applications
of this paradigm have led to the rediscovery or improvement
of solutions to Erd˝os-style problems in combinatorics and
related areas (Novikov et al., 2025; Georgiev et al., 2025),
and have produced heuristics that compete with highly en-
gineered human designs, including strong SAT-solver vari-
ants (Yu et al., 2025). Overall, these results suggests that
LLM-assisted discovery can generate novel, nontrivial al-
gorithms, but at the same time, assessing the originality
and impact of the solutions found is inherently challenging:
validation often requires substantial domain expertise and
collaborative effort, and it remains unclear to what extent
current successes reflect general algorithmic advances rather
than problem-specific improvements!(teorth/erdosproblems
Wiki, 2026). Nevertheless, it seems unlikely that current
approaches are maximally exploiting the structure of the
LLM’s representation of the program space, within which
the automated search takes place. Precisely because the
empirical picture is still evolving, this is a timely moment to
examine how LLM-assisted algorithm-discovery might be
structured to scale more reliably, and to understand which
search mechanisms are likely essential as these methods are
applied to harder and less well-understood problems.
Most existing LLM-assisted algorithm-discovery systems
rely on a fitness-driven evolutionary updates: parents are
selected based on their fitness on the target task and the iter-
ative search proceeds as a walk over the lineage of programs
ordered by performance. While effective in practice, this
strategy operates directly within the program space, which
remains weakly structured. Even when constrained by an
LLM, the algorithms produced do not admit a clear notion
of locality, smooth variation, or compositional structure that
can be exploited by the search, limiting optimization to
generic black-box heuristics. As a result, guidance comes
largely from raw fitness signals and the LLM’s implicit prior,
rather than from an explicit, learned understanding of which
semantic components of the algorithms are actually useful.
This is a key limitation for genuinely novel problems, where
prior knowledge may be insufficient and usefulness must
1
arXiv:2602.03132v1  [cs.LG]  3 Feb 2026


--- Page 2 ---
Contrastive Concept-Tree Search
instead be discovered by interacting with the task.
The key idea of this work is to make the latent structure of
the algorithm space explicit. We posit that algorithms can
be described in terms of an underlying semantic concept
space organized as a hierarchy, where each node represents
a concept and the edges encode refinement or specializa-
tion. Each concept contributes positively or negatively to
task performance, and strong algorithms arise from combin-
ing useful concepts while avoiding harmful ones. Such a
tree-structured organization is natural in scientific discov-
ery, which is mediated by shared concept hierarchies (e.g.,
the Mathematics Subject Classification or the American
Physical Society taxonomy).
Building on this hypothesis, we guide search using con-
trastive statistics that identify which concepts are associated
with high-performing algorithms. Instead of navigating pro-
gram space directly, we bias parent selection and semantic
edits toward empirically useful regions of the concept tree,
enabling a more structured and data-driven search.
To implement the ideas above, we introduce Contrastive
Concept-Tree Search (CCTS), a concept-guided algorithm-
discovery framework that learns which semantic concepts to
prioritize during search. CCTS uses a cross-entropy update
in concept space and a Tree-structured Parzen Estimator
(TPE) to contrast high- and low-performing algorithms, pro-
ducing a likelihood-ratio score that guides parent selection
and semantic edits toward concept combinations associated
with improvement (Fig. 1).
The paper is organized as follows. Sec. 2 reviews related
work on LLM-assisted algorithm discovery and evolution-
ary search. Sec. 3 introduces the general evolutionary al-
gorithm framework for algorithm discovery that underlies
many existing approaches. Sec. 4 then presents Contrastive
Concept-Tree Search in detail. Sec. 5 reports numerical
results and empirical comparisons. For clarity, the notation
used throughout this paper is summarized in App. A.1.
2. Related works
FunSearch (Romera-Paredes et al., 2024) is one of the first
widely recognized methods to reignite interest in evolution-
ary approaches to algorithm discovery by combining them
with pre-trained LLMs, using the model as a mutation op-
erator within an island-based search loop. Building on this
idea, AlphaEvolve (Novikov et al., 2025) generalizes the
framework into a more modular and robust system appli-
cable across domains, including mathematical discovery
(Georgiev et al., 2025) and, in particular, combinatorics.
More recent results on SAT solver design further show
that this paradigm can outperform highly optimized human-
engineered systems (Yu et al., 2025).
Parent selection
Child generation
& evaluation
Prompt engineering
Estimation of distribution
of concept utility
Algorithm Ancestry Tree
x0
x1
x2
x3
x4
b0
b0, b3, b6
b0, b1, b4
b0, b1, b2, b4
b0, b1, b4, b5
LLM generates:
step t = 1: x0 →x1,
t = 2: x0 →x2,
t = 3: x2 →x3, . . .
Feature extractor g
+ cross-entropy learning
Parent sampling
Feature (Concept) Tree
b0
b1
b2
b3
b4
b5
b6
LLM generates:
t = 1: x1 →b0, b3, b6,
t = 2: x2 →b0, b1, b4,
t = 3: x3 →b0, b1, b2, b4, . . .
Figure 1. (top) Overview of our algorithm-discovery loop: given a
task and evaluator, we repeatedly sample a parent program from
an archive, prompt the LLM to generate a mutated child, and
evaluate it. The child’s outcome updates both the prompt context
and a growing tree of semantic concepts, which then biases parent
selection in subsequent iterations. (bottom) Repeating this process
yields a phylogenetic program lineage (x0, x1, . . .) and an induced
concept tree (b0, b1, . . .). We fit concept utility models on high-
vs. low-performing programs via a cross-entropy update, and use
their likelihood ratio to guide parent sampling.
Several recent works extend the evolutionary algorithm-
discovery by modifying candidate generation or evaluation.
Hercules (Wu et al., 2025) extracts reusable abstractions
from strong heuristics and reinjects them into prompts,
LASR (Grayeli et al., 2024) abstracts semantic patterns
from high-performing programs to guide LLM-based mu-
tation, while ReEvo (Ye et al., 2024) uses LLM-generated
reflections over performance differences to guide subse-
quent mutations. Evolution of Heuristics (EoH) (Liu et al.,
2024) evolves both reasoning traces and executable code,
and HeurAgenix (Yang et al., 2025) adopts a two-stage
hyper-heuristic strategy that separates heuristic discovery
from selection. ThetaEvolve (Wang et al., 2025) further
augments an AlphaEvolve-style loop with test-time rein-
forcement learning to adapt the LLM’s generation policy
online.
Despite these variations, most LLM-assisted algorithm-
discovery systems are based on evolutionary algorithms
as the outer search loop, reflecting the highly irregular struc-
ture of program space. Programs are modified through
discrete mutations rather than smooth interpolation, selec-
tion is driven by fitness, and diversity is typically main-
tained via islands, niches(Hu & Zhang, 2025), or MAP-
Elites-style archives (Novikov et al., 2025; Mouret & Clune,
2015). Because algorithm space lacks a simple or well-
behaved structure, principled guided search methods such
as estimation-of-distribution approaches have remained rel-
atively underexplored.
2


--- Page 3 ---
Contrastive Concept-Tree Search
The algorithm-discovery setting considered here is related
to prompt-engineering methods, including evolutionary
prompt search (Guo et al., 2025), tree-based reasoning (Yao
et al., 2023), Bayesian optimization over prompts or rea-
soning traces (Schneider et al., 2024), and other black-box
prompt optimization techniques (Pryzant et al., 2023). A
key difference is that algorithm discovery typically assumes
a well-defined, externally computable evaluator, enabling
direct use of empirical performance signals. For simplicity,
we keep prompt engineering minimal and treat the LLM as
a black-box generator, focusing instead on principled parent
selection and search dynamics over algorithm space.
3. Problem Setup
We formalize here a general framework for algorithm dis-
covery that encompasses previous approaches and serves as
a foundation for our method, which is schematically sum-
marized by the diagram in Fig. 2.
3.1. Search spaces
We consider tasks defined by a formal problem specification
and a verifier or evaluator. Concretely, a task C is charac-
terized by (i) an external evaluation function E that takes
an algorithm x and returns a scalar score measuring perfor-
mance, and (ii) a natural-language description P0(C) that
specifies the objective, constraints, or rules of the problem
(e.g., a mathematical problem statement). The evaluator E
allows ground-truth comparison of candidate algorithms.
Candidate algorithms are represented as runnable programs
x ∈X, where X denotes the genotype (code) space, such
as source code, pseudocode, or structured algorithmic de-
scriptions. Programs are generated conditionally by a large
language model (LLM), which implicitly restricts search
to a learned subset W ⊂X corresponding to the LLM’s
internal representation of plausible algorithms.
Each program x is evaluated to produce a fitness value
y = E(x; C), and may also be mapped to a feature or phe-
notype representation b = Φ(x), which captures behavioral
or semantic properties of the algorithm. These features are
used for selection, diversity maintenance, or analysis, and
may themselves be extracted from the LLM, by directly
prompting it to generate a list of relevant concepts pertain-
ing to a generated program. The overall search dynamics are
further controlled by a set of hyperparameters θ, which gov-
ern aspects such as population size, selection policies, and
generation settings. The list of important hyperparameters
is summarized in App. Table 2.
The objective of algorithm discovery is to identify an algo-
rithm that maximizes performance on the task,
x⋆∈arg max
x∈X E(x; C),
(1)
using only black-box access to the evaluator and the condi-
tional generation capabilities of the LLM.
3.2. Evolutionary search loop
Algorithm discovery proceeds iteratively through an evo-
lutionary loop. At iteration t, the algorithm maintains an
archive At = {(xi, yi, bi)}Nt
i=1 containing previously evalu-
ated programs along with their fitness and features.
Parent selection is defined by a sampling distribution πt(· |
At) over subsets of the archive. Selected parents St ⊆At
are used to generate a new child program by conditioning
an LLM on both the parents and a prompt. Formally, letting
L denote the LLM, a child program xt+1 is sampled via
xt+1 ∼qL(· | Pt, St),
(2)
where Pt is a prompt constructed from the task description
and additional context and qL denotes LLM sampling.
The prompt is decomposed into a fixed task prompt P0(C)
and an adaptive context,
Pt = P0(C) ⊕Ctxt,
(3)
where Ctxt = g(At, St; L) summarizes information from
the current archive. This context may include descriptions of
recent improvements, differences between parent and child
programs, or feedback from failed evaluations. In practice,
such adaptive prompting encourages local refinement within
the LLM-induced program manifold.
Given the child, we evaluate its fitness and features as
yt+1 = E(xt+1; C),
bt+1 = Φ(xt+1),
(4)
and the archive is updated accordingly.
3.3. Parent selection policies
Parent selection plays a central role in shaping the search
dynamics. A general parent-selection policy is defined as a
probability distribution over subsets of the archive,
St ∼πt(· | At),
(5)
which may depend on fitness values, extracted features, or
other archive statistics.
In practice, parent selection is often implemented as a mix-
ture of simple strategies. In this paper, we use the following
strategies:
• Uniform selection: parents are sampled uniformly
over the archive (or current island), providing an explo-
ration baseline that is independent of fitness or features.
• Greedy selection: the highest-scoring algorithm in the
archive is selected as the parent, corresponding to pure
exploitation based on fitness.
3


--- Page 4 ---
Contrastive Concept-Tree Search
Parent sampler
St ∼πt(· | At)
Selection policy
πt
St ⊆At
Parents
LLM generator
xt+1 ∼qL(· | Pt, St)
Program
xt+1 ∈X
Evaluation & descriptors
yt+1 = E(xt+1)
bt+1 = Φ(xt+1)
Archive
At+1 = U(At, xt+1, yt+1, bt+1)
Context builder
Ctxt = g(At)
Prompt
Pt = P0 ⊕Ctxt
Elite selection
goodt = {i : yi ≥τt}
badt = {i : yi < τt}
Empirical feature distribution
q±
t (b) =
1
|good / badt|
P
i∈good / badt δ(b −bi)
Cross-entropy update
η±
t+1 = arg max
η
X
i∈good/badt
log pη(bi)
Feature model
pη±(b | good / badt)
Parent weighting
p(b|goodt)
p(b|badt)
Contrastive Concept Tree Search (CCTS)
Figure 2. Schematic of the LLM-assisted evolutionary search loop. The red blocks implement the parent selection process, the grey blocks
implement the child generation, and the green blocks describe the prompt update process. The blue blocks describe the main novelty
of this work: a contrastive exploration process in context space that is used to inform the parent generation process. Boxes containing
operators and objects are denoted by dark and light colors, respectively. The notation appearing in the blocks is defined in Sec. 3 and Sec.
4.
• k-elite selection (Zames, 1981): parents are sampled
uniformly from the top-k algorithms ranked by fitness,
interpolating between uniform exploration and greedy
exploitation.
• CCTS (this work): parents are sampled according to a
learned, feature-based weighting that exploits semantic
information extracted from programs; this strategy is
described in detail in the next section.
In this paper, we consider a two-component parent-selection
mixture that balances exploration via uniform sampling with
exploitation using one of the remaining strategies. Figure 3
illustrates the resulting exploration–exploitation trade-off.
0
1
Exploration
uniform random
Exploitation
Greedy
OR K-elites
OR CCTS
pexplore
pexploit
Figure 3. Schematic description of the stochastic parent-selection
policy mixing uniform exploration and exploitation. At each step,
a parent can be selected either uniformly from the archive, with
exploration probability pexplore (exploration), or it can be selected
according to a given performance-informed strategy with probabil-
ity pexploit = 1 −pexplore. Segment sizes are schematic.
4. Method: Contrastive Concept-Tree Search
CCTS augments the general evolutionary loop of Section 3
with an explicit semantic feature space and a lightweight
estimation-of-distribution model (Pugh et al., 2016) that
biases parent selection toward empirically useful regions of
that space. The key design choice is to learn guidance in
an interpretable concept space, which is then exploited to
select the programs to mutate.
4.1. Concept representation and concept tree
Each candidate program x is mapped to a semantic feature
representation b = Φ(x) extracted from the program by
a direct prompt to the LLM after the generation process.
In CCTS, b is a set of activated concepts organized in a
rooted concept tree. Concretely, let V denote the set of
concepts discovered so far. Each node v ∈V corresponds to
a semantic concept, and edges encode refinement relations:
a child concept v is a more specific version of its parent,
denoted by pa(v).
We represent the extracted concept set as an indicator vector
b = (bv)v∈V with bv ∈{0, 1}. Concept activations are
assumed to be ancestor-closed, bv = 1
⇒
bpa(v) = 1,
∀v ̸= root, so that activating a refined concept implies
activating all its ancestors. The concept tree is dynamic: as
the search proceeds, the feature extractor may introduce new
4


--- Page 5 ---
Contrastive Concept-Tree Search
concepts (new nodes) that are inserted into the hierarchy
(see Fig. 1). We say a concept is discovered once it appears
in Φ(x) for some evaluated program and is added to V .
4.2. Contrastive guided parent selection
CCTS learns which concepts are empirically associated with
improved performance in a contrastive manner, and uses
this information to bias parent selection (see Fig. 2). We
partition the archive of programs into good and bad subsets
using a threshold τt:
goodt = {i : yi ≥τt},
badt = {i : yi < τt}.
(6)
We then fit two probabilistic models over feature vectors,
one for each subset:
ˆpη+(b) ≈p(b | goodt),
ˆpη−(b) ≈p(b | badt),
(7)
within a shared parametric family {ˆpη}η∈Θ. Parameters are
estimated by a cross-entropy update (equivalently maximum
likelihood) on the corresponding subset:
η±
t+1 ∈arg max
η
X
i∈good/badt
log ˆpη(bi),
(8)
with standard smoothing and regularization for numerical
stability. Here, bi = Φ(xi) is the concept vector of algo-
rithm xi, and the sum is taken over the archive elements in
the good or bad partition.
We bias parent selection using the likelihood-ratio weight
w(bi) = ˆpη+(bi)
ˆpη−(bi),
πCCTS(xi | At) ∝w(bi).
(9)
This contrastive formulation emphasizes features that distin-
guish high- and low-performing programs.
Thus, the model operates entirely in feature space and guides
search by reallocating sampling probability toward existing
archive elements whose features are empirically associated
with improvement. In practice, we define paired empiri-
cal feature distributions over high- and low-performance
algorithms,
q+
t (b) ∝
X
i∈goodt
δ(b −bi),
q−
t (b) ∝
X
i∈badt
δ(b −bi),
(10)
which represent the empirical distributions of features ob-
served in the good and bad subsets of the archive.
In practice, the cross-entropy (CE) method (Rubinstein &
Kroese, 2004) is used to fit a parametric family {ˆpη(b)}
to each empirical distribution by minimizing the Kullback–
Leibler divergence between the empirical measure and the
model (see App. A.2 for details),
η±
t+1 = arg min
η
KL
 q±
t (b)
 ˆpη(b)

,
(11)
where the last expression corresponds to maximum likeli-
hood estimation on samples drawn from q+
t or q−
t respec-
tively. Guided parent selection of a parent with concept
vector b relies then on the log-likelihood ratio log(w(b)) =
log ˆpη+(b) −log ˆpη−(b), called log concept utility, to score
archive elements.
4.3. Hierarchical factorized and leaf-restricted model
In our main implementation, we instantiate the contrastive
feature model using a simple hierarchical, factorized dis-
tribution consistent with the concept-tree structure. This
factorized formulation is closely related to Tree-structured
Parzen Estimator (TPE)–style likelihood ratios over concept
configurations (Bergstra et al., 2011), and is computationally
efficient, interpretable at the level of individual concepts,
and sufficient to capture concept utility. Full details of the
model and estimators are provided in Appendix A.2. When
guiding child generation, we restrict explicit concept-level
interventions to leaf nodes of the current concept tree.
4.4. Exploration mechanism over new and rare concepts
To avoid premature convergence and to encourage discovery
of new or rarely explored concepts, we complement this
exploitation strategy with a lightweight concept-level explo-
ration mechanism operating directly on the concept tree. At
a high level, this mechanism ensures nonzero support for
newly discovered concepts, introduces a novelty bias favor-
ing underexplored concepts, and combines exploitation and
exploration through a simple mixture rule when selecting
concepts to emphasize during generation. Concept selection
is implemented at the prompt level by injecting the chosen
concept as a semantic directive for the LLM. Full details of
this exploration mechanism are provided in Appendix A.3.
This concept exploration mechanism is used regardless of
the parent sampling strategy for exploitation.
5. Experiments
To demonstrate the generality of the proposed method, we
apply our framework to a benchmark constructed for this
work and adapted from previous studies (Novikov et al.,
2025; Georgiev et al., 2025), consisting of several mathe-
matical problems drawn primarily from Erd˝os-style com-
binatorics, including the circle packing problem, the Arith-
metic Kakeya conjecture, Heilbronn’s triangle problem, and
square in square problem (see Appendix A.6 for details).
5.1. Ablating core components
We compare CCTS against standard parent-selection base-
lines defined in Section 3. The full setting (“CCTS”) uses
concept-guided parent selection together with concept ex-
ploration and LLM-based local mutation. As baselines, we
5


--- Page 6 ---
Contrastive Concept-Tree Search
consider Greedy, k-elites (k = 5), and Uniform parent se-
lection strategies (see Section 3). For methods that alternate
between exploitation and exploration (CCTS, Greedy, and
k-elites), the exploitation strategy is selected with probabil-
ity pexploit = 0.85 (see Fig. 3), and uniform sampling is used
otherwise. As shown in Fig. 4(a), CCTS achieves higher
scores for any fixed number of iterations, thus demonstrat-
ing the benefit of exploiting the structure of the concept
space.
To assess the robustness of CCTS’ edge over the baseline
methods, we compare the best score achieved by CCTS
over several runs against the one achieved through other
methods, across multiple mathematical tasks. Our results
are displayed in Fig. 5, and they demonstrate that CCTS
consistently achieves higher scores and faster improvement
than the baseline methods, despite substantial diversity in
problem structure and evaluation criteria.
5.2. Comparisons in synthetic algorithm discovery task
To analyze our results, we construct a synthetic algorithm-
discovery environment in which the LLM is replaced by a
simplified hand-crafted operator. This controlled setting al-
lows us to study the learning dynamics of CCTS in isolation
and to verify that the proposed approach yields computa-
tional advantages independent of language-model-specific
effects. In this synthetic model, a ground-truth (teacher)
concept tree is generated through a stochastic branching pro-
cess with base branching ratio λ0, and a latent ground-truth
utility, drawn from a Gaussian distribution, is assigned to
each concept. An algorithm is then identified by a set of
active concepts on the tree, and its quality is determined by
the sum of the utilities of its active concepts. Child gen-
eration replaces the LLM with a simple mutation operator
that performs local and global edits on the parent’s concepts,
guided by the teacher concept tree. See App. A.4 for de-
tails of the synthetic construction and operators. Beyond
validating the generality of our finding, this model enables
the formulation of testable hypotheses about how properties
of latent concept spaces influence the algorithm-discovery
dynamics.
Fig. 4 (b) shows the score achieved by the best algorithm
upon several iteration of the automatic search in the syn-
thetic environment, under ablations that are functionally
analogous to those performed in the experiments. The re-
sulting curves closely mirror those observed with the LLM-
based experiments, suggesting that the simple synthetic
model captures key qualitative aspects of the search dynam-
ics induced by LLM-assisted algorithm discovery.
Crucially, the synthetic model allows us to compare the
learned concept utilities to the synthetic ground truth. Fig. 6
shows strong agreement between the teacher and student
concept weights, indicating that CCTS recovers both the
structure and relative utility of latent concepts. This result
confirms that CCTS learns meaningful semantic representa-
tions that can effectively guide algorithm discovery.
5.3. Extracted concepts
We next analyze the semantic concepts extracted by the
LLM during search. The concept trees obtained for two
real tasks are shown in Fig. 6. The resulting concepts are
meaningfully related to the underlying problem, capturing
both core structural elements of circle packing and refined,
higher-level algorithmic strategies. Their hierarchical or-
ganization reflects increasing levels of specialization and
provides an interpretable representation of the semantic
structure explored during search. The growth in the number
of discovered and assigned concepts over iterations is shown
in App. Fig. 14.
What drives CCTS’s performance gains? To answer this
question, we rank runs by their final scores (high-performing
versus low-performing runs) and rank concepts b according
to their utility, measured by the log-weight log w(b) defined
in Eq. (9). In Fig. 7, we compare high-performing and low-
performing runs by averaging, across runs, the log-utility
of the top and bottom 10 concepts ranked by their average
log w(b). We observe that both successful and unsuccessful
runs identify a similar set of high-utility (good) concepts,
whereas successful runs learn substantially more about low-
utility (bad) concepts, suggesting that an effective search is
driven primarily by learning which concepts to avoid, while
also identifying useful semantic components. This idea
rationalizes the result displayed in Fig. 5, where we see that
the improvement in average score under CCTS is associated
with a reduced width of the lower tail of the performance
distribution. For further qualitative detail, an interpretable
concept tree with diverse extracted concepts relevant to the
circle packing task is shown in App. Fig. 10, and a heatmap
detailing the inferred per-run concept utilities is shown in
App. Fig. 11 (see App. A.5.1 for details).
LLMs encode many broad, task-agnostic correlations ac-
quired during pretraining, some of which are probably ir-
relevant for the specific objective at hand. As a result, the
LLM may initially propose algorithms that incorporate some
misleading concept. The contrastive probabilistic model cor-
rects this behavior by identifying concepts whose presence
does not correlate with improvement under the task evalu-
ation. In its current form, CCTS appears to rely primarily
on suppressing task-specific spurious correlations, thereby
stabilizing search and reducing unproductive exploration.
5.4. Concept structure dependent strategy
The synthetic model allows us to make predictions relating
the optimal search strategy and the structure of the latent
concept tree. Depending on the shape of the concept tree,
6


--- Page 7 ---
Contrastive Concept-Tree Search
(a) Real task: circle packing
0
10
20
30
40
50
60
Iteration
1.0
1.2
1.4
1.6
1.8
2.0
2.2
2.4
2.6
Best score (y)
CCTS (this work)
Greedy
Uniform
k-elites (k=5)
(b) Synthetic task
0
5
10
15
20
25
30
Iteration
1.5
1.0
0.5
0.0
0.5
1.0
1.5
2.0
CCTS (this work)
Greedy
Uniform
k-elites (k=5)
Figure 4. Best score vs. iteration (number of LLM calls) for the circle packing task. Ablations are described in the text. For all tasks, the
probability of exploitation is set to pexploit = 0.85. (a) Ran with gemini-flash-2.0 and averaged over 60 runs. (b) Synthetic task averaged
over 500 runs. Shaded area show the 95% confidence interval.
CCTS
Greedy
Uniform
1.4
1.6
1.8
2.0
2.2
2.4
2.6
Final best score (y)
circle_packing
CCTS
Greedy
Uniform
0.850
0.875
0.900
0.925
0.950
0.975
1.000
1.025
arithmetic_kakeya_entropy
CCTS
Greedy
Uniform
0.000
0.002
0.004
0.006
0.008
0.010
0.012
heilbronn
CCTS
Greedy
Uniform
15
20
25
30
35
40
45
50
squares_in_square_6_55
CCTS
Greedy
Uniform
Mean
95% CI
Figure 5. Performance of CCTS compared to baseline methods across multiple tasks. Violin plots show the distribution of the best
score after 25 iterations, aggregated over 60 runs; the mean and 95% confidence interval are superimposed. All tasks are run with
gemini-flash-2.0 and pexploit = 0.85. The distribution of best scores for CCTS presents thinner tails at low values of final best scores.
the optimal strategy changes: exploitation is more effective
for wider concept trees (with a higher branching ratio in the
teacher concept tree), whereas exploration is preferable for
narrower ones (see Fig. 8). When using an LLM on a real
task, we observe that the optimal exploitation probability
pexploit varies across problems and experimental settings
(see Appendix A.5.3). We conjecture that these variations
may reflect differences in the underlying latent concept tree
structure. Of course, further work is needed to clarify how
properties of the latent concept tree influence the resulting
search dynamics.
6. Limitations and Broader Impact
In this work, we showed that CCTS primarily improves the
lower tail of the algorithms’ score distribution. Strength-
ening guidance in the upper tail, for example by learning
cross-concept correlations or enabling cross-mutation of
multiple parents to better combine promising semantic com-
ponents, remains an important direction for future work.
The benchmark employed in this work has the primary goal
to allow the systematic study of the dynamics of algorithm
discovery, while solving the underlying problems remained
a secondary objective.
Nevertheless, we report in App. A.6.2 that the solution
found for the circle packing task reproduces the optimal
result achieved by AlphaEvolve (Novikov et al., 2025). The
best solutions obtained for different problems will be ad-
dressed separately. Since our focus is to assessing whether
and how CCTS accelerates improvement relative to baseline
strategies, we restricted our experiments to relatively small,
7


--- Page 8 ---
Contrastive Concept-Tree Search
Inferred concept utility (Circle packing)
Collision detection
...
Computational Geometry
Penalty Methods
...
Constrained Optimization
Convex Optimization
Adaptive radius initialization
Halton Sequences
...
Quasi-Random Sequences
Hilbert Curves
Space-Filling Curves
...
Heuristics and Initialization
K-d trees
Alternative optimization algorithms
Derivative-Free Optimization
CG
...
Gradient Descent
Convergence Criteria
...
Stopping Criterion
Surrogate Models
Swarm Intelligence
...
Optimization Algorithms
Software Engineering
...
Concepts
2.0
1.5
1.0
0.5
0.0
0.5
1.0
1.5
2.0
Average log utility
Inferred concept utility (Heilbronn triangle)
Barycentric Coordinates
Delaunay Triangulation
Voronoi Diagrams
Computational Geometry
Coordinate Transformations
Hyperparameter Tuning
...
Optimization Algorithm
Repair Mechanisms
...
Constrained Optimization
Hybrid Optimization Algorithms
Local Search
Force-Based Methods
Force-Directed Algorithms
Force-Directed Methods
Packing Algorithms
Repulsive Point Processes
Voronoi-based Methods
...
Point Placement Strategies
Stochastic Optimization
...
Optimization Algorithms
...
Concepts
1.0
0.5
0.0
0.5
1.0
Average log utility
1.0
0.5
0.0
0.5
1.0
Teacher log concept utility
1.00
0.75
0.50
0.25
0.00
0.25
0.50
0.75
1.00
Student log concept utility
Concepts
Corr. (r=0.94)
Figure 6. Concept trees extracted by the LLM for the circle packing (left) and Heilbronn triangle (middle) tasks. Tree nodes corresponding
to the top and bottom 10 inferred concept utilities are shown, with warm and cool colors indicating useful and non-useful concepts,
respectively. Utility of concepts are averaged over 60 runs. See App. A.5.1 for details. (Right) Correlation between teacher and student
log concept utility, log w, for the synthetic task (see App. A.4 for details).
Good runs & Good concepts
Good runs & Bad concepts
Bad runs & Good concepts
Bad runs & Bad concepts
0.0
0.5
1.0
1.5
Inferred concept value
n=40
n=59
n=43
n=62
circle_packing
Good runs & Good concepts
Good runs & Bad concepts
Bad runs & Good concepts
Bad runs & Bad concepts
0.0
0.5
1.0
1.5
n=40
n=82
n=44
n=81
squares_in_square_6_55
Figure 7. Inferred log concept utility log(w) , averaged over the
four quadrants defined by run performance (“Good” and “Bad”
runs are the ones with top-50% and bottom-50% final-score) and
concept utility rank (“Good” and “Bad” concepts are the top-50%
and bottom-50% ones ranked by log(w)). Each value is averaged
over n concept–run instances.
low-cost models (Gemini-2.0-Flash, etc.) and modest search
budgets (see App. A.5.4 for a comparison between LLM
models). In this work, our emphasis is on demonstrating
relative, rather than absolute, performance improvements.
Evaluating the potential of this approach for solving pre-
viously open or substantially harder problems will require
scaling to larger models, longer runs, and more extensive
compute.
We note that, although it is not the focus of this work, prompt
engineering has a substantial impact on performance. In
particular, insufficient task-specific information in the initial
prompt can lead to overly generic concept trees, causing the
search to stall as if trapped in a flat plateau of the algorithm
space.
A possible performance improvement to be explored in
the future consist in combining CCTS with additional
population-structuring mechanisms that improve robustness
and scalability but are largely orthogonal to the core search
0.0
0.2
0.4
0.6
0.8
1.0
Exploitation probability (pexploit)
2
3
4
5
Final best score (y)
Concept branching ratio
0=3
0=4
0=5
0=6
Figure 8. Best final score in synthetic task as a function of the
exploitation probability for different branching ratios in synthetic
tasks. The optimal search strategy of CCTS depends on the base
branching ratio of the synthetic teacher concept tree.
logic. Common examples include island-based evolution
(Novikov et al., 2025), and quality–diversity methods such
as MAP-Elites (Novikov et al., 2025; Mouret & Clune,
2015), These features have not been explored here, in order
to focus on the effect of parent sampling on the search, but
their combination with CCTS may further improve perfor-
mance.
7. Conclusion
Fitness-based parent selection is a natural baseline in LLM-
assisted algorithm discovery, but it is often a poor proxy for
parent evolvability: high-scoring algorithms do not necessar-
ily generate strong descendants. Contrastive Concept-Tree
Search addresses this mismatch by shifting selection from
raw fitness to semantic evidence of improvement, using con-
trastive concept statistics to guide search. By learning a
task-conditioned semantic structure at runtime, CCTS al-
lows search to operate in a concept space where distance,
recombination, and search direction are meaningful, leading
to significantly more efficient algorithm discovery.
8


--- Page 9 ---
Contrastive Concept-Tree Search
Impact Statement
This work studies automated algorithm-discovery systems
inspired by multi-agent scientific discovery. A key societal
challenge is ensuring interpretability and controllability as
such systems scale.
By learning explicit, human-compatible semantic concept
structures, the proposed approach aims to make automated
discovery more transparent and easier to interact with and
supervise. Such representations may help reduce risks and
unintended harm by enabling clearer human oversight and
intervention. The primary impact of this work is method-
ological and focused on improving the safety and inter-
pretability of automated discovery systems.
References
Bergstra, J., Bardenet, R., Bengio, Y., and K´egl, B. Algo-
rithms for hyper-parameter optimization. Advances in
neural information processing systems, 24, 2011.
Bloom, T. F. Erd˝os Problems, 2026. URL https://www.
erdosproblems.com/. Accessed: 2026-01-28.
Cohen, A., Pohoata, C., and Zakharov, D. A new upper
bound for the heilbronn triangle problem. arXiv preprint
arXiv:2305.18253, 2023.
Draief, M. and Massouli´e, L. Galton–Watson branching pro-
cesses, pp. 7–18. London Mathematical Society Lecture
Note Series. Cambridge University Press, 2009.
Georgiev, B., G´omez-Serrano, J., Tao, T., and Wagner, A. Z.
Mathematical exploration and discovery at scale. arXiv
preprint arXiv:2511.02864, 2025.
Grayeli, A., Sehgal, A., Costilla Reyes, O., Cranmer, M.,
and Chaudhuri, S. Symbolic regression with a learned
concept library. Advances in Neural Information Process-
ing Systems, 37:44678–44709, 2024.
Green, B. and Ruzsa, I. Z. On the arithmetic kakeya conjec-
ture of katz and tao. Periodica Mathematica Hungarica,
78(2):135–151, 2019.
Guo, Q., Wang, R., Guo, J., Li, B., Song, K., Tan, X.,
Liu, G., Bian, J., and Yang, Y. Evoprompt: Connecting
llms with evolutionary algorithms yields powerful prompt
optimizers. arXiv preprint arXiv:2309.08532, 2025.
Hu, Q. and Zhang, Q. Partition to evolve: Niching-enhanced
evolution with llms for automated algorithm discovery.
In The Thirty-ninth Annual Conference on Neural Infor-
mation Processing Systems, 2025.
Lehman, J., Gordon, J., Jain, S., Ndousse, K., Yeh, C., and
Stanley, K. O. Evolution Through Large Models, pp. 331–
366. Springer Nature Singapore, Singapore, 2024. doi:
10.1007/978-981-99-3814-8 11. URL https://doi.
org/10.1007/978-981-99-3814-8_11.
Liu, F., Tong, X., Yuan, M., Lin, X., Luo, F., Wang, Z.,
Lu, Z., and Zhang, Q. Evolution of heuristics: Towards
efficient automatic algorithm design using large language
model. arXiv preprint arXiv:2401.02051, 2024.
Mouret, J.-B. and Clune, J. Illuminating search spaces by
mapping elites. arXiv preprint arXiv:1504.04909, 2015.
Novikov, A., V˜u, N., Eisenberger, M., Dupont, E., Huang,
P.-S., Wagner, A. Z., Shirobokov, S., Kozlovskii, B., Ruiz,
F. J., Mehrabian, A., et al. Alphaevolve: A coding agent
for scientific and algorithmic discovery. arXiv preprint
arXiv:2506.13131, 2025.
Pryzant, R., Iter, D., Li, J., Lee, Y. T., Zhu, C., and Zeng, M.
Automatic prompt optimization with” gradient descent”
and beam search. arXiv preprint arXiv:2305.03495, 2023.
Pugh, J. K., Soros, L. B., and Stanley, K. O. Quality di-
versity: A new frontier for evolutionary computation.
Frontiers in Robotics and AI, 3:40, 2016.
Romera-Paredes, B., Barekatain, M., Novikov, A., Balog,
M., Kumar, M. P., Dupont, E., Ruiz, F. J., Ellenberg, J. S.,
Wang, P., Fawzi, O., et al. Mathematical discoveries from
program search with large language models. Nature, 625
(7995):468–475, 2024.
Rubinstein, R. Y. and Kroese, D. P.
The cross-entropy
method: a unified approach to combinatorial optimiza-
tion, Monte-Carlo simulation and machine learning.
Springer Science & Business Media, 2004.
Schneider, L., Wistuba, M., Klein, A., Golebiowski, J., Zap-
pella, G., and Merra, F. A. Hyperband-based bayesian op-
timization for black-box prompt selection. arXiv preprint
arXiv:2412.07820, 2024.
Tao, T. Sumset and inverse sumset theory for shannon
entropy. Combinatorics, Probability and Computing, 19
(4):603–639, 2010.
Tao, T. Sum-difference exponents for boundedly many
slopes,
and rational complexity.
arXiv preprint
arXiv:2511.15135, 2025.
teorth/erdosproblems
Wiki.
Ai
contributions
to
erd˝os
problems,
2026.
URL
https://
github.com/teorth/erdosproblems/wiki/
AI-contributions-to-Erds-problems.
Accessed: 2026-01-XX.
Wang, Y., Su, S.-R., Zeng, Z., Xu, E., Ren, L., Yang, X.,
Huang, Z., He, X., Ma, L., Peng, B., et al. Thetaevolve:
Test-time learning on open problems. arXiv preprint
arXiv:2511.23473, 2025.
9


--- Page 10 ---
Contrastive Concept-Tree Search
Wu, X., Wang, D., Wu, C., Wen, L., Miao, C., Xiao, Y., and
Zhou, Y. Efficient heuristics generation for solving com-
binatorial optimization problems using large language
models. arXiv preprint arXiv:2505.12627, 2025.
Yang, X., Zhang, L., Qian, H., Song, L., and Bian,
J. Heuragenix: Leveraging llms for solving complex
combinatorial optimization challenges. arXiv preprint
arXiv:2506.15196, 2025.
Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y.,
and Narasimhan, K. Tree of thoughts: Deliberate problem
solving with large language models. Advances in neural
information processing systems, 36:11809–11822, 2023.
Ye, H., Wang, J., Cao, Z., Berto, F., Hua, C., Kim, H., Park,
J., and Song, G. Reevo: Large language models as hyper-
heuristics with reflective evolution. Advances in neural
information processing systems, 37:43571–43608, 2024.
Yu, C., Liang, R., Ho, C.-T., and Ren, H. Autonomous
code evolution meets np-completeness. arXiv preprint
arXiv:2509.07367, 2025.
Zames, G. Genetic algorithms in search, optimization and
machine learning. Inf Tech J, 3(1):301, 1981.
10


--- Page 11 ---
Contrastive Concept-Tree Search
A. Appendix
A.1. Notation
A.1.1. SPACES AND REPRESENTATIONS
Table 1. Key spaces involved in LLM-assisted evolutionary algorithm discovery.
Space
Role
Prompt space P
Conditioning inputs that guide LLM-based program generation.
Genotype / code space X
Concrete algorithmic representations generated by the LLM.
LLM world-model space W ⊂X
LLM’s learned representation x ∈W of the algorithmic manifold.
Phenotype / feature space b = Φ(x)
Descriptor of algorithm behavior used for selection and diversity.
Hyperparameter space θ
Hyperparameters of the evolutionary dynamics.
Fitness space y = E(x; C)
Performance signal used to evaluate and select algorithms.
An important characteristic of the algorithm search space is that it is multi-layered, as detailed in Table 1. The central
layer is the space of algorithms x ∈X, or the genotype space, representing a program, a function, a file, or a repository
patch. The LLM induces a constrained manifold W over the genotype space X, within which new algorithms are generated
conditioned on prompts P. Each candidate x ∈X is evaluated to produce a fitness y and mapped to observable descriptors
b, which are used to guide selection and maintain diversity. External hyperparameters θ control the resulting evolutionary
dynamics without directly altering the task objective.
A.1.2. OPERATORS AND HYPERPARAMETERS
Table 2 summarizes the important operators of our algorithm-discovery framework, and the relevant hyperparameters for
contrastive concept tree search, the algorithm proposed in this work.
Table 2. Summary of operators used in the LLM-assisted algorithm discovery framework, and main hyperparameters θ of the Contrastive
Concept-Tree Search (CCTS) framework.
Operator
Description
Implementation
ρ
Strategy / policy selector
Fixed core kernel (exploration-exploitation mixture)
g
Meta context generator
LLM-assisted, via prompting with child and parent code
π
Parent selector
Fixed core kernel (CCTS, Greedy, Uniform, k-elites)
q
Child generator
LLM-assisted, via prompting with parent code
Φ
Feature extractor
LLM-assisted, via prompting with child and concept tree
E
Fitness function of task C
Task-dependent, user-defined
Symbol
Description
Default
LLM-related
TLLM
LLM sampling temperature
0.75
L
LLM model used
gemini-2.0-flash
Search dynamics
pexploit
Exploitation weight
0.85
T
Iteration per run
25
New concept suggestion mechanism
λ
Exploration weight in concept proposal
0.05
γ
Novelty decay exponent for concept selection
1.0
Population structure
K
Number of parallel islands
1
11


--- Page 12 ---
Contrastive Concept-Tree Search
A.2. Learning model description
In this section, we describe the model used to infer the class-conditional probability distribution used by the student in
the CCTS framework to approximate the log-likelihood for a given concept to belong to a high quality or a low-quality
algorithm (see Sec. A.4.3).
A.2.1. FACTORIZED CATEGORICAL CASE
Let b = (bv)v∈V denote a binary vector of concept indicators extracted from an algorithm, where V indexes concepts
organized in a rooted tree with parent map pa(v). Such a tree is constructed by directly querying the LLM for empirical
tasks, or through a teacher model for synthetic tasks, which is going to be described in detail in App. A.4. We consider a
parametric family of distributions over b in which features are conditionally independent given their parent in the hierarchy
and satisfy a hard ancestor-consistency constraint.
Specifically, we assign zero probability to any configuration violating
bv ≤bpa(v)
for all v ∈V,
(12)
so that a concept can be active only if its parent concept is active too. For valid configurations obeying the condition above,
we use a hierarchical Bernoulli model in which features are conditionally independent, given the (necessary) presence of
their parent. In this factorized case, the parameter vector η of the generic family {ˆpη(b)} consists of per-node conditional
activation probabilities η = {ηv}v∈V , defined by
Pr(bv = 1 | bpa(v) = 1) = ηv,
ηv ∈(0, 1),
(13)
with Pr(bv = 1 | bpa(v) = 0) = 0 by construction.
Under this parameterization, the induced joint distribution over valid configurations factorizes as
ˆpη(b) =
Y
v̸=root
η bv
v (1 −ηv) bpa(v)−bv,
(14)
and ˆpη(b) = 0 for any configuration violating the hierarchical constraint bv ≤bpa(v).
To guide parent selection, we adopt a Tree-structured Parzen Estimator (TPE) formulation and estimate two such models
with identical structure: ˆpη+(b) ≈p(b | goodt) and ˆpη−(b) ≈p(b | badt). The parameters are learned by cross-entropy /
maximum likelihood estimation1 (a detailed derivation is presented in the paragraph below) on the corresponding subsets of
the archive,
ˆη+
v =
P
i∈goodt bi,v
P
i∈goodt bi,pa(v)
,
ˆη−
v =
P
i∈badt bi,v
P
i∈badt bi,pa(v)
.
(15)
Guided parent selection is then based on the log-likelihood ratio
log w(b) = log ˆpη+(b) −log ˆpη−(b),
(16)
which assigns high weight to algorithms whose semantic features are enriched in high-performing solutions relative to
low-performing ones.
Factorized hierarchical Bernoulli model
For the sake of completeness, we derive here the cross-entropy estimates given
in Eq. (15). For the factorized hierarchical Bernoulli model, the log-likelihood of a single feature vector b = (bv)v∈V is
log ˆpη(b) =
X
v̸=root
h
bv log ηv +
 bpa(v) −bv

log(1 −ηv)
i
,
(17)
1When the target distribution is empirical, minimizing the KL divergence (or equivalently the cross-entropy) between the empirical
measure and a parametric model is exactly equivalent to maximum likelihood estimation.
12


--- Page 13 ---
Contrastive Concept-Tree Search
with the convention that ˆpη(b) = 0 for configurations violating bv ≤bpa(v). Given a subset of the archive (either good or
bad), maximum likelihood estimation amounts to maximizing the sum of the log-likelihood above over all the samples in
the subset. Because the likelihood factorizes across nodes, the optimization problem decouples over the different vector
entries v. We then define, for a fixed node v, define
A±
v ≡
X
i∈good/bad
bi,v,
B±
v ≡
X
i∈good/bad
bi,pa(v),
(18)
where the sums run over the indices i in the selected subset (either i ∈good or i ∈bad). The contribution of node v to the
total log-likelihood in either of the two cases, ℓ±
v (ηv), is then given by
ℓ±
v (ηv) = A±
v log ηv + (B±
v −A±
v ) log(1 −ηv).
(19)
Setting ∂ℓ±
v /∂ηv|η=η±
v = 0 yields the closed-form estimator
ˆη±
v = A±
v
B±
v
,
(20)
which corresponds to the empirical conditional probability Pr(bv = 1 | bpa(v) = 1) estimated from the selected subset.
A.3. New concept exploration
The guided parent-selection mechanism described above biases sampling toward archive elements whose existing semantic
features are enriched among high-performing algorithms. However, this alone does not actively encourage the exploration
of new or rarely tried concepts. We augment CCTS with a lightweight concept-level exploration mechanism that operates
directly on the concept tree, and that we describe hereafter.
Beta priors and nonzero support.
To ensure that newly discovered concepts are never assigned zero probability, we
place Beta priors on the conditional activation parameters of the hierarchical Bernoulli model. Concretely, for each concept
v, rather than using the maximum likelihood estimators given by Eq. (20), we estimate the parameters η±
v through smoothed
counts,
˜η±
v =
A±
v + α0
B±
v + α0 + β0
,
(21)
where A±
v and B±
v denote the empirical counts in the good or bad subsets of the archive, and are given by Eq. (18), and α0
and β0 are smoothening parameters (α0 = 0.1 and β0 = 10.0). This guarantees nonzero probability mass for all concepts,
including those that have not yet been observed, and stabilizes likelihood-ratio estimates for guided selection.
Count-based novelty bias.
In addition to exploitation driven by the likelihood-ratio score, we introduce an explicit bias
toward concepts that have been tried fewer times. For each concept v, we maintain a counter nv representing the number of
times that concept has been targeted during child generation. We define a novelty weight
novel(v) = (nv + 1)−γ,
(22)
where γ > 0 controls the strength of the bias. Concepts that have never been tried (nv = 0) receive maximal novelty weight,
while repeatedly attempted concepts are progressively downweighted. This mechanism naturally supports both first-time
exploration and repeated trials when the effect of a concept is uncertain.
Mixture-based concept selection.
The Beta priors and the count-based novelty bias both contribute to the probability
of p(v) of proposing a semantic edit for a new child during the evolution process. Candidate concepts are sampled from
a mixture of an exploitation distribution based on the learned contrastive model and an exploration distribution based on
novelty, namely,
p(v) ≡(1 −λ)
exp(∆v)
P
u exp(∆u) + λ
novel(v)
P
u novel(u),
∆v = log ˜η+
v −log ˜η−
v ,
(23)
where λ ∈[0, 1] is a parameter that controls the trade-off between exploitation, given by consecutive, incremental, lineage
based mutations, and exploration, which biases the generation process toward unprecedentedly used concepts.
13


--- Page 14 ---
Contrastive Concept-Tree Search
Table 3. Parameters of the synthetic algorithm-discovery environment.
Symbol
Value
Description
Concept tree generation (branching process)
λ0
5.0
Expected branching factor at the root of the concept tree.
α
0.9
Exponential decay rate of branching with depth.
Dmax
10
Maximum depth of the concept tree.
Nmax
25
Maximum number of concepts (used in Fig. 8).
Latent mutation operator (synthetic child generation)
pkeep
0.75
Probability of inheriting an active concept from the parent.
ν
1.5
Mean number of new concepts introduced per mutation.
plocal
0.65
Probability of sampling new concepts locally in the tree.
Ground-truth concept utility (teacher model)
µ0
0.0
Mean logit utility of depth-0 concepts.
σ0
1.0
Standard deviation of logit utility at depth 0.
Noise and observation model
σy
0.1
Standard deviation of fitness noise.
Prompt-level realization.
Once a concept v is selected, it is injected into the LLM prompt as a semantic directive for
child generation. Specifically, the adaptive prompt is augmented as
Pt = P0(C) ⊕Ctxt,
(24)
where Ctxt = ‘‘Try to incorporate concept v’’.
A.4. Synthetic environment
In this Section, we describe the synthetic environment used to rationalize our empirical findings. A schematic summary of
the key elements composing the synthetic environment is shown in Fig. 9, while a table summarizing the notation pertaining
to the synthetic environment is reported in Table 3 and are precisely characterized in what follows.
Concept tree
T t
Latent utility
ρv
Latent concepts
b∗(x)
Fitness
y(x)
Extracted features
ˆb(x)
CE/TPE parameters
ηv
child generation
Tree generation
(λ0, α, Dmax)
Latent utility
logit(ρv) = µd(v) + σd(v)ξv
Child generation
pkeep, ν, plocal, ℓlocal
Feature extraction
rd (false negative)
Fitness model
a (scale)
LLM-extracted
concept tree
TLLM
LLM-extracted
lineage / algorithm tree
CE/TPE on LLM runs
ˆηLLM
Evaluator statistics
(noise / scale)
Figure 9. Schematic description of the synthetic environment. Left: generative teacher model. Center: hyperparameters controlling each
component. Right: empirical statistics extracted from LLM runs used to fit or calibrate the hyperparameters. The solid arrow connect an
element of the synthetic environment with what is constructed starting from it. The dashed lines connect a set hyperparameters with the
object they define. The dotted lines connect an empirical statistics from real tasks to the synthetic hyperparameters that fit them.
14


--- Page 15 ---
Contrastive Concept-Tree Search
A.4.1. GOAL
We introduce a synthetic algorithm-discovery environment that replaces the LLM with controlled probabilistic operators.
The purpose is to (i) isolate the structural mechanisms underlying Contrastive Concept-Tree Search, (ii) identify optimal
operating regimes (e.g., locality, noise, concept granularity), and (iii) explain empirical scaling behavior observed with real
LLMs.
The synthetic environment mirrors the real system at the level of semantics rather than language: algorithms are represented
by latent semantic concepts organized in a hierarchy; fitness depends on which concepts are present within a given algorithm;
child generation performs local semantic edits; and the feature extraction process is noisy. The guided selection mechanism
operates on extracted features exactly as in the real system, by fitting paired feature models over good and bad subsets and
using their likelihood ratio to reweight parent selection.
A.4.2. MODEL
In this Section, we detail how the different components of the synthetic setting are constructed. These components are: a
teacher structure containing the possible concepts and their tree-structured, semantic relations; a semantic utility function
that associates to each concept a numerical value representing its utility; a ”teacher truth”, i.e. a set of concepts through
which an algorithm is defined; a synthetic mutation process that generates a child from a given parent, and that replaces the
LLM as a mutation operator; a linear teacher evaluator that assigns to a given algorithm a score, or fitness, and a synthetic
learner that extract an imperfect set of concepts from a given algorithm.
Concept tree generation (teacher structure)
An artificial latent (teacher) concept tree is generated by a truncated,
depth-inhomogeneous Galton–Watson branching process (Draief & Massouli´e, 2009). Starting from the root node bt
0, each
node b at depth d(b) generates Kb offspring, where Kb is drawn from a Poisson distribution with depth dependent rate λd,
namely,
Kb | d(b) = d ∼Poisson(λd),
λd = λ0 exp(−αd),
(25)
The base branching ratio λ0 > 0 controls the branching process at the root and α ≥0 controls the decay of the mean number
of offspring with the depth reached. The process is truncated at a maximum depth Dmax by setting Kb = 0 for all d(b) =
Dmax. Here, the parameter λd is the mean (and variance) of the Poisson distribution, so that E[Kb | d(b) = d] = λd and
Var(Kb | d(b) = d) = λd. The hyperparameters (λ0, α, Dmax) are fitted to LLM-extracted concept trees by approximately
matching its empirical mean branching factor as a function of depth. The resulting set of nodes in the tree, denoted by V ,
constitutes the set of existing concepts in the synthetic task.
Teacher concept values (semantic utility)
Each concept v ∈V is assigned a latent utility parameter ρv ∈(0, 1), which
controls how strongly the presence of that concept contributes to the quality of the algorithm. We model the utility of a
concept using an underlying Gaussian distribution on the logit scale (i.e., ρv is the sigmoid of a Gaussian random variable):
logit(ρv) ≡log
 ρv/(1 −ρv)

= µd(v) + σd(v) ξv,
ξv ∼N(0, 1),
(26)
where µd denotes average utility of concepts at depth d, and σd denotes the heterogeneity of utility at that depth. ξv is a
Gaussian noise with zero mean and unit correlation. For simplicity, we assume that the realizations of the noise for different
concept values are independent from each other. The logit parametrization ensures that the latent utility parameters ρv
remain in (0, 1) while allowing their distribution to be modeled with an unconstrained Gaussian prior on the logit scale.
Latent algorithm representation (teacher truth)
Each algorithm x is associated with a latent concept configuration
b∗(x) ∈{0, 1}|V |, subject to a hierarchical closure based on the teacher structure: for every non-root node v ∈V ,
b∗
v(x) = 1 ⇒b∗
pa(v)(x) = 1.
(27)
The teacher truth b∗(x) represents which semantic concepts the algorithm truly uses and is not observed directly by the
learner. In this way, we model the possible existence of a mismatch between the LLM’s representation of a given algorithm
and what the algorithm actually does to accomplish a given task.
15


--- Page 16 ---
Contrastive Concept-Tree Search
Child generation operator (synthetic mutation)
Child generation operates directly on latent concepts b∗and induces
local semantic search. Given a parent with latent concepts b∗
parent, we first retain each active concept with probability
pkeep (this step models a possible ”inheritance” mechanism). We then sample m ∼Poisson(ν) new concepts with
probability plocal. These concepts are chosen via a short random walk on the tree, and represent forms of gradual innovation.
Alternatively we sample uniformly from the tree (radical innovation), with probability 1 −plocal. Lastly, we activate all
ancestors of any newly activated concept, thus accommodating the child algorithm within the teacher structure.
This evolution operator induces a notion locality and smoothness within the the search landscape. The gradual innovation
probability plocal and the mean of the Poisson process ν are selected so that synthetic model exhibits search behavior
qualitatively similar to that seen in the LLM-based experiments.
Fitness generation (linear teacher evaluator)
The fitness of an algorithm x is generated as a noisy perturbation of the
latent values wv of the latent concepts b∗(x) represented by x, namely,
y(x) =
X
v∈b∗(x)
wv + ε,
ε ∼N(0, σ2
y),
(28)
with
wv =
 logit(ρv) −¯µd(v)

,
¯µd = Ev:d(v)=d[logit(ρv)] .
(29)
The limitation of this simple model is that the fitness y(x) is assumed to be a linear function of the concept utility. A more
refined model would account for dependencies between concepts, but this is out of the scope of this work.
Feature extraction (synthetic learner noise)
We denote by ˆb(x) the concepts that the learner attributes to a given
algorithm. We assume that the learner observes a noisy version of the latent concepts:
ˆb(x) = Φ
 b∗(x)

.
(30)
We construct the observed concepts as follows: starting from b∗(x), any concept within it can be dropped with probability
1 −rd. Hierarchical closure is then enforced on the resulting vector, yielding ˆb. This prescription models an imperfect
concept extraction from the LLM. The imperfection modeled yields false negatives (a concept belonging to the algorithm is
missed by the LLM). Although not considered here, it is also possible to model the addition of spurious concepts, or false
positives.
A.4.3. COMPARISON WITH THE LLM-GENERATED DATA
Learning mechanism (CE / TPE)
The learner applies a contrastive update in the style of a Tree Parzen Estimator on the
extracted features ˆb. More precisely, at iteration t, the archive is partitioned into good and bad sets using a threshold τt (e.g.,
top-ρ quantile):
goodt = { i : yi ≥τt },
badt = { i : yi < τt }.
(31)
Two class-conditional feature models are then fitted to the conditional probabilities that a good or bad algorithm as a given
concept b as active,
ˆpη+(ˆb) ≈p(ˆb | goodt),
ˆpη−(ˆb) ≈p(ˆb | badt),
(32)
given that the hierarchical closure induced by the concept tree model ( Section 3) is respected. Guided parent selection
according to the contrastive concept search prediction uses then the log-likelihood ratio log w(ˆb) as a discriminative score to
select the parent during the synthetic mutation process, namely,
log w(ˆb) = log ˆpη+(ˆb) −log ˆpη−(ˆb),
π(xi | At) ∝exp(log w(ˆbi)) ,
(33)
with π(xi|At) the probability to select algorithm xi as a parent for the synthetic evolution process. In summary, ρv is the
ground-truth latent utility driving the teacher fitness, while the learned parameters η+, η−(and the induced ratio score log w)
are emergent statistics that drive selection toward more successful concepts, and that rely on an imperfect, noisy learner.
16


--- Page 17 ---
Contrastive Concept-Tree Search
Comparison between teacher and student
The synthetic environment allows us to explicitly compare the latent ground-
truth structure used to generate data, i.e. the teacher, with the statistics learned by the guided search procedure, the student.
Importantly, this comparison must respect the fact that the learner does not attempt to recover the teacher parameters directly,
but instead learns discriminative feature statistics induced by selection dynamics and noisy observations. The teacher is
characterized by a fixed set of latent utility parameters ρ = {ρv}v∈V , which determine the fitness of a given algorithm
through the data-generating process (Section A.4.2). These parameters define how individual concepts contribute to fitness
in expectation, but they do not depend on the archive state nor on any partition between arbitrarily defined ”good” and ”bad”
concepts. By contrast, the learner explicitly introduces a partition in algorithmic space, by fitting two class-conditional
feature models, ˆpη+(b) ≈p(b | good) and ˆpη−(b) ≈p(b | bad), and uses their likelihood ratio to guide parent selection.
The quantity that actually drives selection is therefore the discriminative score
log w(b) = log ˆpη+(b) −log ˆpη−(b),
(34)
which measures how strongly a feature configuration is enriched among high-performing algorithms relative to low-
performing ones. Thus, to compare teacher and student on a common footing, we derive a corresponding teacher-side
discriminative signal by applying the same partition among ”good” and ”bad” algorithms in the synthetic archive and
computing, for each concept v, the conditional log-odds ratio
log w(teacher)
v
= log
Pr(b∗
v = 1 | b∗
pa(v) = 1, y ≥τ)
Pr(b∗v = 0 | b∗
pa(v) = 1, y ≥τ) −log
Pr(b∗
v = 1 | b∗
pa(v) = 1, y < τ)
Pr(b∗v = 0 | b∗
pa(v) = 1, y < τ).
(35)
This quantity is not a parameter of the teacher model, but an empirical statistic implied by the teacher’s data-generating
process under the same selection criterion used by the learner. The student-side analogue is given by the learned parameters,
log w(student)
v
= log ˜η+
v −log ˜η−
v ,
(36)
where ˜η±
v are the maximum likelihood estimators with smoothed counts given by Eq. (21). The quantity log wstudent
v
corresponds to the per-concept contribution to the log-likelihood ratio used in parent selection.
Comparing log w(teacher)
v
and log w(student)
v
therefore isolates how faithfully the guided search mechanism recovers the
directional improvement signal encoded in the teacher, rather than attempting to match absolute concept utility. Discrepancies
between the two log-likelihoods reflect the combined effects of noisy feature extraction, finite sample size, hierarchical
dependencies, and selection-induced bias, and provide a principled way to analyze when and why concept-guided search
succeeds or fails in recovering meaningful semantic structure.
In the experiments reported here, the teacher-side discriminative statistic is computed using a long-time population reference
obtained by Monte Carlo sampling of the synthetic world (implemented as an MCMC over latent algorithms, here identified
by a set of concepts consistent with the teacher’s ground truth tree), which defines a fixed partition among good and
bad algorithms independent of the learner; this stationary reference allows the student–teacher discrepancy to be tracked
consistently over training iterations.
A.5. Additional experimental results
A.5.1. INTERPRETABILITY
To assess the interpretability of the contrastive concept-tree search, we visualize both the semantic concept trees extracted
by the LLM during search (see Figs. 10- 12) and the corresponding concept utility statistics inferred by CCTS (see Figs. 11-
13). The figures below illustrate how task-specific concept hierarchies emerge and how individual concepts are associated
with algorithm performance.
Figure 11 visualizes the relationship between algorithm performance and learned concept utility. Runs are ranked by final
score along the y-axis, while concepts are ranked along the x-axis by their learned log utility log(w), averaged across all
runs (showing the top-10 and bottom-10 concepts). Each rectangle describes the log utility learned for a given concept in a
given run; red regions denote high-utility (“Good”) concepts and blue points denote low-utility (“Bad”) concepts. Empty
entries indicate that the corresponding concept was not explored during that run. Note that the Figure 7 is obtained by
averaging, across runs, the per-run learned log concept values within the four quadrants defined in Fig. 11.
17


--- Page 18 ---
Contrastive Concept-Tree Search
Grid Search
...
Algorithm Tuning
Collision detection
...
Computational Geometry
Lagrangian methods
Penalty Methods
...
Constrained Optimization
Convex Optimization
Adaptive radius initialization
Force-Directed Methods
Multi-Start Approach
Halton Sequences
Low-Discrepancy Sequences
Sobol Sequences
Quasi-Random Sequences
Hilbert Curves
Space-Filling Curves
Voronoi-Based Placement
...
Heuristics and Initialization
Nearest Neighbor Search
...
K-d trees
Adaptive Bound Adjustment
...
Mathematical optimization
Numerical Stability
...
Numerical Analysis
Alternative optimization algorithms
Derivative-Free Optimization
Differential Evolution
CG
...
Gradient Descent
Gradient-Free Methods
Parameter Tuning
Particle swarm optimization
Convergence Criteria
...
Stopping Criterion
Surrogate Models
Swarm Intelligence
Trust-Region Methods
...
Optimization Algorithms
Software Engineering
...
Concepts
2.0
1.5
1.0
0.5
0.0
0.5
1.0
1.5
2.0
Average log utility
Figure 10. Part of the concept tree extracted by the LLM of the circle packing task. Tree nodes corresponding to the top and bottom 20
inferred concept utilities are shown, with warm and cool colors indicating useful and non-useful concepts, respectively. Utility of concepts
are averaged over 60 runs.
18


--- Page 19 ---
Contrastive Concept-Tree Search
Adaptive Radius Initialization
Surrogate Models
Gradient-Based Optimization Methods
Root-Finding Algorithms
Adaptive Tolerance Strategies
Swarm Intelligence
Derivative-Free Optimization
Constraint Aggregation Techniques
Convex Optimization
Approximation Algorithms
Lennard-Jones Potential
Penalty Methods
Lloyd's Algorithm
Random Placement
Sequential Least Squares Programming
Cooling Schedules
Code Duplication
k-d Trees
Sobol Sequence
Constrained Optimization
Concept
circle_packing/run_53
circle_packing/run_12
circle_packing/run_14
circle_packing/run_07
circle_packing/run_42
circle_packing/run_48
circle_packing/run_32
circle_packing/run_22
circle_packing/run_37
circle_packing/run_38
circle_packing/run_04
circle_packing/run_21
circle_packing/run_20
circle_packing/run_47
circle_packing/run_18
circle_packing/run_44
circle_packing/run_40
circle_packing/run_36
circle_packing/run_46
circle_packing/run_26
circle_packing/run_52
circle_packing/run_11
circle_packing/run_49
circle_packing/run_29
circle_packing/run_59
circle_packing/run_17
circle_packing/run_58
circle_packing/run_25
circle_packing/run_33
circle_packing/run_24
circle_packing/run_05
circle_packing/run_31
circle_packing/run_39
circle_packing/run_28
circle_packing/run_55
circle_packing/run_15
circle_packing/run_08
circle_packing/run_43
circle_packing/run_34
circle_packing/run_01
circle_packing/run_35
circle_packing/run_57
circle_packing/run_23
circle_packing/run_03
circle_packing/run_09
circle_packing/run_41
circle_packing/run_10
circle_packing/run_45
circle_packing/run_51
circle_packing/run_19
circle_packing/run_16
circle_packing/run_50
circle_packing/run_56
circle_packing/run_13
circle_packing/run_60
circle_packing/run_02
circle_packing/run_54
circle_packing/run_30
circle_packing/run_27
circle_packing/run_06
Run (sorted by final score)
Good concepts & Good runs
Bad concepts & Good runs
Good concept & Bad runs
Bad concepts & Bad runs
0
1
2
Final score
Adaptive Radius Initialization
Surrogate Models
Gradient-Based Optimization Methods
Root-Finding Algorithms
Adaptive Tolerance Strategies
Swarm Intelligence
Derivative-Free Optimization
Constraint Aggregation Techniques
Convex Optimization
Approximation Algorithms
Lennard-Jones Potential
Penalty Methods
Lloyd's Algorithm
Random Placement
Sequential Least Squares Programming
Cooling Schedules
Code Duplication
k-d Trees
Sobol Sequence
Constrained Optimization
Concept utility
0.5
0.0
0.5
1.0
1.5
mean log utility
2
1
0
1
2
Log concept utility
Figure 11. Algorithm score and concept utility scatter plot for the circle packing task.
19


--- Page 20 ---
Contrastive Concept-Tree Search
Delaunay triangulations
Packing algorithms
Space-filling curves
...
Computational Geometry
Constraint Satisfaction
Affine transformations
Adaptive step sizes
Barrier methods
Lagrangian methods
Penalty functions
...
Constrained Optimization
BFGS
L-BFGS-B
Gradient-based methods
Gradient-Based Optimization
Hybrid optimization methods
Numerical Optimization
...
Geometric optimization
Voronoi diagrams
...
Coordinate geometry
Differential evolution
...
Evolutionary Computation
Space-filling designs
...
Experimental design
Force-directed algorithms
Geometric Algorithms
Adaptive parameter control
Parameter Tuning
Rank-based selection
Roulette wheel selection
Simulated Binary Crossover (SBX)
Uniform crossover
...
Genetic algorithms
Simulated annealing
...
Heuristic search
Numerical Stability
Numerical Analysis
Vectorization
...
Optimization
Halton sequences
...
Quasi-Monte Carlo methods
Rejection sampling
...
Random sampling
Monte Carlo methods
Stochastic Optimization
...
Concepts
1.5
1.0
0.5
0.0
0.5
1.0
1.5
Average log utility
Figure 12. Part of the concept tree extracted by the LLM of the Heilbronn’s Triangle task. Tree nodes corresponding to the top and bottom
20 inferred concept utilities are shown, with warm and cool colors indicating useful and non-useful concepts, respectively. Utility of
concepts are averaged over 60 runs.
20


--- Page 21 ---
Contrastive Concept-Tree Search
Hybrid Optimization Algorithms
Hybrid Optimization Methods
Hybrid Optimization
Repulsive point processes
Adaptive Sampling
Hyperparameter Tuning
Force-Directed Algorithms
Voronoi Diagrams
Stochastic Optimization
Delaunay Triangulation
Elitism
Constraint Satisfaction
Multiple Runs
BFGS
Numerical Optimization
Numerical Stability
Equilateral triangle
Point-in-Triangle Testing
Coordinate Transformations
L-BFGS-B
Concept
heilbronn/run_12
heilbronn/run_60
heilbronn/run_33
heilbronn/run_20
heilbronn/run_36
heilbronn/run_38
heilbronn/run_28
heilbronn/run_04
heilbronn/run_51
heilbronn/run_59
heilbronn/run_22
heilbronn/run_27
heilbronn/run_46
heilbronn/run_16
heilbronn/run_13
heilbronn/run_24
heilbronn/run_02
heilbronn/run_30
heilbronn/run_17
heilbronn/run_48
heilbronn/run_10
heilbronn/run_53
heilbronn/run_15
heilbronn/run_07
heilbronn/run_40
heilbronn/run_50
heilbronn/run_56
heilbronn/run_08
heilbronn/run_49
heilbronn/run_54
heilbronn/run_18
heilbronn/run_09
heilbronn/run_55
heilbronn/run_32
heilbronn/run_29
heilbronn/run_23
heilbronn/run_57
heilbronn/run_31
heilbronn/run_39
heilbronn/run_35
heilbronn/run_44
heilbronn/run_45
heilbronn/run_05
heilbronn/run_47
heilbronn/run_52
heilbronn/run_21
heilbronn/run_01
heilbronn/run_19
heilbronn/run_34
heilbronn/run_43
heilbronn/run_26
heilbronn/run_25
heilbronn/run_58
heilbronn/run_37
heilbronn/run_42
heilbronn/run_11
heilbronn/run_03
heilbronn/run_06
heilbronn/run_14
heilbronn/run_41
Run (sorted by final score)
Good concepts & Good runs
Bad concepts & Good runs
Good concept & Bad runs
Bad concepts & Bad runs
0.00
0.01
0.02
Final score
Hybrid Optimization Algorithms
Hybrid Optimization Methods
Hybrid Optimization
Repulsive point processes
Adaptive Sampling
Hyperparameter Tuning
Force-Directed Algorithms
Voronoi Diagrams
Stochastic Optimization
Delaunay Triangulation
Elitism
Constraint Satisfaction
Multiple Runs
BFGS
Numerical Optimization
Numerical Stability
Equilateral triangle
Point-in-Triangle Testing
Coordinate Transformations
L-BFGS-B
Concept utility
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
mean log utility
2
1
0
1
2
Log concept utility
Figure 13. Algorithm score and concept utility scatter plot for the Heilbronn’s Triangle task.
21


--- Page 22 ---
Contrastive Concept-Tree Search
(a) Real task
0
5
10
15
20
25
30
Iteration
5.0
7.5
10.0
12.5
15.0
17.5
20.0
22.5
Concept count
Concept coverage over iterations
Total concepts
Concepts in new algorithm
Average concepts (so far)
(b) Synthetic task
0
20
40
60
80
100
Iteration
0
20
40
60
80
100
Concept count
Concept coverage over iterations
Total concepts
Concepts in new algorithm
Average concepts (so far)
Figure 14. Number of concepts discovered vs. iteration. The total number of concepts is the cardinality of all concepts appearing in the
sampled algorithms at the current iteration. The number of concepts in the new algorithm refers to the number of concepts in the child
algorithm at the current iteration. The average number of concepts so far is the mean number of concepts across all discovered algorithms.
A.5.2. GROWTH RATE OF THE NUMBER OF CONCEPTS
The growth of the number of concepts discovered vs. iteration is shown in Fig. 14 for the circle packing task in the empirical
setting and the synthetic task. The curves are qualitatively similar in both the empirical and synthetic settings, with the total
number of discovered concept increasing with the number of iterations. Interestingly, this increase proceeds in a step-like
fashion, where time intervals where the total number of concepts remains roughly constant alternate with steep increases in
the concept counts.
A.5.3. EXPLOITATION/EXPLORATION RATIO
In Fig. 15, we vary the exploitation probability pexploit while holding all other settings to the main defaults (see Table 2), then
report the mean final best score across several runs for each value. The experiment is performed using gpt-o4-mini. The
curve generically exhibit a nonmonotonic trend, with the optimal exploitation probability varying from task to task. Note
that simulations using the synthetic data suggest that the optimal exploitation/exploration strategy depends on the structure,
such as the concept branching ratio. of the underlying concept tree (see Fig. 8).
0.6
0.8
1.0
Exploitation probability
0.90
0.92
0.94
0.96
Final best score
arithmetic_kakeya_entropy
0.6
0.8
1.0
Exploitation probability
1.4
1.6
1.8
Final best score
circle_packing
0.6
0.8
1.0
Exploitation probability
0.004
0.006
0.008
0.010
0.012
Final best score
heilbronn
Figure 15. Optimal search strategy of CCTS. We show the normalized score as a function of the exploitation probability pexploit for the
Arithmetic Kakeya conjecture, circle packing, Heilbronn’s triangle problem task after 40 iterations and averaged over 30 runs using
gpt-o4-mini. All the curves display a nonmonotonous trend, with a maximum at a value of the exploitation proability that depends on the
task.
22


--- Page 23 ---
Contrastive Concept-Tree Search
A.5.4. CHOICE OF LLM MODEL
Note that the choice of the underlying LLM model, used in this work as a black-box optimizer, has a significant influence on
task performance. We performed experiments with several LLMs exhibiting different reasoning capabilities, showing that
more advanced models consistently achieve better performance, as illustrated in Fig. 16.
0
10
20
30
40
50
60
Iteration
0
1.14711 × 10
2
Best score (y)
gemini-2.0-flash average
gemini-2.5-flash-lite average
gpt-4.1-nano average
gpt-4o-mini average
Figure 16. Comparison of LLM models for the Heilbronn Triangle Problem using CCTS, averaged over 60 runs. The shaded area shows
the 95% confidence interval.
A.6. Benchmark details
A.6.1. SUMMARY LIST
We briefly describe in Table 4 the different combinatorics task addressed in this work. These problems are related to known
Erd˝os problems, although their exact formulations are adapted to the specific settings considered here and do not necessarily
cover the most general cases.
A.6.2. CIRCLE PACKING
Here the goal is to pack 26 circles inside the unit square [0, 1]2. Each circle is specified by a center ci = (xi, yi) ∈R2 and a
radius ri ≥0. A packing is feasible if every circle lies entirely in [0, 1]2 and circles do not overlap (touching is allowed).
Table 4. Summary of mathematical problems used to evaluate CCTS. Each task defines a structured algorithm-discovery problem with a
verifiable objective and a black-box evaluator.
Problem
Description
Circle packing (Novikov et al., 2025)
Put n = 26 circles inside of a unit square such that the sum of radii is maximized. Circles
can be of different sizes but cannot overlap.
Arithmetic Kakeya Conjecture
Let A be a set of n integers. How many distinct d can occur as the common difference of
a three-term arithmetic progression in A? Are there always O(n3/2) many such d? We
consider an information-theoretic analogue of this question, replacing set cardinalities by
Shannon entropies of linear projections, in the spirit of the entropy sumset theory developed
in (Tao, 2010).
Heilbronn’s Triangle Problem
Places 11 points inside a unit-area equilateral triangle to maximize the minimum area of any
triangle formed by three points. Out-of-bounds points are projected back, and the score is the
smallest triangle area.
Squares-in-Square
Places n squares with disjoint interiors inside a unit square to maximize the sum of side
lengths. Overlapping interiors are forbidden; touching boundaries is allowed.
23


--- Page 24 ---
Contrastive Concept-Tree Search
The optimization objective is to maximize the total size (total radius mass) of the packing which can be stated as follows.
26
X
i=1
ri.
(37)
This serves as a simple scalar measure of how much circular area can be accommodated in the square under these constraints.
We report in Fig. 17 the solution found for the circle packing task, which reproduces the optimal result reported in
AlphaEvolve (Novikov et al., 2025).
Figure 17. Optimal circle packing found by CCTS after 120 iterations, consistently with what has been found with AlphaEvolve (Novikov
et al., 2025).
A.6.3. ARITHMETIC KAKEYA CONJECTURE
This problem concerns a discrete random vector (X, Y ) with finite support and asks how large the entropy of one linear
projection (e.g. a difference) can be relative to the entropies of several other linear projections (e.g. coordinates and sums).
Formally, for linear maps πr(X, Y ) = X + rY (with π∞(X, Y ) = Y ), one seeks sharp constants C (sum-difference
constant (Tao, 2025)) such that,
H(π−1(X, Y )) ≤C max{H(π0(X, Y )), H(π1(X, Y )), H(π2(X, Y )), H(π∞(X, Y ))},
(38)
holds for all finitely supported discrete (X, Y ) (Georgiev et al., 2025; Tao, 2025). This entropy inequality is an information-
theoretic analogue of classical sum-difference and arithmetic progression problems (Tao, 2010), including Erd˝os Prob-
lem #1097 (teorth/erdosproblems Wiki, 2026).
24


--- Page 25 ---
Contrastive Concept-Tree Search
Here a candidate solution specifies a finitely supported probability distribution on Z2, interpreted as the joint law of (X, Y ).
The evaluator computes the Shannon entropies of the projected random variables,
X −Y,
X,
X + Y,
X + 2Y,
Y,
(39)
by aggregating probability mass along each projection (Tao, 2025; Green & Ruzsa, 2019). The score assigned to a candidate
is the entropy ratio,
H(X −Y )
max{H(X), H(X + Y ), H(X + 2Y ), H(Y )}.
(40)
Maximizing this ratio corresponds to constructing distributions where the difference projection is unusually complex
compared to the other directions. Because the theoretical constant is defined as a supremum over all discrete distributions,
each candidate’s entropy ratio provides a valid lower bound on the corresponding sum-difference constant.
A.6.4. HEILBRONN’S TRIANGLE PROBLEM
The Heilbronn triangle problem asks for a placement of 11 points inside a fixed equilateral triangle of area 1 that makes
every triangle formed by three of the points “as large as possible” in the worst case (Georgiev et al., 2025). Hence fixing the
unit-area equilateral triangle K ⊂R2, the task is to choose,
P = {p1, . . . , p11} ⊂K,
(41)
so as to maximize the smallest area of any triangle formed by three selected points,
m(P) =
min
1≤i<j<k≤11 Area(pi, pj, pk),
maximize m(P).
(42)
Intuitively, good configurations avoid having any three points nearly collinear or overly clustered, since that would create a
very small triangle and reduce m(P).
In the testing a candidate returns an array of 11 planar points (shape (11, 2)). Following the description mentioned in
(Georgiev et al., 2025) the evaluator then,
• Feasibility check: if the output does not have the correct shape or contains non-finite entries, it is marked invalid
(score 0).
• Repair step: if any point lies outside K, it is projected to the nearest point on the boundary of K (producing a repaired
set ˜P).
• Score computation: the score is the minimum area over all
 11
3

triangles formed by triples of repaired points (Cohen
et al., 2023):
score = m( ˜P) =
min
i<j<k Area(˜pi, ˜pj, ˜pk),
(43)
where (in 2D) Area(a, b, c) = 1
2
 (b −a) × (c −a)
.
Note that in this case higher scores are better.
A.6.5. SQUARES-IN-SQUARE
This Erd˝os Problem asks how large the total side length of n squares can be when all squares are placed inside the unit
square [0, 1]2 with disjoint interiors (Georgiev et al., 2025). Disjoint interiors means that squares may touch along edges
or at points, but any overlap of positive area is forbidden. Let C(n) denote the maximum achievable sum of side lengths
25


--- Page 26 ---
Contrastive Concept-Tree Search
under these constraints. Erd˝os specifically asked whether, for n = k2 + 1, one always has C(n) = k, extending the obvious
construction showing C(k2) = k (Bloom, 2026; Georgiev et al., 2025).
Here a candidate outputs n squares, each represented by a tuple (cx, cy, θ, s) specifying its center, rotation angle, and side
length. Following the description stated in (Georgiev et al., 2025), the evaluator first checks validity: all square vertices
must lie within [0, 1]2, side lengths must be nonnegative, and no two squares may intersect with positive area (boundary
contact is allowed). If any of these conditions fails, the configuration is declared invalid and assigned score −∞. If the
configuration is valid, the score is simply the sum of side lengths,
score =
n
X
i=1
si.
(44)
Thus, higher scores correspond to packings that place more total square edge length into the unit square without violating
the constraints. The basic formulation for the score is the same as that described in (Georgiev et al., 2025). Within this
formulation, in addition to checking the score, it is necessary to verify that the produced solution is optimal.
26
