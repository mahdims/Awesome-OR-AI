--- Page 1 ---
Algorithmic Prompt-Augmentation for Efficient
LLM-Based Heuristic Design for A* Search
Thomas Bömer1[0000−0003−4979−7455], Nico Koltermann2[0009−0008−0359−0452],
Max Disselnmeyer1[0009−0008−5689−2235], Bastian Amberg1[0000−0001−6715−3819],
and Anne Meyer1[0000−0001−6380−1348]
1 Karlsruhe Institute of Technology, Kriegsstraße 77, 76133 Karlsruhe, Germany
{thomas.boemer, max.disselnmeyer, bastian.amberg, anne.meyer}@kit.edu
2 TU Dortmund University, Leonhard-Euler-Straße 5, 44227 Dortmund, Germany
{nico.koltermann}@tu-dortmund.de
Abstract. Heuristic functions are essential to the performance of tree
search algorithms such as A*, where their accuracy and efficiency
directly impact search outcomes. Traditionally, such heuristics are
handcrafted, requiring significant expertise. Recent advances in large
language models (LLMs) and evolutionary frameworks have opened
the door to automating heuristic design. In this paper, we extend the
Evolution of Heuristics (EoH) framework to investigate the automated
generation of guiding heuristics for A* search. We introduce a novel
domain-agnostic prompt augmentation strategy that includes the A*
code into the prompt to leverage in-context learning, named Algorithmic
- Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH,
we study two problem domains: the Unit-Load Pre-Marshalling Problem
(UPMP), a niche problem from warehouse logistics, and the classical
sliding puzzle problem (SPP). Our computational experiments show that
A-CEoH can significantly improve the quality of the generated heuristics
and even outperform expert-designed heuristics.
Keywords: large language models · automated heuristic design · A* ·
prompt augmentation.
1
Introduction
Combinatorial optimization problems play a crucial role in logistics and
manufacturing. Solving such problems depends on heuristics to find high-quality
solutions in a reasonable time. The design of such heuristics, however, is
traditionally a knowledge-intensive and manual process, requiring deep domain
expertise and extensive experimentation [4]. This has motivated research into
methods that can automatically generate heuristics.
Recent advances in large language models (LLMs) have opened a promising
new
direction
for
automated
heuristic
design.
Several
frameworks
have
demonstrated how LLMs can serve as heuristic designers within an evolutionary
loop [29,21,33]. In these frameworks, LLMs generate candidate heuristic
arXiv:2601.19622v1  [cs.AI]  27 Jan 2026


--- Page 2 ---
2
T. Bömer et al.
functions, which are then evaluated on problem instances, and high-performing
heuristics are iteratively mutated and refined. These methods have achieved
encouraging results for constructive greedy search approaches. Especially, the
design of constructive heuristics for the Traveling Salesperson Problem (TSP)
and Online Bin Packing Problem (oBPP) seems to establish as a standard
benchmark introduced by the first works [29,21] and adapted by various
extensions and variations [33,8,32] in this emerging research field.
Current works in LLM-empowered automated heuristic design predominantly
study constructive heuristics in optimization domains that always yield feasible
solutions (even if far from optimal) like the TSP and oBPP. In contrast, many
optimization domains impose hard constraints or state-dependent restrictions
that limit feasible moves during search. In these cases, early decisions can
strongly influence the reachable parts of the search space, making simple greedy
approaches ineffective. A simple constructive heuristic cannot reliably find a
solution [1] or generalizes poorly [30]. For such problems, more structured
search algorithms such as the A* algorithm are required to efficiently explore
the solution space while potentially maintaining optimality guarantees through
an admissible heuristic [12].
In this study, we investigate the potential of LLMs to automatically
design heuristics suitable for guiding A* search. To explore this question, we
focus on two problem domains with contrasting characteristics: the Unit-Load
Pre-Marshalling Problem (UPMP) and the Sliding Puzzle Problem (SPP). The
UPMP involves determining a sequence of moves to reorder unit loads in a
block-stacking warehouse according to priority classes [25,?,2]. As a relatively
new problem introduced in 2023, the UPMP is scarcely represented in LLM
training data, and only a few handcrafted heuristics are currently available.
The SPP requires finding a sequence of moves that transforms a given initial
configuration into a target goal state [17]. In contrast to the UPMP, this problem
is a well-established benchmark in algorithmic research, studied extensively
since 1980s [17], with numerous heuristics proposed in both academic literature
[18,11,13] and informal implementations on platforms such as GitHub. Together,
these two domains enable a balanced evaluation, covering both a practical,
domain-specific problem with limited prior knowledge (UPMP) and a canonical,
well-studied benchmark (SPP).
While designing heuristics for problems such as the TSP and oBPP is
useful for initially benchmarking new automated heuristic design frameworks (for
example in [29,21,20,34,36,32,15]), we argue that the true value of automated
heuristic design lies in domains where few heuristics exist or where established
ones fail to perform effectively for specific instance configurations. The UPMP
exemplifies the former case, as only a limited number of handcrafted heuristics
are available. To represent the latter case, we study large sliding puzzles of size
20 × 20, for which pattern databases based state-of-the-art heuristics [7,18,10]
become impractical due to the computational cost of pattern precomputation.
Recent work showed that providing additional problem context can
significantly enhance the quality of LLM-generated constructive heuristics for


--- Page 3 ---
Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design
3
the UPMP, particularly for smaller LLMs [1]. We refer to this augmentation
as Problem - Contextual Evolution of Heuristics (P-CEoH). However, the
main limitation of P-CEoH is the problem context still depends on the human
formulating. To address this limitation, we newly introduce Algorithmic -
Contextual Evolution of Heuristics (A-CEoH) that embeds key elements
of the A* algorithm code into the prompt to guide the LLM toward generating
heuristics that align with A*’s search dynamics. The core structure of the A* is
problem-agnostic and hence easily transferable. A-CEoH aims to leverage heuristic
generation by providing problem insights through code. We are building on the
Evolution of Heuristics (EoH) by [21] to investigate the new A-CEoH, the
adapted P-CEoH [1], and a combination of both augmentations named PA-CEoH
for the generation of A* guiding-heuristic for the UPMP and SPP. The main
contributions of this paper are:
– New application field: We demonstrate the potential of LLM-based
automated heuristic design to evolve an A* guiding-heuristic for a niche
optimization problem and a well-studied optimization problem.
– Algorithmic - Contextual Evolution of Heuristic: We show that
including
algorithmic
context
in
prompts
significantly
improves
the
performance of generated heuristics.
– Performance boost for small models: We illustrate that algorithmic
context
enables
small,
locally
deployed
LLMs
to
outperform
large,
general-purpose LLMs.
– Outperforming
handcrafted
heuristics:
We
compare
the
LLM-generated heuristics with hand-crafted heuristics from the literature
and show the superiority of the LLM-generated heuristics for the target
instance configuration.
The rest of the paper is organized as follows. Section 2 briefly introduces
the two studied combinatorial optimization problems. Section 3 provides an
overview of solution approaches to the covered optimization problems, as well
as automated heuristic design approaches using LLMs. Section 4 presents the
evolutionary procedure and the proposed contextual augmentations. Section 5
presents the results of computational experiments. Finally, Section 6 summarizes
the findings and outlines future research directions.
2
Unit-load Pre-marshalling and Sliding Puzzle Problem
The Unit-load Pre-marshalling Problem (UPMP), introduced in 2023 by [25],
is about sorting unit loads in a block-stacking warehouse using autonomous
robots. The goal is to sort unit loads by priority so that high-priority items can
be accessed without being blocked with the minimal number of moves. A unit
load is considered blocking if it prevents access to a higher-priority unit load, for
example one that needs to be retrieved sooner. During pre-marshalling, no new
unit loads enter or leave.


--- Page 4 ---
4
T. Bömer et al.
Figure 1 shows a one-tier single-bay warehouse from a top-down view, where
unit loads are accessed only from the north. In the initial state (0), three
unit loads block access to higher-priority ones. After three moves (state 3), all
blockages are resolved.
State
0
1
2
3
2
4
5
3
2
2
2
1
2
3
4
5
3
3
2
4
5
3
2
1
2
3
4
5
3
2
2
2
4
5
2
2
1
2
3
4
5
2
3
2
2
4
5
3
2
3
2
4
5
3
2
1
1
Column
Row
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
1
2
3
4
Fig. 1: Example sequence of moves to solve an unit-load pre-marshalling problem
instance by [1]. Top-down view of a single-bay. Unit loads can be accessed from
the north direction only.
The Sliding Puzzle Problem (SPP) is a classic combinatorial optimization
problem that has served as a benchmark for search algorithms since the 1980s
[17]. It involves rearranging tiles on a grid into a specified goal configuration by
sliding them into an adjacent empty space. The objective is to reach the target
arrangement with the minimal number of moves, where each move shifts one
tile horizontally or vertically into the empty cell, changing the puzzle’s overall
configuration.
Figure 2 shows a 3×3 sliding puzzle (also called 8-puzzle). In the initial state
(0), three tiles are misplaced. By sliding tiles into the empty position, the correct
order is gradually restored. After three moves (state 3), the puzzle reaches its
solved configuration.
1
2
3
3
Row
1
1
2
3
2
4
5
4
3
7
8
6
7
3
1
7
8
7
8
8
6
6
1
2
3
State
0
1
2
3
2
3
1
2
3
Column
1
2
1
3
6
5
4
1
2
2
5
4
5
Fig. 2: Example sequence of moves to solve a 3×3 sliding puzzle. Tiles are moved
into the empty cell to reach the goal configuration.


--- Page 5 ---
Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design
5
3
Related Work
In this section, we first present related work on pre-marshalling problems and
the sliding puzzle problem. Following this, we present studies employing LLMs in
an evolutionary framework to develop heuristics for combinatorial optimization
problems.
3.1
Related Work on Pre-marshalling
For the UPMP in single-bay block-stacking warehouses, [25] propose a two-stage
solution approach. In the first stage, a network flow formulation is employed
to decompose the warehouse bay into virtual lanes. In the second stage, an
A* algorithm determines a solution that minimizes the total number of moves.
Building upon this work, [6] extend the approach to multi-bay warehouse
environments, aiming to minimize the loaded travel distance while maintaining
the minimal number of reshuffling moves. Subsequently, [2,5] further enhance
this approach by introducing a sequential scheme that allocates the moves
generated by the tree search to multiple robots. This allocation considers
move dependencies and is optimized through a mixed-integer programming
formulation.
The
pre-marshalling
of
unit
loads
in
block-stacking
warehouses
is
conceptually related to the Container Pre-Marshalling Problem (CPMP) in
maritime logistics, where containers within a bay must be rearranged until all
target stacks are free of blockages. Among the solution strategies proposed for
the CPMP—including greedy heuristics [9], dynamic programming [26], integer
programming [19,24], and constraint programming [28,16] tree search approaches
have proven particularly effective. Tree search methods [3,31,14] systematically
explore the solution space by branching on possible moves and applying heuristic
or learned guidance to prune suboptimal states.
Heuristic and exact methods have been developed for both the UPMP
and CPMP to minimize the number of moves; however, their design typically
demands substantial algorithmic and domain-specific expertise.
3.2
Related Work on Sliding Puzzles
The SSP, including the 8- and 15-puzzle, has long served as a key benchmark
for heuristic search, and finding optimal solutions for the general n × n
case is NP-hard [27]. Research on the 15-puzzle accelerated with the work
of Korf [17], who showed that iterative-deepening-A*, combined with the
Manhattan distance heuristic, was capable of producing the optimal solutions
to random puzzle instances. The authors of [11] introduced the linear conflict
heuristic through a systematic method for generating admissible enhancements
to Manhattan distance. A recent work [13] proposed a human-designed
hybrid heuristic—combining Manhattan distance, linear conflicts, and walking
distance—within a bidirectional A* framework, yielding substantial reductions
in generated states. Pattern databases (PDBs) further advanced performance.


--- Page 6 ---
6
T. Bömer et al.
The authors of [7] demonstrated large speed-ups using disjoint PDBs,
enabling optimal solutions to the 24-puzzle. Additive heuristics [18] allowed
multiple PDBs to be combined while preserving admissibility, and later work
[10] introduced static and dynamic partitioning strategies that produced
state-of-the-art admissible heuristics.
Although PDB-based methods dominate standard puzzle sizes, their memory
and preprocessing demands make them infeasible for very large configurations
such as the 20 × 20 puzzles considered in this work.
3.3
Automated Heuristic Design with LLMs
The development of LLM-based automated heuristic design was initiated by
Google DeepMind’s FunSearch [29] framework, and a range of subsequent
approaches have built on its core idea. This section provides an overview:
FunSearch [29] integrates a pre-trained LLM with evolutionary search for
algorithm discovery. Starting from simple hand-written heuristic code, the LLM
generates new program code whose performance on benchmark instances is
evaluated and stored. EoH [21] represents heuristics as both natural-language
thoughts and executable code, refining both in parallel through a prompting
scheme with two exploration and three modification strategies. It outperforms
manual heuristics and FunSearch while requiring far fewer LLM queries (2,000 vs.
one million for oBPP). P-CEoH [1] extends EoH with detailed, problem-specific
contextual information to support constructive heuristic generation for niche
combinatorial problems. Applied to the UPMP, it shows that smaller models
like Qwen2.5-Coder-32B can generate heuristics outperforming larger models
and those from standard EoH. ReEvo [33] augments evolutionary search with
reflective reasoning. Its five-stage workflow—selection, short-term reflection,
crossover, long-term reflection, and elitist mutation—uses repeated reflection to
guide heuristic generation and consolidate insights from parent performance.
HSEvo [8] combines evolutionary operators with harmony search and a
reflection mechanism (flash reflection). The authors aim to support diversity and
tune elitist heuristic parameters via harmony search. Hercules [32] enhances
prompt efficiency via a reflection mechanism (Core Abstraction Prompting),
which extracts key structure from elite heuristics, and reduces evaluation
time via Performance Prediction Prompting, which estimates the heuristic
fitness using semantic similarity with curated examples. LLM-LNS [34] applies
LLM-driven heuristic evolution to Mixed Integer Linear Programming through
Large Neighborhood Search. An inner layer evolves thoughts and code, while an
outer layer adjusts prompts to maintain diversity.
LLaMEA [22] uses an LLM-guided evolutionary process to generate
full metaheuristic algorithms for continuous black-box optimization. The
LLM iteratively refines or redesigns the best algorithm using performance
feedback, producing methods that outperform state-of-the-art metaheuristics.
The
domain-specific
extension
in
[35]
applies
LLaMEA
to
photonics
using structured, domain-aware prompts and varied evolutionary strategies.
Combining LLM-generated problem descriptions with algorithmic insights


--- Page 7 ---
Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design
7
improves
performance
on
two
of
three
tested
continuous
optimization
benchmarks.
These studies demonstrate that LLMs can generate effective heuristics for
combinatorial optimization. Since FunSearch and EoH, numerous extensions have
added mechanisms such as reflection and diversity control. Because our work
isolates the effects of prompt augmentation, we use EoH as our base framework:
it offers strong prompt efficiency, a modular design, and ensures comparability
with prior work such as P-CEoH[1].
4
Integrating Algorithmic Context into Heuristic Design
This section describes the adapted evolutionary framework Evolution of
Heuristics (EoH) by [21] and the adapted Problem - Contextual Evolution of
Heuristics (P-CEoH) by [1] briefly. Further, we explain the newly introduced
prompt augmentation strategy Algorithmic - Contextual Evolution of Heuristics
(A-CEoH). For illustrative examples of the prompt template and prompt
augmentation elements, we refer to our repository 3. Table 1 shows the core
components of each experimental setup. All versions adapt the evolutionary
procedure to evolve heuristics in the form of Python code and an underlying
thought. P-CEoH adds an additional problem description as described in [1].
A-EoH instead adds an algorithmic context to leverage in-context learning and
the development of a more targeted evolution for the algorithmic environment.
PA-CEoH includes both: the additional problem description and algorithmic
context to the prompt.
Table 1: Core components included in EoH, P-CEoH, P-CEoH, and PA-CEoH.
Component
EoH P-CEoH A-CEoH PA-CEoH
Evolutionary procedure
✓
✓
✓
✓
Heuristic (code + thought)
✓
✓
✓
✓
Additional problem description
✓
✓
Algorithmic description
✓
✓
The Figure 3 shows the evolutionary EoH framework and the prompt strategy
variations we discuss in this paper. The additional problem description and the
algorithmic context are highlighted. The original framework is grey and blue in
Figure 3.
Evolutionary Procedure. The evolutionary framework follows an iterative process
that constructs and refines a collection of heuristics over multiple generations.
3 https://github.com/tb-git-tud/a-ceoh-evolution-of-heuristics


--- Page 8 ---
8
T. Bömer et al.
Evaluation
Specifications
Best heuristic code
Three Prompt Strategy Variants
Programs Database
Code 1
Thoughts 1
Code 2
Thoughts 2
...
Code n
Thoughts n
Heuristic
Generator LLM
Code
Thoughts
+ problem description
P-CEoH
E2
E1
Exploration
Modification
M1
M2
EoH
E2
E1
Exploration
Modification
M1
M2
A-CEoH
E2
E1
Exploration
Modification
M1
M2
+ algorithm
+ problem description
PA-CEoH
E2
E1
Exploration
Modification
M1
M2
+ algorithm
Fig. 3: The EoH framework (grey and blue) evolves code and thoughts. The
prompt augmentation components additional problem description (red) and
algorithmic context (green) aim to support the evolutionary procedure.
Each heuristic h ∈H = {1, 2, . . . , |H|} consists of two components: executable
program code and accompanying thought. The program code is implemented
as a Python function with a clearly defined input–output interface, while
the thought captures the conceptual reasoning expressed by the LLM during
heuristic creation.
The
procedure
progresses
through
a
sequence
of
generations
G
=
{1, 2, . . . , |G|}. The population of heuristics in a given generation g ∈G is
represented as Pg = {1, 2, . . . , |Pg|}. Within each generation, a set of prompt
strategies S = {1, 2, . . . , |S|} is employed to produce the next population from
the heuristics of the preceding generation using a pre-trained LLM. Every
strategy s ∈S is applied ¯r times, yielding a total of |S| · ¯r new heuristics for
generation g.
Each newly produced heuristic h is evaluated on a collection of problem
instances I = {1, 2, . . . , |I|}, where its performance is quantified by a fitness
score f I(h). After evaluation, h is added to the current population Pg, and the
process continues until all heuristics for the generation have been created. At
the end of each generation, the top-performing ¯n heuristics are retained and
carried over to the next generation. An initialization phase generates the initial
population P0 by requesting an initial prompt 2 · ¯n times.
Heuristic Prompt Strategies This work employs the prompt strategies by [21],
including the initialization prompt I1, two exploration prompts (E1 and E2),
and two modification prompts (M1 and M2). The following summarizes the
functionality of each strategy.
I1: Formulate a heuristic aimed at solving the given optimization task.
E1: Develop a heuristic that differs substantially from ¯p parent heuristics
sampled from the current population.


--- Page 9 ---
Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design
9
E2: Generate a heuristic that retains the core conceptual idea of ¯p parent
heuristics while offering a new variation.
M1: Revise an existing parent heuristic from the population to enhance its
effectiveness.
M2: Modify the parameter configuration of a parent heuristic from the
population to improve its overall performance.
Each prompt consists of these elements: (1) task description, (2) algorithmic
context, (3) additional problem description, (3) parent heuristic(s) (not in I1), (4)
strategy-specific output instructions, and (5) additional instructions. We detail
each component in the following.
The (1) task description informs the LLM about the optimization problem
and how the heuristic will be used in a bigger context. The (2) algorithmic
context provides the LLM with the precise algorithmic environment in which its
heuristic is applied. Figure 4 shows the algorithmic context provided for the SPP
as an example. It begins by presenting the complete A* driver procedure, which
defines the overall search logic, including the initialization of the open list, node
expansion, and goal detection. This code shows how the heuristic value h(n),
computed via the LLM-generated function score_state(state), is combined
with the path cost g(n) to form the evaluation function f(n) = g(n) + h(n).
After the driver, the context includes the core methods that define the problem’s
search space and objective structure: (a) is_goal() specifies the objective of the
search; (b) get_neighbors() generates successor states and thus determines
how the search tree expands; (c) reconstruct_path() rebuilds the sequence
of actions leading to a found goal; and (d) get_objective_value() quantifies
solution quality according to the task’s optimization criterion. Together, these
components convey how the heuristic integrates into the A* search process, how
it influences node prioritization, and how the resulting solution is evaluated.
Because this structure is domain-agnostic, the same prompt format can be used
for different optimization problems simply by substituting the corresponding
functions. The (3) additional problem description (adapted from [1])
enhances the prompt with contextual details about the optimization setting,
supporting stronger in-context understanding by the LLM. It first outlines the
expected structure of the input data that the heuristic will process. Then, it
clarifies the interpretation of the individual components within the problem
domain. Next, it specifies problem-specific constraints. Finally, it supplements
the description with illustrative examples of both input and output data.
The (4) parent heuristic(s) are supplied as code snippets accompanied
by their underlying thoughts. These examples act as few-shot demonstrations
that guide the LLM’s generation process, helping it identify structural and
conceptual patterns from prior heuristics. The (5) strategy-specific output
instructions determine how the LLM should formulate its response. They define
the expected structure of the output—both the heuristic’s reasoning (thought)
and its executable program code with well-defined inputs and outputs—tailored
to the respective prompt strategy. Finally, the (6) additional instructions
impose essential implementation and stylistic constraints. To ensure logical


--- Page 10 ---
10
T. Bömer et al.
coherence, self-consistency is required so that the generated Python function
aligns with its corresponding thought [23].
1
def
astar_puzzle_core (heuristics , start_puzzle ):
2
open_list = []
3
visited = set ()
4
evaluated_nodes = 0
5
counter = itertools.count ()
6
7
root = PuzzleNode(start_puzzle , g=0, heuristic_fn =heuristics.score_state )
8
heapq.heappush(open_list , (root.f, next(counter), root ))
9
visited.add(root.serialize ())
10
start = time.monotonic ()
11
12
while
open_list:
13
# Timeout / node
cap
check
14
if (( time.monotonic () - start) > TIMEOUT_SECONDS
or
15
evaluated_nodes
> MAX_EVALUATED_NODES ):
16
return
return_result (False)
17
18
_, _, current = heapq.heappop(open_list)
19
20
if
current.is_goal ():
21
return
return_result (True)
22
23
for
neighbor
in
current. get_neighbors (heuristics. score_state ):
24
state = neighbor.serialize ()
25
if state in
visited:
26
continue
27
evaluated_nodes
+= 1
28
visited.add(state)
29
heapq.heappush(open_list , (neighbor.f, next(counter), neighbor ))
30
31
def
is_goal(self ):
32
flat = [num for row in self.puzzle
for num in row]
33
return
flat == list(range (1, self.N * self.N)) + [0]
34
35
def
get_neighbors (self , heuristic_fn ):
36
neighbors = []
37
r, c = self.find_blank ()
38
directions = {(-1, 0): ’U’, (1, 0): ’D’, (0,
-1): ’L’, (0, 1): ’R’}
39
for (dr , dc), move in
directions.items ():
40
nr , nc = r + dr , c + dc
41
if 0 <= nr < self.N and 0 <= nc < self.N:
42
new_puzzle = deepcopy(self.puzzle)
43
new_puzzle[r][c], new_puzzle[nr][nc] = new_puzzle[nr][nc], new_puzzle[r][c]
44
neighbors.append(PuzzleNode(new_puzzle , self.g + 1, heuristic_fn , parent=self , move=move ))
45
return
neighbors
46
47
def
reconstruct_path (node ):
48
path = []
49
while
node.parent is not
None:
50
path.append (( node.move , node.puzzle ))
51
node = node.parent
52
return
list(reversed(path ))
53
54
def
get_objective_value (self ):
55
if not
self.is_goal ():
56
return
MAX_MOVES
57
return
len(self. reconstruct_path (self ))
Fig. 4: Algorithmic context for the SPP.
5
Computational Experiments
We conducted extensive experiments to show the model-specific effects of
A-CEoH, P-CEoH, and PA-CEoH.
Evolutionary Parameters. Each framework version (EoH, P-CEoH, A-CEoH, and
PA-CEoH) is executed ten times per LLM for the UPMP and five times per LLM


--- Page 11 ---
Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design
11
for the SPP. All versions use the initialization prompt I1, called 40 times, with
the 20 best heuristics forming the initial population. Heuristics evolve over 20
generations using prompt strategies E1, E2, M1, and M2, each invoked ¯r = 20
times per generation, resulting in 20·4·20 = 1600 prompts per run. The number
of parent heuristics for E1 and E2 is set to p = 5.
Evaluation Parameters. For the UPMP, we use a 60 s time limit and a node
limit of 100,000 per instance; unsolved instances are penalized with mmax =
100. Evaluation instances use a single-bay 5 × 5 layout (one tier, north access),
five priority classes, and a 60 % fill rate. For the SPP, we apply a 60 s time
limit and a node limit of 1,000,000; unsolved instances receive mmax = 200.
We consider large 20 × 20 puzzles generated by 200 random moves, a scale at
which pattern-database heuristics are impractical (published with code). For
both problems, we use ten training instances (seeds 0–9). All experiments were
conducted on an AMD EPYC 7401P with 64 GB RAM.
Fitness Calculation Each heuristic h is evaluated over a set of instances I. Let mi
denote the number of moves required to solve instance i, and mlb
i a lower bound
on the required moves. For the UPMP, lower bounds follow [25]; for the SPP, we
use the number of misplaced tiles, which suffices for qualitative comparisons. If
h fails to solve instance i, we set mi = mmax ≫mlb
i . The fitness is defined as
the average relative deviation from the lower bound (Eq. 1) and is minimized.
Since mlb
i is not necessarily optimal, a fitness of zero is generally unattainable.
f I(h) = 1
|I|
X
i∈I
mi −mlb
i
mlb
i
(1)
Effect of Context. Figure 5 illustrates the distribution of fitness values for the
best heuristic identified by each LLM. The detailed results for the UPMP are
shown in Figure 5a, and those for the SPP in Figure 5b. For the UPMP, the
newly introduced A-CEoH consistently outperforms the EoH baseline in both the
best-found heuristic and the median fitness across all evaluated models. The
adapted P-CEoH achieves strong performance for the Qwen2.5-Coder:32b and
GPT4o:2024-08-06, although it exhibits instability for the Gemma2:27b. The
combined variant, PA-CEoH, delivers the best overall results, demonstrating that
integrating both prompt augmentations provides complementary benefits across
all tested models. Multiple runs acquire the best reachable fitness value of 0.0815.
For the SPP, the Qwen2.5-Coder:32b benefits most from the newly
introduced algorithmic context in A-CEoH. The best SPP heuristic was generated
by Qwen2.5-Coder:32b in the A-CEoH setup with a fitness value of 0.445. In
contrast, the P-CEoH augmentation setup does not improve heuristic quality
for the Qwen2.5-Coder:32b. The larger GPT4o:2024-08-06 achieves moderate
improvements in performance through prompt augmentation but fails to
surpass a fitness value of 0.6, suggesting convergence to a local optimum.
Gemma2:27b struggles to produce competitive heuristics for the SPP, except in
a few isolated runs in the P-CEoH setup. Overall, the smaller, coding-oriented


--- Page 12 ---
12
T. Bömer et al.
Qwen2.5-Coder:32b generates significantly stronger heuristics than the larger
GPT4o:2024-08-06. Especially with the new A-CEoH prompt context.
Gemma2:27b
Qwen2.5-Coder:32b
GPT4o:2024-08-06
Model
0.10
0.15
0.20
0.25
0.30
0.35
0.40
0.45
0.50
Best Fitness
Framework
EoH
A-CEoH
P-CEoH
PA-CEoH
(a) UPMP
Gemma2:27b
Qwen2.5-Coder:32b
GPT4o:2024-08-06
Model
0.5
0.6
0.7
0.8
0.9
Best Fitness
Framework
EoH
A-CEoH
P-CEoH
PA-CEoH
(b) SPP
Fig. 5: Best heuristic fitness in each experimental run for each model for the
UPMP and SPP. Lower values indicate better performance. The fitness scale for
the UPMP plot is truncated at 0.5 and at 1 for the SPP. Each boxplot reports
ten runs for the UPMP and five runs for the SPP.
3
6
9
12
15
18
Generation
0.1
0.3
0.5
0.7
1
Fitness
EoH
3
6
9
12
15
18
Generation
A-CEoH
3
6
9
12
15
18
Generation
P-CEoH
3
6
9
12
15
18
Generation
PA-CEoH
Fig. 6: Fitness of the best found heuristic by Qwen2.5-Coder:32b for the UPMP
across generations for each experiment run. The best run for each experimental
setup is shown with opacity. Lower values indicate better performance.
Figure 6 illustrates the convergence of fitness values across generations
for each prompt augmentation strategy applied to the Qwen2.5-Coder:32b
model for the UPMP task. The A-CEoH approach enables the LLM to generate
reasonably good heuristics early in the evolutionary process but exhibits
difficulty converging toward better fitness values. In contrast, the experimental


--- Page 13 ---
Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design
13
runs under the P-CEoH setting begin similarly to the base EoH configuration,
but the inclusion of additional problem context allows the model to identify
improvements more reliably. Finally, the combined PA-CEoH strategy leverages
the strengths of both augmentations—adopting the A-CEoH’s ability to produce
good heuristics early on while benefiting from the P-CEoH’s capacity to achieve
stronger overall improvements.
Comparison
with
Human-designed
Heuristics.
We
compare
the
best
LLM-generated heuristics with A* guiding-heuristics proposed in prior work.
To ensure a fair evaluation, the heuristics from the literature are adapted
and integrated into our A* implementation so that only the guiding-heuristic
component differs. We limit the solution time to 600 seconds. Fitness and
solution time are reported on average for the solved instances.
Table 2 presents the comparison between the two best heuristics generated
for the UPMP and the optimal heuristic introduced by [25]. For the training
instances (seeds 0–9), the LLM-generated heuristics achieve optimal fitness
values while solving the instances faster. On an additional 30 test instances (seeds
10–39), the LLM-generated heuristics successfully solve cases that the optimal
implementation fails to solve, while remaining near-optimal in performance.
Table 2: Comparison of the best LLM-generated UPMP A* guiding-heuristics
with an optimal A* implementation from the literature.
PA-CEoH
Qwen2.5-Coder:32b
GPT4o:2024-08-06
Optimal A* [25]
seeds
solved
fitness
time
solved
fitness
time
solved
fitness
time
0–9
10
0.0815
0.0888
10
0.0815
0.1953
10
0.0815
0.2773
10–39
30
0.1388
0.151
30
0.1055
0.098
27
0.0968
0.44
Table 3 compares the best LLM-generated heuristic for the SPP with a
human-designed hybrid heuristic [13] and an optimal implementation based on
Manhattan distance and linear conflicts [11]. The generated heuristic is able to
solve instances that both benchmark heuristics cannot. Considering only the five
instances solved by both the optimal approach and the LLM-generated heuristic
for seeds 0–9, the LLM-generated heuristic achieves a fitness value of 0.281, which
is a 0.031 gap to the optimal 0.252 fitness value. Moreover, the LLM-generated
heuristic achieves significantly shorter runtime while maintaining fitness values
comparable to the optimal approach for seeds 10–19.
Token Usage
Table 4 reports the mean input and output token counts
per prompt for both problems using Qwen2.5-Coder:32b. Adding contextual
information substantially increases input tokens (PA-CEoH ≈×2) compared to
EoH while generally reducing output tokens, indicating more focused generation.


--- Page 14 ---
14
T. Bömer et al.
Table 3: Comparison of the best LLM-generated SPP A* guiding-heuristics with
a heuristic and an optimal A* implementation from the literature.
A-CEoH
Qwen2.5-Coder:32b
Hybrid Heuristic A* [13]
Optimal A* [11]
seeds
solved
fitness
time
solved
fitness
time
solved
fitness
time
0–9
10
0.445
17.417
5
0.539
56.587
5
0.252
137.55
10–19
7
0.392
16.272
6
0.479
189.51
6
0.375
187.91
Table 4: Mean number of input and output tokens per prompt for the
Qwen2.5-Coder:32b for the UPMP and SPP.
EoH
A-CEoH
P-CEoH
PA-CEoH
Input
Output
Input
Output
Input
Output
Input
Output
UPMP
1046
259
1642
178
1474
230
2223
215
SPP
1477
401
2245
387
2823
378
3330
305
6
Conclusion
This study demonstrated that LLMs can autonomously design effective A*
guiding-heuristics for complex combinatorial optimization problems. Building
on the EoH framework, we introduced A-CEoH, a novel prompt augmentation
strategy that embeds the A* code structure directly into LLM prompts. We
compared A-CEoH with the P-CEoH, an adapted approach from the literature
that enhances prompts with domain-specific problem context. Experiments on
the UPMP and the SPP showed that incorporating algorithmic context in
A-CEoH leads to a strong improvement in heuristic quality compared to the
original EoH baseline. When both augmentations were combined in PA-CEoH,
the results improved further for the UPMP, demonstrating that algorithmic and
problem-specific context provide complementary benefits for the studied niche
optimization problem. For the well-studied SPP, the performance of the PA-CEoH
did not exceed that of the A-CEoH. Across both problem domains, the smaller
coding-oriented model Qwen2.5-Coder:32b performed on par with or better than
the much larger GPT4o:2024-08-06, highlighting that well-structured contextual
prompts can outweigh model size. A comparison of the LLM-generated heuristics
with human-designed A* guiding-heuristics from the literature showed superior
performance of the LLM-generated heuristics. These findings emphasize the
importance of algorithm-aware prompt design and represent a step toward
automated, context-sensitive heuristic discovery for constrained optimization
tasks. Future work will extend the problem-agnostic idea of algorithmic context
to additional combinatorial problems and to other algorithmic frameworks such
as large neighborhood search.


--- Page 15 ---
Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design
15
Acknowledgments. This research was funded by the Ministry of Science, Research
and Arts of the Federal State of Baden-Württemberg - InnovationCampus Future
Mobility - funding code BUP59 FitLLM and the European Union - NextGenerationEU
- funding code 13IK032I.
References
1. Bömer,
T.,
Koltermann,
N.,
Disselnmeyer,
M.,
Dörr,
L.,
Meyer,
A.:
Prompt-augmentation for evolving heuristics for a niche optimization problem.
In: Marcelloni, F., Madani, K., van Stein, N., Filipe, J. (eds.) Computational
Intelligence. pp. 214–235. Springer Nature Switzerland, Cham (2026)
2. Bömer, T., Koltermann, N., Pfrommer, J., Meyer, A.: Sorting multibay block
stacking storage systems with multiple robots. In: International Conference on
Computational Logistics. pp. 34–48. Springer (2024), https://doi.org/10.1007/
978-3-031-71993-6_3
3. Bortfeldt, A., Forster, F.: A tree search procedure for the container pre-marshalling
problem. European Journal of Operational Research 217(3), 531–540 (2012). https:
//doi.org/10.1016/j.ejor.2011.10.005
4. Burke, E.K., Gendreau, M., Hyde, M., Kendall, G., Ochoa, G., Özcan, E., Qu,
R.: Hyper-heuristics: A survey of the state of the art. Journal of the Operational
Research Society 64(12), 1695–1724 (2013)
5. Bömer, T., Disselnmeyer, M., Meyer, A.: A constraint programming approach
for the multi-robot multibay unit load pre-marshalling problem. Procedia CIRP
134, 508–513 (2025). https://doi.org/https://doi.org/10.1016/j.procir.2025.02.
151, https://www.sciencedirect.com/science/article/pii/S2212827125005359, 58th
CIRP Conference on Manufacturing Systems 2025
6. Bömer, T., Pfrommer, J., Akizhanov, D., Meyer, A.: Sorting multi–bay block
stacking storage systems. Computers & Operations Research 188, 107359
(2026). https://doi.org/https://doi.org/10.1016/j.cor.2025.107359, https://www.
sciencedirect.com/science/article/pii/S0305054825003880
7. Culberson, J.C., Schaeffer, J.: Pattern databases. Computational Intelligence
14(3), 318–334 (1998)
8. Dat, P.V.T., Doan, L., Binh, H.T.T.: Hsevo: Elevating automatic heuristic design
with diversity-driven harmony search and genetic algorithm using llms. arXiv
preprint arXiv:2412.14995 (2024)
9. Expósito-Izquierdo, C., Melián-Batista, B., Moreno-Vega, M.: Pre-marshalling
problem: Heuristic solution method and instances generator. Expert Systems with
Applications 39(9), 8337–8349 (2012)
10. Felner, A., Korf, R.E., Hanan, S.: Additive pattern database heuristics. Journal of
Artificial Intelligence Research 22, 279–318 (2004)
11. Hansson, O., Mayer, A., Yung, M.: Criticizing solutions to relaxed models
yields
powerful
admissible
heuristics.
Information
Sciences
63(3),
207–227
(1992). https://doi.org/https://doi.org/10.1016/0020-0255(92)90070-O, https://
www.sciencedirect.com/science/article/pii/002002559290070O
12. Hart,
P.E.,
Nilsson,
N.J.,
Raphael,
B.:
A
formal
basis
for
the
heuristic
determination of minimum cost paths. IEEE Transactions on Systems Science and
Cybernetics 4(2), 100–107 (1968). https://doi.org/10.1109/TSSC.1968.300136
13. Hasan, D.O., Aladdin, A.M., Talabani, H.S., Rashid, T.A., Mirjalili, S.: The fifteen
puzzle—a new approach through hybridizing three heuristics methods. Computers
12(1), 11 (2023)


--- Page 16 ---
16
T. Bömer et al.
14. Hottung, A., Tanaka, S., Tierney, K.: Deep learning assisted heuristic tree search
for the container pre-marshalling problem. Computers & Operations Research 113,
104781 (2020)
15. Huang, Z., Wu, W., Wu, K., Wang, J., Lee, W.B.: Calm: Co-evolution of
algorithms and language model for automatic heuristic design. arXiv preprint
arXiv:2505.12285 (2025)
16. Jiménez-Piqueras, C., Ruiz, R., Parreño-Torres, C., Alvarez-Valdes, R.: A
constraint programming approach for the premarshalling problem. European
Journal of Operational Research 306(2), 668–678 (2023). https://doi.org/10.1016/
j.ejor.2022.07.042
17. Korf, R.E.: Depth-first iterative-deepening: An optimal admissible tree search.
Artificial Intelligence 27(1), 97–109 (1985). https://doi.org/https://doi.org/10.
1016/0004-3702(85)90084-0,
https://www.sciencedirect.com/science/article/pii/
0004370285900840
18. Korf, R.E., Felner, A.: Disjoint pattern database heuristics. Artificial Intelligence
134(1),
9–22
(2002).
https://doi.org/https://doi.org/10.1016/S0004-3702(01)
00092-3, https://www.sciencedirect.com/science/article/pii/S0004370201000923
19. Lee, Y., Hsu, N.Y.: An optimization model for the container pre-marshalling
problem. Computers & operations research 34(11), 3295–3313 (2007). https://
doi.org/10.1016/j.cor.2005.12.006
20. Liu, F., Liu, Y., Zhang, Q., Tong, X., Yuan, M.: Eoh-s: Evolution of heuristic set
using llms for automated heuristic design. arXiv preprint arXiv:2508.03082 (2025)
21. Liu, F., Xialiang, T., Yuan, M., Lin, X., Luo, F., Wang, Z., Lu, Z., Zhang, Q.:
Evolution of heuristics: Towards efficient automatic algorithm design using large
language model. In: Forty-first International Conference on Machine Learning
(2024)
22. Liu, S., Chen, C., Qu, X., Tang, K., Ong, Y.S.: Large language models as
evolutionary optimizers. In: 2024 IEEE Congress on Evolutionary Computation
(CEC). pp. 1–8. IEEE (2024)
23. Min, M.J., Ding, Y., Buratti, L., Pujar, S., Kaiser, G., Jana, S., Ray, B.:
Beyond accuracy: Evaluating self-consistency of code large language models with
identitychain. arXiv preprint arXiv:2310.14053 (2023)
24. Parreño-Torres, C., Alvarez-Valdes, R., Ruiz, R.: Integer programming models for
the pre-marshalling problem. European Journal of Operational Research 274(1),
142–154 (2019). https://doi.org/10.1016/j.ejor.2018.09.048
25. Pfrommer, J., Meyer, A., Tierney, K.: Solving the unit-load pre-marshalling
problem in block stacking storage systems with multiple access directions.
European Journal of Operational Research (2023). https://doi.org/10.1016/j.ejor.
2023.08.044
26. Prandtstetter, M.: A dynamic programming based branch-and-bound algorithm
for the container pre-marshalling problem. Technical repot, IT Austrian institute
of technology (2013)
27. Ratner, D., Warmuth, M.: The (n2- 1)-puzzle and related relocation problems.
Journal of Symbolic Computation 10(2), 111–137 (1990)
28. Rendl, A., Prandtstetter, M.: Constraint models for the container pre-marshaling
problem. In: ModRef 2013: The Twelfth International Workshop on Constraint
Modelling and Reformulation (2013), https://api.semanticscholar.org/CorpusID:
43049743
29. Romera-Paredes, B., Barekatain, M., Novikov, A., Balog, M., Kumar, M.P.,
Dupont, E., Ruiz, F.J., Ellenberg, J.S., Wang, P., Fawzi, O., et al.: Mathematical


--- Page 17 ---
Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design
17
discoveries from program search with large language models. Nature 625(7995),
468–475 (2024)
30. Sim, K., Renau, Q., Hart, E.: Beyond the hype: Benchmarking llm-evolved
heuristics for bin packing. In: International Conference on the Applications of
Evolutionary Computation (Part of EvoStar). pp. 386–402. Springer (2025)
31. Wang, Z., Zhou, C., Che, A., Gao, J.: A policy-based monte carlo tree
search method for container pre-marshalling. International Journal of Production
Research 62(13), 4776–4792 (2024)
32. Wu, X., Wang, D., Wu, C., Wen, L., Miao, C., Xiao, Y., Zhou, Y.: Efficient
heuristics generation for solving combinatorial optimization problems using large
language models. In: Proceedings of the 31st ACM SIGKDD Conference on
Knowledge Discovery and Data Mining V.2. p. 3228–3239. KDD ’25, Association
for Computing Machinery, New York, NY, USA (2025). https://doi.org/10.1145/
3711896.3736923, https://doi.org/10.1145/3711896.3736923
33. Ye, H., Wang, J., Cao, Z., Song, G.: Reevo: Large language models as
hyper-heuristics with reflective evolution. arXiv preprint arXiv:2402.01145 (2024)
34. Ye, H., Xu, H., Yan, A., Cheng, Y.: Large language model-driven large
neighborhood search for large-scale milp problems. In: Forty-second International
Conference on Machine Learning (2025)
35. Yin,
H.,
Kononova,
A.V.,
Bäck,
T.,
van
Stein,
N.:
Optimizing
photonic
structures with large language model driven algorithm discovery. arXiv preprint
arXiv:2503.19742 (2025)
36. Zhang,
S.,
Liu,
S.,
Lu,
N.,
Wu,
J.,
Liu,
J.,
Ong,
Y.S.,
Tang,
K.:
Llm-driven instance-specific heuristic generation and selection. arXiv preprint
arXiv:2506.00490 (2025)
