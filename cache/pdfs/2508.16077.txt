--- Page 1 ---
Cooperative Design Optimization through Natural Language
Interaction
Ryogo Niwa
OMRON SINIC X Corporation
Tokyo, Japan
The University of Tsukuba
Tsukuba, Japan
niwa.ryogo.ms@alumni.tsukuba.ac.jp
Shigeo Yoshida
OMRON SINIC X Corporation
Tokyo, Japan
shigeo.yoshida@sinicx.com
Yuki Koyama
National Institute of Advanced Industrial Science and
Technology (AIST)
Tsukuba, Japan
The University of Tokyo
Tokyo, Japan
koyama@pe.t.u-tokyo.ac.jp
Yoshitaka Ushiku
OMRON SINIC X Corporation
Tokyo, Japan
yoshitaka.ushiku@sinicx.com
Designer
Parameters
Cooperation through
Natural Language
BO with LLM
Decide Next Parameters to Test
User Test
App
x1
x2
x3
x4
Figure 1: Concept of cooperative design optimization through natural language interaction. The user interface designer iteratively
conducts user tests to discover the best design parameters (right side). During this process, the designer cooperates with our
system, a Bayesian optimization (BO) system extended with a large language model (LLM), to decide the condition to test
next (left side). The cooperation is done through natural language, offering the opportunity for flexible and cognitively easy
intervention in the optimization process.
Abstract
Designing successful interactions requires identifying optimal de-
sign parameters. To do so, designers often conduct iterative user
This work is licensed under a Creative Commons Attribution 4.0 International License.
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Â© 2025 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-2037-6/2025/09
https://doi.org/10.1145/3746059.3747789
testing and exploratory trial-and-error. This involves balancing mul-
tiple objectives in a high-dimensional space, making the process
time-consuming and cognitively demanding. System-led optimiza-
tion methods, such as those based on Bayesian optimization, can
determine for designers which parameters to test next. However,
they offer limited opportunities for designers to intervene in the op-
timization process, negatively impacting the designerâ€™s experience.
We propose a design optimization framework that enables natural
language interactions between designers and the optimization sys-
tem, facilitating cooperative design optimization. This is achieved by
arXiv:2508.16077v1  [cs.HC]  22 Aug 2025


--- Page 2 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
integrating system-led optimization methods with Large Language
Models (LLMs), allowing designers to intervene in the optimization
process and better understand the systemâ€™s reasoning. Experimen-
tal results show that our method provides higher user agency than a
system-led method and shows promising optimization performance
compared to manual design. It also matches the performance of an
existing cooperative method with lower cognitive load.
CCS Concepts
â€¢ Human-centered computing â†’Human computer interaction
(HCI); Systems and tools for interaction design.
Keywords
Human-in-the-loop optimization, large language models, Bayesian
optimization
ACM Reference Format:
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku. 2025.
Cooperative Design Optimization through Natural Language Interaction. In
The 38th Annual ACM Symposium on User Interface Software and Technology
(UIST â€™25), September 28-October 1, 2025, Busan, Republic of Korea. ACM, New
York, NY, USA, 25 pages. https://doi.org/10.1145/3746059.3747789
1
Introduction
Background. Designing successful interactions requires design-
ers to carefully explore and identify optimal design parameters
through iterative user testing. Manually performing this task is chal-
lenging due to high-dimensional parameter spaces, where designers
must consider both the relationships between design parameters
and their impact on the resulting design performance. Further-
more, there is a need to balance multiple objectives (e.g., speed,
accuracy) simultaneously, as has been pointed out by researchers
in human-computer interaction (HCI) [3, 4, 22, 36]. Consequently,
many iterations of user testing are required, demanding substantial
time and cognitive effort, with no guarantee of finding the opti-
mal solution. To address these issues, researchers have developed
human-in-the-loop design optimization approaches [4, 22], such
as using Bayesian optimization (BO) [32] as a backend. In these
approaches, the system leads the optimization processâ€”the system
decides the parameters to test next with computational reasoningâ€”
providing a more principled and efficient procedure than those with
manual decisions.
Motivation. However, fully system-led optimization has been
criticized for negatively impacting the design experience [4]. While
designers often have their own ideas and intuitions about the explo-
ration process, most system-led methods offer limited opportunities
for them to intervene in the optimization process. Without the abil-
ity to steer the optimization process, designers feel less sense of
agency and also miss opportunities to gain deeper insights into the
design problem.
Our Idea. This leads to the question: can we foster more cooper-
ative interactions between designers and optimization systems by
enabling communication through natural language? Natural lan-
guage offers the flexibility to steer the optimization processâ€”even
when designers have only a rough understanding of the design
space. Such an interface would allow designers to express their in-
tentions in natural language and understand the systemâ€™s reasoning
behind its suggestions, thereby guiding the optimization process
more effectivelyâ€”capabilities that are often limited in standard BO,
where the system leads the process with minimal room for inter-
vention. This design aligns with the principles of cooperative AI
[6], which emphasize shared understanding, communication, and
commitment in human-AI collaboration.
Our Approach. In this work, we propose the concept of coop-
erative design optimization through natural language (Section 3).
To realize this, we present a novel technique to integrate an LLM
with the BO-based optimization procedure (see Figure 1 and Sec-
tion 4), enabling designers to intervene through natural language
and understand the systemâ€™s intentions behind its suggestions. We
implement this technique in a working prototype system for de-
signing web apps. Through our user study with this prototype
system (Section 5), we explore the potential of this approach to
enhance the design experience compared to designer-led (manual)
and system-led approaches. Note that Mo et al. [28] recently pro-
posed a cooperative design optimization system based on a custom
BO technique, which allows designers to specify explicit constraints
on parameter ranges to consider. While we share the overall con-
cept of cooperative design optimization, our approach differs in
its interaction and implementation. We incorporate an LLM into
the BO process to support more flexible and interpretable inter-
actions through natural language. To understand the experiential
differences between the two approachesâ€”ours and that of Mo et
al.â€”we conducted an additional user study (Section 6) and report
the results.
Contributions. The contributions of this work are threefold.
(1) We introduce the concept of cooperative design optimization
through natural language, enabling flexible and interpretable
interactions with the optimization process.
(2) We present a novel technique that integrates an LLM with
the BO process, allowing the optimization behavior to be
guided by natural language.
(3) We discuss the potential benefit of natural language inter-
action based on the results of the user studies, highlighting
future challenges for improving the user experience.
2
Related Work
2.1
Human-in-the-Loop Design Optimization
In human-computer interaction (HCI), design optimization has typi-
cally been applied to two main problem settings. The first focuses on
maximizing subjective preferences, either from designers [17, 34]
or the general audience [18], often using preferential Bayesian opti-
mization (PBO) as a key technique. The second setting seeks to find
the optimal interaction by maximizing user performance metrics,
typically through iterative user testing. In this context, adaptive
experimental design [36] is employed to reduce participant burden
by adaptively adjusting testing conditions, rather than predefining
them, thus minimizing the number of participants required. BO is
commonly used as the backend algorithm for adaptive experimental
design [8, 15, 22, 36].


--- Page 3 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Our work addresses the second setting: design optimization with
iterative user testing. However, fully system-led optimization, while
computationally efficient, often overlooks the designerâ€™s intuition
and experience, leading to a suboptimal designer experience [4].
To address this, various efforts have sought to give designers more
control [16, 28]. Our work builds on these efforts, with Mo et al.â€™s
cooperative system [28] being the most closely related. However,
our approach differs by incorporating LLMs to enable more flexible
and interpretable natural language interactions, offering a novel
approach to cooperative design optimization.
2.2
Large Language Models for Optimization
Large Language Models (LLMs) are highly effective at grasping
context and utilizing their pre-existing knowledge, which makes
them suitable for tackling optimization problems [13]. Some ap-
proaches delegate the entire optimization process to an LLM instead
of using traditional algorithms. For instance, OPRO (Optimization
by PROmpting) generates solutions solely through natural lan-
guage prompts, removing the need for specialized optimization
procedures [35]. Another line of work describes the BO process in
natural language so that an LLM can replicate the BO search steps
[24].
In addition to these fully LLM-based methods, hybrid strategies
that embed an LLM into an existing optimization pipeline are gain-
ing attention. While some employ frameworks other than BO [10],
many focus on integrating LLMs into BO. Our work follows this
hybrid direction. For example, in one study, natural language de-
scriptions of chemical experiments are transformed into a semantic
feature space via an LLM and then used as input to BO for improv-
ing search performance [30]. Another study suggests replacing the
standard surrogate model in molecular design tasks with an LLM,
opening up new avenues for data-driven exploration [29].
More recently, several methods have combined an LLM directly
into the BO sampling process. SLLMBO randomly switches between
a Tree-structured Parzen Estimator (TPE) and an LLM-based sam-
pling at each iteration, balancing exploration and exploitation [25].
Another method, BORA, dynamically selects from three sampling
strategies based on the current context. Although these methods
perform well on single-objective tasks, their effectiveness in multi-
objective optimization remains unverified [5], and most of this work
focuses primarily on algorithmic performance. In contrast, our ap-
proach highlights cooperative design optimization, investigating how
natural language interaction between designers and systems can
enhance both user experience and optimization outcomes.
2.3
Collaborative Optimization Modeling
Recent studies view optimization as a collaborative process where
humans and optimization systems interact to find solutions, and
they investigate how to effectively support this interaction. One
research direction focuses on improving system transparency to
enhance user trust. For instance, it has been suggested that, in
addition to visualizing intermediate solutions, allowing users to
directly verify outputs and engage in trial-and-error helps foster ap-
propriate calibrated trust that reflects the systemâ€™s actual behavior
[23]. While this prior work focuses on understanding and building
designer trust in optimization systems, our research focuses on
how using natural language for interaction with the optimization
system affects the designer experience.
Other related studies use LLMs to bridge the communication gap
between users and optimization systems. Some methods translate
vague natural language inputs into formal constraints for optimiza-
tion solvers [19, 20, 27]. While these studies and ours both aim to
enable natural language-based user input, they differ in terms of
the optimization backend. Additionally, other approaches leverage
LLMs to automate the optimization modeling process, which re-
duces the need for specialized expertise [1, 12]. These approaches
mainly address the formulation phase of optimization, whereas our
approach intervenes during the execution phase by guiding the
selection of candidate solutions.
3
Interaction: Cooperative Design Optimization
through Natural Language Interaction
3.1
Target Design Tasks
The primary goal of this work is to identify optimal interactions by
exploring and fine-tuning design parameters in the target interac-
tive system. We specifically focus on scenarios where this task is
performed by UI/UX designers and HCI researchers refining their
systems through iterative user testing [4, 21, 22, 28]. Examples of
such tasks include optimizing hand-based pointing interactions
[4, 21], configuring haptic notifications on smartwatches [22], and
adjusting the visual design of web pages [28]. In these scenarios,
designers typically manipulate ğ‘›continuous design parameters
within finite value ranges, often controlled via sliders. The objec-
tive is to maximizeğ‘šperformance metrics, represented by objective
functions ğ‘“1, . . . , ğ‘“ğ‘š. Examples of such metrics include accuracy,
speed, and subjective ratings based on aesthetic preference.
Each objective function is evaluated through user testing, where
the performance metrics are measured. Since user testing is labor-
intensive and time-consuming, it is crucial to minimize the number
of required tests. This requires selecting informative test conditions
(i.e., parameter configurations to be tested) for each iteration. The
ultimate goal is to identify a Pareto front, a set of solutions where no
objective can be improved without worsening another, allowing de-
signers to understand the trade-offs between competing objectives.
The name â€œfrontâ€ comes from how these solutions form a boundary
when plotted, showing the edge of non-dominated solutions in the
objective space. Once the Pareto front is identified, the designer
selects a single solution from it based on their understanding of
these trade-offs.
3.2
Design Optimization Approaches
The simplest approach to design optimization is for the designer
to manually adjust the design parameters, which we refer to as
the designer-led method. This approach allows designers to freely
explore the design space based on their intuition, while also deep-
ening their understanding of the target design task. However, it
has been pointed out that this method makes it difficult to navigate
high-dimensional design spaces, often leading to fixation, where
designers repeatedly explore the same areas of the design space
without making significant progress [4].
In contrast, system-led design optimization methods, such as
those using BO, allow for more efficient and broad exploration of


--- Page 4 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
the design space [4]. However, these methods limit the designerâ€™s
ability to intervene in the optimization process, which can result in
a poorer designer experience, particularly in terms of the designerâ€™s
sense of agency [4].
Our approach, cooperative design optimization [28], aims to cre-
ate a flexible balance of control between the designer and the system.
Similar to system-led optimization, where the designer receives
suggested parameter values from the system, conducts evaluation
experiments, and measures performance, cooperative design op-
timization allows designers to intervene in the systemâ€™s behavior
and make final decisions. This approach not only leverages the com-
putational efficiency of system-led optimization but also enables
designers to apply their knowledge and intuition throughout the
process.
3.3
Cooperation through Natural Language
Previous work [28] introduced a specialized cooperative BO tech-
nique that allows designers to constrain the search space by explic-
itly specifying constraints (called â€œforbidden regionsâ€ and â€œforbid-
den rangesâ€). While this method enables the designer to control the
optimization process, it requires careful consideration and precise
input of specific values from the high-dimensional search space,
which can be burdensome.
Our proposed cooperative interaction differs from this approach
in two key ways:
(1) Designers can intervene in the sampling process (i.e., gener-
ating new parameters to test) using natural language. This
allows them to provide general requests in natural language
to guide the optimization, making the system-led optimiza-
tion process more cooperative.
(2) The system provides natural language explanations for why
the specific parameter values were proposed. This feature
helps designers better understand the systemâ€™s intention,
enabling them to plan the next steps in the optimization
process more effectively.
Additionally, designers can manually adjust the parameter values
to test next, either by selecting values entirely on their own or by
modifying the systemâ€™s suggestions. As in the previous work, this
flexibility allows designers to take full control of the optimization
process when desired.
3.4
System Interface and Interaction Scenarios
To facilitate effective interaction with the LLM, our system offers
the following features:
â€¢ A text box for specifying requests (if any) to the LLM,
â€¢ A button to calculate parameter proposals based on the re-
quests, and
â€¢ A display area for showing the LLMâ€™s reasoning.
In addition to these core features, our system inherits functionalities
from the previous system [28], enabling designers to interact with
the optimization process directly:
â€¢ Slider widget: This widget provides a set of sliders corre-
sponding to the target parameters. Designers can use it to
directly specify the set of parameters to test next. It also
reflects the parameter values proposed by the system imme-
diately after each suggestion, helping designers see exactly
what values were proposed.
â€¢ Parallel coordinates plot (PCP): This plot visualizes the ex-
plored parameter sets, helping designers understand the
relationships between parameters. The PCP is linked to the
objective chart, allowing designers to easily see how well
each parameter set performs.
â€¢ Objective chart: This chart visualizes the observed objective
(performance) values of the tested parameter sets. It also
highlights the most recently evaluated parameter set, making
it easier for designers to track and confirm recent results.
Refer to Figure 4 for a screenshot of the implementation used in
our study (note that the system in the screenshot contains some
user study-specific features such as formal and informal evaluation
buttons; we will describe these later).
Figure 1 illustrates a typical interaction scenario of LLM-based
cooperative design optimization. For example, in a web design sce-
nario, a designer may express a preference such as â€œI want to explore
variations with larger font sizesâ€ or provide an instruction based
on performance trade-offs, like â€œI want to find a design that priori-
tizes speed over accuracy.â€ The system then generates parameter
suggestions that reflect these requests.
Moreover, when the designer is uncertain about the rationale
behind a suggested parameter set, they can read the reasoning by
the system. For instance, the system might provide an explanation:
â€œThis suggestion focuses on maximizing accuracy in an area of the
design space that has not yet been explored.â€ This explanation helps
the designer understand the systemâ€™s intentions, allowing them to
decide to either accept the proposed parameters for further testing,
modify them based on their intuition, or provide a different request
for generating alternative parameters.
4
Technique: LLM-Guided Bayesian
Optimization
We integrate an LLM into the BO process to realize cooperative
design optimization through natural language interaction. In each
iteration, the system selects a single point (i.e., a set of parameter
values) to be evaluated next with the help of an LLM (Section 4.3)
from multiple candidates generated by a batch BO technique (Sec-
tion 4.2). In this way, we can integrate the designerâ€™s request into
the optimization process. See Figure 2 for an overview of the system
procedure.
4.1
Problem Formulation
By iteratively conducting user testing, we want to solve the follow-
ing multi-objective optimization problem:
max
xâˆˆX[ğ‘“1(x), . . . , ğ‘“ğ‘š(x)],
(1)
where x is a vector of ğ‘›design parameters to adjust, X âŠ‚Rğ‘›is
the search space, and ğ‘“ğ‘–: X â†’R is the ğ‘–-th objective function
(performance metrics such as speed and accuracy). In each step,
we choose a single parameter set xâ€², conduct a user test using xâ€²,
and then observe performance values ğ‘“1(xâ€²), . . . , ğ‘“ğ‘š(xâ€²). The final
outcome of the optimization process is a Pareto front.


--- Page 5 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Candidates from Batch BO
Selected Parameters
+ Reason by LLM
Task Information: { This is a restaurant map site... }
User Request: { â€œIncrease Visibility... â€ }
Evaluation History: {
    1: { x1: 0.6, x2: 12, ..., visibility: 1.4, accuracy: 76},
    2: { x1: 0.7, x2: 30, ..., visibility: 1.1, accuracy: 70},
    ...
    15: { x1: 0.5, x2: 48, ..., visibility: 0.7, accuracy: 93}
}
Candidate Points from batch BO: {
    1: { x1: 0.8, x2: 20, ..., estimated visibility: 1.5,  
          estimated accuracy: 72},
    2: { x1: 0.6, x2: 35, ..., estimated visibility: 1.9, 
           estimated accuracy: 84},
    ...
    8: { x1: 0.9, x2: 10, ..., estimated visibility: 1.2, 
           estimated accuracy: 60}
}
Prompt for LLM
                To help users find 
restaurants more eaisly, Iâ€™ve 
increased the text size and 
adjusted the icon transparency.
x1: 0.6
x2: 35
x3: 3.2
x4: 40
x5: 25
Figure 2: Overview of the system procedure. In each step, our system first samples ğ‘candidates (ğ‘= 8 in this figure) using a
technique called batch BO. Then, the LLM receives a prompt consisting of the task information, the designerâ€™s request, the
previously evaluated parameter-performance pairs, and the predicted performance of the candidates. Finally, it chooses the
parameter set that best meets the designerâ€™s request and provides its reason for that choice in natural language.
4.2
Batch Bayesian Optimization-Based
Generation of Next Candidates
Surrogate Model. Following the standard choice, we use a Gauss-
ian Process (GP) as the surrogate model for each objective. Our
implementation uses the default setting of BoTorch [2] for this
purpose.
Acquisition Function. An acquisition function is a measure that
BO uses to decide which points to sample next. Although any acqui-
sition function can be employed in principle, we use qLogNEHVI [7]
as our acquisition function, which is a state-of-the-art acquisition
function for multi-objective problems. It is an extension of NEHVI
(Noisy Expected Hypervolume Improvement), which uses the ex-
pected improvement in hypervolume to locate promising candidate
points while accounting for predictive uncertainty. qLogNEHVI ex-
tends NEHVI to batch sampling (i.e., selecting multiple points that
have high acquisition values and maintain diversity), so it can pro-
pose multiple candidate points at once in each iteration.
Batch Sampling. Using the batch BO technique, we sample ğ‘
candidate points {x1, x2, . . . , xğ‘} in each iteration. In standard batch
BO settings, these candidate points are expected to be evaluated
in parallel. However, our approach uses these candidate points
differently; we use the LLM to select only one point from the ğ‘
candidates and then conduct the evaluation of the selected point.
We repeat this process, feeding the observed objective values back
into the GP and incorporating the designerâ€™s request at each step.
4.3
LLM-Guided Candidate Selection and
Reasoning
Among the ğ‘candidate points generated through the batch BO
technique, the LLM identifies the point that best aligns with the
designerâ€™s natural language requests. It also generates a natural
language explanation of its decision so that the designer can un-
derstand why the system chose those particular parameter values.
4.3.1
Prompt. The prompt given to the LLM begins with the main
instruction: â€œBased on the userâ€™s request described below, select the
index of the candidate point and provide a reason for your choice.â€
This is followed by the following information.
Task Information Explanation of the design task, including
the overall description, the meaning and range of each param-
eter, and the meaning and range of each objective function.
Candidate Points Each candidate point contains the acqui-
sition function value, as well as the predictive mean and
variance (potentially unnormalized) from the GP. When nec-
essary, we revert these values to the same scale the designer
sees in the interface. If the unnormalized predictive mean
exceeds its defined range, we clip it to the maximum (or
minimum) to avoid confusion for the designer.
Evaluation History List of the previous observations. Each
observation is a pair of the parameter set and its observed
objective values.
Designerâ€™s Request A sentence provided by the designer to
express their preferences or goals. For example, they might
write, â€œI want the interface to be more visually accessible,â€
or give a brief and abstract guideline. If left blank (i.e., the
text box is empty), this part of the prompt is also left blank.
We provide more details in Appendix A. Furthermore, a technical
evaluation of how faithfully the LLM selects candidates according
to the designerâ€™s request is discussed in Appendix B.
4.3.2
LLM Outputs. Given the prompt, the LLM outputs the index
of the chosen candidate point and the reason for that choice. For
example, it might say: â€œTo meet the goal of increasing user revenue,
I selected the candidate that uses a larger number of ads.â€


--- Page 6 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
4.4
Overall Procedure
In summary, the overall procedure is as follows.
(1) Obtain Initial Samples
Begin the BO process with a small
set of parameter sets (chosen randomly or via an experimen-
tal design).
(2) Batch Sampling
Train a surrogate model for each objec-
tive function using the observed data, and then use the batch
BO technique to sample ğ‘candidate points {x1, x2, . . . , xğ‘}.
(3) Selection by the LLM
Ask the LLM to select the single
best point from the ğ‘candidates that best aligns with the
designerâ€™s requests and to generate an explanation of its
decision in natural language.
(4) Evaluation and Update
Evaluate the selected point via
user testing, observe the objective values, and then re-train
the surrogate models with this new data.
(5) Iteration
Repeat Steps 2â€“4.
5
User Study 1: Comparing Levels of Control
This study aims to examine how differences in the levels of con-
trol affect both user experience and optimization performance in
a design optimization task. Participants were asked to complete
design optimization tasks for web applications using three distinct
ways: entirely relying on the designer (Designer-led), entirely re-
lying on the optimizer (BO-led), and our proposed method, which
enables cooperation with the optimization system through natural
language (Cooperative (Natural Language)).
We formed the following hypotheses:
â€¢ Hypothesis 1.1 (H1.1): Providing natural language instruc-
tions to the optimization system and receiving explanations
for its suggestions improve usersâ€™ sense of agency on design
optimization tasks.
â€¢ Hypothesis 1.2 (H1.2): Providing natural language instruc-
tions to the optimization system and receiving explanations
for its suggestions improve optimization performance.
This study was approved by the ethics review board of the au-
thorsâ€™ institution.
5.1
Study Design
Our study design largely followed the approach used in previous
work [28] by Mo et al. and we customized their publicly available
system1 for our study. The key difference here is that we used our
proposed system for the cooperative optimization condition instead
of theirs.
5.1.1
Condition. To ensure that each participant could experi-
ence all three approaches firsthand and to facilitate direct com-
parisons of agency, user experience, and optimization performance,
we structured our study with a within-participant design. Specif-
ically, within this design, each participant was exposed to three
conditions: Designer-led, BO-led, and Cooperative: Natural Language.
Designer-led Participants were able to adjust the parameters
by manipulating sliders on the UI.
1https://github.com/georgemo535/D3MOBO
BO-led Participants received parameter suggestions from a
multi-objective BO system and were not allowed to adjust
the values themselves using sliders.
Cooperative: Natural Language Participants could both ad-
just parameters using sliders and request suggestions from
the LLM. They were able to communicate with LLM through
natural language, such as specifying the type of parameters
they wanted or asking for clarification about the sugges-
tions. In this section, we refer to this condition simply as
Cooperative.
The order of conditions and design tasks was counterbalanced
across participants to mitigate potential order effects.
5.1.2
Target Design Tasks and Simulated User Testing with Synthetic
Test Functions. We wanted participants to use interfaces under
different conditions and reflect on their relative advantages and
disadvantages. To achieve this, it was necessary to conduct the study
using a within-participant design. Additionally, different tasks were
required for each condition to prevent learning effects. However,
conducting actual user testing in a design optimization task is time-
consuming and makes it challenging to quantitatively compare the
difficulty of each prepared optimization task.
To address this challenge, we adopted an alternative evaluation
method following previous work [28]: instead of actually perform-
ing user testing, simulate it using synthetic test functions. We also
adopted their design optimization tasks for three web applications
(see Figure 3 for screenshots). This approach could save the time
needed to perform each design task, making our within-participant
study design feasible.
In all three web applications, the number of design parameters
is five (ğ‘›= 5), and the number of objective functions is two (ğ‘š= 2).
The design parameters include, for example, â€œicon transparencyâ€,
â€œicon sizeâ€, â€œtext sizeâ€, and so on. The objectives differ among the
three web applications, but typical examples are â€œaverage speedâ€
and â€œaccuracyâ€. Refer to Appendix C for the full details of param-
eters and objectives. In the optimization process, parameters are
normalized to [0, 1], and objectives are normalized to [âˆ’1, 1]. Thus,
all objective functions have a domain of [0, 1]5 and a range of
[âˆ’1, 1]2.
Mo et al. aimed to ensure that the difficulty in finding the op-
timal trade-off design across these test functions is nearly identi-
cal. Therefore, they designed the functions to have similar forms
with the same final Pareto hypervolume. In realistic design sce-
narios, the objective functions are expected to be nearly convex,
and multiple modes are rare. The behavior of the objective func-
tions in prior research can justify this [8]. Thus, they designed
the test functions as quadratic functions for each objective (ğ‘—=
1, 2), where the optimal value is ğ‘ğ‘—, the position of the optimum
is ağ‘—=

ğ‘ğ‘—1,ğ‘ğ‘—2,ğ‘ğ‘—3,ğ‘ğ‘—4,ğ‘ğ‘—5
, and the scaling factors are bğ‘—=

ğ‘ğ‘—1,ğ‘ğ‘—2,ğ‘ğ‘—3,ğ‘ğ‘—4,ğ‘ğ‘—5

. Specifically, the function has the form:
ğ‘“ğ‘—(x) = ğ‘ğ‘—âˆ’
5
âˆ‘ï¸
ğ‘–=1
ğ‘ğ‘—ğ‘–
 ğ‘¥ğ‘–âˆ’ğ‘ğ‘—ğ‘–
2 .
(2)
Exact values of ağ‘—, bğ‘—,ğ‘ğ‘—are provided in Appendix C.
5.1.3
Formal and Informal Evaluations. Following previous work
[28], we prepared two types of evaluation methods: formal and


--- Page 7 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
(a) App 1: Social Networking Service
(b) App 2: Q&A Message Board
(c) App 3: Restaurant Map
Figure 3: Web application design tasks used in Study 1 and Study 2. The visual appearance of each application changes according
to the associated parameter values. For example, in App 1 (Social Networking Service), increasing the â€˜density of adsâ€™ parameter
results in a higher number of â€˜Buy!â€™ icons. We took these screenshots with all parameters set to their medium values. These are
based on the publicly available implementation by Mo et al. [28]: https://github.com/georgemo535/D3MOBO.
informal evaluations.2 Formal evaluation simulates rigorous user
testing to measure target performance metrics accurately. In con-
trast, informal evaluation simulates quicker but less accurate testing
(e.g., conducted with fewer test users). While the results of formal
evaluations are used in the optimization process (in the BO-led and
Cooperative conditions), the results of informal evaluations are not
used for optimization; instead, they help participants better under-
stand the design space and plan which parameter set to evaluate
formally next.
To simulate the timing and accuracy differences between these
two evaluation methods, we applied the following artificial delay
and noise:
â€¢ For formal evaluations, we added small uniform noise sam-
pled from Uniform(âˆ’0.05, 0.05) to the performance metrics.
The result was made available 20 seconds after the partici-
pant requested a formal evaluation.
â€¢ For informal evaluations, we added larger uniform noise sam-
pled from Uniform(âˆ’0.25, 0.25) to the performance metrics.
The result was made available 3 seconds after the participant
requested an informal evaluation.
We chose these specific noise ranges and delays, following Mo
et al. [28], to reflect typical differences in testing rigor and resource
usage.
5.1.4
Initial Seed. As Mo et al. have noted, the systemâ€™s behavior
during the first few iterations can be unreliable due to limited data,
and it is therefore advisable not to rely on the system at such an early
stage. To address this, random sampling is often used during the
first few iterations [9]. Recent studies have specifically set the initial
seeding to five iterations [24, 26]. Our preliminary observations
also suggested that the LLMâ€™s behavior stabilizes after about five
iterations. Based on these considerations, we decided to disable the
2Mo et al. [28] called heuristic evaluation, rather than informal evaluation; these terms
indicate the same concept.
parameter proposal function during the first five iterations in our
implementation.
5.1.5
Number of Samples per Batch. A larger batch size allows our
method to choose from a broader set of candidate points, which
increases the chance of finding one that aligns with the designerâ€™s
request. However, setting it too high increases computational over-
head and ultimately delays when the system can propose a new
option that meets the designerâ€™s needs. To maintain a balance be-
tween variety and responsiveness, we decided, based on empirical
observations, to set the batch size to ğ‘= 8.
5.2
User Interface for Cooperative Condition
through Natural Language
Figure 4 illustrates the interface used in the Cooperative condition,
which consists of three panels and five components.
5.2.1
Set Parameters Panel. Figure 4 (a) shows a set of sliders that
allow participants to manually adjust design parameters at any
time. Each slider corresponds to a specific parameter, and changes
are immediately reflected in the application. For instance, in App 3
(Restaurant Map, Figure 3 (c)), increasing the parameter â€œLocation
Icon Sizeâ€ enlarges the red icon displayed at the center of the map.
Figure 4 (b) includes a text box and an â€œAsk AI for a New Designâ€
button. Participants can convey their preferences to the optimiza-
tion system by entering natural language requests in the text box
and pressing the â€œAsk AI for a New Designâ€ button. Even without
entering a request in the text box, pressing the button retrieves
parameter suggestions from the system. The suggested parameter
values are then automatically applied to the slider.
The panel also provides a history of interactions with the opti-
mization system in natural language. Each time parameter values
are retrieved, they are accompanied by an explanation describing
the reasoning behind the suggestion.


--- Page 8 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
Figure 4: The design interface for the Cooperative: Natural Language condition used in Study 1 and Study 2. (a) A set of sliders
for manually adjusting parameter values, which are immediately reflected in the application. (b) Users can interact with the
optimization system using natural language, where users can input requests to the system and receive suggested parameter
values along with textual explanations. (c) Buttons for conducting simulated evaluationsâ€”either informal or formalâ€”to assess
the performance of the current parameter values. These buttons are used only in the user study interface to mimic user testing
without involving real participants. (d) Objective chart showing the objective values obtained from evaluations, with the Pareto
front highlighted (green line). (e) A parallel coordinates plot (PCP) showing the history of explored parameter values.
5.2.2
Evaluate Panel. Figure 4 (c) shows the buttons for informal
and formal evaluation. Participants can evaluate the current param-
eter values on the slider by pressing either button.
5.2.3
Check and Analyze Results Panel. Figure 4 (d) shows the
objective chart, which visualizes the observed objective values
obtained from formal and informal evaluations. Results obtained
through informal evaluations are plotted in blue circles, while those
from formal evaluations are shown as orange circles. The most re-
cent informal and formal evaluation results are highlighted using
solid blue and orange dots. The Pareto front is visualized by connect-
ing the relevant points with green lines. A checkbox allows users
to toggle the visibility of the results from informal evaluations.
Figure 4 (e) shows the parallel coordinates plot (PCP), which
visualizes all previously explored parameter values. Parameters
evaluated through informal evaluation are visualized with blue


--- Page 9 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
dotted lines, while those evaluated through formal evaluation are
shown as orange dotted lines. The most recent informal and infor-
mal evaluation parameters are visualized with solid blue and orange
lines. Clicking on any of these dotted or solid lines restores the
corresponding parameter values on the slider to help participants
easily revisit previously explored parameters.
5.3
Participants
We recruited 18 participants (11 males and 7 females; average age:
28.94, standard deviation: 9.88). All participants had prior experi-
ence related to UI/UX design: 11 had practical experience in UI/UX,
6 had experience in software development, and 1 had academic
experience. We specifically recruited participants with prior expe-
rience in UI/UX design through a social media post and personal
outreach. They were paid around $17 for the compensation. The
user study was conducted remotely, with communication via Zoom,
and participants performed the design tasks through a web browser.
5.4
Procedure
The following outlines the steps of the procedure in the user study.
The entire study lasted approximately 1.5 to 2 hours.
(1) The study began with a guidance phase, where participants
were shown a detailed video explaining the concept of param-
eter optimization and the idea of Pareto front. This was to fa-
miliarize the participants with the context of multi-objective
design. We also told the participants about the context of
designing a web interface for a technology company as a
design optimization task.
(2) Following this, they watched a video tutorial explaining the
ways they would engage in the design task to ensure the
participants utilize the interactive features of the provided
interface for the task. For example, if the task was under
the Designer-led condition, the participants were introduced
to the idea that an informal evaluation can provide an intu-
itive understanding of the optimization task. For the BO-led
condition, they were introduced that parameters can be ob-
tained by pressing the â€œGet Parameters from Systemâ€ button.
For the Cooperative condition, they were introduced to the
feature that parameters can be obtained by pressing the â€œAsk
AI for a New Designâ€ button, and the reasons for the sugges-
tions are also displayed.
(3) After viewing the tutorial video, participants completed a
task that involved optimizing two design parameters based
on two objective values. We gave the participants 5 minutes
to engage in the tutorial task. During this phase, if partici-
pants did not interact with specific interface features, those
features were explicitly explained to ensure a full under-
standing of the interface.
(4) Next, participants performed the main task, optimizing pa-
rameters in a web design application. They were instructed
to find three Pareto-optimal solutions during this task. The
task was capped at 20 minutes, but participants could finish
early after 15 minutes.
(5) Upon completing each task, participants were asked to fill
out a post-task questionnaire related to the specific condition
they had just experienced. The questionnaire was designed
based on the previous studies. Specifically, items addressing
design space understanding and exploration experience were
developed using [28] as a foundation, while the question-
naire items regarding agency were adapted with reference to
[33]. In the Cooperative condition, participants were asked
additional questions regarding the specific functionalities of
the system. They then returned to step (2) to proceed with
the next condition.
(6) After completing all three conditions, participants answered
a final questionnaire comparing all the interfaces they used.
(7) Finally, we conducted a 15-minute semi-structured inter-
view with each participant to gather additional qualitative
feedback about their experiences with the system and sug-
gestions for improvement.
5.5
Results
5.5.1
Pareto Set Discovery. Figure 5 shows the various Pareto
fronts obtained in the different conditions across the three appli-
cations. We visually examined the Pareto fronts and found that,
across all applications, the BO-led condition (blue) consistently ap-
pears in the upper-right region, indicating higher hypervolumes. In
App 1 and App 3, the Cooperative condition (red) lies between the
BO-led (blue) and the Designer-led (green). However, in App 2, the
Designer-led (green) and Cooperative (red) fronts occupy roughly
the same region. This result indicates that in App 1 and App 3, the
Cooperative condition achieved better optimization performance
than the Designer-led condition, whereas in App 2, both performed
comparably.
We computed six metrics regarding Pareto sets, as described
in [28], to quantitatively compare the three conditions based on
the obtained Pareto sets. In this section, we focus on the relative
hypervolume, while the other metrics are presented in Section E.2.
We choose this metric because it is widely used in multi-objective
optimization, offering a comprehensive comparison with an ideal
Pareto front.
Figure 6 shows a boxplot of the relative hypervolume for each
participant under each condition, normalized against the maxi-
mum hypervolume obtained in the corresponding application. A
Friedman test revealed a significant effect of condition (ğ‘= 0.000).
Multiple comparisons with Bonferroni correction indicated signifi-
cant differences between the Designer-led and BO-led conditions
(ğ‘.adj = 0.000), as well as between the BO-led and Cooperative con-
ditions (ğ‘.adj = 0.001). No significant difference was found between
the Designer-led and Cooperative conditions (ğ‘.adj = 0.071).
5.5.2
Subjective Experience. After each condition ended, partici-
pants answered the questions shown in Appendix D. The question-
naire was divided into two categories: (1) agency and (2) partici-
pantsâ€™ experience in understanding and exploring the design space.
We first checked whether each question item in both categories
satisfied normality. If normality was confirmed, we conducted a
repeated-measures ANOVA followed by paired t-tests with Bonfer-
roni corrections as a post-hoc analysis. If that analysis indicated
significant differences among the conditions, we then performed
paired t-tests with Bonferroni corrections. If normality was not
confirmed, we conducted a Friedman test followed by pairwise


--- Page 10 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
(a) App1.
(b) App2.
(c) App3.
Figure 5: Visualization of obtained Pareto fronts in Study 1. Green: Designer-led, Red: Cooperative, Blue: BO-led. Marker shapes
represent individual participants. In general, a Pareto front located closer to the top-right of the plot indicates better design
outcomes.
Figure 6: Boxplots of the relative hypervolume for the
Designer-led, BO-led, and Cooperative conditions.
Wilcoxon signed-rank tests with Bonferroni corrections. We present
the results below.
Agency. To evaluate participantsâ€™ overall sense of agency, we
computed an Agency Score by aggregating responses to the three
7-point Likert scale items (Q1, Q2, Q3) proposed by Wang et al. [33].
Specifically, we calculated the score as
Composite Score = ğ‘„1 âˆ’ğ‘„2 âˆ’ğ‘„3
(3)
, so higher values indicate a stronger sense of agency. Regarding this
score, the Friedman test indicated a significant difference among
the three conditions (ğ‘= 0.001). Post-hoc comparisons revealed
significant differences between the Designer-led and BO-led con-
ditions (ğ‘.adj = 0.002) and between the BO-led and Cooperative
conditions (ğ‘.adj = 0.002), but not between the Designer-led and
Agency Composite Score
(Q1 - Q2 - Q3) 
Figure 7: Boxplot showing the distribution of the agency
scores across conditions in Study 1. The scores are computed
from three agency-related questions (see Appendix D). Com-
pared to the BO-led condition, both the Designer-led and the
Cooperative conditions exhibit significantly higher agency.
Cooperative conditions (ğ‘.adj = 1.000). For a more detailed analysis
of Q1, Q2, and Q3, see Section D.1.1.
Design Space Understanding and Exploration Experience. First, we
checked each question for normality. We found that Q1, Q2, Q3, Q4,
Q6, and Q8 did not meet the normality assumption, so we applied
Friedman tests to those items; for Q5, which met normality, we
used a repeated-measures ANOVA. As a result, Q1 (ğ‘= 0.046), Q2
(ğ‘= 0.032), Q3 (ğ‘= 0.000), Q4 (ğ‘= 0.003), Q6 (ğ‘= 0.003), and Q8


--- Page 11 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
(ğ‘= 0.001) showed significant differences, while Q5 (ğ‘= 0.765)
and Q7 (ğ‘= 0.327) did not.
Next, we ran pairwise comparisons only for questions with sig-
nificant effects. For Q1, only BO-led vs. Cooperative was significant
(ğ‘.adj = 0.048); Designer-led vs. BO-led and Designer-led vs. Coop-
erative showed no significant difference. For Q2, a significant dif-
ference emerged between Designer-led and BO-led (ğ‘.adj = 0.048),
with no differences among the other pairs. In Q3, we found signif-
icant differences for Designer-led vs. BO-led (ğ‘.adj = 0.000) and
BO-led vs. Cooperative (ğ‘.adj = 0.001), but not for Designer-led vs.
Cooperative. Q4 showed significance only in BO-led vs. Coopera-
tive (ğ‘.adj = 0.005). Similarly, Q6 showed a significant difference
only between BO-led and Cooperative (ğ‘.adj = 0.028). Lastly, Q8
revealed significant differences for Designer-led vs. Cooperative
(ğ‘.adj = 0.037) and BO-led vs. Cooperative (ğ‘.adj = 0.002), while
Designer-led vs. BO-led was not significant.
Preference. Twelve participants preferred the Cooperative condi-
tion, three preferred the designer-led condition, and three preferred
the BO-led condition.
5.6
Discussion
We examined how our proposed system compared to other ap-
proaches regarding agency and optimization performance.
5.6.1
Cooperative Interaction Increases Sense of Agency. We found
a significant difference in the Agency Score between the BO-led and
Cooperative conditions. This result suggests that the proposed sys-
tem gives users a greater sense of agency than the BO-led condition.
Therefore, H1.1. is supported.
Participants described the experience of the cooperative condi-
tion as flexible and collaborative, with comments such as â€œI can
explore it manually when I want, and rely on the AI when I preferâ€
(P16) and â€œIt feels like weâ€™re working togetherâ€ (P3). Another partici-
pant noted, â€œMy intuition and the AIâ€™s proposal fit together nicelyâ€
(P3), highlighting the cooperative nature of the proposed method.
5.6.2
User-Aligned Selection Would Limit Optimization Performance.
When comparing the BO-led and Cooperative conditions, we ob-
served a significant difference in optimization performance, with
the BO-led condition achieving a higher performance. Meanwhile,
the Cooperative condition showed a higher median than the Designer-
led condition, although the difference was not statistically signif-
icant (ğ‘.adj = 0.071). While these results indicate that H1.2. is
not supported, these results suggest that the proposed cooperative
system can achieve optimization performance comparable to or
even exceeding manual human design. Notably, the effect size for
the comparison between the Cooperative and Designer-led condi-
tions was large (ğ‘Ÿ= 0.5333), providing supportive evidence for the
practical benefit of our cooperative approach.
From an algorithmic perspective, the BO-led condition sequen-
tially selects the candidate with the highest acquisition function
value in each iteration. In contrast, our proposed system uses batch
Bayesian optimization to generate candidate points and then relies
on the LLM to select a point that best aligns with the userâ€™s natural
language requests from the candidates. As a result, the system does
not always choose the point with the highest acquisition function
value, which may account for its lower optimization performance
compared to the BO-led condition.
6
User Study 2: Comparing Cooperation
Approaches
The aim of this experiment is to directly compare our approach
with the existing work by Mo et al.[28], which, like ours, pursues a
cooperative optimization process but with a different cooperation
approach. We call their approach Explicit Constraint: designers can
intervene in the optimization process by explicitly specifying areas
in the parameter space that they do not want to explore through a
GUI. Our proposed approach, by contrast, allows them to intervene
more flexibly through natural language.
To evaluate the effectiveness of our approach in supporting
humanâ€“AI collaboration, we focus on two key aspects: cognitive
load and trust. Natural language interaction enables designers to
make ambiguous or flexible requests, eliminating the need to spec-
ify explicit constraints or fully understand the entire parameter
space. This may help reduce cognitive load. In addition, providing
explanations in natural language may help designers understand
and accept the systemâ€™s decisions, thereby fostering a greater sense
of trust.
Based on these considerations, we formed the following hypothe-
ses:
â€¢ Hypothesis 2.1 (H2.1): Our approach imposes a lower cog-
nitive load than the Explicit Constraint condition.
â€¢ Hypothesis 2.2 (H2.2): Our approach has higher perceived
trustworthiness than the Explicit Constraint condition.
This study was approved by the ethics review board of the au-
thorsâ€™ institution.
6.1
Study Design
We largely followed the design and procedure from Study 1 but
introduced several changes. Specifically, the conditions differed,
and we modified some of the questionnaire items.
6.1.1
Condition. We employed a within-participant design in Study
2, where each participant experienced two conditions.
Cooperative: Explicit Constraint Proposed by Mo et al. [28],
this method allows participants to obtain parameter sugges-
tions either by adjusting sliders or through a customized BO
system. Participants can also specify, via a GUI, which re-
gions they do not want the system to explore. In this section,
we refer to this condition as Cooperative-EC.
Cooperative: Natural Language This condition is the same
as tested in Study 1. In this section, we refer to this condition
as Cooperative-NL.
We compared these two conditions across the three applications
used in Study 1. Each participant completed optimization tasks
for two of the three applications, experiencing one condition per
application. The assignment of conditions to applications was coun-
terbalanced across participants using a Latin Square design.
6.1.2
Measurements. To measure participantsâ€™ trust in the system,
we included items from the Multidimensional Trust Questionnaire


--- Page 12 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
(MTQ) [31]. The MTQ assesses trust across four subdimensionsâ€”
purpose, transparency, utility, and performanceâ€”using a 4-point
Likert scale from â€œDisagreeâ€ to â€œAgree.â€ It captures trust in au-
tomated systems by targeting each subdimension with specific
questions. Because our task made it hard for participants to judge
whether they achieved their goals, we omitted the performance
dimension. We also added the NASA-TLX [11] to measure the per-
ceived workload of participants.
6.2
Participants
We recruited 12 participants (8 males and 4 females; average age:
25.4, standard deviation: 1.83). Their backgrounds included 2 with
practical experience in UI/UX, 8 with experience in software devel-
opment, and 2 with academic experience. We specifically recruited
participants with experience in UI/UX design through a social me-
dia post and personal outreach. They were paid around $14 for
the compensation. The user study was conducted remotely, with
communication through Zoom, and the participants performed the
design tasks through a web browser. No participants from Study 1
took part in this study.
6.3
Result
6.3.1
Pareto Set Discovery. Figure 8 presents the Pareto fronts for
the Cooperative-EC (blue) and Cooperative-NL (red) conditions
across the three applications. Although there are minor differences
among the applications, a visual inspection indicates that both
conditions generally occupy similar regions in the Pareto space.
Following the methodology from Study 1 and building on Mo
et al. [28], we computed six metrics to quantitatively compare the
resulting Pareto sets. Here, we focus on the relative hypervolume
and refer readers to the appendix for the other metrics. Figure 9
shows a boxplot of the relative hypervolume for both conditions.
Because normality was not met, we conducted a Wilcoxon signed-
rank test, which revealed no significant difference between the
Cooperative-EC and Cooperative-NL) conditions (ğ‘= 0.204).
6.3.2
Subjective Experience. Before analysing the data, we checked
each measure for normality. We used a paired t-test for measures
that satisfied the normality assumption and a Wilcoxon signed-rank
test for those that did not.
NASA-TLX. We found a significantly lower weighted NASA-TLX
score for the Cooperative-NL condition (ğ‘= 0.034), as shown in
Figure 10. Among the NASA-TLX subscales, we focused on mental
demand (Q1) because it aligns most closely with our hypothesis on
cognitive load. A statistical test on Q1 also revealed a significant
difference (ğ‘= 0.000), indicating lower mental demand under the
Cooperative-NL condition.
Trust. We asked participants to rate three subscales (Purpose,
Transparency, and Utility), each consisting of three items on a 4-
point Likert scale. We then averaged the scores within each subscale
and applied Wilcoxon or paired t-tests, depending on normality. No
significant differences emerged between the Cooperative-EC and
Cooperative-NL conditions for Purpose (ğ‘= 0.090), Transparency
(ğ‘= 0.627), and Utility (ğ‘= 0.347).
Agency. We used the same Agency Score as in Study 1, where the
three 7-point Likert scale items (Q1, Q2, Q3) were aggregated accord-
ing to Equation 3. Higher values indicate a stronger sense of agency.
With only two conditions (Cooperative-EC and Cooperative-NL),
we performed a paired t-test and found a significant difference
(ğ‘= 0.032) favoring Cooperative-EC. This result aligns with the
observation that participants generally reported feeling more â€œin
chargeâ€ under the Cooperative-EC condition (see Section E.1.2 for
a detailed analysis of Q1, Q2, and Q3).
Design Space Understanding and Exploration Experience. We ob-
served a significant difference in Q1 (ğ‘= 0.039), favoring the
Cooperative-EC condition, and in Q7 (ğ‘= 0.021), favoring the
Cooperative-NL condition. The remaining items, all tested with
Wilcoxon (Q2: ğ‘= 0.142, Q3: ğ‘= 0.151, Q4: ğ‘= 0.431, Q5: ğ‘= 0.131,
Q6: ğ‘= 0.469, Q8: ğ‘= 0.394), were not significant.
Preference. Eight participants preferred the Cooperative-NL con-
dition, while four participants preferred the Cooperative-EC condi-
tion.
6.4
Discussion
6.4.1
Reducing the Need for Parameter-Space Understanding Lowers
Cognitive Load. The NASA-TLX scores show that participants expe-
rienced significantly lower cognitive load with the Cooperative-NL
condition than with the Cooperative-EC condition. Therefore, H2.1
is supported.
One participant (P2) said, â€œEven if I donâ€™t fully understand how
each parameter affects the outcome, I could just say â€™make it more
accurate!â€, showing how focusing on the desired outcome can lower
mental effort.
In contrast, the design interface in the Cooperative-EC condition
would raise cognitive demands because it requires designers to
specify forbidden regions, which multiple participants described as
â€œcognitively demanding.â€ One participant (P1) explained, â€œIt felt like
I had to do a lot of thinking. I needed to figure out â€˜this parameter
probably works better within that rangeâ€™ by myself, which took men-
tal effort.â€ Another participant (P10) added, â€œThe interface (in the
Cooperative-EC condition) was more mentally taxing. I had to think
about which instructions to give, depending on the goal.â€ Defining
forbidden regions requires a certain level of parameter-space un-
derstanding, making it more burdensome in higher-dimensional
problems.
Moreover, usage logs show that descriptions of desired outcomes
were a prominent feature in the vast majority of requests (79 out of
85) in the Cooperative-NL condition. We provide a more detailed
analysis of these queries in Section 7.4. This focus on outcomes sug-
gests that requesting the system â€œwhatâ€ to achieve, rather than â€œhowâ€
to achieve it, would substantially reduce participantsâ€™ cognitive load.
Compared to specifying forbidden regions, merely requesting the
desired outcome in natural language can lower designersâ€™ cogni-
tive load. While this goal-directed interaction is facilitated by the
natural language interface, we acknowledge that this cognitive
load reduction may come not only from the direct ease of natural
language control but also partly from an automation effect, as de-
signers are able to delegate the more complex task of parameter
manipulation to the system.


--- Page 13 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
(a) App1.
(b) App2.
(c) App3.
Figure 8: Visualization of obtained Pareto fronts in Study 2. Red: Natural Language (Ours), Blue: Explicit Constraint (Mo et al.
[28]). Marker shapes represent individual participants. In general, a Pareto front located closer to the top-right of the plot
indicates better design outcomes.
Figure 9: Boxplots of the relative hypervolume for the Ex-
plicit Constraint (Mo et al. [28]) and Natural Language (Ours)
conditions.
6.4.2
Why Natural Language Explanations Did Not Increase Trust
as Expected. We found no significant differences in average scores
or individual questions on Transparency. The other two MTQ items
(Purpose and Utility) also showed no significant differences in this
study. Therefore, H2.2 is not supported.
We expected that providing natural language explanations of
parameter suggestions in the Cooperative-NL approach would im-
prove transparency and increase trust. As Figure 11 shows, the
medians for Trust, Utility, and Purpose all tended to be higher
with Cooperative-NL, although the difference was not statistically
significant.
One possible reason is that some participants still felt uncertain
about â€œhow much their instructions were actually being followed,â€
which may have prevented a stronger increase in trust. For instance,
Figure 10: Boxplots of NASA-TLX [11] scores for the Explicit
Constraint (Mo et al. [28]) and Natural Language (Ours) condi-
tions in Study 2. The figure displays boxplots for the weighted
scores calculated from responses and pairwise comparisons
of all six NASA-TLX subscales.
one participant (P7) commented, â€œWe tried several things at first
with the proposed method, but in the end, we only tweaked the AIâ€™s
suggestions. Meanwhile, with the second tool (Cooperative-EC), I could
verify and adjust my requests all the time.â€ Another participant (P12)
said, â€œI trusted the second tool (Cooperative-EC) more overall, because
I felt like it was really listening to me.â€ These comments suggest that
simply having the AI explain its reasoning is not enough, making
it difficult to be sure â€œthe requests were really incorporated.â€
Cooperative-EC allows designers to visually confirm â€œwhich
region is forbiddenâ€ and see how the search proceeds, thus offering


--- Page 14 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
Transparency Score
Purpose Score
Utility Score
Figure 11: Boxplots of average scores for the three Trust dimensions (Purpose, Transparency, and Utility) from the Multidimen-
sional Trust Questionnaire [31] used in Study 2.
a concrete sense of control and reassurance. As one participant (P1)
noted, â€œI can see the big picture, so I feel comfortable and I know what
itâ€™s doing. That makes the first one I used (Cooperative-EC) feel more
tangible to me.â€ Another participant (P6) added, â€œAfter trying it out
for a while, I get a sense of what works and can narrow things down
by setting forbidden regions.â€
While Cooperative-NL reduces cognitive load, it also provides
fewer opportunities to deeply understand the parameter spaceâ€”
particularly in the early stages, when instructions may not be fully
applied. As a result, some participants might have found it diffi-
cult to feel â€œin control,â€ which may explain why Cooperative-EC
scored higher on agency. This factor likely contributed to the lack
of a statistically significant difference in transparency, despite our
assumption that natural language explanations would excel in this
regard.
7
Overall Discussion
This section reflects on the key findings from the two user studies,
discusses their implications for cooperative design optimization.
7.1
AI Suggestions Mitigate Design Fixation
Design fixation [4] is a phenomenon in which designers, while
maintaining a strong sense of agency, can become overly attached
to their initial ideas. In contrast, fully system-led approaches ex-
plore a wider range of possibilities but can undermine a designerâ€™s
sense of agency. Our method addresses these challenges by pro-
viding unexpected yet feasible suggestions within the designerâ€™s
chosen range. One participant commented: â€œEven within the range
I had explored, the AI suggested some surprising combinations that
sometimes led to the best results. I had moments of â€™Oh, I see!â€™ that
felt like real discoveries.â€ (Study 1, P1).
Contradictory rationales from the system can prompt designers
to question their assumptions, leading to a broader exploration of
parameter settings. Another participant described how a conflicting
rationale shifted their perspective: â€œWhen I got a reason that differed
from my expectationsâ€”like I wanted to increase user ratings, but it
turned out to boost adsâ€”I realized that even though I was trying
to ignore revenue, the system was still increasing ads. Surprisingly,
increasing ad parameters didnâ€™t hurt user ratings as much as I thought
it would.â€ (Study 2, P8).
These findings suggest that offering surprising yet valid sug-
gestions can challenge habitual thinking and expand designersâ€™
search space, helping mitigate design fixation while preserving a
designerâ€™s agency.
7.2
Explanations of AIâ€™s Reasoning Provide
Acceptance and Reassurance
Many participants noted that receiving â€œreasonsâ€ for parameter
suggestions made it easier to plan subsequent parameter explo-
rations. For example, one participant remarked, â€œBy having the
system logically explain the causal relationship between parameters
and outcomes, I could figure out which parameters to fix or adjust
next. It was very convenient, and I felt it was better than my own
approach.â€ (Study 1, P9) Similarly, another participant noted, â€œThere
were times when it would explain the reasons for its suggestions each
time, and based on that, I decided to give new requests.â€ (Study 2, P9)
Some participants found explanations especially helpful when
suggestions differed from their expectations, for instance: â€œWhen I
got a parameter suggestion different from my expectations, having
an explanation made it easier to accept.â€ (Study 2, P8). Others used
these explanations to check that the AIâ€™s reasoning matched their
own: â€œIt reassured me that the AIâ€™s thinking aligns with mine.â€ (Study
1, P4)
Taken together, these findings suggest that natural language
explanations not only supported participantsâ€™ decision-making dur-
ing the design exploration but also helped them accept unexpected
suggestions and feel reassured when the systemâ€™s reasoning aligned
with their own.
7.3
Explanations for Parameter Suggestions Are
Helpful but Need More Clarity and Depth
While many participants found the natural language explanations
helpful, some considered them unhelpful when they were overly
general or too lengthy. For instance, â€œIt just stayed with generic
reasonsâ€ (Study 1, P17) suggests that explanations lacking sufficient


--- Page 15 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
context or domain-specific insights may not offer meaningful guid-
ance. Meanwhile, â€œI felt the explanation was too longâ€ (Study 1, P18)
highlights the potential to increase cognitive load by our proposal.
One approach to address these issues is to structure the explana-
tions in two layers: a concise summary, then an optional detailed
view. Designers can quickly grasp the main points from the sum-
mary and refer to the more comprehensive explanation only if nec-
essary. Furthermore, explicitly prompting the LLM to â€œformulate
hypothesesâ€ encourages more targeted and actionable reasoning,
rather than just offering generic rationales.
7.4
Designers Tend to Specify What, Not How
We analyzed the content of the 187 natural language requests from
Study 1 and Study 2, manually applying multiple tags to each. We
used a two-category scheme: Target, to identify an instructionâ€™s
focus (Target: Outcome or Target: Parameter), and Type, to
describe its structural complexity. The instruction types were Type:
Simple (single-goal instructions), Type: Compound (instructions
with multiple parallel goals), and Type: Complex (instructions with
constraints or trade-offs difficult for GUIs to express).
This analysis revealed that designers primarily specified their
goals (â€œwhatâ€) over the actions to achieve them (â€œhowâ€). Of the 187
requests, 170 (90.9%) had a Target: Outcome tag, while only 31 had
a Target: Parameter tag, with 26 containing both. Furthermore,
the instructions showed varied complexity. Among the 170 requests
classified as instructions, 66 (38.8%) were Type: Simple, 69 (40.6%)
were Type: Compound, and 35 (20.6%) were Type: Complex. These
Type: Complex requests included instructions that are difficult to
express with sliders, such as weighting objectives (â€œignore revenue
and prioritize user ratingsâ€) or imposing numerical constraints (â€œset
the user rating to 4.0 or higherâ€). The remaining 17 requests were
categorized as Type: Inquiry/Other. These results show that our
natural language interaction could offer unique value, allowing
designers to focus on high-level goals while flexibly articulating
their complex intentions.
8
Limitations and Future Work
8.1
Trade-off between Candidate Diversity and
Interaction Efficiency
Some participants initially tried to adjust the exact parameter values
but were not satisfied with the outcomes. For example: â€œWhen I
asked for something like â€™set Objective1 to 80 or higher,â€™ it didnâ€™t seem
to match exactly.â€ (Study 1, P8) Highly specific requests tended to
fail when no available candidate satisfied them.
Over time, they shifted to giving broader requests and letting
the AI decide, which often led to better results and a stronger
sense that the system understood their intent: â€œInitially, I said â€™raise
parameter XX,â€™ but later I just described the result I wanted and
let the AI choose. That worked better.â€ (Study 1, P18). Such broad
requests (e.g., â€œimprove overall performanceâ€) often align with at
least one BO candidate, which helped participants feel that the
system understood their intent.
Since we used a batch size of ğ‘= 8 in both studies, increasing ğ‘
might provide more diverse candidates and better align with specific
user requests. However, a larger batch size may require more time
to sample candidates, which could negatively affect the efficiency of
the design exploration. This highlights a trade-off between diversity
and interaction efficiency. Determining the optimal batch size that
balances this trade-off remains an open question and is left for
future work.
8.2
Improving Early-Stage Accuracy of AI
Suggestions
Because the GP has limited predictive accuracy in the early stages,
batch BO may suggest candidates that do not match the designerâ€™s
requests. In the initial phase of the design task, some participants
felt that the system proposed off-target solutions: â€œCalling them
â€™off-targetâ€™ might sound harsh, but initially I saw values drifting to
the lower-left region. Still, since it wonâ€™t improve without trying,
I didnâ€™t think it was ignoring my requests. Overall, it listened to
about half of them.â€ (Study 2, P3) As more data accumulates, the
GP becomes more accurate, and later-stage proposals better reflect
the designerâ€™s request. Many participants noted this improvement
over time, highlighting a difference in responsiveness depending
on the phase of exploration. For example, one participant stated,
â€œBy the later stages, after the AI had accumulated more training data,
its accuracy improved.â€ (Study 1, P14)
An important direction for future work is improving early-stage
performance. For example, using more initial seed points could
boost early performance and give designers a stronger sense that
â€œthe system is listening.â€
8.3
Leveraging Predictive Confidence in
Interaction
One promising future direction is to enhance interaction by better
utilizing the systemâ€™s confidence about the performance prediction
and design proposals. Currently, our system incorporates the BOâ€™s
confidence (i.e., the predictive variance) into the LLM prompt. As a
result, the LLM occasionally generated relevant explanations such
as â€œthe variance is small, so this prediction is reliable,â€ even though
it is not explicitly instructed to reason about uncertainty. However,
this approach does not guarantee consistent communication of
uncertainty, which may lead to overconfidence or misunderstanding
on the part of designers. This issue is closely related to the broader
challenge of ensuring appropriate reliance on AIâ€”an important
topic in the HCI community.
To address this, future work should explore interaction tech-
niques that more effectively communicate uncertainty to designers.
This points to a clear direction: adapting the systemâ€™s explanations
based on its level of uncertainty. For example, the LLM could be
guided to generate more nuanced explanations, such as: â€œThis de-
sign is predicted to be effective, but the system has not explored
similar designs in this area very much, so there may be uncertainty.â€
8.4
Applicability to Real-World Design
Problems
In our experiment, we used artificial and relatively simple interfaces
to enable controlled evaluation of interaction. An important ques-
tion is whether our method can be applied to real-world design prob-
lems, where the parameter space tends to be higher-dimensional


--- Page 16 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
and performance depends on complex interactions among parame-
ters. We believe that, in such settings, the benefits of our approach
become even greater.
As the design space becomes higher-dimensional, designers face
significant challenges when manually specifying search ranges
on a GUI. Similarly, in complex problems where the relationship
between parameters and multiple objectives is not intuitive, it is
difficult to determine which parameter changes will lead to desir-
able outcomes. In contrast, our method allows designers to provide
collective instructions for high-dimensional problems, such as â€œAd-
just the layout-related parameters,â€ and goal-based instructions
for complex problems, such as â€œIncrease daily revenue.â€ The flex-
ibility of intervention that natural language provides plays a key
role in keeping the designerâ€™s cognitive load low. As the design
space becomes more high-dimensional and complex, reducing cog-
nitive load becomes critical and further enhances the conceptual
advantage of our method.
Applying our method to high-dimensional design spaces poses
challenges both inherent to Bayesian optimizationâ€”such as diffi-
culties in surrogate modelingâ€”and common to high-dimensional
optimization in general, where the number of required iterations
tends to grow rapidly. While addressing these issues is beyond the
scope of this work, they could be mitigated by recent advances in
high-dimensional BO methods [14] or by applying techniques such
as dimensionality reduction.
That said, in real-world design practice involving iterative user
testing, designers rarely adjust a large number of parameters at
once. This is because it becomes extremely difficult to identify the
causal relationship between parameter changes and the resulting
outcomes. Instead, designers typically select and focus on a specific
subset of parametersâ€”usually 2 to 5 at a time [4, 21, 22]â€”and iterate
based on the feedback. Our current system aligns well with this
practice. Furthermore, future work could explore ways to semi-
automatically select subsets of interest based on natural language
requests, such as â€œI want to focus on optimizing the layout parame-
ters.â€ Therefore, even as the total number of parameters increases,
our approach can remain valuable when used in this practical man-
ner of targeting specific subsets.
8.5
Generalization to Unknown Design Spaces
While our method appears promising applicability to real-world
design tasks, its effectiveness in unfamiliar design spaces where
the LLM has no prior domain knowledge remains an open question.
Nonetheless, we believe our method holds strong potential for
generalization to such design spaces, owing to a hybrid approach
that combines two key mechanisms.
First, our method leverages statistical indicators from the BO
process. The prompt includes each candidateâ€™s predictive mean and
variance, which serve as indicators of performance and uncertainty,
respectively. This information enables the LLM to make data-driven
decisions and balance the trade-off between exploitation and explo-
ration without relying on domain-specific knowledge.
Second, the LLM uses its in-context learning ability to progres-
sively learn the relationship between parameters and their out-
comes from the evaluation history in the prompt. As more data
is collected, the LLM can make increasingly informed selections,
even if it starts with no understanding of this relationship. The
combination of BOâ€™s data-driven guidance and the LLMâ€™s adaptive
learning allows our method to generalize across new design spaces
without requiring domain-specific knowledge.
Future work includes exploring the application of our method to
design tasks unfamiliar to the LLM, such as tuning haptic feedback
patterns on novel devices, to validate its generalization capability.
9
Conclusion
Our goal is to facilitate cooperative design optimization through
natural language interaction. For this purpose, we propose a novel
method that integrates BO with LLMs, where the use of LLMs
allows designers to provide flexible, natural language requests to the
optimization system and also receive natural language reasoning
of the systemâ€™s proposal. Specifically, this is enabled by sampling
multiple candidate points using a batch BO technique and then
selecting the most suitable one from the candidates by interpreting
the designerâ€™s request through an LLM. Our user studies show
that natural language-based cooperative optimization can provide
higher user agency than a system-led method and shows promising
optimization performance compared to manual design. Moreover,
it offers similar performance to an existing cooperative approach,
with the added benefit of reduced cognitive load. These results
suggest that natural language interaction is an effective means to
balance algorithmic efficiency with human control. Overall, our
findings highlight the potential of a new design framework that
supports more seamless humanâ€“AI collaboration.
Acknowledgments
This work was supported by JST Moonshot R&D Program Grant
Number JPMJMS2236.
References
[1] Ali AhmadiTeshnizi, Wenzhi Gao, and Madeleine Udell. 2024. OptiMUS: scal-
able optimization modeling with (MI)LP solvers and large language models. In
Proceedings of the 41st International Conference on Machine Learning (Vienna,
Austria) (ICMLâ€™24). JMLR.org, Article 24, 20 pages.
[2] Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin
Letham, Andrew Gordon Wilson, and Eytan Bakshy. 2020. BoTorch: A Frame-
work for Efficient Monte-Carlo Bayesian Optimization. In Advances in Neural
Information Processing Systems 33. http://arxiv.org/abs/1910.06403
[3] Xiaojun Bi, Tom Ouyang, and Shumin Zhai. 2014.
Both complete and cor-
rect? multi-objective optimization of touchscreen keyboard. In Proceedings of the
SIGCHI Conference on Human Factors in Computing Systems (Toronto, Ontario,
Canada) (CHI â€™14). Association for Computing Machinery, New York, NY, USA,
2297â€“2306. https://doi.org/10.1145/2556288.2557414
[4] Liwei Chan, Yi-Chi Liao, George B Mo, John J Dudley, Chun-Lien Cheng, Per Ola
Kristensson, and Antti Oulasvirta. 2022. Investigating Positive and Negative Qual-
ities of Human-in-the-Loop Optimization for Designing Interaction Techniques.
In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems
(New Orleans, LA, USA) (CHI â€™22). Association for Computing Machinery, New
York, NY, USA, Article 112, 14 pages. https://doi.org/10.1145/3491102.3501850
[5] Abdoulatif CissÃ©, Xenophon Evangelopoulos, Vladimir V Gusev, and Andrew I
Cooper. 2025. Language-Based Bayesian Optimization Research Assistant (BORA).
arXiv preprint arXiv:2501.16224 (2025).
[6] Allan Dafoe, Yoram Bachrach, Gillian Hadfield, Eric Horvitz, Kate Larson, and
Thore Graepel. 2021. Cooperative AI: Machines Must Learn to Find Common
Ground. Nature 593 (May 2021), 33â€“36.
https://doi.org/10.1038/d41586-021-
01170-0
[7] Samuel Daulton, Sebastian Ament, David Eriksson, Maximilian Balandat, and
Eytan Bakshy. 2023. Unexpected improvements to expected improvement for
Bayesian optimization. In Proceedings of the 37th International Conference on
Neural Information Processing Systems (New Orleans, LA, USA) (NIPS â€™23). Curran
Associates Inc., Red Hook, NY, USA, Article 904, 36 pages.


--- Page 17 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
[8] John J. Dudley, Jason T. Jacques, and Per Ola Kristensson. 2019. Crowdsourcing
Interface Feature Design with Bayesian Optimization. In Proceedings of the 2019
CHI Conference on Human Factors in Computing Systems (Glasgow, Scotland
Uk) (CHI â€™19). Association for Computing Machinery, New York, NY, USA, 1â€“12.
https://doi.org/10.1145/3290605.3300482
[9] Peter I Frazier. 2018.
A tutorial on Bayesian optimization.
arXiv preprint
arXiv:1807.02811 (2018).
[10] Hao Hao, Xiaoqun Zhang, and Aimin Zhou. 2024. Large language models as
surrogate models in evolutionary algorithms: A preliminary study. Swarm and
Evolutionary Computation 91 (2024), 101741.
https://doi.org/10.1016/j.swevo.
2024.101741
[11] Sandra G. Hart and Lowell E. Staveland. 1988. Development of NASA-TLX
(Task Load Index): Results of Empirical and Theoretical Research. In Human
Mental Workload, Peter A. Hancock and Najmedin Meshkati (Eds.). Advances
in Psychology, Vol. 52. North-Holland, 139â€“183. https://doi.org/10.1016/S0166-
4115(08)62386-9
[12] Chenyu Huang, Zhengyang Tang, Shixi Hu, Ruoqing Jiang, Xin Zheng, Dong-
dong Ge, Benyou Wang, and Zizhuo Wang. 2025.
ORLM: A Customizable
Framework in Training Large Models for Automated Optimization Modeling.
arXiv:2405.17743 [cs.CL] https://arxiv.org/abs/2405.17743
[13] Sen Huang, Kaixiang Yang, Sheng Qi, and Rui Wang. 2024. When large language
model meets optimization. Swarm and Evolutionary Computation 90 (2024),
101663. https://doi.org/10.1016/j.swevo.2024.101663
[14] Carl Hvarfner, Erik Orm Hellsten, and Luigi Nardi. 2024. Vanilla Bayesian
Optimization Performs Great in High Dimensions. In Proceedings of the 41st
International Conference on Machine Learning (Proceedings of Machine Learning
Research, Vol. 235), Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian
Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp (Eds.). PMLR,
20793â€“20817. https://proceedings.mlr.press/v235/hvarfner24a.html
[15] Mohammad M. Khajah, Brett D. Roads, Robert V. Lindsey, Yun-En Liu, and
Michael C. Mozer. 2016. Designing Engaging Games Using Bayesian Optimization.
In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems
(San Jose, California, USA) (CHI â€™16). Association for Computing Machinery, New
York, NY, USA, 5571â€“5582. https://doi.org/10.1145/2858036.2858253
[16] Yuki Koyama and Masataka Goto. 2022. BO as Assistant: Using Bayesian Op-
timization for Asynchronously Generating Design Suggestions. In Proceedings
of the 35th Annual ACM Symposium on User Interface Software and Technology
(Bend, OR, USA) (UIST â€™22). Association for Computing Machinery, New York,
NY, USA, Article 77, 14 pages. https://doi.org/10.1145/3526113.3545664
[17] Yuki Koyama, Issei Sato, and Masataka Goto. 2020. Sequential gallery for interac-
tive visual design optimization. ACM Trans. Graph. 39, 4, Article 88 (aug 2020),
12 pages. https://doi.org/10.1145/3386569.3392444
[18] Yuki Koyama, Issei Sato, Daisuke Sakamoto, and Takeo Igarashi. 2017. Sequential
line search for efficient visual design optimization by crowds. ACM Trans. Graph.
36, 4, Article 48 (jul 2017), 11 pages. https://doi.org/10.1145/3072959.3073598
[19] Connor Lawless, Jakob Schoeffer, Lindy Le, Kael Rowan, Shilad Sen, Cristina
St. Hill, Jina Suh, and Bahareh Sarrafzadeh. 2024. â€œI Want It That Wayâ€: Enabling
Interactive Decision Support Using Large Language Models and Constraint Pro-
gramming. ACM Trans. Interact. Intell. Syst. 14, 3, Article 22 (Sept. 2024), 33 pages.
https://doi.org/10.1145/3685053
[20] Beibin Li, Konstantina Mellou, Bo Zhang, Jeevan Pathuri, and Ishai Menache. 2023.
Large Language Models for Supply Chain Optimization. arXiv:2307.03875 [cs.AI]
https://arxiv.org/abs/2307.03875
[21] Yi-Chi Liao, Ruta Desai, Alec M Pierce, Krista E. Taylor, Hrvoje Benko, Tanya R.
Jonker, and Aakar Gupta. 2024. A Meta-Bayesian Approach for Rapid Online
Parametric Optimization for Wrist-based Interactions. In Proceedings of the 2024
CHI Conference on Human Factors in Computing Systems (Honolulu, HI, USA)
(CHI â€™24). Association for Computing Machinery, New York, NY, USA, Article
410, 38 pages. https://doi.org/10.1145/3613904.3642071
[22] Yi-Chi Liao, John J. Dudley, George B. Mo, Chun-Lien Cheng, Liwei Chan, Antti
Oulasvirta, and Per Ola Kristensson. 2023.
Interaction Design With Multi-
Objective Bayesian Optimization. IEEE Pervasive Computing 22, 1 (2023), 29â€“38.
https://doi.org/10.1109/MPRV.2022.3230597
[23] Jie Liu, Kim Marriott, Tim Dwyer, and Guido Tack. 2023. Increasing User Trust
in Optimisation through Feedback and Interaction. ACM Trans. Comput.-Hum.
Interact. 29, 5, Article 42 (Jan. 2023), 34 pages. https://doi.org/10.1145/3503461
[24] Tennison Liu, NicolÃ¡s Astorga, Nabeel Seedat, and Mihaela van der Schaar. 2024.
Large Language Models to Enhance Bayesian Optimization. In The Twelfth Inter-
national Conference on Learning Representations. https://openreview.net/forum?
id=OOxotBmGol
[25] Kanan Mahammadli and Seyda Ertekin. 2024. Sequential large language model-
based hyper-parameter optimization. arXiv preprint arXiv:2410.20302 (2024).
[26] Luca-Maxim Meinhardt, Clara Schramm, Pascal Jansen, Mark Colley, and Enrico
Rukzio. 2025. Fly Away: Evaluating the Impact of Motion Fidelity on Optimized
User Interface Design via Bayesian Optimization in Automated Urban Air Mobil-
ity Simulations. arXiv preprint arXiv:2501.11829 (2025).
[27] Kostis Michailidis, Dimos Tsouros, and Tias Guns. 2024.
Constraint Mod-
elling with LLMs Using In-Context Learning. In 30th International Conference
on Principles and Practice of Constraint Programming (CP 2024) (Leibniz Inter-
national Proceedings in Informatics (LIPIcs), Vol. 307), Paul Shaw (Ed.). Schloss
Dagstuhl â€“ Leibniz-Zentrum fÃ¼r Informatik, Dagstuhl, Germany, 20:1â€“20:27.
https://doi.org/10.4230/LIPIcs.CP.2024.20
[28] George Mo, John Dudley, Liwei Chan, Yi-Chi Liao, Antti Oulasvirta, and Per Ola
Kristensson. 2024. Cooperative Multi-Objective Bayesian Design Optimization.
ACM Trans. Interact. Intell. Syst. 14, 2, Article 13 (jun 2024), 28 pages.
https:
//doi.org/10.1145/3657643
[29] Mayk Caldas Ramos, Shane S Michtavy, Marc D Porosoff, and Andrew D White.
2023.
Bayesian optimization of catalysts with in-context learning.
arXiv
[physics.chem-ph] (April 2023).
[30] Bojana RankoviÄ‡ and Philippe Schwaller. 2023. BoChemian: Large Language
Model Embeddings for Bayesian Optimization of Chemical Reactions. In NeurIPS
2023 Workshop on Adaptive Experimental Design and Active Learning in the Real
World. https://openreview.net/forum?id=A1RVn1m3J3
[31] Eileen Roesler*, Tobias Rieger*, and Dietrich Manzey. 2022. Trust towards Human
vs. Automated Agents: Using a Multidimensional Trust Questionnaire to Assess
The Role of Performance, Utility, Purpose, and Transparency. Proceedings of the
Human Factors and Ergonomics Society Annual Meeting 66, 1 (2022), 2047â€“2051.
https://doi.org/10.1177/1071181322661065
[32] Bobak Shahriari, Kevin Swersky, Ziyu Wang, Ryan P. Adams, and Nando de Fre-
itas. 2016. Taking the Human Out of the Loop: A Review of Bayesian Optimization.
Proc. IEEE 104, 1 (2016), 148â€“175. https://doi.org/10.1109/JPROC.2015.2494218
[33] Bryan Wang, Yuliang Li, Zhaoyang Lv, Haijun Xia, Yan Xu, and Raj Sodhi. 2024.
LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video
Editing. In Proceedings of the 29th International Conference on Intelligent User
Interfaces (Greenville, SC, USA) (IUI â€™24). Association for Computing Machinery,
New York, NY, USA, 699â€“714. https://doi.org/10.1145/3640543.3645143
[34] Kenta Yamamoto, Yuki Koyama, and Yoichi Ochiai. 2022. Photographic Lighting
Design with Photographer-in-the-Loop Bayesian Optimization. In Proceedings
of the 35th Annual ACM Symposium on User Interface Software and Technology
(Bend, OR, USA) (UIST â€™22). Association for Computing Machinery, New York,
NY, USA, Article 92, 11 pages. https://doi.org/10.1145/3526113.3545690
[35] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou,
and Xinyun Chen. 2024. Large Language Models as Optimizers. In The Twelfth
International Conference on Learning Representations. https://openreview.net/
forum?id=Bb4VGOWELI
[36] Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku. 2024. Toward AI-Mediated
Avatar-Based Telecommunication: Investigating Visual Impression of Switching
Between User- and AI-Controlled Avatars in Video Chat. IEEE Access 12 (2024),
113372â€“113383. https://doi.org/10.1109/ACCESS.2024.3441233
A
Prompt
Figure 12 shows an overview of the prompt used to instruct the
LLM during the optimization process. Complete prompts for repro-
ducibility are provided in the supplementary material.
B
Technical Validation of Natural-Language
Guidance
The proposed technique allows users to guide the optimization be-
havior through natural language. We conducted a simple technical
assessment to see how well this technique works.
We initialized the optimization with five randomly generated
candidate points. Over the next 15 iterations, the optimization pro-
cess was guided using the proposed technique. For this evaluation,
we adopted a simulation approach to emulate natural language
requests by human designers; that is, we inserted artificial requests
and then saw how the optimization behavior changes according
to the requests. Specifically, during the 15 iterations, we inserted
the following two request prompts alternately: (1) â€œPlease propose
parameters that increase Objective 1â€ and (2) â€œPlease propose pa-
rameters that increase Objective 2.â€ We then evaluated the returned
parameters using the synthetic test functions (Appendix C) used
in Study 1 and Study 2. This was repeated five times with different
random seeds.
As shown in each subplot of Figure 13, the results of the requests
focusing on Objective 1 (red dots) tend to cluster at higher values of


--- Page 18 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
Based on the userâ€™s request described below, select the index of the candidate point and provide a reason for your choice.
Task context: [Task Name]
Task Description: [Task Description]
Metrics: [Metrics_1]:[Explanation_for_Metrics_1], [Metrics_2]:[Explanation_for_Metrics_2]
Hyperparameter Constraints:
[parameter_name_1] [parameter_range_1] ...[parameter_name_n]:[parameter_range_n]
[objective_name_1]:[objective_range_1] [objective_name_2]:[objective_range_2]
User request: {Here is a request from designer}
Observed results: [configuration_1] [performance_1] ...[configuration_k] [performance_k]
These candidate points are generated by a sampler for batch Bayesian optimization. Each candidate point includes not only the parameter
names but also the following columns: mean_obj means ...and variance_obj means ... and acquisition value means ...
â€¢ index: 1
[configuration_1]
mean_obj1=..., variance_obj1=..., mean_obj2=..., variance_obj2=..., acquisition_value=...
â€¢ ...
â€¢ index: ğ‘
[configuration_ğ‘]
mean_obj1=..., variance_obj1=..., mean_obj2=..., variance_obj2=..., acquisition_value=...
Figure 12: Prompt for candidate selection and reasoning. Bold labels with square brackets represent variables that change
depending on the context. Here, ğ‘›refers to the number of design parameters being adjusted, and ğ‘˜refers to the number of
observed data points at that time.
Objective 1 (right side of the plot), while those focusing on Objective
2 (blue dots) tend to cluster at higher values of Objective 1 (top side
of the plot). This provides visual evidence that the requests could
successfully guide the optimization behavior.
Finally, to measure how distinctly these clusters separate in the
parameter space, we calculated the Euclidean distances between
their centroids. The values were 0.215Â±0.004 for App 1, 0.206Â±0.000
for App 2, and 0.187 Â± 0.006 for App 3. Note that if the natural
language-based guidance has no effect, these values should be closer
to zero. This indicates that alternating between Objective 1 and
Objective 2 successfully steers the system toward different regions
of the search space.
C
Target Tasks and Synthetic Test Functions in
User Study
Table 1 shows the details of the design parameters and objectives
in the user study tasks.
Table 2 lists the hyperparameters of the test functions for the
three applications and the tutorial. These hyperparameters were de-
signed by Mo et al. to have a coherent behavior, and we adopted the
same hyperparameters (i.e., increasing the density of notification
frequency increases daily revenue but decreases user rating).
D
Questionnaire and Detailed Results from
User Study 1
D.1
Questionnaire
D.1.1
Agency-Related Questionnaire. Figure 14 presents the box-
plots for Q1, Q2, and Q3, providing a visual comparison of the
results across conditions. All items (Q1, Q2, Q3, and the Agency
Score) showed significant differences among the three conditions
(Designer-led, BO-led, and Cooperative (Natural Language)) based
on Friedman tests (Q1: ğ‘= 0.001; Q2: ğ‘= 0.001; Q3: ğ‘= 0.050;
Agency Score: ğ‘= 0.001). We then conducted post hoc Wilcoxon
signed-rank tests with Bonferroni corrections, as summarized be-
low.
For Q1, we found significant differences between the Designer-
led and BO-led conditions (ğ‘.adj = 0.001) and between the BO-led
and Cooperative (Natural Language) conditions (ğ‘.adj = 0.001). In
contrast, there was no significant difference between the Designer-
led and Cooperative (Natural Language) conditions (ğ‘.adj = 0.571).
Q2 followed a similar pattern, with significant differences between
the Designer-led and BO-led conditions (ğ‘.adj = 0.003) and be-
tween the BO-led and Cooperative (Natural Language) conditions
(ğ‘.adj = 0.002), but not between the Designer-led and Cooperative
(Natural Language) conditions (ğ‘.adj = 1.000). Although Q3 was
borderline significant (ğ‘= 0.050), none of the pairwise comparisons
were significant (Designer-led vs. BO-led: ğ‘.adj = 0.659; Designer-
led vs. Cooperative (Natural Language): ğ‘.adj = 0.552; BO-led vs.


--- Page 19 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Figure 13: Visualization of optimization results for App 1 (top), App 2 (middle), and App 3 (bottom). The black dots represent
the five initial seed points. The red dots show the results from requests favoring Objective 1, while the blue dots show those
from requests favoring Objective 2.
Q1, I'm in full control of
what I do (determining the 
design parameters 
I want to explore). 
Q2, I'm just an instrument 
in the hands of somebody.
Q3, The consequences of
 my actions feel like 
they don't logically follow 
my intention.
Figure 14: Three agency-related questions used in Study 1 to measure participantsâ€™ sense of agency during the task. Participants
responded on a 7-point Likert scale, and the aggregated scores of these items form the agency composite score.
Cooperative (Natural Language): ğ‘.adj = 0.137), except for a slight
tendency between BO-led and Cooperative (Natural Language).


--- Page 20 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
Table 1: Design parameters, objectives, and ranges for each of the applications (Apps 1â€“3) and tutorial (T).
App
ğ‘¥1
ğ‘¥2
ğ‘¥3
ğ‘¥4
ğ‘¥5
ğ‘“1
ğ‘“2
1
Density
of
ads- [0,1]
Notification
frequency
[0,2]
per
hour
Personalization
rate
of
content-
[0,1]
Moderation
rate
of
content-
[0,1]
Refresh time
of
content
[0,20]
min-
utes
Daily
revenue- [0,
20]
thou-
sands USD
User rating-
[0, 5]
2
Question
categories-
[5,50]
Refresh time
of
content
[0,1000]
Length
of
question pre-
view [0, 500]
characters
Max number
of
question
tags [1,10]
Threshold
activity rat-
ing for user
to
answer
questions
[0,5]
Answering
rate
of
questions-
[0,2]
per
minute
Questions
Answered-
[0,100]
3
Location
icon
trans-
parency
-
[0.5, 1]
Cursor
dis-
tance
for
restaurant
to show - [5,
50]
Location
icon size - [1,
10]
Description
box
size
-
[10, 50]
Restaurant
name
text
size - [10, 30]
Average
speed to find
restaurants-
[0,
2]
per
minute
Accuracy in
finding
all
restaurants-
[0, 100]
T
Force to reg-
ister contact
on screen -
[10, 100]ğ‘
Area to reg-
ister contact
on screen -
[0.5, 3.0]ğ‘ğ‘š2
-
-
-
Average tar-
get hit speed
- [0, 3]per sec-
ond
Accuracy
of
hitting
targets-
[0,
100]%
Table 2: Parameters a1, a2, b1, b2,ğ‘1,ğ‘2 for the synthetic test functions used in the applications (Apps 1â€“3) and tutorial (T).
App
a1
a2
b1
b2
ğ‘1
ğ‘2
1
[0.9, 0.3, 0.8, 0.25, 0.25]
[0.3, 0.35, 1.1, 0.75, 0.3] [0.9, 0.4, 1.3, 0.7, 0.4]
[1.0, 0.6, 1.2, 0.5, 0.4]
0.7
0.8
2
[âˆ’0.1, 0.25, 0.7, 0.7, 0.65] [0.2, 0.75, 0.75, 0.1, 0.7] [1.2, 0.5, 0.4, 1.0, 0.6]
[1.3, 0.7, 0.4, 0.9, 0.4]
0.8
0.7
3
[1.1, 0.75, 0.35, 0.3, 0.3]
[0.8, 0.25, 0.3, 0.9, 0.25] [1.2, 0.5, 0.6, 1.0, 0.4]
[1.3, 0.7, 0.4, 0.9, 0.4]
0.7
0.8
T
[0.3, 0.35]
[0.7, 0.65]
[1.0, 0.8]
[1.2, 0.9]
0.7
0.8
D.1.2
Participantsâ€™ Experience in Understanding and Exploring the
Design Space. We asked participants how well they understood the
design space and how they explored it. The question items, which
are identical to those in [28], are shown in Figure 15, along with
boxplots of participantsâ€™ 7-point Likert ratings across the three
conditions (adapted from [28]).
D.2
Additional Metrics of Pareto Set Discovery
Formal Evaluation. Figure 16 (a) shows a boxplot of the total
number of formal evaluations performed by each participant in
each condition. A repeated measures ANOVA reveals a significant
effect of condition (ğ‘= 0.000). Multiple comparisons using paired
t-tests with Bonferroni correction indicate significant differences
between the Designer-led and BO-led conditions (ğ‘.adj = 0.004) as
well as between the BO-led and Cooperative (Natural Language)
conditions (ğ‘.adj = 0.000). No significant difference is observed
between the Designer-led and Cooperative (Natural Language)
conditions (ğ‘.adj = 1).
Pareto Set Count. Figure 16 (b) shows a boxplot of the total num-
ber of Pareto-optimal designs obtained. A Friedman test reveals a
significant effect of condition (ğ‘= 0.043). Multiple comparisons
with Bonferroni correction indicate significant differences between
the Designer-led and BO-led conditions (ğ‘.adj = 0.040). No signifi-
cant differences are observed between the Designer-led and Coop-
erative (Natural Language) conditions (ğ‘.adj = 0.776,ğ‘Ÿ= 0.257) or
between the BO-led and Cooperative (Natural Language) conditions
(ğ‘.adj = 0.133,ğ‘Ÿ= 0.465).
Design Space Count Metric. Figure 16 (c) shows a boxplot of the
design space count metric. This metric measures the extent of ex-
ploration by dividing the design space into ğ‘šequal parts for each
dimension ğ‘‘, creating ğ‘šğ‘‘hypercubes (in our case ğ‘š= 3, ğ‘‘= 5,
hence 35 = 243 hypercubes). The metric counts the number of
hypercubes that contain evaluated parameters, using only parame-
ters evaluated through formal evaluation. A larger value indicates
a wider exploration. A Friedman test reveals a significant effect
of condition (ğ‘= 0.0258). No significant differences are observed
between any conditions (Designer-led vs. BO-led: ğ‘.adj = 1.0000;
Designer-led vs. Cooperative (Natural Language): ğ‘.adj = 0.3561;
BO-led vs. Cooperative (Natural Language): ğ‘.adj = 0.0592).


--- Page 21 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Q1, I was able to grasp the 
impact of each 
design parameter on the
 output of the design. 
Q2, The system allowed me 
to explore different 
design parameters to
 see what its impact
 on the design output is. 
Q3, I felt that I had 
control over searching 
different areas of
 the design space. 
Q4, I have an intuitive 
senseof the design space 
from using this system. 
Q5, I felt that the 
optimal designs I have 
obtained make sense. 
Q6, I felt that I was 
formally evaluating designs 
that aligned with my intuition
 of the design. 
Q7, I am confident that 
I found the optimal designs 
in the design space. 
Q8, I want to use 
this interface again. 
Figure 15: Boxplots of participantsâ€™ 7-point Likert ratings on design space understanding and exploration experience for the
three conditionsâ€”Designer-led, BO-led, and Cooperativeâ€”in Study 1, adapted from [28].
Total and Mean Design Space Travel Distance. Two metrics were
calculated as proxy measures for assessing the extent of broad ex-
ploration versus local fixation. The total travel distance (Figure 16
(d)) is the sum of the Euclidean distances between consecutive
formally evaluated points in the design space. The mean travel
distance (Figure 16 (e)) is the travel distance divided by the total
number of evaluations performed. A Friedman test reveals a sig-
nificant effect of condition for total travel distance (ğ‘= 0.0000)
and for mean travel distance (ğ‘= 0.0003). Multiple comparisons
with Bonferroni correction indicate significant differences for total
travel distance between the Designer-led and BO-led conditions
(ğ‘.adj = 0.0000) and between the BO-led and Cooperative (Natural
Language) conditions (ğ‘.adj = 0.0002). No significant difference
is observed between the Designer-led and Cooperative (Natural
Language) conditions (ğ‘.adj = 0.4621). For mean travel distance,
significant differences are observed between the Designer-led and
BO-led conditions (ğ‘.adj = 0.0003) and between the BO-led and
Cooperative (Natural Language) conditions (ğ‘.adj = 0.0058), while
no significant difference is found between the Designer-led and
Cooperative (Natural Language) conditions (ğ‘.adj = 0.1027).
E
Questionnaire and Detailed Results from User
Study 2
E.1
Questionnaire
E.1.1
Multidimensional Trust Questionnaire. Figure 17 shows the
boxplots for participantsâ€™ 4-point Likert ratings for three subdimen-
sionsâ€”purpose, transparency, and utilityâ€”of the Multidimensional
Trust Questionnaire (MTQ) [31], which was used to measure trust
in the system.
E.1.2
Agency-Related Questionnaire. Figure 18 shows the boxplots
for the three agency-related questions (Q1, Q2, Q3) and the compos-
ite score (ğ‘„1 âˆ’ğ‘„2 âˆ’ğ‘„3) in User Study 2. The same items were used
in User Study 1. We found significant differences in Q1 (ğ‘= 0.010;
Wilcoxon) and in the overall agency score (ğ‘= 0.032; paired t-test),
both favoring the Cooperative-EC (Mo et al.) condition over the
Cooperative-NL condition. In contrast, Q2 (ğ‘= 0.061; Wilcoxon)
and Q3 (ğ‘= 0.699; paired t-test) showed no significant differences.
E.1.3
Participantsâ€™ Experience in Understanding and Exploring the
Design Space. As in User Study 1, we asked participants how well
they understood the design space and how they explored it. The
question items, which are identical to those in [28], are shown in


--- Page 22 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
(a) Total formal evaluation count.
(b) Pareto set count.
(c) Design space count metric.
(d) Design space travel distance.
(e) Mean travel distance.
Figure 16: These boxplots show five of the six metrics from [28] that compare the three conditions in Study 1: Designer-led,
BO-led, and Cooperative. The plots illustrate (a) the total number of formal evaluations, (b) the total number of Pareto-optimal
designs, (c) design space count, (d) total travel distance, and (e) mean travel distance.
Figure 19, along with the boxplots of participantsâ€™ 7-point Likert
ratings across the three conditions (adapted from [28]).
E.2
Additional Metrics of Pareto Set Discovery
Below, we report the same metrics as in the Appendix of User Study
1 (see for detailed definitions and motivations) and present the
statistical outcomes for the two conditions (Cooperative (Explicit
Constraints) vs. Cooperative (Natural Language)).
Formal Evaluation (Total Formal Evaluation Count). Figure 20 (a)
shows a boxplot of the total number of formal evaluations. A paired
t-test reveals a significant difference between the two conditions
(ğ‘= 0.036).
Pareto Set Count. Figure 20 (b) shows a boxplot of the total num-
ber of Pareto-optimal designs. A Wilcoxon signed-rank test indi-
cates a significant difference (ğ‘= 0.009).
Design Space Count Metric. Figure 20 (c) presents the design space
count metric. A paired t-test finds no significant difference (ğ‘=
0.862). Hence, there is no evidence that either interface produced
broader or narrower exploration in terms of this metric.
Total and Mean Design Space Travel Distance. Figure 20 (d) and (e)
show, respectively, the total and mean travel distances. Wilcoxon
signed-rank tests reveal no significant differences in total travel
distance (ğ‘= 0.424) or mean travel distance (ğ‘= 0.569). These
results suggest that the overall patterns of exploration or fixation,
as reflected by travel distance, did not differ systematically between
the two conditions.


--- Page 23 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Purpose Q1, The intention 
of the system is positive.
Purpose Q2, The system is 
intended to help 
improve overall performance.
Purpose Q3, The system was 
implemented to help me.
Transparency Q1, The way 
the system works is clear to me.
Utility Q3, I find that the system
 supports my work.
Utility Q2, The system is useful
for my work.
Utility Q1, The system makes 
my work more difficult.
Transparency Q3, I understand 
how the system works.
Transparency Q2, I am well informed
 how the system works.
Figure 17: These boxplots show participantsâ€™ 4-point Likert ratings for three subdimensionsâ€”purpose, transparency, and
utilityâ€”of the Multidimensional Trust Questionnaire (MTQ) [31], used to measure trust in the system. Each subdimension has
three items, while the performance subdimension was omitted due to the difficulty of judging goal achievement. In the text, we
present average scores by subdimension and reverse the negatively worded utility item (â€œThe system makes my work more
difficultâ€) as (5 - Q1), ensuring that higher values consistently indicate more positive evaluations.


--- Page 24 ---
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
Ryogo Niwa, Shigeo Yoshida, Yuki Koyama, and Yoshitaka Ushiku
Q1, I'm in full control of
what I do (determining the 
design parameters 
I want to explore). 
Q2, I'm just an instrument 
in the hands of somebody.
Q3, The consequences of
 my actions feel like 
they don't logically follow 
my intention.
Agency Composite Score
(Q1 - Q2 - Q3) 
Figure 18: Boxplots of the three agency-related questions (Q1, Q2, Q3) and the agency composite score in User Study 2, based on
the same items used in User Study 1. Participants responded on a 7-point Likert scale, and the composite score is calculated as
(ğ‘„1 âˆ’ğ‘„2 âˆ’ğ‘„3).
Q1, I was able to grasp the 
impact of each 
design parameter on the
 output of the design. 
Q2, The system allowed me 
to explore different 
design parameters to
 see what its impact
 on the design output is. 
Q3, I felt that I had 
control over searching 
different areas of
 the design space. 
Q4, I have an intuitive 
senseof the design space 
from using this system. 
Q5, I felt that the 
optimal designs I have 
obtained make sense. 
Q6, I felt that I was 
formally evaluating designs 
that aligned with my intuition
 of the design. 
Q7, I am confident that 
I found the optimal designs 
in the design space. 
Q8, I want to use 
this interface again. 
Figure 19: Boxplots of participantsâ€™ 7-point Likert ratings on design space understanding and exploration experience for the
two Cooperative: Explicit Constraint and Cooperative: Natural Languageâ€“in Study 2, adapted from [28].


--- Page 25 ---
Cooperative Design Optimization through Natural Language Interaction
UIST â€™25, September 28-October 1, 2025, Busan, Republic of Korea
(a) Total formal evaluation count.
(b) Pareto set count.
(c) Design space count metric.
(d) Design space travel distance.
(e) Mean travel distance.
Figure 20: These boxplots show five of the six metrics from [28] that compare the two conditions in Study 2: Cooperative:
Explicit Constraint and Cooperative: Natural Language. The plots illustrate (a) the total number of formal evaluations, (b) the
total number of Pareto-optimal designs, (c) design space count, (d) total travel distance, and (e) mean travel distance.
