--- Page 1 ---
A Two-Layer Framework for Joint Online Configuration Selection
and Admission Control
Owen Shenâˆ—â€ , Haoran Xuâˆ—â€¡, Peter Glynnâ€¡, Yinyu Yeâ€¡, and Patrick Jailletâ€ 
â€ Operations Research Center, Massachusetts Institute of Technology
â€¡Department of Management Science and Engineering, Stanford University
â€ {owenshen,jaillet}@mit.edu
â€¡{haoran14, glynn, yyye}@stanford.edu
Abstract
We study online configuration selection with admission control problem, which arises in LLM
serving, GPU scheduling, and revenue management. In a planning horizon with T periods, we
consider a two-layer framework for the decisions made within each time period. In the first layer,
the decision maker selects one of the K configurations (ex. quantization, parallelism, fare class)
which induces distribution over the reward-resource pair of the incoming request. In the second
layer, the decision maker observes the request and then decides whether to accept it or not.
Benchmarking this framework requires care. We introduce a switching-aware fluid oracle
that accounts for the value of mixing configurations over time, provably upper-bounding any
online policy. We derive a max-min formulation for evaluating the benchmark, and we characterize
saddle points of the max-min problem via primal-dual optimality conditions linking equilibrium,
feasibility, and complementarity. This guides the design of SP-UCBâ€“OLP algorithm, which
solves an optimistic saddle point problem and achieves ËœO(
âˆš
KT) regret.
1
Introduction
Many resource-constrained systems require two sequential decisions at each time step. First, the
decision maker selects a system configuration that determines the type of incoming request. Second,
after observing the requestâ€™s characteristics, the decision maker makes an admission decisionâ€”
whether to accept or reject the request, subject to a cumulative resource budget. Neither decision
alone captures the full problem: the configuration shapes what the decision maker will see, and the
admission control determines what resources are consumed. It is the coupling of both decisions that
creates the central challenge.
This two-layer structure arises naturally in several domains. In LLM serving, the system first
selects a serving configuration (quantization level, batching strategy) [Kwon et al., 2023, Yu et al.,
2022], then observes the incoming requestâ€™s prompt length and estimated compute cost, and finally
decides whether to admit the job under its current resource budget. In cluster scheduling, the
system first chooses a parallelism configuration [Gu et al., 2019, Narayanan et al., 2020, Qiao et al.,
2021], then observes the jobâ€™s resource footprint, and decides whether to schedule it. In revenue
management, the firm first selects a fare class [Talluri and van Ryzin, 2004, Gallego and van Ryzin,
1994], then observes a customerâ€™s willingness-to-pay, and decides whether to accept the booking. In
âˆ—These authors contributed equally to this work.
1
arXiv:2602.07663v1  [math.OC]  7 Feb 2026


--- Page 2 ---
Choose config Î¸t
Observe (rt, at)
Accept/Reject
âˆ¼DÎ¸t
admission rule
Layer 1
Revelation
Layer 2
Determines re-
quest type Î¸
(distribution
DÎ¸ unknown)
Reward and re-
source (âˆ¼DÎ¸)
revealed be-
fore commit
Binary decision under
budget constraint
Figure 1: Two-layer decision structure with data revelation.
all cases, the first decision (configuration) is made before the request is revealed, while the second
decision (admission) is made after observing the requestâ€”a selectâ€“observeâ€“admit protocol.
We formalize this protocol as follows. There are K configurations, each inducing a distribution
over rewardâ€“resource pairs (r, a). At each period, the decision maker (1) selects a configuration
Î¸t, (2) observes the rewardâ€“resource pair (rt, at) âˆ¼DÎ¸t, and (3) admits or rejects the request
subject to a cumulative budget B. All decisions are irrevocable. Two existing frameworks each
capture one layer of this problem but not both. Bandits with knapsacks (BwK) [Badanidiyuru et al.,
2018] models configuration selection under budget constraints, but uses sample-and-commit: pulling
an arm immediately consumes resources with no opportunity to reject after observing the outcome.
Online linear programming (OLP) [Agrawal et al., 2014, Li and Ye, 2022] models observation-based
admissionâ€”the decision maker sees (rt, at) before committing resourcesâ€”but assumes a fixed request
distribution with no configuration selection. Our framework unifies both: configuration selection
from BwK with observation-based admission from OLP.
Main Contributions.
1. Switching-aware fluid oracle. Designing an appropriate oracle is essential in solving an online
decision making problem. An oracle solves a so-called offline optimization problem whose optimal
value serves as a benchmark for evaluating the performance of feasible online policies. A natural
oracle of our problem is the fixed configuration oracle, i.e., fix a single best configuration and solve
the offline resource allocation problem of the selected configuration. The offline resource allocation
problem is given in Li and Ye [2022], and its optimal value depends on the reward-resource
distribution. The best configuration in this natural oracle refers to the one whose reward-resource
distribution gives the highest optimal value of the offline resource allocation problem. However,
this oracle which is based on the naive â€œbest-responseâ€ interpretation of our problem fails to upper
bound the optimal online policy when there are heterogeneous resources. In those situations, a
feasible online policy that switches among configurations may have higher total reward than the
fixed configuration oracle by exploiting complementary budgets (Example 1).
In this paper, we propose a switching-aware oracle which provides a valid upper bound on all
feasible online policies (Theorem 8). This eliminates the â€œbeating the oracleâ€ pathology of the
fixed-configuration oracle.
2. Primal-dual characterization of the oracle. We derive an equivalent max-min formulation of
the offline optimization problem in the switching-aware oracle by duality. We build the connection
between the saddle points of the max-min problem and the primal optimal solutions of the
offline optimization problem via threshold rules, feasibility, and complementarity conditions
(Theorems 6â€“7), which also corrects the naive â€œbest-responseâ€ interpretation.
2


--- Page 3 ---
3. Sublinear regret algorithm. We design SP-UCBâ€“OLP Algorithm by repeatedly solving the
saddle points of an optimistic version of the max-min formulation of the offline optimization
problem in the switching-aware oracle. We prove the regret of SP-UCB-OLP Algorithm is
ËœO(
âˆš
KT) (Theorem 9) where T is the number of periods in the planning horizon and K is the
number of configurations. We also conduct numerical experiments to validate the regret upper
bound.
2
Related Work
Bandits with knapsacks (BwK).
BwK [Badanidiyuru et al., 2018] is a framework that deals
with multi-armed bandit problems under budget constraints. Many variants of BwK problems
including adversarial input [Immorlica et al., 2019], contextual features [Agrawal and Devanur,
2016, Agrawal et al., 2016], non-linear reward and constraint [Agrawal and Devanur, 2019] and
non-stationary environments [Liu et al., 2022] have been studied in the literature. Although BwK
has the components of both configuration selection and resource allocation, BwK uses sample-and-
commit: pulling an arm immediately consumes resources without the option to reject after observing
the outcome. This makes our framework and BwK significantly different because our framework
leverages observe-then-decide admission, where the agent sees (rt, at) before committing resources.
Online linear programming (OLP) and threshold-based decision rule.
OLP [Agrawal et al.,
2014] is a framework of online resource allocation problems that uses observe-then-decide. Dual-based
algorithms [Buchbinder and Naor, 2009, Devanur and Hayes, 2009, Agrawal and Devanur, 2015,
Balseiro et al., 2020, Li and Ye, 2022, Bray, 2024] are the most common way to solve OLP problems.
These methods learn dual prices and apply threshold rule to admission control. However, OLP
assumes a fixed reward-resource distribution of the requests and does not explore over configurations.
In this paper, our proposed SP-UCB-OLP algorithm learns both a probability distribution over the
configurations and a dual price. The distribution guides the configuration selection decision, and the
dual price gives a threshold-based admission rule.
Our threshold-based admission rule also relates to prophet inequalities [Krengel and Sucheston,
1977, Samuel-Cahn, 1984], which compare online policies to omniscient prophets. Modern extensions
handle matroid constraints [Kleinberg and Weinberg, 2012] and pricing mechanisms [DÃ¼tting et al.,
2017]. Unlike prophet settings with adversarial inputs, reward and resource consumption of the
requests in our model are stochastic but configuration-dependent. Dynamic pricing problems in
revenue management [Gallego and van Ryzin, 1994, Talluri and van Ryzin, 2004, Besbes and Zeevi,
2012]. are also closely related to the threshold-based admission rule.
Saddle-point of max-min problem.
The offline optimization problem solved by our switching-
aware oracle can be expressed as a max-min optimization problem, and our SP-UCB-OLP algorithm
solves the joint online configuration selection and admission control problem by learning the saddle
point of this max-min optimization problem. Thus our work also aligns with saddle-point learning
and multiplicative weights [Freund and Schapire, 1997, Arora et al., 2012].
Our positioning.
We unify configuration exploration (from BwK) with observe-then-decide
threshold admission (from OLP) through a switching-aware oracle. This switching-aware oracle
provides a valid upper bound for the total reward earned by any feasible online polices, and learning
the saddle point of the max-min optimization problem corresponding to this oracle leads us to the
SP-UCB-OLP algorithm that achieves sublinear regret.
3


--- Page 4 ---
3
Model
Two-layer decision model.
The planning horizon has T âˆˆN time periods, and one request arrives
at each of the time periods. Let d be the number of resource types, and B âˆˆRd
+ be the total budget
vector. Denote (rt, at) âˆˆR+ Ã— Rd
+ as the reward-resource pair of request arriving in time period
t. There are K configurations Î˜ = {1, . . . , K}. Each configuration Î¸ induces a rewardâ€“resource
distribution DÎ¸. At each time t = 1, Â· Â· Â· , T, the decision maker (1) selects a configuration Î¸t âˆˆÎ˜, (2)
observes (rt, at) âˆ¼DÎ¸t of the request arriving in time period t, (3) chooses xt âˆˆ{0, 1} after observing
(rt, at). If xt = 1, the decision maker collects reward rt and consumes resources at. {xt}T
t=1 must
satisfy the pathwise budget constraint:
T
X
t=1
atxt â‰¤B
(componentwise, almost surely).
In addition, the decisions made at each time period is irrevocable. The goal of the decision maker is
to maximize the expected total reward E[PT
t=1 rtxt].
3.1
Assumptions
Assumption 1 (Stationarity and Independence). If an algorithm select configuration Î¸ at time
period t, (rt, at) is drawn independently from DÎ¸. In addition, the distribution DÎ¸ is time-invariant
for all Î¸ âˆˆÎ˜.
Assumption 2 (Boundedness). There exist constants Rmax, Amax > 0 such that for all Î¸ and
(r, a) âˆ¼DÎ¸:
0 â‰¤r â‰¤Rmax,
âˆ¥aâˆ¥âˆâ‰¤Amax
a.s.
Assumption 3 (Budget Scaling). There exists b âˆˆRd
+ such that B = T Â· b.
In the analysis of this paper, we fix the vector b and discuss the dependence of the performance
of algorithms as the number of periods T goes to infinity. Under this asymptotic regime, Assumption
3 indicates that we consider the â€œlarge resource budgetâ€ scenario in which the total budget is
proportional to the total number of time periods.
Assumption 4 (Continuous Valuation). For any Î¸ âˆˆÎ˜, if (r, a) âˆ¼DÎ¸, then the conditional
distribution of r given a = Î± is continuous for any Î± in the support of a.
We will later show that we do admission control through a price-based threshold method, in
which we have a price p âˆˆRd and accept a request with reward-resource pair (r, a) if r > aT p.
Assumption 4 serves as a â€œNo-Tieâ€ assumption, i.e., for any p âˆˆRd, P(r = aT p) = 0.
4
Switching-Aware Fluid Oracle
We define an oracle and the corresponding offline optimization problem, which provides a benchmark
that we can define the regret of an online algorithm with respect to. Recall b := B/T is the
per-period budget given in Assumption 3.
4


--- Page 5 ---
4.1
Fixed configuration oracle leads to negative regret
Let (rt,Î¸, at,Î¸) be the reward-resource pair observed if the decision maker selects configuration Î¸.
Define
V off
Î¸
(b) := E
h
max
n
T
X
t=1
rt,Î¸xt,Î¸

T
X
t=1
at,Î¸xt,Î¸ â‰¤T Â· b,
0 â‰¤xt,Î¸ â‰¤1 âˆ€t
oi
.
The optimization problem inside the expectation defining V off
Î¸
(b) is the so-called offline LP in Li
and Ye [2022]. V off
Î¸
(b) represents the maximal expected total reward earned if the decision maker
always selects configuration Î¸ and knows the reward-resource pairs of all the incoming requests in
advance. Let {xâˆ—
t,Î¸}T
t=1 be the optimal solution of the maximization problem inside the expectation.
Then, a natural oracle of our problem is to always select Î¸âˆ—= arg minÎ¸âˆˆÎ˜ V off
Î¸
(b) and accepting
requests according to {xâˆ—
t,Î¸}T
t=1. Then, the expected total reward earned by this fixed configuration
oracle is V âˆ—(b) := V off
Î¸âˆ—
(b). However, the following example indicates that it is possible for an online
policy having higher expected total reward than V âˆ—(b).
Example 1 (Complementary Resources). Consider T = 100 periods, d = 2 resources with b =
[0.5, 0.5], and two configurations with deterministic resource consumption: (r âˆ¼Uniform(0, 2), a =
[1, 0]) and (r = Uniform(0, 2), a = [0, 1]), each consuming only one type of resource. The fixed
configuration oracle achieves V âˆ—(b) = 7550
101 â‰ˆ74.76 (one budget wasted), but the optimal online
policy is to select configuration 1 when t â‰¤50, select configuration 2 when t > 50 and accept all the
requests, which earns 100 as the expected total reward.
This example motivates the following derivation of the switching-aware oracle.
4.2
Primal Mixed Fluid Relaxation
Let âˆ†K = {w âˆˆRK
+ : P
Î¸ wÎ¸ = 1} be the probability simplex. For each Î¸ âˆˆÎ˜, let xÎ¸ : R+ Ã— Rd
+ â†’
[0, 1] be a measurable acceptance rule. We define the mixed fluid value as:
V mix(b) := max
wâˆˆâˆ†K max
{xÎ¸}
n X
Î¸âˆˆÎ˜
wÎ¸EÎ¸[r xÎ¸(r, a)]

X
Î¸âˆˆÎ˜
wÎ¸EÎ¸[a xÎ¸(r, a)] â‰¤b
o
.
(1)
The max-max form represents the two-layer framework in our problem. The outer maximization
represents the configuration selection, and the inner maximization represents the admission control
after a configuration is selected. V mix(b) also shows how OLP and BwK are connected with our
problem. When K = 1, our problem is reduced to an OLP problem, and V mix(b) is also equivalent
to the fluid relaxation of OLP given by [Chen et al., 2024] in this case. When the acceptance rule is
predetermined and not part of the decision, i.e., {xÎ¸}Î¸âˆˆÎ˜ is fixed, our problem is reduced to a BwK
problem, and V mix(b) is also equivalent to the LP relaxation of BwK given by [Badanidiyuru et al.,
2018] in this case.
The switching-aware fluid oracle knows the optimal solution (wâˆ—, {xâˆ—(Î¸)}). At each time
period t, the oracle randomly select a configuration Î¸t following the probability distribution given
by the mixture wâˆ—. After observing (rt, at), the oracle applies the acceptance rule xÎ¸t and earns
5


--- Page 6 ---
rtxÎ¸t(rt, at). The switching-aware fluid oracle ignores the budget constraint. Thus, the total expected
reward earned by the switching-aware fluid oracle is T Â· V mix(b). In the following subsections, we
characterize V mix(b) and show T Â· V mix(b) is a valid benchmark.
4.3
Dual Form and Envelope Structure
Envelope and threshold consumption.
For p âˆˆRd, define the surplus and threshold
consumption:
gÎ¸(p) := EÎ¸[(r âˆ’âŸ¨p, aâŸ©)+], hÎ¸(p) := EÎ¸[a 1{r > âŸ¨p, aâŸ©}].
For a mixture w âˆˆâˆ†K, define
L(w, p) := âŸ¨p, bâŸ©+
X
Î¸
wÎ¸gÎ¸(p).
Theorem 5 (Primalâ€“Dual Form of the Mixed Fluid Oracle). Under Assumptions 2 and 3, let bmin be
the smallest component of b (in particular, bmin > 0) and Pmax be 2Rmax/bmin. With price domain
P = [0, Pmax]d,
V mix(b) = max
wâˆˆâˆ†K min
pâˆˆP
(
âŸ¨p, bâŸ©+
X
Î¸
wÎ¸gÎ¸(p)
)
= min
pâˆˆP

âŸ¨p, bâŸ©+ max
Î¸âˆˆÎ˜ gÎ¸(p)

.
(2)
Define the induced consumption H(w, p) := P
Î¸ wÎ¸hÎ¸(p). Let A(p) := arg maxÎ¸ gÎ¸(p) be the
active (envelope) set, and supp(w) be the indices of positive components of w. The following
theorem establishes the relationship between the primal form and the max-min form of V mix(b).
Theorem 6 (Primalâ€“dual optimality (saddle/KKT conditions)). Assume Assumptions 1â€“4. A pair
(wâ‹†, pâ‹†) âˆˆâˆ†K Ã— P is a saddle point of maxwâˆˆâˆ†K minpâˆˆP L(w, p) (and hence attains V mix(b)) if
and only if:
(i) (Envelope support) supp(wâ‹†) âŠ†A(pâ‹†).
(ii) (Feasibility) H(wâ‹†, pâ‹†) â‰¤b (componentwise).
(iii) (Complementarity) âŸ¨pâ‹†, b âˆ’H(wâ‹†, pâ‹†)âŸ©= 0.
Moreover, the mixture wâ‹†together with threshold admission xÎ¸(r, a) = 1{r > âŸ¨pâ‹†, aâŸ©} for all Î¸ âˆˆÎ˜,
is primal-optimal for (1) and V mix(b) = L(wâ‹†, pâ‹†).
Theorem 6 indicates that, at equilibrium, wâ‹†randomizes only among envelope-optimal config-
urations at pâ‹†, and the induced threshold consumption matches the budget on priced resources
(complementarity). The following theorem further characterize the saddle points of the max-min
form of V mix(b).
Theorem 7 (Characterization of all saddle points). Assume Assumptions 1â€“4. Define the envelope
objective
f(p) := âŸ¨p, bâŸ©+ max
Î¸âˆˆÎ˜ gÎ¸(p),
Pâ‹†:= arg min
pâˆˆP
f(p).
Then the set of saddle points of L is exactly
S =
n
(w, p) âˆˆâˆ†K Ã— P : p âˆˆPâ‹†, supp(w) âŠ†A(p),
H(w, p) â‰¤b, âŸ¨p, b âˆ’H(w, p)âŸ©= 0
o
.
6


--- Page 7 ---
4.4
Oracle Justification
Denote RÏ€
T as the total reward earned by an online policy Ï€.
Theorem 8 (Switching-Aware Oracle Upper Bound). Under Assumptions 1â€“2, for any online policy
Ï€ satisfying the pathwise budget constraint,
E[RÏ€
T ] â‰¤T Â· V mix(b).
Proof sketch. Fix p âˆˆP, rtxt â‰¤âŸ¨p, atâŸ©xt + (rt âˆ’âŸ¨p, atâŸ©)+ almost surely. By P
t atxt â‰¤B yields
RÏ€
T â‰¤âŸ¨p, BâŸ©+ PT
t=1(rt âˆ’âŸ¨p, atâŸ©)+ almost surely. Taking expectation and upper bounding the
average surplus by maxÎ¸ gÎ¸(p) gives E[RÏ€
T ] â‰¤T(âŸ¨p, bâŸ©+ maxÎ¸ gÎ¸(p)). Minimizing over p completes
the proof. Full proof is in Appendix C.
Remark 1. In Example 1, T Â· V mix(b) = 100 which provides a valid upper bound.
5
Algorithm: SP-UCBâ€“OLP
The switching-aware oracle motivates the following algorithm. At each time period t, we use the
observed data to learn the surplus functions {gÎ¸}Î¸âˆˆÎ˜. Using the sample averages {Ë†gÎ¸,t}Î¸âˆˆÎ˜ with
respect to the observed data is the most straightforward way to learn surplus functions; however, to
balance exploration and exploitation, we apply the idea of UCB and add confidence radii {Î²Î±,Î¸(t)} to
{Ë†gÎ¸,t}Î¸âˆˆÎ˜ to get our final estimates of the surplus functions. We replace the surplus functions in (2)
with the estimated surplus function to get an optimistic saddle point problem and solve this problem
to get (wt, pt). We then randomly select a configuration Î¸t following the probability distribution
given by wt and accept the request if rt > atT pt and we have enough resources. We introduce the
formulation of confidence radii Î²Î±,Î¸(t) and the details of algorithm in the following sections.
5.1
Confidence Radii and Optimistic Saddle Point Problem
We store every observed (rt, at) regardless of whether it is admitted, so that surplus estimates are
unbiased. For each configuration Î¸, maintain a dataset SÎ¸ of all observed samples (accepted or
rejected) with count NÎ¸ = |SÎ¸|. Define the empirical surplus:
bgÎ¸,t(p) :=
1
NÎ¸ âˆ¨1
X
(r,a)âˆˆSÎ¸
(r âˆ’âŸ¨p, aâŸ©)+.
By Lemma 20 and its anytime version (Corollary 21) in the Appendix, for any Î± â‰¥1 and any
Î´ âˆˆ(0, 1), with probability at least 1 âˆ’Î´, the following holds simultaneously for all Î¸ âˆˆÎ˜ and all
rounds t â‰¤T:
sup
pâˆˆP
gÎ¸(p) âˆ’bgÎ¸,t(p)
 â‰¤Î²Î±,Î¸(t),
where the confidence radius is
Î²Î±,Î¸(t) := Î± cgRmax
v
u
u
td log

c0 d Pmax Amax T
Rmax

+ log(KT/Î´)
NÎ¸ âˆ¨1
,
7


--- Page 8 ---
and cg, c0 > 0 are absolute constants from the concentration lemma (Appendix D). Then, at each
round, we solve the following optimistic saddle point problem:
(wt, pt) âˆˆarg max
wâˆˆâˆ†K
arg min
pâˆˆP
Lopt
t
(w, p)
= arg max
wâˆˆâˆ†K
arg min
pâ‰¥0
Lopt
t
(w, p),
(3)
where Lopt
t
(w, p) := âŸ¨p, bsafeâŸ©+ P
Î¸ wÎ¸(bgÎ¸,t(p) + Î²Î±,Î¸(t)), and bsafe := (1 âˆ’Îµ)b with Îµ =
p
log T/T.
The conservative per-period budget bsafe is used to do feasibility control, which is consistent with
literature practice such as in Agrawal et al. [2014]. The equality that replace p âˆˆP with p â‰¥0 is by
Assumption 2. For the proof of this equality, please see Appendix F.
5.2
Algorithm Details
Algorithm 1 provides the full details of our SP-UCB-OLP algorithm. An important step in
the implementation of this algorithm is to solve the optimistic saddle point problem. We provide a
method to solve this problem by solving linear programs in Appendix F.
5.3
Theoretical Results
Define the switching-aware regret of an online policy Ï€ as:
Regmix
Ï€
(T) := T Â· V mix(b) âˆ’E[RÏ€
T ].
Theorem 9 (Main Theorem: Regret vs. Switching-Aware Fluid Oracle). Denote Algorithm 1 as
Ï€1, under Assumptions 1â€“4, run Algorithm 1 with Îµ =
p
log T/T, confidence level Î´ = T âˆ’2, and
exploration parameter Î± â‰¥1. Then
Regmix
Ï€1 (T) â‰¤C1 Î±
p
KT Â· d log T + C2
p
T log T + KRmax,
where constants C1, C2 > 0 depend only on (d, Rmax, Amax, b). In particular, for fixed d,
Regmix
Ï€1 (T) = ËœO(Î±
âˆš
KT).
Remark 2. Theorem 9 requires Î± â‰¥1. In practice, smaller values of Î± (e.g., Î± = 0.01) often
improve empirical performance by reducing over-exploration, but are not covered by the high-probability
analysis. See Appendix D for details.
6
Experiments
Our experiments pursue three goals: (i) validate that SP-UCBâ€“OLP achieves ËœO(
âˆš
T) regret as
predicted by Theorem 9; (ii) validate that the switching-aware benchmark V mix is necessary by
demonstrating the complementarity gap; and (iii) test the algorithm on real GPU cluster traces. In
all experiments, the optimistic saddle point problem is solved via the LP formulation in Appendix F.
In addition to SP-UCBâ€“OLP, we also test the other three algorithms: (1) Greedy runs SPâ€“UCBâ€“
OLP with Î± = 0 yielding pure exploitation. (2) Random selects Î¸t from Î˜ uniformly at random
and accepts as long as the budget constraint is not violated. (3) Oracle runs SPâ€“UCBâ€“OLP by
replacing wt and pt with the true optimal mixture wâˆ—and price pâˆ—computed by the switching-aware
oracle at each round.
8


--- Page 9 ---
Algorithm 1 SP-UCBâ€“OLP:
1: Input: Configurations Î˜ (|Î˜| = K), budget B, horizon T, exploration parameter Î±, slack
Îµ =
p
log T/T
2: Initialize: Brem â†B, b â†B/T, bsafe â†(1 âˆ’Îµ)b
3: For each Î¸: NÎ¸ â†0, SÎ¸ â†âˆ…
4: for t = 1 to T do
5:
// Pure observation phase: initialize sample sets without admission
6:
if t â‰¤K then
7:
Î¸t â†t {Round-robin initialization}
8:
Observe (rt, at) âˆ¼DÎ¸t
9:
SÎ¸t â†SÎ¸t âˆª{(rt, at)};
NÎ¸t â†NÎ¸t + 1
10:
xt â†0 {Observe only, no admission}
11:
continue
12:
end if
13:
// Compute confidence radii
14:
for each Î¸ âˆˆÎ˜ do
15:
Î²Î±,Î¸(t) â†Î± cgRmax
s
d log

c0 d Pmax Amax T
Rmax

+log(KT/Î´)
NÎ¸âˆ¨1
16:
end for
17:
// Empirical surpluses
18:
bgÎ¸,t(p) â†
1
NÎ¸âˆ¨1
P
(r,a)âˆˆSÎ¸(r âˆ’âŸ¨p, aâŸ©)+
19:
// Solve optimistic saddle point problem
20:
(wt, pt) âˆˆarg maxwâˆˆâˆ†K arg minpâ‰¥0 Lopt
t
(w, p)
{Lopt
t
from (3)}
21:
// Sample a configuration from the mixture
22:
Draw Î¸t âˆ¼wt
23:
Observe (rt, at) âˆ¼DÎ¸t
24:
SÎ¸t â†SÎ¸t âˆª{(rt, at)};
NÎ¸t â†NÎ¸t + 1
25:
// Admission decision (bid-price with hard feasibility)
26:
if at â‰¤Brem and rt > âŸ¨pt, atâŸ©then
27:
Accept: xt â†1;
Brem â†Brem âˆ’at
28:
else
29:
Reject: xt â†0
30:
end if
31: end for
In addition to regret Regmix
Ï€
(T), we also consider the competitive ratio CRÏ€ = E[RÏ€
T ]/(T Â·
V mix(b)) as another performance measurement. Unless otherwise noted, experiments use d = 3
resource dimensions. Budget is parameterized by a scaling factor Ï > 0: b = Ï Â· b0, where b0 is a
scenario-specific baseline per-period budget (see Appendix G); Ï < 1 corresponds to tighter budgets
and Ï > 1 to looser ones.
6.1
Regret Scaling with Horizon
We run SP-UCBâ€“OLP with the theory-compliant exploration parameter Î± = 1.5 on a K = 5
Gaussian scenario (S0) with d = 3 resources and budget scaling Ï = 0.7. Each configuration Î¸ âˆˆ
{0, . . . , 4} generates rewards r âˆ¼N(ÂµÎ¸
r, (ÏƒÎ¸
r)2) and per-resource consumptions aj âˆ¼N(ÂµÎ¸
a,j, (ÏƒÎ¸
a,j)2),
independently truncated to [0.01, Rmax] and [0.01, Amax] respectively to satisfy Assumption 2, with
9


--- Page 10 ---
Table 1: Regret scaling with Î± = 1.5 (S0, 50 seeds).
T
Regret
Regret/
âˆš
T
CR
100
15.9 Â± 4.1
1.59 Â± 0.41
0.63
200
22.5 Â± 6.0
1.59 Â± 0.42
0.74
500
35.2 Â± 10.2
1.58 Â± 0.46
0.84
1000
50.6 Â± 13.4
1.60 Â± 0.42
0.88
2000
71.8 Â± 24.7
1.61 Â± 0.55
0.92
250
500
750
1000
1250
1500
1750
2000
Time Horizon T
10
20
30
40
50
60
70
80
Regret
n = 50 seeds per T
Error bands: Â±1.96 SE
Regret Scaling: SP-UCB-OLP with =1.5 (50 Seeds, T
2000)
Fitted T (c=0.60)
SP-UCB ( =1.5)
Figure 2: Regret scaling with Î± = 1.5 (S0, 50 seeds).
Rmax = Amax = 2.0. The five configurations span a range of rewardâ€“consumption trade-offs; full
parameter tables appear in Appendix G. The per-period budget is b = Ï Â· b0 where b0 is the mean
consumption vector of the most resource-intensive configuration, and the baseline budget b0 is
specified in Appendix G. Algorithm parameters are Pmax = 2.0, Î´ = T âˆ’2, Îµ =
p
log T/T, cg = 0.0707
(empirically tuned to match the theoretical
âˆš
T scaling), with warm-start of K rounds (round-robin,
no budget consumption) and saddle-point re-solves on a doubling schedule.
We vary T âˆˆ{100, 200, 500, 1000, 2000} with 50 independent seeds. Table 1 and Figure 2 show
that Regret/
âˆš
T remains approximately constant (â‰ˆ1.6) across all horizon lengths, confirming the
ËœO(
âˆš
T) scaling predicted by Theorem 9.
6.2
Real-World Validation: Alibaba Traces
To validate beyond synthetic settings, we test on real cluster traces from Alibaba [Alibaba Group,
2018] with d = 2 resource dimensions (CPU and memory), K = 3 regime configurations, and
T = 5,000 arrivals processed in original temporal order.
10


--- Page 11 ---
Table 2: Alibaba regime configurations with reward coefficients.
Regime
Description
c1 (CPU)
c2 (Mem)
0
CPU-heavy
2.0
0.5
1
Memory-heavy
0.5
2.0
2
Balanced
1.2
1.2
Data and reward modeling.
We use real resource consumption from the trace:
cpu =
plan_cpu/100 and mem = plan_mem/100, both normalized to [0, 1].
The Alibaba trace ex-
hibits significant resource imbalance: mean CPU utilization is 83.6% while mean memory is 34.9%.
Since the raw trace contains no native reward field, we construct reward as:
r = c1[Î¸] Â· cpu + c2[Î¸] Â· mem + Ïµ,
Ïµ âˆ¼N(0, 0.12)
where c1[Î¸], c2[Î¸] are regime-specific coefficients. This creates a stationary LP structure: the optimal
regime depends on which resource is more abundant, creating a meaningful learning problem.
Configuration table.
Table 2 summarizes the three regime configurations. The CPU-heavy
regime rewards CPU-intensive tasks; the Memory-heavy regime rewards memory-intensive tasks;
the Balanced regime provides equal reward per unit of either resource. Full details appear in
Appendix G.5.
The value of minimal exploration.
Figure 3 shows competitive ratio distributions across 50
seeds with Ï = 1.0. A striking finding is the dramatic benefit of minimal exploration: Greedy (Î± = 0)
achieves 84.8% Â± 14.2% CR with 10 out of 50 seeds stuck below 70%, while Î± = 0.01 achieves
97.4% Â± 0.6% CR. This 24Ã— reduction in variance demonstrates that even minimal exploration
prevents lock-in to suboptimal regimes. SP-UCB-OLP with Î± = 0.01 approaches Oracle performance
(99.95%) while Random provides a lower bound at 61.1%.
6.3
Benchmark Validation: Complementarity Gap
To test whether the switching-aware benchmark V mix is necessary, we construct a diagnostic scenario
S4 with K = 2 configurations having orthogonal resource usage (d = 2). Configuration 0 has
reward r â‰ˆ1 (with uniform noise Â±0.01) and consumption a â‰ˆ[1, 0], consuming only resource 1;
configuration 1 has r â‰ˆ1 and a â‰ˆ[0, 1], consuming only resource 2. The per-period budget is
b = [0.5, 0.5] with Ï = 0.7. By design, the fixed-configuration oracle achieves V âˆ—(b) â‰ˆ0.5 (one
resource wasted), whereas the switching-aware oracle achieves V mix(b) â‰ˆ1.0 (both resources utilized),
yielding a complementarity gap of â‰ˆ2. We use T = 5,000 and 10 random seeds; full specifications
appear in Appendix G.
Recall V âˆ—(b) provided by the fixed configuration oracle defined in Section 4.1 and define
CRâˆ—= E[RÏ€
T ]/V âˆ—(b). Table 3 shows that all learning algorithms achieve CRâˆ—
Ï€ > 1 (exceeding the
fixed oracle), while CRmix
Ï€
â‰¤1 for all algorithms, confirming T Â·V mix is a valid upper bound. Notably,
OneHot achieves CRâˆ—â‰ˆ1.01â€”it cannot exploit complementarity because it commits to a single
configuration.
Complete scenario specifications, algorithm parameters, and extended results appear in Ap-
pendix G.
11


--- Page 12 ---
Oracle
=0.01
=0.10
=1.00
Greedy
( =0)
Random
Algorithm
60%
70%
80%
90%
100%
Competitive Ratio
SP-UCB-OLP Performance on Alibaba Trace Data
(T=5000, =0.7, 50 seeds)
Figure 3: Alibaba traces: competitive ratio across 50 seeds (T = 5,000, Ï = 1.0). Greedy (Î± = 0)
exhibits high variance due to regime lock-in; minimal exploration (Î± = 0.01) dramatically stabilizes
performance.
7
Conclusion
We studied a two-layer sequential decision problem combining configuration exploration and admission
control under budget constraints. We construct a switching-aware fluid oracle which provides a
benchmark that upper bounds the expected total reward of any online policy. This switching-aware
fluid oracle also inspires the design of SP-UCBâ€“OLP algorithm, which solves an optimistic saddle
point problem at each round and uses the computed saddle point to select configurations and do
admission control. We show that the regret of SP-UCBâ€“OLP algorithm against the benchmark
given by the switching-aware oracle is ËœO(
âˆš
KT). We also run numerical experiments to study the
empirical performance of SP-UCBâ€“OLP algorithm.
Limitations and future work.
Our analysis assumes i.i.d. and bounded reward-resource pair
of requests within each configuration. Extensions to non-stationary arrivals, contextual settings
(where configurations depend on observed context), and delayed feedback are natural future research
directions.
Acknowledgements
PJ acknowledges funding from ONR grant N00014-24-1-2470 and AFOSR grant FA9550-23-1-0190.
12


--- Page 13 ---
Table 3: Benchmark validation on S4 (K = 2, d = 2, Ï = 0.7, T = 5,000, 10 seeds). CRâˆ—> 1
confirms the fixed oracle is beatable; CRmix â‰¤1 confirms V mix is a valid upper bound.
Algorithm
CRmix
CRâˆ—
Gap
SP-UCB-OLP
0.91 Â± 0.02
1.81 Â± 0.04
1.99
Greedy
0.96 Â± 0.01
1.90 Â± 0.02
1.99
Random
0.99 Â± 0.00
1.97 Â± 0.00
1.99
OneHot
0.51 Â± 0.01
1.01 Â± 0.02
1.99
References
Shipra Agrawal and Nikhil R. Devanur. Fast algorithms for online stochastic convex programming.
In Proceedings of the 26th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pages
1405â€“1424, 2015. arXiv:1410.7596.
Shipra Agrawal and Nikhil R. Devanur. Linear contextual bandits with knapsacks. In Advances in
Neural Information Processing Systems (NeurIPS), pages 3450â€“3458, 2016. arXiv:1507.06738.
Shipra Agrawal and Nikhil R. Devanur. Bandits with global convex constraints and objective.
Operations Research, 67(5):1486â€“1502, 2019. doi: 10.1287/opre.2019.1840.
Shipra Agrawal, Zizhuo Wang, and Yinyu Ye. A dynamic near-optimal algorithm for online linear
programming. Operations Research, 62(4):876â€“890, 2014. doi: 10.1287/opre.2014.1289.
Shipra Agrawal, Nikhil R. Devanur, and Lihong Li. An efficient algorithm for contextual bandits with
knapsacks, and an extension to concave objectives. In Proceedings of the 29th Annual Conference
on Learning Theory (COLT), volume 49 of PMLR, pages 4â€“18, 2016.
Alibaba Group. Alibaba cluster trace program. https://github.com/alibaba/clusterdata, 2018.
Cluster trace v2018. Accessed: 2024-12-01.
Edward J. Anderson and Peter Nash. Linear Programming in Infinite-Dimensional Spaces: Theory
and Applications. Wiley-Interscience Series in Discrete Mathematics and Optimization. John Wiley
& Sons, Chichester, 1987.
Sanjeev Arora, Elad Hazan, and Satyen Kale. The multiplicative weights update method: A meta-
algorithm and applications. Theory of Computing, 8:121â€“164, 2012. doi: 10.4086/toc.2012.v008a006.
Article 6.
Ashwinkumar Badanidiyuru, Robert Kleinberg, and Aleksandrs Slivkins. Bandits with knapsacks.
Journal of the ACM, 65(3):13:1â€“13:55, 2018. doi: 10.1145/3164539.
Santiago R. Balseiro, Haihao Lu, and Vahab Mirrokni. Dual mirror descent for online allocation
problems. In Proceedings of the 37th International Conference on Machine Learning (ICML),
volume 119 of PMLR, pages 613â€“628, 2020.
Omar Besbes and Assaf Zeevi. Blind network revenue management. Operations Research, 60(6):
1537â€“1550, 2012. doi: 10.1287/opre.1120.1103.
Robert L. Bray. Logarithmic regret in multisecretary and online linear programs with contin-
uous valuations.
Operations Research, 73(4):2188â€“2203, 2024.
doi: 10.1287/opre.2022.0036.
arXiv:1912.08917.
13


--- Page 14 ---
Niv Buchbinder and Joseph Naor. Online primal-dual algorithms for covering and packing problems.
Mathematics of Operations Research, 34(2):270â€“286, 2009. doi: 10.1287/moor.1080.0363.
Guanting Chen, Xiaocheng Li, and Yinyu Ye. An improved analysis of LP-based control for revenue
management. Operations Research, 72(3):1124â€“1138, 2024. doi: 10.1287/opre.2022.2358.
Nikhil R. Devanur and Thomas P. Hayes. The AdWords problem: Online keyword matching with
budgeted bidders under random permutations. In Proceedings of the 10th ACM Conference on
Electronic Commerce (EC), pages 71â€“78, 2009.
Paul DÃ¼tting, Michal Feldman, Thomas Kesselheim, and Brendan Lucier. Prophet inequalities made
easy: Stochastic optimization by pricing non-stochastic inputs. In Proceedings of the 58th Annual
IEEE Symposium on Foundations of Computer Science (FOCS), pages 540â€“551, 2017.
Yoav Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and
an application to boosting. Journal of Computer and System Sciences, 55(1):119â€“139, 1997. doi:
10.1006/jcss.1997.1504.
Guillermo Gallego and Garrett van Ryzin. Optimal dynamic pricing of inventories with stochastic
demand over finite horizons. Management Science, 40(8):999â€“1020, 1994. doi: 10.1287/mnsc.40.8.
999.
Juncheng Gu, Mosharaf Chowdhury, Kang G. Shin, Yibo Zhu, Myeongjae Jeon, Junjie Qian,
Hongqiang Liu, and Chuanxiong Guo. Tiresias: A GPU cluster manager for distributed deep
learning. In Proceedings of the 16th USENIX Symposium on Networked Systems Design and
Implementation (NSDI), pages 485â€“500, 2019.
Nicole Immorlica, Karthik Abinav Sankararaman, Robert Schapire, and Aleksandrs Slivkins. Adver-
sarial bandits with knapsacks. In Proceedings of the 60th Annual IEEE Symposium on Foundations
of Computer Science (FOCS), pages 202â€“219, 2019.
Robert Kleinberg and Seth Matthew Weinberg. Matroid prophet inequalities. In Proceedings of the
44th Annual ACM Symposium on Theory of Computing (STOC), pages 123â€“136, 2012.
Ulrich Krengel and Louis Sucheston. Semiamarts and finite values. Bulletin of the American
Mathematical Society, 83(4):745â€“747, 1977. doi: 10.1090/S0002-9904-1977-14378-4.
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E.
Gonzalez, Hao Zhang, and Ion Stoica. Efficient memory management for large language model
serving with PagedAttention. In Proceedings of the 29th ACM Symposium on Operating Systems
Principles (SOSP), pages 611â€“626, 2023.
Xiaocheng Li and Yinyu Ye.
Online linear programming: Dual convergence, new algorithms,
and regret bounds. Operations Research, 70(5):2948â€“2966, 2022. doi: 10.1287/opre.2021.2164.
arXiv:1909.05499.
Shang Liu, Jiashuo Jiang, and Xiaocheng Li. Non-stationary bandits with knapsacks. In Advances
in Neural Information Processing Systems (NeurIPS), volume 35, 2022. arXiv:2205.12427.
David G. Luenberger. Optimization by Vector Space Methods. John Wiley & Sons, New York, 1969.
14


--- Page 15 ---
Deepak Narayanan, Keshav Santhanam, Fiodar Kazhamiaka, Amar Phanishayee, and Matei Zaharia.
Heterogeneity-aware cluster scheduling policies for deep learning workloads. In Proceedings of
the 14th USENIX Symposium on Operating Systems Design and Implementation (OSDI), pages
481â€“498, 2020.
David Pollard. Convergence of Stochastic Processes. Springer Series in Statistics. Springer-Verlag,
1984.
Aurick Qiao, Sang Keun Choe, Suhas Jayaram Subramanya, Willie Neiswanger, Qirong Ho, Hao
Zhang, Gregory R. Ganger, and Eric P. Xing. Pollux: Co-adaptive cluster scheduling for goodput-
optimized deep learning. In Proceedings of the 15th USENIX Symposium on Operating Systems
Design and Implementation (OSDI), pages 1â€“18, 2021.
Ester Samuel-Cahn. Comparison of threshold stop rules and maximum for independent nonnegative
random variables. Annals of Probability, 12(4):1213â€“1216, 1984. doi: 10.1214/aop/1176993150.
Kalyan T. Talluri and Garrett J. van Ryzin. The Theory and Practice of Revenue Management.
International Series in Operations Research & Management Science. Springer, 2004.
Gyeong-In Yu, Joo Seong Jeong, Geon-Woo Kim, Soojeong Kim, and Byung-Gon Chun. Orca: A
distributed serving system for transformer-based generative models. In Proceedings of the 16th
USENIX Symposium on Operating Systems Design and Implementation (OSDI), pages 521â€“538,
2022.
15


--- Page 16 ---
Contents
1
Introduction
1
2
Related Work
3
3
Model
4
3.1
Assumptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
4
Switching-Aware Fluid Oracle
4
4.1
Fixed configuration oracle leads to negative regret
. . . . . . . . . . . . . . . . . . .
5
4.2
Primal Mixed Fluid Relaxation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
4.3
Dual Form and Envelope Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
4.4
Oracle Justification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
5
Algorithm: SP-UCBâ€“OLP
7
5.1
Confidence Radii and Optimistic Saddle Point Problem . . . . . . . . . . . . . . . . .
7
5.2
Algorithm Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
5.3
Theoretical Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
6
Experiments
8
6.1
Regret Scaling with Horizon . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
6.2
Real-World Validation: Alibaba Traces . . . . . . . . . . . . . . . . . . . . . . . . . .
10
6.3
Benchmark Validation: Complementarity Gap . . . . . . . . . . . . . . . . . . . . . .
11
7
Conclusion
12
A Notation
18
B Algorithm Details
19
C Oracle Construction and Proofs
20
C.1 Bounded Dual Prices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
C.2 Nash Equilibrium Characterization . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
C.3 Pointwise Surplus Inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
22
C.4 Optimal Acceptance Under Fixed Price . . . . . . . . . . . . . . . . . . . . . . . . . .
22
C.5 Proof of Theorem 5 (Primalâ€“Dual Form) . . . . . . . . . . . . . . . . . . . . . . . . .
22
C.6 Proof of Theorem 8 (Oracle Upper Bound) . . . . . . . . . . . . . . . . . . . . . . . .
24
C.7 No-Tie Condition and Subgradients . . . . . . . . . . . . . . . . . . . . . . . . . . . .
24
C.8 Auxiliary Lemmas for Population Primalâ€“Dual Analysis
. . . . . . . . . . . . . . . .
25
C.9 Proof of Theorem 6 (Saddle/KKT Optimality)
. . . . . . . . . . . . . . . . . . . . .
27
C.10 Proof of Theorem 7 (All Saddle Points)
. . . . . . . . . . . . . . . . . . . . . . . . .
28
D Uniform Concentration
29
D.1 Concentration for Surplus Function . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
D.2 Concentration for Threshold Consumption . . . . . . . . . . . . . . . . . . . . . . . .
30
D.3 Good Event . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
16


--- Page 17 ---
E Regret Proof for Theorem 3
32
E.1
Setup
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
E.2
Step 1: Good Event
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
E.3
Step 2: Mixture-Value Regret . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
E.4
Step 3: Admission-Price Error and KKT Feasibility . . . . . . . . . . . . . . . . . . .
34
E.5
Step 4: Budget-Feasibility Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
E.6
Step 5: Summing Confidence Radii and Slack Loss . . . . . . . . . . . . . . . . . . .
38
E.7
Combining All Pieces (Unconditional Expectation; No Conditioning on E) . . . . . .
38
F Implementation Notes
40
F.1
Compute Saddle Point via Linear Programming . . . . . . . . . . . . . . . . . . . . .
40
F.2
Epoch/Doubling Schedule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
G Experimental Details
42
G.1 Scenario Specifications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
G.2 Algorithm Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
G.3 Confidence Radius
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
G.4 E1: Benchmark Validation (Complementarity Gap) . . . . . . . . . . . . . . . . . . .
44
G.5 Alibaba Trace Experiments
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
H Broader Impact
46
Roadmap. This appendix provides complete proofs and extended experiments. Section A defines
notation. Section B details the algorithm. Section C proves the oracle characterization (Theorems 5â€“8
and the saddle/KKT conditions). Section D establishes concentration bounds. Section E proves the
regret bound (Theorem 3). Section F discusses implementation. Section G presents full experimental
specifications and extended results.
17


--- Page 18 ---
A
Notation
Problem Parameters:
â€¢ T: Time horizon
â€¢ B âˆˆRd
+: Initial resource budget vector
â€¢ b := B/T: Per-period budget
â€¢ bsafe := (1 âˆ’Îµ)b: Conservative (safe) per-period budget
â€¢ Î˜ = {1, . . . , K}: Set of configurations
â€¢ d: Resource dimensionality
â€¢ P = [0, Pmax]d: Price domain
Distribution and Arrival Parameters:
â€¢ DÎ¸: Distribution over (r, a) induced by configuration Î¸
â€¢ (rt, at) âˆ¼DÎ¸t: Arrival at time t
â€¢ xt âˆˆ{0, 1}: Admission decision
â€¢ Rmax: Upper bound on rewards
â€¢ Amax: Upper bound on resource consumption
Key Functions:
â€¢ gÎ¸(p) := EÎ¸[(r âˆ’âŸ¨p, aâŸ©)+]: Surplus function
â€¢ hÎ¸(p) := EÎ¸[a Â· 1{r > âŸ¨p, aâŸ©}]: Strict-threshold consumption function (analysis uses >)
â€¢ bgÎ¸,t(p): Empirical surplus from NÎ¸(t) samples
â€¢ bhÎ¸,t(p) :=
1
NÎ¸(t)
P
(r,a)âˆˆSÎ¸(t) a Â· 1{r > âŸ¨p, aâŸ©}: Strict-threshold empirical consumption
Remark 3 (Tie-Handling Convention). Throughout the analysis, we use strict-threshold indicators
(r > âŸ¨p, aâŸ©) for mathematical convenience. Under Assumption 15, this is equivalent to weak thresholds
(r â‰¥âŸ¨p, aâŸ©) for online arrivals. However, empirical minimizers of piecewise-linear objectives can lie
on breakpoints, so the analysis uses strict thresholds to avoid tie-ambiguity. See Lemma 16 for the
tie-weighted subdifferential treatment.
Algorithm Variables:
â€¢ wt âˆˆâˆ†K: Mixture over configurations at time t (algorithm output)
â€¢ Î¸t âˆ¼wt: Configuration sampled from mixture at time t
â€¢ pt âˆˆP: Global bid price at time t
â€¢ Î²Î¸(t): Confidence radius for configuration Î¸ at time t
Oracle and Regret:
â€¢ V mix(b) = minpâˆˆP{âŸ¨p, bâŸ©+ maxÎ¸ gÎ¸(p)}: Switching-aware fluid oracle
â€¢ Regmix(T) := TV mix(b) âˆ’E[RT ]: Switching-aware regret
â€¢ bV opt
t
(w) := minpâˆˆP{âŸ¨p, bsafeâŸ©+ P
Î¸ wÎ¸(bgÎ¸,t(p) + Î²Î¸(t))}: Optimistic mixed value
18


--- Page 19 ---
B
Algorithm Details
We restate Algorithm 1 (SP-UCB-OLP) from the main paper with additional implementation details.
Algorithm 2 SP-UCB-OLP: Optimistic Saddle + Mixture Sampling + Bid-Price Admission
1: Input: Configurations Î˜ (|Î˜| = K), budget B, horizon T, price box P = [0, Pmax]d, exploration
parameter Î±, slack Îµ =
p
log T/T
2: Initialize: Brem â†B, b â†B/T, bsafe â†(1 âˆ’Îµ)b
3: For each Î¸: NÎ¸ â†0, SÎ¸ â†âˆ…
4: for t = 1 to T do
5:
// Warm start: round-robin exploration without consuming budget
6:
if t â‰¤K then
7:
Î¸t â†t {Round-robin}
8:
Observe (rt, at) âˆ¼DÎ¸t
9:
SÎ¸t â†SÎ¸t âˆª{(rt, at)};
NÎ¸t â†NÎ¸t + 1
10:
xt â†0 {Do not consume budget during warm start}
11:
continue
12:
end if
13:
// Compute confidence radii
14:
for each Î¸ âˆˆÎ˜ do
15:
Î²Î¸(t) â†Î± Â· cgRmax
s
d log

c0 d Pmax Amax T
Rmax

+log(KT/Î´)
NÎ¸âˆ¨1
16:
end for
17:
// Empirical surpluses
18:
bgÎ¸,t(p) â†
1
NÎ¸âˆ¨1
P
(r,a)âˆˆSÎ¸(r âˆ’âŸ¨p, aâŸ©)+
19:
// Solve optimistic saddle problem (exact or approximate)
20:
(wt, pt) âˆˆarg maxwâˆˆâˆ†K arg minpâˆˆP

âŸ¨p, bsafeâŸ©+ P
Î¸ wÎ¸(bgÎ¸,t(p) + Î²Î¸(t))
	
21:
// Sample a configuration from the mixture
22:
Draw Î¸t âˆ¼wt
23:
Observe (rt, at) âˆ¼DÎ¸t
24:
SÎ¸t â†SÎ¸t âˆª{(rt, at)};
NÎ¸t â†NÎ¸t + 1
25:
// Admission decision (bid-price with hard feasibility)
26:
if at â‰¤Brem and rt â‰¥âŸ¨pt, atâŸ©then
27:
Accept: xt â†1;
Brem â†Brem âˆ’at
28:
else
29:
Reject: xt â†0
30:
end if
31: end for
Key design features:
1. Warm start: For t â‰¤K, sample each configuration once without consuming budget. This
ensures NÎ¸(t) â‰¥1 for all Î¸ when the saddle problem is first solved, avoiding â€œNÎ¸ âˆ¨1â€ hacks.
The warm start contributes an additive KRmax to regret.
2. Mixture wt is part of the policy: The algorithm outputs a mixture over configurations and
samples Î¸t âˆ¼wt. This is not equivalent to picking the single maximizer of the envelopeâ€”the
mixture is essential for matching multi-resource budgets under complementary configurations.
19


--- Page 20 ---
3. Global price pt: The price is the dual variable of the switching-aware benchmark, not
per-configuration.
4. Optimistic saddle problem: The term P
Î¸ wÎ¸(bgÎ¸,t(p) + Î²Î¸(t)) learns the mixed value with
optimism.
5. Sample storage: All samples (r, a) are stored regardless of admission decision, enabling
unbiased estimation.
6. Conservative slack: Using bsafe = (1 âˆ’Îµ)b ensures budget feasibility with high probability.
7. Strict vs. weak threshold: The algorithm uses rt â‰¥âŸ¨pt, atâŸ©in implementation; the analysis
uses strict thresholds (see Remark 3).
Important note on mixture vs. one-hot selection. The benchmark V mix is generally
attained by a mixture over configurations, not a single configuration. If one instead computes pt
via envelope minimization and picks Î¸t âˆˆarg maxÎ¸(bgÎ¸,t(pt) + Î²Î¸(t)), the policy may fail to match
budget constraints when configurations have complementary resource profiles. Sampling from the
mixture wt ensures the algorithmâ€™s expected resource consumption aligns with the safe budget.
C
Oracle Construction and Proofs
This section proves the primalâ€“dual form of the switching-aware fluid oracle (Theorem 5), the
saddle/KKT conditions (Theorem 6), the characterization of all saddle points (Theorem 7), and the
oracle upper bound (Theorem 8).
C.1
Bounded Dual Prices
We first justify that restricting dual prices to a compact box P = [0, Pmax]d is without loss of
generality.
Lemma 10 (Bounded Dual Prices are W.L.O.G. (Safe Budget)). Assume 0 â‰¤r â‰¤Rmax a.s. and
bsafe âˆˆRd
+ satisfies bsafe
i
â‰¥bsafe
min > 0 for all i. Then every minimizer of
min
pâ‰¥0

âŸ¨p, bsafeâŸ©+ max
Î¸âˆˆÎ˜ gÎ¸(p)

lies in the box âˆ¥pâˆ¥âˆâ‰¤Rmax/bsafe
min. Hence for any Pmax â‰¥Rmax/bsafe
min, restricting to P = [0, Pmax]d
does not change V mix(bsafe).
Proof. Let i be any coordinate and suppose pi > Rmax/bsafe
i
. Then âŸ¨p, bsafeâŸ©â‰¥pibsafe
i
> Rmax. Since
(r âˆ’âŸ¨p, aâŸ©)+ â‰¥0, the objective at p exceeds Rmax.
At p = 0, the objective equals maxÎ¸ EÎ¸[(r)+] = maxÎ¸ EÎ¸[r] â‰¤Rmax. Therefore any point with
pi > Rmax/bsafe
i
cannot be optimal. Applying this coordinatewise yields âˆ¥pâ‹†âˆ¥âˆâ‰¤Rmax/bsafe
min.
Importance. This lemma ensures:
â€¢ The minimax theorem (Sion) applies with compact domain P.
â€¢ The upper boundary constraint pi â‰¤Pmax is non-binding at optimality.
â€¢ KKT conditions for the inner minimization involve only the lower boundary p â‰¥0.
20


--- Page 21 ---
Note: Whenever the analysis claims â€œthe upper box constraint pi â‰¤Pmax is non-binding,â€ the
correct condition is Pmax > Rmax/bsafe
min.
Corollary 11 (Bounded Dual Prices for Empirical Objectives). Fix any mixture w âˆˆâˆ†K and any
time t. Consider the empirical objective
min
pâ‰¥0
(
âŸ¨p, bsafeâŸ©+
X
Î¸
wÎ¸bgÎ¸,t(p)
)
,
bgÎ¸,t(p) =
1
NÎ¸(t)
X
(r,a)âˆˆSÎ¸(t)
(r âˆ’âŸ¨p, aâŸ©)+.
Then every minimizer satisfies âˆ¥pâˆ¥âˆâ‰¤Rmax/bsafe
min. Hence if Pmax > Rmax/bsafe
min, the upper box
constraint pi â‰¤Pmax is non-binding at the empirical minimizer(s) as well.
Proof. The argument is identical to Lemma 10. If pi > Rmax/bsafe
i
, then âŸ¨p, bsafeâŸ©â‰¥pibsafe
i
> Rmax
while bgÎ¸,t(p) â‰¥0, so the objective exceeds Rmax. At p = 0, the objective equals P
Î¸ wÎ¸bgÎ¸,t(0) =
P
Î¸ wÎ¸ 1
NÎ¸
P r â‰¤Rmax. Thus such p cannot be optimal. Apply coordinatewise.
C.2
Nash Equilibrium Characterization
We prove that saddle points of zero-sum games are equivalent to Nash equilibria.
Theorem 12 (Saddle Points â‡”Nash Equilibria). For the zero-sum game with payoff function
L(w, p), a pair (wâˆ—, pâˆ—) is a saddle point of L if and only if it is a Nash equilibrium.
Proof of Theorem 12. Consider the zero-sum game with payoff L(w, p) where Player 1 receives
L(w, p) and Player 2 receives âˆ’L(w, p).
Definition (Saddle Point). (wâˆ—, pâˆ—) is a saddle point if:
L(w, pâˆ—) â‰¤L(wâˆ—, pâˆ—) â‰¤L(wâˆ—, p)
âˆ€w âˆˆâˆ†K, âˆ€p âˆˆP.
Definition (Nash Equilibrium). (wâˆ—, pâˆ—) is a Nash equilibrium if no player can improve by
unilateral deviation:
1. L(wâˆ—, pâˆ—) â‰¥L(w, pâˆ—) for all w âˆˆâˆ†K (Player 1 best-responds)
2. âˆ’L(wâˆ—, pâˆ—) â‰¥âˆ’L(wâˆ—, p) for all p âˆˆP (Player 2 best-responds)
(â‡’) Saddle Point implies Nash Equilibrium.
Assume (wâˆ—, pâˆ—) is a saddle point.
Player 1â€™s condition: The left inequality gives L(w, pâˆ—) â‰¤L(wâˆ—, pâˆ—) for all w, so wâˆ—maximizes
L(Â·, pâˆ—). Player 1 has no profitable deviation.
Player 2â€™s condition: The right inequality gives L(wâˆ—, pâˆ—) â‰¤L(wâˆ—, p) for all p, equivalently
âˆ’L(wâˆ—, p) â‰¤âˆ’L(wâˆ—, pâˆ—). Thus pâˆ—minimizes L(wâˆ—, Â·). Player 2 has no profitable deviation.
(â‡) Nash Equilibrium implies Saddle Point.
Assume (wâˆ—, pâˆ—) is a Nash equilibrium.
From Player 1â€™s condition: L(wâˆ—, pâˆ—) â‰¥L(w, pâˆ—) for all w, yielding the left saddle inequality.
From Player 2â€™s condition: âˆ’L(wâˆ—, pâˆ—) â‰¥âˆ’L(wâˆ—, p) for all p, hence L(wâˆ—, pâˆ—) â‰¤L(wâˆ—, p),
yielding the right saddle inequality.
Combining: L(w, pâˆ—) â‰¤L(wâˆ—, pâˆ—) â‰¤L(wâˆ—, p) for all w, p.
Remark 4 (Existence and Uniqueness). By Sionâ€™s minimax theorem, a saddle point (and hence
Nash equilibrium) exists when âˆ†K and P are compact convex and L is convex in p and linear (hence
concave) in w. The optimal mixture wâˆ—may be unique (when budget constraints pin down resource
utilization), while pâˆ—may be non-unique (any price on the â€œtie surfaceâ€ where configurations have
equal surplus is optimal).
21


--- Page 22 ---
C.3
Pointwise Surplus Inequality
Lemma 13 (Pointwise Surplus Inequality). For any p âˆˆRd
+, any (r, a) âˆˆR+ Ã— Rd
+, and any
x âˆˆ[0, 1]:
r Â· x â‰¤âŸ¨p, aâŸ©Â· x + (r âˆ’âŸ¨p, aâŸ©)+.
Proof. Let z := r âˆ’âŸ¨p, aâŸ©. Then:
âŸ¨p, aâŸ©Â· x + (r âˆ’âŸ¨p, aâŸ©)+ = (r âˆ’z) Â· x + z+ = r Â· x + (z+ âˆ’z Â· x).
We show z+ âˆ’z Â· x â‰¥0:
â€¢ If z â‰¥0: z+ âˆ’z Â· x = z(1 âˆ’x) â‰¥0 since x â‰¤1.
â€¢ If z < 0: z+ = 0 and z+ âˆ’z Â· x = âˆ’z Â· x â‰¥0 since z < 0 and x â‰¥0.
C.4
Optimal Acceptance Under Fixed Price
Lemma 14 (Threshold Optimality). Fix p âˆˆP and Î¸. The optimization:
sup
xÎ¸:0â‰¤xÎ¸â‰¤1
EÎ¸ [(r âˆ’âŸ¨p, aâŸ©) Â· xÎ¸(r, a)]
equals EÎ¸[(r âˆ’âŸ¨p, aâŸ©)+] = gÎ¸(p), achieved by the threshold rule xÎ¸(r, a) = 1{r > âŸ¨p, aâŸ©} (ties
arbitrary).
Proof. For any fixed realization (r, a), the quantity (r âˆ’âŸ¨p, aâŸ©) Â· x is maximized over x âˆˆ[0, 1] by:
â€¢ x = 1 if r âˆ’âŸ¨p, aâŸ©> 0,
â€¢ x = 0 if r âˆ’âŸ¨p, aâŸ©< 0,
â€¢ Any x âˆˆ[0, 1] if r = âŸ¨p, aâŸ©(ties).
Thus the pointwise supremum equals (râˆ’âŸ¨p, aâŸ©)+, achieved by the threshold rule. Taking expectation
yields gÎ¸(p).
C.5
Proof of Theorem 5 (Primalâ€“Dual Form)
Proof of Theorem 5. We prove:
V mix(b) = max
wâˆˆâˆ†K min
pâˆˆP
(
âŸ¨p, bâŸ©+
X
Î¸
wÎ¸gÎ¸(p)
)
= min
pâˆˆP

âŸ¨p, bâŸ©+ max
Î¸
gÎ¸(p)

.
Step 1: Lagrangian dual for fixed w. Fix any w âˆˆâˆ†K. The inner problem in the primal
definition is:
V (w) := max
{xÎ¸}
(X
Î¸
wÎ¸EÎ¸[r Â· xÎ¸]

X
Î¸
wÎ¸EÎ¸[a Â· xÎ¸] â‰¤b
)
.
This is an infinite-dimensional linear program. Let Z := R+ Ã— Rd
+ denote the outcome space (reward-
resource pairs). Each xÎ¸ : Z â†’[0, 1] is a Borel-measurable acceptance function in Lâˆ(Z, B, DÎ¸).
The objective and constraints are linear in xÎ¸, and the Slater constraint qualification is satisfied
22


--- Page 23 ---
since xÎ¸ â‰¡0 is strictly feasible: P
Î¸ wÎ¸EÎ¸[a Â· 0] = 0 â‰ºb (componentwise strict inequality holds
since bmin > 0 by Assumption 3). The key observation is that while the primal space Lâˆis infinite-
dimensional, the constraint map {xÎ¸} 7â†’P
Î¸ wÎ¸EÎ¸[a Â· xÎ¸] takes values in Rd, where the positive
cone Rd
+ has non-empty interior. Under this structure, Slaterâ€™s condition implies strong duality (see
Luenberger [1969], Chapter 8, or Anderson and Nash [1987]):
V (w) = min
pâˆˆP
(
âŸ¨p, bâŸ©+ sup
{xÎ¸}
X
Î¸
wÎ¸EÎ¸[(r âˆ’âŸ¨p, aâŸ©) Â· xÎ¸]
)
.
By Lemma 14, the inner supremum equals P
Î¸ wÎ¸gÎ¸(p). Hence:
V (w) = min
pâˆˆP
(
âŸ¨p, bâŸ©+
X
Î¸
wÎ¸gÎ¸(p)
)
.
Step 2: Maximize over w. By definition, V mix(b) = maxwâˆˆâˆ†K V (w), so:
V mix(b) = max
wâˆˆâˆ†K min
pâˆˆP
(
âŸ¨p, bâŸ©+
X
Î¸
wÎ¸gÎ¸(p)
)
.
Step 3: Minimax swap via Sionâ€™s theorem. Define Î¦(w, p) := âŸ¨p, bâŸ©+ P
Î¸ wÎ¸gÎ¸(p). We
verify the conditions for Sionâ€™s minimax theorem:
â€¢ âˆ†K is compact and convex.
â€¢ P = [0, Pmax]d is compact and convex.
â€¢ For fixed p, Î¦(Â·, p) is linear (hence concave) in w.
â€¢ For fixed w, Î¦(w, Â·) is convex in p because each gÎ¸(p) = E[(r âˆ’âŸ¨p, aâŸ©)+] is convex (expectation
of a convex function in p).
â€¢ Î¦ is continuous and bounded by the boundedness assumptions.
By Sionâ€™s minimax theorem:
max
wâˆˆâˆ†K min
pâˆˆP Î¦(w, p) = min
pâˆˆP max
wâˆˆâˆ†K Î¦(w, p).
Step 4: Simplify max over simplex. For fixed p:
max
wâˆˆâˆ†K
X
Î¸
wÎ¸gÎ¸(p) = max
Î¸
gÎ¸(p),
since a linear function over the simplex is maximized at an extreme point. Therefore:
V mix(b) = min
pâˆˆP

âŸ¨p, bâŸ©+ max
Î¸
gÎ¸(p)

.
23


--- Page 24 ---
C.6
Proof of Theorem 8 (Oracle Upper Bound)
Proof of Theorem 8. Let Ï€ be any causal online policy satisfying PT
t=1 atxt â‰¤B almost surely.
Fix any p âˆˆP. Apply Lemma 13 at each time t with x = xt:
rtxt â‰¤âŸ¨p, atâŸ©xt + (rt âˆ’âŸ¨p, atâŸ©)+.
Summing over t = 1, . . . , T:
RÏ€
T =
T
X
t=1
rtxt â‰¤
*
p,
T
X
t=1
atxt
+
+
T
X
t=1
(rt âˆ’âŸ¨p, atâŸ©)+.
By pathwise feasibility:
RÏ€
T â‰¤âŸ¨p, BâŸ©+
T
X
t=1
(rt âˆ’âŸ¨p, atâŸ©)+.
Taking expectation:
E[RÏ€
T ] â‰¤âŸ¨p, BâŸ©+
T
X
t=1
E [(rt âˆ’âŸ¨p, atâŸ©)+] .
Condition on Î¸t. Since (rt, at) | (Î¸t = Î¸) âˆ¼DÎ¸:
E [(rt âˆ’âŸ¨p, atâŸ©)+ | Î¸t = Î¸] = gÎ¸(p).
Model assumption used: The equality above uses Assumption 1, which ensures that conditional
on Î¸t = Î¸, the pair (rt, at) is distributed according to DÎ¸.
Thus:
E [(rt âˆ’âŸ¨p, atâŸ©)+] =
X
Î¸
Pr(Î¸t = Î¸) Â· gÎ¸(p).
Define the empirical mixture Â¯wÎ¸ := 1
T
PT
t=1 Pr(Î¸t = Î¸). Then Â¯w âˆˆâˆ†K and:
1
T
T
X
t=1
E [(rt âˆ’âŸ¨p, atâŸ©)+] =
X
Î¸
Â¯wÎ¸gÎ¸(p) â‰¤max
Î¸
gÎ¸(p).
Therefore:
E[RÏ€
T ] â‰¤T

âŸ¨p, bâŸ©+ max
Î¸
gÎ¸(p)

.
Minimizing over p âˆˆP and applying Theorem 1:
E[RÏ€
T ] â‰¤T Â· V mix(b).
C.7
No-Tie Condition and Subgradients
For the regret analysis, we require a technical assumption on online arrivals.
Assumption 15 (No-Tie Condition). For all Î¸ âˆˆÎ˜ and all p âˆˆP,
Pr
(r,a)âˆ¼DÎ¸
 r = âŸ¨p, aâŸ©

= 0.
24


--- Page 25 ---
See Remark 3 for why we use strict thresholds in the analysis.
Lemma 16 (Subgradients and Tie-Weighted Consumption). Fix any sample (r, a) and define
Ï•p(r, a) := (r âˆ’âŸ¨p, aâŸ©)+. Then Ï•p is convex in p and its subdifferential is
âˆ‚pÏ•p(r, a) =
ï£±
ï£´
ï£²
ï£´
ï£³
{âˆ’a},
r > âŸ¨p, aâŸ©,
{âˆ’Î»a : Î» âˆˆ[0, 1]},
r = âŸ¨p, aâŸ©,
{0},
r < âŸ¨p, aâŸ©.
Equivalently, for any Î» âˆˆ[0, 1], the vector
âˆ’a

1{r > âŸ¨p, aâŸ©} + Î»1{r = âŸ¨p, aâŸ©}

is a valid subgradient of Ï•p(r, a).
Now fix Î¸ and time t with samples SÎ¸(t) = {(rj, aj)}NÎ¸(t)
j=1
and define
bgÎ¸,t(p) :=
1
NÎ¸(t)
NÎ¸(t)
X
j=1
(rj âˆ’âŸ¨p, ajâŸ©)+.
For any p and any tie-weight vector Î» âˆˆ[0, 1]NÎ¸(t), define the tie-weighted empirical consumption
bhÎ»
Î¸,t(p) :=
1
NÎ¸(t)
NÎ¸(t)
X
j=1
aj

1{rj > âŸ¨p, ajâŸ©} + Î»j1{rj = âŸ¨p, ajâŸ©}

.
Then
âˆ‚bgÎ¸,t(p) =
n
âˆ’bhÎ»
Î¸,t(p) : Î» âˆˆ[0, 1]NÎ¸(t)o
.
Moreover, componentwise for every p and Î»,
bh>,
Î¸,t(p) â‰¤bhÎ»
Î¸,t(p) â‰¤bhâ‰¥,
Î¸,t(p),
where bh>,
Î¸,t(p) uses the strict indicator and bhâ‰¥,
Î¸,t(p) uses the weak indicator.
Proof. The pointwise subdifferential formula is standard for the hinge composed with an affine map.
For the empirical average bgÎ¸,t, the subdifferential is the average of the pointwise subdifferentials (finite
sum of convex functions), hence it equals the set of averages of admissible pointwise subgradients;
this is exactly the tie-weighted form above. The sandwich inequality holds because at a tie the
contribution is Î»jaj with Î»j âˆˆ[0, 1].
C.8
Auxiliary Lemmas for Population Primalâ€“Dual Analysis
Lemma 17 (Upper Box Constraint is Inactive at Minimizers). Assume 0 â‰¤r â‰¤Rmax a.s. and
bmin > 0. Fix any w âˆˆâˆ†K and consider the convex function
Fw(p) := âŸ¨p, bâŸ©+
X
Î¸
wÎ¸gÎ¸(p),
p âˆˆRd
+.
Then every minimizer of minpâ‰¥0 Fw(p) satisfies âˆ¥pâˆ¥âˆâ‰¤Rmax/bmin. In particular, if Pmax >
Rmax/bmin, then every minimizer of minpâˆˆP Fw(p) lies in the strict interior of the upper box
constraints, i.e., pi < Pmax for all i.
25


--- Page 26 ---
Proof. Fix coordinate i and suppose pi > Rmax/bi. Then
Fw(p) â‰¥âŸ¨p, bâŸ©â‰¥pibi > Rmax.
On the other hand, at p = 0,
Fw(0) =
X
Î¸
wÎ¸EÎ¸[r] â‰¤Rmax.
Hence no point with pi > Rmax/bi can be optimal. Applying this argument to all i gives âˆ¥pâˆ¥âˆâ‰¤
Rmax/bmin. If Pmax > Rmax/bmin, then âˆ¥pâˆ¥âˆâ‰¤Rmax/bmin implies p cannot satisfy pi = Pmax for
any i.
Lemma 18 (Differentiability and Gradient Formula for gÎ¸). Assume Assumption 2 and Assump-
tion 15 (no ties). Then for each Î¸, gÎ¸ is convex and continuously differentiable on P, and
âˆ‡gÎ¸(p) = âˆ’hÎ¸(p) = âˆ’EÎ¸[a 1{r > âŸ¨p, aâŸ©}] .
Consequently, for any w âˆˆâˆ†K,
âˆ‡pL(w, p) = b âˆ’H(w, p).
Proof. Fix Î¸ and define Ï•(p; r, a) := (r âˆ’âŸ¨p, aâŸ©)+, so gÎ¸(p) = EÎ¸[Ï•(p; r, a)].
Step 1 (convexity). For each fixed (r, a), p 7â†’r âˆ’âŸ¨p, aâŸ©is affine and x 7â†’x+ is convex, hence
p 7â†’Ï•(p; r, a) is convex. Expectation preserves convexity, so gÎ¸ is convex.
Step 2 (pointwise derivative). Fix coordinate i and consider the one-sided difference quotient:
D(i)
t (r, a) := Ï•(p + tei; r, a) âˆ’Ï•(p; r, a)
t
,
t Ì¸= 0.
Because x 7â†’x+ is 1-Lipschitz and the argument changes by ta(i), we have
|D(i)
t (r, a)| â‰¤a(i) â‰¤Amax
a.s.
Moreover, for any (r, a) with r Ì¸= âŸ¨p, aâŸ©(which holds a.s. by Assumption 15), Ï•(Â·; r, a) is differentiable
at p and
lim
tâ†’0 D(i)
t (r, a) = âˆ‚
âˆ‚pi
Ï•(p; r, a) =
(
âˆ’a(i),
r > âŸ¨p, aâŸ©,
0,
r < âŸ¨p, aâŸ©.
Equivalently,
âˆ‚
âˆ‚pi
Ï•(p; r, a) = âˆ’a(i)1{r > âŸ¨p, aâŸ©}
a.s.
Step 3 (interchange derivative and expectation). By the uniform bound |D(i)
t (r, a)| â‰¤Amax
and dominated convergence,
âˆ‚
âˆ‚pi
gÎ¸(p) = âˆ‚
âˆ‚pi
EÎ¸[Ï•(p; r, a)] = EÎ¸
 âˆ‚
âˆ‚pi
Ï•(p; r, a)

= âˆ’EÎ¸
h
a(i)1{r > âŸ¨p, aâŸ©}
i
.
Stacking coordinates yields âˆ‡gÎ¸(p) = âˆ’hÎ¸(p).
Step 4 (continuity of the gradient). Let pn â†’p. Then 1{r > âŸ¨pn, aâŸ©} â†’1{r > âŸ¨p, aâŸ©}
pointwise for all (r, a) such that r Ì¸= âŸ¨p, aâŸ©; by Assumption 15 this holds a.s. Bounded convergence
with 0 â‰¤a(i) â‰¤Amax implies E[a(i)1{r > âŸ¨pn, aâŸ©}] â†’E[a(i)1{r > âŸ¨p, aâŸ©}], so âˆ‡gÎ¸ is continuous on
P.
Finally, âˆ‡pL(w, p) = b + P
Î¸ wÎ¸âˆ‡gÎ¸(p) = b âˆ’H(w, p).
Lemma 19 (Nonnegative Dot Product Complementarity is Coordinatewise). If u, v âˆˆRd
+ and
âŸ¨u, vâŸ©= 0, then uivi = 0 for every i âˆˆ[d].
Proof. Each term uivi â‰¥0 and P
i uivi = 0, hence each term must be zero.
26


--- Page 27 ---
C.9
Proof of Theorem 6 (Saddle/KKT Optimality)
Proof of Theorem 6. Assume Assumptions 2â€“15, and assume Pmax > Rmax/bmin so that by Lemma 17
the upper box constraints are inactive at any minimizer of p 7â†’L(w, p) for any fixed w.
We prove the equivalence between:
(S) (wâ‹†, pâ‹†) is a saddle point of L, i.e.,
L(w, pâ‹†) â‰¤L(wâ‹†, pâ‹†) â‰¤L(wâ‹†, p)
âˆ€w âˆˆâˆ†K, âˆ€p âˆˆP;
(KKT) conditions (i)â€“(iii) in the theorem statement.
(S) â‡’(KKT).
Step 1 (Envelope support). Fix pâ‹†. The map w 7â†’L(w, pâ‹†) = âŸ¨pâ‹†, bâŸ©+ P
Î¸ wÎ¸gÎ¸(pâ‹†) is linear in
w over the simplex. Therefore, any maximizer wâ‹†âˆˆarg maxwâˆˆâˆ†K L(w, pâ‹†) must place all its mass
on indices attaining the maximum coefficient gÎ¸(pâ‹†):
supp(wâ‹†) âŠ†A(pâ‹†) := arg max
Î¸
gÎ¸(pâ‹†).
This is condition (i).
Step 2 (First-order optimality for the p-minimization). Because (wâ‹†, pâ‹†) is a saddle, pâ‹†âˆˆ
arg minpâˆˆP L(wâ‹†, p). By Lemma 17, pâ‹†lies in the interior of the upper box constraints, so the
effective constraint set is only p âˆˆRd
+.
By Lemma 18, L(wâ‹†, p) is convex and differentiable in p with âˆ‡pL(wâ‹†, p) = b âˆ’H(wâ‹†, p). The
KKT condition for minimizing a convex differentiable function over Rd
+ is
0 âˆˆâˆ‡pL(wâ‹†, pâ‹†) + NRd
+(pâ‹†),
where NRd
+(pâ‹†) is the normal cone to Rd
+ at pâ‹†. Equivalently, there exists v âˆˆNRd
+(pâ‹†) such that
0 = b âˆ’H(wâ‹†, pâ‹†) + v.
The normal cone satisfies: vi = 0 if pâ‹†
i > 0, and vi â‰¤0 if pâ‹†
i = 0. Thus:
pâ‹†
i > 0 â‡’bi âˆ’Hi(wâ‹†, pâ‹†) = 0,
pâ‹†
i = 0 â‡’bi âˆ’Hi(wâ‹†, pâ‹†) â‰¥0.
Hence H(wâ‹†, pâ‹†) â‰¤b componentwise, which is condition (ii). Also, bi âˆ’Hi(wâ‹†, pâ‹†) â‰¥0 and pâ‹†
i â‰¥0
imply âŸ¨pâ‹†, b âˆ’H(wâ‹†, pâ‹†)âŸ©â‰¥0. Moreover, because the coordinatewise implications above include
pâ‹†
i (bi âˆ’Hi(wâ‹†, pâ‹†)) = 0 for each i, we obtain
âŸ¨pâ‹†, b âˆ’H(wâ‹†, pâ‹†)âŸ©= 0,
which is condition (iii).
(KKT) â‡’(S).
Assume (i)â€“(iii).
Step 1 (wâ‹†is a best response to pâ‹†). For fixed pâ‹†, w 7â†’L(w, pâ‹†) is linear over âˆ†K, and its
maximum value equals âŸ¨pâ‹†, bâŸ©+ maxÎ¸ gÎ¸(pâ‹†). Condition (i) implies P
Î¸ wâ‹†
Î¸gÎ¸(pâ‹†) = maxÎ¸ gÎ¸(pâ‹†),
hence for all w âˆˆâˆ†K,
L(w, pâ‹†) â‰¤L(wâ‹†, pâ‹†).
27


--- Page 28 ---
Step 2 (pâ‹†is a best response to wâ‹†). By Lemma 18, L(wâ‹†, p) is convex differentiable in p.
Since (ii) gives b âˆ’H(wâ‹†, pâ‹†) âˆˆRd
+ and (iii) gives âŸ¨pâ‹†, b âˆ’H(wâ‹†, pâ‹†)âŸ©= 0, Lemma 19 implies
pâ‹†
i (bi âˆ’Hi(wâ‹†, pâ‹†)) = 0 for each i. Equivalently:
pâ‹†
i > 0 â‡’bi âˆ’Hi(wâ‹†, pâ‹†) = 0,
pâ‹†
i = 0 â‡’bi âˆ’Hi(wâ‹†, pâ‹†) â‰¥0.
This is exactly the KKT condition 0 âˆˆâˆ‡pL(wâ‹†, pâ‹†) + NRd
+(pâ‹†) for minimizing L(wâ‹†, Â·) over Rd
+
(upper box inactive by our choice of Pmax). Therefore pâ‹†âˆˆarg minpâˆˆP L(wâ‹†, p), and for all p âˆˆP,
L(wâ‹†, pâ‹†) â‰¤L(wâ‹†, p).
Combining Steps 1 and 2 yields the saddle inequalities, so (wâ‹†, pâ‹†) is a saddle point.
Primal optimality of threshold admission and value identity. Let x(r, a) := 1{r > âŸ¨pâ‹†, aâŸ©}
and define the achieved (fluid) reward
U(wâ‹†, pâ‹†) :=
X
Î¸
wâ‹†
Î¸EÎ¸[r1{r > âŸ¨pâ‹†, aâŸ©}] .
Using the identity r1{r > âŸ¨pâ‹†, aâŸ©} = âŸ¨pâ‹†, aâŸ©1{r > âŸ¨pâ‹†, aâŸ©} + (r âˆ’âŸ¨pâ‹†, aâŸ©)+, we obtain
U(wâ‹†, pâ‹†) = âŸ¨pâ‹†, H(wâ‹†, pâ‹†)âŸ©+
X
Î¸
wâ‹†
Î¸gÎ¸(pâ‹†).
Hence
L(wâ‹†, pâ‹†) = âŸ¨pâ‹†, bâŸ©+
X
Î¸
wâ‹†
Î¸gÎ¸(pâ‹†) = U(wâ‹†, pâ‹†) + âŸ¨pâ‹†, b âˆ’H(wâ‹†, pâ‹†)âŸ©.
By condition (iii), the last inner product is zero, so U(wâ‹†, pâ‹†) = L(wâ‹†, pâ‹†). Condition (ii) implies
the threshold rule is feasible for the primal constraint. Finally, since (wâ‹†, pâ‹†) is a saddle point,
L(wâ‹†, pâ‹†) equals the minimax value V mix(b) by Theorem 5. Therefore the mixture wâ‹†together
with threshold admission attains V mix(b) and is primal-optimal for (1).
C.10
Proof of Theorem 7 (All Saddle Points)
Proof of Theorem 7. Recall
f(p) := âŸ¨p, bâŸ©+ max
Î¸âˆˆÎ˜ gÎ¸(p),
Pâ‹†:= arg min
pâˆˆP f(p),
and the candidate saddle set
S =
n
(w, p) âˆˆâˆ†K Ã— P : p âˆˆPâ‹†, supp(w) âŠ†A(p), H(w, p) â‰¤b, âŸ¨p, b âˆ’H(w, p)âŸ©= 0
o
.
Step 1 (Any saddle point lies in S). Let (wâ‹†, pâ‹†) be any saddle point of L. By Theorem 6,
we have supp(wâ‹†) âŠ†A(pâ‹†), H(wâ‹†, pâ‹†) â‰¤b, and âŸ¨pâ‹†, b âˆ’H(wâ‹†, pâ‹†)âŸ©= 0.
Moreover, supp(wâ‹†) âŠ†A(pâ‹†) implies P
Î¸ wâ‹†
Î¸gÎ¸(pâ‹†) = maxÎ¸ gÎ¸(pâ‹†), so
L(wâ‹†, pâ‹†) = âŸ¨pâ‹†, bâŸ©+
X
Î¸
wâ‹†
Î¸gÎ¸(pâ‹†) = âŸ¨pâ‹†, bâŸ©+ max
Î¸
gÎ¸(pâ‹†) = f(pâ‹†).
Because (wâ‹†, pâ‹†) is a saddle point, L(wâ‹†, pâ‹†) equals the minimax value, and by Theorem 5 this
value is minpâˆˆP f(p). Hence
f(pâ‹†) = min
pâˆˆP f(p),
so pâ‹†âˆˆPâ‹†. Therefore (wâ‹†, pâ‹†) âˆˆS.
Step 2 (Any point in S is a saddle point). Now let (w, p) âˆˆS. Then supp(w) âŠ†A(p),
H(w, p) â‰¤b, and âŸ¨p, b âˆ’H(w, p)âŸ©= 0. These are exactly conditions (i)â€“(iii) of Theorem 6.
Therefore (w, p) is a saddle point of L.
Combining Steps 1 and 2 proves that the set of all saddle points of L is exactly S.
28


--- Page 29 ---
D
Uniform Concentration
We prove uniform concentration bounds for the empirical surplus and consumption functions.
D.1
Concentration for Surplus Function
Lemma 20 (Uniform Concentration for gÎ¸ (Fixed n)). Fix Î¸ and n â‰¥1. Let {(ri, ai)}n
i=1 be i.i.d.
samples from DÎ¸ and define
bgÎ¸,n(p) := 1
n
n
X
i=1
(ri âˆ’âŸ¨p, aiâŸ©)+,
gÎ¸(p) := EÎ¸[(r âˆ’âŸ¨p, aâŸ©)+].
There exist absolute constants cg, c0 > 0 such that for any Î´ âˆˆ(0, 1), with probability at least 1 âˆ’Î´,
sup
pâˆˆP
bgÎ¸,n(p) âˆ’gÎ¸(p)
 â‰¤cgRmax
v
u
u
td log

c0dPmaxAmaxn
Rmax

+ log(2/Î´)
n
.
Proof. Step 1 (Pointwise Hoeffding). For fixed p, the random variable (r âˆ’âŸ¨p, aâŸ©)+ lies in
[0, Rmax]. Thus by Hoeffding,
Pr
 bgÎ¸,n(p) âˆ’gÎ¸(p)
 > Ïµ

â‰¤2 exp

âˆ’2nÏµ2
R2max

.
Step 2 (Lipschitzness in p). For any p, q âˆˆP and any (r, a),
(r âˆ’âŸ¨p, aâŸ©)+ âˆ’(r âˆ’âŸ¨q, aâŸ©)+
 â‰¤|âŸ¨p âˆ’q, aâŸ©| â‰¤Amaxâˆ¥p âˆ’qâˆ¥1,
using âˆ¥aâˆ¥âˆâ‰¤Amax. Hence both bgÎ¸,n and gÎ¸ are Amax-Lipschitz in â„“1.
Step 3 (â„“1-net + union bound). Let Î· > 0 and let N be an â„“1-net of P = [0, Pmax]d with
radius Î·. A standard volume argument gives |N| â‰¤
  c0dPmax
Î·
d for an absolute constant c0 > 0.
For any p âˆˆP, pick q âˆˆN with âˆ¥p âˆ’qâˆ¥1 â‰¤Î·. By Lipschitzness,
bgÎ¸,n(p) âˆ’gÎ¸(p)
 â‰¤
bgÎ¸,n(q) âˆ’gÎ¸(q)
 + 2AmaxÎ·.
Set Î· = Ïµ/(4Amax). Then
Pr
 
sup
pâˆˆP
bgÎ¸,n(p) âˆ’gÎ¸(p)
 > Ïµ
!
â‰¤Pr

max
qâˆˆN
bgÎ¸,n(q) âˆ’gÎ¸(q)
 > Ïµ/2

â‰¤
X
qâˆˆN
Pr
 bgÎ¸,n(q) âˆ’gÎ¸(q)
 > Ïµ/2

â‰¤2|N| exp

âˆ’2n(Ïµ/2)2
R2max

= 2|N| exp

âˆ’nÏµ2
2R2max

.
Substitute |N| â‰¤
  4c0dPmaxAmax
Ïµ
d and solve for Ïµ so that the RHS is at most Î´. This yields the stated
bound.
Ïµ = Rmax
v
u
u
u
td log

4dPmaxAmax
Rmax
2
n

+ log
  1
Î´2

n
29


--- Page 30 ---
Corollary 21 (Anytime Version for Adaptive Sample Sizes). Fix Î¸ and horizon T. There exists an
absolute constant câ€²
g > 0 such that for any Î´ âˆˆ(0, 1), with probability at least 1 âˆ’Î´, the following
holds simultaneously for all n âˆˆ{1, . . . , T}:
sup
pâˆˆP
bgÎ¸,n(p) âˆ’gÎ¸(p)
 â‰¤câ€²
gRmax
v
u
u
td log

c0dPmaxAmaxT
Rmax

+ log(2T/Î´)
n
.
Consequently, at any time t â‰¤T, the bound holds with n = NÎ¸(t) even when NÎ¸(t) is chosen
adaptively.
Proof. Apply Lemma 20 with confidence level Î´/T and take a union bound over n = 1, . . . , T.
D.2
Concentration for Threshold Consumption
The threshold consumption function involves weighted indicators a(i) Â· 1{r > âŸ¨p, aâŸ©}, which is not a
pure indicator class. We use pseudo-dimension to obtain uniform concentration.
Lemma 22 (Pseudo-Dimension of Weighted Threshold Consumption). Fix a coordinate i âˆˆ[d] and
define the function class
Fi :=
n
fp(r, a) := a(i) 1{r > âŸ¨p, aâŸ©} : p âˆˆP
o
.
Then Pdim(Fi) â‰¤d + 2.
Proof. Recall the definition of pseudo-dimension: Fi pseudo-shatters n points z1, . . . , zn if there
exist thresholds s1, . . . , sn such that for every labeling S âŠ†[n] there exists f âˆˆFi with f(zj) > sj
iff j âˆˆS.
Take any candidate set {zj = (rj, aj)}n
j=1 and thresholds {sj}.
If sj < 0, then fp(zj) â‰¥0 > sj for all p, so the label of j cannot vary across S. If sj â‰¥a(i)
j , then
fp(zj) â‰¤a(i)
j
â‰¤sj for all p, so again the label cannot vary. Therefore, for a point to be label-flexible
under pseudo-shattering, it must satisfy 0 â‰¤sj < a(i)
j .
For such j, we have:
fp(zj) > sj
â‡â‡’
a(i)
j 1{rj > âŸ¨p, ajâŸ©} > sj
â‡â‡’
1{rj > âŸ¨p, ajâŸ©} = 1.
Thus, on the subset of flexible points, pseudo-shattering by Fi reduces exactly to shattering by the
halfspace indicator class
H := {(r, a) 7â†’1{r > âŸ¨p, aâŸ©} : p âˆˆP} ,
which is a class of halfspaces in Rd+1 and satisfies VCdim(H) â‰¤d + 2. Therefore no more than d + 2
flexible points can be shattered, and hence Pdim(Fi) â‰¤d + 2.
Theorem 23 (Uniform Deviation Bound for Pseudo-Dimension Classes). Let F be a class of
functions mapping into [0, 1] with pseudo-dimension v. Let Z1, . . . , Zn be i.i.d. samples from any
distribution. Then for any Î´ âˆˆ(0, 1), with probability at least 1 âˆ’Î´,
sup
fâˆˆF

E[f(Z)] âˆ’1
n
n
X
j=1
f(Zj)

â‰¤c
r
v log(en) + log(1/Î´)
n
,
for a universal constant c > 0.
30


--- Page 31 ---
This is a standard result in statistical learning theory (see, e.g., Pollard [1984]).
Lemma 24 (Uniform Concentration for hÎ¸ (Strict and Weak Thresholds)). Fix Î¸, n â‰¥1, and coor-
dinate i âˆˆ[d]. Let {(rj, aj)}n
j=1 be i.i.d. from DÎ¸. Define the strict and weak empirical consumptions
bh>,(i)
Î¸,n (p) := 1
n
n
X
j=1
a(i)
j 1{rj > âŸ¨p, ajâŸ©},
bhâ‰¥,(i)
Î¸,n (p) := 1
n
n
X
j=1
a(i)
j 1{rj â‰¥âŸ¨p, ajâŸ©},
and the population consumption (using strict threshold)
h(i)
Î¸ (p) := EÎ¸
h
a(i)1{r > âŸ¨p, aâŸ©}
i
.
Assume Assumption 15 (so that Pr(r = âŸ¨p, aâŸ©) = 0 for all p âˆˆP), hence E[a(i)1{r â‰¥âŸ¨p, aâŸ©}] =
h(i)
Î¸ (p) as well. Then there exists an absolute constant ch > 0 such that for any Î´ âˆˆ(0, 1), with
probability at least 1 âˆ’Î´,
sup
pâˆˆP
bh>,(i)
Î¸,n (p) âˆ’h(i)
Î¸ (p)
 â‰¤chAmax
r
(d + 2) log(en) + log(4/Î´)
n
,
and simultaneously
sup
pâˆˆP
bhâ‰¥,(i)
Î¸,n (p) âˆ’h(i)
Î¸ (p)
 â‰¤chAmax
r
(d + 2) log(en) + log(4/Î´)
n
.
Proof. Both function classes {(r, a) 7â†’a(i)1{r > âŸ¨p, aâŸ©} : p âˆˆP} and {(r, a) 7â†’a(i)1{r â‰¥âŸ¨p, aâŸ©} :
p âˆˆP} have pseudo-dimension at most d + 2 by the same argument as Lemma 22 (the strict vs.
weak inequality does not change VC/pseudo-dimension). After scaling by Amax the functions map
into [0, 1]. Apply Theorem 23 to each class with confidence Î´/2 and union bound. Assumption 15
ensures both expectations coincide with h(i)
Î¸ (p).
Corollary 25 (Anytime Version for Adaptive Sample Sizes). Fix Î¸ and horizon T. There exists a
constant câ€²
h > 0 such that for any Î´ âˆˆ(0, 1), with probability at least 1 âˆ’Î´, the bounds in Lemma 24
hold simultaneously for all n âˆˆ{1, . . . , T} (for both strict and weak thresholds) with the RHS replaced
by
câ€²
hAmax
r
(d + 2) log(eT) + log(4Td/Î´)
n
.
Consequently, at any time t â‰¤T, the bound holds with n = NÎ¸(t) under adaptive sampling.
Proof. Apply Lemma 24 with confidence Î´/T and union bound over n â‰¤T (and over coordinates i
if desired).
D.3
Good Event
Good event definition.
Fix a global confidence Î´tot := T âˆ’2. For each Î¸, apply Corollary 21
with confidence Î´g := Î´tot/(2K) and apply Corollary 25 with confidence Î´h := Î´tot/(2K) (and union
bound over coordinates i âˆˆ[d] inside the corollary if desired). Let E be the event that for every Î¸
and every n â‰¤T simultaneously:
â€¢ suppâˆˆP |bgÎ¸,n(p) âˆ’gÎ¸(p)| â‰¤Î²g,Î¸(n),
â€¢ for every coordinate i, both strict and weak empirical consumptions satisfy suppâˆˆP |bh>,(i)
Î¸,n (p) âˆ’
h(i)
Î¸ (p)| â‰¤Î²h,Î¸(n) and suppâˆˆP |bhâ‰¥,(i)
Î¸,n (p) âˆ’h(i)
Î¸ (p)| â‰¤Î²h,Î¸(n).
Then Pr(Ec) â‰¤Î´tot.
31


--- Page 32 ---
Confidence radii.
For definiteness, one may take (for n â‰¥1)
Î²g,Î¸(n) := câ€²
gRmax
v
u
u
td log

c0dPmaxAmaxT
Rmax

+ log(2KT/Î´tot)
n
,
Î²h,Î¸(n) := câ€²
hAmax
r
(d + 2) log(eT) + log(4KTd/Î´t
n
In the regret proof, we evaluate these at n = NÎ¸(t).
E
Regret Proof for Theorem 3
We prove the main theorem following a five-step decomposition.
E.1
Setup
Let Îµ =
p
log T/T and bsafe = (1 âˆ’Îµ)b. For mixture w âˆˆâˆ†K, define:
V (w) := min
pâˆˆP
(
âŸ¨p, bsafeâŸ©+
X
Î¸
wÎ¸gÎ¸(p)
)
,
V mix(bsafe) = max
wâˆˆâˆ†K V (w).
Define the optimistic mixed value:
bV opt
t
(w) := min
pâˆˆP
(
âŸ¨p, bsafeâŸ©+
X
Î¸
wÎ¸
 bgÎ¸,t(p) + Î²g,Î¸(t)

)
.
The algorithm chooses wt âˆˆarg maxwâˆˆâˆ†K bV opt
t
(w).
Confidence radii used in the analysis.
Fix Î´tot := T âˆ’2. Let Î²g,Î¸(t) be any sequence satisfying
suppâˆˆP |bgÎ¸,t(p) âˆ’gÎ¸(p)| â‰¤Î²g,Î¸(t) on E. For concreteness, by Corollary 21 one may take
Î²g,Î¸(t) := Î± câ€²
gRmax
v
u
u
td log

c0dPmaxAmaxT
Rmax

+ log

2KT
Î´tot

NÎ¸(t) âˆ¨1
,
with any fixed Î± â‰¥1.
Similarly, by Corollary 25 one may take
Î²h,Î¸(t) := câ€²
hAmax
v
u
u
t(d + 2) log(eT) + log

4KTd
Î´tot

NÎ¸(t) âˆ¨1
.
E.2
Step 1: Good Event
On the good event E (probability â‰¥1 âˆ’O(1/T)):
â€¢ suppâˆˆP |bgÎ¸,t(p) âˆ’gÎ¸(p)| â‰¤Î²g,Î¸(t) for all Î¸, t.
â€¢ suppâˆˆP |bh(i)
Î¸,t(p) âˆ’h(i)
Î¸ (p)| â‰¤Î²h,Î¸(t) for all Î¸, t, i.
The bad event contributes at most
E

Regmix(T)1Ec
â‰¤TRmax Pr(Ec) â‰¤TRmax Â· T âˆ’2 = Rmax
T
,
which is negligible compared to the main terms (and can be absorbed into constants).
32


--- Page 33 ---
Lemma 26 (Mixture-Weight Bridge). Since Î¸t âˆ¼wt and Î²Î¸(t) is Ftâˆ’1-measurable,
E[Î²Î¸t(t) | Ftâˆ’1] =
X
Î¸
wt,Î¸Î²Î¸(t).
Therefore, for any realization,
E
" T
X
t=1
Î²Î¸t(t)
#
= E
" T
X
t=1
X
Î¸
wt,Î¸Î²Î¸(t)
#
,
and standard concentration bounds apply to the realized arm sequence {Î¸t}T
t=1.
Proof. Fix any round t. Since wt = (wt,1, . . . , wt,K) is determined by the history up to round t âˆ’1
(i.e., wt âˆˆFtâˆ’1) and Î¸t is drawn from the categorical distribution with weights wt, we have by
definition:
E[Î²Î¸t(t) | Ftâˆ’1] =
K
X
Î¸=1
Pr(Î¸t = Î¸ | Ftâˆ’1) Â· Î²Î¸(t) =
K
X
Î¸=1
wt,Î¸Î²Î¸(t).
Summing over t and taking total expectation via the tower property yields the result. This lemma
bridges the gap between our algorithmâ€™s mixture sampling and classical chosen-arm concentration
lemmas, justifying why bounds on P
Î¸ wt,Î¸Î²Î¸(t) translate to bounds on P
t Î²Î¸t(t).
E.3
Step 2: Mixture-Value Regret
Lemma 27 (Optimism and True Value). On E, for all t â‰¤T and all w âˆˆâˆ†K:
V (w) â‰¤bV opt
t
(w) â‰¤V (w) + 2
X
Î¸
wÎ¸Î²g,Î¸(t).
In particular, bV opt
t
(w) is an optimistic upper bound on V (w).
Proof. For any p, on E:
X
Î¸
wÎ¸gÎ¸(p) â‰¤
X
Î¸
wÎ¸(bgÎ¸,t(p) + Î²g,Î¸(t)).
Adding âŸ¨p, bsafeâŸ©and taking minpâˆˆP gives the lower bound V (w) â‰¤bV opt
t
(w).
For the upper bound, on E:
X
Î¸
wÎ¸(bgÎ¸,t(p) + Î²g,Î¸(t)) â‰¤
X
Î¸
wÎ¸(gÎ¸(p) + 2Î²g,Î¸(t)).
Adding âŸ¨p, bsafeâŸ©and taking minpâˆˆP gives the result.
Let wâ‹†âˆˆarg maxw V (w) so that V (wâ‹†) = V mix(bsafe).
Lemma 28 (Per-Round Mixture-Value Gap). On E, for all t â‰¤T:
V mix(bsafe) âˆ’V (wt) â‰¤2
X
Î¸
wt,Î¸Î²g,Î¸(t).
Proof. Since wt maximizes bV opt
t
(w) over âˆ†K:
V (wâ‹†) â‰¤bV opt
t
(wâ‹†) â‰¤bV opt
t
(wt),
where the first inequality uses Lemma 27. By the upper bound in Lemma 27:
bV opt
t
(wt) â‰¤V (wt) + 2
X
Î¸
wt,Î¸Î²g,Î¸(t).
Combining gives the result.
33


--- Page 34 ---
E.4
Step 3: Admission-Price Error and KKT Feasibility
Define the unconstrained threshold acceptance Ëœxt := 1{rt > âŸ¨pt, atâŸ©} and reward ËœRT := PT
t=1 rtËœxt.
For any mixture w and price p, define (using strict threshold > per our convention):
U(w, p) :=
X
Î¸
wÎ¸EÎ¸[r Â· 1{r > âŸ¨p, aâŸ©}],
H(w, p) :=
X
Î¸
wÎ¸hÎ¸(p),
bHt(w, p) :=
X
Î¸
wÎ¸bhÎ¸,t(p).
Lemma 29 (Primalâ€“Dual Inequality for Threshold Rules). For any mixture w and price p âˆˆRd
+:
V (w) âˆ’U(w, p) â‰¤âŸ¨p, bsafe âˆ’H(w, p)âŸ©.
Proof. Fix any mixture w and price p âˆˆRd
+.
Step 1 (dual upper bound on V (w)). By the dual representation of V (w) (Theorem 1 in
the main paper / Theorem 5), for any fixed p we have
V (w) = min
qâˆˆP
(
âŸ¨q, bsafeâŸ©+
X
Î¸
wÎ¸gÎ¸(q)
)
â‰¤âŸ¨p, bsafeâŸ©+
X
Î¸
wÎ¸gÎ¸(p).
Step 2 (identity for the threshold value). For strict-threshold admission at price p,
r 1{r > âŸ¨p, aâŸ©} = âŸ¨p, aâŸ©1{r > âŸ¨p, aâŸ©} + (r âˆ’âŸ¨p, aâŸ©)+.
Taking expectation under DÎ¸ and summing with weights wÎ¸ yields
U(w, p) =
X
Î¸
wÎ¸EÎ¸[r 1{r > âŸ¨p, aâŸ©}] = âŸ¨p, H(w, p)âŸ©+
X
Î¸
wÎ¸gÎ¸(p),
where H(w, p) = P
Î¸ wÎ¸hÎ¸(p) is the strict-threshold expected consumption.
Step 3 (combine). Subtract the expression for U(w, p) from the dual upper bound on V (w):
V (w) âˆ’U(w, p) â‰¤âŸ¨p, bsafeâŸ©+
X
Î¸
wÎ¸gÎ¸(p) âˆ’
 
âŸ¨p, H(w, p)âŸ©+
X
Î¸
wÎ¸gÎ¸(p)
!
= âŸ¨p, bsafe âˆ’H(w, p)âŸ©.
The following lemma establishes drift control via KKT conditions using tie-weighted consumption.
Lemma 30 (KKT Implies Tie-Weighted Empirical Complementarity). Fix a mixture w âˆˆâˆ†K and
time t with NÎ¸(t) â‰¥1 for all Î¸. Consider the convex problem
min
pâˆˆP
(
âŸ¨p, bsafeâŸ©+
X
Î¸
wÎ¸bgÎ¸,t(p)
)
.
Assume Pmax > Rmax/bsafe
min so that the upper box constraint is non-binding at minimizers (Corol-
lary 11). Let pâ‹†(w) be any minimizer. Then there exist tie-weight vectors Î»Î¸ âˆˆ[0, 1]NÎ¸(t) (one per
34


--- Page 35 ---
configuration) such that, with the tie-weighted empirical consumptions bhÎ»Î¸
Î¸,t(pâ‹†) from Lemma 16, the
mixture tie-weighted empirical consumption
bHkkt
t
(w, pâ‹†) :=
X
Î¸
wÎ¸ bhÎ»Î¸
Î¸,t(pâ‹†)
satisfies
bHkkt
t
(w, pâ‹†) â‰¤bsafe
(componentwise)
and
âŸ¨pâ‹†, bsafe âˆ’bHkkt
t
(w, pâ‹†)âŸ©= 0.
Proof. By optimality of pâ‹†for the constrained convex problem with effective domain p âˆˆRd
+ (upper
box non-binding), the KKT condition is
0 âˆˆbsafe +
X
Î¸
wÎ¸ âˆ‚bgÎ¸,t(pâ‹†) + NRd
+(pâ‹†).
Thus there exist subgradients sÎ¸ âˆˆâˆ‚bgÎ¸,t(pâ‹†) and a normal-cone vector v âˆˆNRd
+(pâ‹†) such that
0 = bsafe +
X
Î¸
wÎ¸sÎ¸ + v.
By Lemma 16, each sÎ¸ can be written as sÎ¸ = âˆ’bhÎ»Î¸
Î¸,t(pâ‹†) for some tie-weight vector Î»Î¸. Define
bHkkt
t
(w, pâ‹†) := P
Î¸ wÎ¸bhÎ»Î¸
Î¸,t(pâ‹†). Then the KKT condition becomes
0 = bsafe âˆ’bHkkt
t
(w, pâ‹†) + v,
i.e.,
v = bHkkt
t
(w, pâ‹†) âˆ’bsafe.
The normal cone NRd
+(pâ‹†) satisfies: vi = 0 if pâ‹†
i > 0 and vi â‰¤0 if pâ‹†
i = 0. Hence if pâ‹†
i > 0 then
bHkkt
t,i
= bsafe
i
, and if pâ‹†
i = 0 then bHkkt
t,i
â‰¤bsafe
i
. This yields the componentwise feasibility. The
complementarity identity follows because for every coordinate i, either pâ‹†
i = 0 or bsafe
i
âˆ’bHkkt
t,i = 0,
hence P
i pâ‹†
i (bsafe
i
âˆ’bHkkt
t,i ) = 0.
Lemma 31 (Consumption Drift Bound). On the good event E (defined in Section D with Lemma 24
holding for both strict and weak thresholds), for all t,
H(wt, pt) â‰¤bsafe +
 X
Î¸
wt,Î¸Î²h,Î¸(t)

1d,
where H(w, p) := P
Î¸ wÎ¸hÎ¸(p) is the population consumption under the strict threshold (which equals
the weak threshold by Assumption 15).
Proof. Fix t and apply Lemma 30 with w = wt and pâ‹†= pt to obtain bHkkt
t
(wt, pt) â‰¤bsafe
componentwise. For each Î¸, the tie-weighted empirical consumption bhÎ»Î¸
Î¸,t(pt) satisfies
bh>,
Î¸,t(pt) â‰¤bhÎ»Î¸
Î¸,t(pt) â‰¤bhâ‰¥,
Î¸,t(pt)
(componentwise)
by Lemma 16. On E, Lemma 24 implies both âˆ¥bh>,
Î¸,t(pt) âˆ’hÎ¸(pt)âˆ¥âˆâ‰¤Î²h,Î¸(t) and âˆ¥bhâ‰¥,
Î¸,t(pt) âˆ’
hÎ¸(pt)âˆ¥âˆâ‰¤Î²h,Î¸(t). Since bhÎ»Î¸
Î¸,t(pt) lies between the strict and weak empirical quantities coordinatewise
and hÎ¸(pt) equals the strict/weak population expectation, it follows that âˆ¥bhÎ»Î¸
Î¸,t(pt) âˆ’hÎ¸(pt)âˆ¥âˆâ‰¤
Î²h,Î¸(t) as well. Therefore,
H(wt, pt) =
X
Î¸
wt,Î¸hÎ¸(pt) â‰¤
X
Î¸
wt,Î¸

bhÎ»Î¸
Î¸,t(pt)+Î²h,Î¸(t)1d

= bHkkt
t
(wt, pt)+
 X
Î¸
wt,Î¸Î²h,Î¸(t)

1d â‰¤bsafe+
 X
Î¸
wt,Î¸Î²
35


--- Page 36 ---
Lemma 32 (Price-Error Bound). On the good event E, for all t â‰¤T,
V (wt) âˆ’U(wt, pt) â‰¤dPmax
X
Î¸
wt,Î¸Î²h,Î¸(t),
where U(w, p) := P
Î¸ wÎ¸ EÎ¸[r1{r > âŸ¨p, aâŸ©}].
Proof. By Lemma 29,
V (wt) âˆ’U(wt, pt) â‰¤âŸ¨pt, bsafe âˆ’H(wt, pt)âŸ©.
Apply Lemma 30 (with w = wt) to obtain a tie-weighted empirical consumption bHkkt
t
(wt, pt)
satisfying âŸ¨pt, bsafe âˆ’bHkkt
t
(wt, pt)âŸ©= 0. Hence
âŸ¨pt, bsafeâˆ’H(wt, pt)âŸ©= âŸ¨pt, bsafeâˆ’bHkkt
t
(wt, pt)âŸ©+âŸ¨pt, bHkkt
t
(wt, pt)âˆ’H(wt, pt)âŸ©= âŸ¨pt, bHkkt
t
(wt, pt)âˆ’H(wt, pt)âŸ©.
By HÃ¶lder and âˆ¥ptâˆ¥1 â‰¤dPmax,
âŸ¨pt, bHkkt
t
(wt, pt) âˆ’H(wt, pt)âŸ©â‰¤âˆ¥ptâˆ¥1 Â· âˆ¥bHkkt
t
(wt, pt) âˆ’H(wt, pt)âˆ¥âˆâ‰¤dPmax Â·
X
Î¸
wt,Î¸Î²h,Î¸(t),
where the last inequality uses the same sandwich argument as in Lemma 31.
E.5
Step 4: Budget-Feasibility Loss
The real algorithm uses budget checks, producing reward RT â‰¤ËœRT . We bound E[ ËœRT âˆ’RT ] using a
clean martingale-maximum approach.
Setup. Let Ëœxt := 1{rt > âŸ¨pt, atâŸ©} be the unconstrained threshold decision (strict inequality by
Assumption 4), and let ËœRT := PT
t=1 rtËœxt. For each resource coordinate i, define ËœC(i)
t
:= Pt
s=1 a(i)
s Ëœxs
and the violation time Ï„i := inf{t â‰¥1 : ËœC(i)
t
> Bi}, with the convention inf âˆ…= âˆ. Let Ï„ :=
miniâˆˆ[d] Ï„i.
Lemma 33 (Budget Loss Controlled by Violation Times). Almost surely,
ËœRT âˆ’RT â‰¤Rmax(T âˆ’Ï„ + 1)+ â‰¤Rmax
d
X
i=1
(T âˆ’Ï„i + 1)+.
Proof. If no coordinate violates, then the budget check never rejects an unconstrained acceptance,
so ËœRT = RT . Otherwise, after the first violation time Ï„, the real algorithm may lose at most Rmax
reward per remaining period, giving the first inequality. The second inequality uses maxi zi â‰¤P
i zi
with zi = (T âˆ’Ï„i + 1)+.
Martingale structure. For coordinate i, let Yt,i := a(i)
t Ëœxt âˆˆ[0, Amax]. Since Î¸t âˆ¼wt and
(rt, at) âˆ¼DÎ¸t:
E[Yt,i|Ftâˆ’1] =
X
Î¸
wt,Î¸EÎ¸
h
a(i) Â· 1{r > âŸ¨pt, aâŸ©}
i
= H(i)(wt, pt).
Define the martingale Mt,i := Pt
s=1(Ys,i âˆ’E[Ys,i|Fsâˆ’1]) with bounded increments |Mt,i âˆ’Mtâˆ’1,i| â‰¤
Amax.
Lemma 34 (Violation Time Bounded by Martingale Maximum and Drift). Assume the drift bound
holds: E[Yt,i|Ftâˆ’1] â‰¤bsafe
i
+ âˆ†t for all t, where âˆ†t â‰¥0 is Ftâˆ’1-measurable. Let âˆ†1:T := PT
t=1 âˆ†t.
Then for the violation time Ï„i,
(T âˆ’Ï„i + 1)+ â‰¤1 + suptâ‰¤T (Mt,i)+ + âˆ†1:T
bi
.
36


--- Page 37 ---
Proof. If Ï„i = âˆthe left side is 0 and the inequality is trivial. Otherwise, by definition ËœC(i)
Ï„i > Bi =
Tbi. By the martingale decomposition,
ËœC(i)
Ï„i =
Ï„i
X
s=1
E[Ys,i|Fsâˆ’1] + MÏ„i,i â‰¤Ï„ibsafe
i
+
Ï„i
X
s=1
âˆ†s + MÏ„i,i â‰¤Ï„i(1 âˆ’Îµ)bi + âˆ†1:T + MÏ„i,i.
Thus
MÏ„i,i > Tbi âˆ’Ï„i(1 âˆ’Îµ)bi âˆ’âˆ†1:T = (T âˆ’Ï„i)bi + ÎµÏ„ibi âˆ’âˆ†1:T â‰¥(T âˆ’Ï„i)bi âˆ’âˆ†1:T .
Rearranging gives
T âˆ’Ï„i < (MÏ„i,i)+ + âˆ†1:T
bi
â‰¤suptâ‰¤T (Mt,i)+ + âˆ†1:T
bi
.
Adding 1 yields the claim.
Lemma 35 (Expected Maximum of Bounded-Increment Martingale). Let (Mt)T
t=0 be a martingale
with M0 = 0 and increments bounded as |Mt âˆ’Mtâˆ’1| â‰¤Amax almost surely. Then
E
"
sup
tâ‰¤T
(Mt)+
#
â‰¤Amax
r
Ï€T
2 .
Proof. By Azumaâ€“Hoeffding,
Pr
 
sup
tâ‰¤T
Mt â‰¥u
!
â‰¤exp

âˆ’
u2
2TA2max

for all u â‰¥0.
(One may prove this by applying Azuma to the stopped process at the first hitting time of level u.)
Integrate the tail bound:
E
"
sup
tâ‰¤T
(Mt)+
#
=
Z âˆ
0
Pr
 
sup
tâ‰¤T
Mt â‰¥u
!
du â‰¤
Z âˆ
0
exp

âˆ’
u2
2TA2max

du = Amax
r
Ï€T
2 .
Corollary 36 (Expected Feasibility Loss Bound). Under the drift condition in Lemma 34,
E[ ËœRT âˆ’RT ] â‰¤Rmax
d
X
i=1
E[(T âˆ’Ï„i + 1)+] â‰¤Rmax
 
d +
d
bmin
E[âˆ†1:T ] + dAmax
bmin
r
Ï€T
2
!
.
Proof. Combine Lemma 33 and Lemma 34, take expectations, apply Lemma 35, and use bi â‰¥bmin.
Drift bound verification. By Lemma 31, on the good event E:
H(wt, pt) â‰¤bsafe +
X
Î¸
wt,Î¸Î²h,Î¸(t) Â· 1d,
so E[Yt,i|Ftâˆ’1] â‰¤bsafe
i
+ âˆ†t with âˆ†t := P
Î¸ wt,Î¸Î²h,Î¸(t). By Corollary 36:
E[ ËœRT âˆ’RT |E] â‰¤Rmax
 
d +
d
bmin
E[âˆ†1:T |E] + dAmax
bmin
r
Ï€T
2
!
.
37


--- Page 38 ---
E.6
Step 5: Summing Confidence Radii and Slack Loss
Lemma 37 (Summation of 1/
âˆš
N). Let Î¸t be the arm pulled at time t. Then pathwise:
T
X
t=1
1
p
NÎ¸t(t) âˆ¨1
â‰¤2
K
X
Î¸=1
p
NÎ¸(T) âˆ¨1 â‰¤2
p
K(T + K).
Proof. For each Î¸, the j-th pull contributes 1/âˆšj; Pn
j=1 1/âˆšj â‰¤1 +
R n
1 sâˆ’1/2ds â‰¤2âˆšn. Then apply
Cauchyâ€“Schwarz: P
Î¸
âˆšNÎ¸ â‰¤
p
K P
Î¸ NÎ¸ =
âˆš
KT.
Since Î²g(n), Î²h(n) = O(
p
d log T/n), Lemma 37 implies:
T
X
t=1
X
Î¸
wt,Î¸Î²g,Î¸(t) = O

Î± cgRmax
p
KT Â· d log T

,
and similarly:
E[âˆ†1:T ] = O

Amax
p
KT Â· d log T

.
Lemma 38 (Lipschitzness and Monotonicity in the Budget). For any b, bâ€² âˆˆRd
+,
V mix(b) âˆ’V mix(bâ€²)
 â‰¤Pmaxâˆ¥b âˆ’bâ€²âˆ¥1.
Moreover, V mix is monotone: if b â‰¥bâ€² componentwise, then V mix(b) â‰¥V mix(bâ€²). In particular,
with bsafe = (1 âˆ’Îµ)b â‰¤b,
0 â‰¤T
 V mix(b) âˆ’V mix(bsafe)

â‰¤Pmaxâˆ¥b âˆ’bsafeâˆ¥1T = Pmaxâˆ¥bâˆ¥1 ÎµT.
Proof. Using the dual form,
V mix(b) = min
pâˆˆP{âŸ¨p, bâŸ©+ max
Î¸
gÎ¸(p)}.
For any fixed p âˆˆP,
âŸ¨p, bâŸ©+ max
Î¸
gÎ¸(p) âˆ’
 âŸ¨p, bâ€²âŸ©+ max
Î¸
gÎ¸(p)

= âŸ¨p, b âˆ’bâ€²âŸ©,
hence V mix(b)âˆ’V mix(bâ€²) â‰¤suppâˆˆPâŸ¨p, bâˆ’bâ€²âŸ©â‰¤Pmaxâˆ¥bâˆ’bâ€²âˆ¥1. Swap b, bâ€² to get the absolute-value
bound. Monotonicity follows since âŸ¨p, bâŸ©is monotone in b and the minimum over p preserves
monotonicity.
E.7
Combining All Pieces (Unconditional Expectation; No Conditioning on E)
We now combine the previous steps in a way that is fully rigorous: we never condition on the
global good event E (which depends on the entire trajectory), and instead split expectations using
indicators 1E and 1Ec.
Warm-start definition.
For warm-start rounds t â‰¤K, the algorithm sets xt = 0 (pure observa-
tion). We define Ëœxt := 0 and U(wt, pt) := 0 for t â‰¤K, as saddle-point outputs (wt, pt) are only
computed for t â‰¥K + 1. Accordingly, all sums involving U(wt, pt) or Ëœxt below are taken over
t = K + 1, . . . , T.
38


--- Page 39 ---
Warm start loss.
During rounds t â‰¤K, the algorithm forces xt = 0, hence it can lose at most
Rmax reward per round relative to any benchmark. Therefore the warm start contributes at most
KRmax to regret.
Step A: relate E[ ËœRT ] to U(wt, pt).
For t > K, recall the unconstrained strict-threshold decision
Ëœxt := 1{rt > âŸ¨pt, atâŸ©}; for t â‰¤K, we set Ëœxt := 0 by convention. Define ËœRT := PT
t=K+1 rtËœxt. Because
wt and pt are Ftâˆ’1-measurable and Î¸t âˆ¼wt, for t > K we have
E[rtËœxt | Ftâˆ’1] =
X
Î¸
wt,Î¸ EÎ¸[r 1{r > âŸ¨pt, aâŸ©}] = U(wt, pt).
Taking total expectation and summing over t = K + 1, . . . , T (tower property) gives
E[ ËœRT ] =
T
X
t=K+1
E[U(wt, pt)] .
Hence
TV mix(bsafe) âˆ’E[ ËœRT ] = KV mix(bsafe) +
T
X
t=K+1
E
h
V mix(bsafe) âˆ’U(wt, pt)
i
.
Step B: per-round expected gap on E.
On the good event E, Lemmas 28 and 32 imply for
every round t > K:
V mix(bsafe)âˆ’U(wt, pt) =
 V mix(bsafe)âˆ’V (wt)

+
 V (wt)âˆ’U(wt, pt)

â‰¤2
X
Î¸
wt,Î¸Î²g,Î¸(t)+dPmax
X
Î¸
wt,Î¸Î²h,Î¸(t).
Multiplying by 1E and using nonnegativity of the RHS yields the unconditional bound
E
h V mix(bsafe) âˆ’U(wt, pt)

1E
i
â‰¤2 E
"X
Î¸
wt,Î¸Î²g,Î¸(t)
#
+ dPmax E
"X
Î¸
wt,Î¸Î²h,Î¸(t)
#
.
On Ec, we use the crude bound 0 â‰¤U(wt, pt) â‰¤Rmax and 0 â‰¤V mix(bsafe) â‰¤Rmax, hence
E
h V mix(bsafe) âˆ’U(wt, pt)

1Ec
i
â‰¤Rmax Pr(Ec).
Summing over t and adding the warm start loss gives
TV mix(bsafe) âˆ’E[ ËœRT ] â‰¤KRmax + 2
T
X
t=K+1
E
"X
Î¸
wt,Î¸Î²g,Î¸(t)
#
+ dPmax
T
X
t=K+1
E
"X
Î¸
wt,Î¸Î²h,Î¸(t)
#
+ TRmax Pr(Ec).
Step C: feasibility loss E[ ËœRT âˆ’RT ].
We split
E[ ËœRT âˆ’RT ] = E[( ËœRT âˆ’RT )1E] + E[( ËœRT âˆ’RT )1Ec].
The bad-event term satisfies E[( ËœRT âˆ’RT )1Ec] â‰¤TRmax Pr(Ec).
On E, the drift condition in Lemma 34 holds with âˆ†t := P
Î¸ wt,Î¸Î²h,Î¸(t) by Lemma 31, so Lemmas
33â€“34 imply (for each coordinate i)
(T âˆ’Ï„i + 1)+ 1E â‰¤

1 + suptâ‰¤T (Mt,i)+ + âˆ†1:T
bi

1E.
39


--- Page 40 ---
Taking expectations and using E[suptâ‰¤T (Mt,i)+ 1E] â‰¤E[suptâ‰¤T (Mt,i)+] together with Lemma 35
gives
E[(T âˆ’Ï„i + 1)+ 1E] â‰¤1 + Amax
p
Ï€T/2
bi
+ E[âˆ†1:T ]
bi
.
Combining with Lemma 33 and bi â‰¥bmin yields
E[( ËœRT âˆ’RT )1E] â‰¤Rmax
 
d + dAmax
bmin
r
Ï€T
2 +
d
bmin
E[âˆ†1:T ]
!
.
Therefore,
E[ ËœRT âˆ’RT ] â‰¤Rmax
 
d + dAmax
bmin
r
Ï€T
2 +
d
bmin
E[âˆ†1:T ]
!
+ TRmax Pr(Ec).
Step D: slack loss.
By Lemma 38,
0 â‰¤T
 V mix(b) âˆ’V mix(bsafe)

â‰¤Pmaxâˆ¥b âˆ’bsafeâˆ¥1T = Pmaxâˆ¥bâˆ¥1
p
T log T.
Step E: bound the confidence sums.
Using Lemma 26 and Lemma 37, and the definitions of
Î²g,Î¸(t) and Î²h,Î¸(t) (both scaling as O(1/
p
NÎ¸(t))), we obtain
T
X
t=K+1
E
"X
Î¸
wt,Î¸Î²g,Î¸(t)
#
= ËœO
âˆš
KT Â· d

,
T
X
t=K+1
E
"X
Î¸
wt,Î¸Î²h,Î¸(t)
#
= ËœO
âˆš
KT Â· d

,
and similarly E[âˆ†1:T ] = ËœO(
âˆš
KT Â· d).
Step F: bad event probability.
By construction of E we have Pr(Ec) â‰¤Î´tot = T âˆ’2, hence the
total bad-event contribution is at most O(Rmax/T).
Conclusion.
Combining Steps Bâ€“F and recalling RT â‰¤ËœRT yields
Regmix(T) = TV mix(b) âˆ’E[RT ] â‰¤C1 Î±
p
KT Â· d log T + C2
p
T log T + KRmax,
for constants C1, C2 depending only on (d, Rmax, Amax, Pmax, bmin, âˆ¥bâˆ¥1). This completes the proof
of Theorem 3.
F
Implementation Notes
F.1
Compute Saddle Point via Linear Programming
Let
L(w, p) = bT p +
X
Î¸âˆˆÎ˜
wÎ¸
ï£«
ï£­1
NÎ¸
NÎ¸
X
j=1
(rj,Î¸ âˆ’aj,Î¸T p)+ + Î²Î¸
ï£¶
ï£¸
By Assumption 2 and arguments in Lemma 10, we have
max
wâˆˆâˆ†K min
pâ‰¥0 L(w, p) = max
wâˆˆâˆ†K min
pâˆˆP L(w, p) = min
pâˆˆP max
wâˆˆâˆ†K L(w, p) = min
pâ‰¥0 max
wâˆˆâˆ†K L(w, p)
40


--- Page 41 ---
by solving Linear programs. Consider the following LP
Min
bT p + z
S.T
z â‰¥
1
NÎ¸
PNÎ¸
j=1 yj,Î¸ + Î²Î¸
âˆ€Î¸
yj,Î¸ â‰¥rj,Î¸ âˆ’aj,Î¸T p
âˆ€Î¸, j
p â‰¥0, yj,Î¸ â‰¥0
âˆ€Î¸, j
Let pâˆ—be the optimal solution of this LP and let wâˆ—= {wâˆ—
Î¸}Î¸âˆˆÎ˜ be optimal dual solution corre-
sponding to the constraints z â‰¥
1
NÎ¸
PNÎ¸
j=1 yj,Î¸ + Î²Î¸ âˆ€Î¸. Then, (pâˆ—, wâˆ—) is a saddle point.
Proof. By dual feasibility, we have wâˆ—
Î¸ â‰¥0 and P
Î¸âˆˆÎ˜ wâˆ—
Î¸ = 1. Thus, wâˆ—âˆˆâˆ†K. Let zâˆ—be the
optimal solution of the LP. For any w âˆˆâˆ†K,
L(w, pâˆ—) â‰¤bT pâˆ—+ max
Î¸âˆˆÎ˜
1
NÎ¸
NÎ¸
X
j=1
(rj,Î¸ âˆ’aj,Î¸T pâˆ—)+ + Î²Î¸ = bT pâˆ—+ zâˆ—
Then, By complementary slackness, wâˆ—
Î¸ is positive only if
1
NÎ¸
NÎ¸
X
j=1
(rj,Î¸ âˆ’aj,Î¸T pâˆ—)+ + Î²Î¸ = zâˆ—
Thus,
X
Î¸âˆˆÎ˜
wâˆ—
Î¸
ï£«
ï£­1
NÎ¸
NÎ¸
X
j=1
(rj,Î¸ âˆ’aj,Î¸T pâˆ—)+ + Î²Î¸
ï£¶
ï£¸= zâˆ—
Thus,
L(w, pâˆ—) â‰¤L(wâˆ—, pâˆ—)
âˆ€w âˆˆâˆ†K
(4)
For any p â‰¥0,
L(wâˆ—, p) = bT p +
X
Î¸âˆˆÎ˜
wâˆ—
Î¸Î²Î¸ +
X
Î¸âˆˆÎ˜
NÎ¸
X
j=1
max
0â‰¤Î·Î¸,jâ‰¤
wâˆ—
Î¸
NÎ¸
Î·Î¸,j(rj,Î¸ âˆ’aj,Î¸T p)
Let Î·âˆ—
Î¸,j =
wâˆ—
Î¸,j
NÎ¸ 1{rj,Î¸ > aj,Î¸T p}. Then,
L(wâˆ—, pâˆ—) = bT pâˆ—+
X
Î¸âˆˆÎ˜
wâˆ—
Î¸Î²Î¸ +
X
Î¸âˆˆÎ˜
NÎ¸
X
j=1
Î·âˆ—
Î¸,j(rj,Î¸ âˆ’aj,Î¸T pâˆ—)
In addition, for any p â‰¥0,
L(wâˆ—, p) â‰¥bT p +
X
Î¸âˆˆÎ˜
wâˆ—
Î¸Î²Î¸ +
X
Î¸âˆˆÎ˜
NÎ¸
X
j=1
Î·âˆ—
Î¸,j(rj,Î¸ âˆ’aj,Î¸T p)
=
X
Î¸âˆˆÎ˜
wâˆ—
Î¸Î²Î¸ +
X
Î¸âˆˆÎ˜
NÎ¸
X
j=1
Î·âˆ—
Î¸,jrj,Î¸ + pT (b âˆ’
X
Î¸âˆˆÎ˜
NÎ¸
X
j=1
Î·âˆ—
Î¸,jaj,Î¸)
41


--- Page 42 ---
By dual feasibility and complementary slackness,
b âˆ’
X
Î¸âˆˆÎ˜
NÎ¸
X
j=1
Î·âˆ—
Î¸,jaj,Î¸ â‰¥0
pâˆ—T (b âˆ’
X
Î¸âˆˆÎ˜
NÎ¸
X
j=1
Î·âˆ—
Î¸,jaj,Î¸) = 0
Thus,
L(wâˆ—, pâˆ—) =
X
Î¸âˆˆÎ˜
wâˆ—
Î¸Î²Î¸ +
X
Î¸âˆˆÎ˜
NÎ¸
X
j=1
Î·âˆ—
Î¸,jrj,Î¸
pT (b âˆ’
X
Î¸âˆˆÎ˜
NÎ¸
X
j=1
Î·âˆ—
Î¸,jaj,Î¸) â‰¥0
âˆ€p â‰¥0
Thus,
L(wâˆ—, pâˆ—) â‰¤L(wâˆ—, p)
âˆ€p â‰¥0
(5)
(4) and (5) complete the proof.
F.2
Epoch/Doubling Schedule
For computational efficiency, one can update (wt, pt) only when some NÎ¸ doubles (i.e., at times
Ï„ âˆˆ{1, 2, 4, 8, . . .} in NÎ¸). This reduces the number of saddle problem solves from T to O(K log T)
while preserving the regret bound up to constants.
Rationale: The confidence radius Î²Î¸(t) âˆ1/âˆšNÎ¸ changes by at most a factor of
âˆš
2 between
doubling updates, so the regret analysis remains valid with adjusted constants.
G
Experimental Details
This section provides complete specifications for reproducibility.
G.1
Scenario Specifications
S4:
Complementarity.
K = 2 configurations with d = 2 resources, designed as a near-
deterministic diagnostic. Both configurations have reward r = 1 + Î¾ with Î¾ âˆ¼Uniform(âˆ’0.01, 0.01)
(small noise satisfies the no-ties assumption). Consumption profiles are orthogonal:
Î¸
Reward
Consumption a
Resource usage
0
1.0 Â± 0.01
[1.0, 0.0] Â± 0.01
Resource 1 only
1
1.0 Â± 0.01
[0.0, 1.0] Â± 0.01
Resource 2 only
Budget: b0 = [0.5, 0.5] (baseline per-period budget), so b = Ï Â· [0.5, 0.5]. With Ï = 0.7,
b = [0.35, 0.35].
Oracle values: V âˆ—(b) = 0.5 (any fixed configuration wastes one resource), V mix(b) = 1.0
(alternating uses both), yielding gap V mix/V âˆ—= 2.0.
Experiment: T = 5,000, 10 seeds, Î± = 0.1.
42


--- Page 43 ---
S0: Theory-Compliant Regret Validation.
K = 5 configurations with d = 3 resources and
truncated Gaussian arrivals. For each configuration Î¸, rewards r âˆ¼N(ÂµÎ¸
r, (ÏƒÎ¸
r)2) are truncated to
[0.01, Rmax] and per-resource consumptions aj âˆ¼N(ÂµÎ¸
a,j, (ÏƒÎ¸
a,j)2) are truncated to [0.01, Amax], with
Rmax = Amax = 2.0. This scenario is used for validating
âˆš
T regret scaling with the theory-compliant
exploration parameter Î± = 1.5 (Section 6.1).
Î¸
Âµr
Ïƒr
Âµa
Ïƒa
0
1.0
0.3
[0.8, 0.2, 0.2]
[0.2, 0.2, 0.2]
1
0.8
0.3
[0.2, 0.7, 0.2]
[0.2, 0.2, 0.2]
2
0.6
0.3
[0.2, 0.2, 0.6]
[0.2, 0.2, 0.2]
3
0.9
0.3
[0.5, 0.5, 0.5]
[0.2, 0.2, 0.2]
4
0.4
0.3
[0.1, 0.1, 0.1]
[0.2, 0.2, 0.2]
Budget: The baseline per-period budget b0 is derived from the mean consumption of the most
resource-intensive configuration (config 0: Â¯a0 = [0.8, 0.2, 0.2]); with Ï = 0.7, b = 0.7 Â· b0.
Algorithm parameters: Î± = 1.5, Rmax = Amax = 2.0, Pmax = 2.0, Î´ = T âˆ’2, Îµ =
p
log T/T,
cg = 0.0707, warm-start rounds = K, saddle-point solve on doubling schedule, Ï = 0.7, T âˆˆ
{100, 200, 500, 1000, 2000}, 50 seeds.
Boundedness enforcement.
In all synthetic experiments, we enforce the boundedness assump-
tions (Assumption 2 in the main paper) by clipping rewards to [0, Rmax] and per-coordinate con-
sumptions to [0, Amax]. To reduce empirical ties at threshold boundaries, we add continuous jitter
Î¾ âˆ¼Unif(âˆ’Î·, Î·) with Î· = 10âˆ’6 to rewards. Note that hard clipping can create atoms at boundary
values; in our experiments, boundary events are rare (clipping occurs in < 0.1% of samples), so
empirical tie frequency remains negligible. For stricter compliance with Assumption 15, one could
use truncation (rejection sampling) instead of clipping.
G.2
Algorithm Parameters
Parameter
Value
Rmax
10.0
Amax
2.0
Pmax
2Rmax/bmin1
Î´
1/T 2
Slack Îµ
p
log T/T
Warm start
First K rounds (round-robin, no budget consumption)
Saddle solve frequency
Doubling schedule (when any NÎ¸ doubles)
G.3
Confidence Radius
The exploration parameter Î± scales the confidence radius:
Î²Î¸(t) = Î± Â· cgRmax Â·
v
u
u
td log

c0 d Pmax Amax T
Rmax

+ log(KT/Î´)
NÎ¸(t)
,
where cg, c0 > 0 are absolute constants from the concentration lemma (Lemma 20). The factor Rmax
(not Rmax + PmaxAmax) arises because (r âˆ’âŸ¨p, aâŸ©)+ âˆˆ[0, Rmax].
43


--- Page 44 ---
Setting Î± = 0 yields pure exploitation (greedy); Î± = 0.1 is the standard UCB scaling. Note:
Theoretical guarantees (Theorem 9 in the main paper) hold for Î± â‰¥1; values Î± < 1 are heuristics
that often improve empirical performance but are not covered by the high-probability analysis.
G.4
E1: Benchmark Validation (Complementarity Gap)
A core claim is that the switching-aware benchmark V mix properly upper-bounds all policies while
the fixed-configuration benchmark V âˆ—can be beaten. We test this on S4 (Complementarity).
Table 4: E1: Benchmark Validation on S4 Complementarity (10 seeds each). CRâˆ—> 1 confirms the
fixed oracle is beatable; CRmix â‰¤1 confirms V mix is a valid upper bound.
Algorithm
Ï
CRmix
CRâˆ—
Gap
Greedy
0.3
0.956 Â± 0.011
1.908 Â± 0.022
1.996
Greedy
0.5
0.956 Â± 0.014
1.904 Â± 0.027
1.992
Greedy
0.7
0.956 Â± 0.012
1.900 Â± 0.023
1.987
Greedy
0.9
0.960 Â± 0.009
1.902 Â± 0.018
1.982
Greedy
1.2
1.000 Â± 0.000
1.652 Â± 0.000
1.652
SP-UCB-OLP
0.3
0.891 Â± 0.054
1.778 Â± 0.109
1.996
SP-UCB-OLP
0.5
0.853 Â± 0.045
1.700 Â± 0.090
1.992
SP-UCB-OLP
0.7
0.909 Â± 0.022
1.807 Â± 0.043
1.987
SP-UCB-OLP
0.9
0.950 Â± 0.029
1.883 Â± 0.057
1.982
SP-UCB-OLP
1.2
0.993 Â± 0.005
1.640 Â± 0.009
1.652
Random
0.7
0.989 Â± 0.000
1.965 Â± 0.000
1.987
OneHot
0.7
0.507 Â± 0.012
1.007 Â± 0.022
1.988
G.5
Alibaba Trace Experiments
We validate SP-UCB-OLP on real-world cluster traces from Alibaba [Alibaba Group, 2018]. The
trace is processed in original temporal order, preserving realistic non-stationary arrival patterns.
Data Source.
Alibaba Cluster Trace v2018 (batch_task.csv), containing 13.4 million task records
over 8.9 days of cluster operations.
Experimental Configuration.
Parameter
Value
T (time horizon)
5,000
K (regimes)
3
d (resources)
2 (CPU, Memory)
Seeds
42â€“91 (50 seeds)
Ï (budget scaling)
1.0
Noise Ïƒ
0.1
44


--- Page 45 ---
Resource Consumption.
Real values from trace, normalized to [0, 1]:
â€¢ CPU: cpu = plan_cpu/100, mean = 0.836, std = 0.635
â€¢ Memory: mem = plan_mem/100, mean = 0.349, std = 0.299
The consumption vector is a = [cpu, mem].
Reward Construction.
r[Î¸] = c1[Î¸] Â· cpu + c2[Î¸] Â· mem + Ïµ,
Ïµ âˆ¼N(0, 0.01)
This formula creates a stationary LP structure where the optimal regime depends on resource
availability. Given the traceâ€™s CPU-heavy profile (mean CPU > mean memory), Regime 0 (CPU-
heavy) tends to dominate.
Regime Specifications.
Regime
Name
c1
c2
Description
0
CPU-heavy
2.0
0.5
High reward per CPU unit
1
Memory-heavy
0.5
2.0
High reward per memory unit
2
Balanced
1.2
1.2
Equal reward per resource
Budget Computation.
Nominal budget: b0 = 0.5 Â· T Â· Â¯a, where Â¯a is mean consumption. Scaled
budget: b = Ï Â· b0.
Oracle Estimation.
V mix estimated via Monte Carlo with 10,000 samples per regime, solving the
dual LP (Section F).
Complete Results.
Algorithm
Î±
Mean CR
Std CR
Range
Oracle
â€“
99.95%
0.02%
[99.88%, 100.00%]
SP-UCB-OLP
0.01
97.38%
0.59%
[94.72%, 98.17%]
SP-UCB-OLP
0.10
95.21%
0.52%
[93.96%, 96.03%]
SP-UCB-OLP
1.00
91.98%
0.57%
[90.52%, 92.99%]
Greedy
0.00
84.81%
14.24%
[60.88%, 98.03%]
Random
â€“
61.05%
0.25%
[60.33%, 61.55%]
Key Findings.
1. Exploration prevents lock-in: Greedy (Î± = 0) has 14.2% std with 10/50 seeds stuck below
70% CR; Î± = 0.01 reduces std to 0.6%.
2. Minimal exploration suffices: Î± = 0.01 achieves 97.4% CR, only 2.6% below Oracle.
3. Diminishing returns: Increasing Î± beyond 0.01 hurts performance (95.2% at Î± = 0.1, 92.0%
at Î± = 1.0).
4. Oracle validates benchmark: 99.95% CR confirms Monte Carlo estimation accuracy.
5. Random baseline: 61.1% CR provides lower bound for uninformed policy.
45


--- Page 46 ---
H
Broader Impact
Our framework for budgeted admission control has both beneficial applications and potential risks.
Positive impacts.
â€¢ Energy efficiency: Optimizing resource allocation under carbon budgets can reduce infrastructure
emissions.
â€¢ Cost reduction: Improved utilization reduces costs, democratizing compute access.
â€¢ Transparency: Dual prices provide interpretable rejection signals, unlike cyan-box heuristics.
Risks and limitations.
â€¢ Fairness: Reward-maximizing admission may disadvantage low-priority users; fairness constraints
should supplement efficiency objectives.
â€¢ Strategic behavior: Observable rejection patterns may incentivize priority inflation.
â€¢ Information leakage: Publishing dual prices reveals system scarcity.
Recommendations for deployment.
1. Incorporate fairness metrics alongside efficiency.
2. Provide clear explanations for rejections.
3. Monitor for strategic behavior.
4. Combine with absolute resource limits.
46
