--- Page 1 ---
Nimbus: A Unified Embodied Synthetic Data Generation
Framework
Zeyu He1, Yuchang Zhang1, Yuanzhen Zhou1, Miao Tao1, Hengjie Li1,2‚àó, Hui Wang1, Yang
Tian1, Jia Zeng1, Tai Wang1, Wenzhe Cai1, Yilun Chen1, Ning Gao1, Jiangmiao Pang1
1Shanghai Artificial Intelligence Laboratory
2Shanghai Innovation Institute
Abstract
Scaling data volume and diversity is critical for generalizing embodied intelligence. While
synthetic data generation offers a scalable alternative to expensive physical data acquisition,
existing pipelines remain fragmented and task-specific. This isolation leads to significant engi-
neering inefficiency and system instability, failing to support the sustained, high-throughput
data generation required for foundation model training. To address these challenges, we present
Nimbus, a unified synthetic data generation framework designed to integrate heterogeneous
navigation and manipulation pipelines. Nimbus introduces a modular four-layer architecture
featuring a decoupled execution model that separates trajectory planning, rendering, and
storage into asynchronous stages. By implementing dynamic pipeline scheduling, global load
balancing, distributed fault tolerance, and backend-specific rendering optimizations, the
system maximizes resource utilization across CPU, GPU, and I/O resources. Our evaluation
demonstrates that Nimbus achieves a 2‚Äì3√ó improvement in end-to-end throughput compared
to unoptimized baselines and ensuring robust, long-term operation in large-scale distributed
environments. This framework serves as the production backbone for the InternData suite,
enabling seamless cross-domain data synthesis.
‚àóCorresponding author.
1
arXiv:2601.21449v2  [cs.RO]  9 Feb 2026


--- Page 2 ---
Contents
1 Introduction
3
2 Background
4
2.1
InternData-N1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
2.2
InternData-A1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
2.3
InternData-M1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5
3 Related Work
7
3.1
Navigation Data Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
3.2
Manipulation Data Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
3.3
System Frameworks for Data Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
4 Architecture
9
4.1
Stage Runner Layer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
4.2
Components Layer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
4.2.1
Navigation Components & Integration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
4.2.2
Manipulation Components & Integration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
4.3
Schedule Opt Layer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
4.4
Backend Opt Layer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
5 Design of Multi-Layer Optimization
13
5.1
Schedule Opt Layer: Pipeline Parallelism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
5.1.1
Pipeline Parallel Execution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
5.1.2
Dynamic Pipeline Scheduling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
5.2
Schedule Opt Layer: Distributed Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
5.2.1
Global Load Balancing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
5.2.2
Fault Tolerance via Supervisor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
5.3
Backend Opt Layer: Renderer Optimization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
5.3.1
Blender: Hardware-Accelerated Pipelining . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
5.3.2
Isaac Sim: Stacked Rendering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
5.3.3
Gaussian Splatting: Kernel Fusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
6 Evaluation
20
6.1
Performance Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
6.1.1
End-to-End Throughput Analysis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
6.1.2
Theoretical Analysis of Effective Throughput. . . . . . . . . . . . . . . . . . . . . . . . . . 21
6.2
Scalability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
7 Conclusion
24
2


--- Page 3 ---
1
Introduction
Progress in embodied intelligence depends fundamentally on two core capabilities: navigation and
manipulation. These primitives enable agents to move autonomously through environments and
interact physically with objects, establishing them as the fundamental building blocks of Artificial
General Intelligence (AGI). Existing works (œÄ0.5 [1], Gen-0 [2]) have demonstrated that scaling
data scale and diversity further could accelerate the capability growth of models. However, most
of these efforts rely on real-world data collection, where data acquisition remains prohibitively
expensive. Specifically, the high capital cost of hardware deployment and the temporal overhead
of collector training prevent physical pipelines from satisfying the high-capacity, multimodal
demands of modern foundation model training.
Synthetic data pipelines ([3], [4], [5]) offer a scalable alternative to bypass the physical
data bottlenecks by generating controllable, diverse data in virtual environments. However,
existing synthetic data pipelines lack a unified framework, which restricts current solutions
to being tailored exclusively to either navigation or manipulation tasks. This deficiency gives
rise to two core issues: first, inefficiency, marked by engineering redundancy and the lack of
generalizability in optimization and acceleration strategies; second, instability, where the absence
of standardized cluster scheduling and fault tolerance mechanisms hinders the sustained, long-cycle
data generation required for large-scale datasets.
To bridge this gap, we present Nimbus, a unified synthetic data generation framework designed
to integrate heterogeneous navigation and manipulation pipelines. Concretely, Nimbus is built
around a layered design and a set of multi-layer optimizations. At the framework level, we
introduce a four-layer architecture that cleanly separates scheduling optimization and fault
tolerance (Schedule Opt Layer), a unified Load-Plan-Render-Store lifecycle runner abstraction
(Stage Runner Layer), interface-driven reusable components for navigation and manipulation
(Components Layer), and a high-performance runtime that integrates an environment based on
Ray [6] and different simulator and renderer backends (Backend Opt Layer). This modularization
enables the same scheduling and optimization primitives to be applied across heterogeneous
pipelines (e.g., InternData-N1 navigation and InternData-A1/M1 manipulation) without rewriting
scenario logic.
At the Schedule Opt Layer, we implement a two-level optimization stack consisting of a
pipeline parallelism and a distributed optimization. In the pipeline parallelism, we decouple
the traditional monolithic pipeline into an asynchronous execution model. Trajectory planning
(CPU-bound), rendering (GPU-bound), and storage (I/O-bound) are executed in independent
worker pools with dynamic pipeline scheduling. This design mitigates blocking and maximizes
CPU, GPU, and I/O utilization. In the distributed optimization, we target cluster-scale high
efficiency and availability. We employ a global balancer and per-worker supervisors to enforce
load balancing, liveness monitoring, and automatic recovery. Finally, at the Backend Opt Layer,
we optimize the critical rendering paths for major backends (Gaussian Splatting [7], Blender,
and Isaac Sim). Techniques such as accelerated rasterization and batched/stacked rendering
are applied to further increase per-process throughput. Together, these designs deliver a 2‚Äì3√ó
end-to-end throughput improvement over an unoptimized baseline and enable stable, sustained
data generation in distributed environments.
In summary, the primary contributions of our work are:
‚Ä¢ We propose Nimbus, a unified framework that integrates the fragmented pipelines of
navigation and manipulation. This design enables seamless cross-domain data synthesis,
serving as the production backbone for the InternData suite [5, 8, 9].
‚Ä¢ We decouple pipeline stages and implement dynamic pipeline scheduling with rendering op-
timization to maximize resource utilization. Compared to the baseline without optimization,
3


--- Page 4 ---
this design boosts end-to-end throughput by 2‚Äì3√ó.
‚Ä¢ We also introduce a high-availability design that supports large-scale cluster deployment. It
incorporates robust fault recovery mechanisms to ensure stability over sustained operation,
effectively resolving the reliability bottlenecks inherent in traditional data pipelines.
The remainder of this paper is organized as follows. Section 2 details the InternData series
datasets and their generation pipeline. Section 3 analyzes existing literature across navigation,
manipulation, and related frameworks. Section 4 describes the Nimbus architecture and its
integration strategy. Section 5 presents our optimization techniques, including stage decoupling,
scheduler design, and distributed fault tolerance. Section 6 evaluates the framework‚Äôs performance,
and Section 7 concludes with future directions.
2
Background
2.1
InternData-N1
InternData-N1 [8, 10, 3] is a large-scale synthetic dataset for Vision-Language Navigation (VLN),
covering over 3,000 indoor scenes with 53.5 million first-person view (FPV) images and 800,000
language instructions (approximately 4,840 km of trajectories). It includes three complementary
subsets (VLN-N1/VLN-CE/VLN-PE) to support general navigation pre-training, fine-grained
instruction following, and sim-to-real transfer, respectively.
Figure 1 illustrates the synthesis workflow, which can be summarized as:
‚Ä¢ Scene library construction. Aggregate six open-source indoor scene repositories (Replica,
Matterport3D, Gibson, 3D-Front, HSSD, and HM3D) to cover diverse room layouts and
scene categories.
‚Ä¢ Path planning. Generate collision-free, smooth trajectories via a three-stage procedure:
(i) construct a Euclidean Signed Distance Field (ESDF) per floor and use A-star to plan
an initial global path between randomly sampled start‚Äìgoal pairs; (ii) refine turning points
based on ESDF to maintain obstacle clearance; and (iii) apply B¬¥ezier smoothing to ensure
continuous motion.
‚Ä¢ Observation rendering. Render the planned trajectories frame-by-frame with Blender-
Proc to obtain FPV RGB images and depth maps.
‚Ä¢ Instruction annotation. Detect keyframes from geometric cues (e.g., sharp turns or
passing landmarks) and split trajectories into sub-segments; use a multimodal model
(LLaVA-OneVision) to generate fine-grained step instructions; then rewrite and summa-
rize the sub-instructions with a language model (Qwen3-72B) into a single long-horizon
instruction.
‚Ä¢ Data filtering. Remove low-quality samples using landmark density and scene information
metrics.
2.2
InternData-A1
InternData-A1 [5] is a high-fidelity synthetic manipulation dataset for pre-training generalist
Vision-Language-Action (VLA) policies [11]. It spans four robot morphologies (Genie-1, Franka
Panda, AgileX Split Aloha, and ARX Lift-2) and covers 18 skills across 227 indoor scenes, totaling
7,433 hours of interaction data.
4


--- Page 5 ---
Dataset Generation
Instruction annotation
LLM
Data Filtering
278k
Traj
Filter
213k
Traj
‚úÖ More Landmarks
‚ùå More Empty Space
Path-Planning
Scene Assets
Navigation
¬†Trajectory
RGB-D¬†
Observation
Caption
Render &
Simulation
VLM
Walk straight
ahead, passing
the wooden
door on your
left...
Instructions
Sub-Clip A
Sub-Clip N
...
Summary
A-star
Scene library construction
subs-instructions
single long-horizon
instruction
Rewrite
RGB-D¬†
Observation
Figure 1: InternData-N1 pipeline
As shown in Figure 2, InternData-A1 is synthesized through a fully decoupled and composable
pipeline:
‚Ä¢ Environment construction. Given a task template, retrieve task-relevant robots, scenes,
and objects from an asset library: robots are provided as validated USD embodied models;
scenes are sourced from GRUtopia GRScenes-100 with annotated manipulation areas;
objects include rigid, articulated, deformable, and fluid categories with high-fidelity physical
models (e.g., AnyGrasp-generated grasp poses for rigid objects and dedicated simulators
for deformables/fluids).
‚Ä¢ Skill composition. Build tasks by selecting and composing atomic skills from a skill
library. Each skill is implemented as a scripted policy that maps object/robot states and
constraints to a sequence of end-effector 6D waypoints, decoupling high-level logic from
low-level interpolation and control (e.g., Pick, Place, Push, Goto-pose, and Gripper-action).
‚Ä¢ Domain randomization. Apply systematic randomization on both appearance and
dynamics to narrow the sim-to-real gap: perturb camera extrinsics (main and wrist cameras),
sample diverse HDR environment maps and lighting parameters, swap instances within
object categories, and randomize table/background layouts; additionally randomize initial
robot/object poses and stochasticity in grasp/contact regions (e.g., sampling from top-
confidence AnyGrasp candidates).
‚Ä¢ Trajectory generation and storage. Given waypoint sequences, use CuRobo for joint-
space planning and dense interpolation; record multi-view RGB observations with camera
parameters, robot states and control commands, object metadata, and language instructions
(optionally exporting depth, grounding labels, and boxes). Only successful rollouts are
rendered and written to the dataset, which is finally converted into the LeRobot format.
2.3
InternData-M1
InternData-M1 [9, 4] is a synthetic tabletop manipulation dataset targeting long-horizon reasoning
and spatial grounding. It contains approximately 244,000 simulation demonstrations with dense
5


--- Page 6 ---
Environment Construction
Cross-Embodiment
Scene Library
study
room
dining
room
living
room
Object Library
Generation & Storage
* Generate diverse data all in once
Planning Data
Object Pose
Current Joint
Position
Current Joint
Velocity
Current Gripper
State
Target Joint Position
Target Joint Velocity
Target Gripper State
Language Data
Language Instruction
Detailed Description
Camera Data
üì∑
Camera Params
RGB Images
cuRobo
Planning
üé¨
Isaac Sim
Rendering
Skill Composition
* Select skills
and require only
modification for
configuration
Skill Retrieval
Skill Configuration
Domain Randomization
* Apply autonomous domain¬†
randomization
Visual Diversity
üìπ
Camera View
üó∫Ô∏è
Environment Map
üìê
Layout
Trajectory
Diversity
Object Pose
üë§
User
I want to
design a task
where a in
the uses one
arm to pick
up a , and
the other arm
takes it and
places it on a
.
...
Auto Grasp
Annotation
dining
room
Grasp Pose
Contact Pose
Figure 2: InternData-A1 pipeline
action and geometric annotations, and incorporates over 80,000 open-vocabulary objects to
promote generalization.
Figure 3 summarizes the LLM-driven simulation workflow, which proceeds as follows:
‚Ä¢ Simulation assets. Construct a large asset library in Isaac Sim, including over 14,000
labeled objects, 200 tables, and nearly 1,700 texture/lighting configurations to provide
broad physical and visual diversity.
‚Ä¢ Physics simulation and task synthesis. Synthesize trajectories by randomizing object
layouts and illumination, and by using privileged signals (e.g., meshes and robot states) to
compute grasp candidates and motion plans. Each trajectory is validated in closed-loop
execution and checked by a scene-graph validator; only successful and physically consistent
rollouts are retained.
‚Ä¢ Decoupled planning and visual rendering. Decouple planning from rendering by
first recording structured planning traces (e.g., joint states and object poses) and then
replaying them under randomized viewpoints, materials, and lighting. Camera calibration
is performed via ArUco markers to align intrinsic/extrinsic parameters with real sensors,
while the renderer produces RGB images and dense spatial supervision (e.g., 2D boxes,
end-effector traces, and precise keypoints).
‚Ä¢ VLM/VLA data packaging. Convert intermediate representations into a unified visual
question answering (VQA) format for VLM pre-training. By pairing actions with natural
language instructions and spatial annotations, the pipeline derives auxiliary supervision for
affordance recognition, trajectory prediction, and multi-step planning, bridging semantic
reasoning and embodied execution.
6


--- Page 7 ---
Simulation
Assets
Layout
generation
Physics Simulation
Task Generation
Grasp Generation
Motion Planning
cuRobo | MPLib
Isaac Sim
Physics
Rollout
Meta Data
Layout
Initial State
Large-scale Simulation for generalizable pick-place: Put <obj1>¬†to the <Relation>¬†of <obj2>¬†
Visual Rendering for VLM and VLA data synthesis
Synthetic
Spatial
Grounding
QA
<2D Point>
<2D Trace>
<2D Box>
Synthetic
Demonstration
244K Episodes
with
GT annotations
¬†Isaac Sim
RGB
Depth
2D Box
Grasp Point
2D Trace
Visual
Rendering
Planning
Data
Object Pose
Joint State
Gripper State
Joint Action
Gripper
Action
14716 Objects
200+ Tables
80+ Lights
1676 Textures
GPT
Figure 3: InternData-M1 pipeline
3
Related Work
3.1
Navigation Data Generation
Embodied navigation tasks predominantly rely on pre-constructed 3D environments and static
task distributions. While mainstream data sources leverage large-scale indoor scans such as
Matterport3D [12] and Habitat-Matterport 3D (HM3D) [13], their acquisition orchestrates a
resource-intensive pipeline involving specialized hardware, physical staging, and complex post-
processing.
In the VLN domain, the dominant approach involves pairing static environmental assets with
human-generated annotation. Benchmarks such as R2R [14] and RxR [15] are constrained to
limited environments, relying on labor-intensive crowdsourcing pipelines to generate instructions
for pre-defined paths. Although successors like CVDN [16] and REVERIE [17] incorporate multi-
turn dialogues and referring expressions to enhance semantic complexity, they incur significant
overhead due to manual intervention in scene selection, trajectory sampling, and verification.
Consequently, the marginal cost of scaling these datasets remains prohibitively high.
Conversely, ObjectNav [18] and related goal-driven tasks demand rigorous scene semantics,
necessitating precise object lists, instance segmentation, and category labels to enable offline task
sampling. While platforms like Habitat automate this process by applying rule-based generation
to scanned assets (e.g., HM3D), the underlying logic is often tightly coupled to specific codebases.
The absence of unified abstractions for task templates, trajectory sampling, and metadata
organization prevents modularity, significantly hindering cross-project reusability.
Ultimately, contemporary navigation data generation follows a hybrid real-world scanning and
simulation workflow. Construction costs are front-loaded in physical scanning and post-processing,
while task generation remains bottlenecked by manual annotation or brittle, ad-hoc scripts. As a
result, dataset updates manifest as discrete, static releases rather than a continuous, evolutionary
production process.
3.2
Manipulation Data Generation
In contrast to navigation tasks, data generation for manipulation has evolved along three distinct
vectors over the past three years: (1) large-scale physical teleoperation, representing the traditional
real-world demonstration paradigm; (2) Universal Manipulation Interface (UMI)-style approaches
(e.g., UMI, Fast-UMI) [19, 20] that decouple human operators from robot morphology to capture
robot-like trajectories in the wild; and (3) synthetic data generation, which orchestrates simulation
environments via demonstration augmentation or rule-based batch processing.
7


--- Page 8 ---
Physical Teleoperation and Multi-Robot Aggregation.
Cross-institutional initiatives,
such as Open X-Embodiment [21], aggregate data from 34 laboratories and over 60 sub-datasets
to construct massive repositories of real-world trajectories. Concurrently, systems like œÄ0 [22]
and RoboMIND [23] enforce unified collection protocols within single institutions to produce
standardized, multi-robot corpora. Recent efforts, including AgiBotWorld [24] and Galaxea [25],
have expanded this paradigm to diverse open-world scenarios yielding high-resolution, long-
horizon trajectories. While these works significantly scale real-world data, they face systemic
scalability bottlenecks: they necessitate the dedicated occupation of hardware resources, rely
heavily on expert teleoperators, and incur substantial overhead for compliance, privacy, and
heterogeneous platform integration.
To mitigate engineering friction, immersive interfaces like IRIS [26] leverage XR and point
cloud rendering to unify cross-platform teleoperation views. Meanwhile, industrial players (e.g.,
Tesla, Figure AI) orchestrate large-scale fleets to collect proprietary behavior data. However,
these industrial pipelines remain closed-source, obscuring their internal orchestration logic and
preventing external researchers from leveraging their system abstractions.
UMI-like Interfaces and Proxy Devices.
A second method decouples the operator from the
robot entirely. Approaches such as UMI, DexUMI [27], and DexCap [28] employ proxy devices
to capture in-the-wild demonstrations that are offline-mapped to target robot morphologies.
UMI, for instance, utilizes a low-cost handheld interface with multimodal sensors, enabling
non-experts to demonstrate complex dynamic manipulations. Fast-UMI further abstracts the
hardware dependency, employing commercial tracking to simplify calibration and utilizing a
specialized toolchain for data conversion.
While UMI-like interfaces preserve real-world physics without monopolizing expensive robot
hardware, they remain linearly bounded by human demonstration time. Furthermore, the
translation from proxy device to robot imposes significant engineering complexity, necessitating
rigorous coordinate mapping, spatiotemporal alignment, and unified control interfaces.
Synthetic Data: Augmentation and Rule-Driven Generation.
Synthetic generation
approaches trade physical realism for scalability, broadly categorized into demonstration aug-
mentation and rule-driven generation. MimicGen [29] exemplifies the augmentation approach,
procedurally expanding a small seed set of human demonstrations into thousands of trajectories
via sub-task segmentation and scene perturbation. RoboCasa [30] and its successor RoboCasa365
integrate this logic into a high-fidelity home simulation platform, effectively operating as a
demonstration factory. Conversely, rule-driven data generation like InternData-M1 pipeline and
InternData-A1 pipeline to generate massive datasets from pre-defined task scripts and physical
constraints. Unlike the fixed benchmarks of RLBench [31] or ManiSkill [32], these works emphasize
synthetic data as a service, exposing interfaces that allow researchers to reuse asset construction
logic.
Simulation synthesis converts the marginal cost of data generation into computational
overhead. While this enables the production of millions of trajectories with negligible human
intervention, it necessitates robust verification mechanisms to filter physically implausible data
and bridge the sim-to-real gap.
Summary: The Dataset-Centric Bottleneck.
The three prevailing paradigms reveal a
critical systemic gap. Physical and UMI-based routes are constrained by hardware and human
labor, while simulation shifts the bottleneck to asset and script construction. Crucially, the current
landscape is dataset-centric: once a corpus is finalized, the underlying generation pipeline is
effectively frozen. Researchers are restricted to consuming static datasets, unable to incrementally
8


--- Page 9 ---
extend task definitions or sensor configurations without re-engineering the entire workflow. This
lack of a reusable, orchestratable system architecture motivates the design of Nimbus.
3.3
System Frameworks for Data Generation
From a systems perspective, existing frameworks fall into three categories: task-specific generation
tools, simulation platforms, and general-purpose workflow engines.
The first category, represented by MimicGen, formalizes data expansion into a programmable
pipeline but restricts control to task-level rule modifications.
The second category, including RoboCasa, integrates assets and collection tools into unified
platforms. While effective for their specific domains, these systems enforce rigid boundaries; their
internal pipelines are tightly coupled to specific simulation backends, hindering migration to new
modalities or tasks.
The third category comprises general-purpose orchestrators like Apache Airflow [33] and
Prefect [34]. While mature for industrial ETL, these systems treat tasks as black-box operators
and lack native abstractions for the robot-environment-sensor topology. They are optimized
for batch processing rather than the real-time, stateful control loops required for embodied AI.
Furthermore, they track file-level metadata rather than the semantic linkage between trajectories,
scene states, and policy versions.
In distributed deep learning, pipeline-parallel training schedules such as Megatron-LM‚Äôs
1F1B [35] and Zero-Bubble Pipeline Parallelism [36] improve throughput by optimizing the
execution order of micro-batches across layer-partitioned pipeline stages under synchronous
training semantics, aiming to reduce pipeline bubbles.
These methods are formulated around a fixed set of pipeline stages with explicit inter-
stage activation/gradient dependencies and consistency constraints required for correct gradient
computation, and their bubble-related optimality is typically analyzed under a stage-time cost
model, while real deployments may suffer from execution-time variance and stragglers.
In contrast, data-collection sessions involves asynchronous, event-driven orchestration with
dynamic participation, failures/retries, and heterogeneous latencies, which calls for a different
scheduling abstraction and objective than layer/microbatch-level training pipelines.
Consequently, a gap remains for a general-purpose framework that spans real and simulated
environments, unifies collection and generation, and provides native orchestration for embodied
tasks. Our Nimbus addresses this by introducing system-level abstractions specifically designed
for the lifecycle of embodied AI data.
4
Architecture
Nimbus adopts a modular, four-layer architecture designed to unify heterogeneous synthetic
data pipelines while maximizing resource efficiency. As illustrated in Figure 4, the framework is
organized into the Components Layer, Stage Runner Layer, Schedule Opt Layer, and Backend Opt
Layer. This layered design decouples high-level orchestration from low-level execution, enabling
unified scheduling and optimization primitives across diverse navigation and manipulation tasks.
4.1
Stage Runner Layer
The Stage Runner Layer defines a standardized Load-Plan-Render-Store lifecycle, abstracting
the generation workflow into four stages. The Load Stage handles asset ingestion and domain
randomization to expand data diversity. The Plan Stage generates physically valid motion
sequences or action plans based on task specifications. The Render Stage visualizes these
sequences into high-fidelity multimodal sensor observations (RGB, Depth, etc.). Finally, the Store
9


--- Page 10 ---
Schedule Opt
Layer
Dynamic Pipeline
Execution
Async Batch
Store
Load Balance
Supervisor
Stage Runner
Layer
Load Stage
Plan Stage
Render Stage
Store Stage
Load
Iterator
Randomize
Iterator
Plan
Iterator
Render
Iterator
Store
Iterator
Components
Layer
GSMeshLoader
EnvLoader
...
BProc3DFront
Randomizer
EnvRandomizer
...
NavPlanner
EnvPlanner
...
SCGSRenderer
BlenderProc
Renderer
...
NavWriter
EnvWriter
...
Backend Opt
Layer
Dist Env
Simulator
IsaacSim
Sapien
Renderer
GS
FlashGS
Blender
Re-schedule
Multi-Proc
IsaacSim
StackRender
TC-GS
Figure 4: Nimbus Layered Architecture. The framework separates domain logic (Components
Layer), workflow abstraction (Stage Runner Layer), control logic (Schedule Opt Layer), and
execution runtime (Backend Opt Layer).
Stage manages data serialization, aggregating heterogeneous outputs into a unified persistence
format.
To standardize execution within each stage, we define five abstract base iterators that
enforce strict input/output protocols, as detailed in Table 1. In the Load Stage, we provide
BaseLoader and BaseRandomizer to collectively construct scenes. Specifically, BaseLoader
ingests configuration to output a scene object, which is then processed by BaseRandomizer
to modify attributes for domain randomization. For the remaining stages, BasePlanner takes
the scenes to generate trajectory sequences; BaseRenderer synthesizes observations from these
sequences; and BaseWriter serializes sequences and observations to storage. By chaining these
iterators, Nimbus orchestrates the end-to-end synthetic data generation flow in a unified manner.
4.2
Components Layer
The Components Layer implements specific logic for navigation and manipulation within the
unified interfaces defined by the Stage Runner. This design addresses the fragmentation of existing
pipelines by enforcing strict interface contracts, enabling code reuse and seamless integration. As
shown in Figure 5, Nimbus integrates distinct Navigation and Manipulation workflows through
flexible component composition.
4.2.1
Navigation Components & Integration
The Navigation components adapt the generic lifecycle to the InternData-N1 pipeline, addressing
the heterogeneity between mesh-based and Gaussian Splatting assets.
10


--- Page 11 ---
Table 1: Interface Specifications of Core Abstract Base Classes
Abstract Class
Core Interface
Input Format
Output Format
Responsibilities
BaseLoader
load asset(config)
Config
Scene
Asset ingestion and integrity
verification.
BaseRandomizer
randomize(scene)
Scene
Scene
Domain randomization.
BasePlanner
gen sequence(scene)
Scene
Sequence
Generation of feasible trajec-
tories or action plans.
BaseRenderer
gen obs(seq)
Sequence
Observation
Multimodal synthesis (RGB,
Depth, Segmentation, etc.).
BaseWriter
save data(seq, obs)
Sequence, Observation
File (Parquet)
Data serialization and unified
persistence.
Navigation
Manipulation
Load Stage
Plan Stage
Render Stage
Store Stage
Data
GSMeshLoader
SCGSRenderer
BProcObjLoader
NavPlanner
BProc3DFront
Loader
BProc3DFront
Randomizer
BProc3DFront
Planner
BlenderProc
Renderer
NavWriter
InternData
N1
EnvLoader
EnvRandomizer
EnvPlanner
EnvRenderer
EnvWriter
InternData
A1
InternData
M1
Figure 5: Example of Nimbus implementing data generation for different data pipelines via
component combination
Versatile Component Suite.
We implement a comprehensive suite of components to
handle diverse data formats across the generation lifecycle. In the Load Stage, we provide
GSMeshLoader for proxy meshes aligned with GS assets, BProcObjLoader for standard .obj files,
and BProc3DFrontLoader for parsing semantic layouts from the 3D-FRONT dataset. To expand
data diversity, BProc3DFrontRandomizer applies domain-specific augmentations, including light-
ing, texture, and pose randomization. In the Plan Stage, NavPlanner generates collision-free
trajectories using A-star pathfinding. This could be extended by dataset-specific logic (e.g.,
BProc3DFrontPlanner) to enforce layout constraints in structured environments. For the Render
Stage, we employ SCGSRenderer for high-fidelity GS rasterization and BlenderProcRenderer for
photorealistic mesh rendering. Finally, in the Store Stage, NavWriter aggregates trajectory poses,
multimodal observations, and scene metadata, serializing them into the unified InternData-N1
format.
Pipeline Integration Strategy.
To reconcile the distinct characteristics of GS and Mesh
assets, we employ differentiated component composition strategies, as illustrated in Figure 5.
For Mesh assets, the pipeline could be configured based on format complexity. For GS assets,
which offer superior rendering fidelity but lack the geometric information required for path
planning, we implement a proxy-based pipeline: GSMeshLoader ‚ÜíNavPlanner ‚ÜíSCGSRenderer
‚ÜíNavWriter. Specifically, GSMeshLoader ingests a proxy mesh aligned with the GS coordinate
11


--- Page 12 ---
system, enabling NavPlanner to compute physically valid trajectories. These trajectories are
subsequently rendered using SCGSRenderer, effectively combining geometric validity with visual
fidelity.
4.2.2
Manipulation Components & Integration
The Manipulation components unify the heterogeneous workflows of InternData-A1 pipeline and
InternData-M1 pipeline. In contrast to the flexible composition used for navigation, we employ
Unified Adapter Components with a standardized Workflow API to manage the complexity of
robotic simulation.
Unified Adapter Components.
We define a suite of Env components (e.g., EnvLoader,
EnvPlanner, etc.) that serve as abstraction wrappers around underlying simulators such as
IsaacSim and Sapien. These components map the domain-specific operations of InternData-A1
and InternData-M1 pipelines to the standardized Nimbus lifecycle stages.
Workflow API.
The implementation of Unified Adapter Components is underpinned by a
standardized Workflow API, which provides three key capabilities:
‚Ä¢ Encapsulation: It encapsulates pipeline logic and simulation interfaces, shielding the
component layer from backend discrepancies.
‚Ä¢ Decoupling: By defining core interfaces such as reset, randomization, generate seq,
seq replay, and save, it strictly separates detailed generation logic from the framework‚Äôs
scheduling and optimization mechanisms.
‚Ä¢ Extensibility: Developers implement specific workflows, such as GenManipWorkflow for
InternData-A1 pipeline and SimBoxWorkflow for InternData-M1 pipeline, by adhering
to this interfaces. The framework‚Äôs Env components invoke these standardized methods,
remaining agnostic to the underlying implementation details.
4.3
Schedule Opt Layer
The Schedule Opt Layer serves as the control plane, responsible for global resource management
and fault tolerance. It employs four key optimizations to address monolithic execution inefficiencies
and cluster instability:
‚Ä¢ Dynamic Pipeline Execution: Leveraging the decoupling of trajectory planning and
rendering, we implement a dynamic pipelining mechanism. This design eliminates inter-stage
blocking, effectively masking computation latency and maximizing throughput.
‚Ä¢ Asynchronous Batch Storage: To mitigate I/O overhead, we offload data persistence to
asynchronous threads. By batching write operations, this module isolates storage latency
from the critical computation path.
‚Ä¢ Load Balancing: Addressing resource skew in distributed environments, the load balancer
dynamically schedules tasks to saturate cluster capacity. This strategy effectively mitigates
the straggler effect and ensures uniform resource utilization.
‚Ä¢ Supervisor: Providing fine-grained fault tolerance, the supervisor monitors task liveness
in real-time. It automatically detects failures and triggers recovery routines to guarantee
continuous system availability.
Detailed implementation of these optimization is presented in Section 5.
12


--- Page 13 ---
4.4
Backend Opt Layer
The Backend Opt Layer provides the high-performance runtime environment. It integrates a
Ray-based environment with optimized renderer backends. Key optimizations include accelerated
rasterization for Gaussian Splatting, RT-cores and tensor-cores optimization for Blender, and
batched rendering for Isaac Sim. These backend-specific enhancements work in concert with the
upper layers to saturate hardware capabilities.
5
Design of Multi-Layer Optimization
Monolithic synthetic data pipelines often couple trajectory planning and visual rendering into a
synchronous execution unit. While convenient for prototyping, this coupling introduces severe
inefficiencies at scale. First, the tight coupling of planning and rendering leads to computation
waste: invalid trajectories generated during the planning phase still trigger rendering, consuming
resources unnecessarily. Second, the resource profiles of the two stages diverge significantly:
planning is CPU-bound while rendering is GPU-bound. Serial execution forces one resource type
to idle while the other is active. It results in severe hardware underutilization. Moreover, as
deployment scales, partial failures become inevitable, mandating robust fault tolerance to ensure
continuous availability.
To mitigate these bottlenecks, Nimbus implements a multi-layer optimization strategy men-
tioned in the Schedule Opt Layer and Backend Opt Layer defined in Section 4. Figure 6 illustrates
the multi-layer optimization strategy. The top part depicts the Pipeline Parallelism (Section 5.1)
and Renderer Optimization (Section 5.3), which decouple the serial execution into an asyn-
chronous model and accelerate rendering to maximize aggregate throughput. The bottom part
demonstrates the Distributed Optimization (Section 5.2), employing global load balancing with
supervisors to ensure cluster-scale efficiency and availability.
5.1
Schedule Opt Layer: Pipeline Parallelism
By decoupling the generation lifecycle into asynchronous stages, we implement Dynamic Pipeline
Execution and Asynchronous Batch Storage. This design employs fine-grained ComputeWorker
encapsulation and dynamic pipeline scheduling to mask computation latency and maximize the
utilization of heterogeneous computing resources.
5.1.1
Pipeline Parallel Execution
Conventional synthetic data generation workflows predominantly rely on monolithic architectures
where planning and rendering are tightly coupled within a synchronous execution loop. In this
paradigm, the pipeline executes sequentially: Load Stage loads scenes, Plan Stage generates
trajectories, Render Stage renders them, and then Store Stage executes persistence. This lockstep
execution serializes hardware usage: GPUs idle during CPU-bound planning, and CPUs stall
during GPU-bound rendering. Blocking storage I/O further amplifies these pipeline bubbles,
preventing resource utilization.
To mitigate these bottlenecks, we propose a Pipeline Parallel Execution optimization that
decouples the generation lifecycle into three asynchronous stages. As illustrated in Figure 7, we
introduce intermediate buffers to sever the serial dependencies between stages.
Asynchronous Stage Decoupling.
We bridge the decoupled stages using high-throughput
message queues. The planner processes act as producers, pushing serialized simulation contexts
into the queue. The renderer processes act as consumers, asynchronously fetching contexts for
13


--- Page 14 ---
PipelineExecutor
Plan
Render
Plan
Render
Plan
Render
Plan
Render
Render
Plan
Plan
Render
Render
Render
Render
Render
t_0
t_1
t_2
"A ball
falling
down"
Worker Node
PipelineExecutor
ComputeWorker
Supervisor
report
Manage
Worker Node
PipelineExecutor
ComputeWorker
Supervisor
report
Manage
Worker Node
PipelineExecutor
ComputeWorker
Supervisor
report
Manage
Master
TaskDispatcher
TaskManager
WorkerManager
Tasks
Figure 6: Schematic diagram of multi-layer optimization of the Nimbus framework
visualization. This design achieves pipeline parallelism: while the renderer process executes
GPU-bound visualization for dequeued contexts, the planner process concurrently generates
simulation states for subsequent tasks on the CPU. Moreover, this architecture supports the
elastic deployment of multiple planner and renderer processes, allowing the system to align the
aggregate processing rates of stages despite their inherent latency differences.
I/O Latency Hiding.
To address the I/O bottleneck in the storage phase, we implement
an Asynchronous Batch Storage mechanism. Rather than performing synchronous writes, the
renderer process offloads data persistence to a dedicated I/O thread pool. By batching write
operations, this design effectively isolates high-latency disk I/O from the critical rendering path.
Throughput Maximization.
This pipelined architecture effectively masks stage-specific
latencies. By overlapping CPU, GPU, and I/O operations, we transform the sparse, sequential
execution timeline into a dense, parallel schedule. This ensures simultaneous saturation of
heterogeneous hardware resources, including CPU cores, GPU compute units, and disk bandwidth,
thereby significantly amplifying end-to-end generation throughput.
14


--- Page 15 ---
ComputeWorker
(planner process)
ComputeWorker
(renderer process)
Load Stage
Plan Stage
Dump Stage
Dedump
Stage
Render Stage
Store Stage
(Async I/O)
Message
Queue
Planning
Computing
Planning
Computing
Planning
Computing
Rendering
Computing
Rendering
Computing
I/O
Time(t)
Rendering
Computing
I/O
I/O
Figure 7: Decoupled Planning and Rendering Architecture. The decoupled architecture enables
overlapping of Plan (CPU), Render (GPU), and Store (I/O) Stages.
Planner
Process A
Planner
Process B
Planner
Process A
Planner
Process B
Renderer
Process 1
(Heavy Load)
Render
Process 1
(Running)
New Renderer
Process 2¬†
(Plan-to-Render
Migrated)
Planner
Process A
Scheduler
Phase 1: Parallel Execution
Phase 2: Event Trigger &
Resource Migration
Phase 3: Adapted Scaling &
Accelerated Rendering
Stop Signal
(Task Finished)
Release Resource
Dynamic Spawning new
Porcess
Figure 8: Dynamic Pipeline Scheduling Mechanism
5.1.2
Dynamic Pipeline Scheduling
Despite the benefits of pipeline parallelism, the latencies of the Plan and Render Stages remain
inherently asymmetric. While static partitioning of planner and renderer processes can theoreti-
cally balance the pipeline, it faces significant practical limitations. First, it requires precise a
priori profiling of stage latencies, which vary widely across tasks. Second, runtime stochasticity,
such as planning failures where invalid trajectories are discarded, disrupts ideal computational
overlap. Consequently, the Plan Stage often completes its workload prematurely, leaving resources
idle while the Render Stage remains backlogged.
To address these inefficiencies, we introduce a dynamic pipeline scheduling policy centered
on adaptive resource reclamation. The mechanism is event-driven: when an upstream planner
process exhausts its task stream, it transmits a termination signal, prompting the global Scheduler
to immediately reclaim its resources. The Scheduler then evaluates the current queue backlog
and dynamically provisions a new renderer process, which inherits the existing message queue
connection and seamlessly joins the renderer group. Figure 8 illustrates this process in a scenario
initialized with two planner processes and one renderer process. As planner processes exit,
their compute capacity is automatically reallocated to launch additional renderer processes,
ensuring that resources flow fluidly from planning to rendering. This dynamic adjustment of stage
parallelism effectively mitigates the long-tail latency observed in static configurations, yielding
substantial improvements in end-to-end generation throughput.
15


--- Page 16 ---
Master Node
WorkerManager
Monitoring node liveness,
& resource availability
Nodes
Status
...
worker1
BUSY
...
worker2
IDLE
...
workerN
IDLE
...
TaskManager
Task Queue
Worker Node 1
StateReporter
TaskGetter
ComputeWorker
Executing Task
(Planning/Rendering)
Worker Node 2
StateReporter
TaskGetter
ComputeWorker
Executing Task
(Planning/Rendering)
Worker Node N
StateReporter
TaskGetter
ComputeWorker
Executing Task
(Planning/Rendering)
Heartbeat
& BUSY
Heartbeat
& IDLE
Heartbeat
& IDLE
task
task
Figure 9: Architecture of the Global Load Balancer. The Master Node orchestrates task dispatching
and state management, while Worker Nodes execute tasks and report status.
5.2
Schedule Opt Layer: Distributed Optimization
To ensure cluster-scale efficiency and high availability, we implement a Distributed Optimization
layer comprising the global load balancing and fault tolerance mechanisms.
5.2.1
Global Load Balancing
In distributed environments, static task assignment often induces severe load imbalance due to
task heterogeneity and hardware performance variance (i.e., stragglers). To maximize cluster
utilization, we implement a Global Load Balancer based on the Master-Worker architecture.
As shown in Figure 9, the Master Node serves as the central coordinator, maintaining global
cluster state. It integrates a WorkerManager to track node liveness and resource availability,
and a TaskManager to dynamically assign pending tasks to the most suitable workers based on
real-time load metrics. The Worker Node hosts a StateReporter to push heartbeat updates
to the Master and a TaskGetter to pull assignments. The ComputeWorker encapsulates the
domain-specific execution logic (e.g., Planning or Rendering). Additionally, to mitigate scheduling
overhead and network congestion, we employ a lazy context initialization strategy. Instead of
transmitting full data payloads, the dispatcher sends only lightweight task metadata. Worker
nodes lazily load the full execution context from shared storage only upon task initialization.
16


--- Page 17 ---
5.2.2
Fault Tolerance via Supervisor
We leverage Ray to manage the lifecycle of ComputeWorkers, providing basic availability via
automatic process restarts. However, large-scale synthetic data generation remains susceptible
to instability, particularly when incorporating complex physics simulators/renderers (e.g., Isaac
Sim). These components often suffer from non-deterministic hangs or silent failures rather than
immediate crashes, leading to execution stalls and resource leaks. Furthermore, conventional
in-process monitoring is compromised by the Python Global Interpreter Lock (GIL), as deadlocks
in the main execution thread frequently block monitoring threads.
To guarantee runtime robustness, we introduce an out-of-band Supervisor, implemented
as an independent process decoupled from the ComputeWorker. Crucially, the Supervisor itself
is managed by Ray, ensuring its own high availability. This design establishes a robust failure
detection loop. Operationally, both the ComputeWorker and the Supervisor maintain their
own Status Monitor components. The ComputeWorker periodically updates its local Status
Monitor status and synchronizes this state to the Supervisor‚Äôs Status Monitor via heartbeat
messages. The Supervisor continuously polls its own Status Monitor status, enforcing strict
timeout policies to verify worker liveness. Upon detecting a timeout, the Supervisor terminates
the unresponsive ComputeWorker via SIGKILL. This triggers Ray to automatically respawn the
worker and restore its execution context, effectively converting silent hangs into fail-stop errors
and maintaining cluster stability without manual intervention.
5.3
Backend Opt Layer: Renderer Optimization
To saturate the hardware capabilities of the underlying infrastructure, the Backend Opt Layer
implements targeted renderer optimizations for the three primary renderers: Blender, Isaac Sim,
and Gaussian Splatting.
5.3.1
Blender: Hardware-Accelerated Pipelining
Blender is a ubiquitous open-source 3D creation suite for high-fidelity physically-based rendering.
We identify two critical bottlenecks in the InternData-N1 Blender baseline pipeline: the under-
utilization of specialized GPU hardware due to legacy execution paths, and the concurrency
limits imposed by the GIL. We address these through heterogeneous compute offloading and
multi-process parallelism.
Hardware-Aware Kernel Mapping.
We re-engineer the rendering pipeline to exploit the
specialized compute units of NVIDIA RTX architectures. As depicted in Figure 10, the baseline
pipeline suffers from resource contention on generic CUDA cores and incurs high latency from
CPU-based denoising, which necessitates expensive device-to-host memory transfers. To mitigate
this, we implement a fully GPU-resident pipeline using the OptiX backend. This design maps
ray-triangle intersection kernels to dedicated RT Cores and delegates denoising to Tensor Cores
via the OptiX AI Denoiser. By confining the entire render-denoise loop to the GPU, we eliminate
CPU bottlenecks and maximize the concurrent utilization of heterogeneous hardware resources.
Multi-Process Parallelism.
To further maximize resource utilization on a single GPU,
we implement a parallel rendering scheduling mechanism that launches multiple concurrent
rendering processes in Nimbus Blender Renderer. This design is motivated by the need to
bypass the Python GIL, which limits standard Blender execution to a single thread and leaves
GPU resources underutilized. In this architecture, a master process acts as the global resource
manager, responsible for scene loading, parameter configuration, task assignment, and final data
17


--- Page 18 ---
A. Single-Process Pipeline Optimization (Heterogeneous Resource Scheduling)
Original Blender
Pipeline
(Baseline)
Preprocessing
Cycles Rendering
Tracing
(CUDA)
Shading
(CUDA)
Compositor
Denoising (CPU)
Postprocessing
Nimbus
Optimized
Pipeline
(Full GPU)
Preprocessing
Cycles Rendering
OptiX Tracing
(RT Cores)
Shading
(CUDA)
OptiX Denoising
(Tensor Cores)
Postprocessing
B. Parallel Rendering Scheduling (Batch Throughput Optimization)
Plan
Master Process
(Global Resource Management)
Scene Loading
Param Config
Task Assign
Data Aggregation
Write
Worker Process 1
Full Optimized Pipeline
(Init -> Render -> Post)
Worker Process 2
Full Optimized Pipeline
(Init -> Render -> Post)
Worker Process N
Full Optimized Pipeline
(Init -> Render -> Post)
...
Launch
Launch
Launch
Data
Data
Data
Avoids Python
GIL
Limitations
Figure 10: Blender Hardware-Accelerated Rendering Pipeline. The optimization delegates ray
tracing and denoising to dedicated RT and Tensor Cores, respectively.
aggregation. It dispatches rendering tasks to a pool of independent worker processes, where each
worker executes the full optimized pipeline (initialization, rendering, and post-processing) in
isolation. This process-level parallelism effectively circumvents the GIL, enabling the system to
saturate the compute capacity of high-end GPUs.
5.3.2
Isaac Sim: Stacked Rendering
NVIDIA Isaac Sim is a high-fidelity robotics simulation and synthetic data generation tool built
on the Omniverse platform. Designed specifically for embodied AI development, it serves as the
core engine for physical simulation and multimodal data production within the synthetic data
pipeline. As illustrated in Figure 11, synthetic manipulation data generation typically requires
recording temporal motion sequences of objects (e.g., the continuous process of a ball falling).
The conventional workflow employs serial state playback, where a single scene and camera render
the object‚Äôs different motion states sequentially over time (t0, t1, t2). This serial execution pattern
fails to exploit the parallel capabilities of the RTX pipeline, creating a significant efficiency
bottleneck.
To address this limitation, we introduce the Stacked Rendering optimization, which maps
multi-step temporal states (e.g., different phases of the falling ball) into multiple independent
sub-regions within a single scene. By deploying multiple cameras to capture these sub-regions in
18


--- Page 19 ---
A. Traditional Serial Rendering (Bottleneck)
Time (t)
Time t‚ÇÄ
Time t‚ÇÅ
Time t‚ÇÇ
Serial Processing: Render t‚ÇÄ ‚Üí Render t‚ÇÅ ‚Üí Render t‚ÇÇ
High Latency, Underutilized RTX Pipeline
B. Stacked Rendering Optimization (Parallel)
Single Scene Loading
Sub-region 1 (t‚ÇÄ state)
Sub-region 2 (t‚ÇÅ state)
Sub-region 3 (t‚ÇÇ state)
Parallel Processing: Single Render Pass (Captures t‚ÇÄ, t‚ÇÅ, t‚ÇÇ Simultaneously)
High Efficiency, Full RTX Pipeline Utilization
Stacked Output
(t‚ÇÄ, t‚ÇÅ, t‚ÇÇ)
Output t‚ÇÄ
Output t‚ÇÅ
Output t‚ÇÇ
Figure 11: Isaac Sim Stacked Rendering Optimization. Temporal states are mapped to spatial
sub-regions for single-pass rendering.
parallel, we enable multi-step data acquisition via a single scene load and one-pass rendering,
effectively replacing the traditional serial temporal rendering approach. This technique maximizes
the throughput of the rendering pipeline.
5.3.3
Gaussian Splatting: Kernel Fusion
3D Gaussian Splatting is a novel 3D representation that models scenes as a collection of learnable
3D Gaussian primitives. Each primitive encapsulates complete geometry (position, rotation, scale)
and appearance (color, opacity) attributes. The rendering pipeline projects these 3D Gaussians
onto the image plane via splatting, executing a sequence of projection, tiling, sorting, and alpha
blending to achieve real-time, high-quality scene synthesis.
To address the rendering efficiency bottlenecks in large-scale synthetic data generation, we
integrate FlashGS [37] and TC-GS [38] to optimize the rasterization kernel. FlashGS targets
the computational and memory overheads of the standard pipeline. It implements redundant
Gaussian filtering to prune invalid or low-contribution primitives, parallelizes the rendering
schedule, and enforces fine-grained GPU kernel execution control. Furthermore, we leverage
Tensor Cores to accelerate alpha blending, which dominates the computational cost in the
rendering pipeline, as proposed in TC-GS. These techniques significantly increase Gaussian
Splatting rendering throughput, substantially improving the overall efficiency of the synthetic
19


--- Page 20 ---
data generation pipeline.
6
Evaluation
We evaluate Nimbus on an Alibaba Cloud cluster configured as detailed in Table 2.
Table 2: Hardware Configuration
Component
Specification
OS
Ubuntu 22.04
GPU
NVIDIA RTX 4090
CPU
Intel(R) Xeon(R) Gold 6462C @ 3889.285 MHz
We benchmark four data generation pipelines:
‚Ä¢ Nav-GS (InternData-N1 Gaussian Splatting Pipeline): A navigation data collection pipeline
that performs planning and rendering on coordinate-aligned mesh models and 3D Gaussian
models. The scenes are custom indoor environments with approximately 3 million Gaussians
per model.
‚Ä¢ Nav-Mesh (InternData-N1 Blender Pipeline): A traditional pipeline sampling endpoints
from the 3D-FRONT dataset. It executes A-star path planning and utilizes Blender for
rendering.
‚Ä¢ GenManip (InternData-M1 Pipeline): Executes object pick-and-place tasks on the Obja-
verse dataset.
‚Ä¢ SimBox (InternData-A1 Pipeline): Executes trash classification tasks on the Objaverse
dataset.
6.1
Performance Evaluation
We evaluate the end-to-end performance of Nimbus against the unoptimized Baseline. Our
evaluation spans four distinct pipelines: Nav-GS and Nav-Mesh for navigation, and GenManip
and SimBox for manipulation. We generate 150 trajectories for Nav-GS, 450 for Nav-Mesh (150
per scene), and 200 each for GenManip and SimBox. Given the inherent heterogeneity in task
complexity and data volume, we focus on relative speedups (Baseline vs. Nimbus) within each
pipeline rather than absolute cross-pipeline comparisons.
6.1.1
End-to-End Throughput Analysis
Figure 12 presents the end-to-end latency comparison. Nimbus delivers substantial performance
gains across all workloads, achieving speedups ranging from 2.1√ó to 3.2√ó. To identify the sources
of these gains, we decompose the latency profiles of key stages. As shown in Figure 13, the
Baseline operates in a sequential mode where planning and rendering are tightly coupled. In
contrast, Nimbus (Figure 14) decouples these stages. Crucially, under our pipeline parallelism
and dynamic scheduling, the end-to-end latency is no longer the additive sum of individual stage
latencies, but is instead dictated by the bottleneck stage.
In navigation tasks, the plan stage is computationally lightweight while the render stage and
store stage dominate. Introducing a fully decoupled pipeline here would incur serialization and
IPC overheads that negate potential concurrency benefits. Thus, Nimbus maintains synchronous
execution for planning and rendering, focusing instead on two targeted optimizations:
20


--- Page 21 ---
Nav-GS
Nav-Mesh
GenManip
SimBox
Pipeline
0
2k
4k
6k
8k
10k
12k
14k
End-to-End Time (s)
Baseline
Nimbus
Speedup
0
1
2
3
4
Speedup (√ó)
2.2√ó
3.2√ó
2.1√ó
2.7√ó
Figure 12: End-to-end performance comparison. Nimbus achieves 2.1√ó‚Äì3.2√ó speedup across all
pipelines.
‚Ä¢ I/O Masking: We decouple the storage stage. By offloading persistence to an asynchronous
writer, we completely mask the ‚àº56 ms/frame disk I/O latency.
‚Ä¢ Renderer Optimization: We optimize the critical rendering path via the Backend Opt
Layer. For instance, Nav-Mesh rendering latency is reduced by 64% (from 446.29 ms to
159.46 ms).
For GenManip and SimBox, Nimbus exploits the structural separation between CPU-bound
planning and GPU-bound rendering:
‚Ä¢ Pipeline Overlap: By isolating planning and rendering into distinct ComputeWorkers, we
overlap their execution. The planning cost is effectively amortized within the rendering
window. To further reduce the bottleneck latency, we increase rendering concurrency via
multiple renderer ComputeWorkers.
‚Ä¢ Dynamic Resource Reallocation: To mitigate tail latency, the scheduler dynamically
reclaims resources from completed Planners to spawn additional Renderers. This adaptive
reallocation ensures that computing resources remain saturated, minimizing idle time
during the rendering tail.
6.1.2
Theoretical Analysis of Effective Throughput
While Nimbus achieves 2√ó‚Äì3√ó speedups, stage-wise latencies (Figure 14) show that total per-
frame computation (Plan and Render) remains comparable to the Baseline. This indicates
that performance gains stem from architectural efficiency rather than operation reduction. We
formalize this via Effective Stage Throughput.
Throughput Model
In a decoupled architecture, stage performance is defined by per-frame
latency ‚Ñìs and time-averaged concurrency ¬ØNs = 1
T
R T
0 Ns(t)dt. The effective throughput is:
¬µs =
¬ØNs
‚Ñìs
(frames/s).
The system‚Äôs steady-state theoretical maximum throughput is Œªtheory = min(¬µplan, ¬µrender). Unlike
the Baseline‚Äôs degenerate pipeline (Œªbase ‚âà(P ‚Ñìi)‚àí1), Nimbus maximizes Œªtheory by increasing
¬ØNs and hiding latencies via overlap.
21


--- Page 22 ---
Nav-GS
Nav-Mesh
GenManip
SimBox
Pipeline
0
100
200
300
400
500
600
Latency (ms/frame)
50.2
506.9
124.9
113.5
Plan
Render
Write
Plan+Render (Mixed)
Figure 13: Latency breakdown of the Baseline pipeline. The monolithic design forces serial
execution of Plan and Render stages.
Impact of dynamic pipeline scheduling
In manipulation tasks where ‚Ñìrender ‚â´‚Ñìplan, the
system is GPU-bound. Nimbus initializes with a balanced Planner:Renderer ratio to saturate
queues, then dynamically reallocates resources. As Planners exit, ¬ØNplan decreases while ¬ØNrender
increases, boosting ¬µrender exactly when the bottleneck shifts to the tail.
Correlation Between Failure Rates and Latency
A counter-intuitive dynamic exists in
GPU-bound regimes: higher planning success rates correlate with longer total execution times.
Let Xi ‚àà{0, 1} be the success indicator for attempt i. The total execution time is approximated
by:
T Nimbus
total
‚âà‚ÑìNimbus
render
¬ØNrender
M
X
i=1
Xi.
Since failed plans are pruned before rendering, a higher failure rate reduces the total rendering load.
To evaluate efficiency fairly, we define Effective Successful Throughput Œªsucc = (P Xi)/Ttotal.
Nimbus maintains high Œªsucc robustly across varying failure rates because dynamic pipeline
scheduling ensures that the throughput of successful samples approaches Œªtheory.
6.2
Scalability
When scaling tasks to larger magnitudes, additional compute nodes are required. This inevitably
introduces two critical challenges: global load balancing and fault recovery for complex physics
simulators. Both challenges significantly impact the framework‚Äôs scalability.
We address load imbalance arising from task heterogeneity and hardware performance
variations through a master-worker architecture with a global load balancer, and ensure runtime
robustness via a Supervisor mechanism, thereby achieving excellent scalability.
We evaluate the system‚Äôs scalability by conducting 24-hour data generation tasks across
clusters ranging from 8 to 128 GPUs. Notably, for the Nav-Mesh pipeline, our evaluation comprises
2,560 distinct scenes. We also conduct comparative experiments with the dynamic load balancing
22


--- Page 23 ---
Nav-GS
Nav-Mesh
GenManip
SimBox
Pipeline
0
25
50
75
100
125
150
175
200
Latency (ms/frame)
22.3
~0
161.2
~0
36.4
112.3
~0
42.9
99.0
~0
Plan
Render
Write
Figure 14: Latency breakdown of Nimbus. Under dynamic pipeline parallelism, end-to-end latency
is bounded by the bottleneck stage rather than the cumulative sum. Values in the figure reflect
single-worker latency and dynamic pipeline parallelism further scales effective throughput via
intra-stage parallelism.
parameter (dynload) enabled and disabled, where enabling dynload activates the global load
balancer. The results are shown in Figure 15.
Theoretically, throughput should scale linearly with the number of GPUs. Our experimental
results demonstrate that when scaling from 8 to 128 GPUs, the system achieves approximately
86% linear scaling efficiency, indicating excellent scalability. Throughout the entire 24-hour
testing period, the system maintained stable operation with no node failures or task failures,
demonstrating exceptional robustness.
The deviation from perfect linear scaling can be attributed to two primary factors. First,
task execution exhibits inherent tail effects. Even with load balancing, the completion time
of the final batch of tasks affects overall throughput measurements, and this effect becomes
more pronounced as the number of nodes increases. Second, the scheduling efficiency of the load
balancer is influenced by task granularity. As the number of nodes increases, the number of tasks
assigned to each node decreases correspondingly, which reduces the scheduling flexibility available
to the global load balancer. In our 128-GPU configuration, the 2,560 scenes are distributed with
only approximately 20 scenes per GPU on average. This relatively small task pool per node is
insufficient for the load balancer to fully exploit its dynamic scheduling capabilities and effectively
mitigate the inevitable tail effects, thereby limiting overall resource utilization efficiency.
Notably, despite these factors, the system maintains high resource utilization on large-scale
clusters, benefiting from the effective coordination between our master-worker architecture
and the Supervisor mechanism. This result validates that our architectural design can support
large-scale data generation requirements in production environments.
23


--- Page 24 ---
8
16
32
64
128
Number of GPUs
10000
100000
1000000
Data Generation Volume
(samples/24h)
Scaling Performance: Data Generation Volume and Speedup
Nav-Mesh 2560
Nav-Mesh (DynLoad)
Nav-GS
Nav-GS (DynLoad)
GenManip
SimBox
8
16
32
64
128
Number of GPUs
0
2
4
6
8
10
12
14
Speedup (vs. 8 GPUs)
Best: 13.7√ó
Nav-Mesh 2560
Nav-Mesh (DynLoad)
Nav-GS
Nav-GS (DynLoad)
GenManip
SimBox
Ideal Linear
Figure 15: 24-Hour Data Generation Volume and Scaling Factors
7
Conclusion
Data scarcity remains the primary bottleneck in training embodied intelligence models. While
synthetic data offers a viable path forward, existing generation pipelines are plagued by fragmen-
tation, inefficiency, and instability. In this paper, we presented Nimbus, a unified framework that
resolves these architectural deficiencies through a systematic design. By consolidating naviga-
tion and manipulation workflows into a single framework, Nimbus successfully orchestrated the
large-scale construction of the InternData dataset series. Our evaluation demonstrates that the
system achieves a 2‚Äì3√ó throughput improvement over baselines via dynamic pipeline scheduling
and rendering optimizations. Furthermore, its fault-tolerant design ensures robust, continuous
operation on large-scale GPU clusters, satisfying the stability requirements for massive data
campaigns.
By replacing ad hoc scripts with a standardized, high-performance infrastructure, Nimbus
circumvents the prohibitive costs of physical data collection. It delivers the high-capacity,
multimodal data streams necessary to advance manipulation and navigation models. Looking
ahead, we plan to extend the framework in three directions: integrating diverse trajectory
planners to enrich behavioral variance, incorporating automated scene generation to broaden
environmental compatibility, and implementing automated task configuration to further enhance
the generalization capabilities of downstream models.
24


--- Page 25 ---
References
[1] Physical Intelligence, Kevin Black, Noah Brown, James Darpinian, Karan Dhabalia, Danny
Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Manuel Y. Galliker,
Dibya Ghosh, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones,
Liyiming Ke, Devin LeBlanc, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair,
Karl Pertsch, Allen Z. Ren, Lucy Xiaoyang Shi, Laura Smith, Jost Tobias Springenberg, Kyle
Stachowicz, James Tanner, Quan Vuong, Homer Walke, Anna Walling, Haohuan Wang, Lili
Yu, and Ury Zhilinsky. œÄ0.5: a vision-language-action model with open-world generalization,
2025.
[2] Generalist AI Team. Gen-0: Embodied foundation models that scale with physical interaction.
Generalist AI Blog, 2025. https://generalistai.com/blog/preview-uqlxvb-bb.html.
[3] Wenzhe Cai, Jiaqi Peng, Yuqiang Yang, Yujian Zhang, Meng Wei, Hanqing Wang, Yilun
Chen, Tai Wang, and Jiangmiao Pang. Navdp: Learning sim-to-real navigation diffusion
policy with privileged information guidance, 2025.
[4] Ning Gao, Yilun Chen, Jiangmiao Pang, et al.
Genmanip: Llm-driven simulation for
generalizable instruction-following manipulation. In IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), 2025.
[5] Yang Tian, Yuyin Yang, Yiman Xie, Zetao Cai, Xu Shi, Ning Gao, Hangxu Liu, Xuekun
Jiang, Zherui Qiu, Feng Yuan, Yaping Li, Ping Wang, Junhao Cai, Jia Zeng, Hao Dong,
and Jiangmiao Pang. Interndata-a1: Pioneering high-fidelity synthetic data for pre-training
generalist policy, 2025.
[6] Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov, Richard Liaw, Eric
Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I Jordan, et al.
Ray: A
distributed framework for emerging {AI} applications. In 13th USENIX symposium on
operating systems design and implementation (OSDI 18), pages 561‚Äì577, 2018.
[7] Bernhard Kerbl, Georgios Kopanas, Thomas Leimk¬®uhler, and George Drettakis. 3d gaussian
splatting for real-time radiance field rendering. ACM Transactions on Graphics, 42(4), July
2023.
[8] InternNav Team. InternVLA-N1: An open dual-system navigation foundation model with
learned latent plans, 2025.
[9] InternVLA-M1 contributors. Internvla-m1: A spatially guided vision-language-action frame-
work for generalist robot policy, 2025.
[10] Meng Wei, Chenyang Wan, Xiqian Yu, Tai Wang, Yuqiang Yang, Xiaohan Mao, Chenming
Zhu, Wenzhe Cai, Hanqing Wang, Yilun Chen, Xihui Liu, and Jiangmiao Pang. Streamvln:
Streaming vision-and-language navigation via slowfast context modeling, 2025.
[11] InternVLA-A1 contributors. Internvla-a1: Unifying understanding, generation and action
for robotic manipulation, 2026.
[12] Angel Chang, Angela Dai, Thomas Funkhouser, Maciej Halber, Matthias Niessner, Manolis
Savva, Shuran Song, Andy Zeng, and Yinda Zhang. Matterport3d: Learning from rgb-d
data in indoor environments. In International Conference on 3D Vision (3DV), 2017.
25


--- Page 26 ---
[13] Santhosh Kumar Ramakrishnan, Aaron Gokaslan, Erik Wijmans, Oleksandr Maksymets,
Alexander Clegg, John Turner, Eric Undersander, Wojciech Galuba, Andrew Westbury,
Angel Chang, Manolis Savva, Yili Zhao, and Dhruv Batra. Habitat-matterport 3d dataset
(hm3d): 1000 large-scale 3d environments for embodied ai. In Advances in Neural Information
Processing Systems (NeurIPS), 2021.
[14] Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko S¬®underhauf,
Ian Reid, Stephen Gould, and Anton van den Hengel. Vision-and-language navigation:
Interpreting visually-grounded navigation instructions in real environments.
In IEEE
Conference on Computer Vision and Pattern Recognition (CVPR), 2018.
[15] Alexander Ku, Peter Anderson, Roma Patel, Eugene Ie, and Jason Baldridge. Room-across-
room: Multilingual vision-and-language navigation with dense spatiotemporal grounding. In
Empirical Methods in Natural Language Processing (EMNLP), 2020.
[16] Jesse Thomason, Michael Murray, Maya Chakravarty, and Luke Zettlemoyer. Vision-and-
dialog navigation. In Conference on Robot Learning (CoRL), 2019.
[17] Yuankai Qi, Qi Wu, Peter Anderson, Xin Wang, William Yang Wang, Chunhua Shen, and
Anton van den Hengel. Reverie: Remote embodied visual referring expression in real indoor
environments. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
2020.
[18] Devendra Singh Chaplot, Dhiraj Prakashchand Gandhi, Abhinav Gupta, and Russ R
Salakhutdinov. Object goal navigation using goal-oriented semantic exploration. Advances
in Neural Information Processing Systems, 33:4247‚Äì4258, 2020.
[19] Cheng Chi, Siyuan Feng, Yilun Du, Zhenjia Xu, Eric Cousineau, Benjamin Burchfiel, and
Shuran Song. Universal manipulation interface: In-the-wild robot teaching without in-the-
wild robots. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
2024.
[20] Zhaxizhuom Zhaxizhuoma, Kehui Liu, Chuyue Guan, Zhongjie Jia, Ziniu Wu, Xin Liu, Tianyu
Wang, Shuai Liang, Pengan Chen, et al. Fastumi: A scalable and hardware-independent
universal manipulation interface with dataset. In Conference on Robot Learning (CoRL),
2025.
[21] Abhishek Padalkar, Acorn Pooley, Ajinkya Jain, Alex Bewley, Alex Herzog, Alex Ir-
pan, Alexander Khazatsky, Anikait Rai, Anikait Singh, Anthony Brohan, et al. Open
x-embodiment: Robotic learning datasets and rt-x models. In IEEE International Confer-
ence on Robotics and Automation (ICRA), 2024.
[22] Kevin Black, Noah Brown, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo
Fusai, Lachy Groom, Karol Hausman, Brian Ichter, et al. œÄ0: A vision-language-action flow
model for general robot control. arXiv preprint arXiv:2410.24164, 2024.
[23] Kun Wu, Chengkai Hou, Jiaming Liu, Zhengping Che, Xiaozhu Ju, Zhuqin Yang, Meng Li,
Yinuo Zhao, Zhiyuan Xu, Guang Yang, et al. Robomind: Benchmark on multi-embodiment
intelligence normative data for robot manipulation. arXiv preprint arXiv:2412.13877, 2024.
[24] Qingwen Bu, Yilun Chen, et al. Agibot world colosseo: A large-scale manipulation platform
for scalable and intelligent embodied systems. arXiv preprint arXiv:2503.06669, 2025.
26


--- Page 27 ---
[25] Tao Jiang, Tianyuan Yuan, Yicheng Liu, Chenhao Lu, Jianning Cui, Xiao Liu, Shuiqi Cheng,
Jiyang Gao, Huazhe Xu, and Hang Zhao. Galaxea open-world dataset and g0 dual-system
vla model. arXiv preprint arXiv:2509.00576, 2025.
[26] Xinkai Jiang, Qihao Yuan, Enes Ulas Dincer, Hongyi Zhou, Ge Li, Xueyin Li, Xiaogang Jia,
Timo Schnizer, Nicolas Schreiber, Weiran Liao, et al. Iris: An immersive robot interaction
system. In Conference on Robot Learning (CoRL), 2025.
[27] Mengda Xu, Han Zhang, Yifan Hou, Zhenjia Xu, Linxi Fan, Manuela Veloso, and Shuran
Song. Dexumi: Using human hand as the universal manipulation interface for dexterous
manipulation. In 3rd RSS Workshop on Dexterous Manipulation: Learning and Control with
Diverse Data, 2025.
[28] Chen Wang, Haochen Shi, Weizhuo Wang, Ruohan Zhang, Li Fei-Fei, and Karen Liu. Dexcap:
Scalable and portable mocap data collection system for dexterous manipulation. In RSS
2024 Workshop: Data Generation for Robotics, 2024.
[29] Ajay Mandlekar, Soroush Nasiriany, Bowen Wen, Iretiayo Akinola, Yashraj Narang, Linxi
Fan, Yuke Zhu, and Dieter Fox. Mimicgen: A data generation system for scalable robot
learning using human demonstrations. In Conference on Robot Learning (CoRL), 2023.
[30] Soroush Nasiriany, Abhiram Maddukuri, Lance Zhang, Adeet Parikh, Aaron Lo, Abhishek
Joshi, Ajay Mandlekar, and Yuke Zhu. Robocasa: Large-scale simulation of everyday tasks
for generalist robots. In Robotics: Science and Systems (RSS), 2024.
[31] Stephen James, Zicong Ma, David Rovick Arrojo, and Andrew J. Davison. Rlbench: The
robot learning benchmark & learning environment. IEEE Robotics and Automation Letters
(RA-L), 2020.
[32] Jiayuan Gu, Fanbo Xiang, Xuanlin Li, Zhan Ling, Xiqiang Liu, Tongzhou Sang, Ackermann
Seymour, Xuan Wei, and Hao Su.
Maniskill2: A unified benchmark for generalizable
manipulation skills. In International Conference on Learning Representations (ICLR), 2023.
[33] The Apache Software Foundation. Apache airflow. https://airflow.apache.org/, 2024.
[34] Prefect Technologies, Inc. Prefect: The workflow orchestration platform. https://www.
prefect.io/, 2024.
[35] Deepak Narayanan, Mohammad Shoeybi, Jared Casper, Patrick LeGresley, Mostofa Patwary,
Vijay Korthikanti, Dmitri Vainbrand, Prethvi Kashinkunti, Julie Bernauer, Bryan Catanzaro,
Amar Phanishayee, and Matei Zaharia. Efficient large-scale language model training on
gpu clusters using megatron-lm. In Proceedings of the International Conference for High
Performance Computing, Networking, Storage and Analysis, SC ‚Äô21, New York, NY, USA,
2021. Association for Computing Machinery.
[36] Penghui Qi, Xinyi Wan, Guangxing Huang, and Min Lin. Zero bubble (almost) pipeline
parallelism. In The Twelfth International Conference on Learning Representations, 2024.
[37] Guofeng Feng, Siyan Chen, Rong Fu, Zimu Liao, Yi Wang, Tao Liu, Boni Hu, Linning Xu,
Zhilin Pei, Hengjie Li, Xiuhong Li, Ninghui Sun, Xingcheng Zhang, and Bo Dai. Flashgs:
Efficient 3d gaussian splatting for large-scale and high-resolution rendering. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages
26652‚Äì26662, June 2025.
27


--- Page 28 ---
[38] Zimu Liao, Jifeng Ding, Siwei Cui, Ruixuan Gong, Boni Hu, Yi Wang, Hengjie Li, XIngcheng
Zhang, Hui Wang, and Rong Fu. Tc-gs: A faster gaussian splatting module utilizing tensor
cores. to appear in the SIGGRAPH Asia 2025 Conference Proceedings, 2025.
28
