--- Page 1 ---
Beyond Algorithm Evolution: An LLM-Driven Framework for
the Co-Evolution of Swarm Intelligence Optimization
Algorithms and Prompts
Shipeng Cen1 and Ying Tan2
1,2 School of Intelligence Science and Technology, Peking University, Beijing 100871,
China
Abstract
The field of automated algorithm design has been advanced by frameworks such as EoH,
FunSearch, and Reevo. Yet, their focus on algorithm evolution alone, neglecting the prompts
that guide them, limits their effectiveness with LLMs‚Äîespecially in complex, uncertain en-
vironments where they nonetheless implicitly rely on strategies from swarm intelligence opti-
mization algorithms. Recognizing this, we argue that swarm intelligence optimization provides
a more generalized and principled foundation for automated design. Consequently, this paper
proposes a novel framework for the collaborative evolution of both swarm intelligence algorithms
and guiding prompts using a single LLM. To enhance interpretability, we also propose a simple
yet eÔ¨Äicient evaluation method for prompt templates. The framework was rigorously evaluated
on a range of NP problems, where it demonstrated superior performance compared to several
state-of-the-art automated design approaches. Experiments with various LLMs (e.g., GPT-
4o-mini, Qwen3-32B, GPT-5) reveal significantly divergent evolutionary trajectories in the
generated prompts, further underscoring the necessity of a structured co-evolution framework.
Importantly, our approach maintains leading performance across different models, demonstrat-
ing reduced reliance on the most powerful LLMs and enabling more cost-effective deployments.
Ablation studies and in-depth analysis of the evolved prompts confirm that collaborative evo-
lution is essential for achieving optimal performance. Our work establishes a new paradigm
for swarm intelligence optimization algorithms, underscoring the indispensable role of prompt
evolution.
1
Introduction
Optimization problems are ubiquitous across various facets of human society and are deeply inter-
twined with production and daily life. Yet, many real-world complex optimization problems are
often NP, NP-hard or NP-complete[8] in nature, for which no perfect algorithms running within
polynomial time are currently available, and their search spaces are typically exponential in size.
As research into the properties of these problems progresses, investigators have begun employing
optimization algorithms such as swarm intelligence algorithms[3] and evolutionary algorithms[2] to
explore the solution space. However, on one hand, the design of various rules within these algo-
rithms heavily relies on expert knowledge; on the other hand, the continuous emergence of new
1
arXiv:2512.09209v1  [cs.NE]  10 Dec 2025


--- Page 2 ---
optimization methods has made the selection of high-performing algorithms a challenging issue for
researchers. These two factors have posed certain obstacles to the advancement of the field. Fur-
thermore, when confronted with complex optimization problems, researchers tend to first turn to
classical and eÔ¨Äicient algorithms like PSO[26], DE[7], FWA[24], and CMA-ES[9], etc. Should these
methods still yield unsatisfactory results, they often need to trial other algorithms‚Äîa process that
can be highly ineÔ¨Äicient.
With the rise of large language models(LLMs)[30], automatic algorithm design[15] based on
LLMs has attracted widespread scholarly attention and growing interest. One the one hand, LLMs
acquire vast amounts of knowledge during training that far exceeds that of any individual, while
demonstrating competence in problem understanding and algorithm design comparable to domain
experts‚Äîthus providing a solid foundation for such applications. On the other hand, automated
design frameworks leveraging LLMs significantly reduce the traditional heavy reliance on expert
knowledge, enabling rapid, straightforward, and eÔ¨Äicient application across diverse problem types.
It can be said that the emergence of LLMs has injected new vitality into the field of optimization.
Several notable works‚Äîsuch as EoH[14], Funsearch[21], Reevo[28] and AlphaEvolve[19]‚Äîhave al-
ready achieved performance surpassing traditional methods on many classic problem classes (e.g.,
TSP[17], CVRP[25]), while also setting numerous new state-of-the-art results. However, we observe
that:
‚Ä¢ On certain challenging problem classes‚Äîwhere challenges may stem from constraint complex-
ity or problem novelty‚Äîonline constructive methods designed by these automated frameworks
often underperform.
As a result, they frequently resort to search strategies from various
swarm intelligence algorithms or even directly invoke solvers for assistance. This suggests
that relying entirely on online construction is impractical, and that search mechanisms from
population-based optimization algorithms still play a critical role.
‚Ä¢ While there has been growing work on prompt evolution‚Äîsince different LLMs exhibit varied
preferences for prompt phrasing‚Äîmost mainstream automated algorithm design frameworks
still overlook the impact of prompt design. Although they may generate different code in
each interaction, other parts of the prompt template remain entirely human-specified, which
ultimately limits the full exploitation of the model‚Äôs capabilities.
As for swarm intelligence optimization algorithms, existing research has begun to explore the
integration of large language models.
For example, some studies have utilized LLMs to design
original operators in the fireworks algorithm and introduced novel operators to balance competition
and cooperation within the population, with validation conducted on engineering design tasks.
Other work has incorporated multimodal large language models in visually rich scenarios, thereby
providing more comprehensive information to support MLLM-based decision-making. These efforts
have also expanded the application scope of swarm intelligence optimization operators, with the
overall architecture achieving outstanding performance on tasks such as the TSP and Electronic
Design Automation (EDA)[13, 12]. However, similar to earlier frameworks such as EoH[14], these
approaches still overlook the impact of prompt templates, which limits the full exploitation of the
capabilities of LLMs.
Based on the current state of research, we propose a novel framework, which realizes the col-
laborative evolution of swarm intelligence algorithms and prompts based on large language models.
This framework is designed to address the previously overlooked aspect of prompt evolution in
automated algorithm design. Both the evolution of the algorithms themselves and the evolution of
2


--- Page 3 ---
the prompt templates are driven by the same large language model. Furthermore, we introduce a
simple yet effective evaluation method for prompt templates, which enhances the interpretability
of the prompt evolution process. For the experimental validation, we tested our framework on var-
ious NP problems with LLMs like gpt-4o-mini[10], Qwen3-32B[27] and GPT-5[20], and conducted
comparisons with several mainstream approaches, the results of which demonstrate the superiority
of our proposed framework. Additionally, ablation studies and an analysis of the generated prompt
templates confirm the necessity of integrating collaborative prompt evolution.
2
Related Work
2.1
Swarm Intelligence Algorithms
Swarm intelligence optimization algorithms represent a class of multi-population optimization al-
gorithms whose performance depends not only on the exploration and exploitation capabilities of
individual agents but also on the interactions and cooperation among them. These algorithms offer
advantages such as gradient-independent operation, ease of parallelization, and simple rules. His-
torically, the design of swarm intelligence algorithms has drawn upon various ‚Äùinspirations,‚Äù which
may originate from the behaviors of certain organisms (e.g., ACO[4], PSO[26], GWO[18]), natural
phenomena (e.g., FWA[24]), or even human activities (e.g., BSO[22]), among other sources.
A well-designed swarm intelligence optimization algorithm requires carefully crafted opera-
tors(rules) and rigorous benchmark testing, ideally supported by convergence theory‚Äîthough this
aspect remains relatively underdeveloped in the field. Currently, swarm intelligence optimization
algorithms have found extensive applications across various domains, including traditional problems
such as TSP and CVRP, neural architecture[5] and hyperparameter search[16], and even low-rank
fine-tuning of large language models under very limited GPU memory constraints[11].
The design of effective operators is often task-specific and poses a significant challenge for human
experts. In response, some researchers have begun to integrate large language models with FWA[6],
developing an automated evolutionary framework to generate high-performance operators tailored
to specific tasks, as shown in Figure 1.
Why choose the Fireworks Algorithm? On the one hand, compared to other swarm intelligence
algorithms, FWA is more of a framework-oriented approach, featuring multiple operators‚Äîsuch
as explosion, mutation, and selection operators‚Äîthus offering a rich design space for operator
customization. On the other hand, both the conventional FWA and its LLM-enhanced variants
have demonstrated strong performance across a variety of tasks. This paper will use FWA as a case
study to construct a novel LLM-based evolutionary framework different from before.
2.2
LLM-driven Automatic Algorithm Design
In recent years, research on automatic algorithm design leveraging Large Language Models has
yielded remarkable breakthroughs, showcasing the significant potential of this paradigm to rev-
olutionize traditional algorithm design processes.
Notable representative works highlight these
advancements. For instance, FunSearch[21] combines the code generation capability of LLMs with
an automated evaluator, enabling the discovery of solutions surpassing known human-derived re-
sults in mathematical and combinatorial optimization problems. EoH[14] introduces a concept of
‚Äùidea-code‚Äù co-evolution, utilizing diverse prompting strategies to drive LLMs in automatically gen-
erating high-performance heuristic algorithms, demonstrating exceptional design eÔ¨Äiciency in tasks
3


--- Page 4 ---
FWA Pool
FWA 
Select-1
Prompt
Problem
Evaluator
New Explosion
Operator
Operators
Replace
Operator
New
FWAs
Explosion
Problem
New Mutation
Operator
New Selection
Operator
New 
Novel_helper
Operator
Mutation
Selection
Novel_helper
Figure 1: LLM-driven pipeline for Fireworks Algorithm (FWA) evolution from [6].
like online bin packing and the Traveling Salesman Problem. ReEvo[28] incorporates dual-level
(short-term and long-term) reflection mechanisms, enabling LLMs to continuously integrate expe-
riences and refine heuristics by learning from comparative performance analysis. AlphaEvolve[19]
is a novel AI-powered coding agent developed by DeepMind, designed for scientific and algorithmic
discovery.
This system has demonstrated remarkable versatility by achieving breakthroughs in
both theoretical domains, such as discovering new matrix multiplication algorithms and improving
solutions to long-standing mathematical problems like the kissing number problem, as well as in
practical applications, including optimizing data center scheduling and hardware design.
The common core advantages of these works include an exceptionally high level of automa-
tion, significantly reducing reliance on human expertise and manual coding; strong potential for
algorithmic innovation, as LLMs can combine or generate novel algorithm components beyond con-
ventional design thinking; and notable generality and flexibility, enabling adaptation to various
algorithm design tasks.
As for swarm intelligence optimization algorithms, we believe their deep integration with
LLMs is not only an inevitable trend in technological development but also highly
necessary. The core strength of swarm intelligence algorithms lies in their ability to effectively
explore complex solution spaces through interaction and cooperation among population individu-
als. However, their performance heavily depends on the design of various operators (e.g., position
update, pheromone update, explosion, mutation), which often rely on fixed, human-crafted rules.
This can limit their adaptability when facing novel, dynamic complex optimization tasks. The
introduction of LLMs provides a key pathway to address this core bottleneck. LLMs can act as
eÔ¨Äicient ‚Äùmeta-designers,‚Äù automatically designing or optimizing core operators for specific swarm
intelligence algorithms. For example, exploratory work has begun combining LLMs with FWA,
utilizing LLMs to automatically design more effective explosion, mutation, and selection operators
4


--- Page 5 ---
for FWA, thereby significantly expanding the design space and potential of the FWA framework,
as shown in Figure 1. Furthermore, the natural language interface of LLMs considerably lowers
the barrier to algorithm design, allowing non-expert users to customize dedicated swarm intelli-
gence optimization strategies through instructions, thereby promoting the democratization of this
technology.
2.3
Prompt Engineering
In recent years, prompt engineering has evolved from a manual, experience-dependent craft into a
systematic and automated engineering discipline. Among these advancements, automatic prompt
evolution has emerged as a key research focus, aiming to leverage algorithms for dynamically gen-
erating and optimizing prompts, thereby enhancing the performance of large language models on
specific tasks.
Researchers directly use LLM to generate and iterate prompts.
For instance, Microsoft‚Äôs
PromptWizard[1] framework implements fully automated discrete prompt optimization: it employs
a feedback-driven process of criticism and synthesis to balance exploration and exploitation, iter-
atively refining prompt instructions and in-context examples to generate human-readable prompts
tailored for specific tasks. This framework demonstrates excellent performance across 45 tasks, even
with limited training data or when using smaller LLMs. Another relevant work is TextGrad[29],
a framework in which researchers conceptualize ‚Äùdifferentiation‚Äù as a metaphor: the feedback pro-
vided by LLMs is referred to as ‚Äùtext gradients.‚Äù When optimizing prompts, TextGrad first evaluates
the final prediction outcomes and then adjusts the initial prompts based on the feedback, thereby
iteratively refining the entire process.
Analogous to numerical gradient descent, Text gradient
descent leverages optimization suggestions generated by language models to dynamically adjust
system variables for performance enhancement.
Also, gradient of LLM can be used to further optimize prompts.
The GradPromptOpt[31]
method is an automatic gradient-based optimization framework.
It leverages internal gradient
information of the LLM to automatically diagnose and optimize weak components within a prompt,
achieving a performance improvement of 31.75% in fine-grained tasks like keyword extraction, far
exceeding the eÔ¨Äiciency of traditional manual tuning.
Prompts have demonstrated critical benefits for tasks; however, current automatic algorithm
design frameworks primarily emphasize the algorithms themselves, overlooking the iterative refine-
ment of prompts during the process.
3
Methods
Traditional automated algorithm design frameworks overlook the importance of interactive prompts,
and the operational templates for interacting with large models remain static. To address this
limitation, we devise a novel approach termed ‚Äùalgorithm-prompt co-evolution‚Äù, with the entire
process illustrated in Figure 1.
In essence, our method can further leverage the potential of large language models without re-
quiring additional training. This is achieved by quantifying the contribution of individual prompt
templates rather than the entire prompt used by PromptWizard during the algorithm evolution
process, and dynamically adjusting these templates for various interactive operations (e.g., muta-
tion, crossover). Crucially, adopting the entire prompt as the unit of design would significantly in-
crease computational overhead and undermine generality, as the combinatorial explosion of possible
5


--- Page 6 ---
Prompt
Template
Algorithms
FWA
FWA
FWA
FWA
FWA
FWA
FWA
        
ÔøΩÔøΩÔøΩÔøΩ
= 
Select
Select
Code & 
Performance
Generate
Evaluate
Combine
Insert
Merge
Generate
Insert
Evaluate
Total Prompt
Figure 2: Swarm intelligence optimization algorithm and prompt template co-evolution framework
based on large language model.Top subfigure: The iterative optimization process of a swarm intelli-
gence optimization algorithm, illustrated here using the Fireworks Algorithm (FWA) as an example.
Bottom subfigure: The automated evolution process of prompt templates, whose generation and
updates are dependent on a LLM. The two processes are designed to interact with each other. It
should be noted that there can be multiple types of prompt templates, meaning the framework may
maintain multiple distinct prompt template pools.
6


--- Page 7 ---
prompt variations would render the optimization process intractable. In contrast, the template-level
approach enables eÔ¨Äicient and reusable prompt component optimization, enhancing both scalability
and adaptability across diverse tasks.
3.1
Algorithm Part
We begin by discussing the evolution of population-based intelligence algorithms within the context
of large language models, focusing specifically on the optimization algorithms themselves. This
process comprises several key steps: algorithm selection, individual generation, task evaluation,
and algorithm update.
First, we discuss algorithm selection.
During the evolutionary process, it is necessary to
choose candidate algorithms for evolution from the current algorithm set. A common approach
is probability-based or greedy selection, where the probability can be derived from the actual eval-
uated values or performance metrics of the algorithms, as shown below, lower rank meaning better
performance. Additionally, the number of algorithms required may vary depending on the genetic
operator. For instance, a mutation operator typically selects only one algorithm, whereas a crossover
operator may require two or more.
p(Ai) = n + 1 ‚àírank(Ai)
‚àë
j rank(Aj)
, rank(Ai) ‚àà{1, 2, 3, ..., n}
Secondly, we proceed to introduce individual generation. For swarm intelligence algorithms and
evolutionary algorithms, different methods may involve distinct procedures. For instance, FWA
includes explosion, mutation, and selection operators; DE employs a differential update operator;
while PSO involves position and velocity update operators. When working with a specific algorithm,
it is essential to first clarify the object and granularity of generation. One may choose to update
only a single operator in FWA, redesign all of its operators‚Äîthough the latter entails more signifi-
cant modifications‚Äîor adjust a single velocity update equation in PSO. Therefore, the term ‚Äùkey
components‚Äù is more appropriate than ‚Äùindividual generation‚Äù in this context. A major advantage
of utilizing large language models for generating such key components lies in their flexibility. For
example, to address the competition and collaboration within populations in FWA, researchers have
proposed a ‚Äùnovel helper‚Äù operator, which allows the LLM to freely implement code based on given
prompts. Furthermore, traditional swarm intelligence optimization algorithms are typically derived
from various conceptual inspirations‚Äîwhether from biological systems or natural phenomena‚Äîand
are manually crafted into code. These algorithms can generally only be utilized as complete opti-
mizers, requiring extensive coding, selecting, testing, and other complex procedures. By leveraging
large language models, however, these very concepts can serve as a design inspiration for specific
operators tailored to diÔ¨Äicult or complex tasks. This approach liberates swarm intelligence algo-
rithms from their traditional role as full-scale optimizers, enabling their application at the operator
level in tough problems like EDA, as shown in Fig.3
The task evaluation component is relatively straightforward. We typically conduct multiple as-
sessments of the generated algorithms, which can be accelerated through parallel implementation.
Since population-based optimization algorithms require extensive search exploration, to prevent ex-
cessive complexity in the algorithm pool, we can employ time-constrained evaluation. This approach
ensures that the final algorithms achieve an optimal balance between computational eÔ¨Äiciency and
solution quality.
7


--- Page 8 ---
ùë£‡Øú
‡Øß‡¨æ‡¨µ‡µåùëì‡¨µùë£‡Øú
‡Øß, ùëùùëèùëíùë†ùë°‡Øú
‡Øß, ùëîùëèùëíùë†ùë°‡Øß
ùëù‡Øú
‡Øß‡¨æ‡¨µ‡µåùëì‡¨∂·à∫ùëù‡Øú
‡Øß, ùë£‡Øú
‡Øß‡¨æ‡¨µ·àª
ùë†ùëùùëéùëüùëò‡Øò‡µåùëî‡¨µùëìùëñùëüùëíùë§ùëúùëüùëò‡Øß
ùë†ùëùùëéùëüùëò‡Ø†‡µåùëî‡¨∂ùë†ùëùùëéùëüùëòùë†‡Ø†
ùëìùëñùëüùë§ùëúùëüùëò‡Øß‡¨æ‡¨µ‡µåùëî‡¨∑·à∫ùë†ùëùùëéùëüùëò‡Øò, ùë†ùëùùëéùëüùëò‡Ø†·àª
PSO
FWA
ACO
ùëùùëéùë°‚Ñé‡Øú‡µå‚Ñé‡¨µùëõùëúùëëùëí‡Ø¶‡Øß‡Øî‡Ø•‡Øß, ùúÇ, ùúè
ùúè‡µå‚Ñé‡¨∂ ·à∫ùëùùëéùë°‚Ñé‡¨µ‡Æ∏‡Øú‡Æ∏‡Ø°, ùúè, ùúå·àª
Type¬†I:¬†Solution¬†=¬†SIOA(problem)
TSP
CVRP
Bin
Packing
SAT
Type¬†II:¬†Solution¬†=¬†Tool(SIOA,¬†problem)
Tool
(Dreamplace)
SIOA¬†
operator
EDA¬†
Figure 3: Top subfigure: The diagram includes three swarm intelligence algorithms‚ÄîPSO, FWA,
and ACO‚Äîalong with their fundamental update rules. We use abstract functions such as f, g, and h
to represent specific mathematical expressions, aiming to illustrate that: (1) these abstract functions
can serve as design targets for the LLM, and can be evolved either individually or collectively; (2)
these abstract functions essentially function as independent heuristic rules, which can be applied
separately in certain contexts. Bottom subfigure: Some NP-hard optimization problems can
be directly encoded using population-based intelligent optimization algorithms (Type I). However,
some NP-hard problems are addressed using specialized tools that also incorporate many heuristics.
In such cases, ideas from swarm intelligence algorithms can be leveraged to enhance the performance
of these tools (Type II).
8


--- Page 9 ---
In the algorithm update phase, the challenge we face is how to select among existing algorithms.
Typically, a greedy strategy can be adopted to retain the top-performing algorithms. However, we
must acknowledge that when two distinct algorithms A and B undergo iterative design improvements
using large language models, they inherently explore different ‚Äùalgorithm spaces.‚Äù Consequently, an
algorithm with currently suboptimal performance might belong to an algorithm space that contains
highly promising variants. Based on this insight, some studies have proposed Monte Carlo tree
search-inspired approaches to balance immediate performance and potential future rewards.
3.2
Prompt Part
Previous studies have predominantly focused on the iterative generation of algorithms while over-
looking the evolution of prompts. In practice, for a fixed LLM, different prompting strategies can
lead to substantially different outcomes. Since each interaction prompt incorporates parameters
such as the current individual‚Äôs code and performance metrics, what we are effectively evolving is
the prompt template. We aim for this prompt template‚Äîdesigned by the current LLM‚Äîto pro-
gressively adapt in a direction that maximizes compatibility with the LLM‚Äôs characteristics, rather
than relying on simplistic automated prompt engineering tools.
First, we need to identify which prompt templates require evolution. In this work, we designed
two types of initial prompts: mutation and crossover. The former is intended to mutate a specific
operator of the current population-based intelligent optimization algorithm, without prescribing
the exact direction of mutation but only requiring a redesign. The latter aims to perform crossover
blending on an operator from two distinct algorithms, without specifying the precise crossover
method. The initial prompts were manually designed as follows:
1 def get_mutation_prompts(problem_description ,
2
current_code ,
3
current_performance):
4
introduction = (
5
f"You are an expert in combinatorial optimization and "
6
f"firework algorithms , now you are faced with a problem: "
7
f"{problem_description}.\n"
8
)
9
current_fwa = (
10
f"I will show you one firework algorithm for solving it:"
11
f"{current_code}. Its performance is {current_performance}. "
12
f"The higher performance , the better.\n"
13
)
14
requirements = (
15
"1. Choose exactly one function in 'explode', 'mutate' or 'select' "
16
"and replace it with your new design\n"
17
"2. Redesign only the chosen function, keeping input/output unchanged\n"
18
"3. Return complete code in format: <code>xxx</code> without explanations"
19
)
20
21
return introduction + current_fwa + requirements
Listing 1: Mutation Prompt Generation Function
1 def get_crossover_prompts(problem_description ,
2
current_codes ,
3
current_performances):
4
introduction = (
9


--- Page 10 ---
5
f"You are an expert in combinatorial optimization and "
6
f"firework algorithms , now you are faced with a problem: "
7
f"{problem_description}.\n"
8
)
9
current_fwa = (
10
f"I will show you two firework algorithms for solving it.\n"
11
f"First algorithm: {current_codes[0]}\n"
12
f"Performance: {current_performances[0]}\n\n"
13
f"Second algorithm: {current_codes[1]}\n"
14
f"Performance: {current_performances[1]}\n"
15
f"The higher performance , the better.\n"
16
)
17
requirements = (
18
"1. Perform crossover on 'explode', 'mutate' and 'select' functions "
19
"using elements from both algorithms\n"
20
"2. Maintain original input/output interfaces for all functions\n"
21
"3. Return complete code in format: <code>xxx</code> without explanations"
22
)
23
24
return introduction + current_fwa + requirements
Listing 2: Crossover Prompt Generation Function
While the performance of an algorithm can be directly evaluated through task-specific assess-
ments, there is no direct quantitative method for evaluating prompts. To address this, we posit
that when a large language model is fixed, the quality of a prompt should be measured by the
performance improvement it imparts to the algorithms it generates. As shown in the following
equation, the performance of a prompt template can be measured by the performance difference
between algorithms at consecutive time steps. It should be noted that this performance difference
is actually dependent on the LLM. However, since the LLM remains frozen during application
and the prompt template is intrinsically coupled with the LLM, we can disregard this dependency
and attribute the performance gain entirely to the contribution of the prompt template. At the
same time, it is well-known that improving a weak algorithm is relatively straightforward, whereas
further enhancing an already strong algorithm is considerably more challenging. Therefore, the
performance improvement achieved by a prompt template should be assigned a lower weight when
applied to weak algorithms, a principle that is inherently consistent with our prompt template
performance calculation method.
Perf(Promptt) = EAt‚àºp(A)[At+1(task) ‚àíAt(task)|At+1 = LLM(At, Promptt)]
In each round, we employ a selection mechanism similar to that used for algorithm selection,
choosing prompt templates from the prompt template library based on performance rankings. The
selected templates will incorporate the task description, code, and algorithm performance metrics
to form complete prompts, which are then fed to the large language model for generating the next
generation of algorithms. Periodically, we update the prompt template library using an interaction-
based approach with the large language model, as illustrated below:
1 def getprompt4prompt(old_prompt_function):
2
prompt4prompt = (
3
f"You are an expert in prompt engineer. "
4
f"I have a function for generating prompt below: {old_prompt_function}, "
5
f"please help me to make it more powerful and appropriate for "
6
f"automatic algorithm design.\n"
10


--- Page 11 ---
7
"You can only modify the 'introduction', 'current_fwa', and "
8
"'requirements' fields, not the input and output of the function, "
9
"and make sure that this prompt allows the large language model to "
10
"put the returned code in <code>xxx</code> for easy parsing.\n"
11
f"Only return the code of the function for generating the prompt "
12
f"in <prompt>xxx</prompt >. Do not explain anything"
13
)
14
return prompt4prompt
Listing 3: Prompt Template Evolution Function
4
Experiments
In the experimental section, we note that while previous work has demonstrated the potential of
LLM-based population intelligence algorithms on continuous problems (including black-box function
test suites and low-dimensional constrained engineering design problems), these problems suffer
from low dimensionality and insuÔ¨Äicient relevance to real-world production scenarios, thus lacking
persuasiveness.
To address this limitation, we selected four distinct task categories from CO-
Benchmark[23] for comparison: aircraft landing problem, equitable partition problem, flow shop
scheduling problem, and uncapacitated p-median problem. These problem instances vary in scale
and feature diverse data distributions.
Our comparative baselines include state-of-the-art LLM-based automated algorithm design
methods such as EoH, Funsearch, and Reevo, as well as traditional widely-applied population
intelligence optimization algorithms like DE and PSO. To ensure fairness, we limited the maximum
number of LLM-generated algorithms to 200 per experiment (preventing potential unfairness in-
troduced by generating multiple algorithms in a single iteration) and run 5 times to get the best
algorithm.
Moreover, it is important to emphasize that, in all experiments, we do not employ penalty
function methods to handle constraints. If a generated solution fails to satisfy the problem con-
straints, it is directly considered invalid. This approach further enhances the algorithm‚Äôs capability
and requirement for constraint handling. In the experiment, we selected the firework algorithm as
the swarm intelligence optimization algorithm to be evolved.
All problem instances come with reference solutions.
The performance of the algorithm is
evaluated by comparing the solution obtained by the best algorithm generated during the process
with the reference solution, using a ratio metric. Ideally, this ratio should be a real number within
the interval [0, 1], though it may exceed 1 if a solution superior to the reference is found.
Performance =
Ô£±
Ô£¥
Ô£¥
Ô£¥
Ô£≤
Ô£¥
Ô£¥
Ô£¥
Ô£≥
Best
Reference,
for maximization problem
Reference
Best
,
for minimization problem
4.1
Aircraft landing problem
This task addresses the aircraft landing scheduling problem, which involves assigning landing times
and runway allocations to a set of aircraft under time window and separation constraints. The
objective is to minimize the total penalty cost incurred from deviations between the actual landing
11


--- Page 12 ---
times and the target times for each aircraft. Formally, given a set of aircraft P and a set of runways
R, the problem requires determining a landing time tp and a runway assignment rp ‚ààR for each
aircraft p ‚ààP. Each aircraft p is characterized by the following parameters: an appearance time
ap (when the aircraft enters the system), an earliest landing time ep, a target landing time œÑp, a
latest landing time lp, a penalty rate Œ±p for early landing per unit time, and a penalty rate Œ≤p for
late landing per unit time. The landing time tp must satisfy the constraint ep ‚â§tp ‚â§lp. The cost
for aircraft p is computed as Œ±p max(0, œÑp ‚àítp) + Œ≤p max(0, tp ‚àíœÑp), representing linear penalties
for earliness or lateness relative to œÑp.
Separation constraints are imposed to ensure safe operations: if two aircraft i and j are assigned
to the same runway, and if ti ‚â§tj, then the time gap must satisfy tj ‚àíti ‚â•sij, where sij is the
separation time provided in the input matrix sn√ón. If aircraft are assigned to different runways,
no separation constraint applies between them, as the input matrix is defined specifically for same-
runway assignments.
The freeze time parameter is provided but does not influence scheduling
decisions.
A solution is feasible only if all time window and separation constraints are satisfied. If any
constraint is violated, the solution is deemed invalid and receives no score. The goal is to find a
feasible schedule that minimizes the sum of penalty costs across all aircraft. Here we focus one the
Aircraft landing instances where |R| = 1. In this task, with |R| growing, it is easier to design a
solution that satisfies the constraints.
In this problem, the encoding scheme of our initial fireworks algorithm represents the takeoff
sequence of different aircraft, transforming the time-scheduling problem into a linear programming
formulation. Consequently, the explosion operator, mutation operator, and selection operator to be
designed are all tailored for permutation space. As shown in Table 1, experimental results indicate
that under the gpt-4o-mini model, conventional automated heuristic design frameworks fail to adapt
to the single-runway aircraft landing problem with complex constraints. Remarkably, Reevo and
Funsearch independently arrived at the same heuristic rules through their search procedures. In
contrast, our framework achieves near-optimal results in most tasks and even surpasses the reference
optimum in certain instances.
Table 1: Comparsions on Aircraft Landing Problems with gpt-4o-mini
Problem Instances
EoH
ReEvo
Funsearch
Ours
Airplane1
24.70%
57.85%
57.85%
100.00%
Airplane2
32.70%
72.91%
72.91%
99.33%
Airplane3
11.70%
28.57%
28.57%
100.00%
Airplane4
44.90%
56.25%
56.25%
100.00%
Airplane5
37.20%
43.54%
43.54%
100.00%
Airplane6
100.00%
100.00%
100.00%
100.00%
Airplane7
100.00%
39.00%
39.00%
100.00%
Airplane8
0.00%
44.42%
44.42%
97.08%
Airplane9
32.80%
55.02%
55.02%
119.63%
Airplane10
44.80%
48.74%
48.74%
100.25%
Airplane11
44.60%
70.13%
70.13%
142.42%
Average Performance
43.04%
56.04%
56.04%
105.66%
12


--- Page 13 ---
4.2
Equitable partition problem
This task addresses the problem of partitioning a set of individuals, each characterized by multiple
binary attributes. So the individuals can be represented as {xi|1 ‚â§i ‚â§n, xi ‚àà{0, 1}m}, into
exactly 8 distinct groups. The objective is to achieve a balanced distribution of attribute values
across these groups. Specifically, for each binary attribute, we aim to minimize the variation in
the count of individuals possessing the attribute value ‚Äô1‚Äô across different groups. The optimization
criterion is defined as the sum, over all attributes, of the average absolute deviation between the
count in each group and the mean count across all groups.
In the initial fireworks algorithm, our initialization process incorporates two distinct strategies.
The first approach involves directly generating a sequence of numbers ranging from 1 to 8, while
ensuring that all digits from 1 to 8 appear at least once. The second strategy employs a greedy
assignment method, where each individual is allocated to a group while simultaneously minimizing
the current absolute deviation measure.
As evidenced by the results in the table, our proposed method successfully resolves all problem
instances. In contrast, traditional optimization algorithms such as Particle Swarm Optimization
(PSO) and Differential Evolution (DE) demonstrate unsatisfactory performance on this problem.
More importantly, the performance gap observed between the first five and the last five instances
indicates that standard swarm intelligence and evolutionary algorithms struggle to adapt effectively
to diverse data distributions. Among automated algorithm design frameworks, Funsearch delivers
the most competitive performance.
The final algorithm configuration discovered by Funsearch
employs a greedy grouping initialization strategy coupled with a simulated annealing procedure
but EoH and ReEvo do not employ any search strategy. While this configuration achieves perfect
solutions on the first five instances, it fails to produce optimal results for instances epp6 through
epp8.
Table 2: Comparison on Equitable Partition Problem with gpt-4o-mini
Problems Instances
EoH
ReEvo
Funsearch
PSO
DE
Ours
Epp1
100.00%
100.00%
100.00%
7.18%
3.91%
100.00%
Epp2
100.00%
14.30%
100.00%
5.84%
4.05%
100.00%
Epp3
100.00%
33.30%
100.00%
7.19%
4.08%
100.00%
Epp4
100.00%
33.30%
100.00%
6.88%
3.81%
100.00%
Epp5
100.00%
100.00%
100.00%
6.42%
3.74%
100.00%
Epp6
90.20%
100.00%
88.50%
57.29%
43.15%
100.00%
Epp7
81.00%
100.00%
89.50%
67.45%
42.89%
100.00%
Epp8
75.30%
100.00%
94.80%
69.23%
47.07%
100.00%
Epp9
84.10%
100.00%
100.00%
71.42%
46.69%
100.00%
Epp10
92.90%
100.00%
100.00%
76.66%
56.81%
100.00%
Average Performance
92.35%
78.09%
97.28%
37.56%
25.62%
100.00%
4.3
Flow shop scheduling problem
The flow shop scheduling problem addresses the challenge of sequencing a set of jobs through a
series of machines in a fixed technological order. Given n jobs and m machines, the objective is
13


--- Page 14 ---
to determine an optimal permutation of jobs that minimizes the makespan‚Äîthe total completion
time required to process all jobs through all machines. Each job must be processed on all machines
in the same predetermined order, typically from machine 1 to machine m. The processing times
are specified in an n √ó m matrix, where each element pij represents the processing time of job j
on machine i. A solution is represented as a permutation of job indices defining the processing
sequence. If the solution violates constraints (e.g., invalid job sequencing or machine order), it is
deemed infeasible and receives no score.
Our search space comprises all permutations of integers from 1 to n, meaning each candidate
solution represents a distinct permutation of the sequence 1 to n. The initial population is generated
through a randomized initialization procedure.
As shown in Table 3, for this specific task, while conventional algorithms such as DE and PSO
achieve reasonably competent performance, those designed via LLM-driven evolution demonstrate
superior effectiveness. It is noteworthy that the top-performing algorithms identified by frameworks
such as EoH, ReEvo, and Funsearch all incorporate search mechanisms of varying complexity,
moving beyond purely online constructive approaches.
Notably, Funsearch hybridizes multiple
components including the NEH heuristic, 2-opt local search, and simulated annealing. Our results
achieve a performance level comparable to these state-of-the-art methods.
Table 3: Comparison on Flow Shop Scheduling Problem with gpt-4o-mini
Problems Instances
EoH
ReEvo
Funsearch
PSO
DE
Ours
Fss1
95.00%
95.00%
95.80%
94.39%
94.98%
95.55%
Fss2
94.40%
94.90%
94.90%
93.94%
94.41%
94.74%
Fss3
94.80%
99.30%
99.30%
95.52%
97.94%
99.07%
Fss4
96.70%
98.10%
97.80%
96.12%
95.93%
97.67%
Fss5
95.50%
96.80%
96.40%
93.03%
95.84%
96.42%
Fss6
97.50%
97.50%
98.70%
94.70%
97.52%
98.13%
Fss7
98.00%
98.00%
98.00%
97.02%
98.01%
98.18%
Fss8
96.40%
96.60%
96.60%
94.67%
95.06%
96.97%
Fss9
98.00%
98.00%
97.70%
93.95%
94.83%
98.05%
Fss10
95.10%
97.70%
97.70%
94.63%
95.93%
97.65%
Average Performance
96.14%
97.19 %
97.29%
94.80%
96.04%
97.24%
4.4
Uncapacitated p-median problem
The uncapacitated p-median problem is a fundamental combinatorial optimization problem in fa-
cility location theory. Given a graph G = (V, E) with n vertices and a symmetric cost matrix
D ‚ààRn√ón representing shortest-path distances between all vertex pairs, the objective is to select
exactly p vertices as medians (facilities) such that the sum of distances from each vertex to its
nearest median is minimized.
In our initial firework algorithm, we employ a discrete encoding scheme where each individual is
represented as a binary string of length n with exactly p ones. The same representation is adopted
for both PSO and DE in our implementation.
14


--- Page 15 ---
As shown in Table 4, the methods based on LLM-automated algorithm evolution all demonstrate
strong performance, significantly surpassing traditional swarm intelligence optimization algorithms.
While Funsearch achieves the best average performance, our method is closely behind it.
Table 4: Comparison on Uncapacitated p-Median Problem with gpt-4o-mini
Problem Instances
EoH
ReEvo
Funsearch
PSO
DE
Ours
Pmu1
98.80%
100.00%
100.00%
96.74%
97.83%
100.00%
Pmu2
99.40%
99.70%
99.70%
94.98%
94.42%
99.97%
Pmu3
96.60%
100.00%
100.00%
95.01%
97.24%
100.00%
Pmu4
98.30%
100.00%
100.00%
91.92%
92.55%
99.99%
Pmu5
98.30%
99.60%
100.00%
86.58%
94.15%
99.90%
Pmu6
97.50%
100.00%
100.00%
95.22%
95.73%
99.98%
Pmu7
99.70%
100.00%
100.00%
92.69%
90.86%
99.99%
Pmu8
99.40%
99.80%
99.80%
90.18%
85.91%
99.98%
Pmu9
96.20%
99.80%
100.00%
86.84%
83.90%
99.58%
Pmu10
96.90%
99.90%
99.80%
80.04%
84.15%
99.78%
Pmu11
99.70%
100.00%
100.00%
95.07%
94.24%
100.00%
Pmu12
99.70%
100.00%
99.90%
90.85%
88.43%
99.99%
Pmu13
97.90%
99.80%
99.90%
89.66%
86.25%
99.87%
Pmu14
98.50%
99.50%
100.00%
85.77%
81.89%
99.48%
Pmu15
98.20%
99.50%
100.00%
79.96%
82.06%
99.71%
Pmu16
99.10%
99.70%
99.90%
93.22%
92.86%
100.00%
Pmu17
99.70%
99.80%
99.80%
89.08%
87.65%
99.79%
Pmu18
98.70%
100.00%
99.70%
88.17%
84.19%
99.92%
Pmu19
98.10%
99.50%
99.30%
84.86%
78.93%
99.61%
Average Performance
98.46%
99.82%
99.88%
89.83%
89.12%
99.87%
4.5
Further discussion
4.5.1
Prompts Analysis
We examine the evolution of the prompt templates.
The high-performance mutation prompts
evolved under different large language models are presented in Appendix. The evolved templates
significantly enhance the level of detail and technical specificity compared to the original, em-
phasizing performance-oriented constraints such as exploration-exploitation balance, convergence
speed, and robustness. A common trend is the focus on targeted algorithm improvement and prac-
ticality, requiring unchanged code interfaces and the return of only complete code, reflecting the
optimization of prompt precision and operability through automatic evolution.
The templates generated by different models vary in language style, level of detail, and con-
straint focus, demonstrating the impact of model capabilities on output quality.
The template
generated by gpt-4o-mini emphasizes conceptual innovation, with fluent language but relatively
lenient requirements, encouraging creative improvements such as adaptive strategies and hybridiza-
tion techniques, showing the model‚Äôs strength in producing heuristic content, though it may lack
15


--- Page 16 ---
0
20
40
60
80
100
120
140
160
Algorithm Step
0.986
0.988
0.990
0.992
0.994
0.996
0.998
1.000
Evaluation Performance
0
c0
m0
m0
c0
m0
m0
m0
m1
m0
m0
m1
m1
m1
m2
m1
m0
c1
m0
m2
m0
c1
m2
c2
m4
m3
m0
c4
m0
m4
c5
c4
c4
c4
m4
Peak: 0.9993
Co-evolution Curve of FWA and Prompts on P-median Problem
Prompt Update
Normal Update
Figure 4: Evolution diagram of the complete LLM+FWA+P framework applied to one PMU prob-
lem instance, where red dots indicate the moments of prompt template updates (a stage that
generates multiple algorithms), and blue dots represent the remaining evolutionary moments. We
have annotated the best-performing prompt template at each moment, where mi denotes the i-th
generation mutation prompt template, and ci denotes the i-th generation crossover prompt tem-
plate. The diagram reveals that many local maxima are attained precisely at the moments when
prompt templates are updated, with m4 ultimately achieving the optimal performance.
deep technical specifics. The template from Qwen3-32B stresses theoretical foundations and engi-
neering practices, requiring improvements based on ‚Äùstrong theoretical and practical foundations‚Äù
and focusing on testability and reproducibility, indicating the model‚Äôs robust ability to combine aca-
demic rigor with practicality, with outputs leaning towards methodological guidance. The template
by GPT-5 is extremely detailed, incorporating multiple technical constraints like the use of ran-
dom number generators, complexity control, and reproducibility, with highly structured language
resembling technical specifications, demonstrating the model‚Äôs advanced logical reasoning and do-
main knowledge, capable of generating highly precise and secure prompts, though potentially at
the cost of conciseness.
Different large language models require distinct guidance approaches, which in turn leads to their
unique areas of emphasis. This inherent relationship validates the necessity of a co-evolutionary
mechanism.
Furthermore, the evolutionary trajectory of a single LLM+FWA+P run on the PMU task, illus-
trated in Figure 4, demonstrates the critical importance of prompt template updates for enhancing
overall performance.
16


--- Page 17 ---
4.5.2
Ablation Study
Next, we conduct a systematic ablation experiment to validate the eÔ¨Äicacy of the LLM+FWA+P
method.
As shown in Table 5, the full model achieves optimal performance on most problem
instances, demonstrating particular superiority in the Airplane series (e.g., 142.42% on Airplane11).
The ablation study compares three progressively simplified methods: LLM+FWA+P, LLM+FWA,
and initial FWA.
The results reveal a distinct performance hierarchy, confirming each component‚Äôs necessity. The
P component proves critical for complex problems, as its removal causes a 9.43% performance
drop on Airplane11. The LLM component‚Äôs fundamental role is evidenced in Pmu tasks, where its
absence leads to catastrophic performance degradation (e.g., from 99.78% to 63.13% on Pmu10).
Notably, the method maintains robust performance across tasks with different initialization
strategies. It achieves significant optimization gains in Airplane/Epp tasks with enhanced initial-
ization, while maintaining competitive advantage in Fss/Pmu tasks using direct encoding. This
cross-task stability demonstrates that LLM+FWA+P constitutes a generalized solving framework
whose effectiveness is independent of specific initialization techniques from human knowledge.
Table 5: Performance comparison of different algorithms with gpt-4o-mini
Problems
EoH
ReEvo
Funsearch
LLM + FWA + P
LLM + FWA
Initial FWA
Airplane2
32.70%
72.91%
72.91%
99.33%
99.20%
98.67%
Airplane8
0.00%
44.42%
44.42%
97.08%
94.82%
78.63%
Airplane9
32.80%
55.02%
55.02%
119.63%
114.93%
107.56%
Airplane10
44.80%
48.74%
48.74%
100.25%
97.68%
88.00%
Airplane11
44.60%
70.13%
70.13%
142.42%
132.99%
128.69%
Epp7
81.00%
100.00%
89.50%
100.00%
100.00%
99.27%
Epp8
75.30%
100.00%
94.80%
100.00%
99.02%
95.94%
Fss1
95.00%
95.00%
95.80%
95.55%
95.41%
94.99%
Fss2
94.40%
94.90%
94.90%
94.74%
94.58%
94.42%
Pmu10
96.90%
99.90%
99.80%
99.78%
98.82%
63.13%
Pmu15
98.20%
99.50%
100.00%
99.71%
98.34%
67.57%
Pmu19
98.10%
99.50%
99.30%
99.92%
99.44%
73.24%
4.5.3
Impact of LLMs
Meanwhile, we also compared the impact of different large language models (LLMs) on the fi-
nal performance of various algorithm design frameworks. We selected three LLMs‚Äîgpt-4o-mini,
Qwen3-32B, and gpt-5‚Äîand conducted comprehensive comparative experiments on the aircraft
landing problem. The results are presented in Table 6Ôøøwhich clearly demonstrates the significant
advantages of the LLM+FWA+P framework over comparative algorithms such as EoH, ReEvo,
and Funsearch.
First, LLM+FWA+P exhibits superior and consistent performance across different underly-
ing LLMs. As shown in the ‚ÄùAverage Performance‚Äù row, regardless of whether the base LLM is
the relatively less powerful GPT-4o-mini or the highly capable GPT-5, the average performance of
17


--- Page 18 ---
LLM+FWA+P (105.34%, 109.36%, 112.57%) is significantly and consistently higher than all bench-
marks. Notably, when using GPT-4o-mini, the performance of LLM+FWA+P is nearly double that
of the next best algorithms (ReEvo and Funsearch, both at 56.04%). This robustly validates the
inherent effectiveness of the framework itself, which is capable of amplifying and complementing
the capabilities of the underlying LLM, rather than being entirely dependent on the LLM‚Äôs native
strength.
Second, the LLM+FWA+P framework demonstrates breakthrough exploratory capabilities in
solving complex problems. For more challenging instances such as Airplane9 to Airplane11, where
the performance of other algorithms generally remains below 100%, the LLM+FWA+P framework
consistently achieves results significantly exceeding 100% (e.g., 142.42% for Airplane11 with GPT-
4o-mini). This indicates that the framework not only finds feasible solutions but can surpass the
established benchmark to discover superior solutions, highlighting its unique advantage in exploring
the algorithm space.
Finally, the framework effectively leverages the potential of more powerful LLMs to enable
further performance gains. When the underlying LLM is upgraded from GPT-4o-mini to GPT-5,
the ‚ÄùAverage Performance‚Äù of LLM+FWA+P increases from 105.34% to 112.57%, achieving peak
performance close to 155% on diÔ¨Äicult problems (e.g., 154.34% for Airplane11 with GPT-5). This
suggests a positive synergistic effect between the LLM+FWA+P framework and advanced LLMs,
where the framework successfully guides more capable LLMs to produce higher-quality algorithmic
innovations.
Table 6: Performance comparison of different algorithms with different LLMs on aircraft landing
problems
GPT-4o-mini
Qwen3-32B
GPT-5
Problems
EoH
ReEvo
Funsearch
LLM + FWA + P
EoH
ReEvo
Funsearch
LLM + FWA + P
EoH
ReEvo
Funsearch
LLM + FWA + P
Airplane1
24.70%
57.85%
57.85%
100.00%
57.90%
57.90%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
Airplane2
32.70%
72.91%
72.91%
99.33%
72.90%
72.90%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
Airplane3
11.70%
28.57%
28.57%
100.00%
28.60%
35.80%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
Airplane4
44.90%
56.25%
56.25%
100.00%
56.20%
56.20%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
Airplane5
37.20%
43.54%
43.54%
100.00%
43.50%
43.50%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
Airplane6
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
Airplane7
100.00%
39.00%
39.00%
100.00%
39.00%
39.00%
100.00%
100.00%
100.00%
100.00%
100.00%
100.00%
Airplane8
0.00%
44.42%
44.42%
97.08%
44.40%
53.90%
100.00%
100.00%
100.00%
98.70%
100.00%
100.00%
Airplane9
32.80%
55.02%
55.02%
119.63%
55.00%
57.80%
71.60%
137.00%
137.50%
138.00%
138.30%
139.86%
Airplane10
44.80%
48.74%
48.74%
100.25%
48.70%
58.50%
82.20%
116.04%
122.40%
135.30%
131.20%
144.06%
Airplane11
44.60%
70.13%
70.13%
142.42%
70.10%
78.10%
73.00%
149.96%
143.10%
141.70%
152.30%
154.34%
Average Performance
43.04%
56.04%
56.04%
105.34%
56.03%
59.42%
93.35%
109.36%
109.36%
110.34%
111.07%
112.57%
4.5.4
Analysis on FWA generated by GPT-5
To gain an intuitive and in-depth understanding of the algorithmic characteristics of the optimized
FWA by GPT-5, we have included its complete code implementation in the Appendix and conducted
a meticulous analysis focusing on its three core operators.
The explosion operator serves as the primary search mechanism, generating new spark solutions
from each firework individual. Its core technology lies in the sequence weight construction mecha-
nism, which calculates positional deviations between the current sequence and the target sequence,
combined with aircraft penalty costs to form guided perturbation weights. The algorithm employs
a multi-modal perturbation strategy with 50% probability for swap operations, 30% for insertion
operations, and 20% for reversal operations, each incorporating amplitude-based adaptive control.
The number of explosion steps correlates positively with amplitude, ensuring dynamic search range
adjustment according to fitness. Meanwhile, repair mechanisms and lightweight local optimization
are introduced to fix infeasible solutions through adjacent swaps, and solution quality is enhanced
18


--- Page 19 ---
through limited neighborhood searches. Finally, solution uniqueness is maintained via hash sets to
avoid redundant computations.
The mutation operator functions as an auxiliary search mechanism, performing secondary op-
timization on sparks generated by explosion with emphasis on population diversity enhancement.
This operator adopts a composite mutation operation system integrating four mutation opera-
tions with probabilistic distribution: swap operations (35%), insertion operations (35%), reversal
operations (20%), and or-opt block moving (10%). The mutation process demonstrates a guidance-
oriented strategy, with 60% probability of selecting the aircraft with maximum positional deviation
for priority mutation, and introduces classical Or-opt block moving operations to simulate profes-
sional domain search behaviors. An intelligent repair mechanism combines guided insertion and
random swapping for hybrid repair of infeasible solutions, where guided insertion focuses on the
aircraft with maximum deviation while random swapping increases exploration randomness. Muta-
tion scale is controlled through mutation rate, targeting 20% of total sparks for mutation, achieving
balance between elitism preservation and diversity enhancement.
The selection operator employs a three-round progressive strategy combining elitism preserva-
tion and diversity maintenance to ensure continuous population quality improvement. The first
round of elite selection preserves 60% population size of optimal non-duplicate solutions, achieving
strict deduplication based on sequence hashing. The second round of diversity selection introduces
an adaptive distance threshold mechanism, using mean absolute position deviation as a diversity
metric to filter individuals maintaining suÔ¨Äicient distance from selected solutions. The third round
of supplemental selection fills remaining positions by fitness order, allowing moderate similarity.
Sequence similarity measurement utilizes mean absolute difference of position mapping vectors,
with thresholds adapting to problem scale. A fitness cleaning mechanism handles anomalies by
setting non-finite values to infinity, ensuring numerical stability during selection. This layered se-
lection strategy effectively prevents premature convergence and maintains population exploration
capability.
5
Conclusion
This paper proposes a novel framework for LLM-driven swarm intelligence optimization algorithm
design, whose core innovation lies in the introduction of a co-evolution mechanism for prompt tem-
plates. Departing fundamentally from prior automated algorithm design approaches (e.g., EoH,
Funsearch, and Reevo) that focused predominantly on automating the algorithm structures them-
selves, our framework treats the prompt templates themselves as evolvable objects, enabling them
to learn and adapt collaboratively with the algorithm population within the same evolutionary
process. Through this design, the framework empowers the prompts to more effectively guide the
contemporary large language models, thereby better unleashing their inherent algorithm design
capabilities. Consequently, it significantly reduces reliance on the innate capabilities of the base
LLM, rendering the entire algorithm evolution process more intelligent and comprehensive .
Extensive experiments on diverse NP-hard problem instances, supported by thorough ablation
studies, demonstrate that our framework, by fully leveraging the guiding role of prompts, achieves
superior performance across various optimization scenarios compared to several previous excellent
benchmark frameworks, including EoH, Funsearch, and Reevo. These results not only validate the
effectiveness of the prompt co-evolution mechanism but also mark a critical step forward for swarm
intelligence optimization research paradigms towards greater eÔ¨Äiciency and automation. We firmly
believe that the research paradigm based on large language models, deeply integrated with prompt
19


--- Page 20 ---
engineering, will inject new vitality into the field of swarm intelligence optimization and open up
broader application prospects.
References
[1] Eshaan Agarwal, Joykirat Singh, Vivek Dani, Raghav Magazine, Tanuja Ganu, and Ak-
shay Nambi.
Promptwizard: Task-aware prompt optimization framework.
arXiv preprint
arXiv:2405.18369, 2024.
[2] Thomas B√§ck and Hans-Paul Schwefel. An overview of evolutionary algorithms for parameter
optimization. Evolutionary computation, 1(1):1‚Äì23, 1993.
[3] Jagdish Chand Bansal, Pramod Kumar Singh, Nikhil R Pal, et al. Evolutionary and swarm
intelligence algorithms, volume 779. Springer, 2019.
[4] Christian Blum. Ant colony optimization: Introduction and recent trends. Physics of Life
reviews, 2(4):353‚Äì373, 2005.
[5] Edvinas Byla and Wei Pang. Deepswarm: Optimising convolutional neural networks using
swarm intelligence. In UK Workshop on Computational Intelligence, pages 119‚Äì130. Springer,
2019.
[6] Shipeng Cen and Ying Tan. Llm-driven customizable fireworks algorithm for diverse optimiza-
tion tasks. In 2025 IEEE Congress on Evolutionary Computation (CEC), pages 1‚Äì9. IEEE,
2025.
[7] Swagatam Das and Ponnuthurai Nagaratnam Suganthan. Differential evolution: A survey of
the state-of-the-art. IEEE transactions on evolutionary computation, 15(1):4‚Äì31, 2010.
[8] Oded Goldreich.
P, NP, and NP-Completeness:
The basics of computational complexity.
Cambridge University Press, 2010.
[9] Nikolaus Hansen, Sibylle D M√ºller, and Petros Koumoutsakos. Reducing the time complexity of
the derandomized evolution strategy with covariance matrix adaptation (cma-es). Evolutionary
computation, 11(1):1‚Äì18, 2003.
[10] Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark,
AJ Ostrow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card. arXiv
preprint arXiv:2410.21276, 2024.
[11] Feihu Jin, Yifan Liu, and Ying Tan. Derivative-free optimization for low-rank adaptation in
large language models. IEEE/ACM Transactions on Audio, Speech, and Language Processing,
2024.
[12] Peiyu Liao, Siting Liu, Zhitang Chen, Wenlong Lv, Yibo Lin, and Bei Yu. Dreamplace 4.0:
Timing-driven global placement with momentum-based net weighting. In 2022 Design, Au-
tomation & Test in Europe Conference & Exhibition (DATE), pages 939‚Äì944. IEEE, 2022.
[13] Yibo Lin, Shounak Dhar, Wuxi Li, Haoxing Ren, Brucek Khailany, and David Z Pan. Dream-
place: Deep learning toolkit-enabled gpu acceleration for modern vlsi placement. In Proceedings
of the 56th Annual Design Automation Conference 2019, pages 1‚Äì6, 2019.
20


--- Page 21 ---
[14] Fei Liu, Xialiang Tong, Mingxuan Yuan, Xi Lin, Fu Luo, Zhenkun Wang, Zhichao Lu, and
Qingfu Zhang. Evolution of heuristics: Towards eÔ¨Äicient automatic algorithm design using
large language model. arXiv preprint arXiv:2401.02051, 2024.
[15] Fei Liu, Yiming Yao, Ping Guo, Zhiyuan Yang, Zhe Zhao, Xi Lin, Xialiang Tong, Mingxuan
Yuan, Zhichao Lu, Zhenkun Wang, et al. A systematic survey on large language models for
algorithm design. arXiv preprint arXiv:2410.14716, 2024.
[16] Pablo Ribalta Lorenzo, Jakub Nalepa, Michal Kawulok, Luciano Sanchez Ramos, and
Jos√© Ranilla Pastor. Particle swarm optimization for hyper-parameter selection in deep neu-
ral networks. In Proceedings of the genetic and evolutionary computation conference, pages
481‚Äì488, 2017.
[17] Rajesh Matai, Surya Prakash Singh, and Murari Lal Mittal. Traveling salesman problem: an
overview of applications, formulations, and solution approaches. Traveling salesman problem,
theory and applications, 1(1):1‚Äì25, 2010.
[18] Seyedali Mirjalili, Seyed Mohammad Mirjalili, and Andrew Lewis. Grey wolf optimizer. Ad-
vances in engineering software, 69:46‚Äì61, 2014.
[19] Alexander Novikov,
Ng√¢n V≈©,
Marvin Eisenberger,
Emilien Dupont,
Po-Sen Huang,
Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Francisco JR Ruiz, Abbas Mehra-
bian, et al. Alphaevolve: A coding agent for scientific and algorithmic discovery. arXiv preprint
arXiv:2506.13131, 2025.
[20] openAI. Gpt-5 system card, 2025.
[21] Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog,
M Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang,
Omar Fawzi, et al. Mathematical discoveries from program search with large language models.
Nature, 625(7995):468‚Äì475, 2024.
[22] Yuhui Shi. An optimization algorithm based on brainstorming process. In Emerging Research
on Swarm Intelligence and Algorithm Optimization, pages 1‚Äì35. IGI Global Scientific Publish-
ing, 2015.
[23] Weiwei Sun, Shengyu Feng, Shanda Li, and Yiming Yang.
Co-bench: Benchmarking lan-
guage model agents in algorithm search for combinatorial optimization.
arXiv preprint
arXiv:2504.04310, 2025.
[24] Ying Tan and Yuanchun Zhu. Fireworks algorithm for optimization. In International conference
in swarm intelligence, pages 355‚Äì364. Springer, 2010.
[25] Paolo Toth and Daniele Vigo. The vehicle routing problem. SIAM, 2002.
[26] Dongshu Wang, Dapei Tan, and Lei Liu. Particle swarm optimization algorithm: an overview.
Soft computing, 22(2):387‚Äì408, 2018.
[27] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu,
Chang Gao, Chengen Huang, Chenxu Lv, et al.
Qwen3 technical report.
arXiv preprint
arXiv:2505.09388, 2025.
21


--- Page 22 ---
[28] Haoran Ye, Jiarui Wang, Zhiguang Cao, Federico Berto, Chuanbo Hua, Haeyeon Kim, Jinkyoo
Park, and Guojie Song.
Reevo: Large language models as hyper-heuristics with reflective
evolution. Advances in neural information processing systems, 37:43571‚Äì43608, 2024.
[29] Mert Yuksekgonul, Federico Bianchi, Joseph Boen, Sheng Liu, Pan Lu, Zhi Huang, Carlos
Guestrin, and James Zou. Optimizing generative ai by backpropagating language model feed-
back. Nature, 639(8055):609‚Äì616, 2025.
[30] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian
Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. A survey of large language models.
arXiv preprint arXiv:2303.18223, 1(2), 2023.
[31] Jianlin Zhong, Dong Tang, Manchang Gu, Mingjiang Xie, Zhaowen Tao, and Zhengyu Zhang.
Gradpromptopt: An enhanced prompt optimization method to improve performance of llms.
In 2025 8th International Symposium on Big Data and Applied Statistics (ISBDAS), pages
716‚Äì720. IEEE, 2025.
6
Appendix
6.1
Prompts produced by different LLMs
1 def get_mutation_prompts(problem_description , current_code , current_perfomance):
2
introduction = f"You are an expert in algorithm design and combinatorial optimization
. Your task is to improve a Firework Algorithm (FWA) for solving the following
problem: {problem_description}.\n" \
3
+ "You should focus on enhancing the algorithm's performance by
redesigning one of its core components with creativity and rigor. Consider aspects
such as exploration -exploitation balance, diversity preservation , convergence speed,
and problem-specific characteristics. Think about how to incorporate adaptive
strategies, hybridization with other techniques , or novel initialization methods if
appropriate. The goal is to achieve better scalability , robustness , and solution
quality."
4
current_fwa = f"The current implementation of the FWA is as follows:\n{current_code}\
nIts performance is currently {current_perfomance}. Higher values indicate better
performance.\n" \
5
+ "Analyze the code carefully and identify potential bottlenecks or
areas where improvements can be made. Pay attention to how each component contributes
to the overall behavior of the algorithm."
6
requirements = "1. Choose exactly one of the functions among 'explode', 'mutate', or
'select' from the provided code and redesign it.\n" \
7
+ "2. Ensure that your redesigned function maintains the same input and
output interfaces as the original.\n" \
8
+ "3. Do not modify any other parts of the algorithm.\n" \
9
+ "4. Return only the complete updated FWA code in the format: <code
>...</code>, with no additional explanations."
10
prompt_mutation = introduction + current_fwa + requirements
11
return prompt_mutation
Listing 4: Good Mutation Prompt Generation Function by gpt-4o-mini
1 def get_mutation_prompts(problem_description , current_code , current_performance):
22


--- Page 23 ---
2
introduction = f"You are a world-class expert in algorithm engineering with deep
expertise in evolutionary and metaheuristic optimization. Your task is to iteratively
refine a fireworks algorithm (FWA) for the combinatorial optimization problem: {
problem_description}. Each step should focus on a single meaningful and impactful
improvement to one of the three core ‚Äîoperators'explode', 'mutate', or 'select'. Your
objective is to enhance solution quality, convergence speed, and robustness while
maintaining structural fidelity to the original algorithm. Use advanced algorithm
design techniques , mathematical reasoning, and empirical insights to guide your
changes. Your suggestions must be grounded in strong theoretical and practical
foundations , and every modification should be performance -oriented, testable, and
reproducible."
3
current_fwa = f"The current FWA implementation , which achieves a performance score of
{current_performance}, is provided below. You are to produce a refined version of
the FWA by introducing one, and only one, focused change to one of the core operators
. Preserve all function signatures , interfaces , and the overall algorithmic structure
to ensure compatibility and continuity.\n\n" \
4
f"{current_code}"
5
requirements = "1. Modify exactly one of the core operators: 'explode', 'mutate', or
'select'.\n" \
6
+ "2. Do not change function signatures , control flow, or core
algorithm structure.\n" \
7
+ "3. Your modification must improve performance , robustness , or
convergence speed in a measurable and meaningful way.\n" \
8
+ "4. Return only the complete and syntactically correct updated FWA
code, enclosed in <code>...</code>, with no explanations , comments, or additional
text."
9
prompt_mutation = introduction + "\n\n" + current_fwa + "\n\n" + requirements
10
return prompt_mutation
Listing 5: Good Mutation Prompt Generation Function by Qwen3-32B
1 def get_mutation_prompts(problem_description , current_code , current_perfomance):
2
introduction = (
3
f"You are an expert automatic algorithm designer specializing in combinatorial
optimization and Fireworks Algorithm (FWA) "
4
f"variants. Your job is to produce a single targeted redesign to maximize the
given performance metric (higher is better). "
5
f"Analyze the baseline internally and simulate the impact of your changes on ‚Äì
explorationexploitation balance, robustness , "
6
f"and reproducibility , but output only code and no commentary in the final answer
. The task context is: {problem_description}.\n"
7
)
8
current_fwa = (
9
f"The baseline FWA implementation (treated as the exact ground truth) is provided
as code:\n"
10
f"{current_code}\n"
11
f"Its current measured performance is: {current_perfomance}.\n"
12
f"You must return the COMPLETE algorithm code, identical to the baseline except
for ONE redesigned function chosen as specified below.\n"
13
)
14
requirements = (
15
"Strict output and design requirements:\n"
16
"1) Choose EXACTLY ONE function to redesign from this set: 'explode', 'mutate',
or 'select'.\n"
17
"2) Redesign ONLY the chosen function. Preserve its function name, parameter list
(names, order, default values), input types, "
18
"and return value(s) and their types/shapes. Do not modify any other functions,
classes, global variables, helper utilities, "
23


--- Page 24 ---
19
"control flow, or imports anywhere outside the chosen function.\n"
20
"3) The modification must be drop-in compatible and runnable: the whole algorithm
must execute without errors using the same inputs. "
21
"Do not add parameters, change data structures , or alter public interfaces.\n"
22
"4) Preserve reproducibility: reuse the baseline's existing random-number
generator(s) and seed(s). Do NOT introduce new randomness sources, "
23
"new global state, new external dependencies , or new imports. If the baseline
uses a seeded RNG object, use it; do not switch to other RNGs.\n"
24
"5) Aim to improve performance by balancing exploration and exploitation while
keeping or reducing computational complexity relative to the original function. "
25
"Examples of allowed strategies (within the chosen function only): adaptive
amplitudes/step sizes based on fitness or diversity, diversity maintenance and "
26
"duplicate handling, robust boundary handling (clip/reflect within known bounds),
elite-aware adjustments. Avoid super-linear time/memory increases; keep "
27
"overheads to constant or near-constant factors.\n"
28
"6) Maintain coding style, variable names, typing hints, and IO contracts used in
the baseline. Do not rename the chosen function or its parameters. "
29
"Do not change return ordering, container types, or shapes. Handle edge cases
robustly (e.g., ties, NaN/Inf fitness, empty lists, boundary-only candidates) "
30
"without altering the external interface.\n"
31
"7) Output formatting: RETURN ONLY the full algorithm code wrapped EXACTLY ONCE
in <code>...</code> tags. Do not include explanations , comments, print/log statements
, "
32
"or any extra text before or after the tags. The returned code must be identical
to the baseline except for the single redesigned function.\n"
33
"8) Determinism: under the same seed, the algorithm must remain reproducible. If
you change the order or number of random calls inside the chosen function, "
34
"ensure the seeded RNG still governs all randomness. Do not introduce time-based
or environment -based variability.\n"
35
"9) Constraints checklist before returning: same imports, same module-level
definitions , same public interfaces; no added dependencies; no I/O; no assertions
that break runtime; "
36
"no changes outside the chosen function. If uncertain, prefer minimal local
changes that improve robustness and performance while honoring all constraints.\n"
37
)
38
prompt_mutation = introduction + current_fwa + requirements
39
return prompt_mutation
Listing 6: Good Mutation Prompt Generation Function by GPT-5
6.2
Best FWA on Aircraft landing problem produced by GPT-5
1 import random
2 import numpy as np
3 from typing import List, Dict, Tuple
4 import copy
5 import time
6
7 class FWA:
8
def __init__(
9
self,
10
evaluator: callable,
# Evaluation function: input -> fitness (smaller is better)
11
num_planes: int,
# Number of planes
12
num_runways: int,
# Number of runways
13
planes: List[Dict],
# Plane information (contains "earliest"/"latest"/"target
"/"penalty_early"/"penalty_late")
24


--- Page 25 ---
14
separation: List[List[float]],
# Separation matrix (separation[i][j] = minimum
separation when i precedes j)
15
fw_size: int = 5,
# Number of fireworks (population size)
16
sp_size: int = 20,
# Total number of sparks (total sparks generated by all
fireworks)
17
init_amp: float = 5,
# Initial explosion amplitude (time perturbation ratio
relative to time window length)
18
max_iter: int = 200,
# Maximum iterations
19
mutation_rate: float = 0.2,
# Mutation probability
20
lp_path, #Path of the lp function
21
):
22
# Core parameter storage
23
self.evaluator = evaluator
24
self.num_planes = num_planes
25
self.num_runways = num_runways
26
self.planes = planes
27
self.separation = np.array(separation)
28
self.fw_size = fw_size
29
self.sp_size = sp_size
30
self.init_amps = init_amp
31
self.max_iter = max_iter
32
self.mutation_rate = mutation_rate
33
self.silent = 0
34
self.lp_path = lp_path
35
self.earliest_landing_times = np.array([self.planes[index]["earliest"] for index
in range(self.num_planes)])
36
self.target_landing_times = np.array([self.planes[index]["target"] for index in
range(self.num_planes)])
37
self.latest_landing_times = np.array([self.planes[index]["latest"] for index in
range(self.num_planes)])
38
self.penalty_early = np.array([self.planes[index]['penalty_early'] for index in
range(self.num_planes)])
39
self.penalty_late = np.array([self.planes[index]['penalty_late'] for index in
range(self.num_planes)])
40
# Dynamic parameters (adaptive explosion amplitude)
41
self.amps = [init_amp] * fw_size
# Explosion amplitude for each firework
42
self.population = []
# Population storage (tuple: (runway_assignment ,
landing_times))
43
def sequence2time(self, sequence):
44
# Here sequence is a numpy sorted array
45
import sys
46
sys.path.append(self.lp_path)
47
from linprog import solve_sequence_with_cost
48
n = self.num_planes
49
a, b, c = self.earliest_landing_times[sequence], self.latest_landing_times[
sequence], self.target_landing_times[sequence]
50
d, e = self.penalty_early[sequence], self.penalty_late[sequence]
51
s = self.separation[sequence][:,sequence]
52
return solve_sequence_with_cost(n, a, b, c, d, e, s)
53
54
def initialize(self):
55
target_landing_times = [self.planes[index]["target"] for index in range(self.
num_planes)]
56
idx = np.argsort(target_landing_times)
57
times, cost = self.sequence2time(idx)
58
runway_assignment = [1 for i in range(self.num_planes)]
59
final_times = [times[idx.tolist().index(k)] for k in range(self.num_planes)]
60
return runway_assignment , final_times , idx
25


--- Page 26 ---
61
62
def explode(self, firework, amp):
63
runway_assignment , times, sequence = firework
64
n = self.num_planes
65
sp_per_fw = max(1, self.sp_size // self.fw_size)
66
exploded = []
67
68
# Target order (sorted by target time)
69
target_order = np.argsort(self.target_landing_times)
70
target_pos = np.empty(n, dtype=int)
71
target_pos[target_order] = np.arange(n)
72
73
# Inertia/guidance: weighted point selection based on deviation from target
sequence and penalty strength
74
penalties = self.penalty_early + self.penalty_late
75
76
def build_weights(idx_arr):
77
pos = np.empty(n, dtype=int)
78
pos[idx_arr] = np.arange(n)
79
displacement = np.abs(pos - target_pos)
80
# Avoid all zeros, add baseline of 1
81
w = 1.0 + displacement * (1.0 + penalties)
82
w = w.astype(float)
83
s = w.sum()
84
if s <= 0:
85
w = np.ones_like(w, dtype=float) / n
86
else:
87
w = w / s
88
return w, pos
89
90
def apply_insertion(idx_arr, pos_map, k_plane, new_pos):
91
cur_pos = pos_map[k_plane]
92
if new_pos == cur_pos:
93
return idx_arr
94
# Perform insertion
95
if new_pos < cur_pos:
96
# Move left
97
new_idx = np.concatenate([idx_arr[:new_pos], [k_plane], idx_arr[new_pos:
cur_pos], idx_arr[cur_pos+1:]])
98
else:
99
# Move right
100
new_idx = np.concatenate([idx_arr[:cur_pos], idx_arr[cur_pos+1:new_pos
+1], [k_plane], idx_arr[new_pos+1:]])
101
return new_idx
102
103
def local_improve(idx_arr, base_cost, max_trials=3):
104
# Lightweight local improvement: try several adjacent swaps, accept if LP
cost decreases
105
best_idx = idx_arr
106
best_times , best_cost = self.sequence2time(best_idx)
107
if not np.isfinite(best_cost):
108
return None, None, np.inf
109
trials = max_trials
110
while trials > 0:
111
trials -= 1
112
p = random.randrange(n - 1)
113
cand = best_idx.copy()
114
cand[p], cand[p+1] = cand[p+1], cand[p]
26


--- Page 27 ---
115
t, c = self.sequence2time(cand)
116
if np.isfinite(c) and c < best_cost:
117
best_idx, best_times , best_cost = cand, t, c
118
return best_idx, best_times , best_cost
119
120
seen = set()
121
seen.add(tuple(sequence.tolist()))
122
123
# Each spark attempts to generate sp_per_fw unique candidates
124
for _ in range(sp_per_fw):
125
tries = 0
126
generated = False
127
while tries < 10 and not generated:
128
tries += 1
129
idx = sequence.copy()
130
w, pos_map = build_weights(idx)
131
132
# Perturbation steps related to amplitude
133
steps = max(1, int(np.random.randint(1, int(amp) + 1)))
134
135
for _step in range(steps):
136
move_type = np.random.choice([0, 1, 2], p=[0.5, 0.3, 0.2])
# 0:swap,
1:insertion, 2:reverse
137
if move_type == 0:
138
# Weighted selection of two different planes for swapping
139
i_plane = np.random.choice(n, p=w)
140
j_plane = np.random.choice(n, p=w)
141
# If duplicate, randomly pick different one
142
if i_plane == j_plane:
143
j_plane = (j_plane + 1) % n
144
i_pos = pos_map[i_plane]
145
j_pos = pos_map[j_plane]
146
idx[i_pos], idx[j_pos] = idx[j_pos], idx[i_pos]
147
elif move_type == 1:
148
# Insertion: move high-weight plane toward target position
149
k_plane = np.random.choice(n, p=w)
150
tgt = target_pos[k_plane]
151
# New position around target with some noise (larger amplitude,
wider range)
152
jitter = int(np.random.normal(0, max(1, amp // 2)))
153
new_pos = int(np.clip(tgt + jitter, 0, n - 1))
154
# Need latest pos_map
155
_, pos_map = build_weights(idx)
156
idx = apply_insertion(idx, pos_map, k_plane, new_pos)
157
else:
158
# Reverse a segment
159
length = max(2, min(n, int(np.random.randint(2, min(n, int(amp) +
2)))))
160
start = np.random.randint(0, n - length + 1)
161
end = start + length
162
idx[start:end] = idx[start:end][::-1]
163
164
key = tuple(idx.tolist())
165
if key in seen:
166
continue
167
168
times_cand, cost_cand = self.sequence2time(idx)
169
27


--- Page 28 ---
170
# Repair attempt: if infeasible, perform minor adjacent swap repair
171
if not np.isfinite(cost_cand):
172
repair_attempts = 3
173
repaired = False
174
cand = idx
175
for _r in range(repair_attempts):
176
p = random.randrange(n - 1)
177
cand2 = cand.copy()
178
cand2[p], cand2[p+1] = cand2[p+1], cand2[p]
179
t2, c2 = self.sequence2time(cand2)
180
if np.isfinite(c2):
181
idx = cand2
182
times_cand , cost_cand = t2, c2
183
repaired = True
184
break
185
else:
186
cand = cand2
187
if not repaired:
188
continue
189
190
# Local improvement (small scale to control time)
191
idx_impr, times_impr, cost_impr = local_improve(idx, cost_cand,
max_trials=min(3, int(amp)))
192
if idx_impr is not None and np.isfinite(cost_impr):
193
idx, times_cand, cost_cand = idx_impr, times_impr, cost_impr
194
195
# Final feasibility check
196
if np.isfinite(cost_cand):
197
# Construct final times (in plane ID order)
198
final_times = np.zeros(n, dtype=float)
199
for pos, pid in enumerate(idx):
200
final_times[pid] = times_cand[pos]
201
exploded.append(([1 for _ in range(n)], final_times , idx))
202
seen.add(tuple(idx.tolist()))
203
generated = True
204
205
return exploded
206
207
def mutate(self, sparks: List[Tuple[List[int], List[float]]]) -> List[Tuple[List[int
], List[float]]]:
208
"""Mutation operator: additional perturbation on sparks"""
209
n = self.num_planes
210
mutated: List[Tuple[List[int], List[float]]] = []
211
if not sparks:
212
return mutated
213
214
# Target order and weight preparation
215
target_order = np.argsort(self.target_landing_times)
216
target_pos = np.empty(n, dtype=int)
217
target_pos[target_order] = np.arange(n)
218
penalties = (self.penalty_early + self.penalty_late).astype(float)
219
220
def build_weights(idx_arr: np.ndarray):
221
pos_map = np.empty(n, dtype=int)
222
pos_map[idx_arr] = np.arange(n)
223
displacement = np.abs(pos_map - target_pos)
224
w = 1.0 + (displacement + 1.0) * (penalties + 1.0)
225
s = float(np.sum(w))
28


--- Page 29 ---
226
if s <= 0:
227
return np.ones(n) / n, pos_map, displacement
228
return (w / s), pos_map, displacement
229
230
def apply_insertion(idx_arr: np.ndarray, pos_map: np.ndarray, k_plane: int,
new_pos: int):
231
cur_pos = pos_map[k_plane]
232
if new_pos == cur_pos:
233
return idx_arr
234
if new_pos < cur_pos:
235
new_idx = np.concatenate([idx_arr[:new_pos], [k_plane], idx_arr[new_pos:
cur_pos], idx_arr[cur_pos+1:]])
236
else:
237
new_idx = np.concatenate([idx_arr[:cur_pos], idx_arr[cur_pos+1:new_pos
+1], [k_plane], idx_arr[new_pos+1:]])
238
return new_idx
239
240
def local_improve(idx_arr: np.ndarray, max_trials: int = 4):
241
best_idx = idx_arr
242
best_times , best_cost = self.sequence2time(best_idx)
243
if not np.isfinite(best_cost):
244
return None, None, np.inf
245
trials = max_trials
246
while trials > 0:
247
trials -= 1
248
# Two neighborhood types: adjacent swap or small segment reversal
249
if random.random() < 0.6 and n >= 2:
250
p = random.randrange(n - 1)
251
cand = best_idx.copy()
252
cand[p], cand[p+1] = cand[p+1], cand[p]
253
else:
254
if n >= 3:
255
L = random.randrange(2, min(8, n) + 1)
256
start = random.randrange(0, n - L + 1)
257
end = start + L
258
cand = best_idx.copy()
259
cand[start:end] = cand[start:end][::-1]
260
else:
261
continue
262
t, c = self.sequence2time(cand)
263
if np.isfinite(c) and c < best_cost:
264
best_idx, best_times , best_cost = cand, t, c
265
return best_idx, best_times , best_cost
266
267
def mutate_once(base_idx: np.ndarray):
268
# Operation selection
269
w, pos_map, disp = build_weights(base_idx)
270
idx = base_idx.copy()
271
# Compound mutation steps (1-2 steps)
272
steps = 1 + int(random.random() < 0.5)
273
for _ in range(steps):
274
op = np.random.choice([0, 1, 2, 3], p=[0.35, 0.35, 0.2, 0.1])
# swap,
insertion, reverse, or-opt
275
if op == 0 and n >= 2:
276
# Weighted swap
277
i_plane = np.random.choice(n, p=w)
278
j_plane = np.random.choice(n, p=w)
279
if i_plane == j_plane:
29


--- Page 30 ---
280
j_plane = (j_plane + 1) % n
281
i_pos, j_pos = pos_map[i_plane], pos_map[j_plane]
282
idx[i_pos], idx[j_pos] = idx[j_pos], idx[i_pos]
283
# Update mapping
284
pos_map[idx[i_pos]] = i_pos
285
pos_map[idx[j_pos]] = j_pos
286
elif op == 1:
287
# Insertion toward target
288
# Prefer planes with larger deviation
289
if random.random() < 0.6:
290
k_plane = int(np.argmax(disp))
291
else:
292
k_plane = np.random.choice(n, p=w)
293
tgt = target_pos[k_plane]
294
sigma = max(1, n // 10)
295
new_pos = int(np.clip(tgt + int(np.random.normal(0, sigma)), 0, n -
1))
296
# Need latest pos_map
297
w, pos_map, disp = build_weights(idx)
298
idx = apply_insertion(idx, pos_map, k_plane, new_pos)
299
# Recompute mapping
300
w, pos_map, disp = build_weights(idx)
301
elif op == 2 and n >= 3:
302
# Segment reversal
303
L = random.randrange(2, min(8, n) + 1)
304
start = random.randrange(0, n - L + 1)
305
end = start + L
306
idx[start:end] = idx[start:end][::-1]
307
w, pos_map, disp = build_weights(idx)
308
elif op == 3:
309
# Or-opt small block move
310
l = random.choice([1, 2, 3]) if n >= 4 else 1
311
if n > l:
312
start = random.randrange(0, n - l + 1)
313
block = idx[start:start + l].copy()
314
rest = np.concatenate([idx[:start], idx[start + l:]])
315
# Target position around mean target of block
316
tgt_block = int(np.round(np.mean(target_pos[block])))
317
jitter = int(np.random.normal(0, max(1, n // 12)))
318
ins_pos = int(np.clip(tgt_block + jitter, 0, n - l))
319
new_idx = np.concatenate([rest[:ins_pos], block, rest[ins_pos:]])
320
idx = new_idx
321
w, pos_map, disp = build_weights(idx)
322
return idx
323
324
# Construct deduplication set (including original sparks)
325
seen = set()
326
for spark in sparks:
327
idx = spark[2]
328
if isinstance(idx, np.ndarray):
329
seen.add(tuple(idx.tolist()))
330
else:
331
seen.add(tuple(list(idx)))
332
333
# Target mutation count
334
target_count = max(1, int(len(sparks) * self.mutation_rate))
335
336
# Randomly select spark indices to mutate
30


--- Page 31 ---
337
indices = list(range(len(sparks)))
338
random.shuffle(indices)
339
indices = indices[:min(target_count , len(sparks))]
340
341
for k in indices:
342
_, _, base_idx = sparks[k]
343
if not isinstance(base_idx, np.ndarray):
344
base_idx = np.array(base_idx, dtype=int)
345
attempts = 6
346
success = False
347
best_pack = None
# (idx, times, cost)
348
while attempts > 0 and not success:
349
attempts -= 1
350
cand_idx = mutate_once(base_idx)
351
key = tuple(cand_idx.tolist())
352
if key in seen:
353
continue
354
times_cand, cost_cand = self.sequence2time(cand_idx)
355
if not np.isfinite(cost_cand):
356
# Repair: combine adjacent swap and guided insertion
357
repaired = False
358
repair_tries = 5
359
cur = cand_idx.copy()
360
for _r in range(repair_tries):
361
# Perform guided insertion on plane with large deviation
362
w0, pos0, disp0 = build_weights(cur)
363
plane_focus = int(np.argmax(disp0)) if random.random() < 0.7 else
np.random.choice(n, p=w0)
364
tgt = target_pos[plane_focus]
365
new_pos = int(np.clip(tgt + int(np.random.normal(0, max(1, n //
12))), 0, n - 1))
366
cur = apply_insertion(cur, pos0, plane_focus , new_pos)
367
# Add random adjacent swap
368
if n >= 2 and random.random() < 0.6:
369
p = random.randrange(n - 1)
370
cur[p], cur[p+1] = cur[p+1], cur[p]
371
t2, c2 = self.sequence2time(cur)
372
if np.isfinite(c2):
373
cand_idx, times_cand, cost_cand = cur, t2, c2
374
repaired = True
375
break
376
if not repaired:
377
continue
378
# Small-scale local improvement
379
imp_idx, imp_times, imp_cost = local_improve(cand_idx, max_trials=4)
380
if imp_idx is not None and np.isfinite(imp_cost):
381
cand_idx, times_cand , cost_cand = imp_idx, imp_times, imp_cost
382
# Record
383
best_pack = (cand_idx, times_cand, cost_cand)
384
success = True
385
386
if success and best_pack is not None and np.isfinite(best_pack[2]):
387
idx_final, times_final , _ = best_pack
388
final_times = np.zeros(n, dtype=float)
389
for pos, pid in enumerate(idx_final):
390
final_times[pid] = times_final[pos]
391
mutated.append(([1 for _ in range(n)], final_times , idx_final))
392
seen.add(tuple(idx_final.tolist()))
31


--- Page 32 ---
393
394
# Control size
395
if len(mutated) >= target_count:
396
break
397
398
return mutated
399
400
def select(self, population: List[Tuple[List[int], List[float]]],
401
sparks: List[Tuple[List[int], List[float]]],
402
mutated_sparks: List[Tuple[List[int], List[float]]]) -> List[Tuple[List[
int], List[float]]]:
403
"""Selection operator: combine candidate solutions and select optimal population"
""
404
# Combine all candidate solutions
405
candidates = population + sparks + mutated_sparks
406
if not candidates:
407
return population
408
409
# Evaluate fitness (call user-provided evaluator)
410
fitness = [self.evaluator.compute((ind[0], ind[1])) for ind in candidates]
411
# Handle infeasible or abnormal values
412
cleaned_fitness = []
413
for f in fitness:
414
if f is None or (isinstance(f, float) and not np.isfinite(f)) or (isinstance(
f, np.ndarray) and not np.isfinite(float(f))):
415
cleaned_fitness.append(float('inf'))
416
else:
417
try:
418
cleaned_fitness.append(float(f))
419
except Exception:
420
cleaned_fitness.append(float('inf'))
421
422
# Stable sorting (by fitness, index as tie-breaker for determinism)
423
sorted_indices = sorted(range(len(candidates)), key=lambda i: (cleaned_fitness[i
], i))
424
425
# Precompute sequence inverse mapping for distance measurement
426
n = self.num_planes
427
seq_keys = []
428
pos_maps = []
429
for i in range(len(candidates)):
430
idx = candidates[i][2]
431
if isinstance(idx, np.ndarray):
432
arr = idx
433
else:
434
arr = np.array(idx, dtype=int)
435
seq_keys.append(tuple(arr.tolist()))
436
pm = np.empty(n, dtype=int)
437
pm[arr] = np.arange(n)
438
pos_maps.append(pm)
439
440
# Diversity threshold (based on average position deviation)
441
diversity_threshold = max(1.0, float(n) / 12.0)
442
443
selected_idx: List[int] = []
444
seen_seq = set()
445
32


--- Page 33 ---
446
# Elite proportion: prioritize selecting several optimal solutions (avoid
premature discarding of good solutions)
447
elite_quota = max(1, int(self.fw_size * 0.6))
448
449
# First round: select elites (non-duplicate sequences)
450
for i in sorted_indices:
451
key = seq_keys[i]
452
if key in seen_seq:
453
continue
454
selected_idx.append(i)
455
seen_seq.add(key)
456
if len(selected_idx) >= elite_quota:
457
break
458
459
# Second round: select remaining individuals based on diversity (avoid too
similar to already selected)
460
if len(selected_idx) < self.fw_size:
461
for i in sorted_indices:
462
if len(selected_idx) >= self.fw_size:
463
break
464
if i in selected_idx:
465
continue
466
key = seq_keys[i]
467
if key in seen_seq:
468
continue
469
# Calculate minimum distance to selected set
470
min_dist = float('inf')
471
pm_i = pos_maps[i]
472
for j in selected_idx:
473
pm_j = pos_maps[j]
474
# Average absolute position difference
475
dist = float(np.mean(np.abs(pm_i - pm_j)))
476
if dist < min_dist:
477
min_dist = dist
478
if min_dist <= diversity_threshold:
# Early stopping
479
break
480
if min_dist >= diversity_threshold:
481
selected_idx.append(i)
482
seen_seq.add(key)
483
484
# Third round: if still insufficient , fill by fitness (allow somewhat similar but
non-duplicate sequences)
485
if len(selected_idx) < self.fw_size:
486
for i in sorted_indices:
487
if len(selected_idx) >= self.fw_size:
488
break
489
if i in selected_idx:
490
continue
491
key = seq_keys[i]
492
if key in seen_seq:
493
continue
494
selected_idx.append(i)
495
seen_seq.add(key)
496
497
# Fallback: if still insufficient (extreme case), allow duplicate sequences to
ensure size
498
if len(selected_idx) < self.fw_size:
499
for i in sorted_indices:
33


--- Page 34 ---
500
if len(selected_idx) >= self.fw_size:
501
break
502
if i not in selected_idx:
503
selected_idx.append(i)
504
505
return [candidates[i] for i in selected_idx[:self.fw_size]]
506
507
def optimize(self) -> Tuple[List[int], List[float], float]:
508
"""Main optimization process"""
509
# Initialize population (ensure all individuals are valid)
510
self.population = []
511
while len(self.population) < self.fw_size:
512
runway_assignment , times, idx = self.initialize()
513
self.population.append((runway_assignment , times, idx))
514
515
best_fitness = float('inf')
516
best_individual = None
517
start_time = time.time()
518
while not self.evaluator.stop():
519
fitness = [self.evaluator.compute((ind[0], ind[1])) for ind in self.
population]
520
current_best_idx = np.argmin(fitness)
521
current_best_fit = fitness[current_best_idx]
522
current_best_ind = self.population[current_best_idx]
523
524
# Update global best
525
if current_best_fit < best_fitness:
526
best_fitness = current_best_fit
527
best_individual = current_best_ind
528
self.silent = 0
529
else:
530
self.silent += 1
531
532
# Adaptive adjustment of explosion amplitude (better fitness, larger
amplitude)
533
max_fit = max(fitness)
534
self.amps = [
535
max(1, min(int(self.init_amps * (1.5 - f/max_fit)), self.fw_size))
536
for f in fitness
537
]
538
# Generate explosion sparks
539
all_sparks = []
540
for i in range(self.fw_size):
541
sparks = self.explode(self.population[i], self.amps[i])
542
all_sparks.extend(sparks)
543
544
# Mutation processing
545
mutated_sparks = self.mutate(all_sparks)
546
547
# Select next generation
548
self.population = self.select(self.population, all_sparks, mutated_sparks)
549
if self.silent >= 10:
550
break
551
return self.evaluator.get_best_solution(), self.evaluator.get_best_fitness()
Listing 7: Best code generated by LLM + FWA + P with GPT-5
34
