--- Page 1 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Optimization Problem Solving Can Transition to Evolutionary
Agentic Workflows
Wenhao Li 1
Bo Jin1
Mingyi Hong3
Changhong Lu2
Xiangfeng Wang2
1Tongji University
2East China Normal University
3University of Minnesota
Abstract
This position paper argues that optimization problem solving can transition
from expert-dependent to evolutionary agentic workflows. Traditional
optimization practices rely on human specialists for problem formulation,
algorithm selection, and hyperparameter tuning, creating bottlenecks that
impede industrial adoption of cutting-edge methods. We contend that an
evolutionary agentic workflow, powered by FMs and evolutionary search,
can autonomously navigate the optimization space, comprising problem,
formulation, algorithm, and hyperparameter spaces. Through case studies
in cloud resource scheduling and ADMM parameter adaptation, we demon-
strate how this approach can bridge the gap between academic innovation
and industrial implementation. Our position challenges the status quo of
human-centric optimization workflows and advocates for a more scalable,
adaptive approach to solving real-world optimization problems.
1
Introduction
Optimization methods are essential for solving real-world application problems as they
enable efficient decision-making by maximizing benefits or minimizing costs within
constraints (Luenberger et al., 1984; Boyd & Vandenberghe, 2004; Chong & ˙Zak, 2013).
These techniques are widely used across industries, such as supply chain manage-
ment (Romero Morales, 2000), manufacturing (Dimopoulos & Zalzala, 2000), and energy
systems (Dincer et al., 2017), to improve resource allocation, reduce waste, and enhance
productivity. Additionally, optimization drives innovation in fields like machine learn-
ing (Sun et al., 2019) and renewable energy (Bernal-Agust´ın & Dufo-Lopez, 2009), where it
refines models and designs sustainable solutions. With advancements in computing power
and algorithms, optimization has become a cornerstone for tackling complex challenges,
improving efficiency, and fostering progress in diverse domains.
When addressing an application problem, which is typically articulated in natural language,
the process of solving it generally involves the formulation of an optimization model
(e.g., linear programming (Dantzig, 2002), mixed-integer programming (Achterberg &
Wunderling, 2013)) that mathematically represents the problem’s objectives, constraints,
and decision variables. This model serves as a formal abstraction of the real-world scenario,
enabling the application of rigorous analytical techniques. Subsequently, an optimization
algorithm or method (e.g., simplex method (Nelder & Mead, 1965), branch and bound (Boyd
& Mattingley, 2007), gradient descent (Ruder, 2016)) must be designed or selected to solve
the formulated model, or an existing optimization solver can be employed.
Both the optimization model and the solution method often involve hyperparameters, which
are parameters that govern the structure of the model (e.g., regularization terms (Schmidt
et al., 2007)) or the behavior of the algorithm (e.g., step sizes (Bazaraa & Sherali, 1981),
convergence criteria (Greenhalgh & Marshall, 2000)). These hyperparameters require careful
tuning to ensure the model’s accuracy and the algorithm’s efficiency. Ultimately, through
this structured approach, an optimal or near-optimal solution to the problem can be derived,
providing actionable insights or decisions that align with the objectives. This systematic
process underscores the interplay between problem formulation, algorithmic design, and
parameter optimization in achieving practical solutions to real-world challenges.
1
arXiv:2505.04354v1  [math.OC]  7 May 2025


--- Page 2 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Unfortunately, a noticeable gap exists between how optimization technologies are developed
in academic research and how they are implemented in industrial practice (Bixby, 2002;
Chen et al., 2023b). While academia often focuses on advancing theoretical frameworks
and pushing algorithmic performance under idealized conditions, industry grapples with
complex real-world constraints and legacy systems (Reisman & Kirschnick, 1994; Ormerod
& Kiossis, 1997; Ormerod, 2002). Many state-of-the-art methods proposed in research
papers struggle with practical deployment due to computational scalability, implementation
complexity, or incompatibility with existing infrastructure (Bohanec & Bratko, 1994; Ibanez
et al., 2018; Sun et al., 2022). Conversely, industrial practitioners frequently rely on outdated,
well-understood techniques because of concerns about reliability, maintainability, and the
scarcity of specialized expertise needed to transfer academic insights into production (Rossit
et al., 2019; Shin, 2021).
This disconnect reflects deeper issues: Academic research typically strives for mathematical
elegance and asymptotic performance guarantees, whereas industry emphasizes robust,
maintainable solutions that meet rigid operational requirements (Oliveira et al., 2016).
Bridging this gap has historically fallen to a small pool of academic experts, who must
translate theoretical advances into workable solutions, creating bottlenecks that limit the
scale and speed at which cutting-edge optimization can be adopted (Van Donselaar et al.,
2010). Below, we highlight four specific but interconnected challenges that stem from
this over-reliance on human expertise, and explain why a new, more agentic workflow is
urgently needed:
Exclusive Reliance on Specialists: Blind Spots in Real-World Optimization. Industrial
problem formulations—and subsequent choices of algorithms and hyperparameter set-
tings—often hinge on a small number of highly specialized individuals. While these experts
can produce effective outcomes, their limited availability creates severe bottlenecks, and
their subjective outlook can lead to overlooked use cases. Promising solutions remain
theoretically trapped, seldom generalized, or rigorously tested outside of niche applications.
Fragmented Innovation: When Academic Timelines Fail Industrial Urgency. The research
community primarily measures success through theoretical breakthroughs (e.g., new con-
vergence bounds or better worst-case complexity), which may not translate cleanly into
industrial viability. This pace of academic evolution is ill-equipped to match rapid industrial
changes in data, processes, and competitive requirements (Simchi-Levi, 2014). As a result,
companies struggle to adopt new methods that are seemingly out of sync with pressing
operational realities, deepening the divide between theoretical potential and everyday
practicality.
Hyperparameter Volatility: The Achilles’ Heel of Practical Adoption. Misconfigured
hyperparameters can undo many powerful optimization algorithms. Even slight deviations
in learning rates, population sizes, or other settings can derail performance. Organizations
without streamlined mechanisms for experimentation and automated tuning face tedious
trial-and-error, often leading them to abandon novel algorithms in favor of stable, if sub-
optimal, legacy solutions. This hyperparameter fragility deters the very innovation that
academic research strives to promote.
The Engineering Gap: Why Cutting-Edge Methods Remain Stuck on Paper. Even when
a promising academic algorithm exists, translating it into a reliable and resource-efficient
industrial system can be prohibitively complex. Many breakthroughs hinge on specialized
hardware, massive datasets, or pristine environments—conditions rarely found in produc-
tion. Consequently, potential benefits remain unrealized: Companies continue relying on
suboptimal workflows, while the latest academic advances gather dust in journals, seldom
validated at scale.
These challenges illuminate how heavily modern optimization practice depends on a tight
bottleneck of expert knowledge–one that struggles to keep up with dynamically shifting
requirements and can stifle radical breakthroughs. This paper contends that an “evo-
lutionary agentic workflow,” underpinned by foundation models (FMs), is uniquely
suited to surmount these obstacles in ways that conventional optimization pipelines
cannot. Rather than merely transferring a trendy technology from one domain to another,
2


--- Page 3 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Optimization Space
Mathematician
Trial
Observe
Foundation agent
Evolution
Observe
Optimization Space
Select
Paradigm Shifts
Figure 1: Comparative frameworks in optimization problem solving: human expertise and
evolutionary agentic workflow.
we argue that specific capabilities of FMs—including broad-domain knowledge integration,
context-sensitive parsing of real-world constraints, and creative solution generation—align
naturally with the evolving nature of industrial optimization problems.
FMs can parse incomplete or ambiguous descriptions of real-world challenges and translate
them into coherent algorithmic or formulation strategies, drawing on extensive corpora
of text, code, and domain data. Concurrently, evolutionary search mechanisms (Yu & Gen,
2010; Zhou et al., 2011; Wu et al., 2024) systematically explore vast spaces of potential
configurations, iteratively testing and refining model structures and hyperparameters. Such
a workflow confronts core barriers in optimization because:
(a) Broad-Domain Generalization: FMs cover diverse operational scenarios (e.g., supply
chains, scheduling, manufacturing), bridging the domain fragmentation often faced
when applying optimization theory to real-world constraints.
(b) Iterative Refinement: Evolutionary loops break away from one-shot human designs;
they continuously discover new approaches, adapt parameters, and update problem
formulations based on empirical feedback.
(c) Creative Exploration vs. Rigorous Checking: Although large models may hallucinate,
sometimes proposing ideas that defy classical analysis, these “illusions” can seed
genuinely novel heuristics if vetted by reasoning modules (e.g., OpenAI o1, DeepSeek-R1)
or symbolic engines.
(d) Dynamic Adaptation to Evolving Data: Industrial realities shift rapidly, and FMs
can swiftly reinterpret data, adapt constraints, and recommend altered strategies,
mitigating reliance on static scripts.
Beyond mere generation of text or code, we leverage specialized reasoning sub-components
to filter, refine, and logically validate proposals. This reduces the risk that creative leaps
devolve into mathematically unsound or operationally infeasible solutions. In fact, the
agentic dimension arises precisely because FMs alone, while rich in knowledge, do not
inherently manage the end-to-end engineering pipeline: reasoning modules guide verification
and symbolic checks, and evolutionary algorithms orchestrate iterative solution refinement.
Together, these layers establish a feedback loop that continuously improves upon the search
for new optimization ideas and the rigorous pruning of false leads. Hence, we do not simply
graft a AI paradigm onto optimization; we exploit FMs’ specific, complementary strengths
and evolutionary computing to tackle the persistent gaps identified above.
To arrive at this position, we introduce an optimization space as the composition of (i) problem
spaces, (ii) optimization formulation spaces, (iii) algorithm spaces, and (iv) hyperparameter
spaces. This framework illuminates the essential questions of real-world optimization:
“which problem formulation is appropriate?”, “which algorithmic strategies are viable?”, and “how
should hyperparameters be tuned?” Expert practitioners typically answer these questions
leveraging domain knowledge, creating precisely the human bottlenecks we aim to alleviate.
We then propose anchoring agentic workflow (Xi et al., 2023; Cheng et al., 2024) in heuristic
search, particularly via evolutionary algorithms (Yu & Gen, 2010; Zhou et al., 2011; Wu
et al., 2024) that mimic how human experts iteratively refine solutions in complex optimiza-
tion landscapes. Evolutionary agentic workflow orchestrates this search by retaining and
updating a dynamic memory of attempts (e.g., prior configurations and partial solutions),
3


--- Page 4 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
invoking specialized optimization tools (e.g., solvers) when needed, formulating plans for
exploring or exploiting promising solution areas, and taking concrete actions to modify
the current pipeline. This framework creates a closed feedback loop: The agent’s evolv-
ing understanding feeds back into subsequent search steps, enabling it to autonomously
discover new algorithmic components, adapt hyperparameters, and innovate on problem
formulations with minimal human intervention.
Moreover, we illustrate this evolutionary agentic workflow with two real-world case studies.
In the first, the agent discovers novel heuristics for cloud resource scheduling—adjusting
strategies to accommodate shifting workload patterns. In the second, it designs an adaptive
step-size mechanism for ADMM (Alternating Direction Method of Multipliers), ensuring
that the convergence properties remain stable. At the same time, performance is tuned to
dynamic industrial conditions. Both studies prove that our hybrid of large language models
and evolutionary search can realize meaningful gains in practical optimization tasks. Finally,
we address the current limitations of the agentic framework, particularly its lack of a built-in
mechanism for theoretical verification and high inference cost.
2
Optimization Space
To systematically address the challenges outlined above and establish a framework for
evolutionary agentic optimization workflows, we first need to formally characterize the
space of optimization problems and their solution approaches. This formalization will
serve as the foundation for understanding how foundation agents can navigate the complex
landscape of real-world optimization tasks. Formally, we can define an optimization space,
which can be denoted as
O := P ⊗F ⊗A ⊗H,
(1)
where P denotes the problem space, which contains the natural language or multi-modal de-
scription of application problems; F denotes the optimization formulation space, where each
formulation can be represented using LATEX codes or other data structures (like an adjacency
matrix for graph issues); A denotes the algorithm space, for instance, the heuristic methods
for scheduling or planning, the gradient-type methods for continuous optimization, and the
branch-and-bound techniques for mixed integer programming (MIP). Each algorithm can
also be represented by code without restricting the programming language. H denotes the
hyperparameter space, which contains all the hyperparameters in the formulation and the
algorithm, like the step-size (learning rate) and the regularization coefficient.
Each subspace can be a singleton. For instance, we can design or search efficient algorithms
for an optimization problem with a specific formulation like linear programming (LP),
although the data can be freely changed. In this case, the optimization formulation space
contains only one specific formulation. However, for the general case, all these sub-spaces
can be an infinite-dimensional functional space. Solving an optimization problem transforms
into searching for the optimal solution in space O or the optimal combination of solutions
in sub-spaces, respectively.
To illustrate how this formula captures the challenges of specialist dependency and hyperpa-
rameter sensitivity in real-world optimization, we examine two representative cases: cloud
computing scheduling and distributed optimization. These examples, spanning discrete
and continuous domains, will demonstrate why navigating the optimization space requires
a more automated, agentic approach.
Cloud Computing Scheduling. In cloud computing, scheduling plays the key role, while a
better scheduling policy can improve user experience and significantly save on purchasing
computing resources (Pietri & Sakellariou, 2016). Given a pool of computing resources
that includes CPU, memory, GPU, etc., cloud computing providers aim to satisfy user
computing requests through scheduling methods. A scheduling problem pschedule ∈Pschedule
is determined by the state of the resource pool sres and the sequence of requests rreq. The
scheduling problem pschedule is usually modeled as an online vector bin-packing problem,
which can be represented by Bin-Packing. Heuristic methods (like best-fit or first-fit) are
popularly designed to solve the online vector bin-packing model (Bays, 1977). Furthermore,
combinatorial optimization (Cˆot´e et al., 2021) and machine learning (Sheng et al., 2022) are
4


--- Page 5 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
also employed to solve this problem. The algorithm space can be denoted as
Aschedule :=

Heuristic, CO, ML, etc
	
.
Both in modeling and algorithm-design, there are some hyperparameters that need to be set,
which can be denoted as Hschedule. Overall, following (1), solving the scheduling problem in
cloud computing can be denoted as
O := Pschedule ⊗Bin-Packing ⊗Aschedule ⊗Hschedule.
(2)
The challenge of navigating this optimization space lies in the unique characteristics of
cloud workloads. For instance, when handling mixed CPU-GPU workloads, traditional bin-
packing heuristics often fail to capture the complex resource dependencies and interference
patterns between co-located tasks (Wolke et al., 2015). While machine learning approaches
can potentially learn these patterns (Jiang et al., 2021; Sheng et al., 2022), they require careful
formulation of the state space (e.g., whether to include historical resource utilization or job
queue information) and reward signals (e.g., balancing immediate resource efficiency versus
long-term cluster stability). The hyperparameter space further expands when considering
practical constraints like power consumption limits and network topology, making manual
tuning increasingly intractable.
Distributed Optimization. ADMM (Boyd et al., 2011) has achieved significant success
in distributed applications (Yang et al., 2022). The classical ADMM algorithm is typically
designed to solve the following structured convex optimization problems (Boyd et al., 2011):
min
x∈Rn,z∈Rm f (x) + g(z),
s.t.
Ax + Bz = c,
(3)
where f and g are both proper, convex, and closed functions; A, B and c establish the linear
constraint. A variety of optimization problems in machine learning Chang et al. (2020),
statistics Boyd et al. (2011), and signal processing Hong et al. (2015) can be formulated in
the form of (3), and the application problem space can be denoted as Padmm. Besides those
hyperparameters in function f and g, there is a typical hyperparameter in ADMM method
which is the penalty parameter in augmented Lagrangian function (usually denoted as β).
In practice, this parameter β is sensitive and usually difficult to choose, as a result some
self-adaptive schemes (He et al., 2016) are proposed to dynamically tune β. Overall, solving
the structured optimization problem by ADMM can be summerized in the framework of
(1), i.e.,
O := Padmm ⊗{(3)} ⊗ADMM ⊗{β} .
(4)
The sensitivity to β in ADMM reflects a deeper theoretical challenge: the penalty parameter
affects both convergence speed and solution quality, but its optimal value depends on
problem properties that are typically unknown a priori, such as the condition number of
ATA and the Lipschitz constants of f and g. While existing adaptive schemes like residual
balancing (Wohlberg, 2017) provide theoretical guarantees, they often perform poorly on
ill-conditioned problems or when the objective functions have dramatically different scales.
This suggests the need for more sophisticated adaptation strategies that can incorporate
problem structure and runtime behavior.
3
Evolutionary Agentic Workflow
To effectively navigate the optimization space O, we propose a novel framework that
combines the reasoning capabilities of foundation agents with the systematic exploration
power of evolutionary methods. Our framework consists of three key components: (1)
foundation agents that leverage FMs for knowledge-driven optimization, (2) evolutionary
methods that enable structured exploration of the solution space, and (3) an integrated
evolutionary agentic workflow that orchestrates their interaction.
The foundation agents serve as intelligent guides in the optimization process, utilizing their
broad knowledge base to make informed decisions about problem formulation, algorithm
selection, and hyperparameter tuning. Meanwhile, evolutionary methods provide a sys-
tematic approach to explore and refine solutions, particularly valuable when dealing with
5


--- Page 6 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Design an optimal transportation scheme between m supply centers and n demand points, where supply center i has capacity ai and demand point j requires bj units. The
unit shipping cost from i to j is cij. The goal is to minimize total transportation cost while satisfying all supply and demand constraints.
min ∑∑cij xij, s.t. ∑xij = ai,
∑xij = bj, xij ≥ 0
min cost flow, sources(ai) →
sinks(bj), edge cost: cij
min ∑∑cij yij min(ai,bj), s.t.
∑yij = 1, ∑yij = 1, yij ∈ {0,1}
min ∑∑cij zij, s.t. ∑zij ≥ 1, 
zij ∈ {0,1}
Barrier method with parameter μ > 0, min
∑∑cij xij - μ∑log(xij), μ → 0 gradually
Step size: α ∈ (0,1)
Momentum factor: β ∈ [0,1), Learning rate: γ
∈ (0,1), Mini-batch size: B
Decay rate: λ
Penalty parameter: ρ > 0, Update rule: ρk+1 =
βρk, β > 1, Dual step size: η ∈ (0,1)
Stopping tolerance: ε
LP Model
Network Flow
Assignment Variant
Set Cover
Interior Point Method
Augmented Lagrangian
Proximal Gradient
ρk+1 = {γ1ρk,if ||g(x)||k > η||g(x)||k-1；ρk, if
τ||g(x)||k ≤ ||g(x)||k-1 ≤ ||g(x)||k；γ2ρk,if
||g(x)||k < τ||g(x)||k-1}，γ1 > 1, γ2 < 1, τ ∈ (0,1)
Merit Function:φ(ρ,η) = ||g(x)||² + ||∇L||²；
Update: ρk+1 = ρk * exp(α * φk/φk-1)，ηk+1 = η0 * (φk/
φ0)^(-θ)，α > 0, θ ∈ (0,1)
Backtracking Rule:ηk = βηk-1，if ||g(x)||k >
σ||g(x)||k-1，β ∈ (0,1), σ ∈ (0,1)
Penalty Parameter
Dual Step Size
Combined Strategy
Optimization Formulation
Algorithmic Design
Hyperparameter Secection
Evaluation
Evolutionary Strategy
Figure 2: Automate optimization formulation, algorithmic design and hyperparameter
selection for the transportation problem with evolutionary agentic workflow.
large-scale or complex optimization problems where exhaustive search is impractical. The
synergy between these components creates a powerful framework that balances exploitation
of existing knowledge with exploration of novel solutions, as shown in Figure 2.
3.1
Foundation Agent Architecture
We now describe the foundation agent (Liu et al., 2024e), which comprises 4 interlinked
modules: Memory, Reasoning, World Modeling, and Action. This design draws on the logic
established in our introduction, where we emphasized the synergy between creative explo-
ration and rigorous checking. Specifically, the reasoning module is tasked with maintaining
mathematical and logical integrity, preventing the overall framework from being derailed
by spurious model outputs or infeasible optimization proposals.
3.1.1
Memory Module
The memory module enables foundation agents to store and retrieve knowledge and interac-
tion histories that guide subsequent reasoning steps. Similar to human memory (Izquierdo
et al., 1999), it comprises: (1) short-term memory to capture the most recent context (such as
the immediate conversation tokens or the latest hyperparameter guesses), and (2) long-term
memory to maintain cumulative encounters and insights gained across multiple optimization
runs or experiments (Wang et al., 2024). Because the memory module can recall successful
solution patterns, it helps the agent refine strategies based on previous attempts—a crucial
mechanism for avoiding repeated mistakes (Park et al., 2023; Shinn et al., 2024). For instance,
if a particular linear solver consistently fails on specific constraints, the memory module can
record this outcome, warning the agent against reusing that solver without modification.
3.1.2
Reasoning Module
While FMs excel at wide-ranging text or code generation, they can inadvertently produce
mathematically unsound or incomplete solutions, often called “hallucinations.” In order
to reconcile creative exploration with rigorous checking, we introduce a dedicated reasoning
module (implemented by large reasoning model (Li et al., 2025d; Xu et al., 2025; Zhou
et al., 2025), e.g., OpenAI-o1 (OpenAI, 2024) or DeepSeek-R1 (Guo et al., 2025)) that enhances
chain-of-thoughts (CoT) depth and quality through the following technical route:
(1) Constructing High-Quality CoT Data for Optimization. Unlike general-purpose tasks,
real-world optimization often has complex constraints, domain-specific feasibility re-
quirements, or shifting objectives. We compile CoTt datasets that reflect these subtleties:
intermediate constraint checking, partial solution tracking, and sub-problem decomposi-
tion. Such data directly encodes correct final solutions and the reasoning steps necessary
to confirm feasibility or assess trade-offs.
(2) Domain-Focused Supervised Fine-Tuning (SFT). We then fine-tune the base model on
these specialized reasoning sequences, ensuring that it internalizes formal optimization
logic (integer feasibility, objective bounding, dual formulation consistency, etc.). This
6


--- Page 7 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
fosters an informed CoT that can avoid naive heuristics and systematically explore
realistic scenarios, aligning with the rigorous checking agenda defined in our introduction.
(3) Rule-Based Reward and Large-Scale Reinforcement Learning. Finally, a rule-based
reward mechanism evaluates each proposed CoTt: solutions that violate capacity con-
straints, fail integer feasibility, or produce inconsistent objective values are penalized,
while improved or pragmatically validated solutions are rewarded. We then apply large-
scale reinforcement learning to refine the model iteratively, boosting sequences that
demonstrate methodical problem-solving and reducing reliance on ad hoc reasoning
patterns. Over successive cycles, the reasoning module converges toward producing
disciplined, logically consistent solution paths that nonetheless retain an element of
creativity in exploring new formulations.
This reasoning framework is especially critical for large-scale optimization tasks that admit
multiple local optima or require iterative constraint handling. By integrating CoTt data
rooted in actual optimization logic, we nurture a system adept at diagnosing and correcting
missteps early on. In practice, the reasoning module can consult external symbolic or
numeric engines to verify partial solutions, fuse those validation signals into its CoTt, and
then guide the agent’s next steps accordingly.
3.1.3
World Modeling via LLMs
Prior research (Hao et al., 2023; Lin et al., 2024a) has shown that large language models
(LLMs) can serve as formidable world models by simulating the broad dynamics of a given
system. Here, an LLM-based world model can approximate the behavior of an optimization
problem: it can hypothesize how constraints interact, estimate the cost of different solution
branches, or predict how stochastic variables might evolve under certain assumptions (Bai
et al., 2022; Ma et al., 2024a). Through CoTt (Wei et al., 2022), Tree-of-Thought (Yao et al.,
2024b), or related paradigms, an LLM can decompose a high-dimensional problem into
manageable sub-problems (Chu et al., 2023) and propose candidate pathways. The ReAct
framework (Yao et al., 2022) further equips agents with introspective checks to evaluate
whether a reasoning path is consistent or sufficiently grounded. These generative and
introspective aspects can be improved with environmental feedback (Yao et al., 2022; Huang
et al., 2022; Wang et al., 2023; 2024; Li et al., 2025c), FM-based critics (Madaan et al., 2024;
Chan et al., 2024; Shinn et al., 2024), and human-in-the-loop guidance (Huang et al., 2022),
complements the module’s latent knowledge.
3.1.4
Action Module
Finally, the action module translates agent strategies into executable operations, bridging
high-level plans and real implementation. This may include the selection of specific problem
formulations (linear vs. mixed-integer), algorithm choices (gradient descent vs. branch-and-
bound), and hyperparameter tuning (learning rates, tolerance levels, solver parameters).
Moreover, the action space can expand as external tools and specialized knowledge bases
are integrated (Lewis et al., 2020; Schick et al., 2023; Ge et al., 2023; Shen et al., 2024). By
tapping into such resources, the action module can directly interface with modeling libraries
or solver APIs, atlasing the current solution approach or pivoting to alternative methods if
performance plateaus.
Holistic Synergy in an Evolutionary Agentic Workflow.
When these modules are combined within an evolutionary agentic workflow, the agent
alternates between exploratory variations of problem settings or parameter values and
rigorous validation by the reasoning module. Through ongoing memory updates, each
promising direction accumulates historical evidence, informing the next generation of search
steps guided by the reasoned CoTt. Thus, the architecture balances the two imperatives
highlighted in our introduction—creative exploration and rigorous verification—as a foundation
for discovering powerful, real-world, viable optimization solutions.
7


--- Page 8 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
3.2
Evolutionary Framework
While foundation agents excel at reasoning and knowledge utilization, they effectively ex-
ploring the vast optimization space O requires systematic exploration mechanisms. Recent
advances in combining LLMs with evolutionary approaches have shown promising results
in various domains. Building upon these developments, we propose a generalized evo-
lutionary framework that complements foundation agents in navigating the optimization
space O. While traditional evolutionary methods rely on random mutations and predefined
operators to generate new solutions, we propose a novel framework that leverages foun-
dation agents as the solution generator within the evolutionary process. Our evolutionary
framework incorporates three key mechanisms that guide the overall optimization process.
Distributed Population Management. We maintain multiple solution populations (islands)
that evolve independently, representing different exploration trajectories. This distributed
approach prevents premature convergence to local optima in O and provides natural
checkpoints for solution diversity. Within each island, foundation agents are called upon
to generate new solutions by formulating specific problem models, designing concrete
algorithms, or tuning particular hyperparameter combinations.
Solution Diversity Preservation. Solutions generated by foundation agents are clustered
based on their characteristic signatures in the optimization space, which could include
performance metrics, structural properties, or behavioral patterns. This clustering mech-
anism helps maintain diversity across different dimensions of O, preventing the search
from collapsing to a single solution type. The selection process balances between exploiting
high-performing solutions and exploring diverse alternatives, informing the foundation
agents about which solution characteristics to preserve or modify in subsequent generations.
Knowledge-Guided Evolution. When new solutions are needed, the evolutionary frame-
work invokes foundation agents to generate them based on the current population state.
The agents leverage their memory and world models to understand successful patterns
from existing solutions and create new variations. This creates an efficient evolutionary
cycle where high-performing solutions inform the agents’ subsequent solution generation,
while the evolutionary mechanism ensures systematic exploration.
3.3
Human-Centered Evaluation
Effective optimization requires algorithmic advancements and meaningful evaluation crite-
ria that align with human priorities and domain-specific requirements. Traditional evolu-
tionary methods often rely on predefined fitness functions that may not capture the nuanced
objectives of real-world optimization problems. Drawing inspiration from human-centered
AutoML approaches (Lindauer et al., 2024), the proposed framework incorporates eval-
uation mechanisms that explicitly account for human preferences and domain expertise.
Rather than optimizing solely for predictive performance, the evaluation considers mul-
tiple objectives, including interpretability, computational efficiency, and domain-specific
constraints. The system enables domain experts to express preferences between candidate
solutions through pairwise comparisons, effectively learning implicit utility functions that
would be difficult to formalize.
This preference-based approach (Giovanelli et al., 2024) allows the evolutionary process
to navigate toward solutions that satisfy formal metrics and tacit domain knowledge.
Additionally, the framework supports interactive refinement of the evaluation criteria
as the optimization progresses, recognizing that human stakeholders often clarify their
requirements through an iterative process of exploring the solution space. By establishing
this bidirectional feedback loop between automated search and human evaluation, the
framework can address the “exclusive reliance on specialists” challenge identified earlier,
democratizing access to optimization while preserving the crucial role of human expertise
in guiding the search toward meaningful solutions.
Remark: Complementarity with AutoML. It is important to clarify how the evolutionary
agentic workflow relates to existing AutoML frameworks. While AutoML systems excel at
efficiently searching predetermined configuration spaces with well-defined boundaries, evo-
8


--- Page 9 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
lutionary agentic workflow addresses fundamentally different challenges in optimization.
Unlike AutoML platforms that primarily focus on selecting and tuning algorithms within
fixed modeling paradigms, evolutionary agentic workflows can navigate unclear formula-
tion spaces where the very structure of the problem representation may be reconsidered.
For instance, the framework can autonomously reformulate cost functions with different
constraints or decision variables—transformations that traditionally require domain experts’
manual intervention. Additionally, while AutoML excels at algorithm selection from es-
tablished options (e.g., choosing between random forests and neural networks), it is not
designed to auto-design entirely new heuristics or derive specialized algorithmic expansions
like the ADMM variants described in our case studies.
We view evolutionary agentic workflow as complementary to, rather than competing with,
traditional AutoML. Indeed, evolutionary agentic workflows can incorporate standard HPO
(hyperparameter optimization) modules (e.g., Optuna (Akiba et al., 2019)) as components
within their iterative search process, unifying the strengths of both paradigms. This inte-
gration allows evolutionary agentic workflows to leverage the efficiency of AutoML for
well-defined subproblems while maintaining the creative exploration capabilities needed
for less bounded optimization spaces. Furthermore, the framework aligns with recent calls
for more human-centered AutoML approaches (Lindauer et al., 2024) by supporting flexible
human feedback mechanisms through our evaluation module. This allows domain experts
to provide targeted guidance at critical junctures while the system autonomously handles
repetitive low-level tasks. This balanced division of labor creates a genuinely collaborative
environment where machine creativity and human expertise contribute to discovering novel
strategies that remain undiscovered through purely automated or manual approaches.
3.4
Operational Workflow
Integrating evolutionary methods and foundation agents creates a robust optimization
framework where evolutionary search guides the overall exploration while foundation
agents serve as sophisticated solution generators. The evolutionary process begins with
an initial population of solutions, each generated by foundation agents based on their
knowledge of the problem domain. As the evolution proceeds, the framework identifies
promising solution characteristics and directs the agents to generate new solutions that
build upon these successful patterns.
Foundation agents are called upon during each iteration to perform specific tasks within
the broader evolutionary search. They analyze existing solutions to understand successful
patterns, generate new solution variations through problem reformulation or algorithm
modification, and provide quality assessments of newly generated solutions. The framework
then manages these solutions across multiple islands, maintains population diversity, and
determines which solutions should inform the next generation.
This structured workflow leverages the complementary strengths of both components: The
evolutionary framework provides systematic exploration and selection pressure, while
foundation agents contribute domain knowledge and sophisticated solution generation
capabilities. The resulting system demonstrates remarkable effectiveness in navigating com-
plex optimization landscapes, as the evolutionary process efficiently explores the solution
space. Meantime, foundation agents ensure each generated solution incorporates domain
expertise and learning from previous successes.
3.5
Generalization and Lifelong Learning
A critical consideration for agentic optimization workflows is their potential ability to
handle problems that extend beyond the foundation model’s training distribution. While
FMs demonstrate impressive zero-shot capabilities across many domains, real-world opti-
mization often involves novel constraints, emerging domains, or unprecedented problem
structures. Here, we discuss several promising mechanisms that could enhance generaliza-
tion and support continual adaptation in evolutionary agentic workflows.
9


--- Page 10 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Retrieval-Augmented Generation (RAG) represents a compelling approach to extend the
knowledge boundaries of FMs. By connecting the foundation agent to external knowledge
repositories containing domain-specific papers, technical reports, and implementation
examples, RAG could effectively enlarge the agent’s knowledge scope beyond its pre-trained
parameters. When encountering a problem with unfamiliar characteristics, such a system
could extract key features from the problem statement, query the external knowledge base
for relevant optimization techniques, and integrate retrieved information with its parametric
knowledge to propose appropriate formulations or algorithms (Lewis et al., 2020). This
hybrid approach would balance the foundation model’s general reasoning capabilities with
precise, specialized knowledge required for domain-specific optimization challenges.
For domains requiring more profound expertise, targeted supervised or reinforcement fine-
tuning could significantly enhance an agent’s ability to navigate specialized optimization
landscapes (Chen et al., 2023a; Liao et al., 2025). Even a modest number of examples
(typically 10-50 samples) might substantially improve performance on domain-specific
tasks, particularly when these examples demonstrate common constraint patterns, typical
failure modes, and their remediation, and effective problem decomposition strategies (Bai
et al., 2022; OpenAI, 2024). This approach would be particularly valuable when adapting
the workflow to new industries or technical domains where problem structures differ
substantially from standard benchmarks.
Continual (lifelong) learning mechanisms represent perhaps the most promising direction
for ensuring long-term viability of agentic optimization workflows (Zheng et al., 2025a;b).
Such mechanisms would allow the optimization agent to evolve with experience as it
encounters and solves new problems (Silver & Sutton, 2025). This capability would maintain
relevance in dynamic industrial environments where problem specifications continuously
evolve. Potential continual learning processes could include experience replay, where the
agent maintains a buffer of previously solved problems; selective parameter updates for
critical performance improvements; and meta-learning approaches, where the agent could
learn to adapt quickly to new problem classes by identifying common patterns across
different optimization tasks.
This multi-faceted approach to generalization and lifelong learning could ensure that evolu-
tionary agentic workflows remain effective even as optimization problems evolve beyond
their original specifications. Rather than providing a static solution, such a framework
would continue to adapt and improve through ongoing interactions with the optimization
environment, mirroring how human experts develop and refine their problem-solving
strategies over time.
3.6
Component-wise Optimization
While our framework proposes an integrated evolutionary approach where foundation
agents serve as solution generators, examining how foundation agents have been applied to
individual optimization components is instructive. Though not yet incorporating evolution-
ary mechanisms, current research has shown promising results in using foundation agents
for problem formulation, algorithm design, and hyperparameter tuning separately (Liu
et al., 2024c). These works provide valuable insights into the foundation agents’ capability
as solution generators and highlight the benefits of incorporating evolutionary methods.
Optimization Formulation. Recent works have demonstrated the potential of foundation
agents in converting natural language descriptions into mathematical optimization mod-
els (Zhang et al., 2019; Meadows & Freitas, 2022; Wu et al., 2022; Wasserkrug et al., 2024).
These efforts make optimization more accessible to non-experts by automating the problem
formulation process.
Several frameworks have been proposed to leverage LLMs for optimization modeling. The
NL4Opt competition (Ramamonjison et al., 2023), inspired by OptGen (Ramamonjison
et al., 2022), catalyzed significant progress in this direction, with various approaches achiev-
ing promising results (Ning et al., 2023; Gangwar & Kani, 2023). Subsequent works like
OptiMUS (AhmadiTeshnizi et al., 2023), ORLM (Tang et al., 2024), LM4OPT (Ahmed &
10


--- Page 11 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Choudhury, 2024), and MAMO (Huang et al., 2024b) have further advanced the field by
developing specialized models and techniques for optimization problem formulation.
Different approaches have been explored to enhance the formulation process. Some works
focus on decomposing the modeling into subtasks (Tsouros et al., 2023; Khot et al., 2023),
while others emphasize interactive refinement with users (Mostajabdaveh et al., 2024;
Almonacid, 2023). Various evaluation methods have been proposed, from comparing with
ground truths (Amarasinghe et al., 2023) to expert validation (Li et al., 2023; Chen et al.,
2024). Recent studies (Fan et al., 2024) have shown that while LLMs excel at textbook-level
problems, they may require iterative refinement for complex real-world scenarios.
While these works demonstrate the potential of foundation agents in problem formulation,
they primarily focus on generating single formulations rather than systematically exploring
the vast space of possible problem models. Evolutionary methods could enhance these
approaches by enabling structured exploration and progressive refinement.
Algorithmic Design. Researchers have explored two main approaches to leverage foun-
dation agents (Huang et al., 2024a). The first approach uses LLMs directly as optimization
algorithms through prompting. For instance, OPRO (Yang et al., 2024) guides LLMs to
generate solutions through in-context learning, incorporating previous solutions to en-
able iterative improvement. However, such direct approaches often face limitations when
dealing with complex problems involving large search spaces (Zhang et al., 2024), leading
researchers to explore more sophisticated methods like utilizing LLMs to generate solver
scripts (AhmadiTeshnizi et al., 2024; Huang et al., 2024b).
The second approach employs foundation agents to design optimization algorithms through
agentic workflows. Some pioneering works have already demonstrated the potential of
combining agentic workflows with evolutionary methods. FunSearch (Romera-Paredes
et al., 2024) and Evolution of Heuristics (Liu et al., 2024a) integrate LLMs with evolutionary
computation to automatically design heuristic algorithms, showing superior performance
over manual designs. Building upon this direction, works like ReEvo (Ye et al., 2024) and
AEL (Liu et al., 2023; 2024b) further enhance the evolutionary framework with reflection
mechanisms and automated algorithm design capabilities.
Various specializations within this approach have emerged, from animal-inspired meta-
heuristics (Zhong et al., 2024) to language model-based crossover operators (Meyerson
et al., 2024). Some researchers focus on population-based algorithms (Pluhacek et al., 2023),
while others explore multi-objective optimization of algorithm design (Yao et al., 2024a).
These works demonstrate that evolutionary agentic workflows can effectively navigate the
complex space of algorithm designs.
While these studies validate our position on the synergy between evolutionary methods and
foundation agents, they have focused on applying this combination to algorithmic design in
isolation, rather than integrating it into a comprehensive optimization framework.
Hyperparameter Selection. While hyperparameter optimization is crucial for optimization
algorithms, research on using foundation agents for this purpose has primarily focused
on machine learning applications rather than optimization problems. Recent works have
demonstrated promising approaches using agentic workflows for automated hyperparame-
ter tuning (Liu et al., 2024d; Zhang et al., 2023a; Mahammadli, 2024).
Despite these advances in ML, the application of foundation agents for hyperparameter
selection in optimization algorithms remains relatively unexplored. Moreover, unlike
the evolutionary approaches in algorithmic design, current hyperparameter optimization
methods using foundation agents have not yet systematically incorporated evolutionary
mechanisms to explore the hyperparameter space.
4
Case Studies
We present two case studies to validate the potential of evolutionary agentic workflows
in optimization. For the computational overhead, each workflow iteration takes about
2 minutes and totaling 200-300 rounds in agentic VM scheduling, and about 10 seconds
11


--- Page 12 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
with 15-20 total iterations in agentic ADMM step-size tuning. These computations rely
on calling external LLM APIs. Thus, local resource usage remains minimal at present.
However, we anticipate that techniques like quantization, distillation, and pruning—as well
as hardware-accelerated GPU kernels (Lange et al., 2025; Chen et al., 2025)—will reduce
runtime if models are fully deployed on-site.
4.1
Agentic Virtual Machine Scheduling
Our first case study examines algorithm design for virtual machine scheduling in cloud
computing, where we fix the problem formulation and hyperparameter settings to isolate
the algorithm design space. This represents a special case of our framework where the
optimization spaces for problem formulation and hyperparameter tuning are reduced to
singletons, allowing us to focus solely on evolving scheduling algorithms through agentic
workflows.
cpu_weight = 0.6, mem_weight = 0.4, cpu_score =
cpu_weight * (1 / (1 + np.exp(-cpu_diff))), mem_score =
mem_weight * (1 / (1 + np.exp(-
mem_diff))), efficiency_score = (cpu_score + mem_score)
/ (bin [0] + bin [1])
lookahead_score = 0, for i in
range(min_lookahead_distance , max_lookahead_distance +
1): next_item = (item [0] * i, item [1] *
i), lookahead_score = lookahead_factor *
(lookahead_score / max_lookahead_distance)
dynamic_factor = (bin [0] / (bin [0] + bin [1])) /
(item [0] / (item [0] + item [1])), adjusted_cpu_weight
= cpu_weight * dynamic_factor, adjusted_mem_weight =
mem_weight * (1 - dynamic_factor)
Online Bin-Packing
Weighted Sum
Dynamic Weight Adjustment
Lookahead Mechanism
Algorithmic Design (for dynamic facor in algorithm)
Evaluation
Evolutionary Strategy
No Hyperparameter
Figure 3: Evolutionary agentic workflow for VM scheduling.
The virtual machine scheduling aims to design a scheduler to arrange the requests received
by the proper virtual machines in the cloud computing system. As discussed in the intro-
duction, this application problem can be modeled as an online vector bin-packing problem,
which is significantly challenging to solve. The system needs to arrange the industry re-
quests as soon as possible. Heuristic methods have become the key to the online scheduling
problem. However, given a particular scheduling algorithm, it cannot always be efficient
even for the request sequence from a relatively robust scenario. This further motivates us
to evolve the scheduling algorithm scheme, especially following the agentic workflow, as
shown in Figure 3.
We have conducted some preliminary experiments. The datasets used are the traces collected
by the Huawei Cloud 1 Each VM request in the dataset needs two types of resources: CPU
cores and memory. For the baseline selection, we compare with a traditional heuristic
method BestFit, which picks the server with the highest current allocation rate, aiming for
an optimal use of resources. We directly implement the procedure on the scenario with 50
virtual machines, with the Deepseek coder LLM model 2 One A100 (80G) GPU is employed
for training, with 300 training epochs and about 7 to 8 hours. Furthermore, more scenarios
with virtual machine size 30, 100, 150 and 200 are tested to show not only efficiency but
also generalization ability. The scheduling length is used to evaluate the performance,
which is defined as the total number of VMs processed by the cluster over a given capacity.
The longer scheduling length indicates a more effective algorithm, reflecting the ability to
1https://github.com/huaweicloud/VM-placement-dataset.
2https://deepseekcoder.github.io.
12


--- Page 13 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
manage and process more tasks over time. In Table 4.1, we can find that the new algorithm
performs significantly better than BestFit on the training scenario. Furthermore, the new
algorithm can beat BestFit if we directly implement it in other scenarios without training.
Scenarios
VM Size
BestFit
NewAlgorithm
Train
50
1386.8
1526.1
Test
30
566.9
572.6
Test
100
3811.5
3874.9
Test
150
6256.2
6318.2
Test
200
8366.5
8447.9
Table 1: Comparision between the NewAlgorithm and BestFit.
Figure 4: The perforcement of the discovered algorithm during traing on scenario with VM
size 50.
We also demonstrate the evolution curve of algorithmic capabilities during the training
process. It can be seen in Figure 4 that the evolutionary generation algorithm is fully
automated and its capabilities are progressively enhanced, significantly improving the
efficiency of algorithm design.
4.2
Agentic ADMM Step-Size Tuning
Our second case study focuses on hyperparameter tuning for the ADMM, where we con-
sider a fixed problem formulation and algorithm design. This represents another special
case of our framework, where the optimization spaces for problem formulation and al-
gorithm design are singletons, allowing us to concentrate on evolving hyperparameter
selection strategies through agentic workflows. This fascinating case demonstrates how our
framework can enhance even well-established optimization algorithms through adaptive
parameter tuning.
The ADMM has shown significant success in various optimization problems in ML, statistics,
and signal processing. However, its performance is sensitive to the selection of the hyperpa-
rameter introduced in the augmented Lagrangian function (typically denoted as β), which
is usually fixed in conventional implementations. As discussed in the introduction section,
employing ADMM to solve a structured convex optimization problem can be formulated in
a unified framework as (4).
Recall the structured convex optimization problem (3), while the iteration scheme of the
classical ADMM method is denoted as (the k-th iteration),





xk
= arg minx L(x, zk−1, λk−1)
zk
= arg minz L(xk, z, λk−1)
λk
= λk−1 −β

Axk + Bzk −c

,
(5)
13


--- Page 14 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
r_norm = np.sqrt(np.linalg.norm(dY1) ** 2 +
np.linalg.norm(dY2) ** 2)，s_norm = mu *
np.sqrt(np.linalg.norm(x - xk) ** 2 + np.linalg.norm(Z
- Zk) ** 2)，if r_norm > tau_incr * s_norm: rho *=
tau_incr，Y1 /= tau_incr，Y2 /= tau_incr；elif s_norm >
tau_decr * r_norm: rho /= tau_decr，Y1 *= tau_decr，Y2
*= tau_decr
r_norm = √(||dY1||² + ||dY2||²),s_norm = μ√(||x-xk||² +
||Z-Zk||²),r_ratio = r_norm/r_norm₀,s_ratio =
s_norm/s_norm₀,β_update = {β * (1 + γ₁r_ratio),  if
r_norm/s_norm > mean(hist_ratio) + σ,β * (1 -
γ₂s_ratio),  if s_norm/r_norm > mean(hist_ratio) +
σ;β,otherwise},hist_ratio.update(r_norm/s_norm),Y₁,₂ *=
β₀/β_update
r_norm = √(||dY1||² + ||dY2||²),s_norm = μ√(||x-xk||² +
||Z-Zk||²), h_norm = ||∇L||,β_update = {
    β * (1 + α₁), if r_norm > τ₁ * s_norm and h_norm >
ε，β * (1 - α₂), if s_norm > τ₂ * r_norm，β * exp(-λ *
h_norm/h_norm₀), otherwise} Y₁,₂ *= β₀/β_update
Trace Lasso Problem
History-aware Adaptive Rule
Hyperparameter selection for ADMM (step-size)
Evaluation
Evolutionary Strategy
ADMM method
Threshold-based Reciprocal Adaptive Rule
Momentum-based Adaptive Rule
Figure 5: Evolutionary agentic workflow for ADMM.
where
L(x, z, λ)
= f (x) + g(z) −λT (Ax + Bz −c)
+ β
2 ∥Ax + Bz −c∥2
2 ,
(6)
where λ denotes the dual variable (or Lagrange multiplier) concerning the linear constraint,
and β denotes the penalty parameter. In general, the parameter β is set to be a constant.
As a representative primal-dual method, the computational efficiency or convergence speed
is closely related not only to primal variables x and z but the dual variable λ. Typically,
balancing the convergence speed of the primal variable and the dual variable is natural to
guarantee better computational efficiency. As in He et al. (2000), we define the primal pk
and dual residual dk in the k-th iteration as follows:
(
pk
= ρATB

zk −zk−1
,
dk
= Axk + Bzk −c.
(7)
As highlighted in many previous works He et al. (2000); Xu et al. (2017b;a), the computational
efficiency or convergence speed of ADMM is highly sensitive to the choice of the parameter
β. As an initial exploration that differs from the fixed constant parameter setting, He et al.
(2000) novelly proposed a self-adaptive scheme to adjust dynamically β by balancing the
primal residua pk and dual residual dk. In the (k + 1)-th iteration, the parameter βk+1 is
determined by the relationship between the primal residua pk and dual residual dk. As a
result, the parameter β can be formalized as a function
βk+1 = h (pk, dk) .
For instance, He et al. (2000) introduced an expert-designed nonlinear function, i.e.,
βk+1 = h (pk, dk) =
( ηβk,
∥dk∥2 > µ||pk||2;
βk/η,
||pk||2 > µ||dk||2;
βk,
otherwise,
(8)
where µ > 1 and η > 1 are hyperparameters. It has been proven in many application
problems that the above self-adaptive parameter tuning scheme performs much better than
the constant parameter setting. However, we cannot conclude that the scheme (8) is the
“optimal” function h. In other words, this scheme should be problem-driven, and general
14


--- Page 15 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
schemes designed by experts may not necessarily perform well on specific problems. This
provides us with greater possibilities to search for better strategies.
We can establish a novel algorithm innovation framework following the evolutionary agentic
workflow, which uses large language models (LLMs) to explore self-adaptive strategies for
the parameter automatically β, as shown in Figure 5. We can employ a pre-trained LLM
for generating and searching the self-adaptive parameter scheme instead of designing the
tuning scheme by experts as (8).
To prove the possibility and efficiency of the proposed framework, we test on a Library
of ADMM for sparse and low-rank optimization, called LibADMM 3 All the problems in
LibADMM can be calculated using the classical ADMM.
The new hyperparameter tuning criteria obtained through the agent workflow have led to
the construction of an enhanced ADMM method, named NewADMM. We first demonstrate
the NewADMM method’s computational capabilities by training and testing on eight
problems from LibADMM. As shown in Table 4.2, the results reveal that compared to the
ADMM-expert approach, the NewADMM method requires significantly fewer iterations to
achieve the same computational accuracy.
Problem
L1
Elasticnet
L1R
ElasticnetR
ADMM-expert
227
229
180
250
NewADMM
60
12
179
24
Problem
RPCA
LRMC
LRR
RMSC
ADMM-expert
94
83
198
116
NewADMM
20
122
3
24
Table 2: Iterative number comparison on LibADMM applications to abtain the same toler-
ence.
Further, in Table 4.2, we test the generalization capability of the new hyperparameter tuning
criteria. Different from the results in Table 4.2, we specifically designed the hyperparameter
tuning criteria by optimizing them on the L1 and Elasticnet problems within the LibADMM
application suite, then directly transferred these criteria to other issues in LibADMM without
further fine-tuning. The results demonstrate that when applying the criteria derived from
the L1 and Elasticnet problems to other tasks, the same computational accuracy can still be
achieved with significantly fewer iteration steps. This further validates the effectiveness of
the agent workflow technology in developing robust hyperparameter tuning criteria.
Problem
ADMM-expert
NewADMM
L1
Elasticnet
235
45
GroupL1
185
39
L1R
187
35
ElasticnetR
255
52
TraceLasso
92
43
GroupL1R
187
40
Elasticnet
L1
237
36
GroupL1
185
34
L1R
187
30
ElasticnetR
255
154
TraceLasso
92
52
GroupL1R
187
34
Table 3: Performance of generalization.
3https://github.com/canyilu/LibADMM.
15


--- Page 16 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
5
Limitations
While the proposed evolutionary agentic workflow shows promise in revolutionizing
optimization practice, there remain two key challenges with promising solutions on the
horizon. First, foundation agents lack built-in mechanisms for theoretical verification. In
optimization research, theoretical guarantees such as convergence properties and optimality
conditions are fundamental requirements, not optional features. When agents propose
novel optimization strategies through evolution, their mathematical soundness remains
unverified, potentially limiting academic adoption.
Second, the high inference cost of FMs presents a significant barrier to industrial adoption.
While the proposed framework aims to bridge the academic-industrial gap by lowering the
expertise barrier, the computational overhead of repeated agent interactions may make it
prohibitively expensive for practical deployment, especially in industrial settings where
cost-efficiency is crucial.
Third, scalability to large-scale industrial optimization problems represents a significant
practical challenge. While the framework offers several advantages, the computational
demands of evaluating solutions for huge problem instances could become prohibitive
without appropriate infrastructure support.
For theoretical verification, integrating code FMs (Roziere et al., 2023; Jiang et al., 2024b)
with automated proof assistants (De Moura et al., 2015; Moura & Ullrich, 2021; Song et al.,
2024) could enable automated verification of mathematical properties. Efforts in formalizing
block-partitioned methods, KKT conditions, and subdifferential-based convergence (Li et al.,
2025a;b) suggest automatically verifying ADMM and other iterative schemes. Future work
involves integrating Lean4 directly into the proposed agentic workflow, enabling proofs
and generation of optimization code in a single loop.
For inference cost, advances in model quantization (Lin et al., 2024b; Egashira et al., 2024),
distillation (Xu et al., 2024), and small FMs (Schick & Sch¨utze, 2020; Van Nguyen et al., 2024)
offer promising solutions for cost-effective industrial deployment.
Regarding scalability challenges, several promising approaches could address these con-
cerns. The proposed workflow is inherently heuristic-focused, optimizing approaches not
restricted by problem size. The primary bottleneck emerges when validating solutions
for huge instances, which could be addressed through high-performance simulation or
distributed HPC frameworks. Furthermore, bottom-up operator optimization—automating
kernel generation and leveraging specialized accelerators (e.g., GPU or HPC cloud re-
sources)—could drastically expedite the evaluation phase for large-scale tasks. This ap-
proach parallels ongoing research efforts where agentic workflows have generated op-
timized CUDA kernels to accelerate large-model inference, and similar speedups could
benefit large-scale industrial optimization (Lange et al., 2025; Chen et al., 2025).
Addressing these limitations would move us toward a unified framework that maintains
theoretical rigor while enabling practical deployment, ultimately making advanced opti-
mization techniques more accessible to practitioners.
6
Alternative Views
Key components of our framework face substantive challenges from existing research.
Studies on LLMs’ mathematical capabilities suggest fundamental limitations in complex
reasoning. Recent work has demonstrated that these models often fail at multi-step mathe-
matical derivations and struggle to maintain logical consistency in complex optimization
problems (Mirzadeh et al., 2024; Yadkori et al., 2024; Kambhampati, 2024; Valmeekam et al.,
2022; 2024; Boix-Adser`a et al., 2024; Jiang et al., 2024a), raising concerns about their reliability
in algorithm design and parameter tuning.
The evolutionary aspect of our approach faces more fundamental criticisms. Traditional
evolutionary computation methods suffer from inherent limitations in rigorous performance
analysis (Kudela, 2022; 2023). Many newly proposed methods show superior performance
16


--- Page 17 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
primarily due to implicit biases in benchmark functions, such as having optima at the center
of the feasible set. Furthermore, when tested on more challenging scenarios like real-world
applications, many evolutionary methods perform no better than classical approaches or
even random search (Wolpert & Macready, 1997; Araujo, 2007; Woldesenbet & Yen, 2009;
Yampolskiy, 2018; Velasco et al., 2024).
Recent advances suggest these challenges can be effectively addressed. LLM trained via
large-scale reinforcement learning has shown enhanced mathematical reasoning capabili-
ties (OpenAI, 2024; Guo et al., 2025). At the same time, the agentic workflow compensates
for evolutionary methods’ limitations by incorporating domain knowledge and efficient
solution representations through FMs. This synergy creates a more principled optimization
framework that leverages improved reasoning capabilities and structured search strategies.
7
Related Work
The automation of optimization processes has been explored from various perspectives.
Automated Machine Learning (AutoML) and Learning to Optimize (L2O) are two specific
methodologies focusing on ML tasks and optimization algorithms. Meta-optimization and
Automatic Algorithm Configuration (AAC) offer more general frameworks, addressing the
higher-level challenge of optimizing optimization processes. While these approaches have
succeeded significantly in their respective domains, they differ from evolutionary agentic
workflow in scope and methodology.
7.1
Automated Machine Learning
AutoML represents a significant step towards automating the ML pipeline (Hutter et al.,
2019; Yao et al., 2018). It primarily focuses on automating model selection, feature engineer-
ing, and hyperparameter optimization for machine learning tasks (Feurer & Hutter, 2019),
employing sophisticated search strategies such as Bayesian optimization (Snoek et al., 2012),
evolutionary algorithms (Real et al., 2019). even agentic workflow (Zhang et al., 2023b;
Hong et al., 2024; Trirat et al., 2024; Chi et al., 2024; Gu et al., 2024; Hoseini et al., 2024).
However, AutoML faces unique challenges when applied to general optimization problems.
While machine learning tasks often share common structural patterns that can be effectively
explored through predefined search spaces (Liu et al., 2018; Pham et al., 2018; Elsken et al.,
2019), optimization problems typically require more sophisticated mathematical formula-
tions and theoretical guarantees (Wolpert & Macready, 1997; Boyd & Vandenberghe, 2004).
Evolutionary agentic workflow potentially extends beyond AutoML’s fixed search space
approach by potentially leveraging FMs to synthesize new optimization strategies and
problem formulations.
7.2
Learning to Optimize
L2O attempts to automate optimization processes through end-to-end neural architec-
tures (Andrychowicz et al., 2016; Chen et al., 2022). This approach treats the optimization
algorithm as a learnable component, typically using recurrent neural networks to generate
update rules that can potentially outperform traditional optimization methods, showing
particular strength in learning highly efficient optimization strategies for specific problem
classes (Li & Malik, 2017). While L2O focuses primarily on learning the optimization algo-
rithm with limited generalization capability (Lv et al., 2017), evolutionary agentic workflow
addresses the entire optimization pipeline. Additionally, agentic workflow can integrate
existing optimization theory and expert insights through FMs, overcoming L2O’s limitation
in incorporating domain knowledge (Metz et al., 2019).
7.3
Meta-Optimization
Meta-optimization, initially developed in ML (Finn et al., 2017; Devlin et al., 2017), has
expanded to general optimization problems (Franceschi et al., 2018). This paradigm focuses
on optimizing the optimization process itself, achieving significant success in few-shot
17


--- Page 18 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
learning and transfer learning (Hospedales et al., 2021), while also showing promise in
adapting solver configurations and learning initialization strategies (Ma et al., 2024b). The
agentic framework distinguishes itself from meta-optimization in its approach to problem-
solving. While meta-optimization typically requires a predefined family of optimization
problems and focuses on learning transferable optimization strategies within this family, the
agentic framework aims to understand and formulate optimization problems from natural
language descriptions, enabling the generation of novel solution approaches rather than
just adapting existing ones.
7.4
Automatic Algorithm Configuration
Automatic algorithm configuration (AAC) has evolved from its origins in operations re-
search (Hutter et al., 2011; L´opez-Ib´a˜nez et al., 2016) to a widely adopted methodology
across multiple domains, including simulation software (Bartz-Beielstein et al., 2020), ma-
chine learning pipelines (Feurer et al., 2022), and various algorithmic frameworks (Hutter
et al., 2017; Gleixner et al., 2021). Using sophisticated search strategies like iterated racing
and model-based search, AAC has successfully tuned complex systems with numerous
interacting parameters. However, AAC’s scope is fundamentally narrower than our pro-
posed framework. While AAC excels at finding optimal configurations within a predefined
parameter space, it cannot reformulate problems or synthesize new algorithmic components.
The agentic workflow extends beyond parameter tuning to enable innovation across the
optimization pipeline, from problem formulation to algorithm design.
8
Conclusion
This paper advocates a paradigm shift in optimization problem solving through evolu-
tionary agentic workflows. While existing research has demonstrated foundation agents’
effectiveness in individual optimization components, our framework proposes their evo-
lutionary integration into a comprehensive system. Although we acknowledge current
verification and computational overhead limitations, recent advances suggest these chal-
lenges can be systematically addressed. Our framework combines FMs’ proven capabilities
with evolutionary methods’ structured exploration, representing a crucial step in bridging
the gap between academic innovation and industrial practice.
References
Achterberg, T. and Wunderling, R. Mixed integer programming: Analyzing 12 years of
progress. In Facets of Combinatorial Optimization: Festschrift for Martin Gr¨otschel, pp. 449–481.
Springer, 2013.
AhmadiTeshnizi, A., Gao, W., and Udell, M. Optimus: Optimization modeling using mip
solvers and large language models. arXiv:2310.06116, 2023.
AhmadiTeshnizi, A., Gao, W., and Udell, M. Optimus: Scalable optimization modeling with
(mi) lp solvers and large language models. In ICML, 2024.
Ahmed, T. and Choudhury, S. LM4OPT: Unveiling the potential of large language models
in formulating mathematical optimization problems. INFOR: Information Systems and
Operational Research, 62(4):559–572, 2024.
Akiba, T., Sano, S., Yanase, T., Ohta, T., and Koyama, M. Optuna: A next-generation
hyperparameter optimization framework. In KDD, 2019.
Almonacid, B. Towards an automatic optimisation model generator assisted with generative
pre-trained transformer. arXiv:2305.05811, 2023.
Amarasinghe, P. T., Nguyen, S., Sun, Y., and Alahakoon, D. AI-Copilot for business op-
timisation: A framework and a case study in production scheduling. arXiv:2309.13218,
2023.
18


--- Page 19 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M. W., Pfau, D., Schaul, T., Shillingford,
B., and De Freitas, N. Learning to learn by gradient descent by gradient descent. NeurIPS,
2016.
Araujo, L. How evolutionary algorithms are applied to statistical natural language process-
ing. Artificial Intelligence Review, 28:275–303, 2007.
Bai, Y., Kadavath, S., Kundu, S., Askell, A., Kernion, J., Jones, A., Chen, A., Goldie, A.,
Mirhoseini, A., McKinnon, C., et al. Constitutional ai: Harmlessness from ai feedback.
arXiv:2212.08073, 2022.
Bartz-Beielstein, T., Doerr, C., Berg, D. v. d., Bossek, J., Chandrasekaran, S., Eftimov, T.,
Fischbach, A., Kerschke, P., La Cava, W., Lopez-Ibanez, M., et al. Benchmarking in
optimization: Best practice and open issues. arXiv:2007.03488, 2020.
Bays, C. A comparison of next-fit, first-fit, and best-fit. Communications of the ACM, 20(3):
191–192, 1977.
Bazaraa, M. S. and Sherali, H. D. On the choice of step-size in subgradient optimization.
European Journal of Operational Research, 7(4):380–388, 1981.
Bernal-Agust´ın, J. L. and Dufo-Lopez, R. Simulation and optimization of stand-alone hybrid
renewable energy systems. Renewable and sustainable energy reviews, 13(8):2111–2118, 2009.
Bixby, R. E. Solving real-world linear programs: A decade and more of progress. Operations
Research, 50(1):3–15, 2002.
Bohanec, M. and Bratko, I. Trading accuracy for simplicity in decision trees. Machine
Learning, 15:223–250, 1994.
Boix-Adser`a, E., Saremi, O., Abbe, E., Bengio, S., Littwin, E., and Susskind, J. M. When can
transformers reason with abstract symbols? In ICLR, 2024.
Boyd, S. and Mattingley, J. Branch and bound methods. Notes for EE364b, Stanford University,
2006:07, 2007.
Boyd, S. and Vandenberghe, L. Convex optimization. Cambridge University Press, 2004.
Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., et al. Distributed optimization and
statistical learning via the alternating direction method of multipliers. Foundations and
Trends® in Machine learning, 3(1):1–122, 2011.
Chan, C.-M., Chen, W., Su, Y., Yu, J., Xue, W., Zhang, S., Fu, J., and Liu, Z. Chateval: Towards
better LLM-based evaluators through multi-agent debate. In ICLR, 2024.
Chang, T.-H., Hong, M., Wai, H.-T., Zhang, X., and Lu, S. Distributed learning in the
nonconvex world: From batch data to streaming and beyond. IEEE Signal Processing
Magazine, 37(3):26–38, 2020.
Chen, B., Shu, C., Shareghi, E., Collier, N., Narasimhan, K., and Yao, S. Fireact: Toward
language agent fine-tuning. arXiv preprint arXiv:2310.05915, 2023a.
Chen, H., Constante-Flores, G. E., and Li, C. Diagnosing infeasible optimization problems
using large language models. INFOR: Information Systems and Operational Research, 62(4):
573–587, 2024.
Chen, T., Chen, X., Chen, W., Heaton, H., Liu, J., Wang, Z., and Yin, W. Learning to optimize:
A primer and a benchmark. Journal of Machine Learning Research, 23(189):1–59, 2022.
Chen, T., Xu, B., and Devleker, K. Automating gpu kernel generation with deepseek-r1 and
inference time scaling, February 2025.
Chen, X., Deng, T., Shen, Z.-J. M., and Yu, Y. Mind the gap between research and practice in
operations management. IISE Transactions, 55(1):32–42, 2023b.
19


--- Page 20 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Cheng, Y., Zhang, C., Zhang, Z., Meng, X., Hong, S., Li, W., Wang, Z., Wang, Z., Yin, F., Zhao,
J., et al. Exploring large language model based intelligent agents: Definitions, methods,
and prospects. arXiv:2401.03428, 2024.
Chi, Y., Lin, Y., Hong, S., Pan, D., Fei, Y., Mei, G., Liu, B., Pang, T., Kwok, J., Zhang, C., et al.
SELA: Tree-search enhanced llm agents for automated machine learning. arXiv:2410.17238,
2024.
Chong, E. K. and ˙Zak, S. H. An Introduction to Optimization, volume 75. John Wiley & Sons,
2013.
Chu, Z., Chen, J., Chen, Q., Yu, W., He, T., Wang, H., Peng, W., Liu, M., Qin, B., and Liu, T. A
survey of chain of thought reasoning: Advances, frontiers and future. arXiv:2309.15402,
2023.
Cˆot´e, J.-F., Haouari, M., and Iori, M. Combinatorial benders decomposition for the two-
dimensional bin packing problem. INFORMS Journal on Computing, 33(3):963–978, 2021.
Dantzig, G. B. Linear programming. Operations Research, 50(1):42–47, 2002.
De Moura, L., Kong, S., Avigad, J., Van Doorn, F., and von Raumer, J. The Lean theorem
prover (system description). In CADE, 2015.
Devlin, J., Bunel, R. R., Singh, R., Hausknecht, M., and Kohli, P. Neural program meta-
induction. NeurIPS, 2017.
Dimopoulos, C. and Zalzala, A. M. Recent developments in evolutionary computation for
manufacturing optimization: problems, solutions, and comparisons. IEEE Transactions on
Evolutionary Computation, 4(2):93–113, 2000.
Dincer, I., Rosen, M. A., and Ahmadi, P. Optimization of Energy Systems. John Wiley & Sons,
2017.
Egashira, K., Vero, M., Staab, R., He, J., and Vechev, M. Exploiting LLM quantization.
arXiv:2405.18137, 2024.
Elsken, T., Metzen, J. H., and Hutter, F. Neural architecture search: A survey. Journal of
Machine Learning Research, 20(55):1–21, 2019.
Fan, Z., Ghaddar, B., Wang, X., Xing, L., Zhang, Y., and Zhou, Z. Artificial intelligence for
operations research: Revolutionizing the operations research process. arXiv:2401.03244,
2024.
Feurer, M. and Hutter, F. Hyperparameter optimization. Automated machine learning: Methods,
systems, challenges, pp. 3–33, 2019.
Feurer, M., Eggensperger, K., Falkner, S., Lindauer, M., and Hutter, F. Auto-sklearn 2.0:
Hands-free automl via meta-learning. Journal of Machine Learning Research, 23(261):1–61,
2022.
Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta-learning for fast adaptation of deep
networks. In ICML, 2017.
Franceschi, L., Frasconi, P., Salzo, S., Grazzi, R., and Pontil, M. Bilevel programming for
hyperparameter optimization and meta-learning. In ICML, 2018.
Gangwar, N. and Kani, N. Highlighting named entities in input for auto-formulation of
optimization problems. In International Conference on Intelligent Computer Mathematics,
2023.
Ge, Y., Hua, W., Mei, K., Tan, J., Xu, S., Li, Z., Zhang, Y., et al. OpenAGI: When LLM meets
domain experts. NeurIPS, 2023.
Giovanelli, J., Tornede, A., Tornede, T., and Lindauer, M. Interactive hyperparameter
optimization in multi-objective problems via preference learning. In AAAI, 2024.
20


--- Page 21 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Gleixner, A., Hendel, G., Gamrath, G., Achterberg, T., Bastubbe, M., Berthold, T., Christophel,
P., Jarck, K., Koch, T., Linderoth, J., et al. MIPLIB 2017: Data-driven compilation of the
6th mixed-integer programming library. Mathematical Programming Computation, 13(3):
443–490, 2021.
Greenhalgh, D. and Marshall, S. Convergence criteria for genetic algorithms. SIAM Journal
on Computing, 30(1):269–282, 2000.
Gu, Y., You, H., Cao, J., and Yu, M. Large language models for constructing and optimizing
machine learning workflows: A survey. arXiv:2411.10478, 2024.
Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R., Zhu, Q., Ma, S., Wang, P., Bi, X.,
et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning.
arXiv:2501.12948, 2025.
Hao, S., Gu, Y., Ma, H., Hong, J., Wang, Z., Wang, D., and Hu, Z. Reasoning with language
model is planning with world model. In EMNLP, 2023.
He, B., Yang, H., and Wang, S. Alternating direction method with self-adaptive penalty
parameters for monotone variational inequalities. Journal of Optimization Theory and
applications, 106:337–356, 2000.
He, B., Ma, F., and Yuan, X. Convergence study on the symmetric version of ADMM with
larger step sizes. SIAM Journal on Imaging Sciences, 9(3):1467–1501, 2016.
Hong, M., Razaviyayn, M., Luo, Z.-Q., and Pang, J.-S. A unified algorithmic framework for
block-structured optimization involving big data: With applications in machine learning
and signal processing. IEEE Signal Processing Magazine, 33(1):57–77, 2015.
Hong, S., Lin, Y., Liu, B., Liu, B., Wu, B., Zhang, C., Wei, C., Li, D., Chen, J., Zhang, J., et al.
Data interpreter: An LLM agent for data science. arXiv:2402.18679, 2024.
Hoseini, S., Ibbels, M., and Quix, C. Enhancing machine learning capabilities in data lakes
with AutoML and LLMs. In ADBIS, 2024.
Hospedales, T., Antoniou, A., Micaelli, P., and Storkey, A. Meta-learning in neural networks:
A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(9):5149–5169,
2021.
Huang, S., Yang, K., Qi, S., and Wang, R. When large language model meets optimization.
arXiv:2405.10098, 2024a.
Huang, W., Xia, F., Xiao, T., Chan, H., Liang, J., Florence, P., Zeng, A., Tompson, J., Mordatch,
I., Chebotar, Y., Sermanet, P., Jackson, T., Brown, N., Luu, L., Levine, S., Hausman, K., and
brian ichter. Inner monologue: Embodied reasoning through planning with language
models. In CoRL, 2022.
Huang, X., Shen, Q., Hu, Y., Gao, A., and Wang, B. MAMO: a mathematical modeling
benchmark with solvers. arXiv:2405.13144, 2024b.
Hutter, F., Hoos, H. H., and Leyton-Brown, K. Sequential model-based optimization for
general algorithm configuration. In LION, 2011.
Hutter, F., Lindauer, M., Balint, A., Bayless, S., Hoos, H., and Leyton-Brown, K. The
configurable SAT solver challenge (CSSC). Artificial Intelligence, 243:1–25, 2017.
Hutter, F., Kotthoff, L., and Vanschoren, J. Automated machine learning: methods, systems,
challenges. Springer Nature, 2019.
Ibanez, M. R., Clark, J. R., Huckman, R. S., and Staats, B. R. Discretionary task ordering:
Queue management in radiological services. Management Science, 64(9):4389–4407, 2018.
Izquierdo, I., Medina, J. H., Vianna, M. R., Izquierdo, L. A., and Barros, D. M. Separate
mechanisms for short-and long-term memory. Behavioural brain research, 103(1):1–11, 1999.
21


--- Page 22 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Jiang, B., Xie, Y., Hao, Z., Wang, X., Mallick, T., Su, W. J., Taylor, C. J., and Roth, D. A peek
into token bias: Large language models are not yet genuine reasoners. arXiv:2406.11050,
2024a.
Jiang, J., Wang, F., Shen, J., Kim, S., and Kim, S. A survey on large language models for code
generation. arXiv:2406.00515, 2024b.
Jiang, Y., Cao, Z., and Zhang, J. Learning to solve 3-D bin packing problem via deep
reinforcement learning and constraint programming. IEEE Transactions on Cybernetics, 53
(5):2864–2875, 2021.
Kambhampati, S. Can large language models reason and plan? Annals of the New York
Academy of Sciences, 1534(1):15–18, 2024.
Khot, T., Trivedi, H., Finlayson, M., Fu, Y., Richardson, K., Clark, P., and Sabharwal, A.
Decomposed prompting: A modular approach for solving complex tasks. In ICLR, 2023.
Kudela, J. A critical problem in benchmarking and analysis of evolutionary computation
methods. Nature Machine Intelligence, 4(12):1238–1245, 2022.
Kudela, J. The evolutionary computation methods no one should use. arXiv preprint
arXiv:2301.01984, 2023.
Lange, R. T., Prasad, A., Sun, Q., Faldor, M., Tang, Y., and Ha, D. The ai cuda engineer:
Agentic cuda kernel discovery, optimization and composition, 2025.
Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., K¨uttler, H., Lewis, M.,
Yih, W.-t., Rockt¨aschel, T., et al. Retrieval-augmented generation for knowledge-intensive
NLP tasks. NeurIPS, 2020.
Li, C., Wang, Z., Bai, Y., Duan, Y., Gao, Y., Hao, P., and Wen, Z. Formalization of algorithms
for optimization with block structures. arXiv preprint arXiv:2503.18806, 2025a.
Li, C., Xu, S., Sun, C., Zhou, L., and Wen, Z. Formalization of optimality conditions for
smooth constrained optimization problems. arXiv preprint arXiv:2503.18821, 2025b.
Li, K. and Malik, J. Learning to optimize neural nets. arXiv:1703.00441, 2017.
Li, Q., Zhang, L., and Mak-Hau, V. Synthesizing mixed-integer linear programming models
from natural language descriptions. arXiv:2311.15271, 2023.
Li, W., Qiao, D., Wang, B., Wang, X., Jin, B., and Zha, H. Multi-agent credit assignment with
pretrained language models. In AISTATS, 2025c.
Li, Z.-Z., Zhang, D., Zhang, M.-L., Zhang, J., Liu, Z., Yao, Y., Xu, H., Zheng, J., Wang, P.-J.,
Chen, X., et al. From system 1 to system 2: A survey of reasoning large language models.
arXiv preprint arXiv:2502.17419, 2025d.
Liao, J., Wen, M., Wang, J., and Zhang, W. Marft: Multi-agent reinforcement fine-tuning.
arXiv preprint arXiv:2504.16129, 2025.
Lin, J., Du, Y., Watkins, O., Hafner, D., Abbeel, P., Klein, D., and Dragan, A. Learning to
model the world with language. In ICML, 2024a.
Lin, J., Tang, J., Tang, H., Yang, S., Chen, W.-M., Wang, W.-C., Xiao, G., Dang, X., Gan, C.,
and Han, S. AWQ: Activation-aware weight quantization for on-device LLM compression
and acceleration. GetMobile: Mobile Computing and Communications, 6:87–100, 2024b.
Lindauer, M., Karl, F., Klier, A., Moosbauer, J., Tornede, A., Mueller, A., Hutter, F., Feurer,
M., and Bischl, B. Position: a call to action for a human-centered automl paradigm. In
ICML, 2024.
Liu, F., Tong, X., Yuan, M., and Zhang, Q. Algorithm evolution using large language model.
arXiv:2311.15249, 2023.
22


--- Page 23 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Liu, F., Tong, X., Yuan, M., Lin, X., Luo, F., Wang, Z., Lu, Z., and Zhang, Q. Evolution of
heuristics: Towards efficient automatic algorithm design using large language model. In
ICML, 2024a.
Liu, F., Tong, X., Yuan, M., Lin, X., Luo, F., Wang, Z., Lu, Z., and Zhang, Q. An example
of evolutionary computation+ large language model beating human: Design of efficient
guided local search. arXiv:2401.02051, 2024b.
Liu, F., Yao, Y., Guo, P., Yang, Z., Lin, X., Tong, X., Yuan, M., Lu, Z., Wang, Z., and Zhang, Q.
A systematic survey on large language models for algorithm design. arXiv:2410.14716,
2024c.
Liu, H., Simonyan, K., and Yang, Y.
Darts:
Differentiable architecture search.
arXiv:1806.09055, 2018.
Liu, S., Gao, C., and Li, Y. Large language model agent for hyper-parameter optimization.
arXiv:2402.01881, 2024d.
Liu, X., Lou, X., Jiao, J., and Zhang, J. Position: Foundation agents as the paradigm shift for
decision making. In ICML, 2024e.
L´opez-Ib´a˜nez, M., Dubois-Lacoste, J., C´aceres, L. P., Birattari, M., and St¨utzle, T. The
irace package: Iterated racing for automatic algorithm configuration. Operations Research
Perspectives, 3:43–58, 2016.
Luenberger, D. G., Ye, Y., et al. Linear and Nonlinear Programming, volume 2. Springer, 1984.
Lv, K., Jiang, S., and Li, J. Learning gradient descent: Better generalization and longer
horizons. In ICML, 2017.
Ma, Y. J., Liang, W., Wang, G., Huang, D.-A., Bastani, O., Jayaraman, D., Zhu, Y., Fan, L., and
Anandkumar, A. Eureka: Human-level reward design via coding large language models.
In ICLR, 2024a.
Ma, Z., Guo, H., Gong, Y.-J., Zhang, J., and Tan, K. C. Toward automated algorithm design:
A survey and practical guide to meta-black-box-optimization. arXiv:2411.00625, 2024b.
Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S., Alon, U., Dziri,
N., Prabhumoye, S., Yang, Y., et al. Self-refine: Iterative refinement with self-feedback.
NeurIPS, 2024.
Mahammadli, K. Sequential large language model-based hyper-parameter optimization.
arXiv:2410.20302, 2024.
Meadows, J. and Freitas, A. A survey in mathematical language processing. arXiv:2205.15231,
2022.
Metz, L., Maheswaranathan, N., Nixon, J., Freeman, D., and Sohl-Dickstein, J. Under-
standing and correcting pathologies in the training of learned optimizers. In ICML,
2019.
Meyerson, E., Nelson, M. J., Bradley, H., Gaier, A., Moradi, A., Hoover, A. K., and Lehman, J.
Language model crossover: Variation through few-shot prompting. ACM Transactions on
Evolutionary Learning, 4(4):1–40, 2024.
Mirzadeh, I., Alizadeh, K., Shahrokhi, H., Tuzel, O., Bengio, S., and Farajtabar, M. Gsm-
symbolic: Understanding the limitations of mathematical reasoning in large language
models. arXiv:2410.05229, 2024.
Mostajabdaveh, M., Yu, T. T., Ramamonjison, R., Carenini, G., Zhou, Z., and Zhang, Y.
Optimization modeling and verification from problem specifications using a multi-agent
multi-stage LLM framework. INFOR: Information Systems and Operational Research, 62(4):
599–617, 2024.
23


--- Page 24 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Moura, L. d. and Ullrich, S. The Lean 4 theorem prover and programming language. In
CADE, 2021.
Nelder, J. A. and Mead, R. A simplex method for function minimization. The Computer
Journal, 7(4):308–313, 1965.
Ning, Y., Liu, J., Qin, L., Xiao, T., Xue, S., Huang, Z., Liu, Q., Chen, E., and Wu, J. A novel
approach for auto-formulation of optimization problems. arXiv:2302.04643, 2023.
Oliveira, J. B., Lima, R. S., and Montevechi, J. A. B. Perspectives and relationships in supply
chain simulation: A systematic literature review. Simulation Modelling Practice and Theory,
62:166–191, 2016.
OpenAI.
Learning
to
reason
with
llms.
https://openai.com/index/
learning-to-reason-with-llms/, 2024.
OpenAI.
Reinforcement fine-tuning, 2024.
URL https://www.youtube.com/watch?v=
yCIYS9fx56U.
Ormerod, R. and Kiossis, I. OR/MS publications: Extension of the analysis of us flagship
journals to the united kingdom. Operations Research, 45(2):178–187, 1997.
Ormerod, R. J. On the nature of OR: Taking stock. Journal of the Operational Research Society,
53(5):475–491, 2002.
Park, J. S., O’Brien, J., Cai, C. J., Morris, M. R., Liang, P., and Bernstein, M. S. Generative
agents: Interactive simulacra of human behavior. In UIST, 2023.
Pham, H., Guan, M., Zoph, B., Le, Q., and Dean, J. Efficient neural architecture search via
parameters sharing. In ICML, pp. 4095–4104, 2018.
Pietri, I. and Sakellariou, R. Mapping virtual machines onto physical machines in cloud
computing: A survey. ACM Computing Surveys (CSUR), 49(3):1–30, 2016.
Pluhacek, M., Kazikova, A., Kadavy, T., Viktorin, A., and Senkerik, R. Leveraging large
language models for the generation of novel metaheuristic optimization algorithms. In
GECCO, 2023.
Ramamonjison, R., Li, H., Yu, T. T., He, S., Rengan, V., Banitalebi-Dehkordi, A., Zhou, Z.,
and Zhang, Y. Augmenting operations research with auto-formulation of optimization
models from problem descriptions. arXiv:2209.15565, 2022.
Ramamonjison, R., Yu, T., Li, R., Li, H., Carenini, G., Ghaddar, B., He, S., Mostajabdaveh, M.,
Banitalebi-Dehkordi, A., Zhou, Z., et al. NL4OPT competition: Formulating optimization
problems based on their natural language descriptions. In NeurIPS 2022 Competition Track,
2023.
Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. Regularized evolution for image classifier
architecture search. In AAAI, 2019.
Reisman, A. and Kirschnick, F. The devolution of OR/MS: Implications from a statistical
content analysis of papers in flagship journals. Operations Research, 42(4):577–588, 1994.
Romera-Paredes, B., Barekatain, M., Novikov, A., Balog, M., Kumar, M. P., Dupont, E., Ruiz,
F., Ellenberg, J. S., Wang, P., Fawzi, O., Kohli, P., and Fawzi, A. Mathematical discoveries
from program search with large language models. Nature, 625(7995):468–475, 2024.
Romero Morales, M. D. Optimization Problems in Supply Chain Management. PhD thesis,
TRAIL Research School, The Netherlands, 2000. ERIM PhD series Research in Manage-
ment nr. 3.
Rossit, D. G., Vigo, D., Tohm´e, F., and Frutos, M. Visual attractiveness in routing problems:
A review. Computers & Operations Research, 103:13–34, 2019.
24


--- Page 25 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Roziere, B., Gehring, J., Gloeckle, F., Sootla, S., Gat, I., Tan, X. E., Adi, Y., Liu, J., Sauvestre, R.,
Remez, T., et al. Code Llama: Open foundation models for code. arXiv:2308.12950, 2023.
Ruder, S. An overview of gradient descent optimization algorithms. arXiv:1609.04747, 2016.
Schick, T. and Sch¨utze, H. It’s not just size that matters: Small language models are also
few-shot learners. arXiv:2009.07118, 2020.
Schick, T., Dwivedi-Yu, J., Dess`ı, R., Raileanu, R., Lomeli, M., Hambro, E., Zettlemoyer, L.,
Cancedda, N., and Scialom, T. Toolformer: Language models can teach themselves to use
tools. NeurIPS, 2023.
Schmidt, M., Fung, G., and Rosales, R. Fast optimization methods for ℓ1 regularization: A
comparative study and two new approaches. In ECML, 2007.
Shen, Y., Song, K., Tan, X., Li, D., Lu, W., and Zhuang, Y. Hugginggpt: Solving ai tasks with
chatgpt and its friends in hugging face. NeurIPS, 2024.
Sheng, J., Hu, Y., Zhou, W., Zhu, L., Jin, B., Wang, J., and Wang, X. Learning to schedule
multi-NUMA virtual machines via reinforcement learning. Pattern Recognition, 121:108254,
2022.
Shin, D. The effects of explainability and causability on perception, trust, and acceptance:
Implications for explainable AI. International journal of human-computer studies, 146:102551,
2021.
Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K., and Yao, S. Reflexion: Language
agents with verbal reinforcement learning. NeurIPS, 2024.
Silver, D. and Sutton, R. S. Welcome to the era of experience. Preprint of a chapter in Designing
an Intelligence, 2025.
Simchi-Levi, D. OM forum—OM research: From problem-driven to data-driven research.
Manufacturing & Service Operations Management, 16(1):2–10, 2014.
Snoek, J., Larochelle, H., and Adams, R. P. Practical bayesian optimization of machine
learning algorithms. NeurIPS, 25, 2012.
Song, P., Yang, K., and Anandkumar, A. Towards large language models as copilots for
theorem proving in lean. arXiv:2404.12534, 2024.
Sun, J., Zhang, D. J., Hu, H., and Van Mieghem, J. A. Predicting human discretion to
adjust algorithmic prescription: A large-scale field experiment in warehouse operations.
Management Science, 68(2):846–865, 2022.
Sun, S., Cao, Z., Zhu, H., and Zhao, J. A survey of optimization methods from a machine
learning perspective. IEEE Transactions on Cybernetics, 50(8):3668–3681, 2019.
Tang, Z., Huang, C., Zheng, X., Hu, S., Wang, Z., Ge, D., and Wang, B. ORLM: Training
large language models for optimization modeling. arXiv:2405.17743, 2024.
Trirat, P., Jeong, W., and Hwang, S. J. Automl-agent: A multi-agent llm framework for
full-pipeline automl. arXiv:2410.02958, 2024.
Tsouros, D., Verhaeghe, H., Kadıo˘glu, S., and Guns, T. Holy Grail 2.0: From natural language
to constraint models. arXiv:2308.01589, 2023.
Valmeekam, K., Olmo, A., Sreedharan, S., and Kambhampati, S. Large language models still
can’t plan (a benchmark for LLMs on planning and reasoning about change). In NeurIPS
2022 Foundation Models for Decision Making Workshop, 2022.
Valmeekam, K., Stechly, K., and Kambhampati, S. LLMs still can’t plan; Can lrms? A
preliminary evaluation of OpenAI’s o1 on planbench. arXiv:2409.13373, 2024.
25


--- Page 26 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Van Donselaar, K. H., Gaur, V., Van Woensel, T., Broekmeulen, R. A., and Fransoo, J. C. Order-
ing behavior in retail stores and implications for automated replenishment. Management
Science, 56(5):766–784, 2010.
Van Nguyen, C., Shen, X., Aponte, R., Xia, Y., Basu, S., Hu, Z., Chen, J., Parmar, M., Kunapuli,
S., Barrow, J., et al. A survey of small language models. arXiv:2410.20011, 2024.
Velasco, L., Guerrero, H., and Hospitaler, A. A literature review and critical analysis of
metaheuristics recently developed. Archives of Computational Methods in Engineering, 31(1):
125–146, 2024.
Wang, G., Xie, Y., Jiang, Y., Mandlekar, A., Xiao, C., Zhu, Y., Fan, L., and Anandkumar, A.
Voyager: An open-ended embodied agent with large language models. Transactions on
Machine Learning Research, 2024. ISSN 2835-8856.
Wang, Z., Cai, S., Chen, G., Liu, A., Ma, X. S., and Liang, Y. Describe, explain, plan and
select: Interactive planning with llms enables open-world multi-task agents. NeurIPS,
2023.
Wasserkrug, S., Boussioux, L., Hertog, D. d., Mirzazadeh, F., Birbil, I., Kurtz, J., and Maragno,
D. From large language models and optimization to decision optimization copilot: A
research manifesto. arXiv:2402.16269, 2024.
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al.
Chain-of-thought prompting elicits reasoning in large language models. NeurIPS, 2022.
Wohlberg, B. ADMM penalty parameter selection by residual balancing. arXiv:1704.06209,
2017.
Woldesenbet, Y. G. and Yen, G. G. Dynamic evolutionary algorithm with variable relocation.
IEEE Transactions on Evolutionary Computation, 13(3):500–513, 2009.
Wolke, A., Tsend-Ayush, B., Pfeiffer, C., and Bichler, M. More than bin packing: Dynamic
resource allocation strategies in cloud data centers. Information Systems, 52:83–95, 2015.
Wolpert, D. H. and Macready, W. G. No free lunch theorems for optimization. IEEE
Transactions on Evolutionary Computation, 1(1):67–82, 1997.
Wu, X., Wu, S.-h., Wu, J., Feng, L., and Tan, K. C. Evolutionary computation in the era of
large language model: Survey and roadmap. arXiv:2401.10034, 2024.
Wu, Y., Jiang, A. Q., Li, W., Rabe, M., Staats, C., Jamnik, M., and Szegedy, C. Autoformaliza-
tion with large language models. NeurIPS, 2022.
Xi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., Zhang, M., Wang, J., Jin, S., Zhou, E., et al.
The rise and potential of large language model based agents: A survey. arXiv:2309.07864,
2023.
Xu, F., Hao, Q., Zong, Z., Wang, J., Zhang, Y., Wang, J., Lan, X., Gong, J., Ouyang, T., Meng,
F., et al. Towards large reasoning models: A survey of reinforced reasoning with large
language models. arXiv preprint arXiv:2501.09686, 2025.
Xu, X., Li, M., Tao, C., Shen, T., Cheng, R., Li, J., Xu, C., Tao, D., and Zhou, T. A survey on
knowledge distillation of large language models. arXiv:2402.13116, 2024.
Xu, Y., Liu, M., Lin, Q., and Yang, T. Admm without a fixed penalty parameter: Faster
convergence with new adaptive penalization. NeurIPS, 2017a.
Xu, Z., Figueiredo, M., and Goldstein, T. Adaptive admm with spectral penalty parameter
selection. In AISTATS, 2017b.
Yadkori, Y. A., Kuzborskij, I., Gy¨orgy, A., and Szepesv´ari, C. To believe or not to believe
your llm. arXiv:2406.02543, 2024.
26


--- Page 27 ---
Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows
Yampolskiy, R. V. Why we do not evolve software? Analysis of evolutionary algorithms.
Evolutionary Bioinformatics, 14:1176934318815906, 2018.
Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., and Chen, X. Large language models
as optimizers. In ICLR, 2024.
Yang, Y., Guan, X., Jia, Q.-S., Yu, L., Xu, B., and Spanos, C. J. A survey of ADMM variants
for distributed optimization: Problems, algorithms and features. arXiv:2208.03700, 2022.
Yao, Q., Wang, M., Chen, Y., Dai, W., Li, Y.-F., Tu, W.-W., Yang, Q., and Yu, Y. Taking human
out of learning applications: A survey on automated machine learning. arXiv:1810.13306,
2018.
Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., and Cao, Y. React: Synergizing
reasoning and acting in language models. arXiv:2210.03629, 2022.
Yao, S., Liu, F., Lin, X., Lu, Z., Wang, Z., and Zhang, Q. Multi-objective evolution of heuristic
using large language model. arXiv:2409.16867, 2024a.
Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T., Cao, Y., and Narasimhan, K. Tree of thoughts:
Deliberate problem solving with large language models. NeurIPS, 2024b.
Ye, H., Wang, J., Cao, Z., Berto, F., Hua, C., Kim, H., Park, J., and Song, G. ReEvo: Large
language models as hyper-heuristics with reflective evolution. arXiv:2402.01145, 2024.
Yu, X. and Gen, M. Introduction to evolutionary algorithms. Springer Science & Business
Media, 2010.
Zhang, D., Wang, L., Zhang, L., Dai, B. T., and Shen, H. T. The gap of semantic parsing: A
survey on automatic math word problem solvers. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 42(9):2287–2305, 2019.
Zhang, M., Desai, N., Bae, J., Lorraine, J., and Ba, J. Using large language models for
hyperparameter optimization. In NeurIPS 2023 Foundation Models for Decision Making
Workshop, 2023a.
Zhang, R., Liu, F., Lin, X., Wang, Z., Lu, Z., and Zhang, Q. Understanding the importance of
evolutionary search in automated heuristic design with large language models. In PPSN,
2024.
Zhang, S., Gong, C., Wu, L., Liu, X., and Zhou, M. AutoML-GPT: Automatic machine
learning with GPT. arXiv:2305.02499, 2023b.
Zheng, J., Qiu, S., Shi, C., and Ma, Q. Towards lifelong learning of large language models: A
survey. ACM Computing Surveys, 57(8):1–35, 2025a.
Zheng, J., Shi, C., Cai, X., Li, Q., Zhang, D., Li, C., Yu, D., and Ma, Q. Lifelong learning of
large language model based agents: A roadmap. arXiv preprint arXiv:2501.07278, 2025b.
Zhong, R., Xu, Y., Zhang, C., and Yu, J. Leveraging large language model to generate a novel
metaheuristic algorithm with CRISPE framework. Cluster Computing, 27(10):13835–13869,
2024.
Zhou, A., Qu, B.-Y., Li, H., Zhao, S.-Z., Suganthan, P. N., and Zhang, Q. Multiobjective evo-
lutionary algorithms: A survey of the state of the art. Swarm and evolutionary computation,
1(1):32–49, 2011.
Zhou, X., Tie, G., Zhang, G., Wang, W., Zuo, Z., Wu, D., Chu, D., Zhou, P., Sun, L., and Gong,
N. Z. Large reasoning models in agent scenarios: Exploring the necessity of reasoning
capabilities. arXiv preprint arXiv:2503.11074, 2025.
27
