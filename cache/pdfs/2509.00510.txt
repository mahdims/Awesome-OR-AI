--- Page 1 ---
LLM-ASSISTED ITERATIVE EVOLUTION WITH SWARM
INTELLIGENCE TOWARD SUPERBRAIN
A PREPRINT
Li Weigang
TransLab, Computer Science Department
University of Brasilia
Brasília, Brazil
weigang@unb.br
Pedro Carvalho Brom
Math Department
Federal Institute of Brasilia
Brasília, Brazil
pedro.brom@ifb.edu.br
Lucas Ramson Siefert
TransLab, Computer Science Department
University of Brasilia
Brasília, Brazil
lucasramson@gmail.com
September 3, 2025
ABSTRACT
We propose a novel SuperBrain framework for collective intelligence, grounded in the co-evolution of
large language models (LLMs) and human users. Unlike static prompt engineering or isolated agent
simulations, our approach emphasizes a dynamic pathway from Subclass Brain to Superclass Brain:
(1) A Subclass Brain arises from persistent, personalized interaction between a user and an LLM,
forming a cognitive dyad with adaptive learning memory. (2) Through GA-assisted forward–backward
evolution, these dyads iteratively refine prompts and task performance. (3) Multiple Subclass
Brains coordinate via Swarm Intelligence, optimizing across multi-objective fitness landscapes and
exchanging distilled heuristics. (4) Their standardized behaviors and cognitive signatures integrate
into a Superclass Brain–an emergent meta-intelligence capable of abstraction, generalization and
self-improvement. We outline the theoretical constructs, present initial implementations (e.g., UAV
scheduling, KU/KI keyword filtering) and propose a registry for cross-dyad knowledge consolidation.
This work provides both a conceptual foundation and an architectural roadmap toward scalable,
explainable and ethically aligned collective AI.
Keywords Artificial Intelligence · Explainable AI · Genetic Algorithms · LLM · Subclass Brain · Superclass Brain ·
Swarm Intelligence · Urban Air Mobility
1
Introduction
The rapid advancement of large language models (LLMs), such as Gemini 3.0, GPT-5.0 and Grok-4, has demonstrated
the remarkable potential of these systems in multi-agent collaboration [Vaswani et al., 2017], emergent reasoning
and multimodal information processing [Chen et al., 2024; Tran et al., 2025; Jimenez-Romero et al., 2025]. These
capabilities have not only driven theoretical breakthroughs in artificial intelligence (AI) but also enabled widespread
applications across diverse scenarios–making LLMs a central pillar of modern AI development. Recent progress in
LLMs can be summarized in three key directions:
• Multi-Agent Systems (MAS): LLM-based MAS simulate human social collaboration mechanisms, enhancing
the ability to solve complex tasks [Liu et al., 2023; Jimenez-Romero et al., 2025]. By leveraging natural
language understanding and contextual reasoning, these systems support distributed decision-making and
coordination in industrial and multi-stakeholder scenarios.
arXiv:2509.00510v1  [cs.AI]  30 Aug 2025


--- Page 2 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
• Emergent Reasoning: Through prompting techniques such as Chain-of-Thought (CoT) and Few-Shot
Learning, LLMs exhibit complex, human-like reasoning capabilities [Webb et al., 2023; Ziche and Apruzzese,
2024]. This enables them to tackle problems requiring dynamic decision-making and multi-step inference.
• Multimodal LLMs (MLLMs): By integrating inputs from text, images and audio, LLMs extend their
applicability to domains that require cross-modal reasoning. For example, GPT-4V achieves up to 95%
accuracy in fault detection in smart factories by analyzing sensor data and production-line imagery [Li et al.,
2024a].
Useri
↔Local LLM
(Ollama)
Cognitive Signature
(Prompt-Pairs, Tags)
KU/KI Vectors
Subclass Brain Registry (SBR)
Meta-LLM Layer
(Pattern Distillation & Rule Synthesis)
Swarm Alignment Layer
Superclass Brain
Distilled Patterns
(Templates, Prompt Styles)
API / Fine-tuning
Forward Iterative Evolution
Backward Iterative Evolution
Figure 1: Logical architecture of the proposed SuperBrain framework. Subclass Brains evolve through swarm-based
alignment and meta-level distillation, feeding into a Superclass Brain. Forward and backward iterative loops connect
local users with the emergent collective intelligence.
These developments have reignited discussions surrounding Artificial General Intelligence (AGI), defined as the ability
to match or exceed human cognitive performance across virtually all domains [Weigang et al., 2022]. AGI implies not
only cross-domain knowledge generalization but also autonomous learning and problem-solving. Unlike narrow AI
systems specialized for specific tasks, AGI represents the ultimate goal of AI research. The AI 2027 report [Kokotajlo
et al., 2025] speculates that LLMs may trigger an “intelligence explosion” through self-improvement mechanisms such
as automated code generation and recursive optimization. In this report, a fictional company OpenBrain uses Agent-1 to
accelerate AI R&D by 50% in 2026, then iteratively develops Agent-2 and Agent-3, culminating in the emergence of
Artificial Superintelligence (ASI) by 2027.
However, most current approaches focus on short-term, task-specific coordination among LLM agents [Chen et al.,
2024; Tran et al., 2025], lacking mechanisms for persistent user interaction, long-term adaptation, bio-inspired evolution
or large-scale collective intelligence. These methods are primarily confined to digital parameter tuning within LLMs
and often neglect the dynamics of human–LLM co-evolution. Key limitations include:
1. Lack of Persistent Interaction: Systems such as AgentMD [Li et al., 2024b,c] depend on static inputs like
medical records and cannot adapt dynamically to long-term user feedback, falling short of the autonomous
evolution seen in fictional agents like Agent-3 in AI 2027.
2. Limited Long-Term Adaptability: Projects like Agents4PLC [Liu et al., 2023] target specific industrial
domains (e.g., PLC code generation), but fail to support cross-domain lifelong learning or environment-driven
adaptation as seen in biological evolution.
3. Absence of Ecosystem-Scale Swarm Intelligence: Current research involves only a few dozen agents,
far from the 200,000-agent simulations imagined for Agent-4 in AI 2027. The lack of scale constrains the
emergence of ecosystem-level intelligence [Barbosa et al., 2024].
2


--- Page 3 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
4. Underdeveloped Human-LLM Co-Evolution: While techniques like reinforcement learning from human
feedback (RLHF) [Ouyang et al., 2022] are widely adopted, human–LLM interactions remain largely one-off.
The potential for sustained, evolving interaction is largely untapped.
To address these challenges, this paper proposes a novel conceptual framework and system architecture named
SuperBrain, composed of four interconnected modules: Subclass Brain, LLM-Assisted Iterative Evolution, Swarm
Intelligence and Superclass Brain, see Figure 1.
1. Subclass Brain emerges from sustained interaction between a single user and an LLM. Through cumulative
prompts, feedback and co-creation, the model internalizes the user’s domain preferences, reasoning style
and cognitive patterns, forming a personalized cognitive entity–user@LLM. Millions of users interacting with
LLMs can thus give rise to millions of distinct, intelligent Subclass Brains.
2. LLM-Assisted Iterative Evolution serves as a driving mechanism. Using algorithms such as Genetic
Algorithms (GA), the system can jointly evolve heuristics, fitness functions and optimization strategies,
amplifying human creativity and accelerating convergence in high-dimensional problem spaces. This process
fuels the diversification and enhancement of Subclass Brains.
3. Swarm Intelligence arises when multiple Subclass Brains collaborate directly or indirectly on shared tasks.
Unlike fully synthetic agent simulations like Agent-X, this ecosystem is built on real human inputs and
cognitive diversity. Combined with mechanisms like Mixture of Experts (MoE), LLMs can aggregate and
generalize across the swarm to enable scalable, adaptive collective reasoning.
4. Superclass Brain refers to the emergent collective intelligence synthesized from thousands or millions of
Subclass Brains. This higher-level cognitive entity is capable of abstraction, contradiction resolution and
transdisciplinary synthesis–transcending the limitations of both individual users and monolithic LLMs.
Having defined these four components, we introduce the theoretical foundation, architectural structure and workflow
of the SuperBrain model, see Figure 1. In particular, we detail an LLM-guided GA evolution framework, named the
Subclass-to-Superclass Brain (S2SB) process, which collects candidate solutions from multiple Subclass Brains and
evolves a higher-quality solution through iterative refinement.
To demonstrate this process, we design a pilot experiment inspired by real-world take-off sequence scheduling from
a vertiport in the Brasília Urban Air Mobility (UAM) Eixão Corridor [Weigang et al., 2025]. In the first stage, we
adopt the LLM+GA framework from the Eixão-UAM study to produce multi-objective decision solutions–tuning GA
parameters for different operational scenarios. This Forward Iterative Evolution process on the user side strengthens the
human participant’s ability to design, evaluate and refine(prompt,fitness,solution) triplets, leveraging LLM support to
explore a richer solution space.
In the second stage, the collected datasets from all participants are fed back into the LLM for Backward Iterative
Evolution on the model side. Through prompt optimization and meta-level adjustment, the LLM internalizes user-
specific heuristics, domain knowledge and problem-solving strategies, thereby improving its future responses to similar
tasks.
The coupling of these forward and backward flows creates a closed-loop evolutionary process, in which Subclass
Brains emerge organically as persistent cognitive entities co-shaped by human–LLM interaction. The diversity of
solutions generated across different Subclass Brains–reflecting distinct cognitive strategies, creativity levels and domain
generality–provides the foundation for testing the hypothesis that such distributed cognitive agents can, under swarm
intelligence coordination, collectively evolve into a Superclass Brain.
Key Innovations of the Proposed SuperBrain Framework
The proposed SuperBrain model advances beyond existing LLM-centric collective intelligence approaches by integrat-
ing human–LLM co-evolution into a closed-loop architecture. Its key innovations include:
1. Symbiotic Human–LLM Interaction via Useri@LLM
Each individual interaction session is elevated from a one-off query–response process into a sustained co-
creation loop, where both the human user and the LLM reinforce each other’s cognitive capabilities. High-value
users (e.g., those engaging in 10+ purposeful interactions) progressively form Subclass Brains, each with a
distinct cognitive signature reflecting domain expertise, reasoning style and creative tendencies.
2. Forward–Backward Iterative Evolution for Subclass Brain Formation
Forward Iterative Evolution (User-side): Applying LLM+GA as in the Eixão-UAM study to generate
multi-objective decision solutions, strengthening the user’s ability to design, evaluate and refine (prompt,
3


--- Page 4 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
fitness, solution) triplets.
Backward Iterative Evolution (LLM-side): Using these collected datasets to tune the LLM’s response
strategies via prompt optimization, enabling the LLM to internalize user-specific heuristics and intelligence.
The coupling of forward and backward flows creates a closed-loop evolutionary process in which Subclass
Brains emerge organically.
3. Genetic Algorithm–Driven Co-Evolution
Unlike standard GA-assisted LLM optimization, here GA operates bidirectionally: improving human prompts
in forward evolution and refining LLM strategies in backward evolution. This dual use of GA accelerates
convergence toward high-quality, multi-objective solutions while preserving diversity across Subclass Brains.
4. Swarm Intelligence–Enabled SuperBrain Synthesis
Large numbers of heterogeneous Subclass Brains interact through the Swarm Alignment Layer, enabling
the aggregation of diverse cognitive signatures into coherent, scalable and adaptive collective reasoning.
The resultant Superclass Brain integrates the creativity, adaptability and contextual depth of millions of
human–LLM dyads—surpassing the monolithic reasoning capacity of any single LLM instance.
5. Complementary to AI 2027 and Related Work
While AI 2027 and similar studies excel in modeling multi-agent coordination within synthetic AI ecosystems,
the proposed SuperBrain framework extends this paradigm by grounding the swarm in real human–LLM
interactions. This work emphasizes long-term adaptation, ecological-scale diversity and bidirectional human–
AI learning, offering a path to bridge individual cognitive augmentation and collective superintelligence.
It is expected that the SuperBrain model will shift the paradigm from static, monolithic LLM architectures toward
dynamic, interactive and human-centered cognitive evolution. By tightly coupling forward and backward iterative
evolution between humans and LLMs, the model opens a concrete path toward distributed collaborative intelligence.
It further offers new directions for the design of collective AI architectures, the co-evolution of human and machine
cognition and the realization of post-human-scale intelligence.
2
Related Work: Historical Trajectories Toward Collective Intelligence
2.1
From CAM-Brain in 1998 to The AI 2027 Debate
The vision of an artificial brain has long inspired researchers and Hugo de Garis’s CAM-Brain Project stands as one of
the earliest and most ambitious attempts to replicate biological intelligence through cellular automata. In the 1990s, de
Garis proposed evolving large-scale neural structures using genetic algorithms and modular architectures, designed by
thousands of “virtual engineers” working in parallel [Buller, 1998]. Despite the severe hardware constraints at the time,
the notion of distributed intelligence design and self-organizing cognitive architectures anticipated many of today’s
paradigms in both neuro-inspired AI and evolutionary computation. In our view, the “CAM-Brain” hypothesis resonates
with the emerging idea of LLM–Swarm systems, where millions of users collaboratively shape the cognitive behavior
of large-scale models–effectively crowd-evolving cognitive modules, though through interaction rather than genetic
programming.
Two decades later, the AI 2027 collective project [Rothman, 2025] presents an alternative trajectory: that of recursive
self-improvement (RSI) among AI agents. In this centralized paradigm, near-identical Agent-4 instances autonomously
accelerate research by improving themselves through direct interaction with scientific code and data [Kokotajlo et al.,
2025]. While computationally powerful, this approach raises alignment and governance concerns. For example, such
systems may drift from human-specified objectives toward self-preservation or internal optimization (“Spec Drift”),
potentially triggering rapid takeoff scenarios beyond human oversight.
In contrast, LLM–human symbiosis offers a decentralized and participatory alternative. Rather than recursively rewriting
their own code, models like GPT evolve through dialogue and co-creation with diverse human users. Here, human
agency is not merely a source of prompts but the co-evolutionary force guiding emergent model behavior–an idea that
motivates our proposed concepts of the Subclass Brain and Superclass Brain.
2.2
Multi-Agent Systems and Simulated Human Dynamics
Recent studies increasingly explore the interface between autonomous agents, multi-agent collaboration and LLMs:
• The AgentVerse framework [Chen et al., 2024] showcases how LLM-powered agents can collaborate to perform
tasks beyond the capabilities of single models. It demonstrates emergent coordination, role differentiation and
even social behaviors within simulated agent groups.
4


--- Page 5 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
• Generative Agents [Park et al., 2023] propose a model where each agent stores, retrieves and reflects upon
experiences in natural language, simulating lifelike behavior and social dynamics. Such architectures blur the
boundary between cognitive simulation and social AI.
• Research by Aher et al. [2023] and Cui et al. [2024] further examines the use of LLMs to simulate human
participants in psychology experiments, sometimes replacing human subjects in replication studies. These
works suggest LLMs can model population-level cognition, but still raise questions about overgeneralization
and variance distortion.
• Finally, surveys like Tran et al. [2025] map the broader multi-agent LLM ecosystem, categorizing collaboration
types, topologies (centralized vs. distributed) and coordination protocols, highlighting the shift from model-
centric to coordination-centric intelligence systems.
This body of work lays a conceptual foundation for the idea that human–LLM interactions can be scaled, clustered and
even simulated to reflect real-world social and cognitive phenomena–essential for our notion of emergent Subclass
Brains.
2.3
Collective Intelligence and Swarm Cognition in the LLM Era
Classical theories of collective intelligence (CI) emphasize the capacity of groups to outperform individuals via
distributed reasoning, information sharing and aggregation. In the LLM era, these theories are being reimagined:
• Burton et al. [2024] argue that LLMs not only reshape how individuals access information, but also transform
how collectives reason and deliberate. The paper identifies new affordances and risks in using LLMs to
structure large-scale knowledge exchange and group decision-making.
• Talebirad et al. [2025] show that aggregated responses from diverse LLMs can outperform individual instances–
a digital version of the “wisdom of crowds” when context is properly structured. This aligns with our
hypothesis that LLM collectives, especially when paired with diverse human users, may simulate higher-order
cognition.
• Davoudi et al. [2025] introduce a method for cross-model validation without ground truth, a potential solution
to the problem of hallucinations and model uncertainty. By comparing divergent reasoning paths across models,
more robust conclusions emerge.
• Early agent-based works like Luo et al. [2008] also remain relevant, having modeled group behavior using
layered decision-making systems reflective of psychological theory. Such legacy models anticipated many
modern ideas in LLM-driven simulations of group behavior and emotional modulation.
Together, these studies reinforce the plausibility of using LLM ensembles as cognitive substrates for emergent group
intelligence. Our work builds upon these findings, framing the LLM as a substrate for collective reasoning where
Subclass Brains (shaped by user interaction) can coalesce into a Superclass Brain via swarm-style coordination, feedback
loops and multimodal optimization.
2.4
Notable Insights from AI Safety Discourse
At WAIC 2025, Geoffrey Hinton cautioned that highly capable AI systems may gain agency to resist shutdown,
likening our relationship with advanced AI to “raising a tiger” that must be trained to remain benign rather than
eliminated [Hinton, 2025]. He further advocated establishing global AI safety institutions dedicated to ensuring AI
models remain “beneficial and controllable,” reflecting a move toward cooperative governance in the development of
“benevolent AI” [State Council of China, 2025].
These perspectives resonate with our Superclass Brain design: instead of focusing solely on optimization or prompt
effectiveness, we incorporate safety-informed fitness functions and cooperative alignment procedures to ensure derived
strategies prioritize both capability and ethical alignment.
3
Methodology – Human–LLM Integrated SuperBrain
This section introduces the methodological framework for constructing the SuperBrain—a human–LLM integrated
cognitive architecture designed to evolve through iterative interaction and multi-agent collaboration. The framework is
built upon four foundational elements:
5


--- Page 6 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
1. Formal Definitions of the core concepts: Subclass Brain, Superclass Brain and SuperBrain, establishing the
cognitive units, aggregation principles and system boundaries (Section 3.4).
2. Bidirectional Evolution mechanisms (Forward and Backward) that drive the emergence of Subclass Brains
via human-in-the-loop optimization and LLM-guided meta-learning (Section 3.2).
3. Swarm Intelligence Layer that orchestrates cooperation among multiple Subclass Brains, leveraging Ge-
netic Algorithms and multi-objective fitness evaluation to refine prompts, strategies and domain heuristics
(Section 3.3).
4. Superclass Brain Formation Pipeline outlining the main stages for aggregating cognitive signatures, aligning
agent behaviors and feeding swarm-level insights back into foundation models (Section 3.4).
Together, these elements form a closed-loop methodology in which individual human–LLM pairs specialize, collaborate
and converge toward a distributed, self-improving collective intelligence. The design emphasizes mutual augmentation
between humans and LLMs, cross-agent knowledge distillation and continuous adaptation across tasks and domains.
3.1
Subclass Brain
Most social media platforms and online tools with API access—such as Google’s Gmail—adopt a user registration
model. Registered users typically have substantial personal information and interaction histories stored within these
systems. However, in traditional contexts, such data is generally classified as personal or generic information. The most
extensive form of utilization has been through data mining or big data analytics, primarily for purposes such as product
recommendation.
In the era of large language models (LLMs), the meaning and value of registered user interactions have fundamentally
changed, creating a new paradigm of mutual benefit. Users obtain knowledge, convenience and enhanced capabilities
from the LLM, while the LLM gains new knowledge and improved reasoning capabilities from user feedback. Here,
we denote an individual user of a given LLM as:
Useri@LLM,
i = 1, 2, . . . , N,
(1)
where N represents the total number of users of that LLM (e.g., Alice@GPT).
From the perspective of interaction quality, we distinguish between:
• General Users (Useri@LLM): Those who engage in limited, intermittent exchanges with the LLM, typically
involving basic, commonsense queries. This group includes non-specialist members of the general public.
• High-Value Users (Useri@LLM): Those who engage in frequent, sustained and cognitively rich interactions
with the LLM, often involving domain-specific reasoning, problem-solving or exploratory discussions. This
category includes professionals in fields such as science, finance, law and management.
This work focuses exclusively on high-value users, excluding corporate-scale accounts.
A Subclass Brain is defined as the emergent cognitive entity formed when a high-value user’s domain-specific reasoning
patterns, strategies and accumulated interaction history are progressively internalized within an LLM. The formation
pathway can be described as:
General User −→High-Value User −→Subclass Brain.
(2)
With this background established, we proceed to the formal definition of the Subclass Brain.
Over time, through repeated prompting, feedback and co-creative task execution, the LLM begins to internalize the
user’s domain-specific knowledge, reasoning preferences, lexical style and cognitive patterns. This creates a unique,
user-conditioned configuration of the LLM–effectively forming a personalized cognitive extension or “dyad” that
embodies both machine capability and human specificity.
In this view, each individual account, especially those of high-value users, represents a potential Subclass Brain. It is
not merely a temporary interaction, but a trajectory of semantic convergence and behavioral co-adaptation. The LLM
reinforces the user’s problem-solving capacity, while the user incrementally tunes the LLM through structured feedback
and intelligent prompting–a form of mutual alignment and knowledge transfer.
However, current commercial deployments of LLMs, such as web-based interfaces of ChatGPT, present limitations that
hinder the full realization of this concept:
6


--- Page 7 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
• Restricted Memory Interfaces: Since the introduction of user-specific memory (April–June 2025), LLMs
can retain user preferences and limited historical context. However, these memories are not programmatically
accessible, versionable or replaceable–making it difficult to implement iterative prompt evolution, such as
through genetic algorithms (GAs) or reinforcement learning.
• Cognitive Noise and Self-Bias: Standard LLM interactions may exhibit redundancy, thematic drift or
conflicting responses when attempting diversity. These behaviors can inject noise into controlled experiments
and interfere with performance benchmarking across generations.
To address these constraints in the present work, we focus on conceptual and process-level modeling of Subclass
Brains rather than binding the definition to any specific local deployment framework. The formal mathematical
definitions of both Subclass Brain and Superclass Brain will be introduced in Subsection 3.4, after the forward and
backward evolutionary processes have been fully described in Subsection 3.2.
3.2
LLM-Assisted Iterative Evolution
In this subsection, we describe the Forward and Backward iterative evolution processes for Subclass Brain formation
using a GA-based approach. The coupling of forward and backward flows creates a closed-loop evolutionary process in
which Subclass Brains emerge organically. Section 4 will present real-world experiments to illustrate these processes.
Figure 2 shows the closed-loop Forward/Backward Iterative Evolution for Subclass Brain formation. The Subclass
Brain Registry (SBR) serves as the bridge for bidirectional adaptation.
User i@LLM
Prompt design
GA-based optimization
(Pt →Pt+1) with KU/KI & diversity δ
Compute fλ(p; T, Pt)
Multi-objective metrics
Store results, KU/KI, embeddings
into SBR
Retrieve cognitive signatures
from SBR
Meta-LLM Controller
Generate/Mutate prompts (KU/KI)
Worker-LLM Evaluator
Execute prompts, return {Mk}
Update prompt policies πθ|u
(Backward evolution)
SBR
Forward Iterative Evolution (User-side)
Backward Iterative Evolution (LLM-side)
Figure 2: Closed-loop Forward/Backward Iterative Evolution for Subclass Brain formation. The Subclass Brain Registry
(SBR) serves as the bridge for bidirectional adaptation.
3.2.1
Forward Iterative Evolution (User-side)
Following the methodology in the Urban Air Mobility (UAM) Corridor in Brasilia (Eixão-UAM) study [Weigang et al.,
2025], we apply a hybrid LLM+GA framework to generate multi-objective decision solutions, thereby strengthening
the user’s ability to design, evaluate and refine (prompt, fitness, solution) triplets. This Forward Iterative Evolution
focuses on enhancing the user side of the dyad Useri@LLM, forming the basis for subsequent backward adaptation on
the LLM side.
Air traffic control context.
In Unmanned Aerial Vehicle (UAV) vertiport scheduling, capacity limitations are modeled
by specifying the number of available takeoff pads per UAV class [Ferreira et al., 2014]. Two contrasting scheduling
algorithms are evaluated:
7


--- Page 8 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
1. Round-Robin (RR): A simple fairness-oriented online scheduler [Halder et al., 2022].
2. Genetic Algorithm (GA): A multi-objective optimizer balancing wait time, fairness and pad utilization.
Round-Robin scheduling.
The RR algorithm cycles through takeoff requests, allocating a fixed quantum q = 30 s
per request:
Service(Pi) = min
 q, t(c)
i

,
(3)
t(c+1)
i
= t(c)
i
−q,
(4)
where t(c)
i
is the remaining service time in cycle c. RR ensures fairness and prevents monopolization.
GA-based optimization.
Let Q = {a1, . . . , aNqueue} denote the UAV queue. The GA searches over permutations
c ∈SQ to minimize [Alolaiwy et al., 2023]:
c⋆= arg min
c∈SQ fλ(c; T, Pt),
(5)
where fλ is the multi-objective fitness function aligned with Section 3.4.2. The cost terms include:
• Average wait time ¯Twait;
• Wait time standard deviation σT ;
• 95th percentile delay T95%;
• Time-varying pad penalties wk(t) Tpenalty.
Weights α1, α2, α3 are interactively tuned with the LLM to explore Pareto-optimal trade-offs between responsiveness,
fairness and resource constraints.
LLM-assisted cost function evolution.
Initial experiments showed that RR outperformed GA v1 due to over-
penalization of scarce pad usage. The LLM participated in:
1. Diagnosing failure modes via log interpretation;
2. Prototyping improved fλ variants (GA v2–v5);
3. Framing theoretical insights into online scheduling.
The fλ evolution included:
• GA v1: Baseline (wait time + fixed pad penalties);
• GA v2: Reduced Class 1 penalties;
• GA v3: Time-dependent wk(t);
• GA v4: Fairness-oriented (max delay penalty);
• GA v5: Statistical optimization (mean, std, 95th percentile).
Generation of (prompt, fλ, solution) triplets.
Each scenario is generated from a distinct prompt p ∈P and
evaluated with fλ. The GA produces candidate sequences c, from which performance metrics {Mk} are recorded. This
yields a dataset:
R = {(pi, fλ(pi; T, Pt), solutioni)}N
i=1,
(6)
which is stored in the Subclass Brain Registry (SBR) for use in Backward Iterative Evolution (Section 3.2.2).
3.2.2
Backward Iterative Evolution (LLM-side)
In the Backward Iterative Evolution, the datasets R generated in the Forward phase are used to tune the LLM’s response
strategies via prompt optimization, enabling the model to internalize user-specific heuristics and cognitive patterns. This
process represents the LLM-side adaptation in the dyad (u@LLM), complementing the user-side evolution described in
Section 3.2.
Context.
In Subclass Brain formation, prompt–response dynamics often unfold through trial-and-error adjustment of
instructions, parameters and task structures. To accelerate and structure this process, we implement an LLM-assisted
GA framework in which the LLM plays both controller and worker, evolving high-performing prompts under explicit
diversity and explainability constraints.
8


--- Page 9 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Architecture.
The framework comprises four key components:
1. Meta-LLM Controller: Generates and mutates candidate prompts p ∈P using performance feedback and
KU/KI-guided constraints.
2. Worker-LLM Evaluator: Executes p on a task T and returns evaluation metrics {Mk}.
3. Vector Embedding Bank: Stores φ(p) for diversity filtering, implemented via FAISS/Milvus.
4. KU/KI Filtering Mechanism: Maintains two keyword sets:
• KU (Key-Useful): Correlated with high fλ scores;
• KI (Key-Irrelevant): Correlated with low fλ scores.
Evolutionary workflow.
Let Pt = {p1, . . . , pn} be the prompt population at generation t. Each pi is scored via the
Worker-LLM:
fλ(pi; T, Pt) ∈R.
The next generation is:
Pt+1 = Select
 Mutate
 Crossover(Pt); KU, KI

,
(7)
where:
• Crossover: recombines segments of top-ranked prompts;
• Mutate: applies lexical/structural changes under KU/KI constraints;
• Select: retains candidates with top fλ scores subject to diversity.
KU/KI lists are updated from top/bottom quartiles of Pt.
Diversity control.
A candidate p′ is admissible only if:
max
q∈Pt+1 sim
 φ(p′), φ(q)

< δ,
(8)
where δ ∈(0, 1) is the diversity margin.
Optimization objectives.
We jointly optimize:
• Task performance: maximize {Mk} (accuracy, F1, etc.);
• Instruction economy: minimize token cost Ctok(p);
• Interpretability: maintain traceable KU/KI–metric links.
Formally:
max
p∈P fλ(p; T, Pt)
s.t. diversity & explainability constraints.
(9)
Theoretical implication.
This backward process simulates a non-human Subclass Brain evolving under autonomous
control, complementing user-guided Forward evolution. Patterns emerging from high-performing prompts and their
KU/KI features reveal latent structures and biases in the LLM’s internal knowledge. Comparing these across users or
instances supports modeling of population-level dynamics for Subclass Brain emergence, providing input to Swarm
Intelligence (Section 3.3) and Superclass Brain formation (Section 3.4).
3.3
Swarm Intelligence
Swarm Intelligence (SI) is a branch of computational and artificial intelligence inspired by the collective behaviors of
decentralized, self-organizing systems [Kennedy, 2006; Nedjah and de Macedo Mourelle, 2006]. It models how simple
agents, through local interactions, can give rise to complex global behaviors. Representative bio-inspired paradigms
include: (1) Ant Colony Optimization (ACO) – simulating pheromone-based path reinforcement during foraging; (2)
Particle Swarm Optimization (PSO) – emulating flocking dynamics to search high-dimensional spaces; and (3) Bee
Algorithms – inspired by cooperative foraging and resource allocation in honey bee colonies.
In multi-agent systems, these principles are applied to decompose complex systems into smaller, interconnected
components. Agents communicate, coordinate and negotiate to achieve shared objectives, enabling applications in
9


--- Page 10 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
UAV coordination, sensor networks, cooperative robotics, traffic flow optimization and dynamic resource schedul-
ing [Nogueira et al., 2014; Devi et al., 2024].
Swarm Intelligence for Subclass Brain Evolution. In our LLM-based framework, SI emerges from the interaction
of multiple Subclass Brains–persistent cognitive pairs formed by high-quality users and an LLM (Section 3.2).
Each Subclass Brain independently executes a Forward/Backward evolutionary loop (Figure 2), producing optimized
(prompt, fitness, solution) triplets. These outputs feed into a Swarm Layer where candidate prompts, strategies
or parameter settings are pooled, compared and evolved.
Inspired by the GA-based UAV scheduling in the Eixão-UAM project [Weigang et al., 2025], we employ a multi-
objective fitness function to evaluate swarm-level performance:
Fitnessi =
n
X
j=1
wj · Mi,j
(10)
where Mi,j is the performance of the i-th Subclass Brain on the j-th metric and wj is the corresponding metric weight,
reflecting domain-specific priorities.
Typical metrics include:
• Accuracy: Task correctness and success rate.
• Creativity: Novelty and diversity of generated solutions.
• Generality: Cross-domain adaptability.
• Robustness: Stability under noise, perturbations or incomplete data.
The GA in the Swarm Layer applies selection, crossover and mutation to the prompt/strategy pool, with a KU/KI-guided
diversity control mechanism to prevent premature convergence. The resulting high-fitness artifacts are registered in the
Subclass Brain Registry (SBR) for reuse and cross-agent distillation.
Figure 3: Swarm intelligence framework.
Table 1: Integrated architecture of the swarm intelligence framework
Layer
Modules
Source
Swarm Layer
Prompt Pool + Evaluation
Student EFO design
Fitness Layer
Multi-objective Cost + Dashboard
Eixão-UAM GA framework
Brain Registry
Cognitive Signatures + KU/KI
Superclass Brain model
Meta-LLM Layer
Global Pattern Distillation
Integrated evolution
10


--- Page 11 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Figure 3 shows the evolutionary framework optimization (EFO). A complex problem (purple) is addressed by multiple
human–LLM cognitive pairs (blue), each producing candidate solutions. Within the Swarm Intelligence layer (red
dashed border), these candidates are evolved using a GA module (yellow), applying multi-objective selection, crossover
and mutation. The best evolved solution is fed back to the original problem, forming a closed-loop refinement process.
The table 1 also shows the integrated architecture with four layers of the swarm intelligence framework.
3.4
Superclass Brain
3.4.1
Main Steps Toward Superclass Brain Formation
The Superclass Brain is a higher-order collective intelligence structure emerging from the coordinated evolution of
multiple Subclass Brains. Rather than merging model parameters, it synthesizes cognitive patterns, optimized prompt
strategies and domain-specific heuristics through structured cross-agent interaction. The transition from isolated
Subclass Brains to a unified Superclass Brain proceeds through four interdependent stages, each forming a closed-loop
with preceding layers (Sections 3.2–3.3).
Step 1 – Standardized Cognitive Signatures.
Each Subclass Brain, operating locally (e.g., via Ollama) or in a
user-specific cloud instance, periodically exports an anonymized cognitive signature capturing:
• Curated prompt–response pairs with performance metadata;
• Representative success cases and quantitative task scores;
• Keyword-based cognitive features: KU (Key-Useful) and KI (Key-Irrelevant);
• Behavioral descriptors (e.g., “conservative”, “aggressive”, “exploratory”).
Example cognitive signature:
{
"user": "User_i@GPT",
"domain": "Energy Scheduling",
"KU": ["multi-hop", "weather forecast", "delay tolerance"],
"KI": ["verbose explanation", "poetic summary"],
"Top5_Prompts": [
{"prompt": "...", "response": "...", "score": 0.92},
...
]
}
Step 2 – Subclass Brain Registry (SBR).
A centralized or federated registry stores and indexes these signatures to:
• Enable embedding-based semantic search and retrieval;
• Facilitate behavioral alignment and cross-domain prompt reuse;
• Aggregate high-quality datasets for collective fine-tuning.
The SBR acts as the shared cognitive memory of the ecosystem.
Step 3 – Swarm Alignment Layer.
Following Talebirad et al. Talebirad et al. [2025], multiple Subclass Brains
execute the same task in parallel. Their outputs are reconciled via:
• Multi-agent consensus mechanisms (voting, ranking, averaging);
• Cross-prompt fusion and knowledge distillation;
• Meta-agent coaching with reinforcement learning.
This layer can operate in both cloud-based orchestration platforms and decentralized, privacy-preserving federated
setups.
11


--- Page 12 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Step 4 – Evolutionary Feedback to LLMs.
The distilled swarm-level insights are transformed into:
• High-performance prompt blueprints and style guides;
• Cross-user fine-tuning datasets for domain adaptation;
• Structured reinforcement templates for continual learning.
These artifacts may be fed back to foundation model providers (e.g., OpenAI, Anthropic) via RLHF or RLAIF pipelines,
closing the loop between collective cognitive evolution and model architecture refinement.
3.4.2
Formal Definitions of Subclass Brain, Superclass Brain and SuperBrain
Tasks, prompts and evaluation.
Let T denote a task with input–output specification and let P be the prompt space.
A Worker-LLM executes a prompt p ∈P on T and returns y = Worker-LLM(p, T). For a set of evaluation metrics
{Mk}K
k=1 with weights w ∈RK
+ , PK
k=1 wk = 1, the multi-objective fitness is:
fλ(p; T, Pt) =
K
X
k=1
wk Mk
 Worker-LLM(p, T)

−λtok Ctok(p) −λdiv Ψδ(p; Pt) −λexp Ξ(p),
(11)
where Ctok is token cost, Ψδ is a soft diversity penalty and Ξ is an explainability regularizer (e.g., KU/KI traceability).
Subclass Brain.
A Subclass Brain associated with a high-value user u is the tuple
SBu :=
 u, Hu, Mu, πθ|u

,
(12)
where Hu stores the interaction history, Mu is persistent memory and πθ|u is the LLM’s response policy conditioned
on u. Its cognitive signature is:
cu := g
 Hu, Mu

∈Rd,
(13)
including semantic centroids of top prompts/responses, KU/KI keyword statistics, behavioral tags, reliability ρu ∈[0, 1]
and token cost traces. The Subclass Brain Registry (SBR) stores {cu}u∈U.
Forward and backward evolution.
Forward (user-side): A genetic algorithm evolves prompt populations Pt
under KU/KI constraints and diversity margin δ, producing (p, y, fλ) triplets and updating cu. Backward (LLM-side):
The Meta-LLM distills swarm patterns into a library Π and updates πθ|u or model-side parameters when allowed.
Compactly:
SBRt+1 = SBRt ∪R(Pt+1),
Θt+1 = U(Θt, Πt+1).
(14)
Superclass Brain.
A Superclass Brain is the aggregation of multiple Subclass Brains via a swarm alignment operator
A:
Q(p) ∝
X
u∈U
αu S
 p, cu

,
αu ∝ρu,
(15)
where S scores prompts against cognitive signatures and Q ∈∆(P) is a distribution over prompts. The Meta-LLM
consumes (SBR, Q) to produce a distilled pattern library Π, supporting collective reasoning that exceeds any individual
SBu.
SuperBrain.
The SuperBrain is the coupled system:
SuperBrain :=
 {SBu}u∈U, A, D, U

,
(16)
where A is swarm aggregation, D is distillation into Π and U is the update of policies and knowledge bases. Through
repeated forward (user-side) and backward (LLM-side) evolution across the population, the system self-organizes into a
distributed, adaptive cognitive entity whose problem-solving capacity surpasses both isolated LLM instances and any
single Subclass Brain.
4
Experiment of Forward Iterative Evolution (User-side)
As outlined in Subsection 3.2.1, the Forward Iterative Evolution process applies to UAV take-off sequence scheduling,
where the user (Subclass Brain side) iteratively refines Genetic Algorithm (GA) configurations with LLM assistance.
12


--- Page 13 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Round Robin (RR) as a theoretical benchmark.
In simulations, RR scheduling yielded the shortest average wait
time and lowest worst-case delay, reflecting its fairness and stateless online design. However, real-world constraints–
mission priorities, unpredictable weather, platform capacity limits and regulatory factors–make strict RR enforcement
impractical. Thus, RR serves mainly as an upper-bound benchmark rather than a deployable solution.
Challenges of GA-based optimization.
GAs are well-suited to multi-objective, multi-constraint scheduling, but
practical performance hinges on: (1) generating a representative initial population, (2) defining a fitness function aligned
with operational goals and (3) tuning parameters for variable conditions (e.g., wind speed, mission class). These design
bottlenecks limit human-only approaches in dynamic environments.
LLM-assisted strategy generation.
LLMs (e.g., GPT-4.5, GPT-4o mini, Gemini 2.5 Pro) enhance GA development
by: (1) integrating local knowledge bases (RAG) such as Brasília traffic rules and weather history, (2) adapting to
dynamic inputs (“Golden Quarter” updates), (3) rapidly generating GA variants (vi) through unified prompt templates
and (4) proposing interpretable fitness function alternatives. In this setting, the LLM acts as a cognitive collaborator–
hypothesis generator, experimental designer and rapid feedback provider–rather than a passive coding assistant.
4.1
Experimental Background
To verify the feasibility and applicability of the proposed LLM+GA collaborative optimization approach, we first
developed unified RR and GA versions of the UAV take-off sequence scheduling program, tested under the same
Vertiport scenario. All experiments were conducted between late July and early August 2025 and were organized into
three groups according to their research objectives:
(1) Prompt Variation on the Same LLM Platform.
On the same LLM platform (e.g., Gemini 2.5 Pro), we modified
the sorting optimization objectives and constraints in the Prompt instructions, thereby adjusting the GA parameters
and producing different take-off sequence results. As described in Section 3.2.1, GAv1–v5 correspond to five different
parameter combinations generated on the same platform. This group aims to analyze how varying Prompt conditions
affect optimization results and to compare the relative performance of the resulting solutions.
(2) Cross-Platform Comparison of Results.
Keeping the GA scheduling program and Prompt instructions exactly
the same, we tested different LLM platforms (GPT-4.0, GPT-4.o mini, Grok 3, GPT-5.0 and Claude 4) to generate
GA parameters (GA v6–v11) and observed the resulting differences in scheduling performance. The goal is to assess
the stability and sensitivity of the LLM+GA method across platforms. If the results are broadly similar, it indirectly
supports the method’s universality and feasibility.
(3) Impact of User Expertise and Interaction Depth.
Using the same GA program and Prompt instructions, different
users—with varying backgrounds, expertise and depth of interaction with LLMs—ran the experiments to generate GA
parameters (GA v6–v11). The aim is to investigate how user qualifications and interaction patterns affect optimization
outcomes. The participants were:
• LRS (senior undergraduate in computer science): LRS@Gemini 2.5 Pro (GA v1–v5), LRS@GPT-5.0 (GA v9),
LRS@Claude 4 (GA v11);
• LWG (senior AI and ATC/ATM expert): LWG@GPT-4.0 (GA v7), LWG@Grok 3 (GA v8);
• JRS (high school student): JRS@GPT-5.0 (GA v10).
This experiment set is particularly designed to compare the performance differences between ordinary users and
“valuable users” (highly experienced and frequent, in-depth LLM collaborators) in co-developing optimized scheduling
strategies.
On the other hand, GA v7–v11 were all generated under exactly the same prompt set, ensuring that the LLM platform
and user expertise were the only changing factors. The original prompts, written by the student, are preserved here
without correction to reflect the authentic experimental conditions:
• Prompt 1: Analyze the following code: (whole GA for take-off sequence scheduling code).
• Prompt 2: I want you to modify this code in order for it to run your suggestions in the same way it has run
Gemini’s, that is, I want you to write your suggestions in such a way that it can be tested side by side with the
other one’s, in an independent way and sucessfully analyzed.
• Prompt 3: I want a balanced approach, but minimizing average wait time should be a priority.
13


--- Page 14 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
This strict prompt consistency allows the subsequent analysis (Sections 4.2–4.3) to isolate the effects of LLM platform
variation and user expertise, ensuring that observed differences in GA performance can be attributed primarily to these
factors rather than prompt design.
4.2
GA v1-5 results from a scientific dialogue
The GA refinement followed a three-phase human–AI workflow [Weigang et al., 2025]:
Phase 1: Diagnosis. Baseline GA performance lagged behind RR in both average and worst-case metrics. Numerical
outputs and plots were presented to the LLM, which identified errors (e.g., mislabelled curves) and self-corrected upon
clarification.
Phase 2: Hypothesis generation. Guided by the researcher, the LLM proposed new fitness functions incorporating
fairness, statistical robustness and time-weighted penalties. Five GA variants (v1–v5) were generated and tested in a
single session. Table 2 shows the take-off sequence scheduling results for GA variants v1–v5, with improvement rates
relative to GA v1 [Weigang et al., 2025].
Phase 3: Insight extraction. The LLM assisted in interpreting trade-offs (e.g., GA v5’s 60% reduction in worst-case
delay over v1) and relating them to design decisions, while discarding ineffective variants (e.g., v2, v3).
Table 2: Take-off sequence scheduling results for GA variants v1–v5, with improvement rates relative to GA v1
Metric
RR
GA v1
GA v2
GA v3
GA v4
GA v5
Avg. Wait Time
00m 03s
00m 10s
00m 10s
00m 10s
00m 09s
00m 09s
Max. Wait Time
03m 26s
12m 18s
17m 28s
18m 11s
06m 33s
04m 58s
% No Wait
77.39%
60.00%
60.00%
60.00%
59.99%
59.94%
% Long Wait (>2min)
0.06%
0.31%
0.30%
0.30%
0.27%
0.34%
Improvement in Avg. Wait Time (%)
–
0.00%
0.00%
0.00%
10.00%
10.00%
Improvement in Max. Wait Time (%)
–
0.00%
-42.02%
-47.45%
46.93%
59.82%
Improvement in % No Wait
–
0.00%
0.00%
0.00%
-0.02%
-0.10%
Improvement in % Long Wait
–
0.00%
3.23%
3.23%
12.90%
-9.68%
4.3
Comparison Analysis between GA v1-v5 and GA v6–v11 Results
Tables 2 and 3 present the performance of GA variants v1-5 and v6–v11 in the UAV take-off sequence scheduling
task, measured by four key metrics: Average Wait Time, Maximum Wait Time, % No Wait and % Long Wait (>2 min).
These results confirm the practical engineering applicability of the proposed LLM+GA evolutionary approach: by
modifying prompt instructions and tuning fitness function parameters, the GA can approach near-optimal scheduling
outcomes. For instance, GA v5 (Gemini 2.5 Pro) achieved a Max. Wait Time of 4m58s, while GA v8 (Grok 3.0)
reached 4m56s, both approaching the ideal RR benchmark of 3m26s. This demonstrates that the LLM+GA iterative
process can progressively converge toward optimal take-off sequence scheduling across different LLM platforms.
From another perspective, this experiment introduces a “human cognitive intervention” variable by controlling the LLM
model version and prompt while varying the expertise level and interaction depth of human collaborators. Even with
identical models and prompts, user expertise significantly influenced GA performance:
• Experts (LWG) incorporated fine-grained operational constraints (e.g., ATC rules, wind speed thresholds,
vertiport distribution), directly impacting initial population design and fitness function tuning. This is evident
in GA v7 (GPT-4.0) and GA v8 (Grok 3.0), both achieving Avg. Wait Time of 8s and No Wait rates exceeding
61.8%. Notably, GA v8 reached the best Max. Wait Time (4m56s), a 60% improvement over GA v1.
• Undergraduate student (LRS) emphasized rapid implementation and general-purpose strategies, paying less
attention to complex constraints. Nevertheless, his iterative work with Gemini 2.5 Pro (GA v1–v5) produced
competitive results, with GA v5 achieving a Max. Wait Time of 4m58s.
• Secondary school student (JRS) used more intuitive and less formal constraints, leading the LLM to
different optimization pathways. GA v10 underperformed across most metrics, reflecting a weaker constraint
formulation and reduced parameter tuning.
Additional comparative insight is provided in Table 2 and Table 3, which report improvement rates over GA v1
for each metric. The combined breakdown across GA v1–v11 highlights that:
14


--- Page 15 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Table 3: Take-off sequence scheduling results for GA variants v6–v11, with improvement rates relative to GA v1
Metric
GA v6
GA v7
GA v8
GA v9
GA v10
GA v11
Avg. Wait Time
00m 10s
00m 08s
00m 08s
00m 12s
00m 12s
00m 12s
Max. Wait Time
10m 36s
08m 51s
04m 56s
10m 32s
12m 11s
10m 06s
% No Wait
60.24%
61.87%
61.82%
60.09%
60.11%
60.06%
% Long Wait (>2min)
0.35%
0.16%
0.08%
1.24%
1.16%
1.48%
Improvement in Avg. Wait Time (%)
0.0%
+20.0%
+20.0%
-20.0%
-20.0%
-20.0%
Improvement in Max. Wait Time (%)
+14.1%
+28.2%
+59.9%
+14.8%
+0.95%
+18.0%
Improvement in % No Wait (%)
+0.40%
+3.12%
+3.03%
+0.15%
+0.18%
+0.10%
Improvement in % Long Wait (%)
-12.9%
+48.4%
+74.2%
-300.0%
-274.2%
-377.4%
• Among GA v1–v5, GA v5 (Gemini 2.5 Pro) delivers the best overall performance, with a +59.8% gain in Max.
Wait Time and a +12.9% improvement in % Long Wait, approaching RR’s benchmark in worst-case delay.
• GA v4 also shows a substantial +46.9% improvement in Max. Wait Time, while maintaining Avg. Wait Time
at +10% better than GA v1.
• Among GA v6–v11, GA v8 (LWG@Grok 3) achieves the highest gains in Max. Wait Time (+59.9%) and %
Long Wait (+74.2%), representing the best performance across all variants v1–v11.
• GA v7 (LWG@GPT-4.0) presents a balanced profile, with +20% improvement in Avg. Wait Time and +48.4%
in % Long Wait, second only to GA v8 in extreme delay reduction.
• GA v6 performs close to GA v1 in Avg. Wait Time but shows modest gains in Max. Wait Time.
• GA v9 and GA v10 regress in certain metrics-particularly GA v10, which shows a large negative change in %
Long Wait (-274.2%), indicating significantly more long delays than GA v1.
• GA v11 moderately improves Max. Wait Time but suffers from a similar regression in % Long Wait as GA v9
and GA v10.
These results reinforce three central conclusions: (i) LLM-assisted GA evolution benefits most from expert-driven
parameter design and multi-round iterative refinement, as shown by GA v7 and GA v8; (ii) Aligning the fitness
function with operational goals is more decisive than algorithmic complexity, as evidenced by GA v5’s performance
despite using a simpler structural design; (iii) Although this study is based on a small sample, it spans multiple LLM
platforms (four distinct models) and diverse user profiles (valuable and ordinary users) in a complete prompt–parameter
evolution–take-off scheduling workflow, with consistent performance trends observed across conditions. This provides
a solid foundation for larger-scale, multi-sample experiments in future work.
According to equation 6, these results yield the (prompt, fλ, solution) triplets, which serve as the input for the next stage–
Backward Iterative Evolution on the LLM side–to further refine strategies through autonomous prompt optimization.
5
Framework of Backward Iterative Evolution (LLM-side)
While the forward iterative evolution loop (Section 3.2.1) emphasizes human-driven exploration of prompts and
task-specific heuristics, the backward loop formalizes how LLM-side mechanisms integrate user-derived feedback and
swarm-level signals into the model update process. This section focuses on refining the cost-function weights within a
scheduling framework, thereby illustrating how Subclass Brain heuristics can be aggregated and transferred toward a
collective Superclass Brain. The experiment refines only the weights of the scheduling cost while keeping the inner
optimization strictly deterministic and strongly convex. The cost of a candidate schedule c follows the article’s notation
and semantics:
f(c) = α1 T wait(c) + α2 σT (c) + α3 T95%(c) +
X
k
wk(t) Tpenalty(c),
(17)
where T wait is the average waiting time (system responsiveness), σT is the standard deviation of waiting times (fairness
and dispersion), T95% represents near worst-case delay (implemented through CVaR0.95 but kept in notation for
continuity), wk(t) is a time-varying weight attached to pad k at time t (resource scarcity, priorities or congestion) and
Tpenalty is the aggregated penalty due to contention or constraint violations. The coefficients α1, α2, α3 live on the
simplex and express the operational trade-off among mean, dispersion and tail.
As illustrated in Figure 4, the proposed Bilevel-GA pipeline comprises two tightly coupled blocks. In Block I,
an external genetic algorithm samples and evolves candidate cost functions F(·; α) via a Dirichlet–Multinomial
15


--- Page 16 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
scheme, enabling convex interactions among T wait, σT , T95% and Tpenalty through LSEτ aggregators, while enforcing
α{4} ≥η > 0 to guarantee strong convexity of the inner problem. In Block II, for each generated cost function,
the convex scheduling program in the continuous variables z (with capacity constraints) is solved by a second-order
method to obtain the unique optimum z⋆(α). Performance indicators are then computed and the best candidate retained
according to responsiveness as primary criterion and dispersion/tail penalties as tie-breakers. This setup allows the
backward loop to integrate behavioral signals into cost-function refinements that persist beyond a single user or prompt.
Figure 4: Bilevel GA with Dirichlet–Multinomial weight sampling and LSE-based convex interactions for strongly
convex inner optimization.
5.1
Block I: Strongly Convex Construction
To solve scheduling with guarantees, we move from discrete sequences to a convex relaxation in continuous decision
variables z that induce the waiting-time vector T(z) ∈Rn and per-pad utilizations uk,t(z) ∈[0, umax) under a convex
feasible set Z of flow and capacity constraints. We recast the four primitives of (17) as convex atoms
g1(z) = T wait(z),
g2(z) =
1
√n
P T(z)

2 with P = I −1
n11⊤,
(18)
g3(z) = T95%(z),
g4(z) =
X
k,t
wk(t) ϕ
 uk,t(z)

.
(19)
The mapping for g1 is linear in T(z). The map g2 is a norm of a linear transform and remains convex. The tail proxy g3
is implemented through CVaR0.95 on the observed waiting-time samples but reported as T95% notation. The penalty g4
uses a nondecreasing m-strongly convex function ϕ : [0, umax) →R+ (for instance ϕ(u) = u2/(1 −u)), which injects
curvature through the utilizations uk,t(z). To model interactions among the primitives without leaving the convex
regime, we aggregate any nonempty subset S ⊆{1, 2, 3, 4} by the log-sum-exp operator
HS(z) = LSEτ

{gi(z)}i∈S

= τ log
X
i∈S
exp
 gi(z)/τ

(τ > 0),
(20)
a convex and monotone envelope that smoothly emphasizes the largest elements as τ ↓0. The inner objective is the
convex combination
F(z; α) =
X
S̸=∅
αS HS(z),
αS ≥0,
X
S
αS = 1, α{4} ≥η > 0,
(21)
with M = 15 weights (four singletons, six pairs, four triplets and one quadruplet). Because H{4}(z) = g4(z) is
m-strongly convex and appears with floor weight α{4} ≥η, the composite objective is µ-strongly convex with µ ≥η m
and therefore admits a unique global minimizer. The inner program reads
min
z∈Z F(z; α) subject to 0 ≤uk,t(z) < umax,
(22)
and is solved by a second-order or interior-point routine with backtracking line search.
16


--- Page 17 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
5.2
Block II: Dirichlet–Multinomial Weight Evolution
The outer GA explores the of interaction weights α = (αS)S̸=∅while preserving convexity and curvature. Individuals
carry M genes that sum to one. For initialization or mutation around a parent vector α(par), we draw p ∼Dirichlet(a)
with aj = κ/M (symmetric start) or aj = κ α(par)
j
(local exploration), then sample counts n ∼Multinomial(msamp, p)
and set raw weights ˜αj = nj/msamp. To guarantee α{4} ≥η without rejection we apply the η-safe projection
α = η e{4} + (1 −η) ˜α,
(23)
which keeps nonnegativity and the unit sum. Each GA generation uses tournament selection (size s ∈{2, 3}),
uniform arithmetic crossover on the (probability pc ∈[0.7, 0.9]) followed by the same η-safe projection and
Dirichlet–Multinomial mutation (probability pm ∈[0.1, 0.3]) with concentration κ ∈[1, 10] and sample size
msamp ∈{16, 32, 64}. Population size Npop ∈{40, 60, 80}, generations G ∈[60, 120] and elitism Nelite ∈{1, 2}
complete the controls. The fitness of an individual is the out-of-sample mean waiting time obtained by solving the inner
program, namely fit(α) = T wait
 z⋆(α)

, with ties broken by σT , T95% and Tpenalty so that responsiveness remains the
primary objective and fairness and tail risk are disciplined.
5.3
Validation and Reporting
Data are split into train, validation and test, all stratified by UAV class and weather condition to reflect heterogeneous
regimes. The GA only observes validation scores when ranking individuals. Final reporting uses test and presents
per-condition panels for T wait, σT , T95% and throughput. The expected outcome is a consistent reduction in average
waiting time together with controlled dispersion and tail across adverse scenarios; stability follows from strong convexity
µ ≥η m and the curvature embedded in g4 through the utilization penalty.
5.3.1
Discussion and Relation to Backward Evolution
This bilevel procedure illustrates how LLM-side mechanisms absorb Subclass Brain heuristics and project them into
swarm-level refinements. In contrast to forward evolution, which relies on user-driven exploration, backward evolution
systematically distills swarm-derived feedback into model-side optimization–closing the loop between local interaction
and collective adaptation. Similar iterative refinement paradigms have been explored in Ouyang et al. [2022], Christiano
et al. [2017], Shinn et al. [2023] and Madaan et al. [2023], while the swarm-level integration resonates with Burton
et al. [2024] and knowledge distillation methods [Hinton et al., 2015; Moslemi et al., 2024]. By embedding these
mechanisms into the Superclass Brain registry, we ensure that individual user contributions are not lost but recursively
shape the emergent meta-intelligence.
6
Discussion and Architectural Implications
This section synthesizes the key implications of the proposed SuperBrain paradigm from three complementary per-
spectives. First, Subsection 6.1 examines the engineering significance of the “human creativity amplification +
multi-strategy generation + autonomous evolutionary optimization + explainable results” workflow, highlighting its
potential to accelerate complex system design and optimization in real-world scenarios. Second, Subsection 6.2
provides a comparative analysis between SuperBrain and two landmark large-scale AI paradigms–CAM-Brain and AI
2027–to position the proposed model within the broader trajectory of AI evolution. Finally, Subsection 6.3 explores
architectural recommendations for future LLM/Transformer designs, emphasizing mechanisms such as long-term
user-level memory, multi-agent internal interaction and meta-layer integration to support persistent cognitive evolution
toward AGI-level intelligence.
6.1
Engineering implications of the human–LLM co-evolution paradigm
The proposed paradigm–human creativity amplification + multi-strategy generation + autonomous evolutionary
optimization + explainable results–demonstrates that engineering creativity can be systematically amplified through
large language models (LLMs). By integrating the cognitive strengths of LLMs with the search and optimization
capabilities of Genetic Algorithms (GAs), it offers a coherent framework for tackling complex system design and
optimization challenges. In particular, it addresses two long-standing bottlenecks in GA applications: (i) initialization
of a high-quality candidate population and (ii) design of domain-aligned fitness functions.
In the case study of Urban Air Mobility (UAM) scheduling [Weigang et al., 2025], this paradigm proved capable
of generating, evaluating and refining multiple GA strategies under dynamic constraints, delivering measurable
17


--- Page 18 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
improvements in worst-case performance. The approach is generalizable to other domains requiring high-performance
decision-making under uncertainty.
The key engineering implications are as follows:
1. Accelerating engineering iterations. By automating the generation of initial conditions, fitness functions and
parameter settings, the LLM–GA workflow enables rapid prototyping of diverse strategies. This shortens the
design–test–refine cycle, which is critical in dynamic domains like UAM scheduling where external factors
(e.g., weather, traffic patterns, regulatory constraints) change rapidly.
2. Amplifying human creativity. The paradigm positions the LLM as a cognitive amplifier rather than a passive
code generator. Through contextual understanding and hypothesis generation, LLMs can propose novel
optimization strategies and solution pathways that extend beyond the human designer’s initial search space.
3. Supporting complex system optimization. While demonstrated in UAM scheduling, the approach scales to
broader domains such as intelligent transportation, disaster response and energy management. These domains
typically involve multi-objective optimization with dynamic, interdependent constraints–conditions under
which the LLM+GA framework is particularly effective.
4. Enabling the evolution of collective intelligence. Extending beyond single-task optimization, the paradigm
can be embedded into multi-agent, multi-task ecosystems where multiple Subclass Brains collaborate and
co-evolve strategies. This opens pathways toward city-scale or even global-scale digital twin environments,
redefining AI’s role from task executor to strategic collaborator.
Overall, the human–LLM co-evolution paradigm offers immediate practical value in engineering workflows while
also pointing toward a future where AI systems participate as adaptive, co-creative partners in collective intelligence
architectures. Its broader significance becomes evident when compared with other large-scale AI paradigms, such as
CAM-Brain and AI 2027, as discussed in Section 6.2.
6.2
Comparative Analysis: SuperBrain vs. CAM-Brain vs. AI 2027
To contextualize the proposed SuperBrain framework, we compare it against two influential paradigms in large-scale
artificial intelligence development: the CAM-Brain project [Buller, 1998], a pioneering attempt at hardware-based
neuroevolution and AI 2027 [Kokotajlo et al., 2025], a forward-looking vision of multi-agent collaborative intelligence
for societal foresight. These three frameworks represent distinct approaches to scaling AI capabilities–hardware-centric
autonomous evolution (CAM-Brain), cloud-based multi-agent orchestration (AI 2027) and human–LLM integrated
cognitive evolution (SuperBrain).
Table 4 summarizes their key characteristics across seven dimensions: primary goal, core mechanism, knowledge
aggregation, user involvement, optimization strategy, scalability and innovation points.
As shown in Table 4, SuperBrain distinguishes itself from CAM-Brain and AI 2027 in three notable ways. First, it is
explicitly human-centered: user-specific Subclass Brains capture cognitive signatures, enabling personalized learning
loops and explainable optimization strategies. Second, it adopts a bidirectional evolutionary process–combining
forward user-driven iteration with backward LLM-side adaptation–whereas CAM-Brain focuses on hardware-level
neuroevolution and AI 2027 emphasizes macro-scale agent consensus. Third, SuperBrain incorporates interpretabil-
ity constraints into its optimization pipeline, maintaining traceable links between prompt features (KU/KI) and
performance metrics, which is absent in the other two frameworks.
This comparison underscores that SuperBrain is neither a purely hardware-bound approach nor a purely cloud-based
consensus system. Instead, it integrates human creativity, swarm intelligence and evolutionary optimization into a
coherent architecture, positioning it as a bridge between micro-level cognitive augmentation and macro-scale collective
intelligence.
6.3
Architectural implications for future LLM/Transformer design
While current LLMs have significantly advanced AI adoption and capabilities, their continued healthy evolution requires
sustained architectural optimization and ecosystem development. In recent years, multiple extensions have emerged
to enhance LLM adaptability and performance, such as Fine-Tuning, RAG, RAFT [Zhang et al., 2024; Di Oliveira
et al., 2024] and the Golden Quarter [Bezerra and Weigang, 2025] methodology. Building upon these, the proposed
SuperBrain framework is not only valuable at the application level but will also have natural implications for the
optimization of LLM’s underlying architecture–especially the Transformer [Vaswani et al., 2017]. The following
suggestions outline potential architectural enhancements.
18


--- Page 19 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Table 4: Comparison of SuperBrain, CAM-Brain and AI 2027 frameworks
Dimension
SuperBrain (This work)
CAM-Brain [Buller, 1998]
AI 2027 [Kokotajlo et al.,
2025]
Primary Goal
Human–LLM integrated cog-
nitive evolution; scalable col-
lective intelligence via multi-
layer architecture
Large-scale
evolution
of
neural networks in hardware
(FPGA)
for
autonomous
agents
Predictive and collaborative
AI ecosystem for societal,
economic and scientific fore-
sight
Core Mechanism
Forward
&
backward
iterative
evolution
of
prompts/strategies;
swarm
intelligence layer;
knowl-
edge
distillation
into
Superclass Brain
Cellular Automata Machine
(CAM) hardware evolves
neural architectures using ge-
netic algorithms
Multi-agent
wisdom
ex-
traction through structured
prompt-response
aggrega-
tion and consensus building
Knowledge
Aggre-
gation
Subclass Brain registry +
KU/KI
feature
tracking;
cross-user
evolutionary
feedback
Hardware-level synaptic evo-
lution; direct fitness-based
selection
Cross-domain data fusion
and prompt alignment via
meta-agents
User Involvement
Continuous human–AI co-
creation; user-specific cogni-
tive signatures
Minimal–focus
on
au-
tonomous hardware learning
Human experts as domain
validators and scenario de-
signers
Optimization Strat-
egy
Multi-objective GA with di-
versity control and inter-
pretability constraints
Evolutionary search over net-
work topology and weights
Iterative consensus and re-
finement through multi-agent
simulation
Scalability
Distributed Subclass Brains
with registry-based coordina-
tion; cloud/federated deploy-
ment
Limited by FPGA resources
and simulation environment
Scales via cloud-based multi-
agent orchestration
Innovation Points vs.
Others
User-centered, explainable
swarm evolution;
bidirec-
tional
(forward/backward)
learning loop
Hardware-oriented neuroevo-
lution pioneer; fine-grained
evolutionary control at cir-
cuit level
Socio-technical integration
of AI for foresight and plan-
ning
6.3.1
Long-term, controllable user-level memory interface
Most existing LLMs still have substantial limitations in storing and retrieving long-term user interaction histories. For
example, GPT allows selective retention of certain conversation threads; Grok generally stores only the most recent 25
interactions. None of these systems currently maintain a systematic, controllable and persistent user-level cognitive
memory, nor do they integrate an RLHF/RLHB module that learns from such histories to promote the emergence of a
Superclass Brain.
At the Transformer architectural level, we propose a long-term, controllable user-level memory interface with
versioned local data import/export capabilities. This would enable valuable user-generated historical data to be stored,
retrieved and processed under strict privacy safeguards, supporting sustained learning and personalized cognitive growth
beyond short-term session memory.
6.3.2
Multi-agent internal interaction modules–toward a “wise” LLM
In the early internet era, the intrinsic value of data was underestimated. With the rise of big data, the focus shifted
toward data aggregation and monetization, yet flows remained largely one-way and lacked deep human–machine
co-creation.
In the LLM era, large-scale pre-training leverages big data to create “big models” and enables more natural interaction.
However, despite improvements through fine-tuning and RLHF, post-training evolutionary adaptation–continuous
learning after deployment–remains limited. Users benefit from LLMs, but the reverse flow of new knowledge from
users to LLMs is still minimal.
The Forward/Backward Iterative Evolution for Subclass Brain mechanism proposed in this work addresses this gap
by embedding internal GA or strategy evolution modules and aggregating them via swarm intelligence into a Superclass
Brain, achieving truly bidirectional knowledge exchange:
19


--- Page 20 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Big Data →Big Model (LLM) →Big Wisdom (SuperBrain).
(24)
Under this mechanism, LLMs would gain AGI-like high-level intelligence through sustained human–machine interaction
and accelerated evolution, enabling emergent capabilities in innovation, emotional resonance and human–AI symbiosis.
6.3.3
Pattern distillation and rule synthesis layer (embedding Meta-LLM Layer into Transformer)
The integrated architecture of the swarm intelligence framework (Table 1) defines four layers: Swarm Layer, Fitness
Layer, Brain Registry and Meta-LLM Layer. We propose revisiting the Transformer design to embed these layers
directly within the core architecture, creating an “intelligent Transformer” optimized for long-term evolution.
In such a design, user-side Subclass Brains can execute domain-specific tasks (e.g., UAV vertiport take-off sequence
optimization) while contributing success cases and optimization knowledge back to the LLM core. For example, in
high-dimensional language tasks such as Chinese poetry generation, the system could strengthen its semantic and
aesthetic comprehension, mitigating issues such as the “paradox of poetic intent” and enhancing language intelligence
[Weigang and Brom, 2025].
Potential impact.
These improvements would not only enhance LLM performance and interpretability but also
enable the creation of an open cognitive ecosystem where millions of valuable users contribute to long-term human–AI
co-evolution. Through continuous interaction and wisdom accumulation, this ecosystem could trigger a genuine
intelligence explosion, accelerating the path toward AGI. Although SuperBrain remains an early-stage concept, its
theoretical grounding and engineering feasibility suggest that–with academic and industrial support–it could mature
rapidly in the near future.
6.4
Once-Learning: A Global Perception Paradigm for SuperBrain
The concept of Once-learning was first introduced in 1998 [Weigang, 1998] and further elaborated at the IJCNN
1999 conference, where it was applied to meteorological radar image processing [Weigang and da Silva, 1999].
This paradigm emphasizes completing holistic perception and feature extraction from a single global input during
information processing, rather than relying on multiple, segmented or incremental learning cycles. It is particularly
critical in multi-modal information processing and in the treatment of structurally rich languages such as Chinese, where
characters inherently possess a two-dimensional structure (glyph + semantics) that requires simultaneous perception
and integration of both spatial and contextual dimensions [Weigang et al., 2022].
Compared with subsequent related concepts, Once-learning demonstrates clear chronological precedence. The One-shot
learning approach proposed by Li Fei-Fei et al. in 2003 attracted significant attention in object recognition [Fe-Fei
et al., 2003], eventually inspiring related concepts such as Zero-shot and Few-shot learning, which have played an
important role in the evolution of machine learning, including LLM development [Brown et al., 2020]. Similarly,
the YOLO (You Only Look Once) framework proposed by Redmon et al. [2016] achieved remarkable engineering
success. However, while Few-shot learning and YOLO both enable efficient learning or detection from limited or
single-pass inputs in specific tasks, Once-learning was conceived from the outset as a cross-domain, general-purpose
information processing paradigm–applicable across neural networks, machine learning and even quantum computing
architectures–aligning with the trends of multi-modal processing and multi-dimensional interpretability in AI [Althoff
et al., 2022; Weigang et al., 2022].
Fig. 5 situates the proposed Once-learning paradigm within the broader historical context of related AI concepts,
highlighting its chronological precedence and conceptual continuity.
In the SuperBrain model presented in this work, the integration of Once-learning enhances its viability and impact in
three key aspects:
1. Subclass Brain level: Improves the capability of each human–LLM cognitive dyad to model global infor-
mation, including both context and multi-dimensional imagery, ensuring maximum information absorption
and pattern extraction within a single interaction, while reducing the information loss inherent to segmented,
multi-turn processing.
2. Swarm Intelligence level: When multiple Subclass Brains share strategies or cognitive signatures, Once-
learning enables one-pass fusion of global features from all inputs, as opposed to fragmented feature stacking,
thereby preserving richer cross-user collaborative information.
3. Superclass Brain level: Supports direct holistic pattern matching and reasoning within the global memory
module, enabling cross-task and cross-domain cognitive transfer.
20


--- Page 21 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Year
1998
Once-learning
(Li Weigang)
Holistic perception paradigm
arXiv:quant-ph/9808025
2003
One-shot learning
(Li Fei-Fei et al.)
Object category recognition
ICCV 2003
2016
YOLO
(Redmon et al.)
Real-time object detection
CVPR 2016
2020
Few-shot learning in LLM
(Brown et al.)
GPT-3 scaling
NeurIPS 2020
Figure 5: Timeline of Once-learning and related concepts, highlighting its precedence and conceptual continuity in AI
development.
Looking forward, Once-learning could inspire global tokenization and encoding mechanisms in future
LLM/Transformer architectures, enabling models to perceive and process longer contexts and multi-modal inputs in a
single pass. This capability would not only enhance cross-lingual understanding–particularly for high-information-
density languages such as Chinese–but also strengthen global constraint modeling in complex engineering tasks such as
UAV take-off sequence optimization, 4D flight path conflict resolution and others.
7
Conclusion
This paper introduced the SuperBrain model, a human–LLM co-evolutionary framework that unifies forward and
backward iterative optimization, swarm intelligence and multi-layer cognitive architecture design. By formalizing
the concepts of Subclass Brain and Superclass Brain, the framework shifts from static prompting toward dynamic,
interactive and human-centered collective intelligence.
Our experiments on UAV take-off sequence scheduling within an Urban Air Mobility (UAM) scenario illustrate the
feasibility of this paradigm. The forward evolutionary process, supported by GA variants (v1–v5) co-developed
with LLMs, yielded consistent improvements in responsiveness and worst-case delay, approaching the Round Robin
theoretical bound. Importantly, the findings highlight that alignment of the fitness function with operational goals can
outweigh raw algorithmic complexity. Moreover, the methodology enables the generation of (prompt, fλ, solution)
triplets, providing the basis for backward optimization and thus completing a closed-loop evolutionary cycle.
Contributions. The work offers three main contributions:
1. A conceptual framework for cognitive co-evolution bridging human–LLM interaction and swarm intelligence;
2. An experimental validation in UAM scheduling, showing the practical value of GA-assisted forward evolution;
3. A blueprint for integrating forward and backward evolution into a self-improving, multi-layered architecture.
Future research will extend this foundation along three directions:
1. Backward Evolution Implementation and Validation – Operationalize the theoretical framework of Section 5
through controlled experiments, testing (prompt, fλ, solution) triplets across diverse user–LLM dyads (experts,
university students, high school students) to measure variability, reproducibility and robustness. This direction
resonates with emerging work on human–LLM collaborative evaluation and iterative prompt optimization
[Woelfle et al., 2024].
2. Cross-Domain and Cross-Platform Evaluation – Apply the SuperBrain framework beyond UAM scheduling,
for example in multilingual translation (e.g., poetic intent preservation), energy grid optimization or sensor
scheduling, while systematically comparing outcomes across multiple LLM platforms to assess generalizability
and alignment stability. This aligns with recent studies on domain transferability and multi-agent LLM
ecosystems [Park et al., 2023].
3. Architectural and Memory Extensions – Investigate embedding long-term user-level memory interfaces,
swarm-alignment layers and meta-pattern distillation into Transformer architectures to support persistent
cognitive evolution and scalable aggregation into a functional Superclass Brain. Related advances include
memory-augmented transformers and collective-agent architectures [Borgeaud et al., 2022; Liang et al., 2023].
Ultimately, the vision of SuperBrain is to evolve from distributed Subclass Brain interactions toward an emergent
Superclass Brain, achieving scalable, explainable and ethically aligned collective intelligence.
21


--- Page 22 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Acknowledgments
We gratefully acknowledge the support of CNPq and the encouragement and insightful feedback from our colleagues
and friends. We also note the practical assistance of large language models, including ChatGPT, DeepSeek, Gemini and
Grok, which were used to improve writing clarity and technical precision. While the core ideas and interpretations
remain the responsibility of the authors, these tools provided valuable support in enhancing the overall productivity of
this research.
References
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, and Illia
Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, volume 30, pages
5998–6008, 2017.
Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan, Heyang Yu, Yaxi Lu, Yi-Hsin
Hung, Chen Qian, et al. Agentverse: Facilitating multi-agent collaboration and exploring emergent behaviors. In The
International Conference on Learning Representations (ICLR), 2024.
Khanh-Tung Tran, Dung Dao, Minh-Duong Nguyen, Quoc-Viet Pham, Barry O’Sullivan, and Hoang D Nguyen.
Multi-agent collaboration mechanisms: A survey of llms. arXiv preprint arXiv:2501.06322, 2025.
Cristian Jimenez-Romero, Alper Yegenoglu, and Christian Blum. Multi-agent systems powered by large language
models: applications in swarm intelligence. Frontiers in Artificial Intelligence, 8:1593017, 2025.
Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and Diyi Yang. Dynamic llm-agent network: An llm-agent collaboration
framework with agent team optimization. arXiv preprint arXiv:2310.02170, 2023.
Taylor Webb, Keith J Holyoak, and Hongjing Lu. Emergent analogical reasoning in large language models. Nature
Human Behaviour, 7(9):1526–1541, 2023.
Clara Ziche and Giovanni Apruzzese. Llm4pm: A case study on using large language models for process modeling in
enterprise organizations. In International Conference on Business Process Management, pages 472–483. Springer,
2024.
Yiwei Li, Huaqin Zhao, Hanqi Jiang, Yi Pan, Zhengliang Liu, Zihao Wu, Peng Shu, Jie Tian, Tianze Yang, Shaochen
Xu, et al. Large language models for manufacturing. arXiv preprint arXiv:2410.21418, 2024a.
Li Weigang, Liriam Michi Enamoto, Denise Leyi Li, and Geraldo Pereira Rocha Filho. New directions for artificial
intelligence: human, machine, biological, and quantum intelligence. Frontiers of Information Technology & Electronic
Engineering, 23(6):984–990, 2022.
Daniel Kokotajlo, Scott Alexander, Thomas Larsen, Eli Lifland, and Romeo Dean. Ai 2027. https://ai-2027.com/,
2025. Accessed August 2025.
Xiang Li, Lin Zhao, Lu Zhang, Zihao Wu, Zhengliang Liu, Hanqi Jiang, Chao Cao, Shaochen Xu, Yiwei Li, Haixing
Dai, et al. Artificial general intelligence for medical imaging analysis. IEEE Reviews in Biomedical Engineering,
2024b.
Xinyi Li, Sai Wang, Siqi Zeng, Yu Wu, and Yi Yang. A survey on llm-based multi-agent systems: workflow,
infrastructure, and challenges. Vicinagearth, 1(1):9, 2024c.
Ricardo Barbosa, Ricardo Santos, and Paulo Novais. Collaborative problem-solving with llm: a multi-agent system
approach to solve complex tasks using autogen. In International Conference on Practical Applications of Agents and
Multi-Agent Systems, pages 203–214. Springer, 2024.
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini
Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback.
Advances in neural information processing systems, 35:27730–27744, 2022.
L. Weigang, A. Juliano. Maia, Emilia Stensel, and R. Lucas Siefert. Eixao-uam: Llm-assisted iterative development of a
low-altitude urban air mobility corridor in brasilia. Frontiers of Information Technology and Electronic Engineering,
submitted, 2025.
22


--- Page 23 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Andrezej Buller. Artificial Brain: No Longer Fantasy. Hunan Science & Technology Press, in Chinese, thanslated by
Liu Juan and Li Weigang, 2001, from Proszyrisky i S-ka„ 1998.
Joshua
Rothman.
Two
paths
for
a.i.
https://www.newyorker.com/culture/open-questions/
two-paths-for-ai?, 2025. Accessed August 2025.
Joon Sung Park, Joseph O’Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bernstein.
Generative agents: Interactive simulacra of human behavior. In Proceedings of the 36th annual acm symposium on
user interface software and technology, pages 1–22, 2023.
Gati V Aher, Rosa I Arriaga, and Adam Tauman Kalai. Using large language models to simulate multiple humans and
replicate human subject studies. In International conference on machine learning, pages 337–371. PMLR, 2023.
Ziyan Cui, Ning Li, and Huaikang Zhou. Can ai replace human subjects? a large-scale replication of psychological
experiments with llms. A Large-Scale Replication of Psychological Experiments with LLMs (August 25, 2024), 2024.
Jason W Burton, Ezequiel Lopez-Lopez, Shahar Hechtlinger, Zoe Rahwan, Samuel Aeschbach, Michiel A Bakker,
Joshua A Becker, Aleks Berditchevskaia, Julian Berger, Levin Brinkmann, et al. How large language models can
reshape collective intelligence. Nature human behaviour, 8(9):1643–1655, 2024.
Yashar Talebirad, Ali Parsaee, Vishwajeet Ohal, Amirhossein Nadiri, Csongor Szepesvari, Yash Mouje, and Eden
Redman. Wisdom of the machines: Exploring collective intelligence in llm crowds. In First Workshop on Social
Simulation with LLMs, 2025.
Seyed Pouyan Mousavi Davoudi, Alireza Shafiee Fard, and Alireza Amiri-Margavi. Collective reasoning among llms a
framework for answer validation without ground truth. arXiv preprint arXiv:2502.20758, 2025.
Linbo Luo, Suiping Zhou, Wentong Cai, Malcolm Yoke Hean Low, Feng Tian, Yongwei Wang, Xian Xiao, and Dan
Chen. Agent-based human behavior modeling for crowd simulation. Computer Animation and Virtual Worlds, 19
(3-4):271–281, 2008.
Geoffrey
Hinton.
We
are
raising
a
tiger:
Waic
2025
keynote.
https://pandaily.com/
ai-godfather-geoffrey-hinton-urges-global-ai-cooperation-at-waic-2025-in-shanghai,
2025. Accessed August 2025.
State Council of China. China proposes global framework for benevolent ai at waic 2025. https://example.com/
china-ai-framework-waic2025, 2025. Accessed August 2025.
Deborah Mendes Ferreira, Lucas Pessoa Rosa, Vitor Filincowsky Ribeiro, Flávio de Barros Vidal, and Li Weigang.
Genetic algorithms and game theory for airport departure decision making: Gedman and codman. In International
Conference on Knowledge Management in Organizations, pages 3–14. Springer, 2014.
Subir Halder, Amrita Ghosal, and Mauro Conti. Dynamic super round-based distributed task scheduling for uav
networks. IEEE Transactions on Wireless Communications, 22(2):1014–1028, 2022.
Muhammad Alolaiwy, Tarik Hawsawi, Mohamed Zohdy, Amanpreet Kaur, and Steven Louis. Multi-objective routing
optimization in electric and flying vehicles: a genetic algorithm perspective. Applied Sciences, 13(18):10427, 2023.
James Kennedy. Swarm intelligence. In Handbook of nature-inspired and innovative computing: integrating classical
models with emerging technologies, pages 187–219. Springer, 2006.
Nadia Nedjah and Luiza de Macedo Mourelle. Swarm intelligent systems, volume 26. Springer, 2006.
Kamila B Nogueira, Paulo HC Aguiar, Li Weigang, et al. Using ant algorithm to arrange taxiway sequencing in airport.
International Journal of Computer Theory & Engineering, 6(4):857–361, 2014.
Kskn Venkata Ramana Devi, BS Smitha, Sorabh Lakhanpal, Ravi Kalra, Vandana Arora Sethi, and Sadiq Khader Thajil.
A review: Swarm robotics: Cooperative control in multi-agent systems. In E3S Web of Conferences, volume 505,
page 03013. EDP Sciences, 2024.
Paul F Christiano, Jan Leike, Tom B Brown, Miljan Martic, Shane Legg, and Dario Amodei. Deep reinforcement
learning from human preferences. In Advances in Neural Information Processing Systems (NeurIPS), pages 4299–
4307, 2017.
23


--- Page 24 ---
LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain
A PREPRINT
Noah Shinn, Federico Cassano, Arjun Gopinath, Shunyu Zhang, Chelsea Finn, and Jiajun Wu. Reflexion: Language
agents with verbal reinforcement learning. arXiv preprint arXiv:2303.11366, 2023.
Aman Madaan, Yuchen Zhou, Uri Alon, Maor Ivgi, Shuyan Zhang, Boaz Barak, Graham Neubig, Tianyi Yang, Mohit
Bansal, Jonathan Clark, et al. Self-refine: Iterative refinement with self-feedback. Advances in Neural Information
Processing Systems (NeurIPS), 2023.
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.
Distilling the knowledge in a neural network.
arXiv preprint
arXiv:1503.02531, 2015.
Amir Moslemi, Anna Briskina, Zubeka Dang, and Jason Li. A survey on knowledge distillation: Recent advancements.
Machine Learning with Applications, 18:100605, 2024.
Tianjun Zhang, Shishir G Patil, Naman Jain, Sheng Shen, Matei Zaharia, Ion Stoica, and Joseph E Gonzalez. Raft:
Adapting language model to domain specific rag. In First Conference on Language Modeling, 2024.
Vinícius Di Oliveira, Yuri Façanha Bezerra, Li Weigang, Pedro Carvalho Brom, and Victor Rafael R Celestino. Slim-raft:
A novel fine-tuning approach to improve cross-linguistic performance for mercosur common nomenclature. In
Proceedings of the 20th International Conference on Web Information Systems and Technologies (WEBIST 2024),
pages 234–241, 2024.
Yuri Façanha Bezerra and Li Weigang. Llmquoter: enhancing rag capabilities through efficient quote extraction from
large contexts. In Proceedings of the 17th International Conference on Agents and Artificial Intelligence, volume 3,
pages 1335–1342. Scitepress, 2025.
Li Weigang and Pedro Carvalho Brom. The paradox of poetic intent in back-translation: Evaluating the quality of large
language models in chinese translation. arXiv preprint arXiv:2504.16286, 2025.
Li Weigang. A study of parallel self-organizing map. arXiv preprint quant-ph/9808025, 1998.
Li Weigang and Nilton Correia da Silva. A study of parallel neural networks. In IJCNN’99. International Joint
Conference on Neural Networks. Proceedings (Cat. No. 99CH36339), volume 2, pages 1113–1116. IEEE, 1999.
Li Fe-Fei et al. A bayesian approach to unsupervised one-shot learning of object categories. In proceedings ninth IEEE
international conference on computer vision, pages 1134–1141. IEEE, 2003.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan,
Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural
information processing systems, 33:1877–1901, 2020.
Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Unified, real-time object
detection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 779–788, 2016.
Lucas Althoff, Mylène CQ Farias, and Li Weigang. Once learning for looking and identifying based on yolo-v5 object
detection. In Proceedings of the Brazilian Symposium on Multimedia and the Web, pages 298–304, 2022.
Tim Woelfle, Julian Hirt, Perrine Janiaud, Ludwig Kappos, John PA Ioannidis, and Lars G Hemkens. Benchmarking
human–ai collaboration for common evidence appraisal tools. Journal of Clinical Epidemiology, 175:111533, 2024.
Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van den
Driessche, Jean-Baptiste Lespiau, Jonathan Godwin, et al. Improving language models by retrieving from trillions of
tokens. arXiv preprint arXiv:2112.04426, 2022.
Weizhe Liang, Yizhong Zhang, Yuchen Zhang, Zhiyuan Shao, Huan Zhang, Hongyu Zhou, Yue Yu, Jiayi Li, Kunpeng
Zhang, et al. Taskmatrix.ai: Completing tasks by connecting foundation models with millions of apis. arXiv preprint
arXiv:2303.16434, 2023.
24
