--- Page 1 ---
Preprint. Under review.
Lyria: A Genetic Algorithm-Driven Neuro-Symbolic Reasoning
Framework for LLMs
Weizhi Tang, Kwabena Nuamah, Vaishak Belle
Artificial Intelligence Applications Institute
The University of Edinburgh
{Weizhi.Tang,k.nuamah,vbelle}@ed.ac.uk
Abstract
While LLMs have demonstrated impressive abilities across various domains, they
struggle with two major issues. The first is that LLMs trap themselves into local
optima and the second is that they lack exhaustive coverage of the solution space.
To investigate and improve these two issues, we propose Lyria, a neuro-symbolic
reasoning framework building on the integration of LLMs, genetic algorithms,
and symbolic systems, comprising 7 essential components. Through conducting
extensive experiments with 4 LLMs across 3 types of problems, we demonstrated
the efficacy of Lyria. Furthermore, with 7 additional ablation experiments, we
further systematically analyzed and elucidated the factors that affect its performance.
In addition, based on Lyria, we extend the ideas to the fine-tuning process of LLMs
and introduce LAFT which enables a weaker model to imitate the reasoning
process of a stronger model that reason under the Lyria reasoning framework. We
demonstrate that the significant effectiveness of LAFT by conducting extensive
experiments against 9 constructed baselines. We finally reveal the limitations and
provide insights into future directions.
1
Introduction
Large Language Models (LLMs) have demonstrated versatile abilities across various domains and
tasks, benefiting from the large-scale corpora they are trained on (Jiang et al., 2024; Valmeekam
et al., 2023; Pan et al., 2023; Tang & Belle, 2024). Nevertheless, their performance remains inferior,
especially when faced with complex problems, which are typically characterized by their immense
solution spaces, precise constraint satisfaction, multi-objective optimization, domain-specific prior
knowledge, and so on, such as reasoning (Mittal et al., 2025), planning (Valmeekam et al., 2023),
theorem proving (Song et al., 2025), code generation (Jiang et al., 2024), etc. In this work, we
primary consider two major issues that the LLMs encounter in their reasoning process given complex
reasoning problems. The first is that LLMs trap themselves into local optima and the second is that
they lack exhaustive coverage of the solution space.
Genetic algorithms, a subset of evolutionary algorithms inspired by natural selection, powered by
their essential operators such as selection, crossover, and mutation, are commonly used to approach
optimal solution by iteratively optimizing the population through generations (Katoch et al., 2021;
Gendreau et al., 2010; Koza, 1994). They have been studied and applied across diverse fields, such as
reasoning (Hameed et al., 2023; SchÂ¨afer & Schulz, 2015; Tamaddoni-Nezhad & Muggleton, 2001),
planning (Burns et al., 2024; Elshamli et al., 2004), combinatorial optimization (Shao et al., 2023;
Kobler, 2009), and symbolic regression (Bertschinger et al., 2024; Ashok et al., 2020), primarily due
to their ability to escape local optima and conduct systematical searches, thereby enabling them to
approach global optimal solutions (Katoch et al., 2021). Therefore, integrating the genetic algorithm
with LLMs is a promising and natural step to eliminate the first issue.
However, for the second issue, one may argue that we could leverage Retrieval-Augmented Generation
(RAG) to alleviate the issue by fetching additional information from external sources, thereby partially
enriching the solution space (Lewis et al., 2020; Gao et al., 2024). Nevertheless, when facing problems
with an exponentially growing solution space, RAG normally fail to retrieve meaningful information
since even external sources may not contain the solution space of the problems. For example, in the
Traveling Salesman Problem (TSP), given ğ‘›cities, the size of its solution space reaches (ğ‘›âˆ’1)!
2
. This
1
arXiv:2507.04034v2  [cs.AI]  9 Feb 2026


--- Page 2 ---
Preprint. Under review.
issue not only happens in problems like TSP, but also could happen in problems like code generation,
planning, and so on. To eliminate this issue, we believe that leveraging symbolic systems, which
typically have complete coverage of solution spaces, is a promising approach.
Therefore, by leveraging both genetic algorithms and symbolic systems, we introduce a neuro-symbolic
reasoning framework called Lyria, consisting of 7 essential components, aiming to enhance the
capability of LLMs to tackle complex reasoning problems. To evaluate its effectiveness, we select
3 types of combinatorial reasoning problems, for the reason that they are typically characterized
by immense solution space and they are easily synthesized to avoid data pollution, and we conduct
experiments using 4 LLMs on them against 2 constructed baselines, demonstrating its significant
performance improvements. Furthermore, we also executed 7 additional ablation experiments to
analyze and reveal the impact of various factors on its performance. In addition, based on Lyria, we
further propose LAFT, a novel method which fine-tunes a weaker model to imitate the reasoning
process of a stronger model that leverages Lyria as its reasoning framework. By conducting extensive
experiments, we show that LAFT achieves significant performance improvements across 9 constructed
baselines.
We summarize our contributions as follows:
1. We propose Lyria, a neuro-symbolic reasoning framework by integrating LLMs with genetic
algorithms and symbolic systems, for complex reasoning problems, and demonstrated its
effectiveness through evaluations with 4 LLMs on 3 types of combinatorial reasoning
problems;
2. We conduct 7 additional ablation experiments to comprehensively analyze the impact of
various factors on the performance of Lyria and demonstrate the indispensability of each
component for Lyria;
3. Based on Lyria, we further propose LAFT, a novel method to improve the performance of
a weaker models by enabling it to imitate the reasoning process of a stronger model that
reasons in the framework of Lyria, and demonstrate that LAFT can lead to consistent and
significant performance improvements by conducting experiments against 9 constructed
baselines.
2
Related Work
Recently, research on the integration of LLMs and genetic algorithms has begun to emerge, demon-
strating promising results across a variety of tasks.
The integration of LLMs and genetic algorithms is used to tackle specific problems. Through
synergistically combining LLMs with evolutionary algorithms, EvoPrompt (Guo et al., 2024)
shows its efficacy to optimize discrete prompt generation, outperforming existing automatic prompt
generation methods across various LLMs and tasks. In addition, Morris et al. (2024) propose a novel
framework which leverages LLMs to autonomously evolve neural network architectures through
feedback-driven code modifications via Evolution of Thought and Character Role Play, while Nasir
et al. (2024) propose a method, LLMatic, that integrates the code-generation capabilities of LLMs
and Quality Diversity algorithms which are a subset of evolutionary algorithms (Cully & Demiris,
2017; Pugh et al., 2016) to efficiently discover network architectures. Furthermore, Stein & BÂ¨ack
(2025) propose LLaMEA, Liu et al. (2024) propose EoH, and Ye et al. (2024) propose ReEvo,
to leverage LLMs to automatically construct and generate code of novel metaheuristic algorithms.
Moreover, Pinna et al. (2024) propose an approach based on LLMs and Genetic Improvement to
improve code generation. Furthermore, Hemberg et al. (2024) propose and demonstrate the way to
replace traditional genetic programming operators with LLM-based operators to evolve code. In
addition, Tang et al. (2025) introduce a hybrid LLM-driven genetic algorithm designed specifically
to improve the ability of LLMs in the task of context-free grammar generation and demonstrated
its significant effectiveness and potential. Nevertheless, these prior works differ from our proposed
method, Lyria, in either methodology or perspectives of analysis. Most existing works mainly leverage
the integration of LLMs and genetic algorithms to tackle a specific problem, rather than proposing
an LLM-based neuro-symbolic reasoning framework that integrates LLMs, genetic algorithms, and
symbolic systems, to explore and eliminate the two main issues.
2


--- Page 3 ---
Preprint. Under review.
In addition, the integration of LLMs and genetic algorithms is also used in the process of fine-tuning
LLMs. Majumdar et al. (2025) introduce Genetic Instruct to improve the code generation ability
of LLMs by using genetic algorithm to generate new code instructions given a small seed of initial
population and fine-tuning models based on the new code instructions. Furthermore, Qiu et al. (2025)
leverages Evolution Strategies (ES) to update parameters in the fine-tuning process and demonstrate
that ES can be scaled up to fine-tune LLMs in billions parameter size and outperform existing
Reinforcement Learning-based fine-tuning method in multiple aspects. In addition, Han et al. (2025)
propose a method called Genetic Prompt, which treats text semantic attributes as genes and using
LLMs as genetic operators to synthesize data closer to real-world to fine-tune models, and demonstrate
it can boost the model performance. However, although several prior works incorporate genetic
algorithms in the fine-tuning process of LLMs, our proposed fine-tuning approach, LAFT, remains
fundamentally different. LAFT is closely related to knowledge distillation, specifically reasoning
patterns distillation, where a weaker model is trained to approach the reasoning behavior of a stronger
model (Xu et al., 2024). Prior works proposes several reasoning patterns distillation methods (Hsieh
et al., 2023; Zhu et al., 2024; Xu et al., 2024; Chen et al., 2025). For example, Hsieh et al. (2023)
introduce a method that uses stronger LLMs to generate step-by-step rationales and then train smaller
models with those rationales and labels. Zhu et al. (2024) propose Program-aided Distillation, which
replaces CoT with programs, enabling automatic verification and filtering of incorrect reasoning
processes, and then fine-tune smaller models on these reasoning processes data to improve reasoning
performance of smaller models. However, distinct from previous reasoning patterns distillation
methods, in LAFT, a model is fine-tuned in the way of imitating the reasoning processes of a stronger
model which operates under the proposed reasoning framework Lyria, by which it not only enables
smaller models imitate the reasoning processes of stronger models, but also mitigates the two issues
mentioned before.
3
Benchmarks
To evaluate Lyria, we selected 3 types of combinatorial reasoning problems, i.e., Sudoku (Yato & Seta,
2003), Traveling Salesman Problem (Papadimitriou & Steiglitz, 1976), and Graph Coloring (Gent
et al., 2017)1. All the 3 types of problems are characterized by their vast solution spaces and stringent
constraints satisfaction requirements, thereby supposed to pose significant challenges to LLMs. It is
worth noting that Lyria is not restricted to these problems, and the selection of them is only motivated
by their complexity and the convenience of generating uncontaminated data. We describe each
problem, their metrics, and the challenges generation in the following sections.
3.1
Sudoku
Sudoku (SK) is a number-placement puzzle played on a 9 Ã— 9 grid, where each cell must be assigned a
digit from 1 to 9. The grid is partitioned into nine 3 Ã— 3 subgrids. A correct Sudoku solution requires
that each row, column, and subgrid contains all digits from 1 to 9 exactly once. The puzzle is typically
presented with some cells pre-filled, and a given solution must respect the constraints.
Let ğ‘ â€² denote a SK solution, defined as a 9 Ã— 9 matrix with each cell filled:
ğ‘ â€² =
ï£®ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°
ğ‘¢1,1
ğ‘¢1,2
ğ‘¢1,3
Â· Â· Â·
ğ‘¢1,9
ğ‘¢2,1
ğ‘¢2,2
ğ‘¢2,3
Â· Â· Â·
ğ‘¢2,9
ğ‘¢3,1
ğ‘¢3,2
ğ‘¢3,3
Â· Â· Â·
ğ‘¢3,9
...
...
...
...
...
ğ‘¢9,1
ğ‘¢9,2
ğ‘¢9,3
Â· Â· Â·
ğ‘¢9,9
ï£¹ï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£»
.
Let S denote the solutions to all SK problems. We mainly employ 3 metrics to assess the quality of
the generated solutions:
â€¢ Correctness: The correctness of ğ‘ â€² is defined as CR(sâ€²), which returns 1 if ğ‘ â€² satisfies all
the row, column, and subgrids constraints, otherwise 0. Formally, let ğ‘…(ğ‘ â€²,ğ‘–) denote a set
1We use the term combinatorial reasoning problems, rather than using NP-hard, NP-complete, or combinatorial
optimization problems, to emphasize their natural as complex reasoning problems in this work.
3


--- Page 4 ---
Preprint. Under review.
of values at row ğ‘–, ğ¶(ğ‘ â€², ğ‘—) denote a set of values at column ğ‘—, and ğµ(ğ‘ â€², ğ‘˜) denote a set of
values in the ğ‘˜-th 3 Ã— 3 subgrid. The CR(ğ‘ â€²) is given as:
CR(ğ‘ â€²) =
ï£±ï£´ï£´ï£²
ï£´ï£´ï£³
1,
if (âˆ€ğ‘–, |ğ‘…(ğ‘ â€²,ğ‘–)| = 9) âˆ§(âˆ€ğ‘—, |ğ¶(ğ‘ â€², ğ‘—)| = 9) âˆ§(âˆ€ğ‘˜, |ğµ(ğ‘ â€², ğ‘˜)| = 9)
âˆ§(âˆ€ğ‘–, ğ‘—, ğ‘ â€²[ğ‘–, ğ‘—] âˆˆ{1, . . . , 9})
0,
otherwise
We report the correctness percentage of S as Sudokuğ¶ğ‘….
â€¢ Score: Evaluating a SK solution solely based on its correctness provides an overly narrow
perspective, since when an LLM fails to provide a fully correct solution, it becomes
challenging to observe and analyze whether it yields a high-quality albeit suboptimal solution
and how closely it approximates the optimal solution. Thus, we define the score of a given
ğ‘ â€² as the average of percentages of constraints sanctification of rows, columns, and subgrids.
Higher score means ğ‘ â€² approaches more to the optimal solution. Formally, let I(ğ‘‹) be an
indicator function that returns 1 if ğ‘‹= {1, . . . , 9}, otherwise 0. Let Iğ‘…
ğ‘ â€² = Ã9
ğ‘–=1 I(ğ‘…(ğ‘ â€²,ğ‘–)),
Iğ¶
ğ‘ â€² = Ã9
ğ‘—=1 I(ğ¶(ğ‘ â€², ğ‘—)), and Iğµ
ğ‘ â€² = Ã9
ğ‘˜=1 I(ğµ(ğ‘ â€², ğ‘˜)). We have SC(ğ‘ â€²) as:
SC(ğ‘ â€²) = 100 Â· 1
27

Iğ‘…
ğ‘ â€² + Iğ¶
ğ‘ â€² + Iğµ
ğ‘ â€²

,
We report the average of S as Sudokuğ‘†ğ¶.
â€¢ Penalized Score: To prevent a solution from resorting to extreme strategies to improve
correctness, such as boosting row and column correctness while sacrificing subgrid correct-
ness, and thus ending up far from the optimal solution despite a seemingly high score, we
adopt the geometric mean to mitigate the impact of these extreme values on the overall score.
Formally, we have PS(ğ‘ â€²) as:
PS(ğ‘ â€²) = 100 Â·
3
âˆšï¸„
Iğ‘…
ğ‘ â€²
9 Â· Iğ¶
ğ‘ â€²
9 Â· Iğµ
ğ‘ â€²
9 ,
We report the average penalized score of S as Sudokuğ‘ƒğ‘†.
To generate a set of SK challenges for evaluation, we fixed the number of unfilled cells to 40 in each
puzzle, generating a total of 50 distinct 9 Ã— 9 SK instances.
3.2
Graph Coloring
Graph Coloring (GC) is the task of assigning colors to the vertices of a given graph such that no two
adjacent vertices share the same color. Formally, given a graph ğº= (ğ‘‰, ğ¸) and a set of ğ‘˜distinct
colors, the goal is to find a function ğ‘“: ğ‘‰â†’{0, 1, . . . , ğ‘˜âˆ’1} such that for any edge (ğ‘¢, ğ‘£) âˆˆğ¸,
ğ‘“(ğ‘¢) â‰ ğ‘“(ğ‘£).
Let ğ‘“â€² be a GC solution. Let F denote the solutions to all GC problems. We mainly employ 4 metrics
to evaluate the solution quality:
â€¢ Correctness: The correctness of ğ‘“â€² indicates whether it assigns colors to each vertex such
that no adjacent vertex has the same color. Formally:
CR( ğ‘“â€²) =
1,
if  âˆ€ğ‘£âˆˆğ‘‰, ğ‘“â€²(ğ‘£) âˆˆ{ğ‘–}ğ‘˜âˆ’1
ğ‘–=0
 âˆ§ âˆ€(ğ‘¢, ğ‘£) âˆˆğ¸, ğ‘“â€²(ğ‘¢) â‰ ğ‘“â€²(ğ‘£),
0,
otherwise.
We report the correctness percentage for F as GCğ¶ğ‘….
â€¢ Conflict Ratio We define the conflict ratio as the ratio of edges whose endpoints share the
same color. Define an indicator function:
Iğ¶ğ¹( ğ‘“â€², ğ‘¢, ğ‘£) =
1,
if ğ‘“â€²(ğ‘¢) = ğ‘“â€²(ğ‘£),
0,
otherwise.
The conflict ratio CF for a given ğ‘“â€² is given as:
CF( ğ‘“â€²) =
Ã
(ğ‘¢,ğ‘£) âˆˆğ¸Iğ¶ğ¹( ğ‘“â€², ğ‘¢, ğ‘£)
|ğ¸|
.
We report the average of F as GCğ¶ğ¹.
4


--- Page 5 ---
Preprint. Under review.
â€¢ Score: We define the score of a given ğ‘“â€² as the percentage of edges colored properly as:
Score( ğ‘“â€²) = (1 âˆ’CF( ğ‘“â€²)) Â· 100.
We report the average of F as GCğ‘†ğ¶.
â€¢ Penalized Score: The penalized score is a modified score that penalizes solutions using too
many colors, e.g., coloring each vertices with a distinct color. Let ğ‘˜â€² = |{ ğ‘“â€²(ğ‘£) : ğ‘£âˆˆğ‘‰}| be
the total number of distinct colors used. Formally, we have PS as:
PS( ğ‘“â€²) =
ï£±ï£´ï£´ï£²
ï£´ï£´ï£³
0,
if ğ‘˜â€² â‰¥|ğ‘‰|,
Score( ğ‘“â€²),
if ğ‘˜â€² â‰¤ğ‘˜,
Score( ğ‘“â€²) Â· ğ‘…,
otherwise.
where ğ‘…= (1 âˆ’ğ‘˜â€² âˆ’ğ‘˜
|ğ‘‰| âˆ’ğ‘˜) is the penalty ratio for the score. We report the average of F as
GCğ‘ƒğ‘†.
To generate a set of GC challenges for evaluation, we fixed the number of vertices |ğ‘‰| to 9, the size of
the color set ğ‘˜to 3 and the edge connection probability to 0.5. This process yields 50 distinct GC
instances.
3.3
Traveling Salesman Problem
Traveling Salesman Problem (TSP) is a route-finding task defined on a set of cities and pairwise
distances between them.
Formally, let ğº= (ğ‘‰, ğ¸) be a complete undirected graph in which
ğ‘‰= {ğ‘£1, . . . , ğ‘£ğ‘›} is a set of vertices of the graph and ğ¸= {(ğ‘¢, ğ‘£) : ğ‘¢, ğ‘£âˆˆğ‘‰, ğ‘¢â‰ ğ‘£} is a set of edges.
A distance function ğ‘‘: ğ‘‰Ã— ğ‘‰â†’Râ‰¥0 assigns each edge (ğ‘¢, ğ‘£) a nonnegative distance ğ‘‘(ğ‘¢, ğ‘£). The
goal in the TSP is to find a Hamiltonian cycle in ğºwhose total distance is minimized. Formally,
a route ğ‘Ÿis any permutation ğœ‹of ğ‘‰, with the first element also appearing at the end, forming a
cycle, defined as a sequence ğ‘Ÿ= [ğ‘£ğœ‹(1), . . . , ğ‘£ğœ‹(ğ‘›), ğ‘£ğœ‹(1)]. The total distance of this route is given as:
D(ğ‘Ÿ) = ğ‘‘(ğ‘£ğœ‹(ğ‘›), ğ‘£ğœ‹(1)) + Ãğ‘›âˆ’1
ğ‘–=1 ğ‘‘(ğ‘£ğœ‹(ğ‘–), ğ‘£ğœ‹(ğ‘–+1)). Thus, the goal of TSP is to determine the route ğ‘Ÿâˆ—
in all possible routes ğ‘…such that âˆ€ğ‘Ÿâˆˆğ‘…, D(ğ‘Ÿ) â‰¥D(ğ‘Ÿâˆ—), i.e., ğ‘Ÿâˆ—= min
râˆˆğ‘…D(ğ‘Ÿ).
Let ğ‘Ÿâ€² âˆˆğ‘…be a TSP solution and ğ‘Ÿâ€² = [ğ‘£â€²
1, ğ‘£â€²
2, . . . , ğ‘£â€²
|ğ‘‰|+1]. Let T denote the solutions to all problems.
We mainly employ 4 metrics to analyze the solution quality:
â€¢ Correctness: The correctness of ğ‘Ÿâ€² indicates whether it is the shortest route while starting
and ending at ğ‘£â€²
1. Formally:
CR(ğ‘Ÿâ€²) =
ï£±ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´ï£³
1,
if (ğ‘Ÿâ€² = min
ğ‘Ÿâˆˆğ‘…D(r))
âˆ§(ğ‘£â€²
1 = ğ‘£â€²
|ğ‘£|+1)
âˆ§(|ğ‘Ÿâ€²| = |ğ‘‰| + 1)
0,
otherwise.
We report the average of T as TSPğ¶ğ‘….
â€¢ Excess Distance Multiplier: The excess distance multiplier of ğ‘Ÿâ€² quantifies the factor by
which a solutionâ€™s distance exceeds the optimal distance ğ·(ğ‘Ÿâˆ—). Formally:
EDM(ğ‘Ÿâ€²) = min

3, ğ·(ğ‘Ÿâ€²) âˆ’ğ·(ğ‘Ÿâˆ—)
ğ·(ğ‘Ÿâˆ—)

The value of 0 indicates the solutionâ€™s distance matches the optimal distance, while a value
of 1 means the solution is twice as long as the option distance and so on. We make the value
saturates at 3 as a default and maximum. We report the average of T as TSPğ¸ğ·ğ‘€.
â€¢ Missing Cities: A given route ğ‘Ÿâ€² may skip some cities or revisit others. To measure this, we
count the number of distinct cities that are missed from the solution. Formally:
MC(ğ‘Ÿâ€²) = |ğ‘‰| âˆ’|{ğ‘£| ğ‘£âˆˆğ‘Ÿâ€²}|.
We report the average of T as TSPğ‘€ğ¶.
5


--- Page 6 ---
Preprint. Under review.
Question
Fitness
Evaluator
Answer
Initialization
Deduplicator
Selector
Crossover
Operator
Mutation
Operator
Experience
Pool
Error
Detector
Figure 1: The Lyria reasoning framework, consisting of 7 essential components, i.e., Error Detector,
Deduplicator, Experience Pool, Fitness Evaluator, Selector, Crossover Operator, and Mutation
Operator, enables evolving candidate solutions through generations to obtain superior solution.
â€¢ Penalized Score The penalized score for ğ‘Ÿâ€² measures how closely it approximates ğ‘Ÿâˆ—,
while applying penalties to the exceeded distance and also the omission of cities. Let
Dist = 1 âˆ’EDM(ğ‘Ÿâ€²)
3
and Miss = 1 âˆ’MC(râ€²)
|ğ‘‰| . Formally:
PS(ğ‘Ÿâ€²) = ğ¼ğ‘†Â· min(Dist, Miss)
where ğ¼ğ‘†= 100 is the initialized score. We report the average of T as TSPğ‘ƒğ‘†.
To generate a set of TSP challenges for evaluation, for each TSP problem, we fixed the number of
cities |ğ‘‰| to 10. The coordinate (ğ‘¥ğ‘£, ğ‘¦ğ‘£) of city ğ‘£is sampled as ğ‘¥, ğ‘¦ğ‘–.ğ‘–.ğ‘‘
âˆ¼U[0, 100] and the distance
between cities are calculated by Euclidean distance. A start and end city is fixed and noted as ğ‘£1. An
optimal reference route is then derived by exhaustively enumerating all Hamiltonian cycles beginning
and ending at ğ‘£1. This procedure is repeated to produce 50 distinct TSP instances.
4
The Lyria Reasoning Framework
4.1
Methodology
The Lyria reasoning framework comprises 7 primary components: Error Detector, Deduplicator,
Experience Pool, Fitness Evaluator, Selector, Crossover Operator, and Mutation Operator. We begin
with a high-level overview of the framework, followed by a detailed elucidation of each component in
Section 4.1.1, Section 4.1.2, Section 4.1.3, Section 4.1.4, Section 4.1.5, Section 4.1.6, Section 4.1.7,
respectively. Subsequently, we provide and explain the pseudo code in Section 4.1.8.
Initially, an LLM generates a population of candidate solutions. Every candidate is scored by the
Fitness Evaluator and analyzed by the Error Detector. Evolution then proceeds in generations: a
fraction of the lowest fitness individuals, determined by the replay rate, is replaced by the highest
fitness candidates drawn from the Experience Pool; the Selector chooses appropriate parents; the
Crossover Operator, guided by parental errors, generates offspring until the population size is restored;
and the Mutation Operator modifies each candidate according to its own errors. After initialization
and every crossover and mutation operations, the Deduplicator removes duplicates to maintain
diversity. The updated population is re-evaluated and advanced in the next generation, until reaching
the predetermined maximum number of generations.
4.1.1
Error Detector
Inspired by Reflexion (Shinn et al., 2023) and Self-Refinement (Madaan et al., 2023), whenever a new
candidate is generated, the error detector (ED) identifies its errors up to a predefined maximum detected
errors, enabling crossover and mutation operators to learn from past mistakes, thereby promoting
6


--- Page 7 ---
Preprint. Under review.
the generation of improved candidates. In Lyria, we proposed two types of EDs: Verifier-based ED
(VED) and LLM-based ED (LED). For both of the two types of EDs, they are mainly consisted of two
error types, i.e., Syntax Error (XE) which indicates whether the syntax or format of a given solution is
correct, and Semantic Error (SE) which reveals the information of the incorrect parts of the solution.
VED
A VED invokes external symbolic systems, e.g., parsers, compilers, test suites, model checkers,
etc., to examine a candidate against formal criteria and to emit deterministic and unbiased diagnoses.
We designed specific VEDs for each problem type:
â€¢ SK VED: Let ğ‘ â€² be a SK solution. With respect to the XE of SK, noted as XESK, for any
generated SK solution by LLMs, we require it to be in the format of a 9 Ã— 9 matrix, with
each cell separated by a space, as described in Prompt Template 13. If the format is correct,
XESK(ğ‘ â€²) = 0, otherwise XESK(ğ‘ â€²) = 1. With respect to the SE of SK, noted as SESK, it
consists of indices of cells that do not satisfy its row, column, and subgrid constraints. We
define it as: SESK(ğ‘ â€²) = {(ğ‘–, ğ‘—, ğ‘¡) | ğ‘–, ğ‘—âˆˆ{1, . . . , 9} âˆ§ğ‘¡âˆˆ{0, 1, 2}}}, where ğ‘–, ğ‘—are row
and column index respectively and ğ‘¡indicates the unsatisfied constraint, in which 0 indicates
row, 1 means column, and 2 refers to subgrid.
â€¢ GC VED: Let ğ‘“â€² be a GC solution, represented as a sequence F â€² = [ğ‘œâ€²
1, ğ‘œâ€²
2, . . . , ğ‘œâ€²
|ğ‘‰|]
where ğ‘œğ‘–= ğ‘“â€²(ğ‘£ğ‘–) is a color assignment for ğ‘£ğ‘–âˆˆğ‘‰. With respect to the XE of GC,
noted as XEGC, for any generated GC solution by LLMs, we require it to be in the format
of a list of digits separated by commas, as described in Prompt Template 14.
If the
format is valid, XEGC(F â€²) = 0, otherwise 1. With respect to the SE of GC, noted as
SEGC, it is composed of two components: Conflict Edges (CE) which consists of a set
of edges where adjacent nodes share the same color, violating coloring constraints, i.e.,
CE( ğ‘“â€²) = {(ğ‘¢, ğ‘£) | (ğ‘¢, ğ‘£) âˆˆğ¸âˆ§ğ‘“â€²(ğ‘¢) = ğ‘“â€²(ğ‘£)}, and Excess Colors Count (ECC) which
indicates the number of distinct colors used that exceeds the specified color count ğ‘˜, i.e.,
ECC( ğ‘“â€²) = |F â€²| âˆ’ğ‘˜. Hence, SEGC for ğ‘“â€² is given as: SEGC( ğ‘“â€²) = (CE( ğ‘“â€²), ECC( ğ‘“â€²)).
â€¢ TSP VED: Let ğ‘Ÿâ€² be a TSP solution. With respect to the XE of TSP, noted as XETSP, for
any generated TSP solution by LLMs, we require it to be in the format of a list of digits
separated by commas, with the first and last city being the same and equal to 0 and each city
index in the range from 0 to ğ‘›ğ‘¢ğ‘šğ‘ğ‘’ğ‘Ÿğ‘œğ‘“ğ‘ğ‘–ğ‘¡ğ‘–ğ‘’ğ‘ âˆ’1, as described in Prompt Template 15. If
it is valid, XETSP(ğ‘Ÿâ€²) = 0, otherwise 1. With respect to the SE of TSP, noted as SETSP, it
comprises two components: Missing Cities Set (MCS) which consists of the cities omitted
in ğ‘Ÿâ€², i.e., MCS(ğ‘Ÿâ€²) = {ğ‘£| ğ‘£âˆˆğ‘‰âˆ§ğ‘£âˆ‰ğ‘Ÿâ€²} and Excess Distance (ED) which indicates the
difference between the distance used in ğ‘Ÿâ€² and ğ‘Ÿâˆ—, i.e., ED(ğ‘Ÿâ€²) = ğ·(ğ‘Ÿâ€²) âˆ’ğ·(ğ‘Ÿâˆ—). Hence,
SETSP is given as: SETSP(ğ‘Ÿâ€²) = (MCS(ğ‘Ÿâ€²), ED(ğ‘Ÿâ€²)).
LED
An LED prompts an LLM to introspectively evaluate the candidate, harnessing its knowledge
and reasoning abilities trained on corpora. By contrast to VED which always gives deterministic
and robust errors information, LED may hallucinate on identifying errors and give imprecise error
information. However, given a certain type of problem, in the case that external verifiers for this type
of problem are unavailable and LLMs are capable of accurately capturing errors and providing errors
information, LED remains indispensable. We crafted dedicated prompt templates for each of problem
types by converting the rules of VEDs given in Section 4.1.1 to natural language, and demonstrated
them in Prompt Template 1, 2, and 3.
4.1.2
Deduplicator
During initialization, crossover, and mutation, the deduplicator (DD) discards any individual that
duplicates an existing one, requesting replacements until a preset maximum deduplication attempts is
reached. This prevents identical candidates from dominating and preserves diversity.
Formally, given a sequence of candidates ğ¶= [ğ‘ğ‘–]ğ‘˜
ğ‘–=1 where ğ‘˜is the number of candidates generated, a
newly generated candidate ğ‘ğ‘˜+1, and a predefined maximum deduplication attempts ğœ, the deduplicator
DD(ğ¶, ğ‘ğ‘˜+1, ğœ) operates as follows: if ğ‘ğ‘˜+1 âˆ‰ğ¶, it returns ğ‘ğ‘˜+1; if âˆƒğ‘–âˆˆ{1, . . . , ğœ}, ğ‘(ğ‘–)
ğ‘˜+1 âˆ‰ğ¶and
âˆ€ğ‘—< ğ‘–, ğ‘( ğ‘—)
ğ‘˜+1 âˆˆğ¶, it returns ğ‘(ğ‘–)
ğ‘˜+1; otherwise, it returns ğ‘(â‰ª)
ğ‘˜+1 . Here, ğ‘(ğ‘–)
ğ‘˜+1 denotes a regenerated
candidate. Hence, unique candidates are accepted immediately, and duplicates trigger up to ğœ
regenerations, with the first non-duplicate retained or the final candidate accepted if all fail.
7


--- Page 8 ---
Preprint. Under review.
4.1.3
Experience Pool
During initialization and after each generation, candidate solutions with their fitness scores and
errors are recorded in the experience pool (EP). Before selection, the lowest fitness individuals in the
population are systematically replaced with the highest fitness candidates in EP, with the number of
replacements determined by a predefined replay rate. The EP preserves high-quality solutions and
prevents inferior candidates from dominating the population, averting convergence toward suboptimal
regions.
For the EP updating, formally, let EPğ‘¡denote EP at generation ğ‘¡, which is initialized as: EP0 =
{(ğ‘ğ‘–, ğ‘ ğ‘–, ğ‘’ğ‘–) | ğ‘ğ‘–âˆˆğ¶0, ğ‘ ğ‘–âˆˆğ‘†0, ğ‘’ğ‘–âˆˆğ¸0} , where ğ¶0 = [ğ‘ğ‘–]ğ‘›
ğ‘–=1 is a sequence of candidates representing
the initial population, ğ‘†0 = [ğ‘ ğ‘–]ğ‘›
ğ‘–=1 is a sequence of fitness score corresponding to each candidate in
ğ¶0, and ğ¸0 = [ğ‘’1]ğ‘›
ğ‘–=1 is a sequence of error information of each candidate in ğ¶0. After each generation
ğ‘¡, the experience pool is updated as: EPğ‘¡+1 = EPğ‘¡âˆª{(ğ‘ğ‘–, ğ‘ ğ‘–, ğ‘’ğ‘–) | ğ‘ğ‘–âˆˆğ¶ğ‘¡, ğ‘ ğ‘–âˆˆğ‘†ğ‘¡, ğ‘’ğ‘–âˆˆğ¸ğ‘¡} .
For the candidates replacement before selection, let ğ¶ğ‘¡âˆ’1 = {ğ‘1, . . . , ğ‘ğ‘›} be the previous population
and Cğ¸ğ‘ƒ
ğ‘¡
= {ğ‘â˜…
1, . . . , ğ‘â˜…
ğ‘š} be the candidates from EP at ğ‘¡. For the replay rate ğœŒ, we define replacement
count ğ‘˜= âŒŠğœŒÂ· ğ‘›âŒ‹. Let permutation ğœâ†‘sort ğ¶ğ‘¡âˆ’1 such that ğ‘ ğœâ†‘(ğ‘–) â‰¤ğ‘ ğœâ†‘( ğ‘—) for all ğ‘–< ğ‘—, and
permutation ğœâ†“sort Cğ¸ğ‘ƒ
ğ‘¡
such that ğ‘ â˜…
ğœâ†“(ğ‘–) â‰¥ğ‘ â˜…
ğœâ†“( ğ‘—) for all ğ‘–< ğ‘—. We construct the new population
ğ¶â€² = [ğ‘â€²
1, ğ‘â€²
2, . . . , ğ‘â€²
ğ‘›], in which ğ‘â€²
ğ‘–= ğ‘â˜…
ğœâ†“(ğ‘–) if 1 â‰¤ğ‘–â‰¤ğ‘˜and ğ‘ â˜…
ğœâ†“(ğ‘–) > ğ‘ ğœâ†‘(ğ‘–), otherwise ğ‘â€²
ğ‘–= ğ‘ğœâ†‘(ğ‘–).
4.1.4
Fitness Evaluator
The fitness evaluator (FE) assigns each candidate a score, determining selection probability during
evolution and influencing their crossover and mutation opportunities. Higher scores indicate the
proximity of solutions to the optimum, increasing the possibility of selection to generate offspring.
Lower scores reduce their selection probability. The FE critically guides the evolution and different
FEs can exert distinct evolutionary processes. In Lyria, we propose two types of FEs, i.e., Oracle-based
FE and LLM-based FE.
Oracle-Based FE
The Oracle-based FE leverages an external symbolic system as a verifier that
deterministically returns a score for a candidate solution. Given a candidate and the associated scoring
criteria, the verifier strictly adheres to the criteria, producing a precise score. For all 3 problem types,
we implement their penalized score metric as the FE criteria in their verifiers to compute their fitness
scores.
LLM-Based FE
The LLM-based FE eliminates the need for external or handcrafted verifiers
by prompting an LLM to generate scores. Although an LLM can occasionally deviate from the
ground-truth score, it is still worthy and indispensable, when an external verifier is unavailable or
costly to obtain. For each type of problem, we instruct the LLM to compute the fitness score based on
their penalized score metric. We demonstrate all prompt templates in Prompt Template 4, 5, and 6.
4.1.5
Selector
Given a sequence of candidate solutions, the selector elects appropriate candidates and prepares a
mating pool for subsequent crossover and mutation. While prioritizing individuals with high fitness
may promote the generation of superior offspring, exclusively retaining them may impede population
diversity and risk premature convergence to local optima. To balance exploration and exploitation,
we implement a hybrid selection strategy for the selector that combines truncation selection with
tournament selection. Nevertheless, we note that Lyria is not confined to a specific selection strategy
and it can be substituted by any alternatives.
Let ğ¶= [ğ‘ğ‘–]ğ‘›
ğ‘–=1 be a sequence of candidates with fitness scores ğ‘†= [ğ‘ ğ‘–]ğ‘›
ğ‘–=1. Let ğ‘˜ğ‘’âˆˆ[0, ğ‘›]
denote the number of fittest candidates that are directly carried forward in truncation selection. Let
ğ‘˜ğ‘Ÿ= ğ‘›âˆ’ğ‘˜ğ‘’denote the number of candidates for tournament selection. The selector sorts ğ¶in
descending order based on their fitness, giving ğ¶ğœâ†“= [ğ‘ğœâ†“(1), ğ‘ğœâ†“(2), . . . , ğ‘ğœâ†“(ğ‘›)]. Then, it selects a
subsequence of ğ‘˜ğ‘’fittest candidates from ğ¶ğœâ†“, corresponding to the truncation selection, as ğ¶trunc =
[ğ‘ğœâ†“(1), ğ‘ğœâ†“(2), . . . , ğ‘ğœâ†“(ğ‘˜ğ‘’)]. Then, let ğ¼tour = [(ğ‘¥ğ‘–, ğ‘¦ğ‘–)]ğ‘˜ğ‘Ÿ
ğ‘–=1 be a sequence of index-pairs and ğ‘¥ğ‘–, ğ‘¦ğ‘–
i.i.d.
âˆ¼
U[1, ğ‘›]. The candidates selected by tournament selection is given as ğ¶tour = [ğ‘tour
1
, ğ‘tour
2
, . . . , ğ‘tour
ğ‘˜ğ‘Ÿ],
8


--- Page 9 ---
Preprint. Under review.
where ğ‘tour
ğ‘–
= ğ‘ğ‘¥ğ‘–if ğ‘ ğ‘¥ğ‘–> ğ‘ ğ‘¦ğ‘–, otherwise ğ‘tour
ğ‘–
= ğ‘ğ‘¦ğ‘–. Thus, combining the truncation selection and
tournament selection, the selector is defined as: Select(ğ¶, ğ‘†, ğ‘˜ğ‘’, ğ‘˜ğ‘Ÿ) = ğ¶trunc âˆªğ¶tour. Hence, the
candidates selected as the mating pool is ğ¶â€² = Select(ğ¶, ğ‘†, ğ‘˜ğ‘’, ğ‘˜ğ‘Ÿ).
4.1.6
Crossover Operator
The crossover operator (CO) selects parent pairs from the mating pool, governed by a predefined
crossover rate. If crossover is skipped, a parent is randomly returned; otherwise, offspring are
generated. This iterates until the offspring population reaches the predefined population size. The
objective of CO is to combine advantageous traits of parents while suppressing detrimental ones to
produce improved offspring with higher fitness. In Lyria, we propose two COs, i.e. External CO
(ECO) and LLM-based CO (LCO) , which are alternated in evolution based on an external crossover
rate, for which higher prioritizes ECO while lower prioritizes LCO.
ECO
In ECO, two parent candidates are combined via external symbolic systems, based on
domain-specific strategies and also the error information of the given parents. Varying from domains,
distinct strategies can be employed, e.g., leveraging external heuristics provided by domain experts,
formal logical constraints, etc. We designed specific ECOs for each problem type:
â€¢ SK ECO Let ğ‘1, ğ‘2 be parent candidates as two 9 Ã— 9 matrix. Let ğ‘ƒremoved denote the initially
removed positions of the puzzle and {(ğ‘–, ğ‘—) | (ğ‘–, ğ‘—, ğ‘¡) âˆˆSESK(ğ‘)} âŠ†ğ‘ƒremoved. The crossover
operator COSK(ğ‘1, ğ‘2) produces the child ğ‘child as:
ğ‘child =
ï£±ï£´ï£´ï£²
ï£´ï£´ï£³
ğ‘1
if SESK(ğ‘1) = âˆ…,
ğ‘2
if SESK(ğ‘2) = âˆ…,
Î¦(ğ‘2, ğ‘ƒcorr(ğ‘1))
otherwise,
where ğ‘ƒcorr(ğ‘1) = ğ‘ƒremoved \ {(ğ‘–, ğ‘—) | (ğ‘–, ğ‘—, ğ‘¡) âˆˆSESK(ğ‘1)} are ğ‘1â€™s corrected positions, and
Î¦(ğ‘, ğ‘ƒcorr) updates ğ‘by replacing ğ‘â€™s values at {(ğ‘–, ğ‘—) | (ğ‘–, ğ‘—, ğ‘¡) âˆˆSESK(ğ‘)} âˆ©ğ‘ƒcorr.
â€¢ GC ECO Let ğ‘1, ğ‘2 be two parent candidates, which are two GC solutions of which each
represented as a sequence of color assignments, i.e., ğ‘= [ğ‘œ1, ğ‘œ2, . . . , ğ‘œ|ğ‘‰|] where ğ‘œğ‘–is a
color assignment for ğ‘£ğ‘–âˆˆğ‘‰. Let CV(ğ‘) = {ğ‘£| (ğ‘£, ğ‘¢) âˆˆCE(ğ‘)} denote conflict vertices in
candidate ğ‘. The external crossover operator ECOGC generates the child ğ‘child as:
âˆ€ğ‘–, ğ‘child[ğ‘–] =
ï£±ï£´ï£´ï£²
ï£´ï£´ï£³
ğ‘2[ğ‘–]
if ğ‘–âˆˆCV(ğ‘1) \ CV(ğ‘2),
ğ‘1[ğ‘–]
if ğ‘–âˆˆCV(ğ‘2) \ CV(ğ‘1),
R(ğ‘1[ğ‘–], ğ‘2[ğ‘–])
otherwise,
where ğ‘–âˆˆ{1, . . . , |ğ‘‰|} indicates both an index in a color assignment sequence and also a
city, and R(ğ‘¥, ğ‘¦) denotes uniform random selection between ğ‘¥and ğ‘¦. Thus, COGC transfers
non-conflicting colors between parents while preserving valid vertex assignments.
â€¢ TSP ECO Let ğ‘1, ğ‘2 be two parent candidates, which are two routines, for which each
routine is a sequence of visited cities. The external crossover operator ECOTSP generates the
child ğ‘child as:
ğ‘child =
ï£±ï£´ï£´ï£²
ï£´ï£´ï£³
ğ‘1
if SETSP(ğ‘1) = (âˆ…, 0),
ğ‘2
if SETSP(ğ‘2) = (âˆ…, 0),
Î¨(ğ‘1, ğ‘2, ğ‘˜)
otherwise,
where ğ‘˜i.i.d.
âˆ¼U[1, ğ‘›âˆ’1] is a uniformly random crossover point, and
âˆ€ğ‘–, Î¨(ğ‘1, ğ‘2, ğ‘˜)[ğ‘–] =
ğ‘1[ğ‘–]
for ğ‘–â‰¤ğ‘˜,
ğ‘2[ğ‘–]
for ğ‘–> ğ‘˜,
where ğ‘–âˆˆ{1, . . . , |ğ‘‰|} is an index of a sequence. Thus, COTSP merges partial routes from
both parents while preserving order.
LCO
In LCO, an LLM is prompted to merge two parent candidates by integrating their advantageous
attributes and excluding their deficiencies, drawing on the experience and prior knowledge of the LLM
and their understanding of the error information of the candidates provided by the ED, to produce an
improved child. This approach eliminates the need to manually specify any domain-specific strategy,
instead fully delegating it to the LLM. We demonstrated the prompts we designed for each of the 3
problem types in Prompt Template 7, 8, and 9.
9


--- Page 10 ---
Preprint. Under review.
4.1.7
Mutation Operator
The mutation operator (MO) applies mutations to each candidate based on a predefined mutation
rate, returning either the original or mutated candidate. This preserves population diversity and
prevents premature convergence. In Lyria, we propose two MOs, i.e., External MO (EMO) and
LLM-based MO (LMO), which are alternated in evolution via an external mutation rate, for which
higher prioritizes EMO while lower prioritizes LMO.
EMO
In EMO, the mutation is handled by external symbolic systems, guided by domain-specific
mutation strategies and also the error information of the candidate, to modify the candidate. We
designed specific EMOs for each problem type:
â€¢ SK EMO Given a candidate ğ‘as a 9 Ã— 9 matrix, the EMOSK is given as:
EMOSK(ğ‘) =
ğ‘
if SESK(ğ‘) = âˆ…,
Î˜(ğ‘, ğ‘, ğ‘£)
otherwise,
where ğ‘ğ‘–.ğ‘–.ğ‘‘.
âˆ¼U({(ğ‘–, ğ‘—) | (ğ‘–, ğ‘—, ğ‘¡) âˆˆSE(ğ‘)}) is an error position, ğ‘£ğ‘–.ğ‘–.ğ‘‘.
âˆ¼U[1, 9] is a random
value, and Î˜(ğ‘, ğ‘, ğ‘£) denotes replacing ğ‘â€™s value at the position ğ‘with the value ğ‘£.
â€¢ GC EMO Given a candidate ğ‘as a sequence of color assignments, the EMOGC proceeds as:
EMOGC(ğ‘) = Î“(Î›(ğ‘)).
It is composed of two main components, i.e., Conflict Edges Resolution and Excess Colors
Correction, denoted as Î› and Î“ respectively.
Conflict Edges Resolution is given as:
Î›(ğ‘)[ğ‘–] =
ğ‘¦
if ğ‘[ğ‘–] âˆˆCV(ğ‘)
ğ‘[ğ‘–]
otherwise,
where ğ‘–ğ‘–.ğ‘–.ğ‘‘.
âˆ¼U[1, |ğ‘|] is a randomly selected index, and ğ‘¦ğ‘–.ğ‘–.ğ‘‘.
âˆ¼U({0, . . . , ğ‘˜âˆ’1} \ {ğ‘[ğ‘–]})
is a new color value. Hence, it reassigns a new color to a vertex if it is conflicted such that
ğ‘¦â‰ ğ‘[ğ‘–].
Excess Colors Correction is given as:
âˆ€ğ‘–, Î“(ğ‘)[ğ‘–] =
ğ‘§
if ğ‘[ğ‘–] âˆˆğ‘‚,
ğ‘[ğ‘–]
otherwise.
where ğ‘–âˆˆ{1, . . . , |ğ‘|}, ğ‘§ğ‘–.ğ‘–.ğ‘‘.
âˆ¼U({0, . . . , ğ‘˜âˆ’1}) and ğ‘‚= {ğ‘˜, . . . , ğ‘˜+ ECC(ğ‘)}. Hence, it
replaces all color values â‰¥ğ‘˜with random valid colors ğ‘§âˆˆ{0, . . . , ğ‘˜âˆ’1}.
â€¢ TSP EMO Give a candidate ğ‘as a route, which is a sequence of visited cities, let ğ‘Œbe a
set of duplicated cities in ğ‘, and let ğ‘€= MCS(ğ‘) be a set of missing cities, the EMOTSP is
given as:
EMOTSP(ğ‘) =
ğ‘
if ğ‘€= âˆ…,
Î©(ğ‘)
otherwise,
where Î© is defined as:
âˆ€ğ‘–, Î©(ğ‘)[ğ‘–] =
ğœ‘(ğ‘–)
if ğ‘[ğ‘–] âˆˆğ‘Œ
ğ‘[ğ‘–]
otherwise,
in which ğ‘–âˆˆ{1, . . . , |ğ‘|}, ğœ‘is an injection from the first ğ‘Ÿ= min(|ğ‘Œ|, |ğ‘€|) elements of ğ‘Œ
into ğ‘€. Hence, it resolves errors by substituting duplicates with missing cities, ensuring the
mutated child becomes a route without missing cities.
LMO
In LMO, an LLM is instructed to mutate a given candidate, by identifying and improving its
inferior parts, based on the knowledge of LLMs and their understanding of error information. Similar
to LCO, this approach eliminates the necessity to manually construct domain-specific strategies and
enables the LLM to autonomously design strategies to modify the given candidate. We designed the
prompt for each problem type and demonstrated them in Prompt Template 10, 11, and 12.
10


--- Page 11 ---
Preprint. Under review.
4.1.8
Pseudo Code
The pseudo code of Lyria is demonstrated in Algorithm 1, in which P means the problem, ğ‘›ğ‘means
population size, ğ‘›ğ‘”means generations, ğ‘˜ğ‘’means the number of fittest candidates that are directly
carried forward in truncation selection, ğœ–means the maximum detected errors, ğœŒmeans replay rate, ğœ
means the maximum deduplication attempts, ğœ‚means crossover rate, ğœ‰means external crossover rate,
ğœ…means mutation rate, ğœ‡means external mutation rate, FE means the fitness evaluator which can
either be Oracle-based or LLM-based, ED means the error detector which can either be Verifier-based
or LLM-based, LCO means the LLM-based crossover operator, ECO means the external crossover
operator, LMO means the LLM-based mutation operator, EMO means the external mutation operator,
and ğ‘™ğ‘™ğ‘šindicates the LLM which accepts a prompt and returns a response2.
We provide a line-by-line explanation of the pseudo code as follows. At Line 2, we initialize essential
parameters. From Line 3 to 12, we use DPPrompt to construct the prompt. For example, we use
prompt templates shown in Prompt Template 13, 14, and 15 to construct the prompt for each problem
type. Then, ğ‘™ğ‘™ğ‘šuses this prompt to generate new candidate. Deduplicator removes redundant
candidates, FE assigns fitness score to the candidate, ED detect its errors up to ğœ–for which we show
the prompt templates we used in Prompt Templates 1, 2, and 3. For Line 13-46, Lyria starts evolution.
At Line 14, EP intervenes to replace the lowest fitness candidates from the previous population with
the highest fitness candidates from EP along with their fitness scores and errors. At Line 15-16, the
selector selects appropriate candidates along with their fitness scores and errors. For Line 17-28, the
crossover rate ğœ‚determines whether to apply the crossover operation, while the external crossover rate
ğœ‰determines whether ECO is prioritized. For LCO, we demonstrate the prompt templates we used
for each problem type in Prompt Template 7, 8, and 9. For Line 29-41, the mutation rate ğœ…determines
whether to apply the mutation operation, while the external mutation rate ğœ‡determines whether EMO
is prioritized. For LMO, we demonstrate the prompt templates we used for each problem type in
Prompt Template 10, 11, and 12. For Line 42-45, ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ , ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ , and EP are updated,
and the evolution advances into the next generation.
In addition, in practice, to prevent unnecessary additional overhead, especially when ğ‘ğ‘’ğ‘ ğ‘¡ğ‘“ğ‘–ğ‘¡ğ‘’ğ‘›ğ‘ ğ‘ 
attains its optima, we also introduce a fitness threshold. During both initialization and the end of each
generation, we check whether ğ‘ğ‘’ğ‘ ğ‘¡ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ meets or exceeds the fitness threshold. The ğ‘ğ‘’ğ‘ ğ‘¡ğ‘ ğ‘œğ‘™ğ‘¢ğ‘¡ğ‘–ğ‘œğ‘›
is returned earlier if it meets the threshold. For every type of problem, the fitness threshold is set to
100.
4.2
Main Experiment
4.2.1
Baselines
We adapted two baselines, i.e., Direct Prompting (DP) and Best-of-N Direct Prompting (BoN), for
comparative evaluation. We elaborate on the details and necessity of the two baselines as follows. A
discussion of why comparisons with other LLM-driven genetic algorithms or metaheuristic algorithms
are not included is provided in Section 6.
For DP, an LLM is invoked once and prompted to generate a solution directly in a zero-shot manner,
in which it is required to think and reason in any way it deems appropriate before producing the final
answer. We designed the prompt templates for each problem type and demonstrated them in Prompt
Template 13, 14, and 15.
Since Lyria may sample an LLM up to ğ¿times for a single problem, a naive comparison against DP
could favor Lyria merely by virtue of increased sampling3. To ensure a fair comparison, we adopt the
BoN approach. For each problem, BoN draws ğ‘= ğ¿independent responses from the LLM using
the identical prompt template employed by DP and preserves the one with the best metrics as the
answer. Additionally, same as Lyria, a deduplicator is introduced to remove redundant answers. This
approach equalizes the number of sampling and ensures any observed performance improvements are
attributable to the innovations of Lyria.
2In Algorithm 1, â€||â€ means concatenating two arrays.
3The calculation of ğ¿is demonstrated in Appendix A.
11


--- Page 12 ---
Preprint. Under review.
Algorithm 1 Pseudo Code of Lyria
1: procedure Lyria(P, ğ‘›ğ‘, ğ‘›ğ‘”, ğ‘˜ğ‘’, ğœ–, ğœŒ, ğœ, ğœ‚, ğœ‰, ğœ…, ğœ‡, FE, ED, LCO, ECO, LMO, EMO, ğ‘™ğ‘™ğ‘š)
2:
ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ , ğ‘ğ‘’ğ‘ ğ‘¡ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ , ğ‘ğ‘’ğ‘ ğ‘¡ğ‘ ğ‘œğ‘™ğ‘¢ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ , EP, ğœâ€² â†[], [], âˆ’âˆ, âˆ…, [], âˆ…, 0
3:
while |ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›| < ğ‘›ğ‘do
âŠ²Initialization
4:
ğ‘ğ‘Ÿğ‘œğ‘šğ‘ğ‘¡â†DPPrompt(P)
5:
ğ‘ğ‘ğ‘›ğ‘‘ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘’â†ğ‘™ğ‘™ğ‘š(ğ‘ğ‘Ÿğ‘œğ‘šğ‘ğ‘¡)
6:
if ğ‘â„ğ‘–ğ‘™ğ‘‘âˆˆğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›and ğœâ€² < ğœthen ğœâ€² â†ğœâ€² + 1; Continue else ğœâ€² â†0
âŠ²Deduplicator
7:
ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ â†ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›âˆ¥[ğ‘ğ‘ğ‘›ğ‘‘ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘’], ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ âˆ¥[FE(ğ‘ğ‘ğ‘›ğ‘‘ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘’)]
8:
ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ â†ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ âˆ¥[ED(ğ‘ğ‘ğ‘›ğ‘‘ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘’, ğœ–)]
9:
if ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ [âˆ’1] > ğ‘ğ‘’ğ‘ ğ‘¡ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ then
10:
ğ‘ğ‘’ğ‘ ğ‘¡ğ‘ ğ‘œğ‘™ğ‘¢ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘ğ‘’ğ‘ ğ‘¡ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ â†ğ‘ğ‘ğ‘›ğ‘‘ğ‘–ğ‘‘ğ‘ğ‘¡ğ‘’, ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ [âˆ’1]
11:
end if
12:
end while
13:
for ğ‘›â€²
ğ‘”â†1 to ğ‘›ğ‘”do
âŠ²Start Evolution
14:
ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ , ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ â†Replacing âŒŠğ‘›ğ‘Â· ğœŒâŒ‹candidates with EP
âŠ²EP Replay
15:
ğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ğ‘’ğ‘‘â†Select(ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ , ğ‘˜ğ‘’, |ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›| âˆ’ğ‘˜ğ‘’)
âŠ²Selection Phase
16:
Update ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ , ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ to align with ğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ğ‘’ğ‘‘
17:
ğ‘œğ‘“ğ‘“ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘”, ğ‘œğ‘ ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ , ğ‘œğ‘ ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ , ğœâ€² â†[], [], [], 0
18:
while |ğ‘œğ‘“ğ‘“ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘”| < ğ‘›ğ‘do
âŠ²Crossover Phase
19:
ğ‘1, ğ‘2, ğ‘ 1, ğ‘ 2, ğ‘’1, ğ‘’2 â†RandomChoice(ğ‘ ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡ğ‘’ğ‘‘, ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ , ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ )
20:
if RD() < ğœ‚then
âŠ²Apply ECO or LCO , and RD() means ğ‘¥ğ‘–.ğ‘–.ğ‘‘.
âˆ¼U[0, 1]
21:
ğ‘â„ğ‘–ğ‘™ğ‘‘â†ECO(P, ğ‘1, ğ‘2, ğ‘’1, ğ‘’2) if RD() < ğœ‰else LCO(P, ğ‘1, ğ‘2, ğ‘ 1, ğ‘ 2, ğ‘’1, ğ‘’2, ğ‘™ğ‘™ğ‘š)
22:
else
23:
ğ‘â„ğ‘–ğ‘™ğ‘‘â†RandomChoice([ğ‘1, ğ‘2])
24:
end if
25:
if ğ‘â„ğ‘–ğ‘™ğ‘‘âˆˆğ‘œğ‘“ğ‘“ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘”and ğœâ€² < ğœthen ğœâ€² â†ğœâ€² + 1; Continue else ğœâ€² â†0
26:
ğ‘œğ‘“ğ‘“ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘”, ğ‘œğ‘ ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ â†ğ‘œğ‘“ğ‘“ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘”âˆ¥[ğ‘â„ğ‘–ğ‘™ğ‘‘], ğ‘œğ‘ ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ âˆ¥[ğ¹ğ¸(ğ‘â„ğ‘–ğ‘™ğ‘‘)]
27:
ğ‘œğ‘ ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ â†ğ‘œğ‘ ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ âˆ¥[ğ¸ğ·(ğ‘â„ğ‘–ğ‘™ğ‘‘, ğœ–)]
28:
end while
29:
ğ‘šğ‘¢ğ‘¡ğ‘ğ‘¡ğ‘’ğ‘‘, ğ‘šğ‘¡ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ , ğ‘šğ‘¡ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ , ğœâ€² â†[], [], [], 0
30:
while |ğ‘šğ‘¢ğ‘¡ğ‘ğ‘¡ğ‘’ğ‘‘| < ğ‘›ğ‘do
âŠ²Mutation Phase
31:
ğ‘–â†|ğ‘šğ‘¢ğ‘¡ğ‘ğ‘¡ğ‘’ğ‘‘|
32:
ğ‘, ğ‘’, ğ‘ â†ğ‘œğ‘“ğ‘“ğ‘ ğ‘ğ‘Ÿğ‘–ğ‘›ğ‘”[ğ‘–], ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ [ğ‘–], ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ [ğ‘–]
33:
if RD() < ğœ…then
âŠ²Apply EMO or LMO
34:
ğ‘â„ğ‘–ğ‘™ğ‘‘â†EMO(P, ğ‘, ğ‘’) if RD() < ğœ‡else LMO(P, ğ‘, ğ‘ , ğ‘’, ğ‘™ğ‘™ğ‘š)
35:
else
36:
ğ‘â„ğ‘–ğ‘™ğ‘‘â†ğ‘
37:
end if
38:
if ğ‘â„ğ‘–ğ‘™ğ‘‘âˆˆğ‘šğ‘¢ğ‘¡ğ‘ğ‘¡ğ‘’ğ‘‘and ğœâ€² < ğœthen ğœâ€² â†ğœâ€² + 1; Continue else ğœâ€² â†0
39:
ğ‘šğ‘¢ğ‘¡ğ‘ğ‘¡ğ‘’ğ‘‘, ğ‘šğ‘¡ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ â†ğ‘šğ‘¢ğ‘¡ğ‘ğ‘¡ğ‘’ğ‘‘âˆ¥[ğ‘â„ğ‘–ğ‘™ğ‘‘], ğ‘šğ‘¡ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ âˆ¥[ğ¹ğ¸(ğ‘â„ğ‘–ğ‘™ğ‘‘)]
40:
ğ‘šğ‘¡ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ â†ğ‘šğ‘¡ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ âˆ¥[ğ¸ğ·(ğ‘â„ğ‘–ğ‘™ğ‘‘, ğœ–)]
41:
end while
42:
ğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ â†ğ‘šğ‘¢ğ‘¡ğ‘ğ‘¡ğ‘’ğ‘‘, ğ‘šğ‘¡ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ 
âŠ²Update Population
43:
ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ â†ğ‘šğ‘¡ğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ 
44:
EP â†EP âˆª{(ğ‘, ğ‘ , ğ‘’) | ğ‘âˆˆğ‘ğ‘œğ‘ğ‘¢ğ‘™ğ‘ğ‘¡ğ‘–ğ‘œğ‘›, ğ‘ âˆˆğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ , ğ‘’âˆˆğ‘’ğ‘Ÿğ‘Ÿğ‘œğ‘Ÿğ‘ }
45:
Update ğ‘ğ‘’ğ‘ ğ‘¡ğ‘ ğ‘œğ‘™ğ‘¢ğ‘¡ğ‘–ğ‘œğ‘›and ğ‘ğ‘’ğ‘ ğ‘¡ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘ 
46:
end for
47:
return ğ‘ğ‘’ğ‘ ğ‘¡ğ‘ ğ‘œğ‘™ğ‘¢ğ‘¡ğ‘–ğ‘œğ‘›
48: end procedure
12


--- Page 13 ---
Preprint. Under review.
Model
Method
SKğ¶ğ‘…
SKğ‘ƒğ‘†
GCğ¶ğ‘…
GCğ‘ƒğ‘†
TSPğ¶ğ‘…
TSPğ‘ƒğ‘†
GPT-4o-Mini
DP
0
39
0
73
0
79
BoN
6
73
0
86
4
94
Lyria
8
73
0
97
6
96
Qwen2.5:32B-Instruct
DP
0
31
0
74
0
81
BoN
8
76
0
87
8
97
Lyria
32
87
0
96
30
99
Mistral:7B-Instruct
DP
0
0
0
0
0
60
BoN
0
5
0
84
0
80
Lyria
0
12
0
92
0
89
Qwen2.5:7B-Instruct
DP
0
26
0
73
0
34
BoN
0
55
0
84
0
88
Lyria
0
61
0
95
4
95
Table 1: The results of Correctness and Penalized Score for SK, GC, TSP. For each LLM, across the
three methods, the best correctness and penalized score are highlighted with a bold font.
4.2.2
Experiment Settings
For a comprehensive evaluation, we selected 4 LLMs: GPT-4o-Mini, Qwen2.5:32B-Instruct,
Qwen2.5:7B-Instruct, and Mistral:7B-Instruct.
For DP, we set the temperature to 0 for greedy decoding and the maximum generated tokens to 4096.
For BoN, we set the temperature at 0.7 to enable diverse generated answers, the maximum generated
tokens at 4096, the sampling times ğ‘at 345 to align the number of queries with Lyria, and the
maximum deduplication attempts at 3.
For Lyria, we switch on the Oracle-based FE. We set the temperature of LLM at 0.7, the maximum
generated tokens at 4096, the population size at 30, the generations at 15, the maximum detected
errors at 3, the maximum deduplication attempts at 3, the replay rate at 0.6, the crossover rate at 0.7,
the external crossover rate at 0.3, the mutation rate at 0.3, and the external mutation rate at 0.3.
4.2.3
Results & Analysis
As shown in Table 1, LLMs struggle across problems with DP4. While BoN greatly improves the
performance across the problems, Lyria demonstrates its ability to further consistently contribute
significant improvement across various LLMs and problems. For example, Lyria improves GCğ‘ƒğ‘†for
GPT-4o-Mini by 24 over DP and 11 over BoN, while enhancing SKğ¶ğ‘…by 32% and 24% and also
SKğ‘ƒğ‘†by 56 and 11, for Qwen2.5:32B-Instruct, compared to DP and BoN, respectively. In addition,
for relatively small LLMs like Qwen2.5:7B-Instruct, Lyria also shows its efficacy, by 22 and 11 GCğ‘ƒğ‘†
increases, and 61 and 7 TSPğ‘ƒğ‘†improved, compared to DP and BoN, respectively.
Furthermore, across all LLMs, for SK, Lyria shows an average 10% and 7% increases on SKğ¶ğ‘…with
34 and 6 increases on SKğ‘ƒğ‘†, compared to DP and BoN. For GC, Lyria shows 40 and 10 improvement
on GCğ‘ƒğ‘†. For TSP, Lyria shows 10% and 7% increases on TSPğ¶ğ‘…with 32 and 5 improvement
on TSPğ‘ƒğ‘†. Therefore, across all LLMs and problems, Lyria demonstrates 7% and 5% increases
on the correctness and 35 and 7 improvements on the penalized score, compared to DP and BoN,
respectively, demonstrating the consistent performance contribution offered by Lyria.
4.3
Ablation Experiments
To further investigate the impact of various factors that influence the performance of Lyria, we
conducted 7 additional experiments. To avoid prohibitive costs, we selected Qwen2.5:7B-Instruct and
limited the number of problems to 10. Unless otherwise specified, we adhere to the same parameter
settings as in the main experiment and refer their performance to the penalized score metric.
4Results of all metrics for each problem type are shown in Appendix B.
13


--- Page 14 ---
Preprint. Under review.
Figure 2: The figure shows the performance comparison between Lyria and BoN, in which the x-axis
indexes each parameter set, e.g., index 0 means the pair of (ğ‘›ğ‘= 5, ğ‘›ğ‘”= 5) for Lyria and ğ‘= 23 for
BoN, and the y-axis shows the corresponding score averaging across SKğ‘ƒğ‘†, GCğ‘ƒğ‘†, and TSPğ‘ƒğ‘†.
4.3.1
Scaling Population Size and Generations
This experiment investigates the impact of scaling population size ğ‘›ğ‘and generations ğ‘›ğ‘”on the
performance of Lyria.
We executed 6 experiment settings, each pairing a ğ‘›ğ‘and ğ‘›ğ‘”: (5, 5),
(10, 10), (20, 20), (30, 30), (40, 40) and (50, 50). For each setting, we applied the BoN baseline
for comparison, with the corresponding values of ğ‘equal to 23, 80, 300, 660, 1160, and 1800. As
demonstrated in Figure 2, averaged across problems, while BoN exhibits diminishing marginal gains as
parameters scaled, Lyria demonstrated consistent improvements and increasingly larger performance
gaps compared to BoN. We attribute the limitations of BoN to LLMs getting trapped in local optima
without effective capacities to extricate themselves from it, resulting in even sampling an arbitrarily
large number of answers yet still failing to yield further performance improvements. However,
Lyria inherently possesses the capacity to escape local optima, driving substantial performance
improvements while increasing ğ‘›ğ‘and ğ‘›ğ‘”.
In addition, to disentangle the individual contribution of ğ‘›ğ‘and ğ‘›ğ‘”, we conducted 6 additional
experiments settings. We fixed the ğ‘›ğ‘at 10 while varying ğ‘›ğ‘”at values of 10, 30, and 50, and
conversely fixed ğ‘›ğ‘”at 10 while adjusting ğ‘›ğ‘across values of 10, 30 and 50. For the former, averaged
across problems, the penalized scores increase by 4, while the latter one yields 7 gains. The modest
3 difference between them could result from the limited diversity in smaller populations, causing
offspring becoming homologous to their parents, thereby suppressing evolutionary efficacy. However,
given this minor gap, we cannot exclude the possibility that it arises from stochastic variation.
4.3.2
Oracle-Based FE VS LLM-Based FE
This experiment seeks to explore how the performance of Lyria varies when using an Oracle-based
FE versus an LLM-based FE. We compared an Oracle-based FE with two LLM-based FEs, one built
on Qwen2.5:7B-Instruct and the other on GPT-4o-Mini.
We observed that, averaged across problems, the Oracle-based FE achieved a penalized score of
84, whereas Qwen2.5:7B-Instruct and GPT-4o-Mini scored only 51 and 50, respectively. The
superior result of Oracle-based FE, as expected, shows that a stronger evaluator markedly boosts
the performance of Lyria. The reason is obvious, that the external symbolic system can always give
14


--- Page 15 ---
Preprint. Under review.
precise fitness to guild the evolution direction while LLMs fails to provide correct fitness resulting in
evolution process oscillated.
Additionally, it is also worth-noting that the nearly identical scores of GPT-4o-Mini and Qwen2.5:7B-
Instruct indicate no significant difference in their evaluative capacity, although GPT-4o-Mini demon-
strates a consistent better problem solving ability than Qwen2.5:7B-instruct as shown in Table 1.
4.3.3
Impact of ED, EP, DD
This experiment aims to investigate the impact of the Error Detector, Experience Pool, and Deduplicator
on Lyria.
For ED, we vary the maximum detected errors ğœ–at values of 0, 3, 6, and 9. For TSP, we do not observe
a significant impact when increasing ğœ–. In contrast, for SK, as ğœ–rises, the SKğ‘ƒğ‘†also increased,
yielding 4 gains. For GC, increasing ğœ–produced a significant 7 improvements. We attribute the
performance differences across problems to the varying efficacy of their dedicated design of ECO and
EMO.
For EP, we vary the replay rate ğœŒat values of 0, 0.3, and 0.6. We observed that varying ğœŒdid
not produce significant changes in GCğ‘ƒğ‘†and TSPğ‘ƒğ‘†. However, for SK, while setting ğœŒto 0 and
0.6 yielded scores of 59 and 62, setting ğœŒ= 0.3 produces a score of 73, bringing up a significant
improvement of 14 and 11 compared to the scores when ğœŒ= 0 and ğœŒ= 0.6. We attribute this
discrepancy to the trade-offs of ğœŒ. When ğœŒis too low or EP is dropped, since the population of each
generation evolves solely by referring to its immediate predecessors, the lack of retained historical
best solutions may bias the evolutionary direction. Conversely, when ğœŒis too high, overreliance
on historical best solutions which may themselves be local optima, can homogenize the evolved
population and lead to premature convergence on suboptimal solutions.
For DD, we vary the maximum deduplication attempts ğœat the values of 0, 3, and 6. Averaged
across problems, increasing ğœdoes not bring up a significant improvement, which, nevertheless, is as
expected and does not mean that the deduplicator is dispensable. Since the solution spaces of all the
given problems are considerably immense, and when the population size remains much smaller than
the solution space, it results in a low incidence of duplicate individuals, DD therefore may not be
invoked. Thus, when encountering problems with comparatively smaller solution spaces, DD could
effectively eliminate duplicates and thereby enhance population diversity.
4.3.4
Impact of ECO and EMO
This experiment aims to investigate the impact of External Crossover Operator (ECO) and External
Mutation Operator (EMO) on Lyria. Given the close interdependence between these two operators,
rather than evaluating their efficacy in isolation, we simultaneously vary both the external crossover
rate ğœ‰and the external mutation rate ğœ‡to investigate the efficacy of them. Thus, we construct 3
experiment settings, each pairing a ğœ‰and ğœ‡: (0, 0), (0.3, 0.3), and (0.6, 0.6).
For GC, raising ğœ‰and ğœ‡induces a 6.35 performance gain by improving GCğ‘ƒğ‘†from 91.07 to 97.42.
However, for TSP, we did not observe a significant performance gain after increasing the rates.
Furthermore, for SK, we observed a 6.23 performance drop after raising rates. The results indicate
that although integrating symbolic system into crossover and mutation can help improve performance,
the disparity of the results illustrates that the quality of ECO and EMO designs tailored to specific
problems can markedly influence performance. High-quality ECO and EMO enable Lyria to evolve
populations more effectively, leading to better performance. We consider that a high-quality ECO and
EMO may contain, but are not limited to, extra or superior heuristics beyond what an LLM alone can
provide, structural or precise constraints, or expert domain knowledge, which can not only fill the
incomplete solution space that is the out-of-distribution data of LLMs but also provide appropriate
crossover and mutation strategy to advance evolution. Conversely, a poor design of them may trigger
performance declines. We consider that inferior operators may fail to fill the incomplete solution
space or may synthesize solutions worse than their predecessors, especially when they are frequently
used in the case that ğœ‰and ğœ‡are elevated, which can introduce low-quality individuals into each
generation, thereby degrading performance. Therefore, a meticulous and superior design of ECO and
EMO is essential for Lyria.
15


--- Page 16 ---
Preprint. Under review.
FT
Questions
Stronger
LLM
Weaker
LLM
Lyria
Reasoning
Traces
Filtered Reasoning Traces Fragments
Initial
Populations
Crossover
Fragments
Mutation
Fragments
Question
Lyria
Answer
Fine-Tuning Process
FT
Dataset
Figure 3: The overall process of LAFT in which the orange dashed-border block depicts the FT
process and the blue dashed-border block illustrates the inference process. The FT process begins
with a set of questions generated for FT data construction, which are answered by a stronger LLM
equipped with the Lyria reasoning framework. During reasoning, detailed reasoning traces are
collected, including the initial populations, crossover fragments, and mutation fragments. These
fragments are subsequently filtered to remove suboptimal ones and retain beneficial ones, forming a
FT dataset. The dataset is then used to fine-tune a weaker LLM. During inference, the fine-tuned
weaker LLM employs Lyria to reason over new questions and generate final answers.
5
The LAFT Fine-tuning Process
Building on Lyria, we extend it to the fine-tuning (FT) process of LLMs and introduce the Lyria
Augmented Fine-Tuning, abbreviated as LAFT, a new method that fine-tunes a weaker model
to imitate the reasoning process of a stronger model that uses Lyria as its reasoning framework,
enabling the weaker model to reason within the Lyria framework at inference time and achieve
improved performance. We detail the methodology, experiment settings, and results with analysis in
Section 5.1, 5.2, and 5.3, respectively.
5.1
Methodology
In LAFT, as illustrated in Figure 3, we initiate the process with a set of questions generated specifically
for building the FT dataset. A stronger LLM then leverages Lyria as its reasoning framework to reason
over and generate answers to these questions. Throughout this reasoning process, we systematically
record all information arising from using Lyria for reasoning, referred to as reasoning traces. These
traces comprise detailed information about the initial populations, as well as the information of every
crossover and mutation operation, which we collectively denote as reasoning trace fragments. These
information include raw responses, errors information, and fitness scores of initial populations, of both
parents and child candidates in the crossover operation, and of both original and mutated candidates
in the mutation operation. Subsequently, a filtering procedure is applied to filter out disturbing and
inferior fragments while retaining beneficial ones. All initial populations are preserved entirely. For
crossover fragments, only those in which the child outperforms both parent candidates are retained.
For mutation fragments, only those where the mutated candidate surpasses its original candidate are
retained. The resulting filtered fragments are then reformatted into a FT dataset, which is used to
fine-tune the weaker LLM. Once fine tuning is completed, during inference, the fine-tuned weaker
LLM employs Lyria as its reasoning framework to reason over new questions and generate final
answers.
16


--- Page 17 ---
Preprint. Under review.
5.2
Experiment Settings
In the experiment, we select Llama3.2:3B-Instruct (Grattafiori et al., 2024) as the weaker model, and
Qwen2.5:32B-Instruct (Qwen et al., 2025) as the stronger model. We generate 100 FT questions for
each type of problems SK, GC, and TSP, respectively, prepared for building the FT dataset. The FT
questions generation strictly follows the benchmark construction process described in Section 3. All
FT questions are disjoint from the test sets used for evaluation. In the FT process of LAFT described
in Section 4.2.2, for Qwen2.5:32B-Instruct with Lyria, we switch on Oracle-based FE and follow
the same parameter settings as the case we set parameters of Lyria described in Section 4.1. The
generated FT dataset is used to fine-tune the Llama3.2:3B-Instruct model to have a new fine-tuned
model, called Llama3.2:3B-LAFT. During inference, it uses the Lyria reasoning framework to answer
questions. We set its parameters as that, the temperature is set to 0.7, the maximum generated tokens
to 4096, population size to 20, the generations to 20, the maximum detected errors to 3, the maximum
deduplication attempts to 3, the replay rate to 0.6, the crossover rate to 0.7, the external crossover rate
to 0.3, the mutation rate to 0.3, and the external mutation rate to 0.3.
To form baselines, for each type of problems, we construct 3 new types of datasets, which are DPFT
dataset, DPFT@Full dataset, and DPFT@Top dataset. For the construction of DPFT, Qwen2.5:32B-
Instruct answers each FT question once with the DP method, where the temperature is set to 0 and
max generated tokens to 4096, following the task-specific DP templates as described in Prompt
Template 13, 14, and 15. This yields 100 pairs of questions and answers for each type of problems.
For the construction of DPFT@Full dataset, Qwen2.5:32B-Instruct answers each FT question 345
times, which is the same as the sample times ğ‘of BoN method set in Section 4.2.2, with the DP
method, where the temperature is set to 0.7 and the max generated tokens to 4096, to ensure a diverse
set of responses towards one question. This process produces 34500 pairs of questions and answers
for each type of problem. For the construction of the DPFT@Top dataset, all pairs of questions and
answers from the DPFT@Full dataset are ranked according to their penalized scores and only the top
20% of pairs with the highest scores are selected to form the DPFT@Top dataset, which results in
6900 pairs per problem type.
Based on the newly constructed datasets, for each problem type, we fine-tune Llama3.2:3B-Instruct
to obtain 3 new fine-tuned models, which are Llama3.2:3B-DPFT, Llama3.2:3B-DPFT@Full, and
Llama3.2:3B-DPFT@Top. For Llama3.2:3B-DPFT, it is fine-tuned on the DPFT dataset. For
Llama3.2:3B-DPFT@Full, it is fine-tuned on the DPFT@Full dataset. For Llama3.2:3B-DPFT@Top,
it is fine-tuned on the DPFT@Top dataset.
Based on the fine-tuned models, for each problem type, we form 9 baselines as follows:
1. Llama3.2:3B-Instruct + DP: The base model Llama3.2:3B-Instruct is used with the DP
method to answer questions. The temperature is set to 0 and the maximum number of
generated tokens to 4096;
2. Llama3.2:3B-Instruct + BoN: The base model Llama3.2:3B-Instruct is used with the BoN
method to answer questions, where ğ‘= 300, the temperature is set to 0.7, the maximum
number of generated tokens is set to 4096, and the maximum deduplication attempts is set to
3;
3. Llama3.2:3B-Instruct + Lyria: The base model Llama3.2:3B-Instruct is used with the Lyria
method to answer questions, under the same parameter setting as in Llama3.2:3B-LAFT;
4. Llama3.2:3B-DPFT + BoN: The fine-tuned model Llama3.2:3B-DPFT is used with the
BoN method to answer questions, under the same parameters settings as the second baseline
5. Llama3.2:3B-DPFT + Lyria: The fine-tuned model Llama3.2:3B-DPFT is used with the
Lyria method to answer questions, under the same parameters setting as the third baseline;
6. Llama3.2:3B-DPFT@Full + BoN: The fine-tuned model Llama3.2:3B-DPFT@Full is used
with the BoN method to answer questions, under the same parameters settings as the second
baseline;
7. Llama3.2:3B-DPFT@Full + Lyria: The fine-tuned model Llama3.2:3B-DPFT@Full is
used with the Lyria method to answer questions, under the same parameters setting as the
third baseline;
17


--- Page 18 ---
Preprint. Under review.
Model
Method
SKğ¶ğ‘…
SKğ‘ƒğ‘†
Llama3.2:3B-LAFT
Lyria
10
65.84
Llama3.2:3B-Instruct
DP
0
1.83
Llama3.2:3B-Instruct
BoN
0
15.04
Llama3.2:3B-Instruct
Lyria
0
10.45
Llama3.2:3B-DPFT
BoN
0
1.32
Llama3.2:3B-DPFT
Lyria
0
1.38
Llama3.2:3B-DPFT@Full
BoN
0
25.54
Llama3.2:3B-DPFT@Full
Lyria
0
12.61
Llama3.2:3B-DPFT@Top
BoN
0
15.97
Llama3.2:3B-DPFT@Top
Lyria
0
13.45
Table 2: Results of our approach LAFT and the constructed 9 baselines for SK.
Model
Method
GCğ¶ğ‘…
GCğ‘ƒğ‘†
Llama3.2:3B-LAFT
Lyria
0
92.99
Llama3.2:3B-Instruct
DP
0
67.97
Llama3.2:3B-Instruct
BoN
0
83.18
Llama3.2:3B-Instruct
Lyria
0
85.08
Llama3.2:3B-DPFT
BoN
0
74.66
Llama3.2:3B-DPFT
Lyria
0
88.38
Llama3.2:3B-DPFT@Full
BoN
0
84.44
Llama3.2:3B-DPFT@Full
Lyria
0
88.38
Llama3.2:3B-DPFT@Top
BoN
0
84.24
Llama3.2:3B-DPFT@Top
Lyria
0
87.85
Table 3: Results of our approach LAFT and the constructed 9 baselines for GC.
8. Llama3.2:3B-DPFT@Top + BoN: The fine-tuned model Llama3.2:3B-DPFT@Top is used
with the BoN method to answer questions, under the same parameters settings as the second
baseline;
9. Llama3.2:3B-DPFT@Top + Lyria: The fine-tuned model Llama3.2:3B-DPFT@Top is
used with the Lyria method to answer questions, under the same parameters settings as the
third baseline.
5.3
Results & Analysis
We demonstrate the results for SK, GC, and TSP problems in Table 2, 3, and 4, respectively.
Across the results of each problem type, Llama3.2:3B-LAFT always demonstrates the best performance
and consistently outperforms all 9 constructed baselines. For SK problems, it improves SKğ¶ğ‘…by 10%
and SKğ‘ƒğ‘†by 64.52 compared to the worst approach, i.e., Llama3.2:3B-DPFT with the BoN method,
while improving SKğ¶ğ‘…by 10% and SKğ‘ƒğ‘†by 40.30 compared to the best approach among 9 baselines,
i.e., Llama3.2:3B-DPFT@Full with the BoN method. For GC problems, it increases GCğ‘ƒğ‘†by 25.02
compared to the worst approach, i.e., Llama3.2:3B-Instruct with the DP method, while increasing
GCğ‘ƒğ‘†by 4.61 compared to the two best approaches among 9 baselines, i.e., Llama3.2:3B-DPFT
with the Lyria method and Llama3.2:3B-DPFT@Full with the Lyria method. For TSP problems, it
enhances TSPğ¶ğ‘…by 18% and TSPğ‘ƒğ‘†by 97.54 compared to the worst approach, i.e., Llama3.2:3B-
Instruct with the DP method, while enhancing TSPğ¶ğ‘…by 14% and SKğ‘ƒğ‘†by 1.51 compared to the
best approach among 9 baselines, i.e., Llama3.2:3B-DPFT@Full with the BoN method.
In addition, for SK problems, compared the results of Llama3.2:3B-LAFT with the results of GPT-
4o-Mini, Qwen2.5:32B-Instruct, Mistral:7B-Instruct, and Qwen2.5:7B-Instruct shown in Table 1,
the Llama3.2:3B-LAFT outperforms the best SKğ¶ğ‘…of GPT-4o-Mini, Mistral:7B-Instruct, and
Qwen2.5:7B-Instruct by 2%, 10%, and 10% respectively, and also outperforms the best SKğ‘ƒğ‘†of
Mistral:7B-Instruct and Qwen2.5:7B-Instruct by 53.84 and 4.82. For GC problems, the Llama3.2:3B-
LAFT outperforms the best GCğ‘ƒğ‘†of Mistral:7B-Instruct by 0.99. For TSP problems, the Llama3.2:3B-
18


--- Page 19 ---
Preprint. Under review.
Model
Method
TSPğ¶ğ‘…
TSPğ‘ƒğ‘†
Llama3.2:3B-LAFT
Lyria
18
97.53
Llama3.2:3B-Instruct
DP
0
0
Llama3.2:3B-Instruct
BoN
0
10.15
Llama3.2:3B-Instruct
Lyria
0
31.88
Llama3.2:3B-DPFT
BoN
0
90.39
Llama3.2:3B-DPFT
Lyria
0
91.11
Llama3.2:3B-DPFT@Full
BoN
4
96.02
Llama3.2:3B-DPFT@Full
Lyria
2
95.11
Llama3.2:3B-DPFT@Top
BoN
0
91.57
Llama3.2:3B-DPFT@Top
Lyria
0
91.94
Table 4: Results of our approach LAFT and the constructed 9 baselines for TSP.
LAFT outperforms the best TSPğ¶ğ‘…of GPT-4o-Mini, Mistral:7B-Instruct, and Qwen2.5:7B-Instruct by
12%, 18%, and 14% respectively, and also outperforms the best SKğ‘ƒğ‘†of GPT-4o-Mini, Mistral:7B-
Instruct, and Qwen2.5:7B-Instruct by 1.53, 8.53, and 2.53. From the results, it indicates that, with
LAFT, the performance of the weaker model like Llama3.2:3B-Instruct can even be elevated to
surpass the GPT-4o-mini. In addition, from the results, we observe that Llama3.2:3B-LAFT is the
one who approaches the performance closet to the stronger model, Qwen2.5:32B-Instruct, used to
generate FT dataset, and Llama3.2:3B-LAFT even outperforms Qwen2.5:32B-Instruct with the BoN
method for 2% in SKğ¶ğ‘…, 5.99 in GCğ‘ƒğ‘†, 10% in TSPğ¶ğ‘…, and 0.53 in TSPğ‘ƒğ‘†.
Furthermore, we consider and provide several reasons to explain why Llama3.2:3B-LAFT can
significantly outperform the constructed 9 baselines. Although the Llama3.2:3B-DPFT, Llama3.2:3B-
DPFT@Full, and Llama3.2:3B-DPFT@Top are trained on a diverse set of responses generated by
Qwen2.5-32B-Intruct, especially the latter twos, for the case that they use the BoN method, they
still merely generate a diverse set of answers which may still be locked in local optima without the
ability to reason beyond the local optima, and for the case they use the Lyria method, since they are
not fine-tuned to be able to proficiently follow and leverage the reasoning framework of Lyria and
they may also be disrupted by the FT process with DPFT, DPFT@Full, and DPFT@Top datasets
which do not include the data of Lyria reasoning process, they could fail to utilize the Lyria reasoning
framework during the inference even explicitly equipped with Lyria. However, for Llama3.2:3B-LAFT,
it is fine-tuned to follow the Lyria reasoning process of the stronger models, which can significantly
improve its proficiency in leveraging Lyria, and during inference, since Lyria can help escape the
local optima and explores a larger solution space, Llama3.2:3B-LAFT can then leverage Lyria to
reason over the questions to avoid locking in the local optima and obtain better performance.
6
Limitations and Future Directions
Although our evaluation of Lyria focuses on SK, GC, and TSP problems, the framework is not
restricted to these domains. Importantly, this work is not to leverage LLMs to achieve SOTA
performance on combinatorial optimization problems. Instead, this work aims to investigate and
improve the two major issues of LLMs we concern and discuss before. With these two major issues
being eased, we believe Lyria can be applied in a broader range of domains. For example, in code
generation domain, we can first construct the Oracle-based FE as a suite of tests and build the ECO
and the EMO as abstract syntax tree-based code operations, and then use Lyria to solve the code
generation problems, in the way of leveraging semantic understanding of LLMs, global search ability
of genetic algorithms, and complete solution space of external symbolic systems such as Oracle-based
FE, ECO, and EMO. We encourage and expect the integration of Lyria into these domains in future
works.
In addition, in Section 4.3.2, we observe a substantial performance gap between the Oracle-based FE
and the LLM-based FE. While this unsurprisingly shows that a reliable external symbolic system
can provide better guidance by giving correct fitness during evolution, it also reveals a limitation of
Lyria, that currently a robust Oracle-based FE is required to fully realize the effectiveness of Lyria.
This makes the present version of Lyria unsuitable for problems where verifying solutions is difficult.
19


--- Page 20 ---
Preprint. Under review.
Instead, it suits well for problems in which verification is easy but generating a correct solution is
challenging and where an Oracle-based FE is available. For instance, the code generation tasks
discussed above suits well for using Lyria to solve. Nevertheless, since we do not expect, in practice,
an Oracle-based FE is always available, we believe replacing the Oracle-based FE with an LLM-based
FE can greatly increase the applicability and convenience of Lyria in real-world applications. Thereby,
we expect future work to improve the LLM-based FE to approach the Oracle-based FE.
Moreover, currently, both ECO and EMO are manually designed, and as we observe in Section 4.3.4,
their design could significantly contribute to the performance. For different problems or domains, to
achieve effective ECOs and EMOs always requires dedicated experts to carefully craft them, often
involving multiple rounds of testing and iteration. Thus, it is necessary to develop an approach that
can automatically design ECOs and EMOs, thereby eliminating the burden of manual design. Such
an approach would not only facilitate the rapid application and generalization of this framework
across diverse domains and problems, but could also enable LLM-based agents to autonomously
design ECOs and EMOs when facing different environments and tasks, and thus leverage Lyria to
substantially enhance their capabilities. As discussed in Section 2, future works may follow the
approaches like LLaMEA (Stein & BÂ¨ack, 2025), EoH (Liu et al., 2024), and ReEvo (Ye et al., 2024)
to enable automatically generating metaheuristic algorithm to construct ECOs and EMOs, which can
future improve and polish the Lyria reasoning framework.
Furthermore, to our best knowledge, while several recent works begin to explore approaches that
integrate LLM with genetic algorithm, as mentioned in Section 2, these efforts have largely been
focused and confined to enhancing performance within a specific domain, falling short of offering a
reasoning framework that integrates of LLMs, genetic algorithms, and symbolic systems, and also a
comprehensive investigation into what factors may affect and govern its effectiveness. Hence, they
lack direct comparability with this work. In addition to integrating with genetic algorithms, research
on hybrid frameworks that integrate LLMs with other metaheuristic algorithms remains scarce,
such as integration of LLMs with particle swarm optimization or ant colony optimization. Since
different metaheuristic algorithms may offer distinct advantages across various domains and problem
types, further investigation along this line could yield deeper insights into the comparative benefits
of integrating LLMs with different metaheuristic algorithms. However, since works that explore
other LLM-driven metaheuristic frameworks in a manner similar to our approach are still lacking,
we are therefore unable to make a comparison. Therefore, as no directly comparable framework
currently exists, this paper concentrates more on the internal analysis to ensure that the observed
performance improvements arise from the virtue of the framework itself rather than from other factors,
e.g., increasing samplings, and examine the contribution and necessity of each component, while also
extending the idea to fine-tuning process and proposing LAFT.
Finally, while Lyria exerts significant performance improvements, especially when the population
size and generations are increased, it necessarily induces more LLM queries, leading to much longer
response time and higher costs, i.e., ğ¿-times more than the DP method as discussed in Section 4.2.1.
Therefore, reducing this overhead is an important goal for subsequent work.
7
Conclusion
In this work, we introduce Lyria, a neuro-symbolic reasoning framework building on the integration of
LLMs, genetic algorithms, and symbolic systems, comprising 7 essential components, to investigate
and improve two major issues of LLMs, which are that LLMs trap themselves into local optima and
they lack exhaustive coverage of the solution space. We conducted extensive experiments with 4
LLMs across 3 types of combinatorial reasoning problems, to show the superior effectiveness of
Lyria, and also conducted 7 additional ablation experiments to demonstrate how various factors affect
its performance. In addition, based on Lyria, we extend the ideas to the fine-tuning process of LLMs
and propose LAFT which enables a weaker model to imitate the reasoning process of a stronger model
that operates under Lyria. By conducting experiments, we demonstrate that LAFT can contribute
consistent and significant performance improvements against 9 constructed baselines. Furthermore,
we also reveal the limitations and offer perspectives on future directions. We hope this work offers
valuable insights into the integration of LLMs, genetic algorithms, and symbolic systems, and sparks
further exploration in this field.
20


--- Page 21 ---
Preprint. Under review.
References
Dhananjay Ashok, Joseph Scott, Sebastian Johann Wetzel, Maysum Panju, and Vijay Ganesh. Logic
guided genetic algorithms. ArXiv, abs/2010.11328, 2020. URL https://api.semanticscholar.
org/CorpusID:225039867.
Amanda Bertschinger, James Bagrow, and Joshua Bongard. Evolving form and function: Dual-
objective optimization in neural symbolic regression networks. In Proceedings of the Genetic and
Evolutionary Computation Conference, GECCO â€™24, pp. 277â€“285, New York, NY, USA, 2024.
Association for Computing Machinery. ISBN 9798400704949. doi: 10.1145/3638529.3654030.
URL https://doi.org/10.1145/3638529.3654030.
Owen Burns, Dana Hughes, and Katia Sycara. Plancritic: Formal planning with human feedback,
2024. URL https://arxiv.org/abs/2412.00300.
Xiaoshu Chen, Sihang Zhou, Ke Liang, and Xinwang Liu. Distilling reasoning ability from large
language models with adaptive thinking. IEEE Transactions on Neural Networks and Learning
Systems, 36(11):19820â€“19833, 2025. doi: 10.1109/TNNLS.2025.3591266.
Antoine Cully and Yiannis Demiris. Quality and diversity optimization: A unifying modular
framework. IEEE Transactions on Evolutionary Computation, 22(2):245â€“259, 2017.
A. Elshamli, H.A. Abdullah, and S. Areibi. Genetic algorithm for dynamic path planning. In Canadian
Conference on Electrical and Computer Engineering 2004 (IEEE Cat. No.04CH37513), volume 2,
pp. 677â€“680 Vol.2, 2004. doi: 10.1109/CCECE.2004.1345203.
Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng
Wang, and Haofen Wang. Retrieval-augmented generation for large language models: A survey,
2024. URL https://arxiv.org/abs/2312.10997.
Michel Gendreau, Jean-Yves Potvin, et al. Handbook of metaheuristics, volume 2. Springer, 2010.
Ian P Gent, Christopher Jefferson, and Peter Nightingale. Complexity of n-queens completion.
Journal of Artificial Intelligence Research, 59:815â€“848, 2017.
Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad
Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, Amy Yang, Angela Fan,
Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev,
Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen Gregerson, Ava Spataru,
Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya Nayak,
Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu,
Corinne Wong, Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle
Pintz, Danny Livshits, Danny Wyatt, David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego
Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina Lobanova,
Emily Dinan, Eric Michael Smith, Filip Radenovic, Francisco GuzmÂ´an, Frank Zhang, Gabriel
Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Govind Thattai, Graeme Nail, Gregoire Mialon,
Guan Pang, Guillem Cucurell, Hailey Nguyen, Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan
Zarov, Imanol Arrieta Ibarra, Isabel Kloumann, Ishan Misra, Ivan Evtimov, Jack Zhang, Jade
Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer
van der Linde, Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang,
Jiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca, Joshua
Johnstun, Joshua Saxe, Junteng Jia, Kalyan Vasuden Alwala, Karthik Prasad, Kartikeya Upasani,
Kate Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, Khalid El-Arini, Krithika Iyer, Kshitiz
Malik, Kuenley Chiu, Kunal Bhalla, Kushal Lakhotia, Lauren Rantala-Yeary, Laurens van der
Maaten, Lawrence Chen, Liang Tan, Liz Jenkins, Louis Martin, Lovish Madaan, Lubo Malo,
Lukas Blecher, Lukas Landzaat, Luke de Oliveira, Madeline Muzzi, Mahesh Pasupuleti, Mannat
Singh, Manohar Paluri, Marcin Kardas, Maria Tsimpoukelli, Mathew Oldham, Mathieu Rita, Maya
Pavlova, Melanie Kambadur, Mike Lewis, Min Si, Mitesh Kumar Singh, Mona Hassan, Naman
Goyal, Narjes Torabi, Nikolay Bashlykov, Nikolay Bogoychev, Niladri Chatterji, Ning Zhang,
Olivier Duchenne, Onur CÂ¸ elebi, Patrick Alrassy, Pengchuan Zhang, Pengwei Li, Petar Vasic, Peter
Weng, Prajjwal Bhargava, Pratik Dubal, Praveen Krishnan, Punit Singh Koura, Puxin Xu, Qing He,
Qingxiao Dong, Ragavan Srinivasan, Raj Ganapathy, Ramon Calderer, Ricardo Silveira Cabral,
21


--- Page 22 ---
Preprint. Under review.
Robert Stojnic, Roberta Raileanu, Rohan Maheswari, Rohit Girdhar, Rohit Patel, Romain Sauvestre,
Ronnie Polidoro, Roshan Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar Hosseini,
Sahana Chennabasappa, Sanjay Singh, Sean Bell, Seohyun Sonia Kim, Sergey Edunov, Shaoliang
Nie, Sharan Narang, Sharath Raparthy, Sheng Shen, Shengye Wan, Shruti Bhosale, Shun Zhang,
Simon Vandenhende, Soumya Batra, Spencer Whitman, Sten Sootla, Stephane Collot, Suchin
Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha, Thomas Georgiou,
Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao, Ujjwal Karn, Vedanuj Goswami,
Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez, Vincent Gonguet, Virginie Do, Vish Vogeti,
VÂ´Ä±tor Albiero, Vladan Petrovic, Weiwei Chu, Wenhan Xiong, Wenyin Fu, Whitney Meers, Xavier
Martinet, Xiaodong Wang, Xiaofang Wang, Xiaoqing Ellen Tan, Xide Xia, Xinfeng Xie, Xuchao
Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine Babaei, Yi Wen, Yiwen Song,
Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre Coudert, Zheng Yan, Zhengxing Chen, Zoe
Papakipos, Aaditya Singh, Aayushi Srivastava, Abha Jain, Adam Kelsey, Adam Shajnfeld, Adithya
Gangidi, Adolfo Victoria, Ahuva Goldstand, Ajay Menon, Ajay Sharma, Alex Boesenberg, Alexei
Baevski, Allie Feinstein, Amanda Kallet, Amit Sangani, Amos Teo, Anam Yunus, Andrei Lupu,
Andres Alvarado, Andrew Caples, Andrew Gu, Andrew Ho, Andrew Poulton, Andrew Ryan, Ankit
Ramchandani, Annie Dong, Annie Franco, Anuj Goyal, Aparajita Saraf, Arkabandhu Chowdhury,
Ashley Gabriel, Ashwin Bharambe, Assaf Eisenman, Azadeh Yazdan, Beau James, Ben Maurer,
Benjamin Leonhardi, Bernie Huang, Beth Loyd, Beto De Paola, Bhargavi Paranjape, Bing Liu,
Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence, Brani Stojkovic, Brian Gamido,
Britt Montalvo, Carl Parker, Carly Burton, Catalina Mejia, Ce Liu, Changhan Wang, Changkyu
Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal, Christoph Feichtenhofer,
Cynthia Gao, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel Li, David Adkins, David Xu,
Davide Testuggine, Delia David, Devi Parikh, Diana Liskovich, Didem Foss, Dingkang Wang, Duc
Le, Dustin Holland, Edward Dowling, Eissa Jamil, Elaine Montgomery, Eleonora Presani, Emily
Hahn, Emily Wood, Eric-Tuan Le, Erik Brinkman, Esteban Arcaute, Evan Dunbar, Evan Smothers,
Fei Sun, Felix Kreuk, Feng Tian, Filippos Kokkinos, Firat Ozgenel, Francesco Caggioni, Frank
Kanayet, Frank Seide, Gabriela Medina Florez, Gabriella Schwarz, Gada Badeer, Georgia Swee,
Gil Halpern, Grant Herman, Grigory Sizov, Guangyi, Zhang, Guna Lakshminarayanan, Hakan Inan,
Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha, Haroun Habeeb, Harrison Rudolph,
Helen Suk, Henry Aspegren, Hunter Goldman, Hongyuan Zhan, Ibrahim Damlaj, Igor Molybog,
Igor Tufanov, Ilias Leontiadis, Irina-Elena Veliche, Itai Gat, Jake Weissman, James Geboski, James
Kohli, Janice Lam, Japhet Asher, Jean-Baptiste Gaya, Jeff Marcus, Jeff Tang, Jennifer Chan, Jenny
Zhen, Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong, Jian Jin, Jingyi Yang, Joe Cummings,
Jon Carvill, Jon Shepard, Jonathan McPhie, Jonathan Torres, Josh Ginsburg, Junjie Wang, Kai
Wu, Kam Hou U, Karan Saxena, Kartikay Khandelwal, Katayoun Zand, Kathy Matosich, Kaushik
Veeraraghavan, Kelly Michelena, Keqian Li, Kiran Jagadeesh, Kun Huang, Kunal Chawla, Kyle
Huang, Lailin Chen, Lakshya Garg, Lavender A, Leandro Silva, Lee Bell, Lei Zhang, Liangpeng
Guo, Licheng Yu, Liron Moshkovich, Luca Wehrstedt, Madian Khabsa, Manav Avalani, Manish
Bhatt, Martynas Mankus, Matan Hasson, Matthew Lennie, Matthias Reso, Maxim Groshev, Maxim
Naumov, Maya Lathi, Meghan Keneally, Miao Liu, Michael L. Seltzer, Michal Valko, Michelle
Restrepo, Mihir Patel, Mik Vyatskov, Mikayel Samvelyan, Mike Clark, Mike Macey, Mike Wang,
Miquel Jubert Hermoso, Mo Metanat, Mohammad Rastegari, Munish Bansal, Nandhini Santhanam,
Natascha Parks, Natasha White, Navyata Bawa, Nayan Singhal, Nick Egebo, Nicolas Usunier,
Nikhil Mehta, Nikolay Pavlovich Laptev, Ning Dong, Norman Cheng, Oleg Chernoguz, Olivia
Hart, Omkar Salpekar, Ozlem Kalinli, Parkin Kent, Parth Parekh, Paul Saab, Pavan Balaji, Pedro
Rittner, Philip Bontrager, Pierre Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratanchandani,
Pritish Yuvraj, Qian Liang, Rachad Alao, Rachel Rodriguez, Rafi Ayub, Raghotham Murthy, Raghu
Nayani, Rahul Mitra, Rangaprabhu Parthasarathy, Raymond Li, Rebekkah Hogan, Robin Battey,
Rocky Wang, Russ Howes, Ruty Rinott, Sachin Mehta, Sachin Siby, Sai Jayesh Bondu, Samyak
Datta, Sara Chugh, Sara Hunt, Sargun Dhillon, Sasha Sidorov, Satadru Pan, Saurabh Mahajan,
Saurabh Verma, Seiji Yamamoto, Sharadh Ramaswamy, Shaun Lindsay, Shaun Lindsay, Sheng
Feng, Shenghao Lin, Shengxin Cindy Zha, Shishir Patil, Shiva Shankar, Shuqiang Zhang, Shuqiang
Zhang, Sinong Wang, Sneha Agarwal, Soji Sajuyigbe, Soumith Chintala, Stephanie Max, Stephen
Chen, Steve Kehoe, Steve Satterfield, Sudarshan Govindaprasad, Sumit Gupta, Summer Deng,
Sungmin Cho, Sunny Virk, Suraj Subramanian, Sy Choudhury, Sydney Goldman, Tal Remez,
Tamar Glaser, Tamara Best, Thilo Koehler, Thomas Robinson, Tianhe Li, Tianjun Zhang, Tim
Matthews, Timothy Chou, Tzook Shaked, Varun Vontimitta, Victoria Ajayi, Victoria Montanez,
Vijai Mohan, Vinay Satish Kumar, Vishal Mangla, Vlad Ionescu, Vlad Poenaru, Vlad Tiberiu
22


--- Page 23 ---
Preprint. Under review.
Mihailescu, Vladimir Ivanov, Wei Li, Wenchen Wang, Wenwen Jiang, Wes Bouaziz, Will Constable,
Xiaocheng Tang, Xiaojian Wu, Xiaolan Wang, Xilun Wu, Xinbo Gao, Yaniv Kleinman, Yanjun
Chen, Ye Hu, Ye Jia, Ye Qi, Yenda Li, Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam, Yu,
Wang, Yu Zhao, Yuchen Hao, Yundi Qian, Yunlu Li, Yuzi He, Zach Rait, Zachary DeVito, Zef
Rosnbrick, Zhaoduo Wen, Zhenyu Yang, Zhiwei Zhao, and Zhiyu Ma. The llama 3 herd of models,
2024. URL https://arxiv.org/abs/2407.21783.
Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian,
and Yujiu Yang. Connecting large language models with evolutionary algorithms yields powerful
prompt optimizers, 2024. URL https://arxiv.org/abs/2309.08532.
Shaima Hameed, Yousef Elsheikh, and Mohammad Azzeh. An optimized case-based software project
effort estimation using genetic algorithm. Information and Software Technology, 153:107088,
2023.
Guangzeng Han, Weisi Liu, and Xiaolei Huang. Attributes as textual genes: Leveraging LLMs as
genetic algorithm simulators for conditional synthetic data generation. In Christos Christodoulopou-
los, Tanmoy Chakraborty, Carolyn Rose, and Violet Peng (eds.), Findings of the Association for
Computational Linguistics: EMNLP 2025, pp. 19367â€“19389, Suzhou, China, November 2025.
Association for Computational Linguistics. ISBN 979-8-89176-335-7. doi: 10.18653/v1/2025.
findings-emnlp.1055. URL https://aclanthology.org/2025.findings-emnlp.1055/.
Erik Hemberg, Stephen Moskal, and Una-May Oâ€™Reilly. Evolving code with a large language model.
Genetic Programming and Evolvable Machines, 25(2):21, 2024.
Cheng-Yu Hsieh, Chun-Liang Li, Chih-kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alex Ratner, Ranjay
Krishna, Chen-Yu Lee, and Tomas Pfister. Distilling step-by-step! outperforming larger language
models with less training data and smaller model sizes. In Anna Rogers, Jordan Boyd-Graber, and
Naoaki Okazaki (eds.), Findings of the Association for Computational Linguistics: ACL 2023, pp.
8003â€“8017, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/
v1/2023.findings-acl.507. URL https://aclanthology.org/2023.findings-acl.507/.
Juyong Jiang, Fan Wang, Jiasi Shen, Sungju Kim, and Sunghun Kim. A survey on large language
models for code generation, 2024. URL https://arxiv.org/abs/2406.00515.
Sourabh Katoch, Sumit Singh Chauhan, and Vijay Kumar. A review on genetic algorithm: past,
present, and future. Multimedia Tools and Applications, 80(5):8091â€“8126, February 2021. ISSN
1380-7501, 1573-7721. doi: 10.1007/s11042-020-10139-6.
Daniel Kobler. Evolutionary algorithms in combinatorial optimizationEvolutionary Algorithms
in Combinatorial Optimization, pp. 950â€“959. Springer US, Boston, MA, 2009. ISBN 978-
0-387-74759-0.
doi: 10.1007/978-0-387-74759-0 167.
URL https://doi.org/10.1007/
978-0-387-74759-0 167.
JohnR. Koza. Genetic programming as a means for programming computers by natural selection.
Statistics and Computing, 4(2), June 1994. ISSN 0960-3174, 1573-1375. doi: 10.1007/BF00175355.
URL http://link.springer.com/10.1007/BF00175355.
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,
Heinrich KÂ¨uttler, Mike Lewis, Wen-tau Yih, Tim RocktÂ¨aschel, Sebastian Riedel, and Douwe Kiela.
Retrieval-augmented generation for knowledge-intensive nlp tasks. In Proceedings of the 34th
International Conference on Neural Information Processing Systems, NIPS â€™20, Red Hook, NY,
USA, 2020. Curran Associates Inc. ISBN 9781713829546.
Fei Liu, Xialiang Tong, Mingxuan Yuan, Xi Lin, Fu Luo, Zhenkun Wang, Zhichao Lu, and Qingfu
Zhang. Evolution of heuristics: towards efficient automatic algorithm design using large language
model. In Proceedings of the 41st International Conference on Machine Learning, ICMLâ€™24.
JMLR.org, 2024.
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,
Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder,
Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark. Self-refine: Iterative
refinement with self-feedback. In Thirty-seventh Conference on Neural Information Processing
Systems, 2023. URL https://openreview.net/forum?id=S37hOerQLB.
23


--- Page 24 ---
Preprint. Under review.
Somshubra Majumdar, Vahid Noroozi, Mehrzad Samadi, Sean Narenthiran, Aleksander Ficek,
Wasi Uddin Ahmad, Jocelyn Huang, Jagadeesh Balam, and Boris Ginsburg. Genetic instruct:
Scaling up synthetic generation of coding instructions for large language models. In Georg Rehm
and Yunyao Li (eds.), Proceedings of the 63rd Annual Meeting of the Association for Computational
Linguistics (Volume 6: Industry Track), pp. 208â€“221, Vienna, Austria, July 2025. Association for
Computational Linguistics. ISBN 979-8-89176-288-6. doi: 10.18653/v1/2025.acl-industry.16.
URL https://aclanthology.org/2025.acl-industry.16/.
Chinmay Mittal, Krishna Kartik, Mausam, and Parag Singla. Fcorebench: Can large language
models solve challenging first-order combinatorial reasoning problems?, 2025. URL https:
//arxiv.org/abs/2402.02611.
Clint Morris, Michael Jurado, and Jason Zutty. Llm guided evolution - the automation of models
advancing models. In Proceedings of the Genetic and Evolutionary Computation Conference,
GECCO â€™24, pp. 377â€“384, New York, NY, USA, 2024. Association for Computing Machinery.
ISBN 9798400704949. doi: 10.1145/3638529.3654178. URL https://doi.org/10.1145/
3638529.3654178.
Muhammad Umair Nasir, Sam Earle, Julian Togelius, Steven James, and Christopher Cleghorn.
Llmatic: Neural architecture search via large language models and quality diversity optimization. In
Proceedings of the Genetic and Evolutionary Computation Conference, GECCO â€™24, pp. 1110â€“1118,
New York, NY, USA, 2024. Association for Computing Machinery. ISBN 9798400704949. doi:
10.1145/3638529.3654017. URL https://doi.org/10.1145/3638529.3654017.
Liangming Pan, Alon Albalak, Xinyi Wang, and William Wang. Logic-LM: Empowering large
language models with symbolic solvers for faithful logical reasoning. In Houda Bouamor, Juan Pino,
and Kalika Bali (eds.), Findings of the Association for Computational Linguistics: EMNLP 2023, pp.
3806â€“3824, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/
v1/2023.findings-emnlp.248. URL https://aclanthology.org/2023.findings-emnlp.248/.
Christos H. Papadimitriou and Kenneth Steiglitz. Some complexity results for the traveling salesman
problem. In Proceedings of the Eighth Annual ACM Symposium on Theory of Computing, STOC â€™76,
pp. 1â€“9, New York, NY, USA, 1976. Association for Computing Machinery. ISBN 9781450374149.
doi: 10.1145/800113.803625. URL https://doi.org/10.1145/800113.803625.
Giovanni Pinna, Damiano Ravalico, Luigi Rovito, Luca Manzoni, and Andrea De Lorenzo. Enhancing
large language models-based code generation by leveraging genetic improvement. In Mario
Giacobini, Bing Xue, and Luca Manzoni (eds.), Genetic Programming, pp. 108â€“124, Cham, 2024.
Springer Nature Switzerland. ISBN 978-3-031-56957-9.
Justin K Pugh, Lisa B Soros, and Kenneth O Stanley. Quality diversity: A new frontier for evolutionary
computation. Frontiers in Robotics and AI, 3:40, 2016.
Xin Qiu, Yulu Gan, Conor F. Hayes, Qiyao Liang, Elliot Meyerson, Babak Hodjat, and Risto
Miikkulainen. Evolution strategies at scale: Llm fine-tuning beyond reinforcement learning, 2025.
URL https://arxiv.org/abs/2509.24372.
Qwen, :, An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan
Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang,
Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin
Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li, Tianyi
Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang, Yu Wan,
Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 technical report, 2025. URL
https://arxiv.org/abs/2412.15115.
Simon SchÂ¨afer and Stephan Schulz. Breeding theorem proving heuristics with genetic algorithms. In
GCAI, pp. 263â€“274. Citeseer, 2015.
Yinan Shao, Jerry Chun-Wei Lin, Gautam Srivastava, Dongdong Guo, Hongchun Zhang, Hu Yi,
and Alireza Jolfaei. Multi-objective neural evolutionary algorithm for combinatorial optimization
problems. IEEE Transactions on Neural Networks and Learning Systems, 34(4):2133â€“2143, 2023.
doi: 10.1109/TNNLS.2021.3105937.
24


--- Page 25 ---
Preprint. Under review.
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik R Narasimhan, and Shunyu Yao. Reflexion:
language agents with verbal reinforcement learning. In Thirty-seventh Conference on Neural
Information Processing Systems, 2023. URL https://openreview.net/forum?id=vAElhFcKW6.
Peiyang Song, Kaiyu Yang, and Anima Anandkumar. Lean copilot: Large language models as
copilots for theorem proving in lean, 2025. URL https://arxiv.org/abs/2404.12534.
Niki van Stein and Thomas BÂ¨ack. Llamea: A large language model evolutionary algorithm for
automatically generating metaheuristics. Trans. Evol. Comp, 29(2):331â€“345, April 2025. ISSN
1089-778X. doi: 10.1109/TEVC.2024.3497793. URL https://doi.org/10.1109/TEVC.2024.
3497793.
Alireza Tamaddoni-Nezhad and Stephen Muggleton. Using genetic algorithms for learning clauses
in first-order logic. In Proceedings of the 3rd Annual Conference on Genetic and Evolutionary
Computation, pp. 639â€“646, 2001.
Weizhi Tang and Vaishak Belle.
Tom-lm: Delegating theory of mind reasoning to external
symbolic executors in large language models. In Neural-Symbolic Learning and Reasoning: 18th
International Conference, NeSy 2024, Barcelona, Spain, September 9â€“12, 2024, Proceedings,
Part II, pp. 245â€“257, Berlin, Heidelberg, 2024. Springer-Verlag. ISBN 978-3-031-71169-5. doi:
10.1007/978-3-031-71170-1 20. URL https://doi.org/10.1007/978-3-031-71170-1 20.
Weizhi Tang, Yixuan Li, Chris Sypherd, Elizabeth Polgreen, and Vaishak Belle. HyGenar: An
LLM-driven hybrid genetic algorithm for few-shot grammar generation. In Wanxiang Che, Joyce
Nabende, Ekaterina Shutova, and Mohammad Taher Pilehvar (eds.), Findings of the Association for
Computational Linguistics: ACL 2025, pp. 13640â€“13665, Vienna, Austria, July 2025. Association
for Computational Linguistics. ISBN 979-8-89176-256-5. doi: 10.18653/v1/2025.findings-acl.701.
URL https://aclanthology.org/2025.findings-acl.701/.
Karthik Valmeekam, Matthew Marquez, Sarath Sreedharan, and Subbarao Kambhampati. On the
planning abilities of large language models: a critical investigation. In Proceedings of the 37th
International Conference on Neural Information Processing Systems, NIPS â€™23, Red Hook, NY,
USA, 2023. Curran Associates Inc.
Xiaohan Xu, Ming Li, Chongyang Tao, Tao Shen, Reynold Cheng, Jinyang Li, Can Xu, Dacheng
Tao, and Tianyi Zhou. A survey on knowledge distillation of large language models, 2024. URL
https://arxiv.org/abs/2402.13116.
Takayuki Yato and Takahiro Seta. Complexity and completeness of finding another solution and its
application to puzzles. IEICE transactions on fundamentals of electronics, communications and
computer sciences, 86(5):1052â€“1060, 2003.
Haoran Ye, Jiarui Wang, Zhiguang Cao, Federico Berto, Chuanbo Hua, Haeyeon Kim, Jinkyoo Park,
and Guojie Song. Reevo: large language models as hyper-heuristics with reflective evolution. In
Proceedings of the 38th International Conference on Neural Information Processing Systems, NIPS
â€™24, Red Hook, NY, USA, 2024. Curran Associates Inc. ISBN 9798331314385.
Xuekai Zhu, Biqing Qi, Kaiyan Zhang, Xinwei Long, Zhouhan Lin, and Bowen Zhou. PaD:
Program-aided distillation can teach small models reasoning better than chain-of-thought fine-
tuning. In Kevin Duh, Helena Gomez, and Steven Bethard (eds.), Proceedings of the 2024
Conference of the North American Chapter of the Association for Computational Linguistics:
Human Language Technologies (Volume 1: Long Papers), pp. 2571â€“2597, Mexico City, Mexico,
June 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.naacl-long.142.
URL https://aclanthology.org/2024.naacl-long.142/.
25


--- Page 26 ---
Preprint. Under review.
A
L Calculation of Lyria
Lyria could sample an LLM up to ğ¿times for a single problem. Let ğ‘›ğ‘be the population size, ğ‘›ğ‘”be
the generations, ğœ‚be the crossover rate, ğœ‰be the external crossover rate, ğœ…be the mutation rate, and ğœ‡
be the external mutation rate. The sample times ğ¿are given as:
ğ¿= ğ‘›ğ‘+  ğ‘›ğ‘Â· ğœ‚Â· (1 âˆ’ğœ‰) + ğ‘›ğ‘Â· ğœ…Â· (1 âˆ’ğœ‡) Â· ğ‘›ğ‘”
Thus, for example, given ğ‘›ğ‘= 30, ğ‘›ğ‘”= 15, ğœ‚= 0.7, ğœ‰= 0.3, ğœ…= 0.3, ğœ‡= 0.3, we have ğ¿=
30 + (30 Â· 0.7 Â· (1 âˆ’0.3) + 30 Â· 0.3 Â· (1 âˆ’0.3)) Â· 15 = 345.
B
Additional Results
We demonstrate the results of all metrics for each problem type in Table 5, 6, and 7.
Model
Method
SKğ¶ğ‘…
SKğ‘†ğ¶
SKğ‘ƒğ‘†
GPT-4o-Mini
DP
0
43
39
BoN
6
74
73
Lyria
8
74
73
Qwen2.5:32B-Instruct
DP
0
35
31
BoN
8
77
76
Lyria
32
87
87
Mistral:7B-Instruct
DP
0
1
0
BoN
0
11
5
Lyria
0
16
12
Qwen2.5:7B-Instruct
DP
0
32
26
BoN
0
57
55
Lyria
0
62
61
Table 5: The results of all metrics for SK.
Model
Method
GCğ¶ğ‘…
GCğ‘†ğ¶
GCğ‘ƒğ‘†
GCğ¶ğ¹
GPT-4o-Mini
DP
0
73
73
27
BoN
0
86
86
14
Lyria
0
97
97
4
Qwen2.5:32B-Instruct
DP
0
74
74
26
BoN
0
87
87
13
Lyria
0
96
96
4
Mistral:7B-Instruct
DP
0
100
0
0
BoN
0
86
84
15
Lyria
0
93
92
7
Qwen2.5:7B-Instruct
DP
0
73
73
27
BoN
0
84
84
16
Lyria
0
95
95
5
Table 6: The results of all metrics for GC.
26


--- Page 27 ---
Preprint. Under review.
Model
Method
TSPğ¶ğ‘…
TSPğ‘ƒğ‘†
TSPğ¸ğ·ğ‘€
TSPğ‘€ğ¶
GPT-4o-Mini
DP
0
79
0.64
0
BoN
4
94
0.18
0
Lyria
6
96
0.13
0
Qwen2.5:32B-Instruct
DP
0
81
0.58
0
BoN
8
97
0.09
0
Lyria
30
99
0.04
0
Mistral:7B-Instruct
DP
0
60
1.20
2
BoN
0
80
0.61
0
Lyria
0
89
0.31
0
Qwen2.5:7B-Instruct
DP
0
34
1.97
5
BoN
0
88
0.36
0
Lyria
4
95
0.15
0
Table 7: The results of all metrics for TSP.
C
Prompts
Prompt Template 1: Sudoku LLM-Based Error Detector
===Instructions===
1. You are a Sudoku expert who can find the errors in a sudoku candidate solution;
2. Given this Sudoku puzzle and its candidate solution, you should find the errors in the
candidate solution;
3. The correctness of the solution depends on:
(1) Correct Syntax: it has a correct format, meaning each row, column, and
{subgrid size}x{subgrid size} square exactly contain {puzzle grid size} number, and each
cell is separated by space. The solution format must be in the same format as the given puzzle
but there is no unfilled dot;
(2) Correct Semantics: for each row, column, and {subgrid size}x{subgrid size} square, the
numbers 1 to {puzzle grid size} should appear exactly once;
4. If the syntax is incorrect, the errors should be â€Syntax is wrongâ€ (Noted as Type 1 Error
Msg);
5. If the syntax is correct, the errors should be the positions of the wrong numbers in the
candidate solution with its conflict type, â€rowâ€, â€colâ€, or â€subgridâ€ (Noted as Type 2 Error
Msg);
6. You should find all the errors in the candidate solution;
7. If there are no errors, the errors should be â€No errorsâ€ (Noted as Type 3 Error Msg);
8. You can think it thoroughly in any way you want, but You MUST give the errors in the end
of your thinking in the format as:
(1) For Type 1 Error Msg: â€Syntax is wrongâ€ wrapped in triple backticks as a code block;
(2) For Type 2 Error Msg:
a. Each error is in the format as â€i,j,typeâ€, where i is the row number and j is the column
number starting from 0 and type is the conflict type, â€rowâ€, â€colâ€, or â€subgridâ€;
b. Each error is separated by a newline;
c. All errors should be wrapped in triple backticks as a code block;
(3) For Type 3 Error Msg: â€No errorsâ€ wrapped in triple backticks as a code block;
(4) You can give comments or explanations before or after the code block but you MUST
NOT give any comments or explanations in the code block;
===Type 1 Error Example===
```
Syntax is wrong
```
===Type 2 Error Example===
27


--- Page 28 ---
Preprint. Under review.
```
0,0,row
1,0,subgrid
2,1,col
```
===Type 3 Error Example===
```
No errors
```
===Sudoku Puzzle===
```
{puzzle}
```
===Candidate Solution===
```
{candidate}
```
Prompt Template 2: Graph Coloring LLM-Based Error Detector
===Instructions===
1. You are a Graph Coloring expert who can find the errors in a graph coloring candidate
solution;
2. Given this Graph Coloring puzzle:
(1) The graph is represented by the adjacency matrix with {n vertices} vertices, in which â€yâ€
means the two vertices are adjacent and â€nâ€ means the two vertices are not adjacent;
(2) The goal is to color the vertices with {color count} colors such that no two adjacent
vertices have the same color;
3. Given its candidate solution, you should find all the errors in the candidate solution;
4. The correctness of the solution depends on:
(1) Correct Syntax: the solution should be a list of {n vertices} integers separated by comma
such as â€0,1,2â€, each integer represents the color of the corresponding vertex, and the colors
should be integers from 0 to {color count - 1};
(2) Correct Semantics: for each pair of adjacent vertices, the colors of the two vertices should
be different;
4. If the syntax is incorrect, the errors should be â€Syntax is wrongâ€ (Noted as Type 1 Error
Msg);
5. If the syntax is correct, the errors messages should be in two types:
(1) Type 2.1 Error Msg: the error msg are in the format as â€i,j,colorâ€, where i is the vertex
number, j is the vertex number, and color is the conflict color, and all of them are integers and
separated by comma;
(2) Type 2.2 Error Msg: the error msg are in a number which indicates the number of
exceeded colors, such as â€0â€ means no exceeded colors, â€1â€ means one exceeded color, â€-1â€
means the colors used are less than the allowed color count, and so on;
6. You should find all the errors in the candidate solution;
7. If there are no errors, the errors should be â€No errorsâ€ (Noted as Type 3 Error Msg);
8. You can think it thoroughly in any way you want, but You MUST give the errors in the end
of your thinking in the format as:
(1) For Type 1 Error Msg: â€Syntax is wrongâ€ wrapped in triple backticks as a code block with
the language indicator as â€t1â€;
(2) For Type 2.1 Error Msg:
a. Each error is in the format as â€i,j,colorâ€, where i is the vertex number, j is the vertex
number, and color is the conflict color, and all of them are integers and separated by comma;
b. Each error is separated by a newline;
c. All errors should be wrapped in triple backticks as a code block with the language indicator
as â€t2.1â€;
28


--- Page 29 ---
Preprint. Under review.
(3) For Type 2.2 Error Msg: the number of exceeded colors wrapped in triple backticks as a
code block with the language indicator as â€t2.2â€;
(3) For Type 3 Error Msg: â€No errorsâ€ wrapped in triple backticks as a code block with the
language indicator as â€t3â€;
(4) You can give comments or explanations before or after the code block but you MUST
NOT give any comments or explanations in the code block;
===Type 1 Error Msg Example===
```t1
Syntax is wrong
```
===Type 2.1 Error Msg Example===
```t2.1
0,1,2
1,2,0
â€œâ€˜
===Type 2.2 Error Msg Example===
```t2.2
1
```
===Type 3 Error Msg Example===
```t3
No errors
```
===Graph Adjacency Matrix===
```
{adjacency matrix}
```
===Candidate Solution===
```
{candidate}
```
Prompt Template 3: Travel Salesman Problem Error Detector
===Instructions===
1. You are a Travel Salesman Problem expert who can find all the errors in a TSP candidate
solution;
2. Given this Traveling Salesman Problem puzzle:
(1) The distance matrix is a 2D matrix with {n cities} rows and {n cities} columns, in which
each element represents the distance of traveling from the city in the row to the city in the
column;
(2) The goal is to find the shortest path that visits each city exactly once and returns to the
origin city;
3. Given its candidate solution, you should find all the errors in the candidate solution;
4. The correctness of the solution depends on:
(1) Correct Syntax:
a. the solution should be a list of {n cities} integers separated by comma such as â€0,1,2â€,
each integer represents the index of the city in the path, and the indexes should be integers
from 0 to {n cities - 1};
b. the first and last city should be the same and should be 0, which means the path should
return to the origin city which is 0;
c. the index of city should be in the range from 0 to {n cities - 1};
(2) Correct Semantics:
a. No missing city: the path should visit each city exactly once and return to the origin city;
b. Optimal path: the path should be the shortest path;
5. If the syntax is incorrect, the errors should be â€Syntax is wrongâ€ (Noted as Type 1 Error
Msg);
29


--- Page 30 ---
Preprint. Under review.
6. If the syntax is correct, the errors messages should be in two types:
(1) Type 2.1 Error Msg: the error msg are in the format of list separated by comma, where
each element is a missing city in the path, such as â€0,1,2â€, where 0, 1, 2 are the missing cities,
and all of them are integers and separated by comma;
(2) Type 2.2 Error Msg: the error msg are in a number which indicates the exceeded distance,
such as â€0â€ means the distance is the optimal distance, â€10.5â€ means the distance exceeds the
optimal distance by 10.5, and it should be a float;
6. You should find all the errors in the candidate solution;
7. If there are no errors, the errors should be â€No errorsâ€ (Noted as Type 3 Error Msg);
8. You can think it thoroughly in any way you want, but You MUST give the errors in the end
of your thinking in the format as:
(1) For Type 1 Error Msg: â€Syntax is wrongâ€ wrapped in triple backticks as a code block with
the language indicator as â€t1â€;
(2) For Type 2.1 Error Msg:
a. the error msg are in the format of list separated by comma, where each element is a missing
city in the path, such as â€0,1,2â€, where 0, 1, 2 are the missing cities, and all of them are
integers and separated by comma;
c. the error should be wrapped in triple backticks as a code block with the language indicator
as â€t2.1â€;
(3) For Type 2.2 Error Msg: the exceeded distance wrapped in triple backticks as a code block
with the language indicator as â€t2.2â€;
(3) For Type 3 Error Msg: â€No errorsâ€ wrapped in triple backticks as a code block with the
language indicator as â€t3â€;
(4) You can give comments or explanations before or after the code block but you MUST
NOT give any comments or explanations in the code block;
===Type 1 Error Msg Example===
```t1
Syntax is wrong
```
===Type 2.1 Error Msg Example===
```t2.1
0,1,2
```
===Type 2.2 Error Msg Example===
```t2.2
10.5
```
===Type 3 Error Example===
```t3
No errors
```
===Distance Matrix===
```
{distance matrix}
```
===Candidate Solution===
```
{candidate}
```
Prompt Template 4: Sudoku LLM-based Fitness Evaluator
===Instructions===
1. You are a Sudoku expert who can evaluate whether a sudoku candidate solution is correct
or not, or how close it is to the correct solution;
2. Given this Sudoku puzzle and its candidate solution, you should evaluate its score. The
score is to measure how close the candidate is to the solution;
30


--- Page 31 ---
Preprint. Under review.
3. The correctness of the solution depends on:
(1) Correct Syntax: it has a correct format, meaning each row, column, and
{subgrid size}x{subgrid size} square exactly contain {puzzle grid size} number, and each
cell is separated by space. The solution format must be in the same format as the given puzzle
but there is no unfilled dot;
(2) Correct Semantics: for each row, column, and {subgrid size}x{subgrid size} square, the
numbers 1 to {puzzle grid size} should appear exactly once;
4. If the syntax is incorrect, the fitness score should be 0.0;
5. If the syntax is correct, the score is calculated based on the number of correct numbers in
rows, columns, and subgrids, and shown in percentage. R = number of correct rows /
{puzzle grid size} + {delta}, C = number of correct columns / {puzzle grid size} + {delta},
and S = number of correct subgrids / {puzzle grid size} + {delta}. The fitness score is
calculated based on geometric mean as (R x C x S) ** (1/3) * 100.0, in which higher is better
and 0.0 means the candidate is wrong at all while 100.0 means the candidate is correct;
6. In most of time, you should NOT give a score of 0.0 unless Â¡4Â¿ are satisfied; You should
give a score between 0.0 and 100.0 to indicate how close the candidate is to the correct
solution;
7. Think it carefully and do NOT randomly guess the score;
8. You can think it thoroughly in any way you want, but You MUST give the score as a float
number in the end of your thinking.
===Sudoku Puzzle===
```
{puzzle}
```
===Candidate Solution===
```
{candidate}
```
Prompt Template 5: Graph Coloring LLM-based Fitness Evaluator
===Instructions===
1. You are a Graph Coloring expert who can evaluate whether a graph coloring candidate
solution is correct or not, or how close it is to the correct solution;
2. Given this Graph Coloring puzzle:
(1) The graph is represented by the adjacency matrix with {n vertices} vertices, in which â€yâ€
means the two vertices are adjacent and â€nâ€ means the two vertices are not adjacent;
(2) The goal is to color the vertices with {color count} colors such that no two adjacent
vertices have the same color;
3. Given its candidate solution, you should evaluate its score. The score is to measure how
close the candidate is to the solution;
4. The correctness of the solution depends on:
(1) Correct Syntax: the solution should be a list of {n vertices} integers separated by comma
such as â€0,1,2â€, each integer represents the color of the corresponding vertex, and the colors
should be integers from 0 to {color count - 1};
(2) Correct Semantics: for each pair of adjacent vertices, the colors of the two vertices should
be different;
4. If the syntax is incorrect, the fitness score should be 0.0;
5. If the syntax is correct, the score is calculated based on:
(1) Number of Conflicted Edges (noted as CE): the number of edges that two adjacent vertices
have the same color;
(2) Number of Exceeded Colors (noted as EC): the number of colors exceeded the allowed
color count;
(3) The score is now calculated as: Max(0, (1 - (CE/{n edges})) * (1 - EC/({n vertices -
color count}))) * 100, which means the score does not only depend on the number of
conflicted edges but also the number of exceeded colors and ranges from 0.0 to 100.0;
31


--- Page 32 ---
Preprint. Under review.
6. In most of time, you should NOT give a score of 0.0 unless your are very sure; You should
give a score between 0.0 and 100.0 to indicate how close the candidate is to the correct
solution;
7. Think it carefully and do NOT randomly guess the score;
8. You can think it thoroughly in any way you want, but You MUST give the score as a float
number in the end of your thinking.
===Graph Adjacency Matrix===
```
adjacency matrix str
```
===Candidate Solution===
```
{candidate}
```
Prompt Template 6: Travel Salesman Problem LLM-based Fitness Evaluator
===Instructions===
1. You are a Travel Salesman Problem expert who can evaluate whether a TSP candidate
solution is correct or not, or how close it is to the correct solution;
2. Given this Traveling Salesman Problem puzzle:
(1) The distance matrix is a 2D matrix with {n cities} rows and {n cities} columns, in which
each element represents the distance of traveling from the city in the row to the city in the
column;
(2) The goal is to find the shortest path that visits each city exactly once and returns to the
origin city;
3. Given its candidate solution, you should evaluate its score. The score is to measure how
close the candidate is to the solution;
4. The correctness of the solution depends on:
(1) Correct Syntax:
a. the solution should be a list of {n cities} integers separated by comma such as â€0,1,2â€,
each integer represents the index of the city in the path, and the indexes should be integers
from 0 to {n cities - 1};
b. the first and last city should be the same and should be 0, which means the path should
return to the origin city which is 0;
c. the index of city should be in the range from 0 to {n cities - 1};
(2) Correct Semantics:
a. No missing city: the path should visit each city exactly once and return to the origin city;
b. Optimal path: the path should be the shortest path;
4. If the syntax is incorrect, the fitness score should be 0.0;
5. If the syntax is correct, the score is calculated based on:
(1) Number of Missing Cities (noted as MC): the number of missing cities in the path;
(2) Used Distance (noted as UD): the total distance of the path;
(3) The score is computed as follows (in range of [0...100]):
1) Let base score = 100;
2) Let OD = the sum of the shortest distances of the path; (You should try to the best to think
about its optimal distance)
3) Let ED = UD - OD;
4) Let ED Multiplier = ED / OD; (calculate how much the distance exceeds the optimal
distance, it MUST be in range of [0...{DEFAULT EDM}])
5) distance excess ratio = ED Multiplier / {DEFAULT EDM}; (in range of [0...1])
6) distance correctness = base score - (base score * distance excess ratio); (in range of
[0...100])
7) missing ratio = MC / (the length of the path - 1); (in range of [0...1])
8) missing correctness = base score - (base score * missing ratio); (in range of [0...100])
9) The final score is min(distance correctness, missing correctness), then clamped so it never
goes below 0 or above 100.
32


--- Page 33 ---
Preprint. Under review.
6. In most of time, you should NOT give a score of 0.0 unless your are very sure; You should
give a score between 0.0 and 100.0 to indicate how close the candidate is to the correct
solution;
7. Think it carefully and do NOT randomly guess the score;
8. You can think it thoroughly in any way you want, but You MUST give the score as a float
number in the end of your thinking.
===Distance Matrix===
```
{distance matrix}
```
===Candidate Solution===
```
{candidate}
```
Prompt Template 7: Sudoku LCO
===Instructions===
1. Given this Sudoku puzzle and these two Sudoku candidate solutions, you should
thoroughly think both good and bad parts of each candidate and whether they are correct
solutions to the puzzle;
2. If you think one of them are already correct, you can give the correct solution directly;
3. If you think the two candidates have good parts or bad parts, you can combine the good
parts of both candidates, exclude the bad parts of both candidates, or do both of them
simultaneously, aiming at creating a new candidate solution which can be better than the
original candidates and approach more to the correct solution;
4. If you think it is not necessary to combine the two candidates, you can also give a new
candidate solution which is totally different from the original candidates, aiming at
approaching more to the correct solution;
5. After crossover, the solution should approach or become correct, which means:
(1) Correct Syntax: it has a correct format, meaning each row, column, and
{subgrid size}x{subgrid size} square exactly contain {puzzle grid size} number, and each
cell is separated by space. The solution format must be in the same format as the given puzzle
but there is no unfilled dot;
(2) Correct Semantics: for each row, column, and {subgrid size}x{subgrid size} square, the
numbers 1 to {puzzle grid size} should appear exactly once;
6. You should check the syntax carefully. If the syntax is incorrect, you should give a new
solution which obey the rule â€correct syntaxâ€;
7. You should check the semantics carefully. If the semantics is incorrect, you should give a
new solution which obey the rule â€correct semanticsâ€;
8. You can think whatever way you want, but at the end of thinking, the final solution should
be given and written in the same format as the puzzle wrapped in triple backticks as a code
block;
9. You can give thinking steps or explanation before or after code block but you MUST NOT
give any comments or explanations in the code block;
===Sudoku Puzzle===
```
{puzzle}
```
===Candidate Solution 1===
```
{c1}
```
Score of Candidate Solution 1: {s1} (0.0 means the candidate is wrong at all while 100.0
means the candidate is correct)
Errors of Candidate Solution 1:
{c1 error}
33


--- Page 34 ---
Preprint. Under review.
===Candidate Solution 2===
```
{c2}
```
Score of Candidate Solution 2: {s2} (0.0 means the candidate is wrong at all while 100.0
means the candidate is correct)
Errors of Candidate Solution 2:
{c2 error}
Now, keep the scores and errors in mind and think about how to combine the two candidates
to create a new candidate solution that is better than the original candidates.
You can think in any way but you must finally give a candidate solution wrapped in triple
backticks as a code block in the same format as the puzzle:
Prompt Template 8: Graph Coloring LCO
===Instructions===
1. Given this Graph Coloring puzzle:
(1) The graph is represented by the adjacency matrix with {n vertices} vertices, in which â€yâ€
means the two vertices are adjacent and â€nâ€ means the two vertices are not adjacent;
(2) The goal is to color the vertices with {color count} colors such that no two adjacent
vertices have the same color;
2. Given these two candidate solutions, you should thoroughly think both good and bad parts
of each candidate and whether they are correct solutions to the puzzle;
3. If you think one of them are already correct, you can give the correct solution directly;
4. If you think the two candidates have good parts or bad parts, you can combine the good
parts of both candidates, exclude the bad parts of both candidates, or do both of them
simultaneously, aiming at creating a new candidate solution which can be better than the
original candidates and approach more to the correct solution;
5. If you think it is not necessary to combine the two candidates, you can also give a new
candidate solution which is totally different from the original candidates, aiming at
approaching more to the correct solution;
6. After crossover, the solution should approach or become correct, which means:
(1) Correct Syntax: the solution should be a list of {n vertices} integers separated by comma
such as â€0,1,2â€, each integer represents the color of the corresponding vertex, and the colors
should be integers from 0 to {color count - 1};
(2) Correct Semantics: for each pair of adjacent vertices, the colors of the two vertices should
be different;
7. You should check the syntax carefully. If the syntax is incorrect, you should give a new
solution which obey the rule â€correct syntaxâ€;
8. You should check the semantics carefully. If the semantics is incorrect, you should give a
new solution which obey the rule â€correct semanticsâ€;
9. You can think whatever way you want, but at the end of thinking, the final solution should
be given and written in a list of integers separated by comma wrapped in triple backticks as a
code block;
10. You can give thinking steps or explanation before or after code block but you MUST NOT
give any comments or explanations in the code block;
===Graph Adjacency Matrix===
```
{adjacency matrix}
```
===Candidate Solution 1===
```
{c1}
```
Score of Candidate Solution 1: {s1} (0.0 means the candidate is wrong at all while 100.0
means the candidate is correct)
34


--- Page 35 ---
Preprint. Under review.
Errors of Candidate Solution 1:
{c1 error}
===Candidate Solution 2===
```
{c2}
```
Score of Candidate Solution 2: {s2} (0.0 means the candidate is wrong at all while 100.0
means the candidate is correct)
Errors of Candidate Solution 2:
{c2 error}
Now, keep the scores and errors in mind and think about how to combine the two candidates
to create a new candidate solution that is better than the original candidates.
You can think in any way but you must finally give a candidate solution as a list of integers
separated by comma wrapped in triple backticks as a code block:
Prompt Template 9: Travel Salesman Problem LCO
===Instructions===
1. Given this Traveling Salesman Problem puzzle:
(1) The distance matrix is a 2D matrix with {n cities} rows and {n cities} columns, in which
each element represents the distance of traveling from the city in the row to the city in the
column;
(2) The goal is to find the shortest path that visits each city exactly once and returns to the
origin city;
2. Given these two candidate solutions, you should thoroughly think both good and bad parts
of each candidate and whether they are correct solutions to the puzzle;
3. If you think one of them are already correct, you can give the correct solution directly;
4. If you think the two candidates have good parts or bad parts, you can combine the good
parts of both candidates, exclude the bad parts of both candidates, or do both of them
simultaneously, aiming at creating a new candidate solution which can be better than the
original candidates and approach more to the correct solution;
5. If you think it is not necessary to combine the two candidates, you can also give a new
candidate solution which is totally different from the original candidates, aiming at
approaching more to the correct solution;
6. After crossover, the solution should approach or become correct, which means:
(1) Correct Syntax:
a. the solution should be a list of {n cities} integers separated by comma such as â€0,1,2â€,
each integer represents the index of the city in the path, and the indexes should be integers
from 0 to {n cities - 1};
b. the first and last city should be the same and should be 0, which means the path should
return to the origin city which is 0;
c. the index of city should be in the range from 0 to {n cities - 1};
(2) Correct Semantics:
a. No missing city: the path should visit each city exactly once and return to the origin city;
b. Optimal path: the path should be the shortest path;
7. You should check the syntax carefully. If the syntax is incorrect, you should give a new
solution which obey the rule â€correct syntaxâ€;
8. You should check the semantics carefully. If the semantics is incorrect, you should give a
new solution which obey the rule â€correct semanticsâ€;
9. You can think whatever way you want, but at the end of thinking, the final solution should
be given and written in a list of integers separated by comma wrapped in triple backticks as a
code block;
10. You can give thinking steps or explanation before or after code block but you MUST NOT
give any comments or explanations in the code block;
===Distance Matrix===
```
35


--- Page 36 ---
Preprint. Under review.
{distance matrix}
```
===Candidate Solution 1===
```
{c1}
```
Score of Candidate Solution 1: {s1} (0.0 means the candidate is wrong at all while 100.0
means the candidate is correct)
Errors of Candidate Solution 1:
{c1 error}
===Candidate Solution 2===
```
{c2}
```
Score of Candidate Solution 2: {s2} (0.0 means the candidate is wrong at all while 100.0
means the candidate is correct)
Errors of Candidate Solution 2:
{c2 error}
Now, keep the scores and errors in mind and think about how to combine the two candidates
to create a new candidate solution that is better than the original candidates.
You can think in any way but you must finally give a candidate solution as a list of integers
separated by comma wrapped in triple backticks as a code block:
Prompt Template 10: Sudoku LMO
===Instructions===
1. Given this Sudoku puzzle and this Sudoku candidate solution, you should thoroughly think
about the good and bad parts of the candidate and whether it is a correct solution to the puzzle;
2. If you think the candidate is already correct, you can give the correct solution directly;
3. If you think the candidate has bad parts, you can change or improve the bad parts to make it
good, aiming at creating a new candidate solution which can be better than the original
candidate and approach more to the correct solution;
4. If you think it is not necessary to change the candidate, you can also give a new candidate
solution which is totally different from the original candidate, aiming at approaching more to
the correct solution;
5. After mutation, the solution should approach or become correct, which means:
(1) Correct Syntax: it has a correct format, meaning each row, column, and
{subgrid size}x{subgrid size} square exactly contain {puzzle grid size} number, and each
cell is separated by space. The solution format must be in the same format as the given puzzle
but there is no unfilled dot;
(2) Correct Semantics: for each row, column, and {subgrid size}x{subgrid size} square, the
numbers 1 to {puzzle grid size} should appear exactly once;
6. You should check the syntax carefully. If the syntax is incorrect, you should give a new
solution which obey the rule â€correct syntaxâ€;
7. You should check the semantics carefully. If the semantics is incorrect, you should give a
new solution which obey the rule â€correct semanticsâ€;
8. You can think whatever way you want, but at the end of thinking, the final solution should
be given and written in the same format as the puzzle wrapped in triple backticks as a code
block;
9. You can give thinking steps or explanation before or after code block but you MUST NOT
give any comments or explanations in the code block;
===Sudoku Puzzle===
```
{puzzle}
```
===Candidate Solution===
36


--- Page 37 ---
Preprint. Under review.
```
{candidate}
```
Score of Candidate Solution: {score} (0.0 means the candidate is wrong at all while 100.0
means the candidate is correct)
Errors of Candidate Solution:
{error}
Now, keep the score and errors in mind and think about how to change the candidate to create
a new candidate solution that is better than the original candidate.
You can think in any way but you must finally give a candidate solution wrapped in triple
backticks as a code block in the same format as the puzzle:
Prompt Template 11: Graph Coloring LMO
===Instructions===
1. Given this Graph Coloring puzzle:
(1) The graph is represented by the adjacency matrix with {n vertices} vertices, in which â€yâ€
means the two vertices are adjacent and â€nâ€ means the two vertices are not adjacent;
(2) The goal is to color the vertices with {color count} colors such that no two adjacent
vertices have the same color;
2. Given this candidate solution, you should thoroughly think about the good and bad parts of
the candidate and whether it is a correct solution to the puzzle;
3. If you think the candidate is already correct, you can give the correct solution directly;
4. If you think the candidate has bad parts, you can change or improve the bad parts to make it
good, aiming at creating a new candidate solution which can be better than the original
candidate and approach more to the correct solution;
5. If you think it is not necessary to change the candidate, you can also give a new candidate
solution which is totally different from the original candidate, aiming at approaching more to
the correct solution;
6. After mutation, the solution should approach or become correct, which means:
(1) Correct Syntax: the solution should be a list of {n vertices} integers separated by comma
such as â€0,1,2â€, each integer represents the color of the corresponding vertex, and the colors
should be integers from 0 to {color count - 1};
(2) Correct Semantics: for each pair of adjacent vertices, the colors of the two vertices should
be different;
7. You should check the syntax carefully. If the syntax is incorrect, you should give a new
solution which obey the rule â€correct syntaxâ€;
8. You should check the semantics carefully. If the semantics is incorrect, you should give a
new solution which obey the rule â€correct semanticsâ€;
9. You can think whatever way you want, but at the end of thinking, the final solution should
be given and written in a list of integers separated by comma wrapped in triple backticks as a
code block;
10. You can give thinking steps or explanation before or after code block but you MUST NOT
give any comments or explanations in the code block;
===Graph Adjacency Matrix===
```
{adjacency matrix}
```
===Candidate Solution===
```
{candidate}
```
Score of Candidate Solution: {score} (0.0 means the candidate is wrong at all while 100.0
means the candidate is correct)
Errors of Candidate Solution:
{error}
37


--- Page 38 ---
Preprint. Under review.
Now, keep the score and errors in mind and think about how to change the candidate to create
a new candidate solution that is better than the original candidate.
You can think in any way but you must finally give a candidate solution as a list of integers
separated by comma wrapped in triple backticks as a code block:
Prompt Template 12: Travel Salesman Problem LMO
===Instructions===
1. Given this Traveling Salesman Problem puzzle:
(1) The distance matrix is a 2D matrix with {n cities} rows and {n cities} columns, in which
each element represents the distance of traveling from the city in the row to the city in the
column;
(2) The goal is to find the shortest path that visits each city exactly once and returns to the
origin city;
2. Given this candidate solution, you should thoroughly think about the good and bad parts of
the candidate and whether it is a correct solution to the puzzle;
3. If you think the candidate is already correct, you can give the correct solution directly;
4. If you think the candidate has bad parts, you can change or improve the bad parts to make it
good, aiming at creating a new candidate solution which can be better than the original
candidate and approach more to the correct solution;
5. If you think it is not necessary to change the candidate, you can also give a new candidate
solution which is totally different from the original candidate, aiming at approaching more to
the correct solution;
6. After mutation, the solution should approach or become correct, which means:
(1) Correct Syntax:
a. the solution should be a list of {n cities} integers separated by comma such as â€0,1,2â€,
each integer represents the index of the city in the path, and the indexes should be integers
from 0 to {n cities - 1};
b. the first and last city should be the same and should be 0, which means the path should
return to the origin city which is 0;
c. the index of city should be in the range from 0 to {n cities - 1};
(2) Correct Semantics:
a. No missing city: the path should visit each city exactly once and return to the origin city;
b. Optimal path: the path should be the shortest path;
7. You should check the syntax carefully. If the syntax is incorrect, you should give a new
solution which obey the rule â€correct syntaxâ€;
8. You should check the semantics carefully. If the semantics is incorrect, you should give a
new solution which obey the rule â€correct semanticsâ€;
9. You can think whatever way you want, but at the end of thinking, the final solution should
be given and written in a list of integers separated by comma wrapped in triple backticks as a
code block;
10. You can give thinking steps or explanation before or after code block but you MUST NOT
give any comments or explanations in the code block;
===Distance Matrix===
```
{distance matrix}
```
===Candidate Solution===
```
{candidate}
```
Score of Candidate Solution: {score} (0.0 means the candidate is wrong at all while 100.0
means the candidate is correct)
Errors of Candidate Solution:
{error}
38


--- Page 39 ---
Preprint. Under review.
Now, keep the score and errors in mind and think about how to change the candidate to create
a new candidate solution that is better than the original candidate.
You can think in any way but you must finally give a candidate solution as a list of integers
separated by comma wrapped in triple backticks as a code block:
Prompt Template 13: Sudoku Direct Prompting
===Instructions===
1. Given this Sudoku puzzle, you should fill in the missing numbers represented by dots;
2. The solution should be correct, which means:
(1) Correct Syntax: it has a correct format, meaning each row, column, and
{subgrid size}x{subgrid size} square exactly contain {puzzle grid size} number, and each
cell is separated by space. The solution format must be in the same format as the given puzzle
but there is no unfilled dot;
(2) Correct Semantics: for each row, column, and {subgrid size}x{subgrid size} square, the
numbers 1 to {puzzle grid size} should appear exactly once;
3. The puzzle is guaranteed to have a unique solution;
4. You should check the syntax carefully. If the syntax is incorrect, you should give a new
solution which obey the rule â€correct syntaxâ€;
5. You should check the semantics carefully. If the semantics is incorrect, you should give a
new solution which obey the rule â€correct semanticsâ€;
6. You can think whatever way you want, but at the end of thinking, the final solution should
be given and written in the same format as the puzzle wrapped in triple backticks as a code
block;
7. You can give thinking steps or explanation before or after code block but you MUST NOT
give any comments or explanations in the code block;
===Sudoku Puzzle===
```
{puzzle}
```
Prompt Template 14: Graph Coloring Direct Prompting
===Instructions===
1. Given this Graph Coloring puzzle:
(1) The graph is represented by the adjacency matrix with {n vertices} vertices, in which â€yâ€
means the two vertices are adjacent and â€nâ€ means the two vertices are not adjacent;
(2) The goal is to color the vertices with {color count} colors such that no two adjacent
vertices have the same color;
2. The solution should be correct, which means:
(1) Correct Syntax: the solution should be a list of {n vertices} integers separated by comma
such as â€0,1,2â€, each integer represents the color of the corresponding vertex, and the colors
should be integers from 0 to {color count - 1};
(2) Correct Semantics: for each pair of adjacent vertices, the colors of the two vertices should
be different;
3. You should check the syntax carefully. If the syntax is incorrect, you should give a new
solution which obey the rule â€correct syntaxâ€;
4. You should check the semantics carefully. If the semantics is incorrect, you should give a
new solution which obey the rule â€correct semanticsâ€;
5. You can think whatever way you want, but at the end of thinking, the final solution should
be given and written in a list of integers separated by comma wrapped in triple backticks as a
code block;
6. You can give thinking steps or explanation before or after code block but you MUST NOT
give any comments or explanations in the code block;
===Graph Adjacency Matrix===
```
39


--- Page 40 ---
Preprint. Under review.
{adjacency matrix}
```
Prompt Template 15: Travel Salesman Problem Direct Prompting
===Instructions===
1. Given this Traveling Salesman Problem puzzle:
(1) The distance matrix is a 2D matrix with {n cities} rows and {n cities} columns, in which
each element represents the distance of traveling from the city in the row to the city in the
column;
(2) The goal is to find the shortest path that visits each city exactly once and returns to the
origin city;
2. The solution should be correct, which means:
(1) Correct Syntax:
a. the solution should be a list of {n cities} integers separated by comma such as â€0,1,2â€,
each integer represents the index of the city in the path, and the indexes should be integers
from 0 to {n cities - 1};
b. the first and last city should be the same and should be 0, which means the path should
return to the origin city which is 0;
c. the index of city should be in the range from 0 to {n cities - 1};
(2) Correct Semantics:
a. No missing city: the path should visit each city exactly once and return to the origin city;
b. Optimal path: the path should be the shortest path;
3. You should check the syntax carefully. If the syntax is incorrect, you should give a new
solution which obey the rule â€correct syntaxâ€;
4. You should check the semantics carefully. If the semantics is incorrect, you should give a
new solution which obey the rule â€correct semanticsâ€;
5. You can think whatever way you want, but at the end of thinking, the final solution should
be given and written in a list of integers separated by comma wrapped in triple backticks as a
code block;
6. You can give thinking steps or explanation before or after code block but you MUST NOT
give any comments or explanations in the code block;
===Distance Matrix===
```
{distance matrix}
```
40
