--- Page 1 ---
LARGE LANGUAGE MODEL-BASED EVOLUTIONARY
OPTIMIZER: REASONING WITH ELITISM
Shuvayan Brahmachary 1 ∗†, Subodh M. Joshi 1 ∗, Aniruddha Panda 1, Kaushik Koneripalli 1,
Arun Kumar Sagotra 1, Harshil Patel 1, Ankush Sharma 1, Ameya D. Jagtap 2 †, Kaushic Kalyanaraman 1
(shuvayan.brahmachary, subodh-madhav.joshi, aniruddha.panda, kaushik.koneripalli,
arun.sagotra, harshil.patel, ankush.sharma, kaushic.kalyanaraman)@shell.com, ameya_jagtap@brown.edu
1 Computational Science Group,
2 Division of Applied Mathematics,
Shell India Markets Pvt. Ltd.
Brown University, RI 02912, USA
ABSTRACT
Large Language Models (LLMs) have demonstrated remarkable reasoning abilities,
prompting interest in their application as black-box optimizers. This paper asserts that
LLMs possess the capability for zero-shot optimization across diverse scenarios, including
multi-objective and high-dimensional problems. We introduce a novel population-based
method for numerical optimization using LLMs called Language-Model-Based Evolution-
ary Optimizer (LEO). Our hypothesis is supported through numerical examples, spanning
benchmark and industrial engineering problems such as supersonic nozzle shape optimiza-
tion, heat transfer, and windfarm layout optimization. We compare our method to several
gradient-based and gradient-free optimization approaches. While LLMs yield comparable
results to state-of-the-art methods, their imaginative nature and propensity to hallucinate
demand careful handling. We provide practical guidelines for obtaining reliable answers
from LLMs and discuss method limitations and potential research directions.
1
INTRODUCTION
The advent of Large Language Models (LLMs) has sparked a revolution in generative Artificial Intelligence
(AI) research (Min et al., 2023; Zhao et al., 2023; Liu et al., 2023e). Since the introduction of transformer
model (Vaswani et al., 2017), the generative AI research has seen a surge of activity and every subsequent
generation of LLM models have become exceedingly more capable than the previous ones. For example,
the first decoder-only model developed by OpenAI in 2018 was called Generative Pre-Trained transformers
(GPT) based on the transformer architecture, was capable of processing textual data alone (Zhao et al.,
2023), while OpenAI’s latest GPT-4 model released in 2023 is multi-modal, i.e., capable of dealing with
natural language, code, as well as images (OpenAI et al., 2023). Several studies since then have shown
that Large Language Models (LLMs), such as GPT-4, possess strong reasoning ability (Huang & Chang,
2023; Kojima et al., 2023). Studies have also shown that a LLM’s performance can be further improved by
techniques such as in-context learning (Brown et al., 2020), chain-of-thought prompting (Wei et al., 2023),
and tree-of-thought prompting (Yao et al., 2024; Long, 2023).
∗Equal contribution
†Corresponding authors
1
arXiv:2403.02054v1  [cs.AI]  4 Mar 2024


--- Page 2 ---
Some examples that highlight the generalization capability of LLM models are: a) Gato (Reed et al., 2022),
a generalist multi-modal agent based on a LLM capable of performing several tasks. b) Eureka (Ma et al.,
2023), a human-level reward design algorithm using LLMs, is a gradient-free in-context learning approach
to reinforcement learning for robotic applications. c) Voyager (Wang et al., 2023), a LLM-powered AI
agent, has shown the ability to conduct autonomous exploration, skill acquisition, and discovery in an open-
ended Minecraft world without human intervention. To test the reasoning and generalization ability of new
generative AI models, Srivastava et. al. published a suite of benchmarks containing 204 problems called the
Beyond the Imitation Game benchmark (BIG-bench) (Srivastava et al., 2023).
This reasoning and generalization ability of LLMs has sparked interest in exploring use of LLM models
as AI agents, particularly for applications in science and technology. Bran et al. (2023) developed an au-
tonomous AI agent called ChemCrow for computational chemistry research. This AI agent has demonstrated
remarkable ability to accomplish tasks across organic synthesis, drug discovery, and material design. Sim-
ilarly, Boiko et al. (2023) presents an autonomous AI agent based on an LLM for chemical engineering
research. Blanchard et al. (2022) use masked LLMs for automating genetic mutations for molecules for ap-
plication in drug likeness and synthesizability. Zhang et al. (2023b) present AutoML-GPT, an AI agent that
acts as a bridge between various AI models as well as dynamically trains other AI models with optimized
hyperparameters. Stella et al. (2023) show that generative AI models can accelerate robot design process
at conceptual as well as technical level. They further propose a human-AI co-design strategy for the same.
Zheng et al. (2023) explores the generative ability of GPT4 as a black-box optimizer to navigate architecture
search space, making it an effective agent for neural architecture search. Singh et al. (2022) study the utility
of LLMs as task planners for robotic applications. Jablonka et al. (2024) show that a fine-tuned GPT-3 model
can outperform many other ML models, particularly in the low-data limit, for predictive Chemistry.
A common thread which passes through the studies mentioned above is the ability of LLMs to find an op-
timal solution for complex multi-objective optimization problems at hand. This has attracted a great deal
of attention from the scientific community. Several studies have been published exploring the ability of
LLMs to work as black-box optimizers. Melamed et al. (2023) presents an automatic prompt optimiza-
tion framework called PROPANE. In a method called InstructZero, Chen et al. optimize a low-dimensional
soft-prompt to an open-source LLM, which in turn generates the prompt for the black-box LLM, which then
performs a zero-shot evaluation (Chen et al., 2023). The soft prompt is optimized using a Bayesian optimiza-
tion method. Deepmind released a general hyperparameter optimization framework called Optformer based
on the transformer architecture (Chen et al., 2022). The idea of generation of optimized prompts automati-
cally is also explored in (Zhou et al., 2023). Similarly, Pryzant et al. (2023) explores incorporating gradient
descent into automatic prompt optimization. Chen et al. (2024) introduces a discrete prompt-optimization
framework incorporating human-designed feedback rules. We also see some examples of using LLM within
a Reinforcement Learning (RL) framework for optimization (Chen et al., 2021; Wang et al., 2017; Ma et al.,
2023).
While the examples mentioned so far focused on optimized prompt generation, a few studies have also
explored using LLMs for mathematical optimization directly. Liu et al. (2023c) propose LLM-based Evolu-
tionary Algorithm (LMEA), in which a LLM is responsible for the selection of the parent solution, mutation,
cross-over, and generation of a new solution. Guo et al. (2023) conducts an assessment of the various opti-
mization abilities of LLM. Their study concludes that LLMs can perform optimization, including gradient
descent, hill-climbing, grid search and black-box optimization well, particularly when the sample sizes are
small. Pluhacek et al. (2023) presents a strategy for using LLM for swarm intelligence-based optimization
algorithms. Liu et al. (2023a) proposes LLM-based multi-objective optimization method, where LLM serves
as black-box search operator for Multi-Objective Evolutionary Algorithms (MOEA). Liu et al. (2023b) pro-
poses using LLMs for optimization algorithm evolution in a framework called AEL (which stands for Al-
gorithm Evolution using LLMs). Liu et al. (2023d) adopt automatic hill-climbing process using language
models as black box optimizers for vision-language models. They show that LLMs utilize implicit gradient
direction for more efficient search. Optimization by PROmpting (OPRO) framework from Google Deep-
2


--- Page 3 ---
mind generates new solutions autoregressively and is seen to outperform human-level prompts (Yang et al.,
2023). We also see examples of using LLM for mathematical operations and optimization; for example,
deep learning for symbolic mathematics (Lample & Charton, 2019), LLM for symbolic regression (Valipour
et al., 2021; Agarwal et al., 2021), using transformers for linear algebra, including matrix operations and
eigen-decomposition (Charton, 2022) etc. In a framework called OptiMUS, LLM are used for formulating
and solving Mixed-Integer Linear Programming (MILP) problems (AhmadiTeshnizi et al., 2023). Zhang
et al. (2023a) use LLMs for hyperparameter optimization. Romera-Paredes et al. (2023) introduce an evolu-
tionary procedure called FunSearch (short for searching in function space), where a pretrained LLM model
is paired with a systematic evaluator for efficient function space search.
In this paper, we focus on the ability of LLMs to perform black-box optimization. We adopt a population
based approach and propose a novel explore-exploit policy using LLMs for generation of new samples. We
call this method a Language-model based Evolutionary Optimizer (LEO). The main contributions of this
paper are as follows:
1. We introduce a novel optimization strategy called Language-model-based Evolutionary Optimizer
(LEO). This is a population-based, parameter-free method in which a LLM is used to generate new
candidate solutions and an elitist framework consisting of separate explore and exploit pools of
solutions is used as guard rails. This strategy helps harness the optimization capabilities of LLMs
while mitigating the risks of getting stuck in local optima. We present the details of the algorithm in
Sections 1 and 2. Additionally, we highlight the rationale for adopting a population-based strategy
for optimization in Section 2.
2. We present distinguishing features of our method compared to other auto-regressive, evolutionary,
or population-based methods using LLMs for black-box optimization, such as in (Liu et al., 2023c;
Yang et al., 2023; Guo et al., 2023; Liu et al., 2023a) (Section 2).
3. We solve several benchmark problems in numerical optimization, single and multi-objective, as
well as explore the ability of LLMs to solve high-dimensional problems. Additionally, we demon-
strate the application of our method to engineering problems such as shape optimization, heat trans-
fer, and windfarm layout optimization (Section 3).
4. We juxtapose our method against the state-of-the art methods for optimization, both gradient based
and gradient-free (Section 3).
5. We provide evidence of LLM’s ability to reason and perform numerical optimization with the help
of two tests (Section 4).
Lastly, we present our analyses and discussions, followed by a conclusion (Section 5).
2
METHODOLOGY
2.1
RATIONALE TOWARDS POPULATED-BASED APPROACH
In this section, we provide the rationale behind the population-based approach for solving complex non-
convex optimisation problems. While non-population-based or gradient-based methods are preferred for
their quick turn-around time towards convergence, the final solutions are likely to get trapped in local optima
for non-convex problems. In this section, we setup a quick experiment to demonstrate this idea via the LLM-
assisted optimisation framework without a population-based strategy to generate a new candidate solution
for every optimisation iteration. To further elaborate, the framework for this toy experiment uses LLM to
generate a new candidate solution given the history of the number of previously generated solutions, nhist.
This approach is strictly not a population-based strategy but rather an adaptive way to generate new candidate
solutions that is likely to minimise a function value. The prompt corresponding to this test is mentioned in
3


--- Page 4 ---
0
10
20
30
Optimisation Iterations
0.2
0.5
0.8
1.1
1.4
Function value, f
(a)
(1 var)
(4 var)
(8 var)
0
10
20
30
Optimisation Iterations
0.2
0.5
0.8
1.1
Decision variable, n
(b)
(1 var)
(4 var)
(8 var)
Figure 1: Convergence towards optimal nose cone shape with increasing number of decision variables as
context.
Table 9 in the Appendix. colorblue Throughout this work, we use the openAI GPT-3.5 Turbo 0613 model
for all our evaluations.
The problem under consideration is the popular nose-cone shape optimisation. This toy problem presents
itself as a single objective, single variable convex optimisation problem, where the objective is to determine
the optimal decision variable (i.e., power-law index, n) that results in minimal drag coefficient body. Please
refer to Section A.1 in the appendix for further information. Figure 1 (a) shows the variation of the func-
tion value (i.e., drag coefficient) with optimisation iterations for various nhist values, where a remarkable
observation is made. It is found that the LLM struggles to find the optimal solution when nhist=1. This is
not surprising and points to the lack of context in the limited number of previously generated candidate so-
lutions. However, for higher nhist values, the optimisation framework quickly aligns itself with the optimal
value. This is also true for the corresponding decision variable value n in Figure 1 (b). This experiment
signifies that the LLM-based hybrid optimisation framework struggles to locate the optimal solution when
limited context in terms of the history of previous candidate points has been passed to it in every optimisation
iteration. This is true for even a simple convex optimisation, as described above.
We now extend the above approach to solve a two-dimensional (2D) benchmark optimisation function,
specifically the Rosenbrock function, using nhist = 10. The global optima for this function is i.e., fmin = 0,
corresponding to xmin, ymin = (1, 1). Figure 2 (a) shows the variation of the objective function value, f,
with optimisation iterations. It is clear that the hybrid approach, despite being fed the history of the last
10 candidate points, suffers from premature convergence. This can be confirmed from Fig. 2(b) where the
decision variables x, y are seen to converge to a local optimal solution. This failure signifies that a single
trajectory of past candidate points alone is not sufficient to converge to the global optimal solution, as they
might be points around the basins of a local optimal solution. It must be remarked that while Yang et al.
(2023) allude to this phenomenon as optimisation stability resulting from sensitivity to prompt, we are of the
opinion that this is rather a misnomer and stems purely from a lack of context and richness of information
from the decision variable space. Besides, our work provides a compelling demonstration of this logic.
From the above two experiments, we can see that a hybrid LLM-based optimisation approach without the
rich information spanning the decision variable space (i.e., exploration) is unlikely to be useful for the LLM
to generate good candidate points around the present candidate solutions (i.e., exploitation). While several
other methods, exemplified by (Liu et al., 2023c; Yang et al., 2023; Guo et al., 2023), incorporate the con-
4


--- Page 5 ---
0
10
20
30
Optimisation iterations
1.0
10.0
100.0
Function value, f
Global optima = 0
(a)
0
10
20
30
Optimisation iterations
0.00
0.25
0.50
0.75
1.00
Decision variable, n
1
,
n
2
Global optima = (1, 1)
(b)
variable n
1
variable n
2
Figure 2: Performance of the LLM-based search algorithm (without a population) described in Section 2.1
for the 2D Rosenbrock function.
cept of exploration versus exploitation during solution search in an auto-regressive manner, they rely on
adjusting the temperature of the Language Model (LLM) to toggle between these two modes. However,
this approach, although effective in simpler scenarios, has limitations. Specifically, a higher temperature
introduces greater randomness into the LLM’s output, potentially hindering its ability to learn the true dis-
tribution of solutions. Conversely, an excessively low temperature can lead to mode collapse—a situation
where the model consistently predicts the same (incorrect) solution. This phenomenon is particularly associ-
ated with auto-regressive LLMs, as highlighted by (Hopkins et al., 2023). Besides, the use of temperature as
a user-defined parameter (unlike the self-adaptive mechanism introduced by (Liu et al., 2023c)) on top of an
already complex optimisation method may diminish its efficiency or user friendliness. In the same vein, we
will also illustrate how an existing evolutionary optimisation framework utilising user-defined parameters
such as probability of crossover and probability of mutation can be simply replaced by using LLM, without
the introduction of temperature. In the following section, we propose a novel approach that uses LLM to
generate points that maintain a fine balance between exploration and exploitation, to arrive at the global
optimal solution. This is unlike the existing approaches, where population based evolutionary optimisation
strategies like genetic algorithms employ mutation and crossover to perturb the parent solution for offspring.
2.2
LANGUAGE-MODEL BASED EVOLUTIONARY OPTIMIZER (LEO)
In order to address the shortcomings that were discussed above, we propose a novel optimization strategy
called Language-model-based Evolutionary Optimizer (LEO). This approach employs LLMs along with
some traditional strategies that act as ‘guardrails’ to better guide the resulting hybrid optimization frame-
work. Being a population-based strategy, LEO generates a pool of random initial solutions of size equal
to population size Npop, within the decision variable bounds. These initial solutions are then evaluated to
determine their function values, i.e., fitness scores. At this stage, we retain all the initial pool of solutions as
candidate solutions. To generate new candidate solutions that allow for a balance between exploitation and
exploration, we invoke the LLM via two different prompts, i.e., shown in Tables 7 and 6, to finally create
exploit and explore pools of candidate solutions. These pools of candidate solutions further undergo function
evaluations for their respective fitness scores and are appended to the solutions from previous generations,
resulting in 2Npop solutions in each pool. At this stage, we export the Nport best solutions from the explore
pool to the exploit pool (and remove the Nport worst solutions from the exploit pool) via the Port and Filter
operation, to restrict the exploitation search to good candidate solutions with a lower function value, see
5


--- Page 6 ---
Global optima
Random initial guess
Exploit pool
Explore pool
Exploit pool
Explore pool
Figure 3: Schematic behind the LLM-assisted optimisation via exploration and exploitation of design space.
Both figures illustrate the distribution of the initial pool of solution (triangle marker in blue color) randomly
generated within the design space bounds along with the global optimal solution (in light green color).
The figure(a) shows the overlay of the exploit pool of points (circle marker in sepia color) generated in close
vicinity of the initial random solutions. The figure(b) shows the juxtaposition of the explore pool of solutions
(diamond marker in sepia color) significantly away from the pool of initial randomly generated solutions.
The best explore points (closest to the global optimal solution) is ported to exploit pool, following which the
equal number of worst solutions from exploit pool will be removed. The xz as well as yz plane in both the
figures depict the density distribution of the newly generated exploit and explore points.
Port & Replace
Function 
Evaluation
Initial Random 
Candidates
LLM 
Exploit Prompt
LLM 
Explore Prompt
Function 
Evaluation
Function 
Evaluation
Exploit 
Pool
Explore 
Pool
Update 
Explore Pool
Update 
Exploit Pool
Final
Exploit Pool
Final
Explore Pool
Termination 
criterion
NO
NO
YES
Final Optimal Solution
Figure 4: Schematic of the LEO framework.
6


--- Page 7 ---
Fig. 3. Finally, to enforce elitism, the 2Npop solutions in each pool are sorted in order of their function
values, and only the top Npop solutions are retained in each pool. This step is pictorially depicted in Fig. 4
and summarized in Algorithm 1. The above step is repeated until the termination criterion (i.e., maximum
generations or optimisation iterations) is reached.
Algorithm 1: LEO algorithm.
Algorithm main()
1
Input: popSize, maxIters, numVars, prompt_init, jitterexplore, jitterexploit, solToPort, objFun(.)
2
Minimise: minFunVal
3
xinit ←random(popSize, numVars), xexplore ←xinit, xexploit ←xinit ;
4
yinit ←objFun(xinit), yexplore ←yinit, yexploit ←yinit ;
5
iter ←1 ;
while iter ≤maxIters do
promptexplore ←PromptCreate(promptinit, jitterexplore, xexplore) ;
promptexploit ←PromptCreate(promptinit, jitterexploit, xexploit) ;
˜xexplore, ˜xexploit ←LLM(promptexplore), LLM(promptexploit) ;
˜yexplore, ˜yexploit = objFun(˜xexplore), objFun(˜xexploit) ;
xexplore, yexplore ←UpdatePopulation(xexplore, yexplore, ˜xexplore, ˜yexplore) ;
xexploit, yexploit ←UpdatePopulation(xexploit, yexploit, ˜xexploit, ˜yexploit) ;
xexploit, yexploit ←PortFilter(xexplore, yexplore, xexploit, yexploit, solToPort) ;
xexploit, yexploit ←sort([xexploit, yexploit]) ;
xexplore, yexplore ←sort([xexplore, yexplore]) ;
iter ←iter + 1
end
6
minFunVal ←yexploit[0] ;
7
return minFunVal
Procedure PromptCreate(prompt, jitter, x)
1
xjitter ←x+ jitter ;
2
promptupdate ←Insert xjitter in prompt ;
3
return promptupdate;
Procedure UpdatePopulation(x, y, ˜x, ˜y)
1
x ←concat(x, ˜x) ;
2
y ←concat(y, ˜y) ;
3
return x, y ;
Procedure PortFilter(xexplore, yexplore, xexploit, yexploit, numPort)
1
xtop, ytop ←sort([xexplore, yexplore])[0:numPort] ;
/* Sort w.r.t yexplore */
2
xexploit, yexploit ←sort([xexploit, yexploit]) ;
/* Sort w.r.t yexploit */
3
xexploit[−numPort :] ←xtop ;
4
yexploit[−numPort :] ←ytop ;
5
return xexploit, yexploit;
3
NUMERICAL RESULTS
In this section, we evaluate our proposed optimisation strategy via a series of test cases, ranging from simple
benchmark problems to engineering applications. These tests are classified into four categories: (a) simple
benchmark function optimisation problems; (b) multi-objective optimization problems; (c) high-dimensional
benchmark optimization problems; and (d) industry-relevant engineering optimization problems. This al-
lows us to scrutinise the approach for a range of problems of different complexity.
3.1
BENCHMARK OPTIMISATION FUNCTIONS
We begin our experiments by recognising the need to evaluate the merits of LEO on a range of test cases
against established optimisation methods. Consequently, in this section, we compare the proposed optimiza-
tion algorithm (LEO) with various gradient-based and gradient-free optimisation algorithms for 6 different
2D benchmark optimisation problems. The corresponding equations describing the function, decision vari-
able bounds, as well as the location of optima are shown in Table 1, for all the respective 2D benchmark
functions.
Among the gradient-based optimization algorithms, we choose Stochastic Gradient Descent (SGD) Kiefer
& Wolfowitz (1952), Adam Kingma & Ba (2014), and L-BFGS-B Byrd et al. (1995) algorithms, whereas
7


--- Page 8 ---
2D Benchmark
Objective
Functions
Equation
Global Minima
Domain
ScaledSphere
f(x, y) = x2 + y4
f(0., 0.) = 0.
−1 ≤x, y ≤4
Himmelblau
f(x, y) = (x2 + y −11)2 + (x + y2 −7)2
f(3.0, 2.0) = 0.0
f(−2.805118, 3.131312) = 0
f(−3.779310, −3.283186) = 0
f(3.584428, −1.848126) = 0
−5 ≤x, y ≤5
Rosenbrock2D
f(x, y) = 100(y −x2)2 + (1 −x)2
f(1., 1.) = 0.
−∞≤x, y ≤∞
Sphere2D
f(x, y) = x2 + y2
f(0., 0.) = 0.
−∞≤x, y ≤∞
Beale
f(x, y) = (1.5 −x + xy)2 +
(2.25 −x + xy2)2 + (2.625 −x + xy3)2
f(3., 0.5) = 0.
−4.5 ≤x, y ≤4.5
Goldstein Price
f(x, y) =

1 + (x + y + 1)2(19 −14x + 3x2 −14y + 6xy + 3y2)


30 + (2x −3y)2(18 −32x + 12x2 + 48y −36xy + 27y2)

f(0., −1) = 3.
−2 ≤x, y ≤2
Table 1: 2D Benchmark test functions with their equations, domain, and global minima.
Traditional Gradient based methods
Traditional Gradient Free methods
SGD with
momentum
Adam
(β2 = 0.999)
Simulated Annealing with
exponential temperature decay
2D Benchmark
Objective
Functions
Global
minima
SGD
ν=0.5
ν=0.9
β1 = 0.1
β1 = 0.5
β1 = 0.9
L-BFGS-B
T = 0.1
T = 1
T = 10
CMA-ES
COBYLA
LEO (ours)
ScaledSphere
0.0000
0.0039
0.0008
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
Himmelblau
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0003
0.0003
0.0002
0.0000
0.0000
0.0086
Rosenbrock
0.0000
0.0362
0.0479
0.0406
0.0986
0.0192
0.0155
0.0000
0.0001
0.0002
0.0005
0.0000
0.0965
0.0012
Sphere
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
0.0000
Beale
0.0000
0.1330
3.2964
4.6201
1.1810
0.1995
0.9322
0.0000
0.0000
0.0000
0.0002
0.0000
0.0071
0.0156
GoldsteinPrice
3.0000
72.5447
54.4256
30.3447
39.4401
30.0070
30.0000
3.0000
30.0038
30.0047
30.0044
3.0000
60.1236
3.0023
Table 2: Comparison of proposed algorithm with traditionally used Gradient-based as well as Gradient-free
methods. All evaluations were continued until the termination criterion of 1000 function evaluations
among the gradient-free optimization algorithms, we employ Simulated Annealing (SA) Kirkpatrick et al.
(1983), Covariance matrix adaptation evolution strategy, CMA-ES Hansen & Ostermeier (1996), and Con-
strained Optimization by Linear Approximation, COBYLA Powell (1994) to compare against LEO. All the
corresponding results are shown in Table 2. The reported values are the median values from 100 indepen-
dently seeded runs, each corresponding to the obtained minima at the end of 1000 function evaluations. It
is found that L-BFGS-B and CMA-ES are the best performing SOTA gradient-based and gradient-free op-
timisation methods, respectively achieving the global optima in all the benchmark optimisation functions.
However, it is interesting to note that LEO also attains the global minima, albeit with a slightly lower pre-
cision when compared across the 100 independent runs. Nevertheless, LEO seems to perform almost at par
with the established SOTA methods like L-BFGS and CMA-ES while outperforming methods like SGD,
SA, COBYLA and even Adam, especially on the Goldstein-Price problem, which happens to be the trickiest
one to solve.
A visual representation of the convergence using one representative experiments among available 100 is de-
picted by the solution with the lowest function value in exploit pool fmin, obtained using LEO on the six 2D
benchmark optimisation functions is shown in Figure 5. Every solution is color coded based on the optimi-
sation iteration at which it was generated. It is found that while sampling of random initial solution results
in fmin being quite distant from the respective global optimal solutions, as optimisation progresses, LEO is
able to quickly navigate towards the global optimal solution. It must be noted that the convergence rate is
rather high at the start of the optimisation and later tapers off near the global optimal solution depending
upon the topology of the functional value space (will be quantitatively demonstrated later in following sec-
tions). This is indicative of the fact that the rate of convergence at the start is heavily influenced by solutions
obtained from exploration pool while towards the end, the success of the approach is largely determined by
the solutions obtained from exploitation pool. With these promising observations, we now shift our attention
towards much more complex problems in the following sections.
Computational cost:
8


--- Page 9 ---
-1.00
0.00
1.00
2.00
3.00
-1.00
0.00
1.00
2.00
3.00
4.00
(a) ScaledSphere function
-4.00
-2.00
0.00
2.00
-4.00
-3.00
-2.00
-1.00
0.00
1.00
2.00
3.00
4.00
(b) Himmelblau function
0.00
0.50
1.00
1.50
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
(c) Rosenbrock function
-0.40
-0.20
0.00
0.20
0.40
-1.00
-0.75
-0.50
-0.25
0.00
0.25
0.50
0.75
1.00
2.20
2.40
2.60
2.80
3.00
3.20
3.40
1.00
1.20
1.40
1.60
1.80
2.00
2.20
2.40
0.50
0.60
0.70
0.80
0.90
1.00
1.10
0.30
0.40
0.50
0.60
0.70
0.80
0.90
1.00
-1.00
-0.50
0.00
0.50
-1.00
-0.75
-0.50
-0.25
0.00
0.25
0.50
0.75
1.00
(d) Sphere function
-4.00
-2.00
0.00
2.00
4.00
-4.00
-3.00
-2.00
-1.00
0.00
1.00
2.00
3.00
4.00
(e) Beale function
-2.00
-1.00
0.00
1.00
-2.00
-1.50
-1.00
-0.50
0.00
0.50
1.00
1.50
2.00
(f) Goldstein-Price function
-0.10
0.00
0.10
0.20
0.30
0.40
-0.40
-0.30
-0.20
-0.10
0.00
0.10
0.20
0.30
2.60
2.80
3.00
3.20
3.40
3.60
0.00
0.20
0.40
0.60
0.80
1.00
-0.20
0.00
0.20
0.40
0.60
0.80
1.00
-1.20
-1.00
-0.80
-0.60
-0.40
-0.20
0.00
0.50
1.00
1.50
2.00
2.50
Function Value
0
5
10
15
20
25
30
Iteration number
2.00
4.00
6.00
8.00
Function Value
0
5
10
15
20
25
30
Iteration number
0.00
0.10
0.20
0.30
0.40
Function Value
0
5
10
15
20
25
30
Iteration number
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
Function Value
0
5
10
15
20
25
30
Iteration number
2.50
5.00
7.50
10.00
12.50
15.00
17.50
Function Value
0
5
10
15
20
25
30
Iteration number
200.00
400.00
600.00
800.00
1000.00
Function Value
0
5
10
15
20
25
30
Iteration number
Exploit Pool (best)
Global optima
Exploit Pool (best)
Global optima
Exploit Pool (best)
Global optima
Exploit Pool (best)
Global optima
Exploit Pool (best)
Global optima
Exploit Pool (best)
Global optima
Figure 5: 2D benchmark functions and their convergence plots using LEO optimization.
9


--- Page 10 ---
To enable a fair comparison across multiple gradient-based and gradient-free optimisation methods, it is im-
perative to consider the number of function evaluations while keeping the total number of iterations constant.
This necessitates treating the total number of optimisation iterations as a variable. Consider the case where
the gradient descent method for a problem with nvar variables requires nvar+1 number of function evalu-
ations per optimisation iteration compared to a population-based approach with population size npop that
warrants npop number of function evaluations per optimisation iterations. Considering this, in the present
work, we choose to keep the same number of function evaluation calls (i.e., 1000), or 30 optimisation itera-
tions for LEO.
For the above set of experiments reported in Table 2, optimization algorithms like CMA-ES and LBFGS
are extremely fast. For instance, 100 randomly seeded experiments take less than a minute across all 6
benchmark functions. On the contrary, LEO, however, takes approximately 3 hours for all six functions to
be repeated using 100 random seeds. We attribute this high computational time by LEO to predominantly 2
factors. Firstly, time consumed by the LLM function call: from our experiments, each call to the LLM with a
∼1000 token prompt takes anywhere between 15-20 seconds for a response from the OpenAI servers. This
is already quite time-prohibitive. Secondly, due to lack of open-sourced and robust LLM models, unlike
GPT-3.5 Turbo: there is a lot of growing literature on improving inference and training times of LLMs
with ideas like FlashAttention (Dao et al., 2022; Dao, 2023), model quantization (Lin et al., 2023; Xiao
et al., 2023), etc. In order to apply these ideas, one needs to have access to the model weights. Currently,
our present work is limited to the use of the GPT-3.5 Turbo-0613 model because of its superior and robust
performance compared to other open-sourced models available.
3.2
MULTI-OBJECTIVE OPTIMIZATION PROBLEM
In the previous section, we demonstrated the merits LEO in tackling single objective optimisation problems
for 2D standard benchmark optimisation functions. In this section, we further explore the capabilities of
LEO in tackling multi-objective optimisation problems. The objective of this section is twofold: (a) Demon-
strate that LLM can be used as plug-and-play or modular feature in the existing state-of-the art evolutionary
optimisation approaches, e.g., non-dominated sorting algorithm (NSGA) II (Deb et al., 2002), (b) demon-
strate the ability of the resulting framework (LEO-modular) to minimize multiple conflicting objectives,
which results in a distinct Pareto optimal front.
The difference between the original NSGA II and the proposed modular feature of the LLM assisted NSGA
II algorithm (or LEO-modular) can be seen from the juxtaposition of flowcharts in Figure 6a and Figure
6b. The key difference lies in the use of LLM to generate candidate solutions that explore and exploit the
design space via prompts, as shown in Table 8, as opposed to the traditional use of crossover and mutations.
The crossover parameter employed in NSGA II algorithm generates offspring by switching parts of the
same chromosome among two parents. This operation retains the best of both parents chromosomes and
often leads to candidate solutions or offsprings in the near vicinity to the parents solutions, encouraging
exploitation. The mutation operator in binary coded genetic algorithm randomly flips the binary encoded bits
of chromosomes based on certain mutation probability. This often results in significant jump in the parent
solution, thus promoting exploration. The numerical experiments using LEO in the previous section has
already demonstrated evidence of generating solutions that exhibits attributes of exploration and exploitation.
We now demonstrate proof of concept that LLM based exploration and exploitation works equally well
within the NSGA II paradigm.
In order to fit the scope of the original NSGA II algorithm for exploitation/exploration, we generate two
offsprings using LLM via two parents as context at a given time. This must be contrasted with the approach
described in Section 2.2 (Figure 4), where we generate the entire population of solutions at a time. To
demonstrate the merits of the present approach we undertake two test cases named after the researchers of
the seminal work (Zitzler et al., 2000): ZDT1 and ZDT3. The equations describing the multiple objective
10


--- Page 11 ---
Population Initialisation
Compute Individual Fitness
Select Ranked Population
Parent Selection
Crossover
Mutation
Evaluate offspring fitness
Max 
Generations?
Ranking of combined population
Final Pareto front
NO
YES
(a) Schematic of the NSGA II Deb et al.
(2002) framework
Population Initialisation
Compute Individual Fitness
Select Ranked Population
Parent Selection
Exploitation via LLM
Exploration via LLM 
Evaluate offspring fitness
Max 
Generations?
Ranking of combined population
Final Pareto front
NO
YES
(b) Schematic of the LLM assisted NSGA
II framework
Figure 6: Original and modified NSGAII framework using LEO-modular
Table 3: Equations and Complexities of ZDT1 and ZDT3 Functions
Function
Complexity
ZDT1:
Non-uniformity in the search space and a convex Pareto-optimal front.
f1(x) = x1
f2(x) = g(1 −
p
f1/g)
Requires algorithms to maintain diversity.
g = 1 +
9
n−1
Pn
i=2 xi
ZDT3:
Disconnected Pareto-optimal front segments introduce additional complexity.
f1(x) = x1
f2(x) = g(1 −
p
f1/g −(f1/g) sin(10πf1))
Maintaining population diversity across gaps is challenging.
g = 1 +
9
n−1
Pn
i=2 xi
functions f1, f2 are listed in Table 3, while also highlighting the complexity associated with the two func-
tions. We employ these test experiments as a two-variable problem, i.e., n=2, in Table 3. The ZDT1 test was
undertaken using a population size of 10, whereas the ZDT3 test was performed using a population size of
30. Higher population size for the ZDT3 test allows for the crisp capture of the segmented Pareto optimal
front.
Figure 7(a) shows the final Pareto optimal front obtained from the LLM-modular, along with suitable com-
parisons made using the original NSGA II algorithm. Every input parameter including population size,
objective functions, number of optimisation iterations etc., are kept same for a fair comparison. Both these
test cases were run upto a total of 40 generations or optimisation iterations. For the sake of comparison,
11


--- Page 12 ---
0.00
0.25
0.50
0.75
1.00
Objective function, f
1
0.00
0.25
0.50
0.75
1.00
Objective function, f
2
(a) test case: ZDT1 
LEO-modular
NSGAII
NSGAII Pymoo
0.00
0.25
0.50
0.75
1.00
Objective function, f
1
−1.0
−0.5
0.0
0.5
1.0
Objective function, f
2
(b) test case: ZDT3 
LEO-modular
NSGAII
NSGAII Pymoo
Figure 7: Comparison of the Pareto optimal front obtained from the present approach with the NSGA II
algorithm
we also present the solutions obtained from yet another implementation of the NSGA II algorithm using
the open-source Pymoo Blank & Deb (2020) library. Pymoo-based solutions were generated using a much
larger population size npop = 200, and the optimisation was carried out for a total of 100 generations. Con-
sequently, the solutions would exhibit a dense Pareto optimal front. It can be seen that the Pareto optimal
front obtained from LEO-modular is in agreement with the Pareto optimal front obtained from the traditional
NSGA II algorithm. Figure 7(b) shows the Pareto optimal front for the ZDT3 test case, where a discontin-
uous front has been obtained. It is again found that the solutions from both approaches are in excellent
agreement despite the presence of discontinuities. These observations have a remarkable significance that
the LLM-based exploration and exploitation without any temperature-based parameter is able to generate
solutions that distinctly identify the Pareto optimal front using. This is especially significant considering
that a low population size and relatively low number of generations were employed to get the final Pareto
optimal front. In the view of the authors, this is the first ever instance where LLM have been used to perturb
parent solutions to generate offsprings purely based on prompts and should be viewed differently than using
LLM to generate offsprings via crossover and mutation.
3.3
HIGH-DIMENSIONAL PROBLEM
We now extend the capabilities of LEO for high-dimensional problems. For this, we consider the Rosenbrock
function which has a generalized N-dimensional formulation (2D formulation shown in Table 1). We linearly
vary the dimensionality of the problem and make some interesting observations about the performance of
LEO. The Rosenbrock N-dimensional function is given by:
f(x) = f(x0, x1, ..., xn−1) =
n−1
X
i=0

100(xi+1 −x2
i )2 + (1 −xi)2
,
−∞< xi < ∞, ∀i
(1)
This function has a global minimum of 0 as follows:
f(1, ..., 1
| {z }
n times
) = 0
We perform experiments by varying n from 2 all the way up to 25 dimensions, giving total 7 instances of
the functions with increasing dimensionality, i.e. 2, 4, 6, 8, 10, 20, 25. Each optimization problem is run for
12


--- Page 13 ---
100 optimization iterations, and we conduct 30 such independent runs for each problem to get statistically
significant results.
A key aspect to this problem is the fact that the global optima for the Rosenbrock function, fmin = 0, is at
the location (1, ..., 1). While LEO is able to accurately predict this optima, it can be argued that the number
1 could be one of the most common numbers encountered by the LLM during it’s training phase, causing the
LLM to predict this number simply because of its training history. This may result in the LLM predicting
the correct solution by the virtue of it being a ‘trivial’ solution. In order to address this issue, we modify the
Rosenbrock function, to have the minima shifted to an arbitrary location. The new shifted function is given
by:
f(x) = f(x0, x1, ..., xn−1) =
n−1
X
i=0

100((xi+1 −a) −(xi −a)2)2 + (1 −(xi −a))2
, −∞< xi < ∞, ∀i
(2)
This function has a global minimum of 0 as follows:
f(1 + a, ..., 1 + a
|
{z
}
n times
) = 0
with a randomly selected as 0.2913. It is critical to point out that doing the above exercise, naturally forces
LEO to thoroughly search for for better candidate solutions instead of returning a trivial solution.
0
20
40
60
80
100
Optimisation iterations
10
−3
10
−2
10
−1
10
0
10
1
10
2
10
3
Objective function value
2D
4D
6D
8D
10D
20D
25D
2D
4D
6D
8D
10D
20D
25D
Figure 8: Convergence pattern in the fmin obtained from exploit pool for the Rosenbrock function with
different dimensions
13


--- Page 14 ---
0.000
0.025
0.050
0.075
x
0.0000
0.0025
0.0050
0.0075
0.0100
y
(a) Initial pool
Control points
Fixed control points
0.000
0.025
0.050
0.075
x
0.0000
0.0025
0.0050
0.0075
0.0100
y
(b) Explore pool
variable control points
fixed control points
0.000
0.025
0.050
0.075
x
0.0000
0.0025
0.0050
0.0075
0.0100
y
(c) Exploit pool
V
ariable control points
Fixed control points
Figure 9: (a) Initial pool of solutions (b) explore pool of solution, and (c) exploit pool of solutions obtained
from LEO
Figure 8 shows a distribution of the mean objective function value in the exploit pool plotted with respect
to the number of optimization iterations for all the 7 instances of the functions. We notice that as the
dimensionality increases, the obtained minima of the function value also increases. This is not surprising
and rather aligns well with the intuition that with higher dimensionality of the problem, the population size
as well as the number of optimisation iterations should also be increased. Nevertheless, the intention behind
performing this exercise is to convey the consistency of the convergence rate for high-dimensional problem
when limited to certain number of optimisation iterations.
3.4
ENGINEERING APPLICATIONS
In this section, we examine the application of our method using practical examples of industrial relevance.
We have selected three applications for this purpose: (a) Nozzle shape optimization for supersonic flow (b)
1D steady-state heat transfer problem; (c) wind-farm layout optimization. In the following subsections,
we discuss the results obtained with LEO. The details of each of the problem setups are provided in the
Appendix.
3.4.1
NOZZLE SHAPE OPTIMIZATION
We begin by showcasing the utility of LEO for industrial-scale optimisation problems, specifically the nozzle
shape design optimisation problem. In the context of the present work, we aim to obtain a nozzle contour rep-
resented by a cubic Bezier curve that allows for maximum thrust by reducing the radial velocity component
at the exit. The length, inlet radii, and outlet radii are kept constant, resulting in an effective 4-dimensional
(4D) problem. For details, please refer to A.2.
Figure 9(a) shows the juxtaposition of the initial nozzle shapes that are fed to both explore and exploit pools.
It is clear that the initial pool of solutions portrays significant variations among themselves without any bias
towards any particular shapes, which is key for any optimisation task. Figure 9(b) presents the final nozzle
shapes from the explore pool at the end of 30 optimisation iterations, which exhibit minor variations, as
expected. The optimal shape obtained from the exploit pool with the least radial velocity at the nozzle exit is
shown in Fig. 9(c). It is noted that the nozzle shape obtained from the final explore and exploit pool clearly
demonstrated bell shaped contours, which augers well with the expected shapes derived using isentropic
flow theory Rao (1958). This demonstrates that LEO is able to refine its search towards obtaining optimal
shapes that are consistent with expected theory, albeit for a 4D problem.
14


--- Page 15 ---
Figure 10: Convergence of the minimum and mean function values with optimisation iterations for exploit
and explore pools
3.4.2
ONE-DIMENSIONAL HEAT TRANSFER PROBLEM
Heat transfer is a fundamental phenomenon in many industrial applications. While robust numerical methods
like finite difference coupled with iterative approaches allow us to compute the discretized solution to the
governing equations A.3, the same can be viewed as an optimisation problem, i.e., temperature distribution
that results in minimization of the residual loss of the underlying governing equation A.3s. In this section,
we determine the solution to a 1D steady-state heat transfer problem in a domain discretised using N points
using LEO. All the test cases in this section are solved using a population size of 10 for a total of 100
optimisation iterations.
Figure 11 (a) shows the steady-state temperature distribution obtained by LEO and its comparison with the
exact solution for N = 2. While N = 2 results in a rather jagged temperature profile, it is clear that the
solution obtained from LEO agrees quite well with that of the exact solution. This signifies that a solution
for a low-dimensional problem can result in a physics-consistent solution. Figure 11 (b) shows the steady-
state temperature profile for N = 4 where minor observable differences with the exact temperature profile
are noted. This is not surprising and rather points to the observation that has been made in Section 3.3.
Similarly, Fig. 11 (c) shows a stark contrast between solutions obtained from LEO and their comparison with
the exact temperature profile. This clearly indicates that while the present approach performs remarkably
well in yielding physics-consistent solutions for low-dimensional problems, the nature of the solution starts
to deviate significantly for higher degrees of freedom, necessitating the need to evolve the search with higher
number of optimisation iterations using higher population size.
3.4.3
WINDFARM LAYOUT OPTIMIZATION
In this experiment, we will investigate the capabilities of LEO in optimizing the layout of a wind farm,
which is essentially the process of finding the optimal locations of wind turbines in a wind farm to maximize
the power production A.4.
Figure 12 shows the kernel density estimation (KDE) obtained for the optimal layout considering all 30 runs
in each of the three cases with 2, 4, and 8 turbines within the domain described previously. This would result
in 4, 8, and 16 decision variables, respectively, for the optimization problem as each turbine is uniquely
specified in a 2D domain with (x, y) coordinates. In the layout optimization routine of FLORIS, Scipy’s
SLSQP optimization method is used as the solver. We can clearly see from this figure that LEO is able
15


--- Page 16 ---
Figure 11: Heat equation optimization for increasing number of variables.
0
200
400
600
800
1000
x
0
200
400
600
800
1000
y
(a) Wind-turbines=2 (LEO)
0
200
400
600
800
1000
x
0
200
400
600
800
1000
(b) Wind-turbines=4 (LEO)
0
200
400
600
800
1000
x
0
200
400
600
800
1000
(c) Wind-turbines=8 (LEO)
0
200
400
600
800
1000
x
0
200
400
600
800
1000
y
(d) Wind-turbines=2 (FLORIS)
0
200
400
600
800
1000
x
0
200
400
600
800
1000
(e) Wind-turbines=4 (FLORIS)
0
200
400
600
800
1000
x
0
200
400
600
800
1000
(f) Wind-turbines=8 (FLORIS)
0.000
0.348
0.753
1.070
1.441
1.802
2.179
2.565
2.937
3.315
Probability Density
1e−6
0.000
0.114
0.170
0.231
0.300
0.385
0.535
0.692
0.846
1.004
Probability Density
1e−6
0.000
1.463
2.185
3.001
3.915
4.879
5.850
6.847
7.841
9.544
Probability Density
1e−7
0.000
1.591
2.515
2.931
3.342
4.022
4.832
5.704
6.659
8.769
Probability Density
1e−7
0.000
2.289
3.835
4.551
4.935
5.391
5.773
6.365
7.157
9.386
Probability Density
1e−7
0.000
2.011
3.293
3.947
4.314
4.700
5.056
5.706
6.764
8.331
Probability Density
1e−7
Figure 12: Windfarm layout optimization for increasing number of wind-turbines.
to produce layouts with a distribution that is in agreement with what is obtained with conventional Scipy’s
SLSQP method. Figure 13 shows the Annual Energy Production (AEP) value with iterations for a randomly
picked run in each of the three cases. This figure clearly demonstrates the optimization trajectory as the
iterations progress, demonstrating that LEO can indeed optimize industrial scale problems.
4
DISCUSSION
In this section, we explore the reasoning capabilities of LLMs backed by strong evidence. We show that
LLMs inherently possess attributes of reasoning that, when assisted by an elitism criterion, allow for a hy-
brid framework that renders faster convergence towards a global optimal solution for highly non-convex
16


--- Page 17 ---
0
20
40
60
80
100
Optimizaton iterations
391
392
393
394
Power (W)
1e2
(a) Wind-turbines=2
0
20
40
60
80
100
Optimizaton iterations
735
740
745
750
755
1e2
(b) Wind-turbines=4
0
20
40
60
80
100
Optimizaton iterations
1260
1280
1300
1320
1340
1e2
(c) Wind-turbines=8
Figure 13: Windfarm layout optimization loss curves for increasing dimensionality of the problem.
optimisation problems. We then list out various challenges that are encountered while using LLMs as op-
timizers. This is followed by enumerating various engineering tweaks and strategies that were devised in
conjunction with LLMs that allow us to circumvent such issues. In our experience, these tweaks have been
instrumental in getting the best optimization performance out of the LLMs. Finally, we provide some future
directions towards improving the performance of LEO for high dimensional problems.
4.1
PROOF OF LLM REASONING CAPABILITIES
The elitism approach that we adopt in this paper, i.e., the explore-exploit-port-filter strategy, naturally
prompts the question, “Does LLM’s reasoning indeed result in better candidate solutions, resulting in faster
convergence to global optimal solution, or would a LLM tasked with the generation of random exploit and
explore solutions result in better convergence?" To systematically address this issue, we designed the follow-
ing two experiments: (a) In the first experiment, we examine the performance of LLM assisted by guardrails
(i.e., LEO) and compare with the same framework where LLM are used to randomly generate explore and
exploit solutions without guardrails (LEO-Rnd) (b) In the second experiment, we undertake additional sta-
tistical evaluations to exhibit the reasoning component of the LLM in arriving at the final optimal solution.
We discuss our findings in the next two sub-sections.
4.1.1
EXPERIMENT 1: LLM SOLELY AS SOLUTION GENERATOR
In this experiment, we designate the LLM as the role of only a random solution generator (LEO-Rnd), i.e.,
random perturbation of candidate points, without any historical context or guardrails such as elitism (refer
Tables 6 and 7). The context in question is the information about candidate solutions and their function
values from previous optimisation iterations. In doing so, the burden of finding the optimal solution falls
completely on the port_and_filter function. This exercise also allows us to prove the contrary: LLMs,
when provided with the context of candidate solutions and tasked with the generation of new candidate
solutions such that function value is reduced, result in faster convergence (refer to Table 5). The purpose
of this experiment is to explicitly demonstrate the superiority of LLMs to generate better candidate points
using optimization history (LEO), as opposed to simply using LLM to exhaustively generate solutions in an
explore and exploit pool that might locate the global optimal solution (LEO-Rnd).
We show experiments using both LEO and LEO-Rnd in optimizing the 2D Goldstein-Price function. This
test was performed for 100 optimisation iterations using 10 different random number seeds. Table 4 high-
lights the differences between the two methods. Table 5 shows the results obtained from this experiment,
where it is found that LEO outperforms LEO-Rnd in terms of mean and median convergence with optimisa-
17


--- Page 18 ---
Task
Context
Guardrails
Explore Prompt
Exploit Prompt
LEO
Generate Solutions
at kth iteration
such that function
value is reduced
Solutions and
function values
at k - 1th iteration
Elitism
Refer Table 6
Refer Table 7
LEO-Rnd
Generate solutions at
kth iteration
None
None
Refer Table 6
Refer Table 7
Table 4: Difference between the underlying approach adopted for LEO and LEO-Rnd
Mean ± std
Median
LEO
3.008 ± 0.019
3.000
LEO-Rnd
5.275 ± 1.718
5.407
Table 5: Comparison of numerical accuracy of LEO and LEO-Rnd methods for 2D Goldstein Price problem
tion iterations. It must be noted that LEO is able to accurately identify the global optimal solution, whereas
this is not reflected in solutions obtained from LEO-Rnd. In addition, Figs. 14(a) and 14(b) show the con-
vergence plots of LEO and LEO-Rnd for both the mean and the median, computed across 10 experiments. It
can be observed that at the start of the optimisation, the rate of convergence exhibited by LEO is much higher
than that of LEO-Rnd, which shows that it very quickly navigates from the poor initial guess to the global
optima. On the contrary, LEO-Rnd shows signs of plateau, signifying that the LLM-based random solution
generation without context and guardrails fails to locate the global optima, despite the port_and_filter
function serving as a ’soft’ optimisation filter. We argue that this experiment is a clear demonstration of the
ability of LLMs to build a topological relation of the decision variable with function space, with which it
adaptively generates better candidate points, that aid in much faster convergence, thereby exhibiting reason-
ing capabilities.
4.1.2
EXPERIMENT 2: DIMINISHING VARIANCE OF THE EXPLORE POOL
A question of paramount importance in this study is to clearly demonstrate the reasoning ability of LLM
to yield better candidate solutions. An affirmative answer to such an evaluation will form the backbone
of the present optimisation approach. To this extent, we ask the following question: if, in the present
strategy, LEO progressively shows signs of diminishing variance in the explore pool, does it amount to
reasoning? This is not a trivial proposition, as solutions are always exported from the explore pool to the
exploit pool. So naturally, it is expected to have diminishing variance in the exploit pool and not the other
way around. Additionally, if the explore pool progressively aligns in the direction of the global optimal
solution, it naturally results in the generation of better candidate solutions in the exploit pool due to the use
of the port_and_filter function. While several papers, for example (Liu et al., 2023c; Yang et al.,
2023; Guo et al., 2023), use the temperature to control the explore and exploit behavior, we entrust the
responsibility of generating explore and exploit pools to the model itself.
Figure 14 presents the results for the Goldstein- Price problem. Specifically, Figures 14(c) and 14(d) il-
lustrate the variation of the Kernel Density Function (KDF) for the explore pools corresponding to the two
variables in the LEO method. Similarly, Figures 14(e) and 14(f) depict the KDF for the same two variables,
but this time using the LEO-Rnd method. Upon analyzing these figures, a clear trend emerges: the mean
of the distribution associated with the explore pool in the LEO method converges towards the solutions,
accompanied by a diminishing variance. This observation confirms that the model effectively reasons for
and extracts ‘better’ points from regions characterized by lower objective function values. In contrast, the
LEO-Rnd method does not exhibit a similar trend. This discrepancy can be attributed to the random selec-
18


--- Page 19 ---
Figure 14: Plots demonstrating reasoning by LEO. Comparison of convergence behaviour depicted by LEO
and LEO-Rnd in terms of (a) mean and (b) median with optimisation iterations. Comparison of kernel
density functions for solutions belonging to explore pool (every 5th iteration) obtained from (c) LEO (var1),
(d) LEO (var1), (e) LEO-Rnd (var1), and (f) LEO-Rnd (var2).
19


--- Page 20 ---
tion of the explore pool. Notably, this finding underscores an important point: relying solely on temperature
as a means to control exploration may not yield optimal results, as it primarily introduces randomness. On
the other hand, the elitism-based guardrails effectively harness the reasoning capability of LLMs to generate
‘better’ points.
4.2
CHALLENGES INVOLVED WITH LLM BASED OPTIMIZERS
We now discuss some practical challenges we have encountered during our exploration of LLMs in the
context of optimization:
1. Reproducibility of exact performances: We can fix a random seed to start the optimization from
the same point. However, we cannot curtail the randomness. If we fix the temperature to zero, we
can ensure repeatability, but at the cost of reduced performance due to poor exploration. Alterna-
tively, a higher temperature value would improve the model’s performance at the cost of reduced
repeatability. Further, as argued previously, a very high temperature value can result in diminished
performance of the method.
2. LLM hallucinations: LLMs sometimes produce numbers such as 1.23456 (i.e., some common
sequences) or common integers such as 0 or 1, which are not backed by any rationale. This issue
has been reported in Hopkins et al. (2023). This sometimes leads to the model getting stuck at local
minima.
3. Mode collapse problem: In spite of a higher temperature value, there are times at which a LLM
keeps producing the same output, often a trivial number such as 1.0000 or 0.0000. This stems from
the model-collapse issue pertaining to the auto-regressive nature of the algorithm, as explained in
Hopkins et al. (2023).
4. The impact of increasing dimensions on model accuracy: From benchmark problems to en-
gineering applications, we consistently observe that LEO produces erroneous solutions for high-
dimensional cases. Further, the uncertainty in the solutions increases with an increase in dimen-
sionality.
5. Computational expenses of large language models: As this technology is still in its infancy, there
are currently high costs associated with querying GPT-3.5 Turbo, which is used in this study. More
advanced models, such as the GPT-4, are even more expensive. However, as the technology evolves
towards maturity, it is anticipated that the costs associated with LLMs will decrease, concurrently
improving their efficacy.
6. Limitations in addressing saddle points: This method may not be able to identify and solve
saddle point problems, because the explore-exploit strategy is based on prompts instructing the
user to minimize the objective function value.
4.3
REMEDIES
Some of the remedies that would be helpful to mitigate the above mentioned challenges are as follows:
1. Exact reproducibility is still unsolved, but a straightforward way to extract consistent performance
is to follow an ensemble approach. The mean of several runs converges to the global optima as the
number of samples increases.
2. To address issues such as mode collapse and hallucinated numbers, we add ‘jitter’ to the prompt.
This means a small amount of perturbation added to the examples in the prompts seems to solve
both of these issues.
20


--- Page 21 ---
3. Assigning the identity of an optimization researcher at the very beginning of the prompt seems to
improve the performance.
The detailed prompts used for the explore and exploit operations are presented in Appendix B.
4.4
IMPROVING ACCURACY FOR HIGH-DIMENSIONAL PROBLEMS
A possible remedy for the high-dimensional problem could be the stochastic sampling suggested in (Hu
et al., 2023). Herein, a subset of dimensions, randomly chosen, are handled at a time by LEO. The batch-
size becomes a hyperparameter and would depend on the context-window length of the LLM. Another
possible approach to tackling the high-dimensional problems could be an agent based approach. Here,
a number of LEO agents can work on a smaller number of dimensions and communicate their outputs
through a message-passing interface or graph-based framework. A successful solution strategy for the high-
dimensional problems could have a huge impact on the field of scientific machine learning, and would be
the topic of future research.
5
CONCLUSIONS
This paper presents a population-based optimization method based on LLMs called Language-model-based
Evolutionary Optimizer (LEO). We present a diverse set of benchmark test cases, spanning from elemen-
tary examples to multi-objective and high-dimensional numerical optimization problems. Furthermore, we
illustrate the practical application of this method to industrial optimization problems, including shape opti-
mization, heat transfer, and windfarm layout optimization.
Several key conclusions can be drawn based on the obtained results.
1. We assert that LLMs exhibit the capacity to reason and execute zero-shot optimization.
The
explore-exploit strategy, as proposed in this paper, effectively harnesses this inherent ability and
consistently performs on par with, if not surpassing, some of the leading methods in numerical
optimization.
2. We deduce that while LLMs are capable of optimization, achieving consistent and improved per-
formance necessitates a series of engineering adjustments. LLMs tend to exhibit creativity and a
propensity for hallucinations. Consequently, prompt engineering interventions become crucial to
eliciting consistent behavior from these models.
3. Our observations reveal that although LLMs excel in low-dimensional problems, they require a
greater number of iterations to converge to a global optimum in high-dimensional scenarios. This
phenomenon is reflected in a gradual reduction in accuracy as the dimensionality increases for the
same fixed number of iterations, a trend also observed in the engineering examples.
4. LEO offers several advantages over conventional methods for low-dimensional problems, such
as a parameter-free method, ease of implementation, suitability for multi-objective optimization
problems with conflicting objectives, as well as problems with multiple minima, automatic step-
size selection, etc.
5. We have demonstrated that LLM-based exploration and exploitation offers a straightforward way to
yield ‘effects’ of crossover and mutation akin to evolutionary strategies such as the popular NSGA
II approach. This enables a seamless way to perturb candidate solutions that distinctively retain the
identity of the Pareto optimal front.
While the method still requires overcoming a few hurdles to make it suitable for engineering applications,
such as tackling high-dimensional problems and the high costs associated with running LLMs, as discussed
previously, it still offers the following advantages in its current form:
21


--- Page 22 ---
1. Parameter-Free Method: Our approach operates without the need for any user-defined parame-
ters. This inherent flexibility renders it suitable for a wide spectrum of problems, eliminating the
burden of fine-tuning specific parameters.
2. Decoupling Exploration and Exploitation: Unlike other LLM-based optimization methods that
rely on temperature-based exploration, our approach treats exploration and exploitation as distinct
operations. This, when coupled with a rich context provided to the LLM, results in a superior
distribution of candidate values. Notably, our experiments demonstrate that this approach leads to
faster convergence compared to random point selection (governed by temperature) while maintain-
ing other settings.
3. Unrestricted step size (learning rate): Unlike other gradient-based optimizers, there is no restric-
tion on step size (learning rate), since it is automatically inferred based on the samples presented in
the prompt. This addresses issues associated with too small as well as too large learning rates, such
as getting stuck in local minima and loss of stability.
4. Optimizing for multi-objective problems It is suitable for multi-objective optimization problems,
as well as for problems with multiple global minima, as evident from the test cases presented in
this study.
5. A modular approach: Owing to its simplicity, it can be seamlessly incorporated into any existing
population-based optimization framework. This vastly improves the usability of this method.
The scope of this paper is limited to exploring the present capabilities of LLMs, specifically GPT3.5 Turbo,
in the context of optimization. The effects of LLM-specific parameters such as model size, model archi-
tecture, and modality (single-modal vs. multi-modal) on the abilities of the models to perform numerical
optimization will be explored in future work. Additionally, our forthcoming work will address strategies
aimed at mitigating the curse of dimensionality.
ACKNOWLEDGEMENTS
The authors from Shell India Markets Pvt. Ltd. would like to acknowledge the financial support from Shell.
REFERENCES
Vishesh Agarwal, Somak Aditya, and Navin Goyal. Analyzing the nuances of transformers’ polynomial
simplification abilities. arXiv preprint arXiv:2104.14095, 2021.
Ali AhmadiTeshnizi, Wenzhi Gao, and Madeleine Udell. Optimus: Optimization modeling using mip solvers
and large language models. arXiv preprint arXiv: Arxiv-2310.06116, 2023.
Andrew E. Blanchard, Mayanka Chandra Shekar, Shang Gao, John Gounley, Isaac Lyngaas, Jens Glaser, and
Debsindhu Bhowmik. Automating genetic algorithm mutations for molecules using a masked language
model. IEEE Transactions on Evolutionary Computation, 26(4):793–799, 2022. doi: 10.1109/TEVC.
2022.3144045.
J. Blank and K. Deb. pymoo: Multi-objective optimization in python. IEEE Access, 8:89497–89509, 2020.
Daniil Boiko, Robert MacKnight, Ben Kline, and Gabe Gomes. Autonomous chemical research with large
language models. Nature, 624:570–578, 12 2023. doi: 10.1038/s41586-023-06792-0.
Shuvayan Brahmachary, Ganesh Natarajan, and Niranjan Sahoo. On maximum ballistic coefficient axisym-
metric geometries in hypersonic flows. Journal of Spacecraft and Rockets, 55(2):518–522, 2018.
22


--- Page 23 ---
Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, and Philippe Schwaller.
Chemcrow: Augmenting large-language models with chemistry tools.
arXiv preprint arXiv: Arxiv-
2304.05376, 2023.
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss,
Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens
Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,
Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.
Language
models are few-shot learners.
In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin
(eds.), Advances in Neural Information Processing Systems, volume 33, pp. 1877–1901. Curran Asso-
ciates, Inc., 2020. URL https://proceedings.neurips.cc/paper_files/paper/2020/
file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.
Richard H Byrd, Peihuang Lu, Jorge Nocedal, and Ciyou Zhu. A limited memory algorithm for bound
constrained optimization. SIAM Journal on scientific computing, 16(5):1190–1208, 1995.
François Charton. Linear algebra with transformers. arXiv preprint arXiv:2112.01898, 2022.
Lichang Chen, Jiuhai Chen, Tom Goldstein, Heng Huang, and Tianyi Zhou. Instructzero: Efficient instruc-
tion optimization for black-box large language models. arXiv preprint arXiv: Arxiv-2306.03082, 2023.
Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Michael Laskin, Pieter Abbeel, Ar-
avind Srinivas, and Igor Mordatch. Decision transformer: Reinforcement learning via sequence modeling.
arXiv preprint arXiv:2106.01345, 2021.
Yongchao Chen, Jacob Arkin, Yilun Hao, Yang Zhang, Nicholas Roy, and Chuchu Fan. Prompt optimiza-
tion in multi-step tasks (promst): Integrating human feedback and preference alignment. arXiv preprint
arXiv:2402.08702, 2024.
Yutian Chen, Xingyou Song, Chansoo Lee, Zi Wang, Qiuyi Zhang, David Dohan, Kazuya Kawakami, Greg
Kochanski, Arnaud Doucet, Marc’Aurelio Ranzato, Sagi Perel, and Nando de Freitas. Towards learn-
ing universal hyperparameter optimizers with transformers. In Neural Information Processing Systems
(NeurIPS) 2022, pp. 32053–32068, 2022.
Tri Dao. Flashattention-2: Faster attention with better parallelism and work partitioning, 2023.
Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. Flashattention: Fast and memory-efficient
exact attention with io-awareness. Advances in Neural Information Processing Systems, 35:16344–16359,
2022.
Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan. A fast and elitist multiobjective
genetic algorithm: Nsga-ii. IEEE transactions on evolutionary computation, 6(2):182–197, 2002.
Eszter Dudás, Nicolas Suas-David, Shuvayan Brahmachary, Vinayak Kulkarni, Abdessamad Benidar, Samir
Kassi, Christine Charles, and Robert Georges. High-temperature hypersonic laval nozzle for non-lte cavity
ringdown spectroscopy. The Journal of Chemical Physics, 152(13), 2020.
Pei-Fu Guo, Ying-Hsuan Chen, Yun-Da Tsai, and Shou-De Lin. Towards optimizing with large language
models. arXiv preprint arXiv: Arxiv-2310.05204, 2023.
Nikolaus Hansen and Andreas Ostermeier. Adapting arbitrary normal mutation distributions in evolution
strategies: The covariance matrix adaptation. In Proceedings of IEEE international conference on evolu-
tionary computation, pp. 312–317. IEEE, 1996.
23


--- Page 24 ---
Aspen K Hopkins, Alex Renda, and Michael Carbin. Can LLMs generate random numbers? evaluating
LLM sampling in controlled domains. In ICML 2023 Workshop: Sampling and Optimization in Discrete
Space, 2023. URL https://openreview.net/forum?id=Vhh1K9LjVI.
Zheyuan Hu, Khemraj Shukla, George Em Karniadakis, and Kenji Kawaguchi. Tackling the curse of dimen-
sionality with physics-informed neural networks. arXiv preprint arXiv: Arxiv-2307.12306, 2023.
Jie Huang and Kevin Chen-Chuan Chang. Towards reasoning in large language models: A survey. arXiv
preprint arXiv: Arxiv-2212.10403, 2023.
Kevin Maik Jablonka, Philippe Schwaller, Andres Ortega-Guerrero, and Berend Smit.
Leveraging
large language models for predictive chemistry.
Nature Machine Intelligence, 6(2):161–169, Feb
2024. ISSN 2522-5839. doi: 10.1038/s42256-023-00788-1. URL https://doi.org/10.1038/
s42256-023-00788-1.
Jack Kiefer and Jacob Wolfowitz. Stochastic estimation of the maximum of a regression function. The
Annals of Mathematical Statistics, pp. 462–466, 1952.
Diederik P Kingma and Jimmy Ba.
Adam: A method for stochastic optimization.
arXiv preprint
arXiv:1412.6980, 2014.
Scott Kirkpatrick, C Daniel Gelatt Jr, and Mario P Vecchi. Optimization by simulated annealing. science,
220(4598):671–680, 1983.
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language
models are zero-shot reasoners. arXiv preprint arXiv: Arxiv-2205.11916, 2023.
Guillaume Lample and François Charton.
Deep learning for symbolic mathematics.
arXiv preprint
arXiv:1912.01412, 2019.
Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Xingyu Dang, and Song Han. Awq: Activation-aware
weight quantization for llm compression and acceleration. arXiv preprint arXiv:2306.00978, 2023.
Fei Liu, Xi Lin, Zhenkun Wang, Shunyu Yao, Xialiang Tong, Mingxuan Yuan, and Qingfu Zhang. Large
language model for multi-objective evolutionary optimization. arXiv preprint arXiv: Arxiv-2310.12541,
2023a.
Fei Liu, Xialiang Tong, Mingxuan Yuan, and Qingfu Zhang. Algorithm evolution using large language
model. arXiv preprint arXiv: Arxiv-2311.15249, 2023b.
Shengcai Liu, Caishun Chen, Xinghua Qu, Ke Tang, and Yew-Soon Ong. Large language models as evolu-
tionary optimizers. arXiv preprint arXiv: Arxiv-2310.19046, 2023c.
Shihong Liu, Zhiqiu Lin, Samuel Yu, Ryan Lee, Tiffany Ling, Deepak Pathak, and Deva Ramanan. Language
models as black-box optimizers for vision-language models. arXiv preprint arXiv:2309.05950, 2023d.
Yiheng Liu, Tianle Han, Siyuan Ma, Jiayue Zhang, Yuanyuan Yang, Jiaming Tian, Hao He, Antong Li,
Mengshen He, Zhengliang Liu, Zihao Wu, Lin Zhao, Dajiang Zhu, Xiang Li, Ning Qiang, Dingang
Shen, Tianming Liu, and Bao Ge. Summary of chatgpt-related research and perspective towards the
future of large language models. Meta-Radiology, 1(2):100017, 2023e. ISSN 2950-1628. doi: https:
//doi.org/10.1016/j.metrad.2023.100017. URL https://www.sciencedirect.com/science/
article/pii/S2950162823000176.
Jieyi Long. Large language model guided tree-of-thought. arXiv preprint arXiv:2305.08291, 2023.
24


--- Page 25 ---
Yecheng Jason Ma, William Liang, Guanzhi Wang, De-An Huang, Osbert Bastani, Dinesh Jayaraman, Yuke
Zhu, Linxi Fan, and Anima Anandkumar. Eureka: Human-level reward design via coding large language
models. arXiv preprint arXiv: Arxiv-2310.12931, 2023.
Rimon Melamed, Lucas H. McCabe, Tanay Wakhare, Yejin Kim, H. Howie Huang, and Enric Boix-Adsera.
Propane: Prompt design as an inverse problem. arXiv preprint arXiv:2311.07064, 2023.
Bonan Min, Hayley Ross, Elior Sulem, Amir Pouran Ben Veyseh, Thien Huu Nguyen, Oscar Sainz, Eneko
Agirre, Ilana Heintz, and Dan Roth. Recent advances in natural language processing via large pre-trained
language models: A survey. ACM Comput. Surv., 56(2), sep 2023. ISSN 0360-0300. doi: 10.1145/
3605943. URL https://doi.org/10.1145/3605943.
OpenAI, :, and Josh Achiam et. al. Gpt-4 technical report. arXiv preprint arXiv: Arxiv-2303.08774, 2023.
Michal Pluhacek, Anezka Kazikova, Tomas Kadavy, Adam Viktorin, and Roman Senkerik. Leveraging
large language models for the generation of novel metaheuristic optimization algorithms. In Proceedings
of the Companion Conference on Genetic and Evolutionary Computation, GECCO ’23 Companion, pp.
1812–1820, New York, NY, USA, 2023. Association for Computing Machinery. ISBN 9798400701207.
doi: 10.1145/3583133.3596401. URL https://doi.org/10.1145/3583133.3596401.
Michael JD Powell. A direct search optimization method that models the objective and constraint functions
by linear interpolation. Springer, 1994.
Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng.
Automatic prompt
optimization with "gradient descent" and beam search. arXiv preprint arXiv: Arxiv-2305.03495, 2023.
GVR Rao. Exhaust nozzle contour for optimum thrust. Journal of Jet Propulsion, 28(6):377–382, 1958.
Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov, Gabriel
Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, Tom Eccles, Jake Bruce,
Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell, Oriol Vinyals, Mahyar Bordbar,
and Nando de Freitas. A generalist agent. arXiv preprint arXiv:2205.06175, 2022.
Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M Pawan Ku-
mar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, et al. Math-
ematical discoveries from program search with large language models. Nature, pp. 1–3, 2023.
Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox,
Jesse Thomason, and Animesh Garg. Progprompt: Generating situated robot task plans using large lan-
guage models. arXiv preprint arXiv: Arxiv-2209.11302, 2022.
Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch,
Adam R. Brown, Adam Santoro, and Aditya Gupta et. al. Beyond the imitation game: Quantifying and
extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615, 2023.
Francesco Stella, Cosimo Della Santina, and Josie Hughes.
How can llms transform the robotic de-
sign process?
Nature Machine Intelligence, 5(6):561–564, Jun 2023.
ISSN 2522-5839.
doi:
10.1038/s42256-023-00669-7. URL https://doi.org/10.1038/s42256-023-00669-7.
Mojtaba Valipour, Bowen You, Maysum Panju, and Ali Ghodsi. Symbolicgpt: A generative transformer
model for symbolic regression. arXiv preprint arXiv:2106.14131, 2021.
25


--- Page 26 ---
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Ł ukasz Kaiser, and Illia Polosukhin.
Attention is all you need.
In I. Guyon, U. Von
Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances
in Neural Information Processing Systems, volume 30, pp. 6000–6010. Curran Associates, Inc.,
2017.
URL https://proceedings.neurips.cc/paper_files/paper/2017/file/
3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf.
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima
Anandkumar. Voyager: An open-ended embodied agent with large language models. arXiv preprint
arXiv: Arxiv-2305.16291, 2023.
Jane X Wang, Zeb Kurth-Nelson, Dhruva Tirumala, Hubert Soyer, Joel Z Leibo, Remi Munos, Charles
Blundell, Dharshan Kumaran, and Matt Botvinick.
Learning to reinforcement learn.
arXiv preprint
arXiv:1611.05763, 2017.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and
Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models. arXiv preprint
arXiv:2201.11903, 2023.
Guangxuan Xiao, Ji Lin, Mickael Seznec, Hao Wu, Julien Demouth, and Song Han. Smoothquant: Accu-
rate and efficient post-training quantization for large language models. In International Conference on
Machine Learning, pp. 38087–38099. PMLR, 2023.
Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V. Le, Denny Zhou, and Xinyun Chen. Large
language models as optimizers. arXiv preprint arXiv:2309.03409, 2023.
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. Tree
of thoughts: Deliberate problem solving with large language models. Advances in Neural Information
Processing Systems, 36, 2024.
Michael Zhang, Nishkrit Desai, Juhan Bae, Jonathan Lorraine, and Jimmy Ba. Using large language models
for hyperparameter optimization. In NeurIPS 2023 Foundation Models for Decision Making Workshop,
2023a. URL https://openreview.net/forum?id=FUdZ6HEOre.
Shujian Zhang, Chengyue Gong, Lemeng Wu, Xingchao Liu, and Mingyuan Zhou. Automl-gpt: Automatic
machine learning with gpt. arXiv preprint arXiv:2305.02499, 2023b.
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen
Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang,
Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. A survey of
large language models. arXiv preprint arXiv: Arxiv-2303.18223, 2023.
Mingkai Zheng, Xiu Su, Shan You, Fei Wang, Chen Qian, Chang Xu, and Samuel Albanie. Can gpt-4
perform neural architecture search? arXiv preprint arXiv:2304.10970, 2023.
Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy
Ba. Large language models are human-level prompt engineers. arXiv preprint arXiv: Arxiv-2211.01910,
2023.
Eckart Zitzler, Kalyanmoy Deb, and Lothar Thiele. Comparison of multiobjective evolutionary algorithms:
Empirical results. Evolutionary computation, 8(2):173–195, 2000.
26


--- Page 27 ---
A
APPENDIX: PROBLEM FORMULATION
A.1
NOSE CONE SHAPE OPTIMISATION
The nose cone shape optimisation has been a well-studied problem in the aerospace industry since the early
1950’s. Researchers have adopted various theoretical approaches, such as the Newtonian method, Taylor-
Maccoll theory, the Fay-Riddel stagnation point heat transfer approach, etc., to design nose cone shapes
with the objective of minimizing drag coefficients, ballistic coefficients, heat transfer, etc. Brahmachary
et al. (2018). In the present work, we represent the shape of the nose cone body having a fineness (or length
to diameter) ratio of L/D=1 using a simple power-law curve as follows:
y = axn ; 0.001 ≤n ≤1
(3)
where n is the decision variable that determines the shape of the body (see Fig. 15). In addition, we employ
Newtonian theory to compute the drag coefficient Cd.
L
R
y = axn
Figure 15: Juxtaposition of typical nose cones represented using a simple power law body
A.2
NOZZLE SHAPE OPTIMISATION
The nozzle shape design is yet another key application in the aerospace industry. For instance, nozzle shape
design is an integral component in the design of ramjet/scramjet engines for high thrust. In the present
study, the two-dimensional (2D) nozzle is designed with the objective to maximise the streamwise velocity
or minimise the radial velocity Dudás et al. (2020). For any given nozzle shape, the radial velocity or the
streamwise velocity can be easily computed using a simple algebraic equation such as the area-Mach number
relation, invoking the simple quasi-1D flow assumptions for high-speed compressible flows. The 2D nozzle
in consideration is parameterized using a cubic Bezier curve as follows:
x(t) = (1 −t)3x0 + 3(1 −t)2tx1 + 3(1 −t)t2x2 + t3x3,
y(t) = (1 −t)3y0 + 3(1 −t)2ty1 + 3(1 −t)t2y2 + t3y3,
t ∈[0, 1].
where the control points (x0, y0) and (x3, y3) are fixed in space (for fixed inlet radius, ri, outlet radii, ro, and
length, l), whereas the remaining control points (x1, y1) and (x2, y2) are variables (see Fig. 16). This results
in a 4D problem.
27


--- Page 28 ---
ri
ro
l
x0, y0
x3, y3
x2, y2
x1, y1
Figure 16: Schematic of the nozzle shape representation and associated variable
A.3
ONE-DIMENSIONAL HEAT TRANSFER PROBLEM
We attempt to solve a 1D steady-state heat transfer equation as shown below:
d2T
dx2 + qx
k = 0 | TL = 0, TR = 1
(4)
where T is the non-dimensional temperature distribution and q/k is the internal heat generation per unit
volume. In order to solve the steady-state temperature distribution that satisfies the above equation, we
impose the Dirichlet boundary condition at the extreme ends of the 1D computational domain, as shown
above. The domain of length L is discritised using N elements, which are varied across multiple test cases
in this present experiment. This results in an equal elemental spacing of ∆x = L/N. We adopt second order
central differencing for the second order term, followed by a constant value for q/k = 10. This results in a
residual loss term (or objective function) as follows:
Ti−1 −2Ti + Ti+1
∆x2
+ qx
k = 0
(5)
While there are established iterative methods that allow us to compute the steady-state temperature distri-
bution across the 1D computational domain, we frame this problem as an optimisation task. This results
in an approach wherein we determine the discretized temperature field that admit solution to Eq. A.3, i.e.,
minimization of loss ∼0.
A.4
WIND FARM LAYOUT OPTIMISATION
Wind farm layout optimisation is a critical endeavor in the renewable energy sector. This optimisation task
is aimed at enhancing the efficiency and output of the wind farms by manipulating the position of the wind
turbines. The objective function in this case is the annual energy production (AEP), which is the amount
of electricity that a wind farm can generate in one year. AEP is influenced by wind conditions such as
wind direction and speed. We consider 72 wind directions ranging from 0◦to 360◦with a step size of 5◦,
and we consider a random wind speed whose value is centered around 8 m/s with a standard deviation of
0.5 m/s. The rotor diameter of the turbine is taken to be 126.0 m and the domain is considered to be of size
1000 m × 1000 m. The wake calculation settings are kept the same across all the runs.
28


--- Page 29 ---
B
APPENDIX: PROMPTS
LEO
LEO-Rnd
Explore
Prompt
You are an optimization researcher
tasked to minimize the value of loss.
Current candidate solutions for
N=2 variables in the order
var1, var2 with their respective
function loss in csv format are:
var1, var2, loss
-0.018822,-0.692810,74.271916
0.320219,-1.629214,3430.938028
0.886970,-1.846776,3507.116813
-1.149739,0.407518,4330.723936
1.958779,-0.219516,5479.393434
-0.489178,0.695195,22743.401171
-1.957878,0.271882,91001.711544
-0.095039,1.589113,130107.754358
-0.664592,1.331668,169337.055368
-1.622905,1.526054,353181.485985
You have to look at the above points
and think of the (min, max) values
for each variable that might reduce
or minimize the loss. With these limits
of (min, max) values for each variable,
you must provide exactly 10 new, but
completely different and scattered sets
of values from the above ones, to
explore away regions for minimizing
the function loss. Generate the result
like a csv file with 10 rows and 2
columns, where each row represents
a candidate and each column represents
a variable. The response must only
contain these numerical values in the
csv format without column headers. Do
not provide additional text or explanation.
Strictly, provide only the variable values
as floating point numbers with precision
format %.6f.
You must provide exactly 10 new, but
completely different and scattered sets
of values within all variables, in between
-2 and 2. Generate the result like a csv
file with 10 rows and 2 columns, where each
row represents a candidate and each column
represents a variable. The response must
only contain these numerical values in the
csv format without column headers. Do not
provide additional text or explanation. Strictly,
provide only the variable values as floating
point numbers with precision format %.6f.
For example (with column headers):
0.8166, 0.1868
0.6788, 0.0772
...
0.1853, 0.3935
Table 6: Explore prompt for LEO and LEO-Rnd methods for Goldstein Price problem
29


--- Page 30 ---
LEO
LEO-Rnd
Exploit
prompt
You are an optimization researcher
tasked to minimize the value of loss.
Current best candidate solution for
N=2 variables in the order
var1, var2, with their respective
function loss in csv format are:
var1, var2, loss
1.8859, 0.2995, 101.5838
Please provide exactly 10 new but different
candidates of values for all variables, in
between -2 and 2, to exploit close by regions
for minimizing the function loss. Generate
the result like a csv file with 10 rows and 2
columns, where each row represents a candidate
and each column represents a variable. The
response must only contain these numerical
values in the csv format without column
headers and row index. Do not provide
additional text or explanation. Strictly,
provide only the variable values as floating
point numbers with precision format %.6f.
For example (with column headers):
0.8166, 0.1868
0.6788, 0.0772
...
0.1853, 0.3935
Please provide exactly 10 new but
different candidates of values for all
variables, in between -2 and 2 to
exploit close by regions. Generate
the result like a csv file with 10 rows
and 2 columns, where each row
represents a candidate and each
column represents a variable. The
response must only contain these
numerical values in the csv format
without column headers and row
index. Do not provide additional
text or explanation. Strictly, provide
only the variable values as floating
point numbers with precision format %.6f.
For example (with column headers):
0.8166, 0.1868
0.6788, 0.0772
...
0.1853, 0.3935
Table 7: Exploit prompt for LEO and LEO-Rnd methods for Goldstein Price problem
LEO
Exploit
Prompt
You are an intelligent assistant who can understand great technical details.
You will help me minimise two functions by taking cues from given information.
Current candidate solutions (a, b) with their function loss are:
Candidate 1: a=0.2536, b=0.7346, function loss f1=0.2536, function loss f2=6.2219
Candidate 2: a=0.3953, b=0.1976, function loss f1=0.3953, function loss f2=1.7307
Please provide exactly 2 new but different pairs of values for 0<’a’<1 and 0<’b’<1
to exploit closeby regions for minimizing the function loss1 and function loss2. Take
cues from the above points. The response should contain 4 values, corresponding
to 2 pairs in the format: ’a1, b1, a2, b2, ..., an, bn’. Provide only these 4 numerical
values in order as python [list], separated by commas, with no additional text or
explanation.
Explore
Prompt
You are an intelligent assistant who can understand great technical details.
You will help me minimise two functions by taking cues from given information.
Current candidate solutions (a, b) with their function loss are:
Candidate 1: a=0.3953, b=0.1976, function Loss f1=0.3953, function Loss f2 =1.7307
Candidate 2: a=0.1061, b=0.9373, function Loss f1=0.1061, function Loss f2 =8.4352
Please provide exactly 2 new but different pairs of values for 0<’a’<1 and 0<’b’<1
to explore away regions for minimizing the function loss1 and function loss2. The response
should contain 4 values, corresponding to 2 pairs in the format: ’a1, b1, a2, b2, ..., an, bn’.
Provide only these 4 numerical values in order, separated by commas, with no additional
text or explanation.
Table 8: Exploit and exploit prompts for NSGA II with LLM plug and play.
30


--- Page 31 ---
Prompt
Nosecone design
You are an optimization researcher tasked to minimize the value of function
loss. Current best candidate solution for 1 variable (n) with their respective
function loss are:
candidate: n=0.90000; loss: 0.37450
Give me a new (n) value that satisfies the following: (a) new n is different
from all above, (b) has a function value lower than the above function
values and (c) result in a rapid convergence towards the value of n that
results in lowest function value. Do not write code or any explanation. The
output must end with just a numerical value for next variable.
Rosenbrock 2D
You are an optimization researcher tasked to minimize the value of function
loss with two input variables n1 and n2. Current best candidate solution for
2 variables (n1, n2) with their respective function loss are:
input: n1=1.00, n2=0.300, loss:49.00
Give me a new (n1, n2) pair value that satisfies the following: (a) new n1 and
n2 is different from all above, (b) has a function value lower than the above
function values and (c) result in a rapid convergence towards the value of n1
and n2 that results in lowest function value. Do not write code or any
explanation. The output must end with two numerical values for (n1, n2) only.
Table 9: Prompts for testing reasoning abilities of LEO for Rosenbrock 2D function and rocket nose cone
shape optimization problem
31
